@inproceedings{10.1007/978-3-030-77772-2_1,
author = {B\"{o}ckle, Martin and Yeboah-Antwi, Kwaku and Kouris, Iana},
title = {Can You Trust the Black Box? The Effect of Personality Traits on Trust in AI-Enabled User Interfaces},
year = {2021},
isbn = {978-3-030-77771-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77772-2_1},
doi = {10.1007/978-3-030-77772-2_1},
abstract = {Human-centred artificial intelligence is a fast-growing research stream within the artificial intelligence (AI) and human–computer interaction (HCI) communities. One key focus of this stream is the enablement of trust between end users and the intelligent solution. Although, the current body of literature discusses and proposes a range of best practices for the design of user interfaces for intelligent solutions, there is a dearth of research how such interfaces are perceived by users and especially focusing on trust in these interfaces. In this paper, we investigate how the Big Five personality traits affect trust in AI-enabled user interfaces. We then experimentally verify which design best practices and guidelines proposed by Google enable trust in AI-enabled user interfaces for the different personality types. Initial results (n = 211) reveal that three of the Big Five personality traits – Extraversion, Agreeableness and Open-Mindedness – show a significant correlation between the degree of the personality trait and trust in the proposed storyboards. In addition, we identified significant positive relationships between the perception of trust by users and four out of the twelve design principles: review implicit feedback; connect the feedback to UX changes; create opportunities for feedback; fail gracefully and highlight failure. This paper is of a highly explorative character and provides first experimental results on designing for trust to the HCI/AI community and also highlights future research directions in the form of a research agenda.},
booktitle = {Artificial Intelligence in HCI: Second International Conference, AI-HCI 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings},
pages = {3–20},
numpages = {18},
keywords = {Human-centred AI, Personality traits, HCI/AI, Big five}
}

@inproceedings{10.1007/978-3-031-11647-6_21,
author = {Marsh Runyon, K. Rebecca and D. Montilus, Kinta and Nachman, Larisa and Smith Herrick, Kristen and Ferrara, Lisa},
title = {ETS® AI Labs™ Ways of Working Tutorial: How to Build Evidence-Based, User-Obsessed, AI-Enabled Learning Solutions in an Agile Framework},
year = {2022},
isbn = {978-3-031-11646-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-11647-6_21},
doi = {10.1007/978-3-031-11647-6_21},
abstract = {How do you advance the science and engineering of digital learning solutions at your institution, business, or organization? Bring your current ways of working to this tutorial and get ready to innovate them alongside your fellow researchers, practitioners, business owners, and policy makers. As we work together to share our knowledge and lived experiences, presenters will assist participants in co-creating action plans for how they can utilize best practices from user-centered design (UCD), Design thinking, and Agile to deliver user-obsessed, AI-enabled, efficacious learning solutions.},
booktitle = {Artificial Intelligence  in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium: 23rd International Conference, AIED 2022, Durham, UK, July 27–31, 2022, Proceedings, Part II},
pages = {119–122},
numpages = {4},
keywords = {Agile, Design Thinking, UCD},
location = {Durham, United Kingdom}
}

@inproceedings{10.1007/978-3-030-40124-5_3,
author = {Anwar, Syed Muhammad and Altaf, Tooba and Rafique, Khola and RaviPrakash, Harish and Mohy-ud-Din, Hassan and Bagci, Ulas},
title = {A Survey on Recent Advancements for AI Enabled Radiomics in Neuro-Oncology},
year = {2019},
isbn = {978-3-030-40123-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-40124-5_3},
doi = {10.1007/978-3-030-40124-5_3},
abstract = {Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistance in diagnosis of cancer, planning of treatment strategy, and prediction of survival. Radiomics in neuro-oncology has progressed significantly in the recent past. Deep learning has outperformed conventional machine learning methods in most image-based applications. Convolutional neural networks (CNNs) have seen some popularity in radiomics, since they do not require hand-crafted features and can automatically extract features during the learning process. In this regard, it is observed that CNN based radiomics could provide state-of-the-art results in neuro-oncology, similar to the recent success of such methods in a wide spectrum of medical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology.},
booktitle = {Radiomics and Radiogenomics in Neuro-Oncology: First International Workshop, RNO-AI 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings},
pages = {24–35},
numpages = {12},
keywords = {Radiomics, Neuro-oncology, Classification, Deep learning},
location = {Shenzhen, China}
}

@inproceedings{10.1007/978-3-031-21388-5_4,
author = {Morales, Sergio and Claris\'{o}, Robert and Cabot, Jordi},
title = {Towards a&nbsp;DSL for&nbsp;AI Engineering Process Modeling},
year = {2022},
isbn = {978-3-031-21387-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21388-5_4},
doi = {10.1007/978-3-031-21388-5_4},
abstract = {Many modern software products embed AI components. As a result, their development requires multidisciplinary teams with diverse skill sets. Diversity may lead to communication issues or misapplication of best practices. Process models, which prescribe how software should be developed within an organization, can alleviate this problem. In this paper, we introduce a domain-specific language for modeling AI engineering processes. The DSL concepts stem from our analysis of scientific and gray literature that describes how teams are developing AI-based software. This DSL contributes a structured framework and a common ground for designing, enacting and automating AI engineering processes.},
booktitle = {Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyv\"{a}skyl\"{a}, Finland, November 21–23, 2022, Proceedings},
pages = {53–60},
numpages = {8},
keywords = {Domain-specific language, AI engineering, Process modeling},
location = {Jyv\"{a}skyl\"{a}, Finland}
}

@inproceedings{10.1145/3340435.3342718,
author = {Diosan, Laura and Motogna, Simona},
title = {Artificial intelligence meets software engineering in the classroom},
year = {2019},
isbn = {9781450368520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340435.3342718},
doi = {10.1145/3340435.3342718},
abstract = {We aimed to assess the reliability of teaching Artificial Intelligencefor Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements.We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence},
pages = {35–38},
numpages = {4},
keywords = {Software creation, Software engineering education, theory and algorithms for application domain},
location = {Tallinn, Estonia},
series = {EASEAI 2019}
}

@article{10.1016/j.asoc.2023.110421,
author = {Ahmad, Khlood and Abdelrazek, Mohamed and Arora, Chetan and Bano, Muneera and Grundy, John},
title = {Requirements practices and gaps when engineering human-centered Artificial Intelligence systems},
year = {2023},
issue_date = {Aug 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {143},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2023.110421},
doi = {10.1016/j.asoc.2023.110421},
journal = {Appl. Soft Comput.},
month = {aug},
numpages = {15},
keywords = {Requirements engineering, Software engineering, Artificial Intelligence, Machine learning, Human-centered, Survey research}
}

@inproceedings{10.1145/3494193.3494260,
author = {Rak, Richard},
title = {Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems},
year = {2022},
isbn = {9781450390118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494193.3494260},
doi = {10.1145/3494193.3494260},
abstract = {The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.},
booktitle = {Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance},
pages = {481–484},
numpages = {4},
keywords = {AI, Internet of Healthcare, Internet of Things, data governance, data protection, eHealth, privacy, telehealth},
location = {Athens, Greece},
series = {ICEGOV '21}
}

@inproceedings{10.1145/3581754.3584137,
author = {Wijekoon, Anjana and Wiratunga, Nirmalie and Palihawadana, Chamath and Nkisi-Orji, Ikeckukwu and Corsar, David and Martin, Kyle},
title = {iSee: Intelligent Sharing of Explanation Experience by Users for Users},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584137},
doi = {10.1145/3581754.3584137},
abstract = {The right to obtain an explanation of the decision reached by an Artificial Intelligence&nbsp;(AI) model is now an EU regulation. Different stakeholders of an AI system&nbsp;(e.g. managers, developers, auditors, etc.) may have different background knowledge, competencies and goals, thus requiring different kinds of interpretations and explanations. Fortunately, there is a growing armoury of tools to interpret ML models and explain their predictions, recommendations and diagnoses which we will refer to collectively as explanation strategies. As these explanation strategies mature, practitioners will gain experience that helps them know which strategies to deploy in different circumstances. What is lacking, and is addressed by iSee, is capturing, sharing and re-using explanation strategies based on past positive experiences. The goal of the iSee platform is to improve every user’s experience of AI, by harnessing experiences and best practices in Explainable AI.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {79–82},
numpages = {4},
keywords = {Conversation AI, Explainable AI, Interactive Explanations},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@article{10.1145/3626234,
author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Whittle, Jon and Zowghi, Didar and Jacquet, Aurelie},
title = {Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3626234},
doi = {10.1145/3626234},
abstract = {Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The Responsible AI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and responsible-AI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement responsible AI.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {oct},
keywords = {Responsible AI, ethical AI, trustworthy AI, AI governance, AI engineering, MLOps, software engineering, software architecture, pattern, best practice}
}

@inproceedings{10.1109/COMPSAC.2015.41,
author = {Thekkilakattil, Abhilash and Dodig-Crnkovic, Gordana},
title = {Ethics Aspects of Embedded and Cyber-Physical Systems},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.41},
doi = {10.1109/COMPSAC.2015.41},
abstract = {The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the "responsibility" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical "responsibility" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {39–44},
numpages = {6},
keywords = {Cyber-physical systems, Ethics, Extra-functional Properties, Software-responsibility},
series = {COMPSAC '15}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00042,
author = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
title = {Software engineering for machine learning: a case study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00042},
doi = {10.1109/ICSE-SEIP.2019.00042},
abstract = {Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be "entangled" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {291–300},
numpages = {10},
keywords = {AI, data, process, software engineering},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1007/978-3-031-28238-6_22,
author = {Agarwal, Anmol and Gupta, Shrey and Bonagiri, Vamshi and Gaur, Manas and Reagle, Joseph and Kumaraguru, Ponnurangam},
title = {Towards Effective Paraphrasing for&nbsp;Information Disguise},
year = {2023},
isbn = {978-3-031-28237-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-28238-6_22},
doi = {10.1007/978-3-031-28238-6_22},
abstract = {Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors’ posts on the Internet. Research on ID becomes important when authors’ written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author’s post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit “r/AmItheAsshole” as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach. ()},
booktitle = {Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2–6, 2023, Proceedings, Part II},
pages = {331–340},
numpages = {10},
keywords = {Neural information retrieval, Adversarial retrieval, Paraphrasing, Information disguise, Computational ethics},
location = {Dublin, Ireland}
}

@inproceedings{10.1145/3383583.3398496,
author = {Fox, Edward A.},
title = {How Should One Explore the Digital Library of the Future?},
year = {2020},
isbn = {9781450375856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383583.3398496},
doi = {10.1145/3383583.3398496},
abstract = {Motivated by the Foreword of Licklider's "Libraries of the Future" (dedicated to Vannevar Bush), this keynote focuses on users, exploration, and future directions of the digital library (DL) field, which moves toward procognitive systems. Many different digital library "users," each a member of a Society, engage in a diversity of Scenarios, often involving some aspect of exploration, usually of the DL content Streams. Services -- e.g., searching, browsing, recommending, and visualizing -- help those users leverage knowledge Structures and Spatial representations. Following on the final sentence of Licklider's book, we "call for a formal base plus an overlay of experience, " leading to a new way to build better DLs. Licklider said we seek "the facts, concepts, principles, and ideas that lie behind the visible and tangible aspects of documents," to help us acquire and use knowledge. Put simply: "The console of the procognitive system will have two special buttons, a silver one labeled 'Where am I" and a gold one labeled 'What should I do next?' "How can we build and use this?For more than 55 years, researchers have applied artificial intelligence (AI), natural language processing (NLP), representations (data, information, knowledge), question-answering, databases, human-computer interaction, and other techniques described by Licklider, to these challenges. We have a vast range of hardware and software services available, but without a more formal approach, will not enable adaptive self-organization and tailored exploration.The 5S framework can help us build, apply, and improve digital libraries to facilitate exploration, through a formal approach that will simplify such efforts, making them extensible through both human and computing agents. For example, to more easily build DLs, we propose collaboratively building knowledge graphs -- involving both User eXperience designers, subject matter experts, and developers -- that specify connections to services and workflows, enabling DL operation atop a workflow engine. User exploration, additional help by UX designers, recommendations of adaptations of existing workflows, and AI-based optimizations and solutions to new problems, will all expand the knowledge graph to ensure new and more helpful assistance.When this is accomplished, we must teach and learn about this next generation of digital libraries, further developing suitable curriculum and educational modules, that rest upon a solid theoretical foundation, helping spread understanding of key concepts and best practices.},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020},
pages = {1–2},
numpages = {2},
keywords = {5S, AI, HCI, NLP, adaptive self-organization, licklider, procognitive, scenarios, societies, spaces, streams, structures},
location = {Virtual Event, China},
series = {JCDL '20}
}

@inproceedings{10.1145/3616961.3616969,
author = {Raftopoulos, Marigo},
title = {[WORKSHOP] Augmented Humans: Provocations for collaborative AI system design},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616969},
doi = {10.1145/3616961.3616969},
abstract = {This workshop is designed to facilitate an exploration of collaborative methodologies from both academia and industry practice to advance insight into the emergent problem space of designing AI-enabled information systems. The recent developments and implementations of AI-enabled technologies have seen a parallel proliferation of practical approaches to ensure human-centred and ethical design principles are imbedded into AI development which has largely been in response to widespread industry criticism of unethical practices and unintended negative consequences of ‘black box’ algorithmic decision making. Our prototype design cards and collaborative design process are targeted at current problems and limitations with intelligent human-machine systems that can be averted with more inclusive collaboration with users as stakeholders in system design. Our intention is to refine our AI design methodology and design cards over several international workshops and to provide them to the public as a free open-source tool for AI researchers and practitioners.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {294–297},
numpages = {4},
keywords = {artificial intelligence, design cards, stakeholder collaborative design methods},
location = {<conf-loc>, <city>Tampere</city>, <country>Finland</country>, </conf-loc>},
series = {Mindtrek '23}
}

@inproceedings{10.1007/978-3-031-15342-6_7,
author = {Kabudi, Tumaini and Pappas, Ilias O. and Olsen, Dag H.},
title = {Deriving Design Principles for AI-Adaptive Learning Systems: Findings from Interviews with Experts},
year = {2022},
isbn = {978-3-031-15341-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-15342-6_7},
doi = {10.1007/978-3-031-15342-6_7},
abstract = {AI applications are increasing in the field of education, from laboratory set-ups to contemporary and complex learning systems. A great example of such systems is AI-enabled adaptive learning systems (AI-ALS) that promote adaptive learning. Despite its promised potential, there are challenges such as design issues, highly complex models, and lack of evidence-based guidelines and design principles that hinder the large-scale adoption and implementation of AI-ALS. The goal of this paper thus is to establish a set of empirically grounded design principles (DPs) of AI-ALS, that would serve well in a university context. 22 interviews were con-ducted with experts knowledgeable about the design and development of AI-ALS. Several rounds of coding and deep analysis of the expert interviews revealed features and functionalities of AI-ALS; purposes for designing and using AI-ALS; and recommended improvements for AI-ALS as requirements. These requirements were translated to 13 preliminary DPs. The findings of this study serve as a guide on how to better design AI-ALS, that will improve the learning experiences of students.},
booktitle = {The Role of Digital Technologies in Shaping the Post-Pandemic World: 21st IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2022, Newcastle upon Tyne, UK, September 13–14, 2022, Proceedings},
pages = {82–94},
numpages = {13},
keywords = {AI, AIEd, Design principles, Adaptive learning systems, Adaptive learning},
location = {Newcastle upon Tyne, United Kingdom}
}

@article{10.1007/s00146-021-01285-y,
author = {Nandutu, Irene and Atemkeng, Marcellin and Okouma, Patrice},
title = {Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda},
year = {2021},
issue_date = {Feb 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {1},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-021-01285-y},
doi = {10.1007/s00146-021-01285-y},
abstract = {With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.},
journal = {AI Soc.},
month = {sep},
pages = {245–257},
numpages = {13},
keywords = {Wildlife conservation concerns, Human–wildlife conflicts, AI Ethics, AI in wildlife conservation, AI Ethics integration, Artificial intelligence}
}

@inproceedings{10.1007/978-3-031-32808-4_7,
author = {Bunde, Enrico and Eisenhardt, Daniel and Sonntag, Daniel and Profitlich, Hans-J\"{u}rgen and Meske, Christian},
title = {Giving DIAnA More TIME – Guidance for the Design of XAI-Based Medical Decision Support Systems},
year = {2023},
isbn = {978-3-031-32807-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-32808-4_7},
doi = {10.1007/978-3-031-32808-4_7},
abstract = {Future healthcare ecosystems integrating human-centered artificial intelligence (AI) will be indispensable. AI-based healthcare technologies can support diagnosis processes and make healthcare more accessible globally. In this context, we conducted a design science research project intending to introduce design principles for user interfaces (UIs) of explainable AI-based (XAI) medical decision support systems (XAI-based MDSS). We used an archaeological approach to analyze the UI of an existing web-based system in the context of skin lesion classification called DIAnA (Dermatological Images – Analysis and Archiving). One of DIAnA’s unique characteristics is that it should be usable for the stakeholder groups of physicians and patients. We conducted the in-situ analysis with these stakeholders using the think-aloud method and semi-structured interviews. We anchored our interview guide in concepts of the Theory of Interactive Media Effects (TIME), which formulates UI features as causes and user psychology as effects. Based on the results, we derived 20 design requirements and developed nine design principles grounded in TIME for this class of XAI-based MDSS, either associated with the needs of physicians, patients, or both. Regarding evaluation, we first conducted semi-structured interviews with software developers to assess the reusability of our design principles. Afterward, we conducted a survey with user experience/interface designers. The evaluation uncovered that 77% of the participants would adopt the design principles, and 82% would recommend them to colleagues for a suitable project. The findings prove the reusability of the design principles and highlight a positive perception by potential implementers.},
booktitle = {Design Science Research for a New Society: Society 5.0: 18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023, Pretoria, South Africa, May 31 – June 2, 2023, Proceedings},
pages = {107–122},
numpages = {16},
keywords = {Design Science Research, Design Principles, Explainable Artificial Intelligence, Medical Decision Support Systems, Healthcare},
location = {Pretoria, South Africa}
}

@article{10.1007/s10796-022-10284-3,
author = {V\"{o}ssing, Michael and K\"{u}hl, Niklas and Lind, Matteo and Satzger, Gerhard},
title = {Designing Transparency for Effective Human-AI Collaboration},
year = {2022},
issue_date = {Jun 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-022-10284-3},
doi = {10.1007/s10796-022-10284-3},
abstract = {The field of artificial intelligence (AI) is advancing quickly, and systems can increasingly perform a multitude of tasks that previously required human intelligence. Information systems can facilitate collaboration between humans and AI systems such that their individual capabilities complement each other. However, there is a lack of consolidated design guidelines for information systems facilitating the collaboration between humans and AI systems. This work examines how agent transparency affects trust and task outcomes in the context of human-AI collaboration. Drawing on the 3-Gap framework, we study agent transparency as a means to reduce the information asymmetry between humans and the AI. Following the Design Science Research paradigm, we formulate testable propositions, derive design requirements, and synthesize design principles. We instantiate two design principles as design features of an information system utilized in the hospitality industry. Further, we conduct two case studies to evaluate the effects of agent transparency: We find that trust increases when the AI system provides information on its reasoning, while trust decreases when the AI system provides information on sources of uncertainty. Additionally, we observe that agent transparency improves task outcomes as it enhances the accuracy of judgemental forecast adjustments.},
journal = {Information Systems Frontiers},
month = {jun},
pages = {877–895},
numpages = {19},
keywords = {Agent transparency, Design science research, Human-AI collaboration, Human-AI interaction, Trust}
}

@inproceedings{10.1007/978-3-031-35891-3_8,
author = {Kutz, Janika and Neuh\"{u}ttler, Jens and Bienzeisler, Bernd and Spilski, Jan and Lachmann, Thomas},
title = {Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services},
year = {2023},
isbn = {978-3-031-35890-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35891-3_8},
doi = {10.1007/978-3-031-35891-3_8},
abstract = {AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.},
booktitle = {Artificial Intelligence in HCI: 4th International Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I},
pages = {115–130},
numpages = {16},
keywords = {Industrial AI, Human-Centered AI, Design Principles},
location = {Copenhagen, Denmark}
}

@article{10.1016/j.chb.2023.107737,
author = {J\"{a}rvel\"{a}, Sanna and Nguyen, Andy and Vuorenmaa, Eija and Malmberg, Jonna and J\"{a}rvenoja, Hanna},
title = {Predicting regulatory activities for socially shared regulation to optimize collaborative learning},
year = {2023},
issue_date = {Jul 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {144},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2023.107737},
doi = {10.1016/j.chb.2023.107737},
journal = {Comput. Hum. Behav.},
month = {jul},
numpages = {10},
keywords = {Socially shared regulation, Collaborative learning, Multimodal data, Physiological signal, Episode rule mining, Artificial intelligence (AI)}
}

@inproceedings{10.1007/978-3-030-98404-5_23,
author = {Park, Sunyoung and Kim, Hyun K. and Lee, Yuryeon and Park, Gyuwon and Lee, Danbi},
title = {User Experience Design for Defense Systems with AI},
year = {2021},
isbn = {978-3-030-98403-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98404-5_23},
doi = {10.1007/978-3-030-98404-5_23},
abstract = {As artificial intelligence (AI) is applied at an increasing frequency in various fields, the number of studies on the user experience (UX) design of human-AI interaction is also increasing. However, the results of these studies on AI UX design principles are insufficient for actual AI systems. In light of this fact, the purpose of this study was to upgrade the UX design of a defense system that uses AI technology to detect land changes and targets. In order to upgrade the UX design of this AI system, a three-step procedure was executed. First, AI UX principles were derived by analyzing literature related to human-AI interaction. Second, ideation was performed to improve the interface. Finally, the results of the ideation were utilized to construct the UX prototype of the AI system with Adobe XD. The results of this study are expected to be used as fundamental data for future research that will develop UX principles and advanced methods for AI systems.},
booktitle = {Intelligent Human Computer Interaction: 13th International Conference, IHCI 2021, Kent, OH, USA, December 20–22, 2021, Revised Selected Papers},
pages = {242–247},
numpages = {6},
keywords = {Artificial intelligence, User experience, AI UX, AI system design, AI usability, AI system design process},
location = {Kent, OH, USA}
}

@inproceedings{10.1007/978-3-031-32808-4_29,
author = {Oberste, Luis and R\"{u}ffer, Florian and Ayding\"{u}l, Okan and Rink, Johann and Heinzl, Armin},
title = {Designing User-Centric Explanations for Medical Imaging with Informed Machine Learning},
year = {2023},
isbn = {978-3-031-32807-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-32808-4_29},
doi = {10.1007/978-3-031-32808-4_29},
abstract = {A flawed algorithm released in clinical practice can cause unintended harm to patient health. Risks, regulation, responsibility, and ethics shape the demand of clinical users to understand and rely on the outputs made by artificial intelligence. Explainable artificial intelligence (XAI) offers methods to render a model’s behavior understandable from different perspectives. Extant XAI, however, is mainly data-driven and designed to meet developers’ demands to correct models rather than clinical users’ expectations to reflect clinically relevant information. To this end, informed machine learning (IML) utilizes prior knowledge jointly with data to generate predictions, a promising paradigm to enrich XAI with medical knowledge. To explore how IML can be used to generate explanations that are congruent to clinical users’ demands and useful to medical decision-making, we conduct Action Design Research (ADR) in collaboration with a team of radiologists. We propose an IML-based XAI system for clinically relevant explanations of diagnostic imaging predictions. With the help of ADR, we reduce the gap between implementation and user evaluation and demonstrate the effectiveness of the system in a real-world application with clinicians. While we develop design principles of using IML for user-centric XAI in diagnostic imaging, the study demonstrates that an IML-based design adequately reflects clinicians’ conceptions. In this way, IML inspires greater understandability and trustworthiness of AI-enabled diagnostic imaging.},
booktitle = {Design Science Research for a New Society: Society 5.0: 18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023, Pretoria, South Africa, May 31 – June 2, 2023, Proceedings},
pages = {470–484},
numpages = {15},
keywords = {Explainable Artificial Intelligence, Informed Machine Learning, Action Design Research, Medical Image Analysis, User-Centric Design},
location = {Pretoria, South Africa}
}

@inproceedings{10.1145/3491101.3519809,
author = {Lu, Yuwen and Zhang, Chengzhi and Zhang, Iris and Li, Toby Jia-Jun},
title = {Bridging the Gap Between UX Practitioners’ Work Practices and AI-Enabled Design Support Tools},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519809},
doi = {10.1145/3491101.3519809},
abstract = {User interface (UI) and user experience (UX) design have become an indispensable part of today’s tech industry. Recently, much progress has been made in machine-learning-enabled design support tools for UX designers. However, few of these tools have been adopted by practitioners. To learn the underlying reasons and understand user needs for bridging this gap, we conducted a retrospective analysis with 8 UX professionals to understand their practice and identify opportunities for future research. We found that the current AI-enabled systems to support UX work mainly work on graphical interface elements, while design activities that involve more ‘design thinking” such as user interviews and user testings are more helpful for designers. Many current systems were also designed for overly-simplistic and generic use scenarios. We identified 4 areas in the UX workflow that can benefit from additional AI-enabled assistance: design inspiration search, design alternative exploration, design system customization, and design guideline violation check.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {7},
keywords = {Human-AI Collaboration, User Experience (UX), data-driven design, design-support tools},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@phdthesis{10.5555/AAI28541283,
author = {Ebrahimi, Mohammadreza and F., Nunamaker, Jay and A, Brown, Susan},
advisor = {Hsinchun, Chen,},
title = {AI-Enabled Cybersecurity Analytics: Detecting and Defending against Cyber Threats},
year = {2021},
isbn = {9798534685190},
publisher = {The University of Arizona},
abstract = {Cyber attacks are estimated to cost the global economy $6 trillion annually by 2021. To combat these attacks, many cybersecurity organizations rely on manual cyber threat detection and mitigation approaches for cyber defense. However, the fast-paced nature of the cyber threat landscape and the sheer volume of the data preclude effective cyber defense via manual approaches or ad-hoc software programs. Artificial Intelligence (AI)-enabled cybersecurity is an emerging approach that draws upon statistical and machine learning theories to yield AI agents that address this issue. These agents can automatically conduct cyber defense operations at a large scale, provide predictive insights in complex tasks, and improve incident response. Consequently, major cybersecurity analytics firms are increasingly incorporating AI agents into their cyber defense fabric. Despite their promise, AI agents are vulnerable to adversarial attacks from AI-enabled adversaries. These adversarial attacks incur damage by automatically generating malicious input data that misleads these AI agents. Given the societal impact of AI-enabled cybersecurity and the crucial need for resistant cybersecurity AI agents, this dissertation presents six essays to contribute to two broad aspects of AI-enabled cybersecurity: AI agents for cybersecurity – designing AI agents to automate detecting cyber threats (three essays), and (2) security of AI agents – designing AI agents for defending against adversarial attacks (three essays). To make concrete contributions to cyber defense, each of these aspects is focused on a high-impact cybersecurity application domain. The first aspect concerns dark web analytics – focusing on cyber threat detection in international hidden anonymous platforms. The second area focuses on malware analytics – targeting the robustness of malware detectors against adversarial attacks. The essays follow design science guidelines to draw on statistical machine learning theories to develop Information Technology (IT) artifacts that address cybersecurity research inquiries via novel designs that enhance IS (information systems) knowledge base. Each proposed design also contributes to the state-of-the-art in the reference discipline (i.e., statistical machine learning) via one or more novel algorithms in transductive learning, transfer learning, adversarial learning, and reinforcement learning theory. Essays I-III are dedicated to AI for cybersecurity. Specifically, Essay I offers a cybersecurity AI agent to identify key cyber threats in English dark net markets using transductive learning. Essay II generalizes the first essay to a multilingual setting for detecting cyber threats within the international dark web using transfer and adversarial learning. Essay III extends the second essay from text to image analytics in illegal e-commerce markets by presenting a more general framework leveraging adversarial kernel learning and deep dictionary learning. Essays IV-VI target the security of AI agents. Specifically, Essay IV focuses on a high-impact application of AI for improving the security of AI-enabled malware detectors as the first line of defense in cybersecurity. Essay V generalizes Essay IV to improve the robustness of any cybersecurity AI agent against adversarial attacks via reinforcement learning (RL) and robust optimization theory. Finally, Essay VI offers a generalized approach to defend against adversarial attacks based on sequential decision making and learning action representations in RL to minimize reliance on insider knowledge about the attack target.},
note = {AAI28541283}
}

@article{10.1016/j.eswa.2022.118002,
author = {Devagiri, Jeevan S. and Paheding, Sidike and Niyaz, Quamar and Yang, Xiaoli and Smith, Samantha},
title = {Augmented Reality and Artificial Intelligence in industry: Trends, tools, and future challenges},
year = {2022},
issue_date = {Nov 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {207},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2022.118002},
doi = {10.1016/j.eswa.2022.118002},
journal = {Expert Syst. Appl.},
month = {nov},
numpages = {13},
keywords = {Augmented Reality, Artificial Intelligence, Machine learning, Industrial applications, Deep learning}
}

@inproceedings{10.1145/3544548.3580900,
author = {Yildirim, Nur and Pushkarna, Mahima and Goyal, Nitesh and Wattenberg, Martin and Vi\'{e}gas, Fernanda},
title = {Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580900},
doi = {10.1145/3544548.3580900},
abstract = {Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {356},
numpages = {13},
keywords = {human-AI guidelines, human-AI interaction, people AI guidebook},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}

@inproceedings{10.1145/3419249.3420105,
author = {Komatsu, Tomoko and Gutierrez Lopez, Marisela and Makri, Stephann and Porlezza, Colin and Cooper, Glenda and MacFarlane, Andrew and Missaoui, Sondess},
title = {AI should embody our values: Investigating journalistic values to inform AI technology design},
year = {2020},
isbn = {9781450375795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419249.3420105},
doi = {10.1145/3419249.3420105},
abstract = {In the current climate of shrinking newsrooms and revenues, journalists face increasing pressures exerted by the industry’s for-profit focus and the expectation of intensified output. While AI-enabled journalism has great potential to help alleviate journalists’ pressures, it might also disrupt journalistic norms and, at worst, interfere with their duty to inform the public. For AI systems to be as useful as possible, designers should understand journalists’ professional values and incorporate them into their designs. We report findings from interviews with journalists to understand their perceptions of how professional values that are important to them (such as truth, impartiality and originality) might be supported and/or undermined by AI technologies. Based on these findings, we provide design insight and guidelines for incorporating values into the design of AI systems. We argue HCI design can achieve the strongest possible value alignment by moving beyond merely supporting important values, to truly embodying them.},
booktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
articleno = {11},
numpages = {13},
keywords = {algorithmic systems, artificial intelligence, automated journalism, value sensitive design, values},
location = {Tallinn, Estonia},
series = {NordiCHI '20}
}

@inproceedings{10.1145/3325413.3329793,
author = {Almeida, Mario and Laskaridis, Stefanos and Leontiadis, Ilias and Venieris, Stylianos I. and Lane, Nicholas D.},
title = {EmBench: Quantifying Performance Variations of Deep Neural Networks across Modern Commodity Devices},
year = {2019},
isbn = {9781450367714},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325413.3329793},
doi = {10.1145/3325413.3329793},
abstract = {In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators.},
booktitle = {The 3rd International Workshop on Deep Learning for Mobile Systems and Applications},
pages = {1–6},
numpages = {6},
keywords = {deep neural networks, mobile devices, on-device inference},
location = {Seoul, Republic of Korea},
series = {EMDL '19}
}

@article{10.1109/MIC.2022.3182349,
author = {Sheth, Amit and Gaur, Manas and Roy, Kaushik and Venkataraman, Revathy and Khandelwal, Vedant and Sheth, Amit},
title = {Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety},
year = {2022},
issue_date = {Sept.-Oct. 2022},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {26},
number = {5},
issn = {1089-7801},
url = {https://doi.org/10.1109/MIC.2022.3182349},
doi = {10.1109/MIC.2022.3182349},
abstract = {AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.},
journal = {IEEE Internet Computing},
month = {sep},
pages = {76–84},
numpages = {9}
}

@article{10.1145/3636508,
author = {Schelenz, Laura and Segal, Avi and Adelio, Oduma and Gal, Kobi},
title = {Transparency-Check: An Instrument for the Study and Design of Transparency in AI-based Personalization Systems},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636508},
doi = {10.1145/3636508},
abstract = {As AI-based systems become commonplace in our daily lives, they need to provide understandable information to their users about how they collect, process, and output information that concerns them. The importance of such transparency practices has gained significance due to recent ethical guidelines and regulation, as well as research suggesting a positive relationship between the transparency of AI-based systems and users’ satisfaction. This paper provides a new tool for the design and study of transparency in AI-based systems that use personalization. The tool, called Transparency-Check, is based on a checklist of questions about transparency in four areas of a system: input (data collection), processing (algorithmic models), output (personalized recommendations) and user control (user feedback mechanisms to adjust elements of the system). Transparency-Check can be used by researchers, designers, and end users of computer systems. To demonstrate the usefulness of Transparency-Check from a researcher perspective, we collected the responses of 108 student participants who used the transparency checklist to rate five popular real-world systems (Amazon, Facebook, Netflix, Spotify, and YouTube). Based on users’ subjective evaluations, the systems showed low compliance with transparency standards, with some nuances about individual categories (specifically data collection, processing, user control). We use these results to compile design recommendations for improving transparency in AI-based systems, such as integrating information about the system’s behavior during the user’s interactions with it.},
note = {Just Accepted},
journal = {ACM J. Responsib. Comput.},
month = {dec},
keywords = {Transparency, Guideline, Best Practice, User Study, Ethics, Design, Artifical Intelligence, Personalization}
}

@inproceedings{10.1145/3411764.3445591,
author = {Rietz, Tim and Maedche, Alexander},
title = {Cody: An AI-Based System to Semi-Automate Coding for Qualitative Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445591},
doi = {10.1145/3411764.3445591},
abstract = {Qualitative research can produce a rich understanding of a phenomenon but requires an essential and strenuous data annotation process known as coding. Coding can be repetitive and time-consuming, particularly for large datasets. Existing AI-based approaches for partially automating coding, like supervised machine learning (ML) or explicit knowledge represented in code rules, require high technical literacy and lack transparency. Further, little is known about the interaction of researchers with AI-based coding assistance. We introduce Cody, an AI-based system that semi-automates coding through code rules and supervised ML. Cody supports researchers with interactively (re)defining code rules and uses ML to extend coding to unseen data. In two studies with qualitative researchers, we found that (1) code rules provide structure and transparency, (2) explanations are commonly desired but rarely used, (3) suggestions benefit coding quality rather than coding speed, increasing the intercoder reliability, calculated with Krippendorff’s Alpha, from 0.085 (MAXQDA) to 0.33 (Cody).},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {394},
numpages = {14},
keywords = {Artifact design, Qualitative coding, Qualitative research, Rule-based coding, Supervised machine learning, User-centered design},
location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
series = {CHI '21}
}

@inproceedings{10.1145/3522664.3528590,
author = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
title = {Data smells: categories, causes and consequences, and detection of suspicious data in AI-based systems},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528590},
doi = {10.1145/3522664.3528590},
abstract = {High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {229–239},
numpages = {11},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3394486.3409557,
author = {Amershi, Saleema},
title = {Toward Responsible AI by Planning to Fail},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3409557},
doi = {10.1145/3394486.3409557},
abstract = {The potential for AI technologies to enhance human capabilities and improve our lives is of little debate; yet, neither is their potential to cause harm and social disruption. While preventing or minimizing AI biases and harms is justifiably the subject of intense study in academic, industrial and even legal communities, an approach centered on acknowledging and planning for AI-based failures has the potential to shed new light on how to develop and deploy responsible AI-based systems.In this talk, I will discuss the sociotechnical nature of several inherent and unavoidable AI failures and why it is important for the industry to systematically and proactively identify, assess, and mitigate harms caused by such failures in our AI-based products and services. I will then present Microsoft's recently released Guidelines for Human-AI Interaction and how we've been using them at Microsoft to help teams think through and prepare for different types of AI failures.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3607},
numpages = {1},
keywords = {guidelines, human-ai interaction, responsible and ethical ai},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1109/MCOM.001.1900103,
author = {Zhu, Guangxu and Liu, Dongzhu and Du, Yuqing and You, Changsheng and Zhang, Jun and Huang, Kaibin},
title = {Toward an Intelligent Edge: Wireless Communication Meets Machine Learning},
year = {2020},
issue_date = {January 2020},
publisher = {IEEE Press},
volume = {58},
number = {1},
issn = {0163-6804},
url = {https://doi.org/10.1109/MCOM.001.1900103},
doi = {10.1109/MCOM.001.1900103},
abstract = {The recent revival of AI is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and IoT devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interest in realizing an "intelligent edge" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, has emerged, which crosses and revolutionizes two disciplines: wireless communication and machine learning. A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design guidelines for wireless communication in edge learning, collectively called learning- driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design guidelines. Unique research opportunities are identified.},
journal = {Comm. Mag.},
month = {jan},
pages = {19–25},
numpages = {7}
}

@article{10.1016/j.asoc.2023.110455,
author = {Ahmad, Khlood and Abdelrazek, Mohamed and Arora, Chetan and Agrahari Baniya, Arbind and Bano, Muneera and Grundy, John},
title = {Requirements engineering framework for human-centered artificial intelligence software systems},
year = {2023},
issue_date = {Aug 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {143},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2023.110455},
doi = {10.1016/j.asoc.2023.110455},
journal = {Appl. Soft Comput.},
month = {aug},
numpages = {19},
keywords = {Requirements engineering, Software engineering, Artificial intelligence, Machine learning, Human-centered, Conceptual modeling, Virtual reality, Empirical software engineering}
}

@inproceedings{10.1609/aiide.v18i1.21955,
author = {Kreminski, Max and Dickinson, Melanie and Wardrip-Fruin, Noah and Mateas, Michael},
title = {Loose ends: a mixed-initiative creative interface for playful storytelling},
year = {2022},
isbn = {978-1-57735-877-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aiide.v18i1.21955},
doi = {10.1609/aiide.v18i1.21955},
abstract = {We present Loose Ends, a mixed-initiative co-creative storytelling play experience in which a human player and an AI system work together to compose a story. Loose Ends specifically aims to provide computational support for managing multiple parallel plot threads and bringing these threads to satisfying conclusions—something that has proven difficult in past attempts to facilitate playful mixed-initiative storytelling. We describe the overall human-AI interaction loop in Loose Ends, including the implementation of the rules-based AI system that enables this interaction loop; discuss four examples of desirable mixed-initiative interactions that are possible in Loose Ends, but not in similar systems; and present results from a preliminary expert evaluation of Loose Ends. Altogether, we find that Loose Ends shows promise for creating a sense of coauthorship in the player while also mitigating the directionlessness reported by players of earlier systems.},
booktitle = {Proceedings of the Eighteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
articleno = {15},
numpages = {9},
location = {Pomona, CA, USA},
series = {AIIDE'22}
}

@inproceedings{10.1007/978-3-031-40837-3_11,
author = {Tavolato-W\"{o}tzl, Christina and Tavolato, Paul},
title = {Enhancing Trust in Machine Learning Systems by Formal Methods: With an Application to a Meteorological Problem},
year = {2023},
isbn = {978-3-031-40836-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-40837-3_11},
doi = {10.1007/978-3-031-40837-3_11},
abstract = {With the deployment of applications based on machine learning techniques the need for understandable explanations of these systems’ results becomes evident. This paper clarifies the concept of an “explanation”: the main goal of an explanation is to build trust in the recipient of the explanation. This can only be achieved by creating an understanding of the results of the AI systems in terms of the users’ domain knowledge. In contrast to most of the approaches found in the literature, which base the explanation of the AI system’s results on the model provided by the machine learning algorithm, this paper tries to find an explanation in the specific expert knowledge of the system’s users. The domain knowledge is defined as a formal model derived from a set of if-then-rules provided by experts. The result from the AI system is represented as a proposition in a temporal logic. Now we attempt to formally prove this proposition within the domain model. We use model checking algorithms and tools for this purpose. If the proof is successful, the result of the AI system is consistent with the model of the domain knowledge. The model contains the rules it is based on and hence the path representing the proof can be translated back to the rules: this explains, why the proposition is consistent with the domain knowledge. The paper describes the application of this approach to a real world example from meteorology, the short-term forecasting of cloud coverage for particular locations.},
booktitle = {Machine Learning and Knowledge Extraction: 7th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2023, Benevento, Italy, August 29 – September 1, 2023, Proceedings},
pages = {170–187},
numpages = {18},
keywords = {Explainable AI, Machine Learning, Formal Methods, Model Checking, Solar Radiation Forecast, Meteorology},
location = {Benevento, Italy}
}

@article{10.1145/3631614,
author = {Larasati, Retno and De Liddo, Anna and Motta, Enrico},
title = {Meaningful Explanation Effect on User’s Trust in an AI Medical System: Designing Explanations for Non-Expert Users},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3631614},
doi = {10.1145/3631614},
abstract = {Whereas most research in AI system explanation for healthcare applications looks at developing algorithmic explanations targeted at AI experts or medical professionals, the question we raise is: How do we build meaningful explanations for laypeople? And how does a meaningful explanation affect user’s trust perceptions? Our research investigates how the key factors affecting human-AI trust change in the light of human expertise, and how to design explanations specifically targeted at non-experts. By means of a stage-based design method, we map the ways laypeople understand AI explanations in a User Explanation Model. We also map both medical professionals and AI experts’ practice in an Expert Explanation Model. A Target Explanation Model is then proposed, which represents how experts’ practice and layperson’s understanding can be combined to design meaningful explanations. Design guidelines for meaningful AI explanations are proposed, and a prototype of AI system explanation for non-expert users in a breast cancer scenario is presented and assessed on how it affect users’ trust perceptions.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {dec},
articleno = {30},
numpages = {39},
keywords = {Explanation, trust, artificial intelligence explanation}
}

@inproceedings{10.1145/3593434.3593453,
author = {Agbese, Mamia and Mohanani, Rahul and Khan, Arif and Abrahamsson, Pekka},
title = {Implementing AI Ethics: Making Sense of the Ethical Requirements},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593453},
doi = {10.1145/3593434.3593453},
abstract = {Society’s increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {62–71},
numpages = {10},
keywords = {AI, AI ethics, AI ethics principles, Agile portfolio management, Ethical requirements, Ethical requirements stack},
location = {Oulu, Finland},
series = {EASE '23}
}

@article{10.1016/j.compbiomed.2022.106337,
author = {Vahadane, Abhishek and Sharma, Shreya and Mandal, Devraj and Dabbeeru, Madan and Jakthong, Josephine and Garcia-Guzman, Miguel and Majumdar, Shantanu and Lee, Chung-Wein},
title = {Development of an automated combined positive score prediction pipeline using artificial intelligence on multiplexed immunofluorescence images},
year = {2023},
issue_date = {Jan 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2022.106337},
doi = {10.1016/j.compbiomed.2022.106337},
journal = {Comput. Biol. Med.},
month = {jan},
numpages = {9},
keywords = {CPS, Combined positive score, mIF, Multiplex immunofluorescence, IHC, Immunohistochemistry, HNSCC, Head and neck squamous cell carcinoma, PD1, Program cell death protein 1, PD-L1, Programmed cell death ligand 1, ICI, Immune checkpoint inhibitors, FFPE, Formalin-fixed, paraffin-embedded, AI, Artificial intelligence, Deep learning}
}

@article{10.1007/s10462-022-10260-y,
author = {Nguyen, Khanh T. P. and Medjaher, Kamal and Tran, Do T.},
title = {A review of artificial intelligence methods for engineering prognostics and health management with implementation guidelines},
year = {2022},
issue_date = {Apr 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-022-10260-y},
doi = {10.1007/s10462-022-10260-y},
abstract = {The past decade has witnessed the adoption of artificial intelligence (AI) in various applications. It is of no exception in the area of prognostics and health management (PHM) where the capacity of AI has been highlighted through numerous studies. In this paper, we present a comprehensive review of AI-based solutions in engineering PHM. This review serves as a guideline for researchers and practitioners with varying levels of experience seeking to broaden their know-how about AI-based PHM. Specifically, we provide both a broad quantitative analysis and a comprehensive qualitative examination of the roles of AI in PHM. The quantitative analysis offers an insight into the research community’s interest in AI-based approaches, focusing on the evolution of research trends and their developments in different PHM application areas. The qualitative survey gives a complete picture on the employment of AI in each stage of the PHM process, from data preparation to decision support. Based on the strengths and weaknesses of existing methods, we derive a general guideline for choosing proper techniques for each specific PHM task, aiming to level up maintenance practitioners’ efficiency in implementing PHM solutions. Finally, the review discusses challenges and future research directions in the development of autonomous intelligent PHM solutions.},
journal = {Artif. Intell. Rev.},
month = {sep},
pages = {3659–3709},
numpages = {51},
keywords = {Artificial intelligence, Prognostics and health management, Condition monitoring, Machine learning, Predictive maintenance, Decision-making support}
}

@inproceedings{10.1007/978-981-99-8024-6_8,
author = {Ji, Ilhwan and Jeon, Seungho and Seo, Jung Taek},
title = {AE-LSTM Based Anomaly Detection System for Communication Over DNP 3.0},
year = {2024},
isbn = {978-981-99-8023-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-981-99-8024-6_8},
doi = {10.1007/978-981-99-8024-6_8},
abstract = {Energy Management System (EMS) communicates with power plants and substations to maintain the reliability and efficiency of power supplies. EMS collects and monitors data from these sources and controls power flow through commands to ensure uninterrupted power supply, frequency and voltage maintenance, and power recovery in the event of a power outage. EMS works in a Distributed Network Protocol (DNP) 3.0-based network environment that is considered secure due to its unique security features and communication methods. However, cyberattacks exploiting the vulnerability of the DNP 3.0 protocol can manipulate the power generation output, resulting in serious consequences such as facility malfunction and power outages. To address this issue, this paper identifies security threats in power system networks, including DNP 3.0, and proposes an AI-based anomaly detection system based on DNP 3.0 network traffic. Existing network traffic target rule-based detection methods and signature-based detection methods have defects. We propose an AI-based anomaly detection system to compensate for defects in existing anomaly detection methods and perform efficient anomaly detection. To evaluate the performance of the AI-based anomaly detection system proposed in this paper, we used a dataset containing normal network traffic and nine types of attack network traffic obtained from the DNP 3.0 communication testbed, and experiments showed 99% accuracy, 98% TPR, and 1.6% FPR, resulting in 99% F-1 score. By implementing these security measures, power system network environments, including EMS, can be better protected against cyber threats.},
booktitle = {Information Security Applications: 24th International Conference, WISA 2023, Jeju Island, South Korea, August 23–25, 2023, Revised Selected Papers},
pages = {91–104},
numpages = {14},
keywords = {ICS, SCADA, EMS, AI-based Anomaly Detection System},
location = {<conf-loc content-type="InPerson">Jeju Island, Korea (Republic of)</conf-loc>}
}

@inproceedings{10.1145/3583780.3614732,
author = {Zong, Zefang and Yan, Huan and Sui, Hongjie and Li, Haoxiang and Jiang, Peiqi and Li, Yong},
title = {An AI-based Simulation and Optimization Framework for Logistic Systems},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614732},
doi = {10.1145/3583780.3614732},
abstract = {Improving logistics efficiency is a challenging task in logistic systems, since planning the vehicle routes highly relies on the changing traffic conditions and diverse demand scenarios. However, most existing approaches either neglect the dynamic traffic environment or adopt manually designed rules, which fails to efficiently find a high-quality routing strategy. In this paper, we present a novel artificial intelligence (AI) based framework for logistic systems. This framework can simulate the spatio-temporal traffic conditions to form a dynamic environment in a data-driven manner. Under such a simulated environment, it adopts deep reinforcement learning techniques to intelligently generate the optimized routing strategy. Meanwhile, we also design an interactive frontend to visualize the simulated environment and routing strategies, which help operators evaluate the task performance. We will showcase the results of AI-based simulation and optimization in our demonstration.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5138–5142},
numpages = {5},
keywords = {deep reinforcement learning, logistic system, time-dependent graph, travel time estimation, vehicle routing problem},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@article{10.4018/JOEUC.308814,
author = {Yang, Yin and Siau, Keng and Xie, Wen and Sun, Yan},
title = {Smart Health: Intelligent Healthcare Systems in the Metaverse, Artificial Intelligence, and Data Science Era},
year = {2022},
issue_date = {Sep 2022},
publisher = {IGI Global},
address = {USA},
volume = {34},
number = {1},
issn = {1546-2234},
url = {https://doi.org/10.4018/JOEUC.308814},
doi = {10.4018/JOEUC.308814},
abstract = {In recent decades, healthcare organizations around the world have increasingly appreciated the value of information technologies for a variety of applications. Three of the new technological advancements that are impacting smart health are metaverse, artificial intelligence (AI), and data science. The metaverse is the intersection of three major technologies — AI, augmented reality (AR), and virtual reality (VR). Metaverse provides new possibilities and potential that are still emerging. The increased work efficiency enabled by artificial intelligence and data science in hospitals not only improves patient care but also cuts costs and workload for healthcare providers. Artificial intelligence, coupled with machine learning, is transforming the healthcare industry. The availability of big data enables data scientists to use the data for descriptive, predictive, and prescriptive analytics. This article reviews multiple case studies and the literature on AI and data science applications in hospital administration. The article also presents unresolved research questions and challenges in the applications of the metaverse, AI, and data science in the smart health context. For researchers, in addition to providing a good synopsis of the development and applications of the metaverse, AI, and data science in the healthcare area, this article identifies possible future research directions and discusses the possibilities of the metaverse, artificial intelligence, and data science in smart health. For practitioners, this article provides both hospital decision-makers and healthcare workers with practical guidelines and a smart health management model.},
journal = {J. Organ. End User Comput.},
month = {aug},
pages = {1–14},
numpages = {14},
keywords = {Artificial Intelligence, Data Science, Hospital Management, Smart Health, Smart Hospital}
}

@inproceedings{10.1007/978-3-031-21707-4_34,
author = {Passalacqua, Mario and Pellerin, Robert and Doyon-Poulin, Philippe and Del-Aguila, Laur\`{e}ne and Boasen, Jared and L\'{e}ger, Pierre-Majorique},
title = {Human-Centred AI in the Age of Industry 5.0: A Systematic Review Protocol},
year = {2022},
isbn = {978-3-031-21706-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21707-4_34},
doi = {10.1007/978-3-031-21707-4_34},
abstract = {Research within AI-based Industry 4.0 (I4.0) work systems has predominantly focused on technical and process performance, while human and psychosocial factors are rarely examined. These factors must be considered to design human-centred systems that cultivate sustainable human-AI interaction, i.e., human-AI interaction that promotes long-term well-being, engagement, and performance. The European Commission has brought forward a new vision of I4.0 called Industry 5.0, where well-being and technological advancement are jointly considered, thus overcoming the weaknesses of I4.0. To move forward with Industry 5.0, it is necessary to consolidate our knowledge of human-technology interaction within I4.0. This systematic review aims to uncover the antecedents and consequences of human and psychosocial factors within AI-based I4.0 systems, with an end goal of providing guidelines for the sustainable design, implementation, and use of these systems. This protocol presents the background and the methodology behind our review, as well as preliminary results and expected contributions.},
booktitle = {HCI International 2022 – Late Breaking Papers: Interacting with EXtended Reality and Artificial Intelligence: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings},
pages = {483–492},
numpages = {10},
keywords = {Human-centred AI, Industry 5.0, Industry 4.0, Psychosocial factors, Human factors}
}

@article{10.1007/s10462-022-10381-4,
author = {Levshun, Diana and Kotenko, Igor},
title = {A survey on artificial intelligence techniques for security event correlation: models, challenges, and opportunities},
year = {2023},
issue_date = {Aug 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {8},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-022-10381-4},
doi = {10.1007/s10462-022-10381-4},
abstract = {Information systems need to process a large amount of event monitoring data. The process of finding the relationships between events is called correlation, which creates a context between independent events and previously collected information in real time and normalizes it for subsequent processing. In cybersecurity, events can determine the steps of attackers and can be analyzed as part of a specific attack strategy. In this survey, we present the systematization of security event correlation models in terms of their representation in AI-based monitoring systems as: rule-based, semantic, graphical and machine learning based-models. We define the main directions of current research in the field of AI-based security event correlation and the methods used for the correlation of both single events and their sequences in attack scenarios. We also describe the prospects for the development of hybrid correlation models. In conclusion, we identify the existing problems in the field and possible ways to overcome them.},
journal = {Artif. Intell. Rev.},
month = {jan},
pages = {8547–8590},
numpages = {44},
keywords = {Event correlation, Security event, Data mining, Situational awareness, Knowledge representation, Cybersecurity}
}

@inproceedings{10.1109/FUZZ-IEEE55066.2022.9882675,
author = {Kieseberg, Peter and Buttinger, Christina and Kaltenbrunner, Laura and Temper, Marlies and Tjoa, Simon},
title = {Security considerations for the procurement and acquisition of Artificial Intelligence (AI) systems},
year = {2022},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FUZZ-IEEE55066.2022.9882675},
doi = {10.1109/FUZZ-IEEE55066.2022.9882675},
abstract = {Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.},
booktitle = {2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
pages = {1–7},
numpages = {7},
location = {Padua, Italy}
}

@inproceedings{10.1145/3514094.3534187,
author = {Deshpande, Advait and Sharp, Helen},
title = {Responsible AI Systems: Who are the Stakeholders?},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534187},
doi = {10.1145/3514094.3534187},
abstract = {As of 2021, there were more than 170 guidelines on AI ethics and responsible, trustworthy AI in circulation according to the AI Ethics Guidelines Global Inventory maintained by AlgorithmWatch, an organisation which tracks the effects of increased digitalisation on everyday lives. However, from the perspective of day-to-day work, for those engaged in designing, developing, and maintaining AI systems identifying relevant guidelines and translating them into practice presents a challenge.The aim of this paper is to help anyone engaged in building a responsible AI system by identifying an indicative long-list of potential stakeholders. This list of impacted stakeholders is intended to enable such AI system builders to decide which guidelines are most suited to their practice. The paper draws on a literature review of articles short-listed based on searches conducted in the ACM Digital Library and Google Scholar. The findings are based on content analysis of the short-listed literature guided by probes which draw on the ISO 26000:2010 Guidance on social responsibility.The paper identifies three levels of potentially relevant stakeholders when responsible AI systems are considered: individual stakeholders (including users, developers, and researchers), organisational stakeholders, and national / international stakeholders engaged in making laws, rules, and regulations. The main intended audience for this paper is software, requirements, and product engineers engaged in building AI systems. In addition, business executives, policy makers, legal/regulatory experts, AI researchers, public, private, and third sector organisations developing responsible AI guidelines, and anyone interested in seeing functional responsible AI systems are the other intended audience for this paper.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {227–236},
numpages = {10},
keywords = {AI ethics, AI system builders, ISO 26000:2010 guidance on social responsibility, corporate social responsibility, responsible AI systems, stakeholder identification},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@article{10.1016/j.ipm.2022.103212,
author = {Charef, Nadia and Ben Mnaouer, Adel and Aloqaily, Moayad and Bouachir, Ouns and Guizani, Mohsen},
title = {Artificial intelligence implication on energy sustainability in Internet of Things: A survey},
year = {2023},
issue_date = {Mar 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {60},
number = {2},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2022.103212},
doi = {10.1016/j.ipm.2022.103212},
journal = {Inf. Process. Manage.},
month = {mar},
numpages = {42},
keywords = {IoT, Sustainability, Energy harvesting, Energy awareness, Machine learning, AI, Swarm intelligence, Data aggregation and fusion}
}

@article{10.1287/isre.2020.0980,
author = {Jussupow, Ekaterina and Spohrer, Kai and Heinzl, Armin and Gawlitza, Joshua},
title = {Augmenting Medical Diagnosis Decisions? An Investigation into Physicians’ Decision-Making Process with Artificial Intelligence},
year = {2021},
issue_date = {September 2021},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {32},
number = {3},
issn = {1526-5536},
url = {https://doi.org/10.1287/isre.2020.0980},
doi = {10.1287/isre.2020.0980},
abstract = {Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions, but they are not without errors and biases. Failure to detect those may result in wrong diagnoses and medical errors. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Thus, it is difficult, yet critical, for physicians to carefully evaluate AI advice. This study uncovers the cognitive challenges that medical decision makers face when they receive potentially incorrect advice from AI-based diagnosis systems and must decide whether to follow or reject it. In experiments with 68 novice and 12 experienced physicians, novice physicians with and without clinical experience as well as experienced radiologists made more inaccurate diagnosis decisions when provided with incorrect AI advice than without advice at all. We elicit five decision-making patterns and show that wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial evaluation of the AI advice. Our study has implications for the training of physicians and spotlights the crucial role of human actors in compensating for AI errors.Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Much research currently aims to improve AI technologies and debates their societal implications. Surprisingly little effort is spent on understanding the cognitive challenges of decision augmentation with AI-based systems although these systems make it more difficult for decision makers to evaluate the correctness of system advice and to decide whether to reject or accept it. As little is known about the cognitive mechanisms that underlie such evaluations, we take an inductive approach to understand how AI advice influences physicians’ decision-making process. We conducted experiments with a total of 68 novice and 12 experienced physicians who diagnosed patient cases with an AI-based system that provided both correct and incorrect advice. Based on qualitative data from think-aloud protocols, interviews, and questionnaires, we elicit five decision-making patterns and develop a process model of medical diagnosis decision augmentation with AI advice. We show that physicians use second-order cognitive processes, namely metacognitions, to monitor and control their reasoning while assessing AI advice. These metacognitions determine whether physicians are able to reap the full benefits of AI or not. Specifically, wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial information search. Our findings provide a first perspective on the metacognitive mechanisms that decision makers use to evaluate system advice. Overall, our study sheds light on an overlooked facet of decision augmentation with AI, namely, the crucial role of human actors in compensating for technological errors.},
journal = {Info. Sys. Research},
month = {sep},
pages = {713–735},
numpages = {23},
keywords = {decision making, artificial intelligence, decision support, metacognition, healthcare, dual process, advice taking}
}

@inproceedings{10.1145/3506469.3506473,
author = {Khullar, Aman and Panjal, Paramita and Pandey, Rachit and Burnwal, Abhishek and Raj, Prashit and Jha, Ankit Akash and Hitesh, Priyadarshi and Reddy, R Jayanth and Himanshu, Himanshu and Seth, Aaditeshwar},
title = {Experiences with the Introduction of AI-based Tools for Moderation Automation of Voice-based Participatory Media Forum},
year = {2022},
isbn = {9781450396073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506469.3506473},
doi = {10.1145/3506469.3506473},
abstract = {Voice-based discussion forums where users can record audio messages which are then published for other users to listen and comment, are often moderated to ensure that the published audios are of good quality, relevant, and adhere to editorial guidelines of the forum. There is room for the introduction of AI-based tools in the moderation process, such as to identify and filter out blank or noisy audios, use speech recognition to transcribe the voice messages in text, and use natural language processing techniques to extract relevant metadata from the audio transcripts. We design such tools and deploy them within a social enterprise working in India that runs several voice-based discussion forums. We present our findings in terms of the time and cost-savings made through the introduction of these tools, and describe the feedback of the moderators towards the acceptability of AI-based automation in their workflow. Our work forms a case-study in the use of AI for automation of several routine tasks, and can be especially relevant for other researchers and practitioners involved with the use of voice-based technologies in developing regions of the world.},
booktitle = {Proceedings of the 12th Indian Conference on Human-Computer Interaction},
pages = {30–39},
numpages = {10},
keywords = {Interactive Voice Response systems, artificial intelligence, automation, content moderation},
location = {Virtual Event, India},
series = {IndiaHCI '21}
}

@inproceedings{10.1109/ISTAS52410.2021.9629170,
author = {Dennis, Jordyn and Grady, Caitlin and Rajtmajer, Sarah},
title = {Comparative assessment of cyber-physical threats to megacities},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISTAS52410.2021.9629170},
doi = {10.1109/ISTAS52410.2021.9629170},
abstract = {By 2030, forecasts suggest that urban areas will house 60 percent of the world’s population and one in every three people will live in cities with at least half a million inhabitants. Within the same time frame, the number of global megacities is expected to jump from 33 today to 43 in 2030 [1]. Underpinning these large urban areas will be an interconnected network of critical physical infrastructures reliant on Internet-connected Industrial Control Systems and susceptible to increasingly sophisticated, e.g., AI-enabled, cyber threats. In hand, the cyber threat landscape is shifting rapidly. We are seeing a sharp rise in the number of cyberattacks on critical infrastructure [2] with significant impacts cascading across multiple sectors and causing disruption to the provisioning of essential goods and services. Security scholars suggest that these impacts are not always equitable and that disruption to critical infrastructure can affect vulnerable groups differently [3], which further emphasizes the need to improve cybersecurity between critical infrastructure sectors [4]. Through structured analysis of city statistics, demographic information, cyber incidents, and current cyber policy, our presentation will articulate potential social implications of megacity growth through the lens of cyber-physical infrastructure disruption. We investigate the largest 15 megacities in the world and find that megacities continue to grow in population but not in cyber policy. We highlight recent examples of cyber-physical disruption in Mumbai and New York City with focus on implications for vulnerable populations. Our work suggests the need for future research on social responsibility regarding security of these critical infrastructure sectors and on the need for technology-focused law, policy, and regulation guidelines.},
booktitle = {2021 IEEE International Symposium on Technology and Society (ISTAS)},
pages = {1},
numpages = {1},
location = {Waterloo, ON, Canada}
}

@article{10.1016/j.eswa.2015.03.023,
author = {Mohd Ali, Jarinah and Hussain, M.A. and Tade, Moses O. and Zhang, Jie},
title = {Artificial Intelligence techniques applied as estimator in chemical process systems - A literature survey},
year = {2015},
issue_date = {August 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {14},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.03.023},
doi = {10.1016/j.eswa.2015.03.023},
abstract = {Intensive review of AI applied as estimators in chemical process systems.Provide guidelines to select and design AI-based estimators.Discussed the advantages, limitations and compare each algorithm.Future suggestions and directions of the research. The versatility of Artificial Intelligence (AI) in process systems is not restricted to modelling and control only, but also as estimators to estimate the unmeasured parameters as an alternative to the conventional observers and hardware sensors. These estimators, also known as software sensors have been successfully applied in many chemical process systems such as reactors, distillation columns, and heat exchanger due to their robustness, simple formulation, adaptation capabilities and minimum modelling requirements for the design. However, the various types of AI methods available make it difficult to decide on the most suitable algorithm to be applied for any particular system. Hence, in this paper, we provide a broad literature survey of several AI algorithms implemented as estimators in chemical systems together with their advantages, limitations, practical implications and comparisons between one another to guide researchers in selecting and designing the AI-based estimators. Future research suggestions and directions in improvising and extending the usage of these estimators in various chemical operating units are also presented.},
journal = {Expert Syst. Appl.},
month = {aug},
pages = {5915–5931},
numpages = {17},
keywords = {Artificial Intelligence, Chemical process systems, Estimator, Soft-sensor}
}

@article{10.1016/j.csi.2019.103361,
author = {Turan, Ertan and \c{C}etin, G\"{u}rcan},
title = {Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {66},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2019.103361},
doi = {10.1016/j.csi.2019.103361},
journal = {Comput. Stand. Interfaces},
month = {oct},
numpages = {11},
keywords = {Animal behaviors, Artificial intelligence, Fuzzy logic, Unity 3D modeling, Virtual environment}
}

@inproceedings{10.1145/3311957.3361858,
author = {Bennett, Sarah Joy},
title = {Investigating the Role of Moral Decision-Making in Emerging Artificial Intelligence Technologies},
year = {2019},
isbn = {9781450366922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311957.3361858},
doi = {10.1145/3311957.3361858},
abstract = {In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development.},
booktitle = {Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {28–32},
numpages = {5},
keywords = {artificial intelligence, design, ethics},
location = {Austin, TX, USA},
series = {CSCW '19 Companion}
}

@inproceedings{10.1145/3205946.3205962,
author = {Loi, Daria},
title = {Intelligent, Affective Systems: People's Perspective &amp; Implications},
year = {2018},
isbn = {9781450364294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205946.3205962},
doi = {10.1145/3205946.3205962},
abstract = {AI-based systems are shifting and will increasingly shift how we relate to content, context and each other. This extended keynote abstract discusses insights from a global study that focused on people's perceptions, attitudes, thresholds and expectations of intelligent systems as well as their perspectives on smart home, autonomous cars, and smart workspace. Insights helped create ten design guidelines to assist intelligent systems designers, technologists and decision makers.},
booktitle = {Proceedings of the 4th International Conference on Human-Computer Interaction and User Experience in Indonesia, CHIuXiD '18},
pages = {101–104},
numpages = {4},
keywords = {Affective Computing, Artificial Intelligence, System Design, User Experience},
location = {Yogyakarta, Indonesia},
series = {CHIuXiD '18}
}

@inproceedings{10.1145/3548606.3563539,
author = {Wang, Ningfei and Luo, Yunpeng and Sato, Takami and Xu, Kaidi and Chen, Qi Alfred},
title = {Poster: On the System-Level Effectiveness of Physical Object-Hiding Adversarial Attack in Autonomous Driving},
year = {2022},
isbn = {9781450394505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548606.3563539},
doi = {10.1145/3548606.3563539},
abstract = {In Autonomous Driving (AD) systems, perception is both security and safety-critical. Among different attacks on AD perception, object-hiding adversarial attack is one of the most critical ones due to the direct impact on safety-critical driving decisions such as collision avoidance. However, all of the prior works on physical object-hiding adversarial attacks only study the security of the AI component alone rather than with the entire AD system pipeline with closed-loop control. This thus inevitably raises a critical research question: can these prior works actually achieve system-level effects (e.g., vehicle collisions, traffic rule violation) under real-world AD settings with closed-loop control?To answer this critical question, in this work we take the necessary first step by performing the first measurement study on whether and how effective the existing designs can lead to system-level effects. Our early results find that RP2 and FTE, as two representative examples of prior works, cannot achieve any system-level effect in a representative closed-loop AD setup in common STOP sign-controlled road speeds. In the future, we plan to 1) perform a more comprehensive measurement study using both simulated environments and a real vehicle-sized AD R&amp;D chassis; and 2) analyze the measurement study results and explore new attack designs that can better achieve the system-level effect in AD systems.},
booktitle = {Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3479–3481},
numpages = {3},
keywords = {autonomous driving (ad) system security, object hiding attack, system-level effect},
location = {Los Angeles, CA, USA},
series = {CCS '22}
}

@phdthesis{10.5555/AAI29061985,
author = {Ebbeler, Raymond Walter and Sharon, Kimmel,},
advisor = {Charles, Beverley, and Robert, Davis,},
title = {Following the Path of Small and Medium-Sized Medical Technology Startups Seeking Funding Before FDA Clearance},
year = {2022},
isbn = {9798209987611},
publisher = {Northcentral University},
abstract = {There is a problem for medical technology startups in the US with obtaining funding for the regulation of new medical devices before FDA clearance. The selection criteria identified small and medium medical device companies (SMMDCs) in the top 15 cities for the medical technology industry excluding non-US SMMDCs. Limited responses required secondary data to supplement the interviews conducted. The application of a semi-structure interview allowed a comprehensive data analysis with only three participants. While consensus was observed for all participants regarding the FDA's cybersecurity program with the FDA' medical device breakthrough, the sample size was small which required approval for modifying the study by the Northcentral University' Institutional Review Board. Thus, secondary data was acquired from the SMMDC' websites as press releases, newswires, and branding of a combination medical device. The CEO and decision maker of several SMMDCs depended also on the Securities Exchange Commission's (SEC) EDGAR search engine to identify Form D document, rule 506 (b and c) for private placement. Recommendations for practice is the integration of primary and secondary data with NVivo version 12 software. The thematic analysis indicated two and three-word group associations to infer as saturation and triangulation respectively. Recommendations for future research were telehealth with artificial intelligence (AI), augmented reality (AR), three-dimensional (3-D) Printing, and Blockchain technology a qualitative management system for a combination medical device. Finally, a coalition model addressed technological innovation diffusion with business incubators and accelerators relative to government and non-governmental organizations. Crunchbase, as an accelerator portal, identified SMMDC's pre seed and seed capital for early-stage funding under $1-3 million and late-stage funding for Series A and Series B funding as $20 - $50 million to avoid the valley of death and for expansion and growth.},
note = {AAI29061985}
}

@article{10.1145/3635715,
author = {Pant, Aastha and Hoda, Rashina and Spiegler, Simone V. and Tantithamthavorn, Chakkrit and Turhan, Burak},
title = {Ethics in the Age of AI: An Analysis of AI Practitioners’ Awareness and Challenges},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3635715},
doi = {10.1145/3635715},
abstract = {Ethics in AI has become a debated topic of public and expert discourse in recent years. But what do people who build AI – AI practitioners – have to say about their understanding of AI ethics and the challenges associated with incorporating it into the AI-based systems they develop? Understanding AI practitioners’ views on AI ethics is important as they are the ones closest to the AI systems and can bring about changes and improvements. We conducted a survey aimed at understanding AI practitioners’ awareness of AI ethics and their challenges in incorporating ethics. Based on 100 AI practitioners’ responses, our findings indicate that the majority of AI practitioners had a reasonable familiarity with the concept of AI ethics, primarily due to workplace rules and policies. Privacy protection and security was the ethical principle that the majority of them were aware of. Formal education/training was considered somewhat helpful in preparing practitioners to incorporate AI ethics. The challenges that AI practitioners faced in the development of ethical AI-based systems included (i) general challenges, (ii) technology-related challenges, and (iii) human-related challenges. We also identified areas needing further investigation and provided recommendations to assist AI practitioners and companies in incorporating ethics into AI development.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {dec},
keywords = {AI ethics, AI practitioners, Awareness, Challenges, Survey}
}

@inproceedings{10.1007/978-3-030-50341-3_32,
author = {Mari, Alex and Mandelli, Andreina and Algesheimer, Ren\'{e}},
title = {The Evolution of Marketing in the Context of Voice Commerce: A Managerial Perspective},
year = {2020},
isbn = {978-3-030-50340-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50341-3_32},
doi = {10.1007/978-3-030-50341-3_32},
abstract = {The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N = 62) revealed the expected impact of voice assistants on the shopping process. Findings show that managers consider voice assistants a disruptive technology assuming a central relational role in the consumer market. However, they often divergence in opinions across industry, function, and seniority level. Besides, managers’ familiarity with voice commerce is correlated to a higher optimism towards voice technologies (opportunity for brands) but also a greater sense of urgency (short-term focus) with implications for marketing strategy. This article offers support to brand owners explaining how voice assistants work and examining their effects on consumption. The authors discuss empirical results while providing managerial guidelines to create resilient and sustainable brands in the era of voice commerce.},
booktitle = {HCI in Business, Government and Organizations: 7th International Conference, HCIBGO 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {405–425},
numpages = {21},
keywords = {Voice assistant, Voice commerce, Marketing, Machine behavior},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3351095.3375784,
author = {Noriega-Campero, Alejandro and Garcia-Bulle, Bernardo and Cantu, Luis Fernando and Bakker, Michiel A. and Tejerina, Luis and Pentland, Alex},
title = {Algorithmic targeting of social policies: fairness, accuracy, and distributed governance},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3375784},
doi = {10.1145/3351095.3375784},
abstract = {Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and widespread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them---and who is not---are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {241–251},
numpages = {11},
keywords = {AI for social good, algorithmic fairness, cash transfers, proxy means tests, targeted social programs},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@inproceedings{10.1145/3447548.3470823,
author = {Ahmad, Muhammad Aurangzeb and Overman, Steve and Allen, Christine and Kumar, Vikas and Teredesai, Ankur and Eckert, Carly},
title = {Software as a Medical Device: Regulating AI in Healthcare via Responsible AI},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470823},
doi = {10.1145/3447548.3470823},
abstract = {With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4023–4024},
numpages = {2},
keywords = {ai in healthcare, explainable ai, fairness in machine learning, interpretable machine learning, responsible ai, xai},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1007/978-3-031-21648-0_23,
author = {Bhoi, Suman and Sourav, Suman},
title = {Towards Understanding and&nbsp;Improving Handwriting with&nbsp;AI},
year = {2022},
isbn = {978-3-031-21647-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21648-0_23},
doi = {10.1007/978-3-031-21648-0_23},
abstract = {What makes a handwriting good? If the aesthetic judgment of handwriting follows implicit rules, can those rules be recovered by observing good and bad examples? To answer these questions, we apply explainability techniques to the classification of good and bad handwriting. We show that it is indeed possible to recover these inherent rules. We develop an AI system that uses a modified version of LIME Image Explainer and generates images containing suggestions for improvement. We use single-character and word-level datasets labelled with binary labels generated via accepted rules for handwriting classification. We discuss the possible improvements to the current system as well as where this research could be applied, such as user-specific auto-suggestions.},
booktitle = {Frontiers in Handwriting Recognition: 18th International Conference, ICFHR 2022, Hyderabad, India, December 4–7, 2022, Proceedings},
pages = {331–344},
numpages = {14},
keywords = {Handwriting analysis, Explainability, Feature attribution},
location = {Hyderabad, India}
}

@inproceedings{10.1145/3311957.3359433,
author = {Park, Sun Young and Kuo, Pei-Yi and Barbarin, Andrea and Kaziunas, Elizabeth and Chow, Astrid and Singh, Karandeep and Wilcox, Lauren and Lasecki, Walter S.},
title = {Identifying Challenges and Opportunities in Human-AI Collaboration in Healthcare},
year = {2019},
isbn = {9781450366922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311957.3359433},
doi = {10.1145/3311957.3359433},
abstract = {The proposed workshop will identify research questions that will enable the field to uncover the types of work, labor relations, and social impacts that should be considered when designing AI-based healthcare technology. The workshop aims to outline key challenges, guidelines, and future agendas for the field, and provide collaboration opportunities for CSCW researchers, social scientists, AI researchers, clinicians, and relevant stakeholders in healthcare, to share their perspectives and co-create sociotechnical approaches to tackle timely issues related to AI and automation in healthcare work.},
booktitle = {Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {506–510},
numpages = {5},
keywords = {ai fairness, ai transparency, algorithms, artificial intelligence, automation, explainable ai, healthcare, machine learning, sociotechnical systems},
location = {Austin, TX, USA},
series = {CSCW '19 Companion}
}

@article{10.1016/j.jss.2022.111604,
author = {Heyn, Hans-Martin and Knauss, Eric and Pelliccione, Patrizio},
title = {A compositional approach to creating architecture frameworks with an application to distributed AI systems},
year = {2023},
issue_date = {Apr 2023},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {198},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2022.111604},
doi = {10.1016/j.jss.2022.111604},
journal = {J. Syst. Softw.},
month = {apr},
numpages = {19},
keywords = {AI systems, Architectural frameworks, Compositional thinking, Requirements engineering, Systems engineering}
}

@article{10.1016/j.jss.2022.111475,
author = {Giordano, Giammaria and Palomba, Fabio and Ferrucci, Filomena},
title = {On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review},
year = {2022},
issue_date = {Nov 2022},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {193},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2022.111475},
doi = {10.1016/j.jss.2022.111475},
journal = {J. Syst. Softw.},
month = {nov},
numpages = {25},
keywords = {Data privacy, Artificial intelligence, Internet-of-Things, Software engineering for IoT}
}

@phdthesis{10.5555/AAI29030873,
author = {Yao, Heming and A., Williamson, Craig and Alan, Boyle, and Harm, Derksen, and Alla, Karnovsky, and S., Omenn, Gilbert and W, Stidham, Ryan},
advisor = {Kayvan, Najarian,},
title = {Machine Learning and Image Processing for Clinical Outcome Prediction: Applications in Medical Data from Patients with Traumatic Brain Injury, Ulcerative Colitis, and Heart Failure},
year = {2021},
isbn = {9798780610069},
publisher = {University of Michigan},
address = {USA},
abstract = {Artificial intelligence (AI) and machine learning (ML) have achieved extensive success in many fields. They are powerful in pattern recognition and function modeling. The digitization of health data provides an important opportunity for improving care delivery and patient management through the AI-based clinical decision-support (CDS) system. Medical images are important components in evaluating the disease severity. While the human's interpretation of medical images is subjective and qualitative, AI-based models can analyze those data in a more reproducible, quantitative, and less expensive way. With clinical observations and quantitative findings extracted from medical images, ML methods can be used to learn and discover knowledge. The automated CDS system can provide recommendations on diagnosis, treatment, and outcome prediction by leveraging massive medical data. Those systems can facilitate drug development, disease pathology research, and clinical practice. This dissertation investigates medical image analysis and CDS systems development in a more reliable, interpretable manner. Limitations exist in applying AI/ML techniques in medical problems. Medical data may have high variability in terms of the patient population, collection site, equipment, and imaging protocols. It is crucial that the ML and image processing algorithms have a good generalizability and can be reliably applied to unseen patient data. In addition, a broad spectrum of AI/ML methods is among the "black box" models. The lack of justification leads to concerns and hesitations of using AI/ML techniques in clinical or research practice. Features with clinical meaning and models that can be well explained can gain more trust and are more favorable to end-users. In this dissertation, several AI-based CDS systems have been designed and implemented to facilitate clinical and research practice. Novel algorithms are proposed to overcome the challenges of applying AI/ML techniques. To improve the generalizability of the deep learning models, a robust learning algorithm is proposed to encourage the network to be invariant to hematoma intensity variability. A Scale Module and filter pruning technique are proposed to reduce the network's size and complexity. To improve the interpretability of the CDS systems, a transparent ML algorithm is proposed based on tropical geometry and fuzzy logic, which can learn humanly understandable rules from the dataset and integrate existing domain knowledge to facilitate the model training. Domain knowledge plays an important role in the design of CDS systems. With automated image analysis methods, quantitative and objective measurements are extracted to capture the patient's condition and disease characteristics in a meaningful and reproducible way. The proposed CDS systems have been validated using data collected from routine practice and clinical trials. The datasets used in this dissertation are from multiple medial centers, which increases the generalizability of the proposed frameworks and trained models. This work aims to research the capacity of AI models toward fully automated CDS systems that can replicate expert judgment and provide insight for the patient. Efforts have been made to improve the generalizability and interpretability of AI/ML models, which are the major limitations that hinder a broad application of AI techniques in practice. The proposed algorithms and strategies in this dissertation leverage big data to improve the healthcare system and disease research. Additionally, the proposed methods are transferable beyond the target application. The contributions of this dissertation have a meaningful impact on applying AI-based systems to clinical and research practice.},
note = {AAI29030873}
}

@article{10.1016/j.eswa.2021.115597,
author = {Sachan, Swati and Almaghrabi, Fatima and Yang, Jian-Bo and Xu, Dong-Ling},
title = {Evidential reasoning for preprocessing uncertain categorical data for trustworthy decisions: An application on healthcare and finance},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {185},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115597},
doi = {10.1016/j.eswa.2021.115597},
journal = {Expert Syst. Appl.},
month = {dec},
numpages = {27},
keywords = {Categorical, Uncertainty, Decision-making, Evidential reasoning, Trustworthy}
}

@article{10.1109/TLT.2022.3225432,
author = {Tomi\'{c}, Bojan B. and Kijev\v{c}anin, Anisja D. and \v{S}evarac, Zoran V. and Jovanovi\'{c}, Jelena M.},
title = {An AI-based Approach for Grading Students’ Collaboration},
year = {2023},
issue_date = {June 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {3_Part_1},
issn = {1939-1382},
url = {https://doi.org/10.1109/TLT.2022.3225432},
doi = {10.1109/TLT.2022.3225432},
abstract = {Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made—something that proved to be very important to teachers.},
journal = {IEEE Trans. Learn. Technol.},
month = {jun},
pages = {292–305},
numpages = {14}
}

@article{10.1007/s10044-023-01163-x,
author = {Oommen, B. John and Omslandseter, Rebekka Olsson and Jiao, Lei},
title = {The object migration automata: its field, scope, applications, and future research challenges},
year = {2023},
issue_date = {Aug 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {3},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-023-01163-x},
doi = {10.1007/s10044-023-01163-x},
abstract = {Partitioning, in and of itself, is an NP-hard problem. Prior to the Artificial Intelligence (AI)-based solutions, it was solved in the 1970s by optimization-based strategies. However, AI-based solutions appeared in the 1980s in a pioneering way, by using a Learning Automaton (LA)-motivated strategy known as the so-called Object Migrating Automaton (OMA). Although the OMA and its derivatives have been used in numerous applications since then, the basic kernel has remained the same. Because the number of possible partitions in a partitioning problem can be combinatorially exponential and the underlying tasks are NP-hard, the most advanced OMA algorithms could, until recently, only solve issues involving equally sized groups. Due to our recent innovations cited in the body of this paper, the enhanced OMA now also handles non-equally sized groups. Earlier, we had presented in Omslandseter (Pattern Anal Appl, 2023), a comprehensive survey of the state-of-the-art enhancements of the best-known OMA. We believe that these results will be the benchmark for a few decades and that it will be very hard to beat these results. This is a companion paper, intended to augment the contents of Omslandseter (Pattern Anal Appl, 2023). In this paper, we first discuss the OMA’s prior applications, its historical and current innovations, and the OMA-based algorithms’ relevance to societal needs. We also provide well-specified guidelines for future researchers so that they can use them for unresolved tasks, and also develop further advancements.},
journal = {Pattern Anal. Appl.},
month = {apr},
pages = {917–928},
numpages = {12},
keywords = {Learning automata, Object migration automata, Partitioning}
}

@inproceedings{10.1109/ProComm53155.2022.00078,
author = {McKee, Heidi A. and Porter, James E.},
title = {Team Roles &amp; Rhetorical Intelligence in Human-Machine Writing},
year = {2022},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ProComm53155.2022.00078},
doi = {10.1109/ProComm53155.2022.00078},
abstract = {This paper examines AI-based writing systems and how humans might partner with these systems to produce effective professional communication. We offer a taxonomy for examining roles in human-machine teaming for writing: Resource Tool, Assistant, Writer, and Executive Decision-Maker (whether at the beginning or end of the project). In particular, we focus on humanmachine teaming in relation to what we call rhetorical intelligence, the ability to invent and write for audience, purpose, and context. We examine human-machine writing by focusing on two cases: GameChanger and Phrazor by vPhrase. We conclude by proposing some guidelines for human-machine teaming for the production of professional communication.},
booktitle = {2022 IEEE International Professional Communication Conference (ProComm)},
pages = {384–391},
numpages = {8},
location = {Limerick, Ireland}
}

@inproceedings{10.1145/3514094.3539522,
author = {Xu, Yifan},
title = {Dialogue Explanation With Reasoning for AI},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3539522},
doi = {10.1145/3514094.3539522},
abstract = {Explainable Artificial Intelligence is increasingly gaining attention in domains, such as self-driving cars and medical treatment. One of the most prevalent issues with these explainable models is that they are difficult to comprehend and have not been tested in real-world scenarios. In this research, I propose a dialogue-based explanation with reasoning for a rule-based system with the intention of utilising it in the future with a Neuro Symbolic AI system, to give machines the capacity to explain their actions or decisions using logic. We hypothesize that when a system makes a deduction that was, in some way, unexpected by the user then locating the source of the disagreement or misunderstanding is best achieved through a collaborative dialogue process that allows the participants to gradually isolate the cause. I also conduct a user evaluation for this hypothesis.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {918},
numpages = {1},
keywords = {artificial intelligence (ai), dialogue for explanation, explainable artificial intelligence (XAI), machine reasoning, neuro symbolic},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@article{10.1002/smr.2543,
author = {Dzhusupova, Rimma and Banotra, Richa and Bosch, Jan and Olsson, Helena Holmstr\"{o}m},
title = {Using artificial intelligence to find design errors in the engineering drawings},
year = {2023},
issue_date = {December 2023},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {35},
number = {12},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2543},
doi = {10.1002/smr.2543},
abstract = {Artificial intelligence is increasingly becoming important to businesses because many companies have realized the benefits of applying machine learning (ML) and deep learning (DL) in their operations. ML and DL have become attractive technologies for organizations looking to automate repetitive tasks to reduce manual work and free up resources for innovation. Unlike rule‐based automation, typically used for standardized and predictable processes, machine learning, especially deep learning, can handle more complex tasks and learn over time, leading to greater accuracy and efficiency improvements. One of such promising applications is to use AI to reduce manual engineering work. This paper discusses a particular case within McDermott where the research team developed a DL model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). We also present a cost‐benefit analysis and potential scale‐up of the developed software. Our goal is to share the successful experience of AI‐based product development that can substantially reduce the engineering hours and, therefore, reduce the project's overall costs. The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry. It also could motivate practitioners and researchers to create similar products for the various fields within engineering industry.This paper discusses a particular case where the research team developed a deep learning model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry.


image
image},
journal = {J. Softw. Evol. Process},
month = {feb},
numpages = {19},
keywords = {artificial intelligence, deep learning, engineering drawings, engineering, procurement, and construction (EPC) industry, object recognition, piping and instrumentation diagrams (P&amp;IDs)}
}

@phdthesis{10.5555/AAI29164242,
author = {He, Jingxi and Won, Yoon, Sang and Hiroki, Sayama, and W, Lewis, Harold},
advisor = {Daehan, Won,},
title = {An AI-Based Pick-and-Place Control for Quality Enhancement in Surface Mount Technology},
year = {2022},
isbn = {9798834049036},
publisher = {State University of New York at Binghamton},
address = {USA},
abstract = {The main goal of this dissertation is to investigate an AI-based pick-and-placeclosed-loop control system capable of identifying optimal placement positions in adynamic manufacturing environment. According to the industrial survey, assembly defects account for over 55% of field failures in passive components (the mostfrequently used chips on printed circuit boards). Moreover, the pick and placement(P&amp;P) cause over half of the assembly defects. Thus, the P&amp;P process is criticalto improving surface mount technology (SMT). Components have traditionallybeen aligned with the pad centers, referred to as a place-on-pad (PP), and it isthe most widely used method in the industry. However, with the miniaturizationof electronic components, assembly defects have increased. Recently, an adaptiveplacement strategy has been introduced to improve assembly quality [1], called the"place-on-paste" (PPS). In our experiment with miniature passive components,PPS outperformed PP in some instances. As a result, an advanced placementstrategy should be developed to improve the mini-size component assembly consistently. With limited historical data, this research proposes an AI-based P&amp;Pcontrol system that uses both rule-based and machine learning-based placementmethods. For the former, a PB is used to account for the offsets of the printedpaste. Then, multiple dynamic placement options with synthetic placement dataare generated. A hybrid machine learning algorithm predicts the final componentivmisalignment based on the data. Finally, multiple decision-making rules identify the optimal placement option based on the prediction results. According tothe experimental results, the machine learning-based model outperforms PP in adynamic environment. In various application scenarios, the proposed frameworkoutperforms industrial placement strategies.},
note = {AAI29164242}
}

@phdthesis{10.5555/AAI28767347,
author = {Liu, Bingjie and Beth, Oliver, Mary},
advisor = {Shyam, Sundar, S.},
title = {Effects of Agency Locus and Transparency of Artificial Intelligence: Uncertainty Reduction and Emerging Mind},
year = {2020},
isbn = {9798535587745},
publisher = {The Pennsylvania State University},
abstract = {Existing research and mass media conceptualize interactive technologies, such as social robots and voice assistants, as machines without true agency despite their apparent autonomy and human-likeness. This is because they are often machines fully programmed by humans and act by following human-made rules. However, self-learning artificial intelligence (AI), which is increasingly used in powering many interactive technologies, is not fully programmed and does not merely follow human-made rules, but instead, learns rules from data with so little human interference that we quite often do not even understand the rules it has learned. The shift of agency locus from human to machine and the lack of transparency of the learning outcomes raise new questions for human-machine communication. How do individuals react to machines that learn autonomously yet remain opaque and mysterious? What measures should we take to cultivate appropriate levels of trust in such machines?To answer these questions, the current study examines the effects of an AI system's agency locus, meaning whether it makes decisions by following human-made rules (human-agency AI) or rules it has learned from data by itself (machine-agency AI), and the level of transparency about such rules (no transparency vs. placebic transparency vs. real transparency), upon users' cognitions, affects, and behaviors toward an AI system. Two online experiments following a 2 (agency locus: human vs. machine) X 3 (transparency: no vs. placebic vs. real) factorial design were conducted in two contexts (fake news detection and personality evaluation).Across contexts, the human-agency AI triggered more person presence, homophily, and was more trusted than the machine-agency AI. The machine-agency AI was perceived as more autonomous and triggered more "mind perception," which also enhanced trust. Real transparency about AI's internal states (i.e., rules) reduced uncertainty and increased mind perception, both of which enhanced trust. By reducing uncertainty, real transparency reduced anxiety and induced more excitement. Underlying the influence of agency locus and transparency of AI on trust are both a route of anthropomorphism (person presence → uncertainty reduction → trust) and a non-anthropomorphism route of mind perception (perceived autonomy or direct access → mind perception → trust).The actual processes are found to be governed by laws of intergroup communication, interpersonal communication, and information processing. Specifically, participants were less influenced by peripheral cues with categorical information (i.e., agency locus) when they had enough cognitive resources (i.e., more past experience with AI applications, or with real transparency). Participants were more motivated to scrutinize messages about an AI system's internal states when the need for uncertainty reduction was high (i.e., when interacting with the machine-agency AI). Contexts, as proxies of individuals' goal structures and social densities, were found to influence outcomes of human-machine interaction by potentially influencing their level of involvement and expectancies.Findings suggest that for machine-learning AI, users recognize it as a mind that is not necessarily humanlike, and that having knowledge about its internal states can to some extent help individuals surpass the human-machine ontological boundary, go beyond the anthropomorphism route, and develop trust in AI. Findings shed light on fundamental interpersonal processes and the larger question of the problem of other minds. In addition, findings also have methodological implications for research on human-machine interaction and practical implications for the design of intelligent machines in general and the design of AI transparency in particular, while also informing policy-making about AI regulations in terms of transparency and accountability.},
note = {AAI28767347}
}

@article{10.1007/s00500-023-09330-2,
author = {Song, Yang and He, Yingwei},
title = {Toward an intelligent tourism recommendation system based on artificial intelligence and IoT using Apriori algorithm},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-023-09330-2},
doi = {10.1007/s00500-023-09330-2},
abstract = {In recent years, the rapid development of the Internet has promoted the continuous expansion of the scale of China’s tourism industry, and the amount of tourism data has surged. However, tourists need help bringing personal interest and high-value data from the plethora of tourism information. The rise of artificial intelligence has transformed traditional tourism into an intelligent, data-driven industry. This shift has generated vast tourism data, offering both opportunities and challenges. The paper discusses an AI and IoT-based Intelligent Tourism Recommendation System (ITRS) that offers travelers predefined itineraries, personalized suggestions, and tourism insights. This system simplifies attraction discovery, unveiling hidden value within tourism data at the intersection of AI and IoT. The present study thoroughly investigates AI-based recommendation algorithms before delving into the system’s architecture. It categorizes user-based, project-based, and article-based collaborative filtering methodologies tailored to specific goals. First, thoroughly examine AI-based recommendation algorithms before delving into the system architecture. Second, categorize collaborative filtering methods as user-based, project-based, and article-based, each tailored to specific objectives. Third, delve into the Apriori algorithm’s complexity within the context of weighted association rules and introduce an enhanced iteration for improved efficiency. The proposed scheme encompasses an elaborate ITRS plan featuring a user interest model and a client module, crucial for the computation and analysis of users’ long-term and short-term interests. Rigorous performance testing confirms the ITRS’s superiority across varying support levels, with experimental results demonstrating the Apriori algorithm’s exceptional accuracy, achieving a 94.3% improvement over other methods. The Apriori algorithm is better than traditional recommendation algorithms such as Linear Regression, Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, K-nearest neighbor, Naive Bayes, and XGBoost.},
journal = {Soft Comput.},
month = {oct},
pages = {19159–19177},
numpages = {19},
keywords = {Internet, Artificial intelligence, Intelligent tourism recommendation system, Apriori algorithm}
}

@article{10.1145/3370270,
author = {Ertl, Tanja and Taugerbeck, Sebastian and Esau, Margarita and Aal, Konstantin and Tolmie, Peter and Wulf, Volker},
title = {The Social Mile - How (Psychosocial) ICT can Help to Promote Resocialization and to Overcome Prison},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {GROUP},
url = {https://doi.org/10.1145/3370270},
doi = {10.1145/3370270},
abstract = {There is currently uncertainty in the research community as to how ICT can and should be designed in such a way that it can be convincingly integrated into the everyday lives of prison inmates. In this paper, we discuss a design fiction that closes this research gap. The descriptions and results of the study are purely fictitious. Excluded is the State of the Art as well as the description of the legal situation of prisons in Germany. The analysis of the fictional study data designed here thus refers to the real world in order to derive ethical guidelines and draw practical conclusions. It is our intention to use these results as a possible basis for further research. The paper presents results of an explorative study dealing with the design, development and evaluation of an AI-based Smart Mirror System, Prison AI 2.0, in a German prison. Prison AI 2.0 was developed for daily use and voluntarily tested by eight prisoners over a period of 12 months to gain insight into their individual and social impact, with an emphasis on its ability to actively support rehabilitation. Based on qualitative data, our findings suggest that intelligent AI-based devices can actually help promote such an outcome. Our results also confirm the valuable impact of (Psychosocial) ICT on the psychological, social and individual aspects of prison life, and in particular how prisoners used the Smart Mirror system to improve and maintain their cognitive, mental and physical state and to restore social interactions with the outside world. With the presentation of these results we want to initiate discussions about the use of ICT by prisoners in closed prisons in order to identify opportunities and risks.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {dec},
articleno = {248},
numpages = {31},
keywords = {ai-infused, cscw, digital participation, prison, prisoners, psychosocial ict, qualitative research, smart mirror, social participation, voice-based technology}
}

@inproceedings{10.1007/978-3-030-78227-6_38,
author = {Ruiz, Cinthia and Quaresma, Manuela},
title = {UX Aspects of AI Principles: The Recommender System of VoD Platforms},
year = {2021},
isbn = {978-3-030-78226-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78227-6_38},
doi = {10.1007/978-3-030-78227-6_38},
abstract = {This paper aims to investigate the user experience with recommender systems of Video on Demand (VoD) platforms based in Machine Learning (ML), focusing on the Artificial Intelligence (AI) principles. We start from the hypothesis that the inclusion of AI algorithms has the potential to improve the user experience in digital systems, but they are still developed with a greater focus on technology, however, they should also consider more aspects regarding human factors. Nine principles on AI related to UX were selected from a compilation of seven lists of government and industry entities to understand the bases that every AI system should respect to ensure a good user experience. In sequence, we discuss their effects on the user experience of VoD platforms. To finish, the experience with these platforms were explored in a directed storytelling method involving thirty-one participants. Some behaviors and patterns found were analyzed and discussed to suggest guidelines to be applied to ML algorithms of VoD Platforms.},
booktitle = {Design, User Experience, and Usability:  Design for Contemporary Technological Environments: 10th International Conference, DUXU 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part III},
pages = {535–552},
numpages = {18},
keywords = {User Experience (UX), Artificial Intelligence (AI), Recommender system}
}

@inproceedings{10.1145/3633083.3633223,
author = {Danilevskyi, Mykhailo and Perez Tellez, Fernando},
title = {On the compliance with ethical principles in AI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633223},
doi = {10.1145/3633083.3633223},
abstract = {In recent years, there has been a lot of discussion around ethics in IT and AI. Researchers and organizations have proposed guidelines to address privacy, fairness, and explainability challenges for creating trustworthy AI. In this work, we outline the importance of compliance with the above-mentioned ethical principles and their influence on the quality of AI systems. We map the relationship between available approaches for compliance with privacy, fairness, explainability principles and the accuracy of AI system decisions. Additionally, we introduce the difference between ensuring fairness for phenomena presented with tabular data and text. Tabular data may contain protected attributes such as gender, age, or race as well as the decision made historically in relation to the people concerned. Data presented in text is not structured and requires sense perception by AI systems to detect bias or unfairness. In the poster, we compare available approaches and present experiments for measuring bias in text data.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {50},
numpages = {1},
keywords = {Bias detection, Ethics in AI, Fairness, Text data},
location = {<conf-loc>, <city>Dublin</city>, <country>Ireland</country>, </conf-loc>},
series = {HCAIep '23}
}

@inproceedings{10.5555/3586210.3586384,
author = {M\"{o}bius, Michael and Kallfass, Daniel and Doll, Thomas and Kunde, Dietmar},
title = {AI-Based Military Decision Support Using Natural Language},
year = {2023},
publisher = {IEEE Press},
abstract = {To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2082–2093},
numpages = {12},
location = {Singapore, Singapore},
series = {WSC '22}
}

@inproceedings{10.1007/978-3-031-40878-6_4,
author = {Xu, Yifan and Collenette, Joe and Dennis, Louise and Dixon, Clare},
title = {Dialogue Explanations for Rule-Based AI Systems},
year = {2023},
isbn = {978-3-031-40877-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-40878-6_4},
doi = {10.1007/978-3-031-40878-6_4},
abstract = {The need for AI systems to explain themselves is increasingly recognised as a priority, particularly in domains where incorrect decisions can result in harm and, in the worst cases, death. Explainable Artificial Intelligence (XAI) tries to produce human-understandable explanations for AI decisions. However, most XAI systems prioritize factors such as technical complexities and research-oriented goals over end-user needs, risking information overload. This research attempts to bridge a gap in current understanding and provide insights for assisting users in comprehending the rule-based system’s reasoning through dialogue. The hypothesis is that employing dialogue as a mechanism can be effective in constructing explanations. A dialogue framework for rule-based AI systems is presented, allowing the system to explain its decisions by engaging in “Why?” and “Why not?” questions and answers. We establish formal properties of this framework and present a small user study with encouraging results that compares dialogue-based explanations with proof trees produced by the AI System.},
booktitle = {Explainable and Transparent AI and Multi-Agent Systems: 5th International Workshop, EXTRAAMAS 2023, London, UK, May 29, 2023, Revised Selected Papers},
pages = {59–77},
numpages = {19},
location = {London, United Kingdom}
}

@inproceedings{10.1145/3568294.3580127,
author = {Foster, Mary Ellen and Candelaria, Patricia and Dwyer, Lauren J. and Hudson, Summer and Lindsay, Alan and Nishat, Fareha and Pacquing, Mykelle and Petrick, Ronald P. A. and Ram\'{\i}rez-Duque, Andr\'{e}s Alberto and Stinson, Jennifer and Zeller, Frauke and Ali, Samina},
title = {Co-design of a Social Robot for Distraction in the Paediatric Emergency Department},
year = {2023},
isbn = {9781450399708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568294.3580127},
doi = {10.1145/3568294.3580127},
abstract = {We are developing a social robot to help children cope with painful and distressing medical procedures in the hospital emergency department. This is a domain where a range of interventions have proven effective at reducing pain and distress, including social robots; however, until now, the robots have been designed with limited stakeholder involvement and have shown limited autonomy. For our system, we have defined and validated the necessary robot behaviour together with children, parents/caregivers, and healthcare professionals, taking into account the ethical and social implications of robotics and AI in the paediatric healthcare context. The result of the co-design process has been captured in a flowchart, which has been converted into a set of concrete design guidelines for the AI-based autonomous robot system.},
booktitle = {Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {461–465},
numpages = {5},
keywords = {child-robot interaction, co-design, socially assistive robots},
location = {Stockholm, Sweden},
series = {HRI '23}
}

@inproceedings{10.1109/FUZZ48607.2020.9177770,
author = {Alonso, Jose M. and Toja-Alamancos, J. and Bugar\'{\i}n, A.},
title = {Experimental Study on Generating Multi-modal Explanations of Black-box Classifiers in terms of Gray-box Classifiers},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FUZZ48607.2020.9177770},
doi = {10.1109/FUZZ48607.2020.9177770},
abstract = {Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets.},
booktitle = {2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@inproceedings{10.1007/978-3-030-50334-5_10,
author = {Wallach, Dieter P. and Flohr, Lukas A. and Kaltenhauser, Annika},
title = {Beyond the Buzzwords: On the&nbsp;Perspective of AI in UX and Vice Versa},
year = {2020},
isbn = {978-3-030-50333-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50334-5_10},
doi = {10.1007/978-3-030-50334-5_10},
abstract = {Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies.},
booktitle = {Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {146–166},
numpages = {21},
keywords = {User experience, Artificial Intelligence, AI and UX, Human-AI Interaction, Human factors, Design, Case studies, Predictive prototyping, ACT-R, Clinical decision support systems, Intensive care, Autonomous mobility-on-demand, Autonomous vehicles},
location = {Copenhagen, Denmark}
}

@inproceedings{10.5555/3524938.3525281,
author = {Gottesman, Omer and Futoma, Joseph and Liu, Yao and Parbhoo, Sonali and Celi, Leo Anthony and Brunskill, Emma and Doshi-Velez, Finale},
title = {Interpretable off-policy evaluation in reinforcement learning by highlighting influential transitions},
year = {2020},
publisher = {JMLR.org},
abstract = {Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares, as well as importance sampling methods. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {343},
numpages = {10},
series = {ICML'20}
}

@inproceedings{10.5555/3504035.3504221,
author = {Oudah, Mayada and Rahwan, Talal and Crandall, Tawna and Crandall, Jacob W.},
title = {How AI wins friends and influences people in repeated games with cheap talk},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as "if you can't say something nice, don't say anything at all" and principles articulated in Carnegie's classic How to Win Friends and Influence People, offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {186},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.5555/2832581.2832600,
author = {Sun, Rongju and Lian, Zhouhui and Tang, Yingmin and Xiao, Jianguo},
title = {Aesthetic visual quality evaluation of Chinese handwritings},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
abstract = {Aesthetic evaluation of Chinese calligraphy is one of the most challenging tasks in Artificial Intelligence. This paper attempts to solve this problem by proposing a number of aesthetic feature representations and feeding them into Artificial Neural Networks. Specifically, 22 global shape features are presented to describe a given handwritten Chinese character from different aspects according to classical calligraphic rules, and a new 10-dimensional feature vector is introduced to represent the component layout information using sparse coding. Moreover, a Chinese Handwriting Aesthetic Evaluation Database (CHAED) is also built by collecting 1000 Chinese handwriting images with diverse aesthetic qualities and inviting 33 subjects to evaluate the aesthetic quality for each calligraphic image. Finally, back propagation neural networks are constructed with the concatenation of the proposed features as input and then trained on our CHAED database for the aesthetic evaluation of Chinese calligraphy. Experimental results demonstrate that the proposed AI system provides a comparable performance with human evaluation. Through our experiments, we also compare the importance of each individual feature and reveal the relationship between our aesthetic features and the aesthetic perceptions of human beings.},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2510–2516},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}

@inproceedings{10.1007/978-3-031-09342-5_6,
author = {Woensel, William Van and Scioscia, Floriano and Loseto, Giuseppe and Seneviratne, Oshani and Patton, Evan and Abidi, Samina and Kagal, Lalana},
title = {Explainable Clinical Decision Support: Towards Patient-Facing Explanations for Education and Long-Term Behavior Change},
year = {2022},
isbn = {978-3-031-09341-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-09342-5_6},
doi = {10.1007/978-3-031-09342-5_6},
abstract = {There is an increasing shift towards the self-management of long-term chronic illness by patients in a home setting, supported by personal health electronic equipment. Among others, self-management requires comprehensive education on the illness, i.e., understanding the effects of nutritional, fitness, and medication choices on personal health; and long-term health behavior change, i.e., modifying unhealthy lifestyles that contribute to chronic illness. Smart health recommendations, generated using AI-based Clinical Decision Support (CDS), can guide patients towards positive nutritional, fitness, and health behavioral choices. Moreover, we posit that explaining these recommendations to patients, using Explainable AI (XAI) techniques, will effect education and positive behavior change. We present our work towards an explanation framework for rule-based CDS, called EXPLAIN (EXPLanations of AI In N3), which aims to generate human-readable, patient-facing explanations.},
booktitle = {Artificial Intelligence in Medicine: 20th International Conference on Artificial Intelligence in Medicine, AIME 2022, Halifax, NS, Canada, June 14–17, 2022, Proceedings},
pages = {57–62},
numpages = {6},
keywords = {Explainable AI, Clinical Decision Support, Semantic Web},
location = {Halifax, NS, Canada}
}

@article{10.1007/s10676-023-09693-y,
author = {Azafrani, Rachel and Gupta, Abhishek},
title = {Bridging the civilian-military divide in responsible AI principles and practices},
year = {2023},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {1388-1957},
url = {https://doi.org/10.1007/s10676-023-09693-y},
doi = {10.1007/s10676-023-09693-y},
abstract = {Advances in AI research have brought increasingly sophisticated capabilities to AI systems and heightened the societal consequences of their use. Researchers and industry professionals have responded by contemplating responsible principles and practices for AI system design. At the same time, defense institutions are contemplating ethical guidelines and requirements for the development and use of AI for warfare. However, varying ethical and procedural approaches to technological development, research emphasis on offensive uses of AI, and lack of appropriate venues for multistakeholder dialogue have led to differing operationalization of responsible AI principles and practices among civilian and defense entities. We argue that the disconnect between civilian and defense responsible development and use practices leads to underutilization of responsible AI research and hinders the implementation of responsible AI principles in both communities. We propose a research roadmap and recommendations for dialogue to increase exchange of responsible AI development and use practices for AI systems between civilian and defense communities. We argue that generating more opportunities for exchange will stimulate global progress in the implementation of responsible AI principles.},
journal = {Ethics and Inf. Technol.},
month = {apr},
numpages = {5},
keywords = {Artificial intelligence (AI), Machine learning, AI ethics, Responsible AI, Military, Military applications}
}

@article{10.1145/3590151,
author = {Li, Juntao},
title = {Information Processing for Low Resource Processing Based Cognitive Psychology for Second Language Teaching by Opinion Mining using Deep Learning Architecture},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3590151},
doi = {10.1145/3590151},
abstract = {Foreign language instruction is crucial and difficult in every nation. Effective teachers must consider students' attitudes, motivation, and knowledge. Quality teaching determines student success. This study presents an AI-based deep learning method for second language and English instruction. This dataset was collected from students' second language and English teaching preferences. Dimensionality reduction and missing value removal were done on the dataset. Fuzzy set-based clustering with stochastic gradient residual neural network (ResNet) architecture classified this processed data. Students' second language and English teaching opinions were collected using fuzzy rules. Fuzzy clustering and stochastic gradient ResNet architecture classified this data. Student opinion mining was used for experimental study of various datasets and the parametric analysis yielded 96% accuracy, 90% sensitivity, 92% specificity, 82% F-1 score, 72% Mean squared error (MSE), and 88% Area Under the Curve (AUC).},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {apr},
keywords = {CALL, AI, second language learning, English teaching, classification}
}

@article{10.4018/IJEGR.298216,
author = {Kuberkar, Sachin and Singhal, Tarun Kumar and Singh, Shikha},
title = {Fate of AI for Smart City Services in India: A Qualitative Study},
year = {2022},
issue_date = {Mar 2022},
publisher = {IGI Global},
address = {USA},
volume = {18},
number = {2},
issn = {1548-3886},
url = {https://doi.org/10.4018/IJEGR.298216},
doi = {10.4018/IJEGR.298216},
abstract = {With the rollout of the smart city initiative in India, this study explores potential risks and opportunities in adopting artificial intelligence (AI) for citizen services. The study deploys expert interview technique and the data collected from various sources are analyzed using qualitative analysis. It was found that AI implementation needs a critical examination of various socio-technological factors to avoid any undesirable impacts on citizens. Fairness, accountability, transparency, and ethics (FATE) play an important role during the design and execution of AI-based systems. This study provides vital insights into AI implications to smart city managers, citizen groups, and policymakers while delivering promised smart city experience. The study has social implications in terms of ensuring that proper guidelines are developed for using AI technology for citizen services, thereby bridging the ever-critical trust gap between citizens and city administration.},
journal = {Int. J. Electron. Gov. Res.},
month = {mar},
pages = {1–21},
numpages = {21},
keywords = {AI, Ethics, Fairness, Smart City, Transparency}
}

@inproceedings{10.1145/3001773.3001797,
author = {Ishihara, Makoto and Miyazaki, Taichi and Chu, Chun Yin and Harada, Tomohiro and Thawonmas, Ruck},
title = {Applying and Improving Monte-Carlo Tree Search in a Fighting Game AI},
year = {2016},
isbn = {9781450347730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001773.3001797},
doi = {10.1145/3001773.3001797},
abstract = {This paper evaluates the performance of Monte-Carlo Tree Search (MCTS) in a fighting game AI and proposes an improvement for the algorithm. Most existing fighting game AIs rely on rule bases and react to every situation with predefined actions, making them predictable for human players. We attempt to overcome this weakness by applying MCTS, which can adapt to different circumstances without relying on predefined action patterns or tactics. In this paper, an AI based on Upper Confidence bounds applied to Trees (UCT) and MCTS is first developed. Next, the paper proposes improving the AI with Roulette Selection and a rule base. Through testing and evaluation using FightingICE, an international fighting game AI competition platform, it is proven that the aforementioned MCTS-based AI is effective in a fighting game, and our proposed improvement can further enhance its performance.},
booktitle = {Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology},
articleno = {27},
numpages = {6},
keywords = {Artificial Intelligence, Fighting Game, FightingICE, MCTS, Roulette Selection},
location = {Osaka, Japan},
series = {ACE '16}
}

@inproceedings{10.1145/3466933.3466969,
author = {Siqueira de Cerqueira, Jos\'{e} Antonio and Acco Tives, Heloise and Dias Canedo, Edna},
title = {Ethical Guidelines and Principles in the Context of Artificial Intelligence},
year = {2021},
isbn = {9781450384919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466933.3466969},
doi = {10.1145/3466933.3466969},
abstract = {The interest in Artificial Intelligence (AI) based systems has been gaining momentum at a fast pace, both for software development teams and for society as a whole. This work aims to identify the guidelines and ethical principles for systems based on Artificial Intelligence. Design Science Research methodology was adopted in order to understand the various guidelines and principles existing in the literature. From the current landscape, a body of knowledge in the field of AI ethics is presented, with the purpose of supporting developers and Product Owners in identifying the guidelines and ethical principles in the literature so that they can be used during the software development process. Thus, this work will contribute to the various stakeholders in the development of ethical systems in the context of AI, such as: policy makers, ethicists, users, organizations, data scientists, development teams, among others.},
booktitle = {Proceedings of the XVII Brazilian Symposium on Information Systems},
articleno = {36},
numpages = {8},
location = {Uberl\^{a}ndia, Brazil},
series = {SBSI '21}
}

@inproceedings{10.5555/3466184.3466363,
author = {Feldkamp, Niclas and Bergmann, Soeren and Strassburger, Steffen},
title = {Simulation-based deep reinforcement learning for modular production systems},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {Modular production systems aim to supersede the traditional line production in the automobile industry. The idea here is that highly customized products can move dynamically and autonomously through a system of flexible workstations without fixed production cycles. This approach has challenging demands regarding planning and organization of such systems. Since each product can define its way through the system freely and individually, implementing rules and heuristics that leverage the flexibility in the system in order to increase performance can be difficult in this dynamic environment. Transport tasks are usually carried out by automated guided vehicles (AGVs). Therefore, integration of AI-based control logics offer a promising alternative to manually implemented decision rules for operating the AGVs. This paper presents an approach for using reinforcement learning (RL) in combination with simulation in order to control AGVs in modular production systems. We present a case study and compare our approach to heuristic rules.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1596–1607},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@inproceedings{10.1145/3544548.3581369,
author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
title = {DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581369},
doi = {10.1145/3544548.3581369},
abstract = {Children acquire an understanding of the world by asking “why” and “how” questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children’s questions as they are more readily available than parents or teachers. However, CAs’ answers to “why” and “how” questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children’s engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children’s questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {22},
keywords = {Children, Conversational Agents, Dialogue, Natural Language, Question Answering},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}

@inproceedings{10.1145/3570991.3570998,
author = {Arya, Vijay and Saha, Diptikalyan and Hans, Sandeep and Rajasekharan, Amaresh and Tang, Tony},
title = {Global Explanations for Multivariate time series models},
year = {2023},
isbn = {9781450397971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570991.3570998},
doi = {10.1145/3570991.3570998},
abstract = {Several explainable AI algorithms have been proposed to help make machine learning models more interpretable and trustworthy. However in spite of numerous methodological advancements, there is still a persistent gap between what researchers develop and what business users seek. In this work, we aim to bridge this gap for an AI system that predicts the remaining useful life of an aircraft’s engine using time series data collected from multiple sensors. We propose a novel approach to compute easily understandable explanations by fusing two explainers in sequence wherein explanations of the first explainer are explained by the second. We use this approach to build a global post-hoc model-agnostic explainer for AI models that ingest multivariate time series data. Our approach fuses a local explainer that yields feature importance weights, with a directly interpretable model that outputs global rules. Our experimental results based on the C-MAPSS open-source dataset demonstrate that the proposed two-stage explainer computes global explanations that are amenable to business users and sheds light on how the behavior of an individual and a group of sensors impacts the remaining useful life of an aircraft’s engine.},
booktitle = {Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD)},
pages = {149–157},
numpages = {9},
keywords = {AI Explainability, global explanations, timeseries data},
location = {Mumbai, India},
series = {CODS-COMAD '23}
}

@article{10.1016/j.procs.2019.09.463,
author = {Aljaafreh, Ahmad and Al-Oudat, Naeem},
title = {Development of a Computer Player for Seejeh (A.K.A Seega, Siga, Kharbga) Board Game with Deep Reinforcement Learning},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {160},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.463},
doi = {10.1016/j.procs.2019.09.463},
journal = {Procedia Comput. Sci.},
month = {jan},
pages = {241–247},
numpages = {7},
keywords = {Board game, deep reinforcement learning, search, MCTS, Minimax, self-play, Seejeh}
}

@article{10.1109/TC.2019.2949300,
author = {Mor\'{a}n, Alejandro and Frasser, Christiam F. and Roca, Miquel and Rossell\'{o}, Josep L.},
title = {Energy-Efficient Pattern Recognition Hardware With Elementary Cellular Automata},
year = {2020},
issue_date = {March 2020},
publisher = {IEEE Computer Society},
address = {USA},
volume = {69},
number = {3},
issn = {0018-9340},
url = {https://doi.org/10.1109/TC.2019.2949300},
doi = {10.1109/TC.2019.2949300},
abstract = {The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) is able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy.},
journal = {IEEE Trans. Comput.},
month = {mar},
pages = {392–401},
numpages = {10}
}

@inproceedings{10.1007/978-3-030-68007-7_6,
author = {Rjoob, Khaled and Bond, Raymond and Finlay, Dewar and McGilligan, Victoria and Leslie, Stephen J. and Rababah, Ali and Iftikhar, Aleeha and Guldenring, Daniel and Knoery, Charles and McShane, Anne and Peace, Aaron},
title = {Towards Explainable Artificial Intelligence and Explanation User Interfaces to Open the ‘Black Box’ of Automated ECG Interpretation},
year = {2020},
isbn = {978-3-030-68006-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68007-7_6},
doi = {10.1007/978-3-030-68007-7_6},
abstract = {This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system.},
booktitle = {Advanced Visual Interfaces. Supporting Artificial Intelligence and Big Data Applications: AVI 2020 Workshops, AVI-BDA and ITAVIS, Ischia, Italy, June 9, 2020 and September 29, 2020, Revised Selected Papers},
pages = {96–108},
numpages = {13},
keywords = {Artificial intelligence (AI), ECG interpretation, Explainable AI (XAI)}
}

@article{10.1007/s42979-021-00557-0,
author = {Sarker, Iqbal H. and Furhad, Md Hasan and Nowrozy, Raza},
title = {AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00557-0},
doi = {10.1007/s42979-021-00557-0},
abstract = {Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or&nbsp;Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or&nbsp;AI-based technical point of view.},
journal = {SN Comput. Sci.},
month = {mar},
numpages = {18},
keywords = {Cybersecurity, Artificial intelligence, Machine learning, Cyber data analytics, Cyber-attacks, Anomaly, Intrusion detection, Security intelligence}
}

@article{10.1145/3579628,
author = {Holstein, Kenneth and De-Arteaga, Maria and Tumati, Lakshmi and Cheng, Yanghuidi},
title = {Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579628},
doi = {10.1145/3579628},
abstract = {In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {152},
numpages = {20},
keywords = {algorithm-assisted decision-making, behavioral experiment, human-AI complementarity, unobservables}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ambiguity, artificial intelligence, medical data analysis},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '20}
}

@inproceedings{10.1145/3593013.3594063,
author = {Petti, Ulla and Nyrup, Rune and Skopek, Jeffrey M. and Korhonen, Anna},
title = {Ethical considerations in the early detection of Alzheimer's disease using speech and AI},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594063},
doi = {10.1145/3593013.3594063},
abstract = {While recent studies indicate that AI could play an important role in detecting early signs of Alzheimer's disease in speech, this use of data from individuals with cognitive decline raises numerous ethical concerns. In this paper, we identify and explain concerns related to autonomy (including consent, depersonalization and disclosure), privacy and data protection (including the handling of personal content and medical information), welfare (including distress, discrimination and reliability), transparency (including the interpretability of language features and AI-based decision-making for developers and clinicians), and fairness (including bias and the distribution of benefits). Our aim is to not only raise awareness of the ethical concerns posed by the use of AI in speech-based Alzheimer's detection, but also identify ways in which these concerns might be addressed. To this end, we conclude with a list of suggestions that could be incorporated into ethical guidelines for researchers and clinicians working in this area.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1062–1075},
numpages = {14},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1007/978-3-319-07221-0_64,
author = {Martinez-Maldonado, Roberto and Clayphan, Andrew and Yacef, Kalina and Kay, Judy},
title = {Towards Providing Notifications to Enhance Teacher's Awareness in the Classroom},
year = {2014},
isbn = {9783319072203},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-07221-0_64},
doi = {10.1007/978-3-319-07221-0_64},
abstract = {Students often need prompt feedback to make the best from the learning activities. Within classrooms, being aware of students' achievements and weaknesses can help teachers decide how to time feedback. However, they usually cannot easily assess student's progress. We present an approach to generate automated notifications that can enhance teacher's awareness in runtime. This paper formulates the theoretical framing and describes the technological infrastructure of a system that can help teachers orchestrate learning activities and monitor small groups in a multi-tabletop classroom. We define the design guidelines underpinning our system, which include: i generating notifications from teacher-designed or AI-based sources; ii enhancing teacher's awareness in the orchestration loop; iii presenting both positive and negative notifications; iv allowing teachers to tune the system; and v providing a private teacher's user interface. Our approach aims to guide research on ways to generate notifications that can help teachers drive their attention and provide relevant feedback for small group learning activities in the classroom.},
booktitle = {12th International Conference on Intelligent Tutoring Systems - Volume 8474},
pages = {510–515},
numpages = {6},
keywords = {CSCL, Classroom, F2F Collaboration, Notifications, Orchestration},
location = {Honolulu, HI, USA},
series = {ITS 2014}
}

@article{10.1016/j.ipm.2022.103099,
author = {Castelnovo, Alessandro and Cosentini, Andrea and Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario},
title = {         FFTree: A flexible tree to handle multiple fairness criteria},
year = {2022},
issue_date = {Nov 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {59},
number = {6},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2022.103099},
doi = {10.1016/j.ipm.2022.103099},
journal = {Inf. Process. Manage.},
month = {nov},
numpages = {14},
keywords = {0000, 1111, Machine learning, Explainable AI, Fairness, Discrimination-aware decision tree}
}

@inproceedings{10.1145/3386392.3399276,
author = {D\'{\i}az-Rodr\'{\i}guez, Natalia and Pisoni, Galena},
title = {Accessible Cultural Heritage through Explainable Artificial Intelligence},
year = {2020},
isbn = {9781450379502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386392.3399276},
doi = {10.1145/3386392.3399276},
abstract = {Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy.},
booktitle = {Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {317–324},
numpages = {8},
keywords = {art, computer vision, cultural heritage, deep learning, deep neural networks, explainable artificial intelligence, generative models, image captioning, natural language processing},
location = {Genoa, Italy},
series = {UMAP '20 Adjunct}
}

@article{10.1007/s10270-023-01131-3,
author = {Planas, Elena and Mart\'{\i}nez, Salvador and Brambilla, Marco and Cabot, Jordi},
title = {Modeling and enforcing access control policies in conversational user interfaces},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-023-01131-3},
doi = {10.1007/s10270-023-01131-3},
abstract = {Conversational user interfaces (CUIs), such as chatbots, are becoming a common component of many software systems. Although they are evolving in many directions (such as advanced language processing features, thanks to new AI-based developments), less attention has been paid to access control and other security concerns associated with CUIs, which may pose a clear risk to the systems they interface with. In this paper, we apply model-driven techniques to model and enforce access-control policies in CUIs. In particular, we present a fully fledged framework to integrate the role-based access-control (RBAC) protocol into CUIs by: (1) modeling a set of access-control rules to specify permissions over the bot resources using a domain-specific language that tailors core RBAC concepts to the CUI domain; and (2) describing a mechanism to show the feasibility of automatically generating the infrastructure to evaluate and enforce the modeled access control policies at runtime.},
journal = {Softw. Syst. Model.},
month = {nov},
pages = {1925–1944},
numpages = {20},
keywords = {Model-driven engineering, Conversational user interfaces, CUIs, Access-control, RBAC}
}

@inproceedings{10.1007/978-3-031-35708-4_22,
author = {Heuer, Marvin and Lewandowski, Tom and Weglewski, Joffrey and Mayer, Tom and Kubicek, Max and Lembke, Patrick and Ortgiese, Simon and B\"{o}hmann, Tilo},
title = {Rethinking Interaction with Conversational Agents: How to Create a Positive User Experience Utilizing Dialog Patterns},
year = {2023},
isbn = {978-3-031-35707-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35708-4_22},
doi = {10.1007/978-3-031-35708-4_22},
abstract = {Conversational agents (CAs) are increasingly used as an additional convenient and innovative customer service channel to relieve service employees, as in the studied organization. In the process of analyzing and maintaining the present AI-based agent, however, user satisfaction is low as the CA lacks understanding and offers unsatisfactory solutions to users. Nonetheless, solving the requests and providing a positive user experience is crucial to relieve the service employees’ workload permanently. For CAs’ improvement, this study followed action design research (ADR) and used design thinking. We identified the central interaction problems (findability, welcome message, dialog control and fallback issues) with a monitoring process and analysis. Afterward, we interviewed users about their expectations and requirements and addressed these problems by creating user-centric mock-ups. Through a quantitative survey, the most popular solutions were implemented in a prototype. Finally, the resulting CA prototype was evaluated, showing a significantly improved user experience afterward, and design guidelines were discovered.},
booktitle = {Design, User Experience, and Usability: 12th International Conference, DUXU 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part IV},
pages = {283–301},
numpages = {19},
keywords = {conversational agents, chatbot user experience (UX), fallback strategy, interaction design, artificial intelligence (AI)},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3278721.3278751,
author = {Vasconcelos, Marisa and Cardonha, Carlos and Gon\c{c}alves, Bernardo},
title = {Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278751},
doi = {10.1145/3278721.3278751},
abstract = {Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {323–329},
numpages = {7},
keywords = {attempts at refutation, bias of ai, constrained models, hiring algorithms, problem of induction, semi-automatic decision making},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@inproceedings{10.1145/3600160.3605052,
author = {Nguyen, Manh-Dung and Bouaziz, Anis and Valdes, Valeria and Rosa Cavalli, Ana and Mallouli, Wissam and Montes De Oca, Edgardo},
title = {A deep learning anomaly detection framework with explainability and robustness},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3605052},
doi = {10.1145/3600160.3605052},
abstract = {The prevalence of encrypted Internet traffic has resulted in a pressing need for advanced analysis techniques for traffic analysis and classification. Traditional rule-based and signature-based approaches have been hindered by the introduction of network encryption methods. With the emergence of machine learning (ML) and deep learning (DL), several preliminary works have been developed for anomaly detection in encrypted network traffic. However, complex Artificial Intelligence (AI) models like neural networks lack explainability, limiting the understanding of their predictions. To address this limitation, eXplainable Artificial Intelligence (XAI) has emerged, aiming to provide users with a rationale for understanding AI system outputs and fostering trust. However, existing explainable frameworks still lack comprehensive support for adversarial attacks and defenses. In this paper, we present Montimage AI Platform (MAIP), a new GUI-based deep learning framework for malicious traffic detection and classification combined with its ability of explaining the decision of the model. We employ popular XAI methods to interpret the prediction of the developed deep learning model. Furthermore, we perform adversarial attacks to assess the accountability and robustness of our model via different quantifiable metrics. We perform extensive experiments with both public and private network traffic. The experimental results demonstrate that our model achieves high performance and robustness, and its outcomes align closely with the domain knowledge.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {134},
numpages = {7},
keywords = {Adversarial Attacks, Deep Learning, Encrypted Traffic Analysis, Explainable AI, Malware Detection, Network Security},
location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>, </conf-loc>},
series = {ARES '23}
}

@inproceedings{10.1145/3462244.3479926,
author = {Tutul, Abdullah Aman and Nirjhar, Ehsanul Haque and Chaspari, Theodora},
title = {Investigating Trust in Human-Machine Learning Collaboration: A Pilot Study on Estimating Public Anxiety from Speech},
year = {2021},
isbn = {9781450384810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462244.3479926},
doi = {10.1145/3462244.3479926},
abstract = {Trust is a key element in the development of effective collaborative relationships between humans and increasingly complex artificial intelligence (AI) systems. Here, we examine trust in AI in the context of a human-AI partnership that involves a joint decision making task for estimating levels of public speaking anxiety based on speech signals. The AI system is comprised of an explainable machine learning (ML) algorithm, that takes acoustic characteristics as input and outputs the estimate of public speaking anxiety levels, a local explanation about the most important features that contributed to the decision of each speech sample, and a global explanation about the most important features for the data overall. We analyze interactions between AI and human annotators with background in psychological sciences, and measure trust over time via the annotators’ agreement with the AI model and the annotators’ self-reports. We further examine factors of trust that are related to the characteristics of the human annotator and the ML algorithm. Results indicate that trust in AI depends on the openness level of the annotator and the importance level of input features. Findings from this study can provide guidelines to designing solutions that properly calibrate human trust in AI in collaborative human-AI tasks.},
booktitle = {Proceedings of the 2021 International Conference on Multimodal Interaction},
pages = {288–296},
numpages = {9},
keywords = {Trustworthy AI, human-AI interaction, public speaking anxiety, speech},
location = {Montr\'{e}al, QC, Canada},
series = {ICMI '21}
}

@inproceedings{10.1007/978-3-319-92046-7_42,
author = {Kim, Jae Min and Lee, Seung Jun},
title = {Framework to Develop Artificial Intelligent Autonomous Operating System for Nuclear Power Plants},
year = {2018},
isbn = {978-3-319-92045-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-92046-7_42},
doi = {10.1007/978-3-319-92046-7_42},
abstract = {As artificial intelligent (AI) technology has been dramatically developed, various industries have been challenged to apply it. In a view of nuclear power plants (NPP), it seems that AI technology applies to NPPs at the last because NPPs are required the most stringent level of regulatory guideline for safety. To overcome it, AI technology should be applied incrementally into the NPPs rather than all at once. According to the unintended shutdown records during startup and shutdown operation from 1997 to 2017 in Korea, it is reported that human errors accounts for 40% of the total. This is because operators feel heavy burden to monitor hundreds of parameters for a long time of operating time. Also, there are lots of startup and shutdown operating history that can be used for correcting the data from the NPP simulator. Therefore, this work proposes a framework to develop AI automatic operating system for startup and shutdown operations of NPPs. Operating procedures of startup and shutdown operations are categorized. In addition, AI technologies will be introduced to find out the most suitable learning algorithm. It is expected that economic loss from human error during startup and shutdown operation will be reduced as AI system developed.},
booktitle = {Human Interface and the Management of Information. Information in Applications and Services: 20th International Conference, HIMI 2018, Held as Part of HCI International 2018, Las Vegas, NV, USA, July 15-20, 2018, Proceedings, Part II},
pages = {508–517},
numpages = {10},
keywords = {Artificial intelligent, Startup and shutdown operation, Operating procedure},
location = {Las Vegas, NV, USA}
}

@article{10.1016/j.ijinfomgt.2021.102387,
author = {Akter, Shahriar and McCarthy, Grace and Sajib, Shahriar and Michael, Katina and Dwivedi, Yogesh K. and D’Ambra, John and Shen, K.N.},
title = {Algorithmic bias in data-driven innovation in the age of AI},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {60},
number = {C},
issn = {0268-4012},
url = {https://doi.org/10.1016/j.ijinfomgt.2021.102387},
doi = {10.1016/j.ijinfomgt.2021.102387},
journal = {Int. J. Inf. Manag.},
month = {oct},
numpages = {13},
keywords = {Algorithmic bias, Data driven innovation, Data bias, Method bias, Societal bias}
}

@inproceedings{10.1145/3102071.3102105,
author = {de Mesentier Silva, Fernando and Lee, Scott and Togelius, Julian and Nealen, Andy},
title = {AI-based playtesting of contemporary board games},
year = {2017},
isbn = {9781450353199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102071.3102105},
doi = {10.1145/3102071.3102105},
abstract = {Ticket to Ride is a popular contemporary board game for two to four players, featuring a number of expansions with additional maps and tweaks to the core game mechanics. In this paper, four different game-playing agents that embody different playing styles are defined and used to analyze Ticket to Ride. Different playing styles are shown to be effective depending on the map and rule variation, and also depending on how many players play the game. The performance profiles of the different agents can be used to characterize maps and identify the most similar maps in the space of playstyles. Further analysis of the automatically played games reveal which cities on the map are most desirable, and that the relative attractiveness of cities is remarkably consistent across numbers of players. Finally, the automated analysis also reveals two classes of failures states, where the agents find states which are not covered by the game rules; this is akin to finding bugs in the rules. We see the analysis performed here as a possible template for AI-based playtesting of contemporary board games.},
booktitle = {Proceedings of the 12th International Conference on the Foundations of Digital Games},
articleno = {13},
numpages = {10},
keywords = {artificial intelligence, board games, contemporary board games, playtesting, ticket to ride},
location = {Hyannis, Massachusetts},
series = {FDG '17}
}

@article{10.1016/j.comnet.2019.106950,
author = {Gupta, Lav and Salman, Tara and Zolanvari, Maede and Erbad, Aiman and Jain, Raj},
title = {Fault and performance management in multi-cloud virtual network services using AI: A tutorial and a case study},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {165},
number = {C},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2019.106950},
doi = {10.1016/j.comnet.2019.106950},
journal = {Comput. Netw.},
month = {dec},
numpages = {22},
keywords = {Network Function Virtualization, Virtual Network Services, Service Function Chains, Virtual Network Functions, Multi-cloud, Fault management, Performance management, Machine learning, Deep learning}
}

@article{10.1016/j.compbiomed.2023.107187,
author = {Wang, Yan and Zhang, Ruochi and Zhang, Shengde and Guo, Liming and Zhou, Qiong and Zhao, Bowen and Mo, Xiaotong and Yang, Qian and Huang, Yajuan and Li, Kewei and Fan, Yusi and Huang, Lan and Zhou, Fengfeng},
title = {OCMR: A comprehensive framework for optical chemical molecular recognition},
year = {2023},
issue_date = {Sep 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {163},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2023.107187},
doi = {10.1016/j.compbiomed.2023.107187},
journal = {Comput. Biol. Med.},
month = {sep},
numpages = {11},
keywords = {Bioinformatics, OCSR, Chemical informatics, Chemical structure recognition, Molecular graph, OCMR}
}

@article{10.1007/s00146-022-01442-x,
author = {Murtaza, Mohsin and Cheng, Chi-Tsun and Fard, Mohammad and Zeleznikow, John},
title = {The importance of transparency in naming conventions, designs, and operations of safety features: from modern ADAS to fully autonomous driving functions},
year = {2022},
issue_date = {Apr 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {2},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-022-01442-x},
doi = {10.1007/s00146-022-01442-x},
abstract = {This paper investigates the importance of standardising and maintaining the transparency of advanced driver-assistance systems (ADAS) functions nomenclature, designs, and operations in all categories up until fully autonomous vehicles. The aim of this paper is to reveal the discrepancies&nbsp;in ADAS functions across automakers and discuss the underlying issues and potential solutions. In this pilot study, user manuals of various brands are reviewed systematically and critical analyses of common ADAS functions are conducted. The result shows that terminologies used to describe ADAS functions vary widely across manufacturers and sometimes do not reflect their fundamental functions intuitively. Operational conditions and control procedures also vary across the selected models under this study. Due to this lack of consensus across the industry, drivers are not aware or well informed about ADAS functions in their vehicles, leading to a very low utilization rate and may lead to misuse of those functions. This paper provides insightful suggestions for the transport industry, Artificial Intelligence (AI) experts, and regulators to design frameworks and guidelines in governing the naming convention, operating conditions, control procedures, and information disclosure of ADAS. Such guidelines can be the foundations for regulating future AI-based self-driving functions.},
journal = {AI Soc.},
month = {apr},
pages = {983–993},
numpages = {11},
keywords = {ADAS, Autonomous vehicles, Operating conditions, Regulation, Standards, Transparency}
}

@inproceedings{10.1145/3597512.3599697,
author = {Ronanki, Krishna and Cabrero-Daniel, Beatriz and Horkoff, Jennifer and Berger, Christian},
title = {RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems},
year = {2023},
isbn = {9798400707346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597512.3599697},
doi = {10.1145/3597512.3599697},
abstract = {Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address these concerns, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.},
booktitle = {Proceedings of the First International Symposium on Trustworthy Autonomous Systems},
articleno = {1},
numpages = {8},
keywords = {Autonomous Systems, EU AI Act, Ethical AI, Frameworks, Guidelines, Limitations, Recommendations, Requirements Engineering, Trustworthy AI},
location = {<conf-loc>, <city>Edinburgh</city>, <country>United Kingdom</country>, </conf-loc>},
series = {TAS '23}
}

@inproceedings{10.1145/3341162.3349331,
author = {Banerjee, Rohan and Ghose, Avik and Sinha, Aniruddha and Pal, Arpan and Mandana, K M},
title = {A multi-modal approach for non-invasive detection of coronary artery disease},
year = {2019},
isbn = {9781450368698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341162.3349331},
doi = {10.1145/3341162.3349331},
abstract = {Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity = 0.96 and specificity = 0.91 in classifying CAD patients on an in-house hospital dataset, recorded using commercially available sensors.},
booktitle = {Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers},
pages = {543–550},
numpages = {8},
keywords = {cardiovascular signals, classification, coronary artery disease, feature extraction},
location = {London, United Kingdom},
series = {UbiComp/ISWC '19 Adjunct}
}

@article{10.1016/j.jss.2021.111050,
author = {Myllyaho, Lalli and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi and Mikkonen, Tommi and Nurminen, Jukka K.},
title = {Systematic literature review of validation methods for AI systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111050},
doi = {10.1016/j.jss.2021.111050},
journal = {J. Syst. Softw.},
month = {nov},
numpages = {22},
keywords = {Artificial intelligence, Machine learning, Validation, Testing, V&amp;V, Systematic literature review}
}

@inproceedings{10.1007/978-3-031-16437-8_33,
author = {Yao, Jiawen and Ye, Xianghua and Xia, Yingda and Zhou, Jian and Shi, Yu and Yan, Ke and Wang, Fang and Lin, Lili and Yu, Haogang and Hua, Xian-Sheng and Lu, Le and Jin, Dakai and Zhang, Ling},
title = {Effective Opportunistic Esophageal Cancer Screening Using Noncontrast CT Imaging},
year = {2022},
isbn = {978-3-031-16436-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-16437-8_33},
doi = {10.1007/978-3-031-16437-8_33},
abstract = {Esophageal cancer is the second most deadly cancer. Early detection of resectable/curable esophageal cancers has a great potential to reduce mortality, but no guideline-recommended screening test is available. Although some screening methods have been developed, they are expensive, might be difficult to apply to the general population, and often fail to achieve satisfactory sensitivity for identifying early-stage cancers. In this work, we investigate the feasibility of esophageal tumor detection and classification (cancer or benign) on the noncontrast CT scan, which could potentially be used for opportunistic cancer screening. To capture the global context, a novel position-sensitive self-attention is proposed to augment nnUNet with non-local interactions. Our model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients. In comparison, the mean sensitivity and specificity of four doctors are 75.0% and 83.8%, respectively. For the classification task, our model outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system, our method has comparable performance and is even more sensitive for early-stage cancer and benign tumor. Our proposed method is a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer.},
booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2022: 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part III},
pages = {344–354},
numpages = {11},
keywords = {Esophageal cancer, Cancer screening, Self-attention, Noncontrast CT},
location = {Singapore, Singapore}
}

@inproceedings{10.1007/978-3-030-98464-9_1,
author = {Balasubramaniam, Nagadivya and Kauppinen, Marjo and Hiekkanen, Kari and Kujala, Sari},
title = {Transparency and Explainability of AI Systems: Ethical Guidelines in Practice},
year = {2022},
isbn = {978-3-030-98463-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98464-9_1},
doi = {10.1007/978-3-030-98464-9_1},
abstract = {[Context and Motivation] Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. [Question] The goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems. We analyzed the ethical guidelines in 16 organizations representing different industries and public sector. [Results] In the ethical guidelines, the importance of transparency was highlighted by almost all of the organizations, and explainability was considered as an integral part of transparency. Building trust in AI systems was one of the key reasons for developing transparency and explainability, and customers and users were raised as the main target groups of the explanations. The organizations also mentioned developers, partners, and stakeholders as important groups needing explanations. The ethical guidelines contained the following aspects of the AI system that should be explained: the purpose, role of AI, inputs, behavior, data utilized, outputs, and limitations. The guidelines also pointed out that transparency and explainability relate to several other quality requirements, such as trustworthiness, understandability, traceability, privacy, auditability, and fairness. [Contribution] For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a structured way to define explainability requirements of AI systems.},
booktitle = {Requirements Engineering: Foundation for Software Quality: 28th International Working Conference, REFSQ 2022, Birmingham, UK, March 21–24, 2022, Proceedings},
pages = {3–18},
numpages = {16},
keywords = {Transparency, Explainability, Quality requirements, Ethical guidelines, AI systems},
location = {Birmingham, United Kingdom}
}

@article{10.1016/j.compag.2017.04.015,
author = {Agostini, Alejandro and Aleny, Guillem and Fischbach, Andreas and Scharr, Hanno and Wrgtter, Florentin and Torras, Carme},
title = {A cognitive architecture for automatic gardening},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {138},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2017.04.015},
doi = {10.1016/j.compag.2017.04.015},
abstract = {A cognitive system to autonomously control the growth of plants is proposed.The system integrates artificial intelligence and robotic techniques.Decisions are made using symbolic planning and machine learning.Plants are modelled using 3D model acquisition of deformable objects (leaves).Action rules are learned during run-time under the guidance of a human gardener. In large industrial greenhouses, plants are usually treated following well established protocols for watering, nutrients, and shading/light. While this is practical for the automation of the process, it does not tap the full potential for optimal plant treatment. To more efficiently grow plants, specific treatments according to the plant individual needs should be applied. Experienced human gardeners are very good at treating plants individually. Unfortunately, hiring a crew of gardeners to carry out this task in large greenhouses is not cost effective. In this work we present a cognitive system that integrates artificial intelligence (AI) techniques for decision-making with robotics techniques for sensing and acting to autonomously treat plants using a real-robot platform. Artificial intelligence techniques are used to decide the amount of water and nutrients each plant needs according to the history of the plant. Robotic techniques for sensing measure plant attributes (e.g. leaves) from visual information using 3D model representations. These attributes are used by the AI system to make decisions about the treatment to apply. Acting techniques execute robot movements to supply the plants with the specified amount of water and nutrients.},
journal = {Comput. Electron. Agric.},
month = {jun},
pages = {69–79},
numpages = {11},
keywords = {Automatic gardening, Cognitive architecture, Human-robot interaction, Learning planning operators, Optimized plant treatments}
}

@inproceedings{10.1007/978-3-030-77211-6_34,
author = {Parimbelli, Enea and Gabetta, Matteo and Lanzola, Giordano and Polce, Francesca and Wilk, Szymon and Glasspool, David and Kogan, Alexandra and Leizer, Roy and Gisko, Vitali and Veggiotti, Nicole and Panzarasa, Silvia and de Groot, Rowdy and Ottaviano, Manuel and Sacchi, Lucia and Cornet, Ronald and Peleg, Mor and Quaglini, Silvana},
title = {CAncer PAtients Better Life Experience (CAPABLE) First Proof-of-Concept Demonstration},
year = {2021},
isbn = {978-3-030-77210-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77211-6_34},
doi = {10.1007/978-3-030-77211-6_34},
abstract = {The CAncer PAtient Better Life Experience (CAPABLE) project combines the most advanced technologies for data and knowledge management with a socio-psychological approach, to develop a coaching system for improving the quality of life of cancer patients managed at home. The team includes complementary expertise in data- and knowledge-driven AI, data integration, telemedicine and decision support. The time is right to fully exploit Artificial Intelligence for cancer care and bring the benefits right to patients’ homes. CAPABLE relies on predictive models based on both retrospective and prospective data, integrated with computer interpretable guidelines and made available to oncologists. CAPABLE’s Virtual Coach component identifies unexpected needs and provides patient-specific decision support and lifestyle guidance to improve mental and physical wellbeing of patients. The demo, designed around a use-case scenario developed with clinicians involved in the project, addresses the ESMO Diarrhea guideline. It revolves around a prototypical fictional patient named Maria. Maria, 66, is affected by renal cell carcinoma and moderate insomnia. The demo follows Maria during the first three days of using the CAPABLE system. This allows the audience to understand the scope and innovation behind this AI-based decision-support and coaching system that personalizes lifestyle and medication interventions to patients, their carer and clinicians.},
booktitle = {Artificial Intelligence in Medicine: 19th International Conference on Artificial Intelligence in Medicine, AIME 2021, Virtual Event, June 15–18, 2021, Proceedings},
pages = {298–303},
numpages = {6},
keywords = {Cancer, Side effects, Personalization, Coaching, Guideline, FAIR, FHIR, OMOP, AI, mHealth}
}

@inproceedings{10.1145/3510003.3510163,
author = {Chen, Boyuan and Wen, Mingzhi and Shi, Yong and Lin, Dayi and Rajbahadur, Gopi Krishnan and Jiang, Zhen Ming (Jack)},
title = {Towards training reproducible deep learning models},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510163},
doi = {10.1145/3510003.3510163},
abstract = {Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2202–2214},
numpages = {13},
keywords = {artificial intelligence, deep learning, reproducibility, software engineering},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3604321.3604375,
author = {Wright, Craig and Allnutt, Jack and Campbell, Rosie and Evans, Michael and Jolly, Stephen and Shotton, Em and Lechelt, Susan and Phillipson, Graeme and Kerlin, Lianne},
title = {AI in Production: Video Analysis and Machine Learning for Expanded Live Events Coverage},
year = {2023},
isbn = {9798400708459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604321.3604375},
doi = {10.1145/3604321.3604375},
abstract = {As with many industries, TV and video production is likely to be transformed by artificial intelligence (AI) and machine learning (ML), with software and algorithms assisting production tasks that, conventionally, could only be carried out by people. Expanded coverage of a diverse range of live events is particularly constrained by the relative scarcity of skilled people, and it is a strong use case for AI-based automation. This article describes the recent research conducted by the British Broadcasting Corporation (BBC) on the potential production benefits of AI algorithms, using visual analysis and other techniques. Rigging small, static ultra high-definition (UHD) cameras, we have enabled a one-person crew to crop UHD footage in multiple ways and cut between the resulting shots, effectively creating multicamera HD coverage of events that cannot accommodate a camera crew. By working with programme-makers to develop simple deterministic rules and, increasingly, training systems using advanced video analysis, we are developing a system of algorithms to automatically frame, sequence, and select shots, and construct acceptable multicamera coverage of previously untelevised types of events. This paper was published in the proceedings of the International Broadcasting Convention in 2018&nbsp;[1], and in SMPTE Motion Imaging Journal in 2020&nbsp;[2].},
booktitle = {Proceedings of the 2023 ACM International Conference on Interactive Media Experiences Workshops},
pages = {77–78},
numpages = {2},
keywords = {broadcast technology, broadcasting, intelligent cinematography, user evaluation},
location = {Nantes, France},
series = {IMXw '23}
}

@inproceedings{10.1109/SMC42975.2020.9282981,
author = {Fujita, Shigeru and Gidel, Thierry and Kaeri, Yuki and Tucker, Andrea and Sugawara, Kenji and Moulin, Claude},
title = {AI-based Automatic Activity Recognition of Single Persons and Groups During Brainstorming&lt;sup&gt;*&lt;/sup&gt;},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC42975.2020.9282981},
doi = {10.1109/SMC42975.2020.9282981},
abstract = {In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person’s motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person’s activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students’ work sessions.},
booktitle = {2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {3782–3787},
numpages = {6},
location = {Toronto, ON}
}

@article{10.3233/IP-211524,
author = {Barkane, Irena and \v{C}as, Johann and De Hert, Paul and Porcedda, Maria Grazia and Raab, Charles D.},
title = {Questioning the EU proposal for an Artificial Intelligence Act: The need for prohibitions and a stricter approach to biometric surveillance1},
year = {2022},
issue_date = {2022},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {2},
issn = {1570-1255},
url = {https://doi.org/10.3233/IP-211524},
doi = {10.3233/IP-211524},
abstract = {Artificial Intelligence (AI)-based surveillance technologies such as facial recognition, emotion recognition and other biometric technologies have been rapidly introduced by both public and private entities all around the world, raising major concerns about their impact on fundamental rights, the rule of law and democracy. This article questions the efficiency of the European Commission’s Proposal for Regulation of Artificial Intelligence, known as the AI Act, in addressing the threats and risks to fundamental rights posed by AI biometric surveillance systems. It argues that in order to meaningfully address risks to fundamental rights the proposed classification of these systems should be reconsidered. Although the draft AI Act acknowledges that some AI practices should be prohibited, the multiple exceptions and loopholes should be closed, and in addition new prohibitions, in particular to emotional recognition and biometric categorisation systems, should be added to counter AI surveillance practices violating fundamental rights. The AI Act should also introduce stronger legal requirements, such as third-party conformity assessment, fundamental rights impact assessment, transparency obligations as well as enhance existing EU data protection law and the rights and remedies available to individuals, thus not missing the unique opportunity to adopt the first legal framework that truly promotes trustworthy AI.},
journal = {Info. Pol.},
month = {jan},
pages = {147–162},
numpages = {16},
keywords = {Artificial Intelligence Act, ban on mass surveillance, remote biometric identification, biometric categorisation, emotion recognition, prohibited artificial intelligence practices}
}

@article{10.1155/2021/5754322,
author = {Rathee, Geetanjali and Khelifi, Adel and Iqbal, Razi and Reina, Daniel G.},
title = {Artificial Intelligence- (AI-) Enabled Internet of Things (IoT) for Secure Big Data Processing in Multihoming Networks},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5754322},
doi = {10.1155/2021/5754322},
abstract = {The automated techniques enabled with Artificial Neural Networks (ANN), Internet of Things (IoT), and cloud-based services affect the real-time analysis and processing of information in a variety of applications. In addition, multihoming is a type of network that combines various types of networks into a single environment while managing a huge amount of data. Nowadays, the big data processing and monitoring in multihoming networks provide less attention while reducing the security risk and efficiency during processing or monitoring the information. The use of AI-based systems in multihoming big data with IoT- and AI-integrated systems may benefit in various aspects. Although multihoming security issues and their analysis have been well studied by various scientists and researchers; however, not much attention is paid towards big data security processing in multihoming especially using automated techniques and systems. The aim of this paper is to propose an IoT-based artificial network to process and compute big data processing by ensuring a secure communication multihoming network using the Bayesian Rule (BR) and Levenberg-Marquardt (LM) algorithms. Further, the efficiency and effect on multihoming information processing using an AI-assisted mechanism are experimented over various parameters such as classification accuracy, classification time, specificity, sensitivity, ROC, and F-measure.},
journal = {Wirel. Commun. Mob. Comput.},
month = {jan},
numpages = {9}
}

@inproceedings{10.1145/3494193.3494195,
author = {Mitrou, Lilian and Janssen, Marijn and Loukis, Euripidis},
title = {Human Control and Discretion in AI-driven Decision-making in Government},
year = {2022},
isbn = {9781450390118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494193.3494195},
doi = {10.1145/3494193.3494195},
abstract = {Traditionally public decision-makers have been given discretion in many of the decisions they have to make in how to comply with legislation and policies. In this way, the context and specific circumstances can be taken into account when making decisions. This enables more acceptable solutions, but at the same time, discretion might result in treating individuals differently. With the advance of AI-based decisions, the role of the decision-makers is changing. The automation might result in fully automated decisions, humans-in-the-loop or AI might only be used as recommender systems in which humans have the discretion to deviate from the suggested decision. The predictability of and the accountability of the decisions might vary in these circumstances, although humans always remain accountable. Hence, there is a need for human-control and the decision-makers should be given sufficient authority to control the system and deal with undesired outcomes. In this direction this paper analyzes the degree of discretion and human control needed in AI-driven decision-making in government. Our analysis is based on the legal requirements set/posed to the administration, by the extensive legal frameworks that have been created for its operation, concerning the rule of law, the fairness – non-discrimination, the justifiability and accountability, and the certainty/ predictability.},
booktitle = {Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance},
pages = {10–16},
numpages = {7},
location = {Athens, Greece},
series = {ICEGOV '21}
}

@inproceedings{10.1007/978-3-031-45368-7_2,
author = {Godoy B. de Oliveira, Cristina and de Paula Albuquerque, Ot\'{a}vio and Liene Belotti, Emily and Ferreira Lopes, Isabella and Brand\~{a}o de A. Silva, Rodrigo and Arbix, Glauco},
title = {Regulation and&nbsp;Ethics of&nbsp;Facial Recognition Systems: An Analysis of&nbsp;Cases in&nbsp;the&nbsp;Court of&nbsp;Appeal in&nbsp;the&nbsp;State of&nbsp;S\~{a}o Paulo},
year = {2023},
isbn = {978-3-031-45367-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-45368-7_2},
doi = {10.1007/978-3-031-45368-7_2},
abstract = {Context: The use of Artificial Intelligence (AI) in various sectors of the economy is already a reality in Brazil. Consequently, since 2019, the number of cases in the Judiciary involving AI has increased. Cases involving facial recognition systems (FRS) for contracting bank credit are increasing annually, so it is necessary to analyze how the Judiciary handles the issues. Problem: Why is the S\~{a}o Paulo Court of Appeal ruling in favor of banks in all cases involving taking out credit through facial recognition technology? Methodology and Methods: Data were collected and processed using automated computer programs. The qualitative analysis used the analytical, comparative and monographic methods. Results: The Court of Appeal of S\~{a}o Paulo considers it difficult to deceive an AI system, therefore, the burden of proof is on the author, even if there is a consumer relationship. That is, the decisions are contrary to the general rule of the Code of Consumer Protection in Brazil, which consists of reversing the burden of proof in consumer relations when one of the parties is underprivileged. Contributions and Solutions: The research points to the path of jurisprudence in cases involving the contracting of credit through FRS, and the Judiciary is deciding against the bank’s customers, dispensing with the production of evidence by the banking sector. Therefore, it is necessary to alert the National Council of Justice and the Central Bank regarding this situation so that it is disciplined adequately since the FRS is fallible and does not guarantee the absence of fraud.},
booktitle = {Intelligent Systems: 12th Brazilian Conference, BRACIS 2023, Belo Horizonte, Brazil, September 25–29, 2023, Proceedings, Part I},
pages = {18–32},
numpages = {15},
keywords = {Facial Recognition Systems and Legal Cases, Artificial Intelligence and Law, AI and Jurisprudence},
location = {Belo Horizonte, Brazil}
}

@article{10.1109/MCI.2020.3039068,
author = {Nguyen, Minh N.H. and Pandey, Shashi Raj and Thar, Kyi and Tran, Nguyen H. and Chen, Mingzhe and Saad Bradley, Walid and Hong, Choong Seon},
title = {Distributed and Democratized Learning: Philosophy and Research Challenges},
year = {2021},
issue_date = {Feb. 2021},
publisher = {IEEE Press},
volume = {16},
number = {1},
issn = {1556-603X},
url = {https://doi.org/10.1109/MCI.2020.3039068},
doi = {10.1109/MCI.2020.3039068},
abstract = {Due to the availability of huge amounts of data and processing abilities, current artificial intelligence (AI) systems are effective in solving complex tasks. However, despite the success of AI in different areas, the problem of designing AI systems that can truly mimic human cognitive capabilities such as artificial general intelligence, remains largely open. Consequently, many emerging cross-device AI applications will require a transition from traditional centralized learning systems towards large-scale distributed AI systems that can collaboratively perform multiple complex learning tasks. In this paper, we propose a novel design philosophy called democratized learning (Dem-AI) whose goal is to build large-scale distributed learning systems that rely on the self-organization of distributed learning agents that are wellconnected, but limited in learning capabilities. Correspondingly, inspired by the societal groups of humans, the specialized groups of learning agents in the proposed Dem-AI system are selforganized in a hierarchical structure to collectively perform learning tasks more efficiently. As such, the Dem-AI learning system can evolve and regulate itself based on the underlying duality of two processes which we call specialized and generalized processes. In this regard, we present a reference design as a guideline to realize future Dem-AI systems, inspired by various interdisciplinary fields. Accordingly, we introduce four underlying mechanisms in the design such as plasticity-stability transition mechanism, self-organizing hierarchical structuring, specialized learning, and generalization. Finally, we establish possible extensions and new challenges for the existing learning approaches to provide better scalable, flexible, and more powerful learning systems with the new setting of Dem-AI.},
journal = {Comp. Intell. Mag.},
month = {feb},
pages = {49–62},
numpages = {14}
}

@inproceedings{10.1007/978-3-030-77967-2_45,
author = {Przybyszewski, Andrzej W.},
title = {Theory of Mind Helps to Predict Neurodegenerative Processes in Parkinson’s Disease},
year = {2021},
isbn = {978-3-030-77966-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77967-2_45},
doi = {10.1007/978-3-030-77967-2_45},
abstract = {Normally, it takes many years of theoretical and clinical training for a physician to be the movement disorder specialist. It takes additional multiple years of the clinical practice to handle various “non-typical” cases. The purpose of our study was to predict neurodegenerative disease development by abstract rules learned from experienced neurologists. Theory of mind (ToM) is human’s ability to represent mental states such as emotions, intensions or knowledge of others. ToM is crucial not only in human social interactions but also is used by neurologists to find an optimal treatment for patients with neurodegenerative pathologies such as Parkinson’s disease (PD). On the basis of doctors’ expertise, we have used supervised learning to build AI system that consists of abstract granules representing ToM of several movement disorders neurologists (their knowledge and intuitions). We were looking for similarities between granules of patients in different disease stages to granules of more advanced PD patients. We have compared group of 23 PD with attributes measured three times every half of the year (G1V1, G1V2, G1V3) to other group of 24 more advanced PD (G2V1). By means of the supervised learning and rough set theory we have found rules describing symptoms of G2V1 and applied them to G1V1, G1V2, and G1V3. We have obtained the following accuracies for all/speed/emotion/cognition attributes: G1V1: 68/59/53/72%; G1V2: 72/70/79/79%; G1V3: 82/92/71/74%. These results support our hypothesis that divergent sets of granules were characteristic for different brain’s parts that might degenerate in non-uniform ways with Parkinson’s disease progression.},
booktitle = {Computational Science – ICCS 2021: 21st International Conference, Krakow, Poland, June 16–18, 2021, Proceedings, Part III},
pages = {542–555},
numpages = {14},
keywords = {Granular computing, Rough set, Rules, Cognition},
location = {Krakow, Poland}
}

@article{10.1016/j.compbiomed.2021.105111,
author = {Salahuddin, Zohaib and Woodruff, Henry C. and Chatterjee, Avishek and Lambin, Philippe},
title = {Transparency of deep neural networks for medical image analysis: A review of interpretability methods},
year = {2022},
issue_date = {Jan 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {140},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.105111},
doi = {10.1016/j.compbiomed.2021.105111},
journal = {Comput. Biol. Med.},
month = {jan},
numpages = {18},
keywords = {Explainable artificial intelligence, Medical imaging, Explainability, Interpretability, Deep neural networks}
}

@article{10.1016/j.chb.2022.107547,
author = {Lim, Lyn and Bannert, Maria and van der Graaf, Joep and Singh, Shaveen and Fan, Yizhou and Surendrannair, Surya and Rakovic, Mladen and Molenaar, Inge and Moore, Johanna and Ga\v{s}evi\'{c}, Dragan},
title = {Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning},
year = {2023},
issue_date = {Feb 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {139},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2022.107547},
doi = {10.1016/j.chb.2022.107547},
journal = {Comput. Hum. Behav.},
month = {feb},
numpages = {18},
keywords = {Self-regulated learning, Learning analytics, Personalized scaffolds, Adaptive support, Process mining, Trace data}
}

@inproceedings{10.1007/978-3-030-58796-3_10,
author = {Su\'{a}rez-Figueroa, Mari Carmen and Ruckhaus, Edna and L\'{o}pez-Guerrero, Jorge and Cano, Isabel and Cervera, \'{A}lvaro},
title = {Towards the Assessment of Easy-to-Read Guidelines Using Artificial Intelligence Techniques},
year = {2020},
isbn = {978-3-030-58795-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58796-3_10},
doi = {10.1007/978-3-030-58796-3_10},
abstract = {The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities, who have difficulties in reading comprehension. The main goal of the E2R Methodology is to present clear and easily understood documents. This methodology includes a set of guidelines and recommendations that affect the writing of texts, the supporting images, the design and layout of documents, and the final editing format. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. The process of adapting existing documents is cyclic and implies three activities: analysis, transformation, and validation. All these activities are human resource consuming, due to the need of involving people with cognitive disabilities as well as E2R experts. In order to alleviate such processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to perform the analysis and transformation of documents in a (semi)-automatic fashion. In this paper we present our AI-based method for assessing a particular document with respect to the E2R guidelines as well as an initial implementation of such a method; our research on the transformation of documents is out of the scope of this paper. We carried out a comparative evaluation of the results obtained by our initial implementation against the results of the document analysis performed by people with cognitive disabilities.},
booktitle = {Computers Helping People with Special Needs: 17th International Conference, ICCHP 2020, Lecco, Italy, September 9–11, 2020, Proceedings, Part I},
pages = {74–82},
numpages = {9},
keywords = {E2R methodology, Cognitive accessibility, Artificial intelligence},
location = {Lecco, Italy}
}

@inproceedings{10.1145/3514094.3534160,
author = {Cachel, Kathleen and Rundensteiner, Elke},
title = {FINS Auditing Framework: Group Fairness for Subset Selections},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534160},
doi = {10.1145/3514094.3534160},
abstract = {Subset selection is an integral component of AI systems that is increasingly affecting people's livelihoods in applications ranging from hiring, healthcare, education, to financial decisions. Subset selections powered by AI-based methods include top-k analytics, data summarization, clustering, and multi-winner voting. While group fairness auditing tools have been proposed for classification systems, these state-of-the-art tools are not directly applicable to measuring and conceptualizing fairness in selected subsets. In this work, we introduce the first comprehensive auditing framework, FINS, to support stakeholders in interpretably quantifying group fairness across a diverse range of subset-specific fairness concerns. FINS offers a family of novel measures that provide a flexible means to audit group fairness for fairness goals ranging from item-based, score-based, and a combination thereof. FINS provides one unified easy-to-understand interpretation across these different fairness problems. Further, we develop guidelines through the FINS Fair Subset Chart, that supports auditors in determining which measures are relevant to their problem context and fairness objectives. We provide a comprehensive mapping between each fairness measure and the belief system (i.e., worldview) that is encoded within its measurement of fairness. Lastly, we demonstrate the interpretability and efficacy of FINS in supporting the identification of real bias with case studies using AirBnB listings and voter records.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {144–155},
numpages = {12},
keywords = {algorithmic fairness, machine learning fairness, subset selection},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@inproceedings{10.1145/3375627.3377139,
author = {Gurumurthy, Anita},
title = {The AI-development Connection - A View from the South},
year = {2020},
isbn = {9781450371100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375627.3377139},
doi = {10.1145/3375627.3377139},
abstract = {The socialisation of Artificial Intelligence and the reality of an intelligence economy mark an epochal moment. The impacts of AI are now systemic - restructuring economic organisation and value chains, public sphere architectures and sociality. These shifts carry deep geo-political implications, reinforcing historical exclusions and power relations and disrupting the norms and rules that hold ideas of equality and justice together.At the centre of this rapid change is the intelligent corporation and its obsessive pursuit of data. Directly impinging on bodies and places, the de facto rules forged by the intelligent corporation are disenfranchising the already marginal subjects of development. Using trade deals to liberalise data flows, tighten trade secret rules and enclose AI-based innovation, Big Tech and their political masters have effectively taken away the economic and political autonomy of states in the global south. Big Tech's impunity extends to a brazen exploitation - enslaving labour through data over-reach and violating female bodies to universalise data markets. Thinking through the governance of AI needs new frameworks that can grapple with the fraught questions of data sovereignty, economic democracy, and institutional ethics in a global world with local aspirations. Any effort towards norm development in this domain will need to see the geo-economics of digital intelligence and the geo-politics of development ideologies as two sides of the same coin.},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
pages = {3},
numpages = {1},
keywords = {digital intelligence, geo-politics of development, intelligent corporation},
location = {New York, NY, USA},
series = {AIES '20}
}

@inproceedings{10.1007/978-3-030-63885-6_33,
author = {Lee, Tony Szu-Hsien and Liu, Shiang-Yao and Wei, Yin-Ling and Chang, Li-Yun},
title = {A Comparative Study on Ethics Guidelines for Artificial Intelligence Across Nations},
year = {2020},
isbn = {978-3-030-63884-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63885-6_33},
doi = {10.1007/978-3-030-63885-6_33},
abstract = {This study aimed to investigate the commonality and differences among AI research and development (R&amp;D) guidelines across nations. Content analysis was conducted on AI R&amp;D guidelines issued by more economically developed countries because they may guide the trend of AI-based applications in education. Specifically, this study consisted of three phases: 1) information retrieval, (2) key term extraction, and (3) data visualization. First, Fisher’s exact test was employed to ensure that different AI R&amp;D guidelines (e.g., the latest ones in the US, EU, Japan, Mainland, and Taiwan) were comparable. Second, the Key Word Extraction System was developed to retrieve essential information in the guidelines. Third, data visualization techniques were performed on key terms across multiple guidelines. A word cloud revealed the similarity among guidelines (e.g., key terms that these guidelines share in common) while a color-coding scheme showed the differences (e.g., occurrence of a key term across guidelines and its frequency within a guideline). Importantly, three key terms, namely, AI, human, and development, are identified as essential commonality across guidelines. As for key terms that only extracted from particular guidelines, interestingly, results with the color-coding scheme suggested that these key terms were weighted differently depends on the developmental emphasis of a nation. Collectively, we discussed how these findings concerning ethics guidelines may shed light on AI research and development to educational technology.},
booktitle = {Innovative Technologies and Learning: Third International Conference, ICITL 2020, Porto, Portugal, November 23–25, 2020, Proceedings},
pages = {289–295},
numpages = {7},
keywords = {Artificial intelligence, Data visualization technique, Education, Ethics guidelines, Text mining},
location = {Porto, Portugal}
}

@inproceedings{10.1007/978-3-031-16902-1_8,
author = {Puyol-Ant\'{o}n, Esther and Ruijsink, Bram and Sidhu, Baldeep S. and Gould, Justin and Porter, Bradley and Elliott, Mark K. and Mehta, Vishal and Gu, Haotian and Rinaldi, Christopher A. and cowie, Martin and Chowienczyk, Phil and Razavi, Reza and King, Andrew P.},
title = {AI-Enabled Assessment of&nbsp;Cardiac Systolic and&nbsp;Diastolic Function from&nbsp;Echocardiography},
year = {2022},
isbn = {978-3-031-16901-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-16902-1_8},
doi = {10.1007/978-3-031-16902-1_8},
abstract = {Left ventricular (LV) function is an important factor in terms of patient management, outcome, and long-term survival of patients with heart disease. The most recently published clinical guidelines for heart failure recognise that over reliance on only one measure of cardiac function (LV ejection fraction) as a diagnostic and treatment stratification biomarker is suboptimal. Recent advances in AI-based echocardiography analysis have shown excellent results on automated estimation of LV volumes and LV ejection fraction. However, from time-varying 2-D echocardiography acquisition, a richer description of cardiac function can be obtained by estimating functional biomarkers from the complete cardiac cycle. In this work we propose for the first time an AI approach for deriving advanced biomarkers of systolic and diastolic LV function from 2-D echocardiography based on segmentations of the full cardiac cycle. These biomarkers will allow clinicians to obtain a much richer picture of the heart in health and disease. The AI model is based on the ’nn-Unet’ framework and was trained and tested using four different databases. Results show excellent agreement between manual and automated analysis and showcase the potential of the advanced systolic and diastolic biomarkers for patient stratification. Finally, for a subset of 50 cases, we perform a correlation analysis between clinical biomarkers derived from echocardiography and cardiac magnetic resonance and we show a very strong relationship between the two modalities.},
booktitle = {Simplifying Medical Ultrasound: Third International Workshop, ASMUS 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings},
pages = {75–85},
numpages = {11},
keywords = {Echocardiography, Image segmentation, Cardiac function, Deep learning},
location = {Singapore, Singapore}
}

@article{10.1016/j.knosys.2022.108410,
author = {Yang, Long-Hao and Ren, Tian-Yu and Ye, Fei-Fei and Nicholl, Peter and Wang, Ying-Ming and Lu, Haitian},
title = {An ensemble extended belief rule base decision model for imbalanced classification problems},
year = {2022},
issue_date = {Apr 2022},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {242},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2022.108410},
doi = {10.1016/j.knosys.2022.108410},
journal = {Know.-Based Syst.},
month = {apr},
numpages = {15},
keywords = {Belief rule base, Imbalanced classification, Diversity, Inconsistency, Oversampling}
}

@article{10.1007/s11554-021-01070-6,
author = {Saponara, Sergio and Elhanashi, Abdussalam and Gagliardi, Alessio},
title = {Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-021-01070-6},
doi = {10.1007/s11554-021-01070-6},
abstract = {COVID-19 is a disease caused by a severe respiratory syndrome coronavirus. It was identified in December 2019 in Wuhan, China. It has resulted in an ongoing pandemic that caused infected cases including many deaths. Coronavirus is primarily spread between people during close contact. Motivating to this notion, this research proposes an artificial intelligence system for social distancing classification of persons using thermal images. By exploiting YOLOv2 (you look at once) approach, a novel deep learning detection technique is developed for detecting and tracking people in indoor and outdoor scenarios. An algorithm is also implemented for measuring and classifying the distance between persons and to automatically check if social distancing rules are respected or not. Hence, this work aims at minimizing the spread of the COVID-19 virus by evaluating if and how persons comply with social distancing rules. The proposed approach is applied to images acquired through thermal cameras, to establish a complete AI system for people tracking, social distancing classification, and body temperature monitoring. The training phase is done with two datasets captured from different thermal cameras. Ground Truth Labeler app is used for labeling the persons in the images. The proposed technique has been deployed in a low-cost embedded system (Jetson Nano) which is composed of a fixed camera. The proposed approach is implemented in a distributed surveillance video system to visualize people from several cameras in one centralized monitoring system. The achieved results show that the proposed method is suitable to set up a surveillance system in smart cities for people detection, social distancing classification, and body temperature analysis.},
journal = {J. Real-Time Image Process.},
month = {dec},
pages = {1937–1947},
numpages = {11},
keywords = {COVID-19, Neural network, Social distancing, Temperature analysis, Jetson nano, Distributed surveillance system}
}

@article{10.1016/j.compbiomed.2023.107441,
author = {Seoni, Silvia and Jahmunah, Vicnesh and Salvi, Massimo and Barua, Prabal Datta and Molinari, Filippo and Acharya, U. Rajendra},
title = {Application of uncertainty quantification to artificial intelligence in healthcare: A review of last decade (2013–2023)},
year = {2023},
issue_date = {Oct 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {165},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2023.107441},
doi = {10.1016/j.compbiomed.2023.107441},
journal = {Comput. Biol. Med.},
month = {oct},
numpages = {28},
keywords = {Uncertainty techniques, Machine learning models, Deep learning models, PRISMA, Images, Signals, Healthcare, Bayesian models}
}

@phdthesis{10.5555/AAI28869363,
author = {Banian, Sara and Raymond, Fu, Yun and Sarah, Ostadabbas,},
advisor = {Casper, Harteveld, and Magy, Seif El-Nasr,},
title = {Content-Aware AI-Driven Design Assistance Frameworks for Graphic Design Layouts},
year = {2021},
isbn = {9798762103787},
publisher = {Northeastern University},
address = {USA},
abstract = {Designing user interfaces (UIs) for mobile interaction is widespread but still challenging. It is important for the overall user satisfaction and application success. During the design process, designers express their requirements through images describing the UI's layout, structure, and content. Designers, however, encounter key challenges throughout the design process. For example, searching for inspiring design examples is challenging because current search systems rely on only text-based queries and do not consider the UI structure and content. Furthermore, these systems often focus on overall page-level layout over individual UI components. Also, creating wireframe templates is difficult for many designers as it necessitates an understanding of different design guidelines. Therefore, it is critical to support designers by developing effective design tools to help them be more productive and creative.In this dissertation, I aim to explore how to develop design assistance methodologies to augment the process of UI layout design, with a particular focus on visual search and layout generation. Specifically, for this exploration, I seek to investigate the use of advanced deep learning models in the context of mobile UI layout design. Processing layouts differs from processing pixel-level images in that it necessitates processing both the semantic (e.g., labels) and spatial (e.g., coordinates) content of the layout to model the data properly. To achieve this, I explore the design problems from both the data and the model side. First, I present a large-scale UI dataset that accurately specifies the interface's view hierarchy (i.e., UI components and their location). Second, I contribute the VINS framework, which is composed of three systems LayVis, CompVis, and TransVis that addresses layout-based visual search, component-based visual search, and layout generation, respectively.First, I introduce LayVis, an object-detection layout-based retrieval model. It takes as input a UI image and retrieves visually similar design examples. Next, I introduce CompVis, a component-based visual search system to easily retrieve individual UI components via convolutional neural networks (CNNs). Specifically, for a given query, the system allows to retrieve (1) text label synonyms, (2) similar UI components, and (3) design examples containing such components. Finally, I present TransVis, a transformer-based generative framework that investigate how to generate UI layouts according to user specifications and following design practices. It specifically models UI layouts as an ordered sequence of elements based on spatial and semantic relationships for (1) generating complete UI layouts, (2) auto-completing existing UI layouts seamlessly, and (3) supporting many design elements per layout.Overall, the work presented in this dissertation contributes to augmenting the UI layout design. Through quantitative and qualitative evaluation of VINS, we conclude the following: (1) Advanced deep learning models can aid in the development of design assistance methodologies for layout design; and (2) Designers perceive the use of VINS inspiring and useful. Such insights, combined with the open-sourced large-scale dataset, can help the research community develop more effective AI-based data-driven design tools. This work presents future opportunities to investigate different deep learning models within the context of layout design and how designers interact with these AI-based models.},
note = {AAI28869363}
}

@inproceedings{10.1007/978-3-031-34017-8_14,
author = {Laarhoven, Thijs and Ponukumati, Aditya},
title = {Towards Transparent Cheat Detection in&nbsp;Online Chess: An Application of&nbsp;Human and&nbsp;Computer Decision-Making Preferences},
year = {2023},
isbn = {978-3-031-34016-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-34017-8_14},
doi = {10.1007/978-3-031-34017-8_14},
abstract = {Online game providers face the challenge of preventing malicious users (cheaters) from breaking the rules and winning games through illegal means. This issue in particular plagues the online chess scene, where the strongest algorithms have long surpassed the world’s best players&nbsp;[4] – any cheater can beat the best human players through computer assistance. Moreover, recent developments in AI-based chess engines have opened the door to even more human-like engines&nbsp;[33], which are increasingly able to mimic legitimate human players. Unfortunately, because major chess websites do not discuss their cheat detection mechanisms publicly, there is limited scientific literature on how to tackle the pervasive problem of cheating in online chess. Certainly, there is no way to validate whether these mechanisms actually work.We take a first step towards formalizing a proper cheat detection framework for online chess by leveraging a large-scale statistical examination of human and computer decision-making tendencies over millions of chess games played online. Although cheaters are not engines (computer players) but centaurs (computer-assisted human players), the insights into computer play serve as a useful guideline for finding the strongest indicators of cheating. We then demonstrate how these findings may distinguish legitimate human players from cheaters in an automated, rules-based manner. Additionally, we argue that the status quo of hiding cheat detection mechanisms from the public eye is dangerous to the integrity of the game, and that cheat detection is foremost a service to society instead of a competitive advantage for chess websites to attract more users. Consistent with Kerckhoffs’ paradigm&nbsp;[24], we believe that the benefits of an open discussion on cheat detection far outweigh the potential drawbacks of cheaters learning about these methods.},
booktitle = {Computers and Games: International Conference, CG 2022, Virtual Event, November 22–24, 2022, Revised Selected Papers},
pages = {163–180},
numpages = {18},
keywords = {chess, cheat detection, decision-making}
}

@article{10.1109/TSE.2021.3106280,
author = {Hoda, Rashina},
title = {Socio-Technical Grounded Theory for Software Engineering},
year = {2022},
issue_date = {Oct. 2022},
publisher = {IEEE Press},
volume = {48},
number = {10},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2021.3106280},
doi = {10.1109/TSE.2021.3106280},
abstract = {Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents &lt;italic&gt;Socio-Technical Grounded Theory&lt;/italic&gt; (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.},
journal = {IEEE Trans. Softw. Eng.},
month = {oct},
pages = {3808–3832},
numpages = {25}
}

@article{10.1016/j.ijhcs.2022.102941,
author = {Naiseh, Mohammad and Al-Thani, Dena and Jiang, Nan and Ali, Raian},
title = {How the different explanation classes impact trust calibration: The case of clinical decision support systems},
year = {2023},
issue_date = {Jan 2023},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {169},
number = {C},
issn = {1071-5819},
url = {https://doi.org/10.1016/j.ijhcs.2022.102941},
doi = {10.1016/j.ijhcs.2022.102941},
journal = {Int. J. Hum.-Comput. Stud.},
month = {jan},
numpages = {17},
keywords = {Explainable AI, Clinical decision support systems, Human-AI Interaction, Trust Calibration}
}

@article{10.1007/s10207-023-00729-4,
author = {Farhat, Saida and Abdelkader, Manel and Meddeb-Makhlouf, Amel and Zarai, Faouzi},
title = {CADS-ML/DL: efficient cloud-based multi-attack detection system},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1615-5262},
url = {https://doi.org/10.1007/s10207-023-00729-4},
doi = {10.1007/s10207-023-00729-4},
abstract = {With the increasing adoption of cloud computing, securing cloud-based systems and applications has become a critical concern for almost every organization. Traditional security approaches such as signature-based and rule-based have limited detection capabilities toward new and sophisticated attacks. To address this issue, there has been an increasing focus on implementing Artificial Intelligence (AI) in cloud security measures. In this research article, we present CADS-ML/DL, an efficient cloud-based multi-attack detection system. We investigate the effectiveness of Machine Learning (ML) and Deep Learning (DL) techniques for detecting cloud attacks. Our approach leverages a realistic dataset consisting of both benign and fourteen common attack network flows that meet real-world criteria on the AWS cloud platform. We evaluate eight Intrusion Detection Systems (IDSs) based on ML and DL algorithms, including Decision Tree (DT), Random Forest (RF), Extreme Gradient Boosting (XGBoost), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), Stacked LSTM, and Bidirectional LSTM (Bi-LSTM) models. Experimental results demonstrate that the CADS-ML/DL system, specifically the XGBoost model, outperforms the other models, exhibiting an accuracy of 0.9770 and a false error rate of 0.0230. Furthermore, we validate the effectiveness of our proposed XGBoost model on the AWS benchmark CSE-CICIDS2018 dataset, attaining a remarkable accuracy score of 0.9999 and an exceptionally low false error rate of 0.0001. Our findings suggest that AI-based approaches have the potential to detect cloud attacks effectively and contribute to the development of reliable and efficient IDSs for cloud security.},
journal = {Int. J. Inf. Secur.},
month = {jul},
pages = {1989–2013},
numpages = {25},
keywords = {Cloud computing, CICFlowMeter, Machine learning (ML), Deep learning (DL), Multi-attack detection system, CSE-CICIDS2018}
}

@article{10.1007/s11277-021-08403-5,
author = {Setiawan, Roy and Ganga, Ramakoteswara Rao and Velayutham, Priya and Thangavel, Kumaravel and Sharma, Dilip Kumar and Rajan, Regin and Krishnamoorthy, Sujatha and Sengan, Sudhakar},
title = {Encrypted Network Traffic Classification and Resource Allocation with Deep Learning in Software Defined Network},
year = {2021},
issue_date = {Nov 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {127},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08403-5},
doi = {10.1007/s11277-021-08403-5},
abstract = {The climate has changed absolutely in every area in just a few years as digitized, making high-speed internet service a significant need in the future. Future Internet is supposed to face exponential growth in traffic, and highly complicated infrastructure, threatening to make conventional NTC approaches unreliable and even counterproductive. In recent days, AI Stimulated state-of-the-art breakthroughs with the ability to tackle extensive and multifarious challenges, and the network community is initiated by considering the NTC prototype from legacy rule-based towards a novel AI-based. Design and execution are applied to interdisciplinary become more essential. A smart home network supports various applications and smart devices within the proposed work, including e-health devices, regular computing devices, and home automation devices. Many devices accessible through the Internet by Home GateWay for Congestion (HGC) in a smart home. Throughout this paper, a Software-Defined Network Home GateWay for Congestion (SDNHGC) architecture for improved management of remote smart home networks and protection of the significant network's SDN controller. It enables effective network capacity regulation, focused on real-time traffic analysis and core network resource allocation. It cannot control the Network in dispersed smart homes. Our innovative SDNHGC expands power across the connectivity network, a smart home network enabling improved end-to-end monitoring of networks. The planned SDNHGC directly will gain centralized device identification by classifying traffic through a smart home network. Several of the current traffic classifications approach, checking deep packets, cannot have this real-time device knowledge for encrypted data to solve this issue.},
journal = {Wirel. Pers. Commun.},
month = {mar},
pages = {749–765},
numpages = {17},
keywords = {Software-defined network, Traffic detection, Security, Deep learning, Data flow}
}

@inproceedings{10.1145/3526073.3527593,
author = {Rahman, Md Saidur and Khomh, Foutse and Rivera, Emilio and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Lehnert, Bernd},
title = {Challenges in machine learning application development: an industrial experience report},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527593},
doi = {10.1145/3526073.3527593},
abstract = {SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers' feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {21–28},
numpages = {8},
keywords = {challenges and best practices, error detection and correction, software engineering for machine learning},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@article{10.1016/j.future.2022.12.017,
author = {Eun, Sung-Jong and Kim, Eun Joung and Kim, JungYoon},
title = {Artificial intelligence-based personalized serious game for enhancing the physical and cognitive abilities of the elderly},
year = {2023},
issue_date = {Apr 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {141},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2022.12.017},
doi = {10.1016/j.future.2022.12.017},
journal = {Future Gener. Comput. Syst.},
month = {apr},
pages = {713–722},
numpages = {10},
keywords = {Digital healthcare, Game design, Serious game, Artificial intelligence (AI), Difficulty level adjustment, Relative scoring}
}

@inproceedings{10.1007/978-3-030-58796-3_30,
author = {de Filippis, Maria Laura and Federici, Stefano and Mele, Maria Laura and Borsci, Simone and Bracalenti, Marco and Gaudino, Giancarlo and Cocco, Antonello and Amendola, Massimo and Simonetti, Emilio},
title = {Preliminary Results of a Systematic Review: Quality Assessment of Conversational Agents (Chatbots) for People with Disabilities or Special Needs},
year = {2020},
isbn = {978-3-030-58795-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58796-3_30},
doi = {10.1007/978-3-030-58796-3_30},
abstract = {People with disabilities or special needs can benefit from AI-based conversational agents, which are used in competence training and well-being management. Assessment of the quality of interactions with these chatbots is key to being able to reduce dissatisfaction with them and to understand their potential long-term benefits. This will in turn help to increase adherence to their use, thereby improving the quality of life of the large population of end-users that they are able to serve. We systematically reviewed the literature on methods of assessing the perceived quality of interactions with chatbots, and identified only 15 of 192 papers on this topic that included people with disabilities or special needs in their assessments. The results also highlighted the lack of a shared theoretical framework for assessing the perceived quality of interactions with chatbots. Systematic procedures based on reliable and valid methodologies continue to be needed in this field. The current lack of reliable tools and systematic methods for assessing chatbots for people with disabilities and special needs is concerning, and may lead to unreliable systems entering the market with disruptive consequences for users. Three major conclusions can be drawn from this systematic analysis: (i) researchers should adopt consolidated and comparable methodologies to rule out risks in use; (ii) the constructs of satisfaction and acceptability are different, and should be measured separately; (iii) dedicated tools and methods for assessing the quality of interaction with chatbots should be developed and used to enable the generation of comparable evidence.},
booktitle = {Computers Helping People with Special Needs: 17th International Conference, ICCHP 2020, Lecco, Italy, September 9–11, 2020, Proceedings, Part I},
pages = {250–257},
numpages = {8},
keywords = {Chatbots, Conversational agents, People with disability, People with special needs, Usability, Quality of interaction},
location = {Lecco, Italy}
}

@article{10.1016/j.compbiomed.2021.104660,
author = {Saheb, Tahereh and Saheb, Tayebeh and Carpenter, David O.},
title = {Mapping research strands of ethics of artificial intelligence in healthcare: A bibliometric and content analysis},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104660},
doi = {10.1016/j.compbiomed.2021.104660},
journal = {Comput. Biol. Med.},
month = {aug},
numpages = {19},
keywords = {Artificial intelligence, Healthcare, Robotics, Bibliometric analysis, Content analysis, Network visualization, Ethics}
}

@article{10.1145/3475870,
author = {Jiang, Yizhang and Gu, Xiaoqing and Hua, Lei and Li, Kang and Tao, Yuwen and Li, Bo},
title = {Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted TSK Fuzzy System},
year = {2021},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/3475870},
doi = {10.1145/3475870},
abstract = {Artificial intelligence– (AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ε-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {64},
numpages = {24},
keywords = {Fog/edge computing, multi-tasking learning, TSK fuzzy system, multi-task weighted fuzzy c-means clustering, COVID-19}
}

@inproceedings{10.1007/978-3-030-69781-5_8,
author = {Chandramouli, Krishna and Izquierdo, Ebroul},
title = {An Advanced Framework for Critical Infrastructure Protection Using Computer Vision Technologies},
year = {2020},
isbn = {978-3-030-69780-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-69781-5_8},
doi = {10.1007/978-3-030-69781-5_8},
abstract = {Over the past decade, there has been unprecedented advancements in the field of computer vision by adopting AI-based solutions. In particular, cutting edge computer vision technology based on deep-learning approaches has been deployed with an extraordinary degree of success. The ability to extract semantic concepts from continuous processing of video stream in real-time has led to the investigation of such solutions to enhance the operational security of critical infrastructure against intruders. Despite the success of computer vision technologies validated in a laboratory environment, there still exists several challenges that limit the deployment of these solutions in operational environment. Addressing these challenges, the paper presents a framework that integrates three main computer vision technologies namely (i) person detection; (ii) person re-identification and (iii) face recognition to enhance the operational security of critical infrastructure perimeter. The novelty of the proposed framework relies on the integration of key technical innovations that satisfies the operational requirements of critical infrastructure in using computer vision technologies. One such requirement relates to data privacy and citizen rights, following the implementation of General Data Protection Regulation across Europe for the successful adoption of video surveillance for infrastructure security. The video analytics solution proposed in the paper integrates privacy preserving technologies, high-level rule engine for threat identification and a knowledge model for escalating threat categorises to human operator. The various components of the proposed framework has been validated using commercially available graphical processing units for detecting intruders. The performance o the proposed framework has been evaluated in operational environments of the critical infrastructure. An overall accuracy of 97% is observed in generating alerts against malicious intruders.},
booktitle = {Cyber-Physical Security for Critical Infrastructures Protection: First International Workshop, CPS4CIP 2020, Guildford, UK, September 18,  2020, Revised Selected Papers},
pages = {107–122},
numpages = {16},
keywords = {Person detection, Person re-identification (RE-ID), Intrusion detection, Face recognition, Region based Fully Connected Network (RFCN), Un-supervised clustering, Knowledge model, Privacy preserving technologies},
location = {Guildford, United Kingdom}
}

@article{10.1016/j.infsof.2023.107197,
author = {Balasubramaniam, Nagadivya and Kauppinen, Marjo and Rannisto, Antti and Hiekkanen, Kari and Kujala, Sari},
title = {Transparency and explainability of AI systems: From ethical guidelines to requirements},
year = {2023},
issue_date = {Jul 2023},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {159},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2023.107197},
doi = {10.1016/j.infsof.2023.107197},
journal = {Inf. Softw. Technol.},
month = {jul},
numpages = {15},
keywords = {Transparency, Explainability, Ethical guidelines, Quality requirements, Explainability requirements, AI systems}
}

@article{10.1155/2021/8686469,
author = {Alomari, Mohammad Kamel and Khan, Habib Ullah and Khan, Sulaiman and Al-Maadid, Alanoud Ali and Abu-Shawish, Zaki Khalid and Hammami, Helmi and Chaudhry, Shehzad Ashraf},
title = {Systematic Analysis of Artificial Intelligence-Based Platforms for Identifying Governance and Access Control},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/8686469},
doi = {10.1155/2021/8686469},
abstract = {Artificial intelligence (AI) has become omnipotent with its variety of applications and advantages. Considering the other side of the coin, the eruption of technology has created situations that need more caution about the safety and security of data and systems at all levels. Thus, to hedge against the growing threats of cybersecurity, the need for a robust AI platform supported by machine learning and other supportive technologies is well recognized by organizations. AI is a much sought-after topic, and there is extolling literature available in repositories. Hence, a systematic arrangement of the literature that can help identify the right AI platform that can provide identity governance and access control is the need of the hour. Having this background, the present study is commissioned a Systematic Literature Review (SLR) to accomplish the necessity. Literature related to AI and Identity and Access Management (IAM) is collected from renowned peer-reviewed digital libraries for systematic analysis and assessment purposes using the systematic review guidelines. Thus, the final list of articles relevant to the framed research questions related to the study topic is fetched and is reviewed thoroughly. For the proposed systematic research work, the literature reported during the period ranging from 2016 to 2021 (a portion of 2021 is included) is analyzed and a total of 43 papers were depicted more relevant to the selected research domain. These articles were accumulated from ProQuest, Scopus, Taylor &amp; Franics, Science Direct, and Wiley online repositories. The article's contribution can supplement the AI-based IAM information and steer the entities of diverse sectors concerning seamless implementation. Appropriate suggestions are proposed to encourage research work in the required fields.},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {10}
}

@article{10.1155/2022/1703696,
author = {Faritha Banu, J. and Neelakandan, S. and Geetha, B.T and Selvalakshmi, V. and Umadevi, A. and Martinson, Eric Ofori and Sharma, Kapil},
title = {Artificial Intelligence Based Customer Churn Prediction Model for Business Markets},
year = {2022},
issue_date = {2022},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2022},
issn = {1687-5265},
url = {https://doi.org/10.1155/2022/1703696},
doi = {10.1155/2022/1703696},
abstract = {The introduction of artificial intelligence (AI) and machine learning (ML) technologies in recent years has resulted in improved company performance. Customer churn forecast is a difficult problem in many corporate sectors, particularly the telecommunications industry. Because customer churns have a direct impact on a company's total revenue, telecommunications firms have begun to develop 76 models to reduce churns at an earlier stage. Previous research has revealed that AI and ML models are effective CCP solutions. According to this viewpoint, this study proposes a unique AI-based CCP model for Telecommunication Business Markets (AICCP-TBM). The AICCP-TBM model's purpose is to control the existence of churners and non-churners in the telecom sector. The proposed AICCP-TBM model employs a Chaotic Salp Swarm Optimization-based Feature Selection (CSSO-FS) method for the best feature assortment. In addition, a Fuzzy Rule-based Classifier(FRC) is used to distinguish between client churners and non-churners. A technique known as Quantum Behaved Particle Swarm Optimization (QPSO) is used to pick the membership functions for the FRC model in order to improve the classification performance of the FRC model. The performance of the AICCP-TBM model is validated using a benchmark CCP dataset and the experimental results are reviewed from several angles. In relations of presentation, the imitation consequences demonstrated that the AICCP-TBM model surpassed the most recent state-of-the-art CPP models. The suggested AICCP-TBM method's comparative accuracy was thoroughly tested on the three datasets used. Using datasets 1-3, this technique obtained better levels of accuracy, with the maximum attainable values being 97.25 %, 97.5 % and 94.33 %. The simulation results for the AICCP-TBM model demonstrated improved prediction performance.},
journal = {Intell. Neuroscience},
month = {jan},
numpages = {14}
}

@article{10.1007/s00146-022-01478-z,
author = {Ramanayake, Rajitha and Wicke, Philipp and Nallur, Vivek},
title = {Immune moral models? Pro-social rule breaking as a moral enhancement approach for ethical AI},
year = {2022},
issue_date = {Apr 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {2},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-022-01478-z},
doi = {10.1007/s00146-022-01478-z},
abstract = {We are moving towards a future where Artificial Intelligence (AI) based agents make many decisions on behalf of humans. From healthcare decision-making to social media censoring, these agents face problems, and make decisions with ethical and societal implications. Ethical behaviour is a critical characteristic that we would like in a human-centric AI. A common observation in human-centric industries, like the service industry and healthcare, is that their professionals tend to break rules, if necessary, for pro-social reasons. This behaviour among humans is defined as pro-social rule breaking. To make AI agents more human-centric, we argue that there is a need for a mechanism that helps AI agents identify when to break rules set by their designers. To understand when AI agents need to break rules, we examine the conditions under which humans break rules for pro-social reasons. In this paper, we present a study that introduces a ‘vaccination strategy dilemma’ to human participants and analyzes their response. In this dilemma, one needs to decide whether they would distribute COVID-19 vaccines only to members of a high-risk group (follow the enforced rule) or, in selected cases, administer the vaccine to a few social influencers (break the rule), which might yield an overall greater benefit to society. The results of the empirical study suggest a relationship between stakeholder utilities and pro-social rule breaking (PSRB), which neither deontological nor utilitarian ethics completely explain. Finally, the paper discusses the design characteristics of an ethical agent capable of PSRB and the future research directions on PSRB in the AI realm. We hope that this will inform the design of future AI agents, and their decision-making behaviour.},
journal = {AI Soc.},
month = {may},
pages = {801–813},
numpages = {13},
keywords = {Machine ethics, Pro-social rule breaking, Pro-social behaviour, Artificial Intelligence}
}

@inproceedings{10.1145/3611643.3613882,
author = {Laaber, Christoph and Yue, Tao and Ali, Shaukat and Schwitalla, Thomas and Nyg\r{a}rd, Jan},
title = {Automated Test Generation for Medical Rules Web Services: A Case Study at the Cancer Registry of Norway},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613882},
doi = {10.1145/3611643.3613882},
abstract = {The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN’s practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN’s software system. In particular, we focus on GURI, CRN’s medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster’s black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI’s code. Concerning domain-specific coverage, EvoMaster’s black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster’s black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1937–1948},
numpages = {12},
keywords = {REST APIs, automated software testing, cancer registry, electronic health records, rule engine, test generation},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1007/978-3-031-20627-6_17,
author = {Guo, Long Yin and Xia, Lin and Huang, Xin Yi and Fu, Yu Xin and Li, Xin Yi and Zhou, Si Chen and Zhao, Chao and Yang, Bing Xiang},
title = {The Construction and Validation of an Automatic Crisis Balance Analysis Model},
year = {2022},
isbn = {978-3-031-20626-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20627-6_17},
doi = {10.1007/978-3-031-20627-6_17},
abstract = {Background: With the development of Internet, many people with suicide risk tend to express their thoughts on social media platforms. AI-based model can early identify social media users with suicide risk and analyze their cognitive and interpersonal characteristics. Then we can do early intervention to help them.Objective: To build an automatic crisis balance analysis model based on artificial intelligence which can perform automatic early suicide identification, suicide risk classification and analyze cognitive distortion and interpersonal relationship of users. Then to validate the predictive efficiency of model.Method: Firstly, based on the suicide knowledge graph, free annotation data set was generated and then Bert-based model was built. Secondly, the data set was refined by psychology students and experts to build fine-tuning model and Psychology+ model. The Psychology+ model was used as final suicide risk assessment model. We enriched and quantified the variables of cognitive and interpersonal characteristics and built the cognitive distortion and interpersonal relationship analysis model. Using F1 score, precision, recall and accuracy to evaluate the model performance and the consistence of model results with expert judgment and scales results to evaluate the model prediction ability.Results: For the suicide risk assessment model, the F1 score, precision, recall rate and accuracy rate of the model are 77.98%, 80.75%, 75.41% and 78.68% respectively. For the cognitive distortion and interpersonal relationship analysis model, the F1 score, accuracy and recall rate of the model are 77.26%, 78.22% and 76.33% respectively. Comparing the results with the results of the scale by chi square test, there was no significant difference in cognitive distortion(P = 0.521) and interpersonal relationship(P = 0.189) aspect.Conclusion: The model showed good performance and can be used as a guideline and evaluation tool for intervention.},
booktitle = {Health Information Science: 11th International Conference, HIS 2022, Virtual Event, October 28–30, 2022, Proceedings},
pages = {177–188},
numpages = {12},
keywords = {Suicide, Artificial intelligence, Social media, Model validation}
}

@inproceedings{10.1145/3292500.3332281,
author = {Gade, Krishna and Geyik, Sahin Cem and Kenthapadi, Krishnaram and Mithal, Varun and Taly, Ankur},
title = {Explainable AI in Industry},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3332281},
doi = {10.1145/3292500.3332281},
abstract = {Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling.As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks.In this tutorial, we will present an overview of model interpretability and explainability in AI, key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3203–3204},
numpages = {2},
keywords = {explainable ai, industry case studies, ml model transparency and interpretability},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1007/s10462-023-10415-5,
author = {El-Sappagh, Shaker and Alonso-Moral, Jose M. and Abuhmed, Tamer and Ali, Farman and Bugar\'{\i}n-Diz, Alberto},
title = {Trustworthy artificial intelligence in Alzheimer’s disease: state of the art, opportunities, and challenges},
year = {2023},
issue_date = {Oct 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {10},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-023-10415-5},
doi = {10.1007/s10462-023-10415-5},
abstract = {Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017–2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer’s Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain.},
journal = {Artif. Intell. Rev.},
month = {mar},
pages = {11149–11296},
numpages = {148},
keywords = {Trustworthy AI, AI for Alzheimer’s disease diagnosis and progression detection, Machine learning in medicine, Responsible AI, Fairness, accountability, and transparency in AI}
}

@article{10.1016/j.cageo.2022.105281,
author = {Jacinto, Marcos V.G. and Doria Neto, Adri\~{a}o D. and de Castro, David L. and Bezerra, Francisco H.R.},
title = {Karstified zone interpretation using deep learning algorithms: Convolutional neural networks applications and model interpretability with explainable AI},
year = {2023},
issue_date = {Feb 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2022.105281},
doi = {10.1016/j.cageo.2022.105281},
journal = {Comput. Geosci.},
month = {feb},
numpages = {18},
keywords = {Ground penetrating radar, Karstified zones, Deep learning, Explainable AI}
}

@proceedings{10.1145/3194085,
title = {SEFAIS '18: Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems},
year = {2018},
isbn = {9781450357395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Autonomous systems have been a subject of computer science research for many years. Recent advances in hardware and in artificial intelligence have brought autonomous systems within the reach of product development. For example, most major carmakers are working on autonomous driving.During the early years of autonomous systems research, the focus has been on making autonomous functionality possible in the first place. As we move closer to building end-user products, software engineering concerns are becoming at least equally important. Most conventional embedded software products are built on rule-based control engineering approaches. The corresponding software engineering practices are mature and well understood. For autonomous systems, however, the conventional control engineering approaches are extended by modern artificial intelligence techniques, in particular, machine learning. The corresponding product software engineering approaches are less well understood and need attention.The 2018 ACM/IEEE 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS 2018) focuses on software engineering and software architecture approaches that achieve the usual software engineering goals, such as quality, maintainability, scalability, robustness, safety, etc., for systems that are built using a combination of conventional embedded software development and AI. Since many of the relevant techniques are just about to move from the research stage to the product development stage, many of the software engineering ideas and approaches will benefit from the typical "idea/work in progress" discussions that are enabled by this workshop.We want to bring together researchers and practitioners to form a community that shares common interests in building robust autonomous systems. In particular, for the application domain of autonomous driving, our goal is to better understand the techniques necessary to verify and validate AI-based autonomous systems, ensure their robustness, safety, security, and other important system properties, in general. To this end, we have grouped three of the workshop contributions to form a special session on the verification of autonomous driving.},
location = {Gothenburg, Sweden}
}

@article{10.1016/j.artmed.2021.102163,
author = {Santra, Debarpita and Goswami, Subrata and Mandal, Jyotsna Kumar and Basu, Swapan Kumar},
title = {Low back pain expert systems: Clinical resolution through probabilistic considerations and poset},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102163},
doi = {10.1016/j.artmed.2021.102163},
journal = {Artif. Intell. Med.},
month = {oct},
numpages = {16},
keywords = {Medical expert system, Subgrouping of low back pain, Knowledge representation, Probabilistic inference logic, Partially ordered set, Clinical uncertainty handling}
}

@inproceedings{10.1145/3534678.3542617,
author = {Kenthapadi, Krishnaram and Lakkaraju, Himabindu and Natarajan, Pradeep and Sameki, Mehrnoosh},
title = {Model Monitoring in Practice: Lessons Learned and Open Challenges},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3542617},
doi = {10.1145/3534678.3542617},
abstract = {Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges.In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4800–4801},
numpages = {2},
keywords = {case studies from industry, ethics in ai, model monitoring and model risk management, responsible ai},
location = {Washington DC, USA},
series = {KDD '22}
}

@phdthesis{10.5555/AAI28846644,
author = {Subramonyam, Hariharan and Colleen, Seifert, and Steven, Drucker, and Steve, Oney,},
advisor = {Eytan, Adar,},
title = {Designing AI Experiences: Boundary Representations, Collaborative Processes, and Data Tools},
year = {2021},
isbn = {9798471103603},
publisher = {University of Michigan},
address = {USA},
abstract = {Artificial Intelligence (AI) has transformed our everyday interactions with technology through automation, intelligence augmentation, and human-machine partnership. Nevertheless, we regularly encounter undesirable and often frustrating experiences due to AI. A fundamental challenge is that existing software practices for coordinating system and experience designs fall short when creating AI for diverse human needs, i.e., ``human-centered AI'' or HAI. ``AI-first'' development workflows allow engineers to first develop the AI components, and then user experience (UX) designers create end-user experiences around the AI's capabilities. Consequently, engineers encounter end-user blindness when making critical decisions about AI training data needs, implementation logic, behavior, and evaluation. In the conventional ``UX-first'' process, UX designers lack the needed technical understanding of AI capabilities (technological blindness) that limits their ability to shape system design from the ground up. Human-AI design guidelines have been offered to help but neither describe nor prescribe ways to bridge the gaps in needed expertise in creating HAI.  In this dissertation, I investigate collaboration approaches between designers and engineers to operationalize the vision for HAI as technology inspired by human intelligence that augments human abilities while addressing societal needs. In a series of studies combining technical HCI research with qualitative studies of AI production in practice, I contribute (1) an approach to software development that blurs rigid design-engineering boundaries, (2) a process model for co-designing AI experiences, and (3) new methods and tools to empower designers by making AI accessible to UX designers. Key findings from interviews with industry practitioners include the need for ``leaky'' abstractions shared between UX and AI designers. Because modular development and separation of concerns fail with HAI design, leaky abstractions afford collaboration across expertise boundaries and support human-centered design solutions through vertical prototyping and constant evaluation. Further, by observing how designers and engineers collaborate on HAI design in an in-lab study, I highlight the role of design `probes' with user data to establish common ground between AI system and UX design specifications, providing a critical tool for shaping HAI design. Finally, I offer two design methods and tool implementations --- Data-Assisted Affinity Diagramming and Model Informed Prototyping --- for incorporating end-user data into HAI design. HAI is necessarily a multidisciplinary endeavor, and human data (in multiple forms) is the backbone of AI systems. My dissertation contributions inform how stakeholders with differing expertise can collaboratively design AI experiences by reducing friction across expertise boundaries and maintaining agency within team roles. The data-driven methods and tools I created provide direct support for software teams to tackle the novel challenges of designing with data. Finally, this dissertation offers guidance for imagining future design tools for human-centered systems that are accessible to diverse stakeholders.},
note = {AAI28846644}
}

@phdthesis{10.5555/AAI28390929,
author = {Kaur, Navdeep},
advisor = {Sriraam, Natarajan,},
title = {Efficient Combination of Neural and Symbolic Learning for Relational Data},
year = {2020},
isbn = {9798569988662},
publisher = {The University of Texas at Dallas},
abstract = {Much has been achieved in AI but to realize its true potential, it is imperative that the AI system should be able to learn generalizable and actionable higher-level knowledge from lowest level percepts. Inspired by this goal, neuro-symbolic systems have been developed for the past four decades. These systems encompass the complementary strengths of fast adaptive learning of neural networks from low-level input signals and the deliberative, generalizable models of the symbolic systems. The advent of deep networks has accelerated the development of these neuro-symbolic systems. While successful, there are several open problems to be addressed in these systems, a few of which we tackle in this dissertation. These include: (i) several primitive neural network architectures have not been well studied in the symbolic context; (ii) lack of generic neuro-symbolic architectures that are do not make distributional assumptions; (iii) generalization abilities of many such systems are limited. The objective of this dissertation is to develop novel neuro-symbolic models that (i) induce symbolic reasoning capabilities to fundamental yet unexplored neural network architectures, and (ii) provide unique solutions to the generalization issues that occur during neuro-symbolic integration.More specifically, we consider one of the primitive models, Restricted Boltzmann Machines, that was originally employed for pre-training the deep neural networks and propose two unique solutions to lift them for relational model. For the first solution, we employ relational random walks to generate relational features for Boltzmann machines. We train the Boltzmann machines by passing these resulting features through a novel transformation layer. For the second solution, we employ the mechanism of functional gradient boosting to learn the structure and the parameters of the lifted Restricted Boltzmann Machines simultaneously. Next, most of the neuro-symbolic models designed till date have focused on incorporating neural capabilities in specific models, resulting in lack of a general relational neural network architecture. To overcome this, we develop a generic neuro-symbolic architecture that exploits the concept of relational parameter tying and combining rules to incorporate the first-order logic rules into the hidden layers of the proposed architecture. One of the prevalent neuro-symbolic models called knowledge graph embedding models encode the symbols as learnable vectors in Euclidean space and lose an important characteristic of generalizability to newer symbols while doing so. We propose two unique solutions to circumvent this problem by exploiting the text description of entities in addition to the knowledge graph triples in both the models. In our first model, we train both the text and knowledge graph data in generative setting, while in the second model, we posit the two data sources in adversarial setting. Our broad results across these several directions demonstrate the efficacy and efficiency of the proposed approaches on benchmarks and novel data sets.In summary, this dissertation takes one of the first steps towards realizing the grand vision of the neuro-symbolic integration by proposing novel models that allow for symbolic reasoning capabilities inside neural networks.},
note = {AAI28390929}
}

@phdthesis{10.5555/AAI30346245,
author = {Olsson, Henrik},
advisor = {Martin, Eklund, and Anna, Lantz, and Mark, Clements,},
title = {Personalized Prostate Cancer Management : Ai-Assisted Prostate Pathology and Improved Active Surveillance},
year = {2023},
isbn = {9798374490367},
publisher = {Karolinska Institutet (Sweden)},
abstract = {Prostate cancer is a major global health concern and is the most common cancer-related causeof death in Sweden. Prostate cancer screening using PSA has been shown to reduce prostatecancer mortality but also leads to significant overdiagnosis and overtreatment of low-risk cancers.Improved risk stratification and effective active surveillance are crucial to balancing thebenefits of screening with the risk of overdiagnosis and overtreatment.In Study I, we studied the uptake and the follow-up of active surveillance using a retrospectivecohort of patients who were diagnosed with low-risk prostate cancer between 2008 and 2017in Stockholm County. Our results showed that only 50% of eligible active surveillance patientsreceived active surveillance as their primary treatment choice at diagnosis. Most men thatenrolled in active surveillance remained on surveillance during the first years after diagnosis(82% during a median 3.5 years), but did not receive a follow up according to guidelines withregard to repeat biopsies and PSA tests.Current clinical practice has seen an increase in the use of magnetic resonance imaging (MRI)and the incorporation of risk prediction models to select men with the highest suspicion of clinicallysignificant prostate cancer for prostate biopsy. However, the effectiveness and how MRIand risk prediction models should be incorporated into active surveillance follow-up have yet tobe established. Study II evaluated the performance of MRI-targeted biopsies and a blood-basedrisk prediction model (the Stockholm3 test) for monitoring disease progression in patients onactive surveillance and compared this to the conventional follow-up using PSA and systematicbiopsies. When MRI-targeted and systematic biopsies were combined, the detection rateof clinically significant prostate cancer increased when compared to conventional systematicbiopsies. Biopsies performed in MRI-positive men resulted in a 49% reduction in performedbiopsies, at the expense of failing to diagnose 1.4% clinically significant prostate cancer in MRInegativemen. The incorporation of the Stockholm3 test showed a 27% reduction in requiredMRI investigations and a 57% reduction in performed biopsies compared to performing onlysystematic biopsies.In Study III, we digitized biopsy cores from STHLM3 participants to develop an artificialintelligence (AI) for prostate cancer diagnostics. The AI system demonstrated clinically usefulperformance that was comparable to that of the study pathologist for cancer detection (AUCof 0.986) and for predictions of cancer length (correlation of 0.87) and grading performancethat was on par with that of expert prostate pathologists.In Study IV, we developed a conformal predictor to estimate the uncertainty of the predictionsfor the model in Study III. The uncertainty estimates were used to control the error rate so thatonly predictions with high confidence are accepted and unreliable predictions can be detected.The conformal predictor was able to identify unreliable predictions as a result of variations indigital pathology scanners, preparation of tissue in different pathology laboratories, and theexistence of unusual prostate tissue that the AI model was not exposed to during training.Little is known about the relationships between prostate cancer genetic risk factors and themorphology of prostate tissue. In Study V:, we investigated whether weakly supervised deeplearning can learn to detect such possible associations. The findings in this paper imply relationshipsbetween prostatic tissue morphology and genetic risk factors for prostate cancer,particularly in young men. These results provide proof of principle for exploring the use ofmorphological information in multi-modal prostate cancer risk prediction algorithms.In conclusion, the purpose of this thesis was to describe possible extensions to improve prostatecancer active surveillance management, as well as to develop prediction models for improvedprostate cancer diagnostics.},
note = {AAI30346245}
}

@phdthesis{10.5555/AAI28930568,
author = {Chimatapu, Ravikiran},
title = {An Explainable Artificial Intelligence Approach Based on Deep Type-2 Fuzzy Logic System},
year = {2021},
publisher = {University of Essex (United Kingdom)},
abstract = {Artificial intelligence (AI) systems have benefitted from the easy availability of computing power and the rapid increase in the quantity and quality of data which has led to the widespread adoption of AI techniques across a wide variety of fields. However, the use of complex (or Black box) AI systems such as Deep Neural Networks, support vector machines, etc., could lead to a lack of transparency. This lack of transparency is not specific to deep learning or complex AI algorithms; other interpretable AI algorithms such as kernel machines, logistic regressions, decision trees, or rules-based algorithms can also become difficult to interpret for high dimensional inputs. The lack of transparency or explainability reduces the effectiveness of AI models in regulated applications (such as medical, financial, etc.), where it is essential to explain the model operation and how it arrived at a given prediction. The need for explainability in AI has led to a new line of research that focuses on developing Explainable AI techniques. There are three main avenues of research that are being explored to achieve explainability; first, Deep Explanations, which involves the modification of existing Deep learning models to add explainability. The methods proposed to do Deep explanations generally provide details about all the input features that affect the output, generally in a visual format as there might be a large number of features. This type of explanation is useful for tasks such as image recognition, but in other tasks, it might be hard to distinguish the most important features. Second, Model induction, which involves methods that are model agnostic, but these methods might not be suitable for use in regulated applications. The third method is to use existing interpretable models such as decision trees, fuzzy logic, etc., but the problem with them is that they can also become opaque for high dimensional data. Hence, this thesis presents a novel AI system by combining the predictive power of Deep Learning with the interpretability of Interval Type-2 Fuzzy Logic Systems. The advantages of such a system are, first, the ability to be trained via labelled and unlabelled data (i.e., mixing supervised and unsupervised learning). Second, having embedded feature selection abilities (i.e., can be trained by hundreds and thousands of inputs with no need for feature selection) while delivering explainable models with small rules bases composed of short rules to maximize the model's interpretability. The proposed model was developed with data from British Telecom (BT). It achieved comparable performance to the deep models such as Stacked Autoencoder (SAE) and Convolution Neural Networks (CNN). In categorical datasets, the model outperformed the SAE by 2%, performed within 2-3% of the CNN and outperformed Multi-Layer Perceptron (MLP) and IT2FLS by 4%. In the regression datasets, the model performed slightly worse than the SAE, MLP and CNN models, but it outperformed the IT2FLS with a 15% lower error. The proposed model achieved excellent interpretability in a survey where it was rated within 2% of the highly interpretable IT2FLS. It was also rated 20% and 17% better than Deep learning XAI tools LIME and SHAP, respectively. The proposed model shows a small loss in performance for significantly higher interpretability, making it a suitable replacement for the other AI models in applications with many features where interpretability is paramount.},
note = {AAI28930568}
}

@phdthesis{10.5555/AAI30395221,
author = {Hosseinzadehtaher, Mohsen and Danilo, Erricolo, and Line, He, and Sabri, Cetin, and Frede, Blaabjerg,},
advisor = {Mohammad, Shadmand,},
title = {Resilient Operation of Active Distribution Networks via Self-Learning Smart Devices},
year = {2022},
isbn = {9798374420418},
publisher = {University of Illinois at Chicago},
address = {USA},
abstract = {This dissertation focuses on developing Artificial Intelligence (AI)-based and self-healing control techniques to enhance the resiliency of active distribution networks for upcoming power grid challenges. In the first stage of this work, a high bandwidth primary control layer is developed to achieve an ultra-fast predictive controlled dual active bridge converter interfaced grid-following inverter for voltage and frequency support. The primary control layer is developed by a novel model predictive self-healing control (MPSC) scheme. This control technique heals intrinsic drawbacks in commonly used control approaches by decreasing the potential errors in the control processes. However, the frequency restoration process needs more advanced techniques due to the high nonlinearity of the active distribution networks such as power electronic dominated grids (PEDG). Therefore, an artificial intelligence-based power reference correction (AI-PRC) mechanism is developed to address the shortcomings of frequency restoration of the state-of-the-art virtual synchronous generator (VSG)-based or droop-based grid following inverters (GFLIs) and grid forming inverters (GFMIs) via re-defining GFLI role at grid-edge. A detailed analytical validation is provided that shows control rules in PEDG intrinsically follow the underlying dynamic of the swing-based machines to extend its stability boundary. Considering this fact, comprehensive transient and steady state-based mathematical models are used for constructing the learning database of the proposed AI-PRC mechanism. Subsequently, a neural network is trained by Bayesian Regularization Algorithm (BRA) to realize the proposed AI-PRC for GFLIs. The proposed training approach can deal with all grid characteristics alterations and uncertainties. Thus, this approach incorporates all PEDG's effective variables that shape its dynamic response during transient disturbances. Several simulations and experimental case studies were provided that evaluate the functionality of the proposed AI-PRC for GFLIs towards enhancing transient response and resiliency of PEDG. The provided evaluations demonstrate significant improvement in frequency restoration in response to transient disturbances.Moreover, the proposed control technique is exploited as a shadow controller in the case that the attacker aims to threaten the entire grid stability via stealthy attacks. Some stealthy attack scenarios are investigated on the 14-bus PEDG, and the results have proven the effectiveness of the proposed approach in fast supporting of the grid in the event of stealthy attacks, thus the grid resiliency is enhanced in this case as well.Due to the high importance of power grid resiliency, in the final stage of this work, an intrusion detection system (IDS) is developed to provide another layer of security that monitors grid dynamics and vital variables in other time scales. The groundwork of this technique is based on a load forecasting procedure that benefits from an artificial intelligence approach. In more details, an anomaly detection technique based on a condition monitoring vector and ultra-short demand forecasting is designed and developed for achieving the above-mentioned goals. The designed IDS is more robust against attack scenarios that could bypass other primary control layers. Thus, the proposed approach enables grid operators to take proper and prompt actions for providing a secure operation of the grid.},
note = {AAI30395221}
}

@phdthesis{10.5555/AAI29997492,
author = {Suh, Youngjoon and Aparna, Chandramowlishwaran, and Ramin, Bostanabad,},
advisor = {Yoonjin, Won,},
title = {Bridging the Gap: Vision-Inspired Two-Phase Heat Transfer Analysis},
year = {2022},
isbn = {9798368432908},
publisher = {University of California, Irvine},
abstract = {Liquid-vapor phase-change phenomena have been critical to maintaining sustainable and habitable environments on Earth for countless millennia, and are continuing to play central roles in present-day's industries with ever growing presence. Among different types of phase-change processes, boiling and condensation are two of the most widely used in both domestic and industrial applications. Central to the mechanistic understanding of the thermofluidic processes governing the phase-change phenomena is the rapid and high-fidelity extraction of interpretable physical descriptors from the highly-transient nucleation behaviors. However, extracting quantifiable measures out of dynamic objects with conventional imaging technologies poses a challenge to researchers. This thesis focuses on addressing the fundamentally weak connection between phase-change heat and mass transfer and nucleation statistics available in visual data streams. We outline core ideas of current artificial intelligence (AI) technologies connected to thermal energy science to illustrate how they can be used to push the limit of our knowledge boundaries about boiling and condensation physics. The comprehensive review offers insight into the role of recent advances in AI and computer vision in advancing modern boiling and condensation research. Based on foundational literature analysis and problem definition, the remainder of the thesis proposes various AI-based solutions for connecting visual data streams with heat and mass transfer performances at the device and system level. First, we introduce a data-driven learning framework that correlates high-quality imaging on dynamic bubbles with associated boiling curves. The framework leverages cutting-edge machine learning models including convolutional neural networks and object detection algorithms to automatically extract both hierarchical and physics-based features. By training on these features, our model learns physical boiling laws that statistically describe the manner in which bubbles nucleate, coalesce, and depart under boiling conditions, enabling in situ boiling curve prediction with a mean error of 6%. Our framework offers an automated, learning-based, alternative to conventional boiling heat transfer metrology. Next, we demonstrate an intelligent vision-based framework called Vision Inspired Online Nuclei Tracker (VISION-iT), which unites classical thermofluidic imaging techniques with deep learning to fundamentally address the challenge of extracting high-fidelity interpretable physical descriptors for the highly-transient two-phase processes. We introduce and discuss the detailed construction, algorithms, and optimization guidelines of individual modules so that the framework can easily be adjusted to custom datasets. The concepts and procedures that we propose is transferable, and thus can benefit a broader audience dealing with similar problems. Finally, VISION-iT is deployed in practical phase-change heat transfer analysis applications. For boiling applications, the combined efforts of materials design, deep learning techniques, and data-driven approach shed light on the mechanistic relationship between vapor/liquid pathways, bubble statistics, and phase change performance. For condensation applications, the data-centric analysis enabled by VISION-iT conclusively shows that contrary to classical understanding, the overall condensation performance is governed by a key trade-off between heat transfer rate per individual droplet and droplet population density. Our vision-based approach presents a powerful tool for the study of not only phase-change processes but also any nucleation-based process within and beyond the thermal science community through the harnessing of big data.},
note = {AAI29997492}
}

@inproceedings{10.1007/978-3-031-35891-3_8,
author = {Kutz, Janika and Neuh\"{u}ttler, Jens and Bienzeisler, Bernd and Spilski, Jan and Lachmann, Thomas},
title = {Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services},
year = {2023},
isbn = {978-3-031-35890-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35891-3_8},
doi = {10.1007/978-3-031-35891-3_8},
abstract = {AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.},
booktitle = {Artificial Intelligence in HCI: 4th International Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I},
pages = {115–130},
numpages = {16},
keywords = {Industrial AI, Human-Centered AI, Design Principles},
location = {Copenhagen, Denmark}
}

@article{10.1007/s10796-021-10234-5,
author = {Meske, Christian and Bunde, Enrico},
title = {Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection},
year = {2022},
issue_date = {Apr 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-021-10234-5},
doi = {10.1007/s10796-021-10234-5},
abstract = {Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high.},
journal = {Information Systems Frontiers},
month = {mar},
pages = {743–773},
numpages = {31},
keywords = {Design science research, Design principles, Hate speech detection, Explainable artificial intelligence, Local explanations}
}

@article{10.1155/2022/1375009,
author = {Xiang, Jianmin and Tong, Litao and Zhou, Shengfa and Sharma, Kapil},
title = {Design of AI System for National Fitness Sports Competition Action Based on Association Rules Algorithm},
year = {2022},
issue_date = {2022},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2022},
issn = {1687-5265},
url = {https://doi.org/10.1155/2022/1375009},
doi = {10.1155/2022/1375009},
abstract = {In information system construction, online data migration is a very important link. At present, in different fields, people provide protection for online data migration through the way of project management to ensure the speed and efficiency of online migration. However, some problems may occur in the process of online data migration. In the development of contemporary sports, competitive sports, as the high-end stage of sports development, are constantly pursued by ordinary sports enthusiasts. Therefore, in the national fitness activities, how to combine the national fitness and competitive sports data to provide a more professional storage platform is a focus of research but also a problem to be solved in the process of online data migration. Because the data mining ID3 algorithm only supports querying and retrieving RowKey indexes, it does not support non-RowKey column indexing. Therefore, if you want to query non-RowKey indexes, the data mining ID3 algorithm will search the form in the overall scan, but the performance of this method is low. In order to improve the query speed of non-RowKey columns, this paper designs a secondary index function based on HBase. The sports competition action system can retrieve data from the secondary index of the query state, to avoid scanning the whole world and improve the search speed. In this paper, ID3 algorithm is used to combine national fitness and competitive sports data, which provides a guarantee for the migration of competitive sports data in the national fitness system.},
journal = {Intell. Neuroscience},
month = {jan},
numpages = {11}
}

@article{10.1155/2022/9913450,
author = {Ye, Yanping and Arif, Muhammad},
title = {Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology},
year = {2022},
issue_date = {2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2022},
issn = {1939-0114},
url = {https://doi.org/10.1155/2022/9913450},
doi = {10.1155/2022/9913450},
abstract = {With the development of the Internet, “Internet Plus” has been widely used in various fields, and the Internet has become a great opportunity to transform CET. People’s demand for education, especially higher education, has also increased rapidly. With the attention and investment of the state in recent years, higher education has developed rapidly, accounting for half of China’s higher education. However, the increase in the number of students has brought great pressure to CET. How to improve the teaching efficiency of large classes is an urgent problem to be solved. The development of sci and tech, especially computer, has brought us new hope. Computer-assisted instruction has been introduced into CET. However, there are some unreasonable points in the design of computer-aided marking system in China, which is not suitable for CET. It is very important to research and design a computer-aided marking system that can expand CET methods and maximize the integration of English instructional resources. This paper introduces the principle, characteristics, and application fields of AI; analyzes the problems faced by CET; and puts forward a CET path based on computer-aided technology.},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {8}
}

@inproceedings{10.1145/3522664.3528590,
author = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
title = {Data smells: categories, causes and consequences, and detection of suspicious data in AI-based systems},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528590},
doi = {10.1145/3522664.3528590},
abstract = {High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {229–239},
numpages = {11},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@article{10.1155/2023/9758670,
author = {Communication Networks, Security and},
title = {Retracted: Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology},
year = {2023},
issue_date = {2023},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2023},
issn = {1939-0114},
url = {https://doi.org/10.1155/2023/9758670},
doi = {10.1155/2023/9758670},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {1}
}

