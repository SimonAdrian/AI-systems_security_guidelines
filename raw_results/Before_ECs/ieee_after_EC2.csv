"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"An AI-Based Heart Failure Treatment Adviser System","Z. Chen; E. Salazar; K. Marple; S. R. Das; A. Amin; D. Cheeran; L. S. Tamil; G. Gupta","Computer Science Department, The University of Texas at Dallas, Richardson, TX, USA; Computer Science Department, The University of Texas at Dallas, Richardson, TX, USA; Walmart Technology, Plano, TX, USA; Cardiology Division, University of Texas Southwestern Medical Center, Dallas, TX, USA; Cardiology Division, University of Texas Southwestern Medical Center, Dallas, TX, USA; Cardiology Division, University of Texas Southwestern Medical Center, Dallas, TX, USA; Electrical Engineering Department, The University of Texas at Dallas, Richardson, TX, USA; Computer Science Department, The University of Texas at Dallas, Richardson, TX, USA","IEEE Journal of Translational Engineering in Health and Medicine","4 Dec 2018","2018","6","","1","10","Management of heart failure is a major health care challenge. Healthcare providers are expected to use best practices described in clinical practice guidelines, which typically consist of a long series of complex rules. For heart failure management, the relevant guidelines are nearly 80 pages long. Due to their complexity, the guidelines are often difficult to fully comply with, which can result in suboptimal medical practices. In this paper, we describe a heart failure treatment adviser system that automates the entire set of rules in the guidelines for heart failure management. The system is based on answer set programming, a form of declarative programming suited for simulating human-style reasoning. Given a patient's information, the system is able to generate a set of guideline-compliant recommendations. We conducted a pilot study of the system on 21 real and 10 simulated patients with heart failure. The results show that the system can give treatment recommendations compliant with the guidelines. Out of 187 total recommendations made by the system, 176 were agreed upon by the expert cardiologists. Also, the system missed eight valid recommendations. The reason for the missed and discordant recommendations seems to be insufficient information, differing style, experience, and knowledge of experts in decision-making that were not captured in the system at this time. The system can serve as a point-of-care tool for clinics. Also, it can be used as an educational tool for training physicians and an assessment tool to measure the quality metrics of heart failure care of an institution.","2168-2372","","10.1109/JTEHM.2018.2883069","National Science Foundation(grant numbers:1718945); Texas Medical Research Collaborative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543643","Automated reasoning;knowledge representation;guideline automation;heart failure management","Heart;Guidelines;Diseases;Cognition;Programming;Medical treatment","","38","","20","OAPA","23 Nov 2018","","","IEEE","IEEE Journals"
"Robust AI-enabled Simulation of Treatment Paths with Markov Decision Process for Breast Cancer Patients","S. S. Hossain; M. R. Ebrahimi; B. Padmanabhan; I. El Naqa; P. C. Kuo; A. Beard; S. Merkel","Muma College of Business, University of South Florida, Tampa, USA; Muma College of Business (Star-AI Lab), University of South Florida, Tampa, USA; Muma College of Business, University of South Florida, Tampa, USA; Chair of Machine Learning, H. Lee Moffitt Cancer Center and Research Institute, Tampa, USA; Dept. of Surgery, Morsani College of Medicine, Tampa; Dept. of Surgery, Morsani College of Medicine, Tampa; Resident Physician, Morsani College of Medicine, Tampa, USA","2023 IEEE Conference on Artificial Intelligence (CAI)","2 Aug 2023","2023","","","105","108","Development in AI/ML-based methodologies has facilitated improvement in clinical decision making at various stages of treatment in breast cancer care. While this addresses patient needs at specific stages of treatment, the overall treatment path of a patient from a holistic standpoint has remained understudied due to challenges in accessing the relevant data. In this study, we propose to develop an AI-enabled treatment path simulation for breast cancer patients while characterizing the treatment paths as a Markov decision process (MDP). In order to avoid the limitations of healthcare records, which are often incomplete and subject to misinformation, we have leveraged clinical practice guidelines and expertise from physicians at Moffitt Cancer Center to develop the MDP. Our study of developing such an MDP, leveraging domain knowledge, contributes to improving research on treatment path simulation for breast cancer patients.","","979-8-3503-3984-0","10.1109/CAI54212.2023.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195029","Breast cancer;Markov decision process;NCCN guidelines;Reinforcement Learning","Decision making;Medical services;Learning (artificial intelligence);Markov processes;Breast cancer;Fake news;Guidelines","","","","23","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Challenges in Machine Learning Application Development: An Industrial Experience Report","M. S. Rahman; F. Khomh; E. Rivera; Y. -G. Guéhéneuc; B. Lehnert","Polytechnique Montreal, Canada; Polytechnique Montreal, Canada; Polytechnique Montreal, Canada; Concordia University, Canada; SAP Montreal, Canada","2022 IEEE/ACM 1st International Workshop on Software Engineering for Responsible Artificial Intelligence (SE4RAI)","30 Jun 2022","2022","","","21","28","SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers’ feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours. CCS CONCEPTS • Software and its engineering → Programming teams.","","978-1-4503-9319-5","10.1145/3526073.3527593","Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808693","Software Engineering for Machine Learning;Error Detection and Correction;Challenges and Best Practices","Conferences;Collaboration;Machine learning;Manuals;Programming;Servers;Research and development","","","","30","","30 Jun 2022","","","IEEE","IEEE Conferences"
"Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study","J. Bogner; R. Verdecchia; I. Gerostathopoulos","University of Stuttgart, Institute of Software Engineering, Stuttgart, Germany; Department of Computer Science, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Department of Computer Science, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands","2021 IEEE/ACM International Conference on Technical Debt (TechDebt)","25 Jun 2021","2021","","","64","73","Background: With the rising popularity of Artificial Intelligence (AI), there is a growing need to build large and complex AI-based systems in a cost-effective and manageable way. Like with traditional software, Technical Debt (TD) will emerge naturally over time in these systems, therefore leading to challenges and risks if not managed appropriately. The influence of data science and the stochastic nature of AI-based systems may also lead to new types of TD or antipatterns, which are not yet fully understood by researchers and practitioners. Objective: The goal of our study is to provide a clear overview and characterization of the types of TD (both established and new ones) that appear in AI-based systems, as well as the antipatterns and related solutions that have been proposed. Method: Following the process of a systematic mapping study, 21 primary studies are identified and analyzed. Results: Our results show that (i) established TD types, variations of them, and four new TD types (data, model, configuration, and ethics debt) are present in AI-based systems, (ii) 72 antipatterns are discussed in the literature, the majority related to data and model deficiencies, and (iii) 46 solutions have been proposed, either to address specific TD types, antipatterns, or TD in general. Conclusions: Our results can support AI professionals with reasoning about and communicating aspects of TD present in their systems. Additionally, they can serve as a foundation for future research to further our understanding of TD in AI-based systems.","","978-1-6654-1405-0","10.1109/TechDebt52882.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463054","Artificial Intelligence;Machine Learning;Technical Debt;Antipatterns;Systematic Mapping Study","Ethics;Systematics;Pipelines;Stochastic processes;Tools;Data models;Software","","16","","56","IEEE","25 Jun 2021","","","IEEE","IEEE Conferences"
"Advancing Trustworthy Knowledge Engineering through User-Centered AI-based Systems: A Systematic Review","A. Rossner; R. Dörner; S. Pagel","Mainz University of Applied Sciences, Mainz, Germany; RheinMain University of Applied Sciences, Wiesbaden, Germany; Mainz University of Applied Sciences, Mainz, Germany","2023 IEEE Sixth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","8 Jan 2024","2023","","","66","70","This document is a model and instructions for LATEX. This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, or Math in Paper Title or Abstract.","2831-7203","979-8-3503-3128-8","10.1109/AIKE59827.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10381541","Knowledge Engineering;Trustworthy AI;User-Centred Artificial Intelligence;Human-AI Interaction","Knowledge engineering;Systematics;Symbols","","","","28","IEEE","8 Jan 2024","","","IEEE","IEEE Conferences"
"Designing User-friendly Medical AI Applications - Methodical Development of User-centered Design Guidelines","L. Wiebelitz; P. Schmid; T. Maier; M. Volkwein","Corporate Strategy and Development, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute for Engineering Design and Industrial Design, University of Stuttgart, Stuttgart, Germany; Institute for Engineering Design and Industrial Design, University of Stuttgart, Stuttgart, Germany; Corporate Strategy and Development, Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany","2022 IEEE International Conference on Digital Health (ICDH)","24 Aug 2022","2022","","","23","28","Medical artificial intelligence (AI) applications will become increasingly relevant in the future and change the medical technology market. Areas of application are located in the professional as well as in private use. The human-machine interface (HMI) is crucial for a successful use of these AI technologies and for a high user added value. The factors of user experience, usability and joy of use significantly determine the quality of an HMI, but are still insufficiently researched for medical AI applications. This work addresses this gap and provides generally applicable design guidelines to AI-based mobile medical applications. For this purpose, a user-centered requirements analysis was conducted to evaluate possible HMI concepts for a fictitious medical AI application. Based on these findings, specific design guidelines for the HMI of the fictitious application were established. Finally, a universal design catalog for medical AI applications was developed.","","978-1-6654-8149-6","10.1109/ICDH55609.2022.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861079","medical AI;IEC 62366;AI design guidelines;user-centered design;human-AI interaction;AI usability factor","Industries;Biomedical equipment;User centered design;User experience;Mobile handsets;Electronic healthcare;Artificial intelligence","","1","","25","IEEE","24 Aug 2022","","","IEEE","IEEE Conferences"
"Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems","H. Foidl; M. Felderer; R. Ramler","University of Innsbruck, Austria; University of Innsbruck, Austria; Software Competence Center Hagenberg GmbH, Austria","2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)","17 Jun 2022","2022","","","229","239","High data quality is fundamental for today’s AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.","","978-1-4503-9275-4","10.1145/3522664.3528590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796422","data smells;artificial intelligence;data engineering;software engineering;data quality","Industries;Codes;Data integrity;Maintenance engineering;Solids;Oncology;Software","","2","","63","","17 Jun 2022","","","IEEE","IEEE Conferences"
"Designing Cybersecurity AI Based Awareness Games for Citizens: Best Practices and Future Directions","S. Chennamaneni; P. Pradhan; V. Chebolu; M. Vejendla; S. K. Kannaiah; S. S. Aravinth","Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, AP, India","2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)","25 Apr 2023","2023","","","407","412","Cybercrimes are a hazard to both people and businesses. Knowing the best techniques for cyber security is essential for defending against these threats. Despite their ability to be useful, conventional learning techniques like reading articles or attending seminars lack interest. Because of this, employing serious games for education is growing in popularity. Serious games give players an involved learning experience while educating them on a subject, like cyber security. In order to give players a useful understanding to defend themselves, this study investigates the best approaches for embedding cyber security education into serious games. Learning about cyber security is made enjoyable and more relevant by using a game-based methodology. In order to evaluate how game design aspects might be utilized to effectively instruct players on cyber security, the paper examines a variety of game design elements, including game mechanics, narrative, and feedback mechanisms. Additionally, it goes into how different players, such as novice and experienced players, might be catered to in serious games. In general, playing serious games is a fun and effective approach to educate yourself about cyber security. Designers and teachers can produce games that are both enjoyable and instructional by adhering to the quality standards described in this paper.","","978-1-6654-9199-0","10.1109/ICSCDS56580.2023.10104800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104800","Cybercrimes;Cyber security;Conventional learning techniques;Serious games;Education;Game-based methodology;Game design elements;Game mechanics;Narrative;Feedback mechanisms;Novice players;Experienced players;Fun;Effective;Designers;Teachers;Quality standards","Seminars;Education;Information security;Games;Reinforcement learning;Hazards;Serious games","","8","","18","IEEE","25 Apr 2023","","","IEEE","IEEE Conferences"
"AI-based Research and Application of Fault Diagnosis for Steam Turbine Regenerative System","X. Jiang","State Grid Jibei Electric Power Company Limited Skills Training Center, Baoding Electric Power VOC & TECH. College, Baoding, China","2020 International Conference on Information Science, Parallel and Distributed Systems (ISPDS)","18 Nov 2020","2020","","","333","335","As the key equipment of electric power plant, the safe operation of steam turbine plays a vital role in practical production. At the same time, the normal and stable operation of excitation system, water-oxygen cooling system, regenerative system and other set system also play a decisive role in the safe operation of the unit. Fault diagnosis in the past mainly relied on the domain experts to judge the type of fault based on its experience, which has too much limitation, it is difficult to make effective diagnosis for the unconspicuous fault. The paper analyzed the common failures of the steam turbine regenerative system and established a typical fault set of the regenerative system. On the basis of using the fuzzy rules to establish knowledge base of fault symptom of regenerative system, a fault diagnosis method of regenerative system based on support vector machine multi-classification algorithm was proposed. Finally, the method was applied to the fault diagnosis of the regenerative system of a steam turbine. The experimental results showed that the model could effectively identify the fault of the regenerative system.","","978-1-7281-9668-8","10.1109/ISPDS51347.2020.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9258563","Regeneration system;fuzzy rules;support vector machine;multi-classification algorithm;fault diagnosis","Fault diagnosis;Training;Support vector machines;Knowledge based systems;Information science;5G mobile communication","","","","4","IEEE","18 Nov 2020","","","IEEE","IEEE Conferences"
"Reducing Bias in AI-Based Analysis of Visual Artworks","Z. Zhang; J. Li; D. G. Stork; E. Mansfield; J. Russell; C. Adams; J. Z. Wang","The Pennsylvania State University, University Park, PA, USA; The Pennsylvania State University, University Park, PA, USA; NA; The Pennsylvania State University, University Park, PA, USA; The Pennsylvania State University, University Park, PA, USA; The Pennsylvania State University, University Park, PA, USA; The Pennsylvania State University, University Park, PA, USA","IEEE BITS the Information Theory Magazine","9 Dec 2022","2022","2","1","36","48","Empirical research in science and the humanities is vulnerable to bias which, by definition, implies incorrect or misleading findings. Artificial intelligence-based analysis of visual artworks is vulnerable to bias in ways specific to the domain. Works of art belong to a distinct cultural category that often prioritizes such characteristics as hand-craftsmanship, uniqueness, originality, and imaginative content; works of art are also responsive to diverse social and cultural contexts. Ascertaining which features of an artwork can be rightly ascribed to an objective “truth,” without which the concept of bias is not even relevant, is itself challenging. Incorporating expert knowledge into machine learning applications can help reduce bias in final estimates. We review several sources of bias that can occur across different stages of AI-based analysis, protocols, and best practices for reducing bias, and approaches to measuring these biases. This systematic investigation of various types of bias can help researchers better understand bias, become aware of practical solutions, and ultimately cultivate the prudent adoption of AI-based approaches to artwork analysis.","2692-4110","","10.1109/MBITS.2022.3197102","National Endowment for the Humanities(grant numbers:HAA-271801-20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9851932","","Painting;Art;Image color analysis;Cultural differences;Feature extraction;Visualization;Imaging;Machine learning;Best practices;Systematics","","3","","43","IEEE","8 Aug 2022","","","IEEE","IEEE Magazines"
"Artificial Intelligence, Policing and Ethics – a best practice model for AI enabled policing in Australia","H. Harris; A. Burke","School of Law, Macquarie University, Sydney, Australia; School of Law, Macquarie University, Sydney, Australia","2021 IEEE 25th International Enterprise Distributed Object Computing Workshop (EDOCW)","1 Dec 2021","2021","","","53","58","The application of Artificial Intelligence (AI) to policing processes and practices has transformative potential. Despite its potential, utilising AI for policing also comes with risks and challenges. The objective of this article is to provide a starting point for the development of a best practice model for the application of AI to policing in Australia. Such a best practice model would be the first of its kind and could put Australian police departments at the forefront of AI application – enabling Australian police to deploy AI in a way that has broad stake-holder support, maximising effectiveness and ensuring ethical concerns are adequately addressed","2325-6605","978-1-6654-4488-0","10.1109/EDOCW52865.2021.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626315","Artificial Intelligence;law;policing;best practice;governance","Ethics;Law enforcement;Conferences;Computational modeling;Australia;Artificial intelligence;Best practices","","","","41","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Energy Saving Technologies and Best Practices for 5G Radio Access Network","R. Tan; Y. Shi; Y. Fan; W. Zhu; T. Wu","China Telecom Research Institute, Guangzhou, China; China Telecom Research Institute, Guangzhou, China; Shanghai Research Institute, ZTE Corporation, Shanghai, China; China Mobile Group, Design Institute Company Ltd., Beijing, China; National Institute of Metrology, Beijing, China","IEEE Access","18 May 2022","2022","10","","51747","51756","This article identifies energy-saving potential of the fifth generation (5G) Radio Access Network, and describes main energy-saving principles and technologies. It explores how to use network energy saving technologies, such as carrier shutdown, channel shutdown, and symbol shutdown in 5G network, that have been inherited from 4G. Some enhanced technologies for 5G like equipment deep sleep and symbol aggregation have also been introduced in this article. However, it is far from enough and an innovative energy-saving solution should be considered. To meet the requirements and development of intelligent and self-adaptive energy-saving solution, Artificial Intelligence (AI) and big data analysis are introduced to form a more precise energy-saving strategy based on site-specific traffic and site-related conditions, thus improving the efficiency and reducing the manpower. Finally, two commercial application practices of AI-based energy-saving solution are elaborated. One is the practice of AI-based service awareness energy saving for 4G/5G collaborative networks, the energy benefits can be improved up to 20%; The other practice is the adoption of a new architecture Active Antenna Unit (AAU) with beam pattern optimization, its energy benefits can be promoted by 30%. These two practices could help mobile network operators (MNOs) to achieve the most energy-efficient network with good network performance and lower Operating Expense (OPEX).","2169-3536","","10.1109/ACCESS.2022.3174089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772655","5G;artificial intelligence;base station;energy efficiency;energy saving;radio access network","5G mobile communication;Symbols;Power demand;Artificial intelligence;Time-domain analysis;Radio frequency;Base stations","","9","","20","CCBYNCND","11 May 2022","","","IEEE","IEEE Journals"
"AI Living Lab: Quality Assurance for AI-based Health systems","V. Lenarduzzi; M. Isomursu",University of Oulu; University of Oulu,"2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)","4 Jul 2023","2023","","","86","87","The main goal of this project is to develop an AI Living Lab providing methods and software tools for AI trustworthiness analysis, running digital twins to simulate Digital Health solutions (Hardware and Software) integrated with AI elements in vitro for early-stage validation experiments. In this paper, we present the motivation beyond the need of a AI Living Lab methods for researchers and companies, our idea in practice, and the scheduled roadmap. The insights of the AI Living Lab can enable researchers to understand possible problems on the quality of AI-enabled systems opening new research topics and allows companies to understand how to better address quality issues in their systems.","","979-8-3503-0113-7","10.1109/CAIN58948.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164757","Artificial Intelligence;Machine Learning;Soft-ware Quality;Software Engineering;Health","Quality assurance;Companies;Hardware;Electronic healthcare;Digital twins;Artificial intelligence;Software tools","","","","4","IEEE","4 Jul 2023","","","IEEE","IEEE Conferences"
"Artificial Intelligence (AI) based Detection of Traffic Violations by Two-Wheeler Vehicles","M. Bala Kishore; I. Srinivasa Reddy; L. Sujihelen; A. Sivasangari; A. Christy","Department of CSE, Sathyabama Institute of Science and Technology; Department of CSE, Sathyabama Institute of Science and Technology; Department of CSE, Sathyabama Institute of Science and Technology; Department of IT, Sathyabama Institute of Science and Technology; Department of CSE, Sathyabama Institute of Science and Technology","2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)","8 Jun 2023","2023","","","1788","1792","Increasing commuters, bad traffic signal management, and rider mentality are some of the factors contributing to traffic violations in India. Monitoring large traffic volumes physically and tracking violations at the same time is clearly insufficient with only physical traffic police. The result has been that many violators have gone undetected. By violating the traffic laws, the violators cause more serious mishaps on the road, thereby putting both themselves and others in danger. To avoid manual intervention in detecting and catching violators, Artificial Intelligence (AI)-based techniques should be incorporated. This research study demonstrates a novel technique to discover multiple offences on Indian roads electronically, which include helmet detection, using a smartphone while driving, tri cruising, wheeling, and parking illegally, and ultimately model the issuing of tickets by monitoring the infractions and affiliated car number together in record. Through all the automated AI-based traffic offense and booking system, the software will be extremely beneficial in determining diverse safety-related guidelines, facilitating in the imposing of harsher traffic restrictions, and fostering the development of such a green technology atmosphere.","2768-5330","979-8-3503-9725-3","10.1109/ICICCS56967.2023.10142605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142605","AI-Based;Detection;YOLO-V4;Object-bounding","Head;Law enforcement;Roads;Manuals;Software;Safety;Artificial intelligence","","","","15","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Hybrid AI-based Control Strategy for a Full-Vehicle Semi-Active Suspension System Equipped with MR Dampers","A. R. B. Ahmadi; M. S. Panahi; M. Ayati","School of Mechanical Engineering College of Engineering, University of Tehran, Tehran, Iran; School of Mechanical Engineering College of Engineering, University of Tehran, Tehran, Iran; School of Mechanical Engineering College of Engineering, University of Tehran, Tehran, Iran","2022 10th RSI International Conference on Robotics and Mechatronics (ICRoM)","1 Feb 2023","2022","","","433","438","This paper’s goal is to design a hybrid AI-based controller for a MR-damped semi-active suspension system using a seven-degree-of-freedom model to enhance ride comfort by mitigating the acceleration exerted on the passenger. A fuzzy-logic control strategy is employed to determine the desired force required to be applied to the vehicle body. Also, a recurrent neural network was developed to predict the input voltage of the damper required to generate its actual force. The fuzzy controller rules are designed based on minimizing the vehicle body acceleration. The neural network is trained using the synthetic data produced from the modified Bouc-Wen model. The performance of the proposed hybrid AI-based method was evaluated by applying it to a full suspension system model incorporating an MR damper model with 7-DOF riding on a bumpy road. Based on various simulations, the effectiveness of the proposed strategy is proved by calculating RMS values of the vertical body acceleration, angular acceleration, and the vertical displacement of body center mass.","2572-6889","978-1-6654-5452-0","10.1109/ICRoM57054.2022.10025306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025306","semi-active suspension system;MR damper;AI-based control;fuzzy control;recurrent neural networks;NARX;vibration control","Damping;Recurrent neural networks;Mechatronics;Roads;Force;Control systems;Shock absorbers","","","","9","IEEE","1 Feb 2023","","","IEEE","IEEE Conferences"
"How Well Can Masked Language Models Spot Identifiers That Violate Naming Guidelines?","J. Villmow; V. Campos; J. Petry; A. Abbad-Andaloussi; A. Ulges; B. Weber","RheinMain University of Applied Sciences, Wiesbaden, Germany; RheinMain University of Applied Sciences, Wiesbaden, Germany; RheinMain University of Applied Sciences, Wiesbaden, Germany; University of St. Gallen, St. Gallen, Switzerland; RheinMain University of Applied Sciences, Wiesbaden, Germany; University of St. Gallen, St. Gallen, Switzerland","2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation (SCAM)","20 Dec 2023","2023","","","131","142","Using meaningful identifiers in source code reduces the risk of errors, the cognitive load of developers, and speeds up the development process. Therefore, recent research has looked into an AI-based analysis of identifiers, for which large-scale language models appear to offer great potential. Based on tokens’ probabilities, such models can suggest identifiers that are likely to appear in a given context. While current research has used language models to predict the most likely identifier names, studies on assessing the quality of given identifiers are scarce. To this end, we explore adherence to identifier naming guidelines as a proxy for identifier quality and propose and evaluate two unsupervised approaches for spotting violations: First, a generative approach, which uses the probability distribution of the language model directly without fine-tuning. Second, a discriminative method, which fine-tunes the model’s encoder to discriminate between original identifiers and similar drop-in replacements suggested by a weak AI. We demonstrate that the proposed approaches can successfully detect violations of common guidelines for identifier naming. To do so, we have developed a dataset built on widely accepted identifier naming guidelines. The manually annotated dataset contains more than 6000 dense annotations of identifiers for 28 common guidelines. Using the data, we show that the generative approach achieves the best results, but that the particular masking strategy and scoring method matter substantially. Also, we demonstrate our approach to outperform other recent code transformers. In a per-guideline analysis, we highlight the potential and limitations of language models, and provide a blue-print for training and evaluating their ability to identify bad identifier names in source code. We make our dataset and models’ implementation publicly available to encourage future research on AI-based identifier quality assessment.","2470-6892","979-8-3503-0506-7","10.1109/SCAM59687.2023.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356698","Masked Language Models;Source Code Identfiers;Naming Guidelines;Code Quality;Identfier Quality Assessment;Generative Approaches;Language Model Fine-tuning;Code Transformers;AI-based Code Analysis","Training;Analytical models;Computer languages;Codes;Source coding;Training data;Transformers","","","","54","IEEE","20 Dec 2023","","","IEEE","IEEE Conferences"
"AI Empowered Resource Management for Future Wireless Networks","Y. Shen; J. Zhang; S. H. Song; K. B. Letaief","Dept. of ECE, The Hong Kong University of Science and Technology, Hong Kong; Dept. of EIE, The Hong Kong Polytechnic University, Hong Kong; Dept. of ECE, The Hong Kong University of Science and Technology, Hong Kong; Dept. of ECE, The Hong Kong University of Science and Technology, Hong Kong","2021 IEEE International Mediterranean Conference on Communications and Networking (MeditCom)","23 Dec 2021","2021","","","252","257","Resource management plays a pivotal role in wireless networks, which, unfortunately, leads to challenging NP-hard problems. Artificial Intelligence (AI), especially deep learning techniques, has recently emerged as a disruptive technology to solve such challenging problems in a real-time manner. However, although promising results have been reported, practical design guidelines and performance guarantees of AI-based approaches are still missing. In this paper, we endeavor to address two fundamental questions: 1) What are the main advantages of AI-based methods compared with classical techniques; and 2) Which learning method should we choose for a given resource management task. For the first question, four advantages are identified and discussed. For the second question, optimality gap, i.e., the gap to the optimal performance, is proposed as a measure for selecting model architectures, as well as, for enabling a theoretical comparison between different AI-based approaches. Specifically, for K-user interference management problem, we theoretically show that graph neural networks (GNNs) are superior to multi-layer perceptrons (MLPs), and the performance gap between these two methods grows with $\sqrt K $.","","978-1-6654-4505-4","10.1109/MeditCom49071.2021.9647580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9647580","Resource management;wireless networks;interpretable neural networks;deep learning;PAC-learning","Training;Learning systems;Systematics;NP-hard problem;Wireless networks;Design methodology;Interference","","9","","42","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"Contactless Temperature Detection of Multiple People and Detection of Possible Corona Virus Affected Persons Using AI Enabled IR Sensor Camera","A. M.; S. K.; S. K. R.; Y. I.","Department of Electronics and Communication Engineering, IFET College of Engineering, Villupuram, India; Department of Electronics and Communication Engineering, IFET College of Engineering, Villupuram, India; Department of Electronics and Communication Engineering, IFET College of Engineering, Villupuram, India; Department of Electronics and Communication Engineering, IFET College of Engineering, Villupuram, India","2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","11 May 2021","2021","","","166","170","Today our whole world is entangled with the most dreadful disease Corona which is caused by the successor of SARS known as SARS-Cov-2 virus. Coronavirus is the influenza-like respiratory disease causing damage to the respiratory system of the humans through the ACE2 receptors which acts as an entry gate for the virus to enter. The Corona virus was identified in late 2019 in the city of Wuhan, China which later spread to the most of the territories in China. The spread was first identified by the Bluedot which is a Saas service designed to track and detect the spread of infectious disease. When the other countries came to know the severity of the virus they made various steps to prevent the spread of the virus. The initial symptoms of coronavirus are rise in temperature, loss of taste and smell and short breathness. As the entry level check many institutions and offices, checks the body temperature of the people and checks whether the person is wearing a mask or not. To make this process fully automatic without human intervention the use of AI enabled IR camera sensor with the Arduino UNO is made. The detection of temperature can be made possible by the use of the computer leveraging vision techniques which is equipped with the Raspberry-pi camera module. The process is based on the thermal imaging of the person which can detect the elevated temperature of the person and prevents them from entering into the institution or offices thereby the spread due to the possibly affected persons can be avoided thereby the spread can be controlled. The system not only identifies the person with high temperature but also checks whether the person is wearing a mask or not. The real time analysis of the system is the major advantage of the proposed system.","","978-1-6654-4086-8","10.1109/WiSPNET51692.2021.9419439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419439","AI enabled IR camera sensors;Arduino;Raspberry-pi camera module;body temperature;contactless temperature detection;real time analysis","Temperature sensors;COVID-19;Wireless communication;Urban areas;Signal processing;Cameras;Coronaviruses","","3","","23","IEEE","11 May 2021","","","IEEE","IEEE Conferences"
"DyReT: A Dynamic Rule Framing Engine Equipped With Trust Management for Vehicular Networks","H. El-Sayed; H. Alexander; M. A. Khan; P. Kulkarni; S. Bouktif","Collage of Information Technology, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates; Collage of Information Technology, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates; Collage of Information Technology, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates; Collage of Information Technology, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates; Collage of Information Technology, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates","IEEE Access","28 Apr 2020","2020","8","","72757","72767","Managing a dynamic traffic system is a challenging task in vehicular environments. Clarity of vehicular data for efficient decision making is vital in Intelligent Transportation Systems (ITS). Huge volumes of vehicular data are collected and processed during vehicular transactions. Pre-processing the huge amounts of raw vehicular data followed by framing effective traffic rules to take appropriate rapid decisions by the ITS on the vehicles continues to be a challenging problem. Most of the current studies done on ITS have proposed decision making strategies to handle only specific vehicular events and many lacked framing intelligent dynamic decision rules along with appropriate actions, representing all traffic events prevailing in the vehicular environment. This study proposes a versatile decision engine implanted with a two-stage mechanism. In the first stage, we propose a novel data cleaning algorithm to identify and remove dirty data from the voluminous vehicular dataset. In the second stage, a unique rule framing mechanism is suggested to frame dynamic traffic rules along with their actions using real-time vehicular data. The vehicular entities take suitable decisions to respond to the traffic events based on these rules and their associated actions. A new Naïve Bayesian classifier is proposed in this study to test the new rule framed with the trained rules set, either to accept or reject the new rule for further processing. The algorithms are developed and implemented using machine learning concepts. Experimental and comparative analysis was carried out with other related referred studies to evaluate the performance of the proposed algorithms. Although the proposed decision engine is generic enough for decision making in most ITS use-cases, discussion in this article elaborates on its applicability in use-cases provisioning trust management.","2169-3536","","10.1109/ACCESS.2020.2987414","Roadway Transportation and Traffic Safety Research Center (RTTSRC) of the United Arab Emirates University(grant numbers:31R151); Abu Dhabi Department of Education and Knowledge (ADEK)(grant numbers:AARE18-114); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064528","Vehicular networks;artificial intelligence;data pre-processing;rule framing;trust management","Vehicle dynamics;Cleaning;Engines;Decision making;Heuristic algorithms;Task analysis","","3","","22","CCBY","13 Apr 2020","","","IEEE","IEEE Journals"
"Trustworthy AI Development Guidelines for Human System Interaction","C. S. Wickramasinghe; D. L. Marino; J. Grandio; M. Manic","Virginia Commonwealth University, Richmond, Virginia; Virginia Commonwealth University, Richmond, Virginia; Virginia Commonwealth University, Richmond, Virginia; Virginia Commonwealth University, Richmond, Virginia","2020 13th International Conference on Human System Interaction (HSI)","17 Jul 2020","2020","","","130","136","Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.","2158-2254","978-1-7281-7392-4","10.1109/HSI49210.2020.9142644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142644","Trustworthy AI;Transparency;Explainable AI;Human System Interactions;Human Machine Interactions;AI Life Cycle","Artificial intelligence;Guidelines;Data models;Organizations;Robustness;Optimization;Testing","","20","","32","IEEE","17 Jul 2020","","","IEEE","IEEE Conferences"
"An AI-based Approach for Grading Students’ Collaboration","B. B. Tomić; A. D. Kijevčanin; Z. V. Ševarac; J. M. Jovanović","Department of Software Engineering, Faculty of Organizational Sciences, University of Belgrade, Belgrade, Serbia; Department of Software Engineering, Faculty of Organizational Sciences, University of Belgrade, Belgrade, Serbia; Department of Software Engineering, Faculty of Organizational Sciences, University of Belgrade, Belgrade, Serbia; Department of Software Engineering, Faculty of Organizational Sciences, University of Belgrade, Belgrade, Serbia","IEEE Transactions on Learning Technologies","15 Jun 2023","2023","16","3","292","305","Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made—something that proved to be very important to teachers.","1939-1382","","10.1109/TLT.2022.3225432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9965596","Automatic assessment tools;collaboration;computer science education;fuzzy systems;machine learning (ML);soft skills","Collaboration;Codes;Software engineering;Measurement;Teamwork;Market research;Electronic mail","","1","","42","IEEE","29 Nov 2022","","","IEEE","IEEE Journals"
"One to Rule them All: A Study on Requirement Management Tools for the Development of Modern AI-based Software","A. -R. Ottun; M. Asadi; M. Boerger; N. Tcholtchev; J. Gonçalves; D. Borovčanin; B. Siniarsk; H. Flores","University of Tartu, Estonia; Vrije Universiteit Brussel, Belgium; Fraunhofer Institute for Open Communication Systems, Germany; Fraunhofer Institute for Open Communication Systems, Germany; Erasmus University Rotterdam, The Netherlands; MAINFLUX LABS, Serbia; University College Dublin, Ireland; University of Tartu, Estonia","2023 IEEE International Conference on Big Data (BigData)","22 Jan 2024","2023","","","3556","3565","Modern system architectures are rapidly adopting AI-based functionality. As a result, new requirements about software trustworthiness must be considered during the entire software development life cycle of applications. While several requirement management tools are available to track and monitor requirements over time, it is still unknown to what extent these tools can cope with these new demands imposed by AI. In this paper, we contribute by performing a qualitative and quantitative analysis of different requirement management tools and their performance in managing AI-related requirements effectively. Through a rigorous analysis performed by a consortium formed by different industry and academic partners, we evaluate the suitability of five different requirement management tools. Our results indicate that while several tools are available for managing requirements, it is currently challenging to find a tool that can manage AI requirements mainly because tools do not comply with the required aspects imposed by regulatory entities. Lastly, we also shared our lessons learned and experiences from selecting requirement tools that can be used in team-based consortium projects.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386926","Requirement Engineering;XAI;AI Applications;Trustworthy AI","Industries;Requirements management;Statistical analysis;Systems architecture;Big Data;Software;Artificial intelligence","","","","40","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App","P. Wang; H. Zare","Department of Computer Information Systems, Robert Morris University, Pittsburgh, USA; Bloomberg School of Public Health, Johns Hopkins University, Baltimore, USA","2023 IEEE Conference on Artificial Intelligence (CAI)","2 Aug 2023","2023","","","296","297","Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.","","979-8-3503-3984-0","10.1109/CAI54212.2023.00132","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195065","AI;healthcare;ethics;privacy;security;risks","Privacy;Ethics;Data privacy;Medical services;Artificial intelligence;Guidelines","","","","14","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Association Rule Mining Based Algorithm for Recovery of Silent Data Corruption in Convolutional Neural Network Data Storage","M. Ramzanpour; S. A. Ludwig","Department of Computer Science, North Dakota State University, Fargo, USA; Department of Computer Science, North Dakota State University, Fargo, USA","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","3057","3064","Embedded systems are finding their way into almost every aspects of our daily life from mp3 players and console games to the mobile phones. Different Artificial Intelligence (AI) based applications are commonly utilized in embedded systems from which computer vision based approaches are included. The demand for higher accuracy in computer vision applications is associated with the increased complexity of convolutional neural networks and the storage requirement for saving pre-trained networks. Different factors can lead to the data corruption in the storage units of the embedded systems, which can result in drastic failures due to the propagation of the errors. Hence, the development of software-based algorithms for the detection and recovery of data corruption is crucial for improvement and failure-prevention of embedded systems. This paper proposes a new algorithm for the recovery of the data in the case of single event upset (SEU) error. The association rule mining based algorithm will be used to find the probability of the corruption in each of the bits. The recovery algorithm was tested on four different pre-trained ResNet (ResNet32 and ResNet110 at two different accuracy levels each) and the best recovery rate of 66% was found in the most complex scenario, i.e., random bit corruption. However, for the special cases of SEU errors, e.g. error in the frequently repeated bits, the recovery rate was found to be perfect with a value of 100%.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308545","Single event upset;Silent data corruption;Association rule mining;Recovery algorithm","Computer architecture;Single event upsets;Prediction algorithms;Embedded systems;Kernel;Data mining;Computer vision","","2","","28","IEEE","5 Jan 2021","","","IEEE","IEEE Conferences"
"An AI based High-speed Railway Automatic Train Operation System Analysis and Design","M. Zhang; Q. Zhang; Y. Lv; W. Sun; H. Wang","The Center of National Railway Intelligent Transportation System Engineering and Technology, China Academy of Railway Sciences Corporation Limited, Beijing, China; The Center of National Railway Intelligent Transportation System Engineering and Technology, China Academy of Railway Sciences Corporation Limited, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation Chinese Academy of Sciences, Beijing, China; The Center of National Railway Intelligent Transportation System Engineering and Technology, China Academy of Railway Sciences Corporation Limited, Beijing, China; The Center of National Railway Intelligent Transportation System Engineering and Technology, China Academy of Railway Sciences Corporation Limited, Beijing, China","2018 International Conference on Intelligent Rail Transportation (ICIRT)","14 Feb 2019","2018","","","1","5","Recent years, the research and application of High-Speed Railway (HSR) automatic train operation (ATO) system are under fast development, while the safety, energy efficiency and passenger comfort of ATO systems still need improvement. On the other hand, Artificial Intelligence (AI) technology, for example, Deep Learning, has been widely applied in automata industry such as robot control and driverless vehicle. In this paper, we propose a new idea of improving train control system performance with AI technologies such as Deep Reinforcement Learning and Imitation learning, and describe the system objective, structure and development process. The details of key processes such as establishment of Train Running Condition Evaluation Index, acquisition and processing of relevant big data, construction of AI based automatic train operation model and the program of simulation and experiment are presented in this paper, which provides a brand new and practical idea to the development of High-Speed Railway automatic train operation systems.","","978-1-5386-7528-1","10.1109/ICIRT.2018.8641650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8641650","Artificial Intelligence;ATO;Deep Reinforcement Learning;HSR;Imitation Learning","Rail transportation;Safety;Training;Control systems;Reinforcement learning;Big Data","","10","","24","IEEE","14 Feb 2019","","","IEEE","IEEE Conferences"
"Legal Document Summarization Using Ripple Down Rules","S. A. Takale; S. A. Thorat; R. S. Sajjan","Department of Information Tech., VPKBIET, Baramati; Department of Computer Engineering, Government COE & R Avasari, Pune; Department of CSE, School of Computing, MIT ADT, Pune","2022 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)","19 Jun 2023","2022","","","78","83","This paper presents an approach for legal document summarization using Ripple Down Rules(RDR). RDR is an Artificial Intelligence(AI) based approach and an alternative technique to Machine Learning(ML) algorithms for incrementally building the knowledge base. In this implementation, we have used RDR to develop an improving and increasing knowledge base of classification rules for assigning rhetorical role labels to the sentences in a legal document. The RDR rules for classification are developed using a set of syntactic, semantic and statistical features at word, sentence and document level. For each sentence in the legal document we have assigned an rhetorical role with the help of Ripple Down Rule. We have generated the final summary using the identified thirteen rhetorical roles. The proposed system is evaluated using 50 legal documents from four different domains. Experiments demonstrate that the RDR based Legal Document summarization approach has advantages over supervised and unsupervised ML techniques such as, independence from the need of annotated dataset and continuous updation of classification rules for rhetorical role labeling with the help of expert knowledge.","","979-8-3503-1156-3","10.1109/WIECON-ECE57977.2022.10150974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10150974","Summarization;Machine Learning;Artificial Intelligence;Natural Language Processing;Rhetorial Roles;Ripple Down Rules","Performance evaluation;Machine learning algorithms;Law;Knowledge based systems;Semantics;Buildings;Syntactics","","","","23","IEEE","19 Jun 2023","","","IEEE","IEEE Conferences"
"AI-based Automatic Activity Recognition of Single Persons and Groups During Brainstorming","S. Fujita; T. Gidel; Y. Kaeri; A. Tucker; K. Sugawara; C. Moulin","Faculty of Information and Computer Science, Chiba Institute of Technology, Chiba-ken, Japan; Université de Technologie de Compiègne, Sorbonne Universités, France; Department of Media Studies, Faculty of Media Studies, Mejiro University, Tokyo, Japan; Center for Research in Education, Université de Lille, France; Faculty of Information and Computer Science, Chiba Institute of Technology, Chiba-ken, Japan; Université de Technologie de Compiègne, Sorbonne Universités, Heudiasyc, France","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","3782","3787","In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person’s motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person’s activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students’ work sessions.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9282981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282981","Human-Machine Systems;Human-Machine Cooperation & Systems;Multi-user Interaction;Team Performance and Training Systems","Deep learning;Training;Tracking;Collaboration;Streaming media;Brain modeling;Video recording","","","","17","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"A Review of Potential AI-Based Automation for IoT-Enabled Smart Homes","Y. M. Leong; E. H. Lim; L. K. Lim","Faculty of Computing and Engineering, Quest International University, Ipoh, Malaysia; Faculty of Information and Communication Technology, Universiti Tunku Abdul Rahman, Ipoh, Malaysia; School of Computing, Newcastle University, Newcastle, United Kingdom","2023 IEEE 13th International Conference on System Engineering and Technology (ICSET)","30 Oct 2023","2023","","","1","6","The Internet of Things (IoT) has brought significant changes in the way we interact with technology in our homes. Smart homes equipped with IoT devices offer a comfortable and convenient lifestyle. However, managing these devices and their operations can be challenging, especially for individuals with limited technical expertise. The integration of artificial intelligence (AI) in IoT-based smart homes can potentially overcome these challenges by automating device management and enabling proactive responses to users’ needs. This paper investigates the potential of AI-based automation for IoT-enabled smart homes. We review the literature on AI-based automation and IoT-based smart homes, highlighting their benefits, challenges, and existing solutions. The research methodology used in this study is through deep learning approach. The results indicates that AI-based automation can improve user experience and enhance the efficiency and effectiveness of IoT-based smart homes. However, some technical and ethical challenges, such as privacy and security concerns, need to be addressed.","2470-640X","979-8-3503-4089-1","10.1109/ICSET59111.2023.10295156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10295156","IoT;Smart homes;AI;Automation","Technological innovation;Privacy;Automation;Heuristic algorithms;Smart homes;Transforms;User experience","","","","41","IEEE","30 Oct 2023","","","IEEE","IEEE Conferences"
"Run-Time Safety Monitoring Framework for AI-Based Systems: Automated Driving Cases","M. H. Osman; S. Kugele; S. Shafaei","Department of Software Engineering & Information Systems, University Putra Malaysia, Serdang, Malaysia; Department of Computer Science, Technical University of Munich, Munich, Germany; Department of Computer Science, Technical University of Munich, Munich, Germany","2019 26th Asia-Pacific Software Engineering Conference (APSEC)","2 Jan 2020","2019","","","442","449","Intelligent systems based on artificial intelligence techniques are increasing and are recently being accepted in the automotive domain. In the competition of automobile makers to provide fully automated vehicles, it is perceived that artificial intelligence will profoundly influence the automotive electric and electronic architecture in the future. However, while such systems provide highly advanced functions, safety risk increases as AI-based systems may produce uncertain output and behaviour. In this paper, we devise a run-time safety monitoring framework for AI-based intelligence systems focusing on autonomous driving functions. In detail, this paper describes (i) the characteristics of a safety monitoring framework; (ii) the safety monitoring framework itself, and (iii) we develop a prototype and implement the framework for two critical driving functions: Lane detection and object detection. Through an implementation of the framework to a prototypic control environment, we show the possibility of this framework in the real context. Finally, we discuss the techniques used in developing the safety monitoring framework and describes the encountered challenges.","2640-0715","978-1-7281-4648-5","10.1109/APSEC48747.2019.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945611","System Safety, Run time Safety Monitoring, Autonomous Driving, Artificial Intelligence","Monitoring;Hazards;Software;Anomaly detection;ISO Standards;Automotive engineering","","5","","26","IEEE","2 Jan 2020","","","IEEE","IEEE Conferences"
"AI based Impact of COVID 19 on food industry and technological approach to mitigate","R. M. Rawat; A. Rana; A. J. Toppo; A. Beck","Department of Computer Science & Engineering, Delhi Technological University, Delhi, India; Department of Computer Science & Engineering, Delhi Technological University, Delhi, India; Department of Computer Science & Engineering, Delhi Technological University, Delhi, India; Department of Computer Science & Engineering, Delhi Technological University, Delhi, India","2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)","26 May 2021","2021","","","1743","1748","The food industry or the restaurant business has always been one of the most profitable and growing businesses. As technology is evolving day by day and to sustain itself in the food industry the restaurant needs to come up with new and innovative services which they can provide to the customers. Pandemic has made a major impact on the business of the restaurant industry in 2020. This paper will help to understand how technology can help in food ordering, while taking care of the COVID-19 pandemic guidelines. The purpose of this paper is to analyze the impact of COVID-19 in the food industry and suggest methods that would help restaurants to adapt to challenges that originate from COVID-19. One of the ways would be to automate the food ordering process. Our Project “Contactless food ordering system” is a mobile application operated by a voice assistant. That the client (The Restaurant Customer) can use to scan through the restaurant menu and view various food categories and items like “Starter” “Drinks” etc. and place their order through the Application. They can modify and confirm their order, as well as make their payment. The aim of the study is to reduce the point of contact during COVID-19 and automate the ordering and billing process, simplifying the work. Thus, providing a totally computerized, automated, and scalable food ordering system that will assist the business by reducing their workload, provide better management and smooth operation. The restaurant can also use various other means to increase their presence as a business.","","978-1-6654-1272-8","10.1109/ICICCS51141.2021.9432152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432152","Food Industry;COVID-19;Automated System;Digital Marketing;Artificial intelligence;Voice assistant;Supply Chain","COVID-19;Industries;Pandemics;Food industry;Human factors;Control systems;Social factors","","2","","16","IEEE","26 May 2021","","","IEEE","IEEE Conferences"
"AI Based Approach For Path Traversal","S. Ranjan; P. Vasisht; D. Thakral","School of Engineering and Technology, Apeejay Stya University, Gurugram, India; School of Engineering and Technology, Apeejay Stya University, Gurugram, India; School of Engineering and Technology, Apeejay Stya University, Gurugram, India","2022 International Conference on Smart and Sustainable Technologies in Energy and Power Sectors (SSTEPS)","22 May 2023","2022","","","178","181","The manuscript intends to provide holistic overview of AI based forward traversal path and backward traversal path. These path are obtained from a collection of web accesses, once the user session are identified. The proposed work contains an alternative approach to generate path traversal and reduced the forward and backward traversal Path.","","978-1-6654-6414-7","10.1109/SSTEPS57475.2022.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10125529","Artificial Intelligence (AI);Transaction minimization algorithm;Path Traversal","Clustering algorithms;Minimization;Artificial intelligence","","","","14","IEEE","22 May 2023","","","IEEE","IEEE Conferences"
"Dynamic Network Provisioning with AI-enabled Path Planning","H. -N. Quach; C. Choi; K. Kim","Department of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea; Department of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea; Department of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea","2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)","23 Oct 2020","2020","","","271","274","As the number of mobile devices increases and the concept of 5G networks becomes popular, various network infrastructures and services emerge. Also, more users request user-specific network services within limited network resources. Under this complex situation, in order to provide a guaranteed QoS level to users, it requires to consider various factors which affect the performance of network service, and dynamic network provisioning is required. In this paper, we propose a dynamic network provisioning system with AI-enabled path planning, which uses the side channel information such as disaster events, maintenance events, and distribution of users. In this system, we design a user request handler that understands user-specific QoS and spatio-temporal requirements in order to maximize the utilization of a given network resource. Also, this system utilizes side-channel information to optimizing the network provisioning in a realtime manner.","2576-8565","978-89-950043-8-8","10.23919/APNOMS50412.2020.9236957","Basic Science Research Program through the National Research Foundation of Korea(NRF); Ministry of Science, ICT & Future Planning(grant numbers:NRF-2017R1A2B4012559); MSIT(Ministry of Science and ICT), Korea; ITRC(Information Technology Research Center)(grant numbers:IITP-2020-20 16-0-00314); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9236957","Software-defined Networking;Q-routing;network provisioning;Artificial Intelligence;location-aware network;bandwidth demand constraints","Databases;Quality of service;Bandwidth;Network topology;Topology;Planning;Delays","","2","","7","","23 Oct 2020","","","IEEE","IEEE Conferences"
"Enhanced Interoperating Mechanism Between OneM2M and OCF Platform Based on Rules Engine and Interworking Proxy in Heterogeneous IoT Networks","N. A. Tuan; R. Xu; D. Kim","Department of Computer Engineering, Jeju National University, Jeju, South Korea; Big Data Research Center, Jeju National University, Jeju, Republic of Korea; Department of Computer Engineering, Jeju National University, Jeju, South Korea","IEEE Access","22 Feb 2023","2023","11","","16096","16107","In recent years, the Internet of Things (IoT) is growing rapidly and is being applied in a variety of industries including healthcare, smart homes, and smart cities. Many standard IoT platforms are proposed to connect and communicate with IoT devices easily and securely such as oneM2M, Google Weave and Apple HomeKit. However, this makes IoT application development difficult as it requires IoT devices and applications to support multiple protocols to connect different IoT platforms. Therefore, it is necessary to provide a consistent schema to support interoperability in heterogeneous IoT networks. In this paper, we propose how to design and implement interoperating schema between two edge servers oneM2M and Open Connectivity Foundation (OCF) with heterogeneous IoT devices. Specifically, we build proxies for bridging oneM2M Mobius edge server and OCF IoTivity edge server. The sensor data is collected from various IoT devices and sent to an edge server with a compatible platform. Next, the data stored in each server will be exchanged with the other server through a proposed interworking proxy. We also use a rules engine to automatically identify registered devices to support edge server interaction within the same domain and across domains. In addition, we build a web application in each edge server to provide friendly IoT services (data visualization) to clients from different environments. In order to evaluate our system, we collect the delay time of each process in the edge servers. The results show that our proposal is completely applicable in practice.","2169-3536","","10.1109/ACCESS.2023.3236412","Institute for Information & Communications Technology Pro-motion (IITP) (Cooperative Intelligence Framework of Scene Perception for Autonomous IoT Devices)(grant numbers:2022-0-00980); Institute for Information & Communications Technology Promotion (IITP) (Open-source development and standardization for AI-enabled IoT platforms and interworking)(grant numbers:2021-0-00188); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10015747","Internet of Things;interoperability;oneM2M standard;open connectivity foundation;rules engine;interworking proxy;hypertext transfer protocol;constrained application protocol","Internet of Things;Servers;Standards;Engines;Interoperability;Cloud computing;Hypertext systems","","2","","49","CCBY","12 Jan 2023","","","IEEE","IEEE Journals"
"Dependency on AI-Based Writing Tools in English Learning: Implications for Human-Computer Interaction","A. Zunaidah; C. K. Wiharja; M. A. Febriantono","Communication Science Department, Digital Language Center, Faculty of Humanities, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Digital Language Center, Faculty of Humanities, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia","2023 International Conference on Information Management and Technology (ICIMTech)","17 Oct 2023","2023","","","1","6","This study investigates the reliance of English learners on AI-based writing tools and the repercussions for human-computer interaction (HCI). Through survey and interview administered to a sample of English learners, this study investigates their reliance on AI tools, its impact on their writing skills, and their attitudes toward these technologies. The results disclose a significant reliance on AI tools among participants, with the majority relying on them for writing assignments and having doubts about their writing ability without them. The findings emphasize the potential benefits of AI tools for enhancing learners' writing skills and boosting their confidence. However, they also raise concerns about overdependence, decreased participation in face-to-face learning, and addiction to these technologies. The research highlights the need for a balanced incorporation of AI tools in language learning. The study contributes to the field of Human-Computer Interaction (HCI) by providing insights into user experiences and promoting informed decision-making regarding the incorporation of AI-based writing tools in language learning contexts.","2837-2778","979-8-3503-2609-3","10.1109/ICIMTech59029.2023.10278054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10278054","AI-based writing tools;dependency;english learning;Human-computer interaction","Human computer interaction;Training;Surveys;Limiting;Addiction;Writing;Information management","","","","24","IEEE","17 Oct 2023","","","IEEE","IEEE Conferences"
"Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety","A. Sheth; M. Gaur; K. Roy; R. Venkataraman; V. Khandelwal","University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA","IEEE Internet Computing","13 Sep 2022","2022","26","5","76","84","AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.","1941-0131","","10.1109/MIC.2022.3182349","National Science Foundation(grant numbers:2133842); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889132","","Performance evaluation;Mental health;Machine learning;Safety;Diabetes;Artificial intelligence;User centered design","","4","","15","IEEE","13 Sep 2022","","","IEEE","IEEE Magazines"
"AI Empowered Quantitative Evaluation Method for Handwritten Chinese Character","J. Shu; C. Zhu; S. Shi; W. Ma; J. Li; S. Lu","National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China; National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China; National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China; National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China; National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China; National Engineering Research Center of Educational Big Data, Central China Normal University, Wuhan, China","2023 International Conference on Intelligent Education and Intelligent Research (IEIR)","16 Jan 2024","2023","","","1","6","In order to solve the problems of untimely evaluation, unspecific and ineffective feedback for writers and to improve writing quality in the daily standardized Chinese character writing practice of primary and secondary school students, a quantitative evaluation method for paper-pen handwritten standardized Chinese character based on neural network is proposed in this paper. It takes handwritten Chinese character by paper-pen writing as the evaluation object, and obtains the quantitative features of Chinese character through feature extraction of handwritten Chinese character image samples. On this basis, CNN classifier is used to complete the classification of handwritten Chinese character images. Then, based on the Gaussian distribution to fit the writing feature values of excellent samples, strict and loose normative interval thresholds are obtained. Finally, the deviation between the quantitative features of handwritten Chinese characters and the threshold is calculated, to realize the general quality evaluation and the detailed quantitative evaluation of strokes.","","979-8-3503-4289-5","10.1109/IEIR59294.2023.10391219","National Natural Science Foundation of China; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10391219","paper-pen handwritten Chinese character;quantitative evaluation;Chinese character model;CNN","Neural networks;Education;Writing;Gaussian distribution;Feature extraction;Artificial intelligence","","","","16","IEEE","16 Jan 2024","","","IEEE","IEEE Conferences"
"AI-enabled Multi-modal Network Anomaly Association: A Deep Self/Semi-Supervised Learning Approach","Y. Tang; Y. Zhang; Z. Yin; J. Deng; F. Li; Y. Cui; X. Zhang",Huawei Technologies Co. Ltd.; Huawei Technologies Co. Ltd.; Huawei Technologies Co. Ltd.; Huawei Technologies Co. Ltd.; Huawei Technologies Co. Ltd.; Tsinghua University; Huawei Technologies Co. Ltd.,"ICC 2022 - IEEE International Conference on Communications","11 Aug 2022","2022","","","4068","4073","In nowadays large-scale networks, it is challenging for network operation and maintenance systems to analyze the reported massive network anomaly information. To handle this problem, we proposed a deep multi-modal learning approach called multi-modal anomaly root cause analysis, which enables network operation and maintenance systems to automatically and effectively associate the related network anomalies that appear from different modalities or aspects, and then locate the root causes. As a self/semi-supervised approach, our proposal is capable of realizing self-learning, self-adapting, and does not rely on a large number of manual annotations. According to the experimental results in a real large-scale network, without any annotations, our approach achieves up to 14% accuracy improvement in terms of multi-modal network anomaly association and root cause locating compared to the classical association rule mining algorithm Apriori, while its performance turns even much better when a few of labeled training samples are provided. The experiment also well proves the versatility and self-adaptability of our approach, which means our learning-based approach is able to not only achieve fast convergence but also automatically adapt itself to network changes.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9839022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839022","network anomaly association;network operation and maintenance;root cause analysis;deep multi-modal learning","Training;Measurement;Root cause analysis;Annotations;Training data;Manuals;Maintenance engineering","","","","20","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"AI-based botnet attack classification and detection in IoT devices","V. Puri; A. Kataria; V. K. Solanki; S. Rani","Center of Visualization and Simulation, Duy Tan University, Da Nang, Vietnam; CSIR-CSIO, Chandigarh, India; Dept. of Computer Science and Engineering, CMR Institute of Technology, Hyderabad, TS, India; Dept. of Computer Science and Engineering, Guru Nanak Dev Engineering College, Ludhiana, Punjab, India","2022 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT)","2 Jan 2023","2022","","","1","5","End-user Internet of Things (IoT) devices, including security cameras, smart appliances, home monitors, and thermostats, are becoming more prevalent in households. Additionally, the proliferation of devices facilitates the propagation of security concerns like DoS and spoofing. However, it is difficult for conventional rule-based security systems to recognize IoT assaults due to the development of heterogenous devices in the IoT ecosystem. Artificial Intelligence (AI) techniques can be a solution which enables the creation of an effective security model based on actual data from each device. In this work, IoT botnets are detected and classified using machine learning (ML) and deep learning (DL) based algorithms. Six ML models and three DL models are used to assess the system's performance. The best-performing model is also implemented as an API.","","978-1-6654-8701-6","10.1109/ICMLANT56191.2022.9996464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996464","IoT;AI;botnet;gadgets;API;machine learning models;deep learning models","Deep learning;Home appliances;Machine learning algorithms;Botnet;System performance;Ecosystems;Internet of Things","","4","","15","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"AI-Based Localization and Classification of Visual Anomalies on Semiconductor Devices","M. K. Le; J. Z. J. Chia; D. Peskes","Elmos Semiconductor SE, Dortmund, Germany; Elmos Semiconductor SE, Dortmund, Germany; Elmos Semiconductor SE, Dortmund, Germany","2023 IEEE International Conference on Electro Information Technology (eIT)","25 Jul 2023","2023","","","122","126","This paper presents an AI-based system for automated visual inspection of semiconductor components, aimed at improving the Zero-Defect strategy in their manufacturing process. The system leverages unsupervised learning using Variational Autoencoder to learn and compare images of undamaged components to identify anomalies. An anomaly score is devised to enable detection of even minor flaws on the edges of components and decision rules are evaluated using appropriate metrics. The proposed system surpasses the current tape machine in detecting anomalies, hence contributing to achieving the Zero-Defect strategy in semiconductor manufacturing.","2154-0373","978-1-6654-9376-5","10.1109/eIT57321.2023.10187356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10187356","","Integrated circuits;Performance evaluation;Visualization;Semiconductor device measurement;Manufacturing processes;Semiconductor devices;Quality control","","","","12","IEEE","25 Jul 2023","","","IEEE","IEEE Conferences"
"Hybrid Crowd-AI Learning for Human-Interpretable Symbolic Rules in Image Classification","A. Shimizu; K. Wakabayashi; M. Matsubara; H. Ito; A. Morishima","University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan; University of Tsukuba, Tsukuba, Japan","2023 14th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","29 Dec 2023","2023","","","263","270","Explainable AI is an indispensable goal for an AI-based society with trust, and deriving human-interpretable symbolic rules is one of the promising ways to verify whether the decision is appropriate. This paper explores a hybrid crowd-AI approach to develop white-box ML models associated with human-interpretable symbolic rules. The key idea of the proposed method is to discover human-interpretable latent features from trained neural networks by leveraging human abductive reasoning. The proposed method automatically generates crowdsourcing tasks that display subsets of images corresponding to each latent feature and ask crowd workers to provide the semantics of the features in natural language. The obtained semantics allow us to use the latent features as human-interpretable predicates that form symbolic rules to define target classes. We provide experimental results showing that the proposed approach can obtain interpretable symbolic rules and explanations.","2472-0070","979-8-3503-2422-8","10.1109/IIAI-AAI59060.2023.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371633","XAI;Human-in-the-loop;Image Classification","Semantics;Natural languages;Neurons;Cognition;Data mining;Task analysis;Informatics","","","","23","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"Towards Productizing AI/ML Models: An Industry Perspective from Data Scientists","F. Lanubile; F. Calefato; L. Quaranta; M. Amoruso; F. Fumarola; M. Filannino","University of Bari, Bari, Italy; University of Bari, Bari, Italy; University of Bari, Bari, Italy; Prometeia, Milano, Italy; Prometeia, Milano, Italy; Prometeia, Milano, Italy","2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI (WAIN)","8 Jul 2021","2021","","","129","132","The transition from AI/ML models to production-ready AI-based systems is a challenge for both data scientists and software engineers. In this paper, we report the results of a workshop conducted in a consulting company to understand how this transition is perceived by practitioners. Starting from the need for making AI experiments reproducible, the main themes that emerged are related to the use of the Jupyter Notebook as the primary prototyping tool, and the lack of support for software engineering best practices as well as data science specific functionalities.","","978-1-6654-4470-5","10.1109/WAIN52551.2021.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474371","AI/ML models;data science;Jupyter notebooks;data products","Conferences;Computational modeling;Companies;Tools;Data science;Data models;Software","","7","","8","IEEE","8 Jul 2021","","","IEEE","IEEE Conferences"
"Efficiency Improvement to Neural-Network-Driven Optimal Path Planning via Region and Guideline Prediction","Y. Huang; C. -T. Tsao; H. -H. Lee","Graduate School of Information, Production and Systems, University of Waseda, Kitakyushu, Japan; Graduate School of Information, Production and Systems, University of Waseda, Kitakyushu, Japan; Graduate School of Information, Production and Systems, University of Waseda, Kitakyushu, Japan","IEEE Robotics and Automation Letters","16 Jan 2024","2024","9","2","1851","1858","Traditional sampling-based algorithms rely on random samples to explore a whole configuration space of robots for optimal path planning, while a uniform sampler impedes the exploration with randomly generated samples, leading to a long calculation time, especially in complex environments. Recently, neural-network-driven methods have attracted wide interest in developing non-uniform sampling to improve the sampling efficiency and reduce the calculation time. A region that contains an optimal path is predicted by neural networks and employed subsequently to biasedly generate samples. This work aims at enhancing the sampling efficiency and reducing the calculation time of the optimal path planning by a novel region and guideline prediction (denoted as RGP) model. We innovatively propose the RGP model with a guideline prediction module to estimate the guideline distributions, which are characterized by the central line of the predicted region. The predicted region and guideline are integrated into a sampling-based algorithm, namely RGP-RRT*, with an adaptively biased sampling strategy to select a proper domain for sampling. Simulations demonstrate the RGP model outperforms other region prediction models in accuracy and robustness. Besides, the RGP-RRT* reliably achieves a 7.2–80.1% reduction in calculation time and a 2.0–58.1% reduction in sample number compared with other neural-network-driven methods.","2377-3766","","10.1109/LRA.2024.3350979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10382594","Motion and path planning;AI-based methods","Path planning;Guidelines;Predictive models;Prediction algorithms;Convolution;Adaptation models;Space exploration","","","","21","IEEE","8 Jan 2024","","","IEEE","IEEE Journals"
"AIFIS: Artificial Intelligence (AI)-Based Forensic Investigative System","R. Alnafrani; D. Wijesekera","Cyber Security Engineering Department, George Mason University, Fairfax, VA, USA; Cyber Security Engineering Department, George Mason University, Fairfax, VA, USA","2022 10th International Symposium on Digital Forensics and Security (ISDFS)","22 Jun 2022","2022","","","1","6","The scope of forensic investigations has recently expanded. Since most Internet of Things (IoT) devices are plug and play and do not have much memory or storage to pre-process data, it is a challenge for forensic investigators to identify and obtain relevant evidence to reconstruct attacks. As a solution, we propose using artificial intelligence (AI)-inspired techniques to automate the forensic analysis process by emulating attacks in the process of identifying and collecting forensic evidence. We used a differentiable inductive logic programming (∂ILP) system to obtain attack emulation information from different sources, such as device- and subsystem-level vulnerabilities gathered by assessing device components in an enterprise network, and to predict potential attacks from previous attacks on similar configurations. Our experimental results showed that the proposed methodology could successfully generate rules that can assist forensic examiners in identifying evidence to emulate attacks without execution.","","978-1-6654-9796-1","10.1109/ISDFS55398.2022.9800801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9800801","∂ILP;digital forensics;forensic investigation;artificial intelligence;IoT","Logic programming;Forensics;Emulation;Digital forensics;Internet of Things;Security;Object recognition","","","","23","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Study of NMT: An Explainable AI based approach","G. Datta; N. Joshi; K. Gupta","Dept. of Mathematical and Computer Science, Banasthali Vidyapeeth, Bansthali, Rajasthan, India; Dept. of Mathematical and Computer Science, Banasthali Vidyapeeth, Bansthali, Rajasthan, India; Dept. of Mathematical and Computer Science, Banasthali Vidyapeeth, Bansthali, Rajasthan, India","2021 5th International Conference on Information Systems and Computer Networks (ISCON)","14 Feb 2022","2021","","","1","4","Machine translation (MT) which translates source to the target language is a challenging task. It is one of the important area under Natural language Processing (NLP).These days we are having neural based translation system viz. Neural Machine Translation (NMT). In this study we have discussed some of the important architecture of NMT systems and their working in brief. NMT uses deep neural network frame work in its design. Deep neural network based machine learning (ML) approach is entirely black box for end user. NMT requires several hyper parameter tuning during training. We still don't get any satisfactory answer of why we are getting any specific result (output) with specific set of linguistic features and the hyper parameters that are tuned. We have tried to focus on this aspect with very recent concept in AI i.e. explainable AI (XAI). XAI, can interpret and explain the internal behavior of model's architecture which can provide us reasons (explanation) when we get any result (output) from our model. We have discussed some of the techniques such as LIME, SHAPELY, Seq-2-Seq-Vis, LSTM-Vis which are widely used by data scientists and incorporate them in ML pipeline to design an unbiased, robust and accurate model.","","978-1-6654-0341-2","10.1109/ISCON52037.2021.9702396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9702396","Neural machine translation;Sequence to Sequence model;Explainable AI;LSTM- Vis;Seq-to-seq-Vis","Deep learning;Training;Computational modeling;Neural networks;Pipelines;Computer architecture;Linguistics","","2","","16","IEEE","14 Feb 2022","","","IEEE","IEEE Conferences"
"Autonomous Decision-Making With Incomplete Information and Safety Rules Based on Non-Monotonic Reasoning","J. -L. Vilchis-Medina; K. Godary-Déjean; C. Lesire","ONERA/DTIS, University of Toulouse, Toulouse, France; LIRMM/EXPLORE, University of Montpellier, Montpellier, France; ONERA/DTIS, University of Toulouse, Toulouse, France","IEEE Robotics and Automation Letters","9 Sep 2021","2021","6","4","8357","8362","In this article we propose a decision process integrating Non-Monotonic Reasoning (NMR), embedded in a deliberative architecture. The NMR process uses Default Logic to implement goal reasoning, managing partially observable or incomplete information, allowing the design of default behaviours completed by the handling of specific situations, in order to manage the current mission objective as well as safety rules. We illustrate our approach through an application of an underwater robot performing a marine biology mission.","2377-3766","","10.1109/LRA.2021.3103048","I-Site MUSE of the University of Montpellier; Agence Nationale de la Recherche(grant numbers:ANR-16-IDEX-0006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511268","AI-based methods;formal methods in robotics and automation;cognitive control architectures;marine robotics","Cognition;Robots;Safety;Nuclear magnetic resonance;Planning;Robot sensing systems;Uncertainty","","2","","24","IEEE","10 Aug 2021","","","IEEE","IEEE Journals"
"Massive AI based cloud environment for smart online education with data mining","Y. Pei; G. Li","Xi'an Siyuan University, Xi'an, Shaanxi, China; Xi'an Thermal Power Research Institute Co., Ltd, Xi'an, Shaanxi, China","2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)","26 May 2021","2021","","","1115","1118","Under the background of the deep integration of Internet technology and artificial intelligence technology with the field of education, the traditional teacher centered teaching mode is facing a historic change. How to guide students to learn and communicate actively, and explore and improve the new student-centered teaching mode, has become the key problem to be solved. In the mixed cloud environment, the data stream is disturbed, and the error of mining association data is large. Aiming at the problem of poor anti-interference of scattered point cloud adaptive compression mining algorithm, this paper analyzes the data mining technology in cloud environment. Firstly, the time series analysis model of big data information flow in hybrid cloud environment is constructed to analyze the data structure, and then the high-dimensional phase space of data information flow in hybrid cloud environment is reconstructed. In the reconstructed phase space, the association rules are extracted, and the extracted features are used as pheromones to guide data location mining, so as to improve the data mining algorithm.","","978-1-6654-1272-8","10.1109/ICICCS51141.2021.9432201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432201","Online Education;Artificial Intelligence;Deep Learning;Cloud Computing;Data Mining","Cloud computing;Analytical models;Three-dimensional displays;Education;Time series analysis;Big Data;Feature extraction","","1","","24","IEEE","26 May 2021","","","IEEE","IEEE Conferences"
"Knowledge-Intensive Language Understanding for Explainable AI","A. Sheth; M. Gaur; K. Roy; K. Faldu","University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; University of South Carolina, Columbia, SC, USA; Embibe, Inc., Bengaluru, India","IEEE Internet Computing","8 Oct 2021","2021","25","5","19","24","AI systems have seen significant adoption in various domains. At the same time, further adoption in some domains is hindered by the inability to fully trust an AI system that it will not harm a human. Besides, fairness, privacy, transparency, and explainability are vital to developing trust in AI systems. As stated in Describing Trustworthy AI,aa.https://www.ibm.com/watson/trustworthy-ai. “Trust comes through understanding. How AI-led decisions are made and what determining factors were included are crucial to understand.” The subarea of explaining AI systems has come to be known as XAI. Multiple aspects of an AI system can be explained; these include biases that the data might have, lack of data points in a particular region of the example space, fairness of gathering the data, feature importances, etc. However, besides these, it is critical to have human-centered explanations directly related to decision-making, similar to how a domain expert makes decisions based on “domain knowledge,” including well-established, peer-validated explicit guidelines. To understand and validate an AI system's outcomes (such as classification, recommendations, predictions) that lead to developing trust in the AI system, it is necessary to involve explicit domain knowledge that humans understand and use. Contemporary XAI methods are yet addressed explanations that enable decision-making similar to an expert. Figure 1 shows the stages of adoption of an AI system into the real world.","1941-0131","","10.1109/MIC.2021.3101919","National Science Foundation(grant numbers:2133842); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514440","","Artificial intelligence;Task analysis;Computational modeling;Deep learning;Decision making;Knowledge discovery;Human computer interaction","","10","","15","IEEE","16 Aug 2021","","","IEEE","IEEE Magazines"
"Performance and Endurance Training for Equine Racing (PETER)","Y. Al Tawil; W. Mansoor; S. Atalla; H. Mukhtar; K. F. Bin Hashim; S. Miniaoui","College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates; College of Engineering and IT, University of Dubai, Dubai, United Arab Emirates","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","1259","1262","Leveraging the Internet of Things (IoT) technologies into farming domains contribute significantly in more productive and sustainable farming activities. The concept of Smart stable depends on smart devices with the Internet connection to monitor and control the stable system and its animals. This paper proposes this method to provide the farmer and the horse trainer with an automated process to perform their daily activities to take better decisions or more efficient exploitation operations and management. In addition to that, the proposed system with being powered with artificial intelligence (AI) component able to absorb new horse health status updates then combines it with knowledge learned from historical records to predict the horse readiness for participating in training or real race sessions. The system equipped with sensors to detect physical data from the real world such as the speed of the horse, temperature, heartbeats, recovery time. Gathered data flows feed an advanced visualization dashboard based on Kibana, while another branch of data flow feeds the AI component.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060347","IoT, Smart Farming, AI","Horses;Artificial intelligence;Temperature sensors;Monitoring;Internet of Things;Heart rate","","","","5","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"AI Based Monitoring System for Social Engineering","K. Yapa; S. W. I. Udara; U. P. B. Wijayawardane; K. N. P. Kularatne; N. M. P. P. Navaratne; W. G. V. U. Dharmaphriya","Dept. of Computer System Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Dept. of Computer System Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Dept. of Computer System Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Dept. of Computer System Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Dept. of Computer System Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Dept. of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka","2021 3rd International Conference on Advancements in Computing (ICAC)","11 Jan 2022","2021","","","264","269","Social media is one of the most predominantly used online platforms by individuals across the world. However, very few of these social media users are educated about the adverse effects of obliviously using social media. Therefore, this research project, is to develop an advisory system for the benefit of the general public who are victimized by the adverse impacts of their ignorant and oblivious behavior on social media. The system was implemented using a decision tree model with the use of customized datasets; and for the proceeding operational implementations, Python programming language, Pandas, Natural Language Processing and TensorFlow were used. This advisory system can monitor user behaviors and generate customized awareness reports for the users based on category and level of their behaviors on social media. Furthermore, the system is also capable of generating graph reports of the use behavior fluctuations for the reference of the user. With the help of these customized awareness reports and the graph reports, the users can identify their potential vulnerabilities and improve their social media habits.","","978-1-6654-0862-2","10.1109/ICAC54203.2021.9671218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671218","Awareness Report;Cyber-Crimes;Graph Report;Natural Language Processing;Social Engineering;Social Media","Fluctuations;Social networking (online);Machine learning;Media;Portable document format;Natural language processing;Internet","","1","","12","IEEE","11 Jan 2022","","","IEEE","IEEE Conferences"
"AI-Based convolute Neural Approach Management To Predict The RNA Structure","S. Rishi; S. Debnath; S. Dewani; D. S. David; R. A. Jaleel; M. M. A. Zahra","Department of Microbiology, Government Medical College Srinagar, Kashmir, India; Department of Genetics and Plant Breeding, Genetics & Plant Breeding, Palli Siksha Bhavana (Institute of Agriculture), Visva-Bharati University, Sriniketan, Birbhum, West Bengal, India; Department of Physiology, Government Medical College, Srinagar, Kashmir, India; Department of Information Technology, Vel Tech Multi Tech Dr. Rangarajan Dr.Sakunthala Engineering College; Department of Information and Communication Engineering, Al-Nahrain University, Iraq; Computer Techniques Engineering Department, Al-Mustaqbal University College, Hillah, Iraq","2022 2nd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","18 Jul 2022","2022","","","2224","2228","Let us begin with Machine learning (ML), which is a type of neural network (AI) that empowers software programmers to start increasing prediction without being done with full to do so. Because data is so valuable, improving strategies for intelligently having to manage the now-Ubiquitous content infrastructures is a necessary part of the process toward completely autonomous agents. In a nutshell, deep learning is a subset of machine learning that solves problems that machine learning alone cannot. Acquiring RNA secondary spatial relationships has been more significant in RNA and functional genomics studies in recent years. Although some RNA secondary sequences may be discovering approaches, most of the time, quick and accurate computational approaches are utilized to predict the structure of DNA strands. Current methods for determining RNA structure of proteins are generally based on the lowest power storage strategy, which seeks the optimal RNA folded form in vivo and employs an incremental process to satisfy the lowest source of critical energy and related aspects.","","978-1-6654-3789-9","10.1109/ICACITE53722.2022.9823922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9823922","Deep learning;automatic assistance;Data Acquisition;Data processing;Algorithm;Data Management;Interpretation;statistics;probabilities;data wrangling;imputation;supervised learning;classification;regression;clustering;Healthcare;Data protection;Security;RNA structure;AI;convolute neural network","Deep learning;Proteins;Sequential analysis;In vivo;RNA;Neural networks;Hydrogen","","1","","17","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Safety Assurance of Artificial Intelligence-Based Systems: A Systematic Literature Review on the State of the Art and Guidelines for Future Work","A. V. S. Neto; J. B. Camargo; J. R. Almeida; P. S. Cugnasca","Department of Computer Engineering and Digital Systems (PCS), Safety Analysis Group (GAS), Escola Politécnica, Universidade de São Paulo (USP), São Paulo, Brazil; Department of Computer Engineering and Digital Systems (PCS), Safety Analysis Group (GAS), Escola Politécnica, Universidade de São Paulo (USP), São Paulo, Brazil; Department of Computer Engineering and Digital Systems (PCS), Safety Analysis Group (GAS), Escola Politécnica, Universidade de São Paulo (USP), São Paulo, Brazil; Department of Computer Engineering and Digital Systems (PCS), Safety Analysis Group (GAS), Escola Politécnica, Universidade de São Paulo (USP), São Paulo, Brazil","IEEE Access","21 Dec 2022","2022","10","","130733","130770","The objective of this research is to present the state of the art of the safety assurance of Artificial Intelligence (AI)-based systems and guidelines on future correlated work. For this purpose, a Systematic Literature Review comprising 5090 peer-reviewed references relating safety to AI has been carried out, with focus on a 329-reference subset in which the safety assurance of AI-based systems is directly conveyed. From 2016 onwards, the safety assurance of AI-based systems has experienced significant effervescence and leaned towards five main approaches: performing black-box testing, using safety envelopes, designing fail-safe AI, combining white-box analyses with explainable AI, and establishing a safety assurance process throughout systems’ lifecycles. Each of these approaches has been discussed in this paper, along with their features, pros and cons. Finally, guidelines for future research topics have also been presented. They result from an analysis based on both the cross-fertilization among the reviewed references and the authors’ experience with safety and AI. Among 15 research themes, these guidelines reinforce the need for deepening guidelines for the safety assurance of AI-based systems by, e.g., analyzing datasets from a safety perspective, designing explainable AI, setting and justifying AI hyperparameters, and assuring the safety of hardware-implemented AI-based systems.","2169-3536","","10.1109/ACCESS.2022.3229233","Brazilian Institution CAPES—Coordenação de Aperfeiçoamento de Pessoal de Nível Superior through PROEX Scholarship(grant numbers:88887.513631/2020-00); Brazilian institution FDTE—Fundação para o Desenvolvimento Tecnológico da Engenharia through Scholarship(grant numbers:1954.01.20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984982","Artificial intelligence;formal verification;learning systems;machine learning;neural networks;product safety engineering;risk analysis;safety","Safety;Artificial intelligence;Bibliographies;Neural networks;Systematics;Rail transportation;Learning systems;Risk management","","2","","165","CCBY","14 Dec 2022","","","IEEE","IEEE Journals"
"An Adaptive Service-Oriented Business Management Pattern Based on Machine Learning Rule ML","M. N; K. D. V. Prasad; K. Soujanya; D. Chandra Dobhal; M. Ali; M. A. Tripathi","CMR Institute of Technology; Symbiosis Institute of Business Management, Hyderabad Symbiosis International (Deemed University), Pune; Department of BBA, Koneru Lakshmaiah Educational Foundation, Vaddeswaram; Department of Computer Science & Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; Department of Computer Science, Khazar University, Baku, Azerbaijan; Department of Humanities and Social Sciences, Motilal Nehru National Institute of Technology, Allahabad","2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","24 Jul 2023","2023","","","1672","1676","The significance of artificial intelligence (AI) and machine learning (ML) for businesses is briefly and comprehensively discussed in this study. AI is a new trend and technology of the modern era that offers numerous advantages to businesses. AI and machine learning save the company money by lowering over- all business operations costs. In addition, it enables businesses to effectively solve business issues and helps them make better decisions about their processes. Customers can communicate with the AI-based chat bots at any time, day or night, and they can answer their questions about any business or product. Based on business operations, ML creates opportunities for businesses and automates the process completely. In addition, the ML effectively enhances cognitive engagement between employees and customers and offers solutions to customer issues like password issues and many others. In addition, the study contains the strategies and procedures utilized in its completion. In this study, the researcher has used secondary qualitative and quantitative methods to collect data. Companies must comprehend the augmentation and automation process in order to implement AI and ML in business operations. In addition, the type of business is used to describe the Al’s market size in percentage and dollars.","","979-8-3503-9926-4","10.1109/ICACITE57410.2023.10183158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183158","service oriented;knowledge base;XML;computing service","Computational modeling;Standards organizations;Semantics;Machine learning;Companies;Market research;Turning","","","","19","IEEE","24 Jul 2023","","","IEEE","IEEE Conferences"
"Socio-Technical Grounded Theory for Software Engineering","R. Hoda","Faculty of Information Technology, Monash University, Melbourne, VIC, Australia","IEEE Transactions on Software Engineering","18 Oct 2022","2022","48","10","3808","3832","Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.","1939-3520","","10.1109/TSE.2021.3106280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9520216","Socio-technical grounded theory;STGT;grounded theory;GT;software engineering;research method;theory;theory development;qualitative research;data analysis;guidelines;evaluation","Guidelines;Data collection;Software engineering;Tools;Systematics;Sociology;Encoding","","30","","95","IEEE","20 Aug 2021","","","IEEE","IEEE Journals"
"AI based MPPT methods for grid connected PV systems under non linear changing solar irradiation","A. Arora; P. Gaur","Dept. of Instrumentation and Control Engineering; Netaji Subhas Institute of Technology (NSIT) University of Delhi, India","2015 International Conference on Advances in Computer Engineering and Applications","23 Jul 2015","2015","","","542","547","This paper presents the artificial neural network (ANN), fuzzy logic controller (FLC) maximum power point tracking (MPPT) methods in grid connected photovoltaic (PV) systems for optimizing the solar energy efficiency. All the methods are simulated in MATLAB-Simulink, respectively together with SunPower-SPR305 PV module connected to single-ended primary inductor converter (SEPIC). Performance assessment covers efficiency, overshoot, settling time response, oscillations and stability.","","978-1-4673-6911-4","10.1109/ICACEA.2015.7164752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164752","Maximum power point tracking;Artificial Neural Network;Fuzzy Logic Controller;Photovoltaic;Single-ended primary inductor converter","Artificial neural networks;Radiation effects;Maximum power point trackers;Mathematical model;Fuzzy logic;Niobium;Computers","","9","","9","IEEE","23 Jul 2015","","","IEEE","IEEE Conferences"
"Novel Four-Layered Software Defined 5G Architecture for AI-based Load Balancing and QoS Provisioning","S. Hongvanthong","School of Computer Science, Wuhan University of Technology, Wuhan, China","2020 5th International Conference on Computer and Communication Systems (ICCCS)","16 Jun 2020","2020","","","859","863","Software defined 5G network (SD-5G) is an evolving networking technology. The integration of SDN and 5G brings scalability, and efficiency. However, Quality of Service (QoS) provision is still challenging in SD-5G due to improper load balancing, traffic unawareness and so on. To overwhelm these issues this paper designs a novel load balancing scheme using Artificial Intelligence (AI) techniques. Firstly, novel four-layered SD-5G network is designed with user plane, smart data plane, load balancing plane, and distributed control plane. In the context to 5G, the data transmission rate must satisfy the QoS constraints based on the traffic type such as text, audio, video etc. Thus, the data from the user plane is classified by Smart Traffic Analyzer in the data plane. For traffic analysis, Enriched Neuro-Fuzzy (ENF) classifier is proposed. In the load balancing plane, Primary Load balancer and Secondary Load Balancer are deployed. This plane is responsible for balancing the load among controllers. For controller load balancing, switch migration is presented. Overloaded controller is predicted by Entropy function. Then decision for migration is made by Fitness-based Reinforcement Learning (F-RL) algorithm. Finally, the four-layered SD-5G network is modeled in the NS-3.26. The observations shows that the proposed work improves the SD-5G network in terms of Loss Rate, Packet Delivery Rate, Delay, and round trip time.","","978-1-7281-6136-5","10.1109/ICCCS49078.2020.9118463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9118463","QoS;software defined 5G network;Artificial intelligence;distributed control plane","Switches;Load management;Quality of service;5G mobile communication;Monitoring;Feature extraction","","4","","16","IEEE","16 Jun 2020","","","IEEE","IEEE Conferences"
"AI Enabled IoT based Intelligent Waste Water Management System for Municipal Waste Water Treatment Plant","K. L. Narayanan; R. Karthik Ganesh; S. T. Bharathi; A. Srinivasan; R. S. Krishnan; S. Sundararajan","Francis Xavier Engineering College, Tirunelveli; SCAD College of Engineering and Technology, Tirunelveli; PSNA College of Engineering and Technology, Dindigul; Velammal College of Engineering and Technology, Madurai; SCAD College of Engineering and Technology, Tirunelveli; SCAD College of Engineering and Technology, Tirunelveli","2023 International Conference on Inventive Computation Technologies (ICICT)","1 Jun 2023","2023","","","361","365","Water is considered to be an essential part of human life, it is our individual responsibility to utilize the water with utmost care. Agriculture is considered to be an important factor in the growth of the economy which also depends upon the availability of water. Rainfall in today's scenario is unpredictable and uncertain as the monsoon rainfalls are irregular in recent days, this causes serious water scarcity and agriculture failure in most places. To overcome these problems, various technologies are adopted in the field of agriculture to make the irrigation system more effective. This research study adopts a novel Artificial Intelligence (AI) based system to properly manage the usage of water in Municipal Wastewater Treatment Plants with the help of the Internet of Things (IoT). This system runs on a central Atmega 328p Microcontroller connected with an ESP 8266 Wi-Fi on the chip. Various parameters of the water such as pH, conductivity, color, smell, and temperature are recorded in the cloud server, which is analyzed with an AI-based system to decide whether the water can be reused or it can be passed to the garden for irrigation.","2767-7788","979-8-3503-9849-6","10.1109/ICICT57646.2023.10134075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10134075","Agriculture;Artificial Intelligence;Atmega 328p;ESP8266;Internet of Things;Cloud Server","Irrigation;Cloud computing;Monsoons;Sensors;Servers;Internet of Things;Wastewater","","1","","15","IEEE","1 Jun 2023","","","IEEE","IEEE Conferences"
"Performance Analysis of AI-based Optical guiding Device for visually compromised person","P. Srivastava; P. Shrivastav; N. Chaturvedi; R. L. Yadava","Department of Electronics and Communication, Galgotia College of Engineering and Technology, Greater Noida, India; Department of Electronics and Communication, Galgotia College of Engineering and Technology, Greater Noida, India; Department of Electronics and Communication, Galgotia College of Engineering and Technology, Greater Noida, India; Department of Electronics and Communication, Galgotia College of Engineering and Technology, Greater Noida, India","2022 International Conference on Smart Technologies and Systems for Next Generation Computing (ICSTSN)","25 Apr 2022","2022","","","1","5","To defeat the voyaging trouble for an outwardly impeded individual in chiefly outside climate, this paper presents a thought of savvy directing gadget dependent on CNN and fuzzy to distinguish snags like bicycle, vehicle, individual and give an appropriate sound criticism to the client in the wake of working out speed, distance and in the wake of applying fuzzy to exact the result. Work is to diminish the different sensors of distance and speed estimating and perform calculation on pictures to set exact outcomes up to make it financially savvy. It is a difficult situation for blind individual to stroll on themselves in free space or in street of snags. Different techniques have appeared for directing them to move like headlock strategies, multi-sensors combination Algorithm, yet among every one of them because of utilization of sensors its size turns out to be enormous and furthermore get high in cost. To lessen this, we have presented different calculations for exact speed and distance estimations in order to give appropriate sound criticism.","","978-1-6654-2111-9","10.1109/ICSTSN53084.2022.9761308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761308","ANN;CNN;RNN;SLAM;RDG-B","Integrated optics;Costs;Estimation;Bicycles;Cameras;Performance analysis;Optical sensors","","","","9","IEEE","25 Apr 2022","","","IEEE","IEEE Conferences"
"Multiple AI Based Web Mining","R. Singh; A. Gehlot","Uttaranjal Institute of Technology, Uttaranjal University, Dehradun, India; Uttaranjal Institute of Technology, Uttaranjal University, Dehradun, India","2022 International Interdisciplinary Humanitarian Conference for Sustainability (IIHC)","17 Mar 2023","2022","","","1239","1244","Artificial intelligence (AI) refers to the computational process of finding, identifying, and evaluating patterns in huge data sets using techniques that lie at the confluence of machine learning, statistics, and database strategies. Its major purpose is to extract relevant information from raw data sets and reformat them into the desired format for analysis and application. Web Mining (WM), an expanding viewpoint of data mining, encompasses all data mining and associated processes. It is employed for automatically locating and extracting data from online records and services. So, the goal of WM is to glean useful information from the web. Given its significance, this research conducts a survey of DM methods for web mining.","","978-1-6654-5687-6","10.1109/IIHC55949.2022.10059948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059948","Web Mining;Artificial Intelligence;Social Networks and World Wide Web","Industries;Knowledge based systems;Web mining;Machine learning;User interfaces;Software systems;Web sites","","","","35","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"AI based Automated Essay Grading System using NLP","V. Suresh; R. Agasthiya; J. Ajay; A. A. Gold; D. Chandru","Computer Science and Engineering, Dr. N.G.P Institute of Technology, Coimbatore, India; Computer Science and Engineering, Dr. N.G.P Institute of Technology, Coimbatore, India; Computer Science and Engineering, Dr. N.G.P Institute of Technology, Coimbatore, India; Computer Science and Engineering, Dr. N.G.P Institute of Technology, Coimbatore, India; Computer Science and Engineering, Dr. N.G.P Institute of Technology, Coimbatore, India","2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS)","8 Jun 2023","2023","","","547","552","The goal of this proposed work is to develop an AI-powered system for automated essay grading. The system will utilize natural language processing and Graph based techniques to analyze, and grade written essays. It not only checks the syntax, semantics and grammar but also grades according to the similarity of sentences using a Graph based approach. The system will be trained on a dataset of labelled essays and will be able to accurately grade new essays based on their content and writing quality. The system can be able to integrate with existing learning management systems. The goal is to provide a more efficient and accurate essay grading process, so the teachers can provide valuable feedback to students. The proposed work aims to develop an automated essay grading system using AI technology. The system will be able to analyze, and grade written essays by using natural language processing and machine learning techniques. The system will be trained on a dataset of labelled essays, which will be used to teach the system to recognize patterns and characteristics of high-quality writing. This will enable the system to accurately grade new essays based on their content and writing quality.","2768-5330","979-8-3503-9725-3","10.1109/ICICCS56967.2023.10142822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10142822","Natural Language Processing;Automated Essay Scoring;Artificial Intelligence;Essay Scoring System;Neural Network","Learning management systems;Text analysis;Machine learning algorithms;Semantics;Neural networks;Process control;Syntactics","","","","15","IEEE","8 Jun 2023","","","IEEE","IEEE Conferences"
"Developing AI-based Fraud Detection Systems for Banking and Finance","S. Dash; S. Das; S. Sivasubramanian; N. K. Sundaram; H. K. G; T. Sathish","School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India; KL Business School, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Andhra Pradesh, India; Department of Information Technology, New Prince Shri Bhavani College of Engineering and Technology, Chennai, Tamil Nadu, India; Department of Information Technology, New Prince Shri Bhavani College of Engineering and Technology, Chennai, Tamil Nadu, India; Department of Computer Science, JSS Academy of Technical Education, Noida, Uttar Pradesh, India; Department of Mechanical Engineering, Saveetha School of Engineering, Chennai, Tamil Nadu, India","2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)","28 Aug 2023","2023","","","891","897","Safeguarding financial institutions and their consumers against fraudulent activity makes fraud detection a top priority in the banking and finance business. There has been a rise in the development of artificial intelligence-based fraud detection systems in tandem with the popularity of machine learning methods. This study presents a comprehensive evaluation of modern machine learning approaches like neural networks in comparison to more conventional ones like logistic regression and decision trees. These techniques are tested using financial and banking data from the real world, and the findings indicate that neural networks are superior to more conventional approaches. In addition, our research emphasizes the significance of data gathering and administration in the evolution of fraud detection systems.","","979-8-3503-2142-5","10.1109/ICIRCA57980.2023.10220838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220838","Fraud detection;Finance;Banking;Machine learning;Artificial intelligence;Decision trees;Logistic regression;Neural networks;Data management;Performance evaluation;Legal frameworks","Logistic regression;Neural networks;Finance;Banking;Machine learning;Fraud;Regression tree analysis","","","","15","IEEE","28 Aug 2023","","","IEEE","IEEE Conferences"
"A NLU-based method for a first level automatic categorization of AI-based security documents","A. Psarologou; M. Virvou; N. G. Bourbakis",NA; NA; NA,"IISA 2013","10 Oct 2013","2013","","","1","7","Managing and organizing the information is a difficult subject. Especially in our time with the plethora of available sources accessible to the public, basically through the Internet, the volume of these pieces of information becomes larger and larger. The purpose of this dissertation is the creation of a model of documents' categorization. Our goal is to illustrate an as possible automated way of classification that takes into consideration the meaning of the documents. The way in which a human evaluates and classifies documents is followed in this proposed methodology. We also illustrate some empirical examples of the function of our classification method.","","978-1-4799-0771-7","10.1109/IISA.2013.6623729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6623729","document categorization;natural language understanding","Intrusion detection;Unsolicited electronic mail;Filtering;Classification algorithms;Learning (artificial intelligence)","","","","22","IEEE","10 Oct 2013","","","IEEE","IEEE Conferences"
"The Research and Construction of the AI-Based Knowledge Graph in Multi-Dimensional Data","J. Zhou","School of Information Engineering, Wuhan Business University, Wuhan City, Hubei Province, China","2023 International Conference on Computer Engineering and Distance Learning (CEDL)","12 Dec 2023","2023","","","1","6","With the development of deep learning and the knowledge graph, artificial intelligence has had a significant influence on the area of education as a result of the rapid growth of this age, which has profoundly altered human productivity and daily life. The university is undergoing a digital transformation. The essence of the knowledge graph is the knowledge base of the semantic network. Using natural language processing (NLP) technology, the university can construct a knowledge graph. Integrating knowledge graphs and deep learning has become one of the most important aspects of further improving the effect of deep learning. The solution to knowledge graph processing data is “algorithm, totalization, and implementation”. The key technologies of constructing knowledge graphs in multi-dimensional data mainly focus on knowledge ontology definition, knowledge representation, knowledge modeling, knowledge extraction, knowledge fusion, knowledge processing, knowledge computing, and other technologies. The research in this paper shows that the RDF model and algorithm of the knowledge graph have application prospects in multi-dimensional data.","","979-8-3503-2903-2","10.1109/CEDL60560.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10337415","natural language processing;data;entity;knowledge graph","Deep learning;Productivity;Computational modeling;Semantics;Knowledge based systems;Knowledge graphs;Ontologies","","","","8","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models","D. P. Panagoulias; F. A. Palamidas; M. Virvou; G. A. Tsihrintzis","Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Medicine, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece","2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI)","20 Dec 2023","2023","","","70","77","In this paper, we investigate the enhancement of Artificial Intelligence (AI) technologies in healthcare and the better understanding of medical literature with the use of Large Language Models (LLMs) and Natural Language Processing (NLP). Specifically, we introduce a rule-augmented AI-empowered system which incorporates a rule-based decision system, the ChatGPT application programming interface (API), and other external machine learning and analytical APIs to offer diagnostic suggestions to patients. The complexities of patient healthcare experiences, including doctor-patient interactions, understanding levels, treatment procedures, and preventive care, are considered. We illustrate how a diagnostic process typically integrates various strategies depending on various factors. To digitize the greatest portion of the process, we propose and illustrate the use of LLMs for humanizing the communication process and investigating ways to reduce burdens and costs in primary healthcare. We also outline a theoretical decision model for evaluating the use of technological components from external sources versus building them from scratch. The paper is structured into sections detailing background theories and context, our proposed and implemented rule-augmented AI-empowered system, as well as a system test in a corresponding use case. Finally, the paper key findings are presented, which contribute valuable insights for future work in this field.","2375-0197","979-8-3503-4273-4","10.1109/ICTAI59109.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10356438","AI-empowered software engineering;explainability;ChatGPT;LLM;NLP;prompt-engineering","Costs;Buildings;Machine learning;Chatbots;Software;Complexity theory;Medical diagnosis","","1","","33","IEEE","20 Dec 2023","","","IEEE","IEEE Conferences"
"RLOps: Development Life-Cycle of Reinforcement Learning Aided Open RAN","P. Li; J. Thomas; X. Wang; A. Khalil; A. Ahmad; R. Inacio; S. Kapoor; A. Parekh; A. Doufexi; A. Shojaeifard; R. J. Piechocki","Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Vilicom U.K. Ltd., Reading, U.K; Vilicom U.K. Ltd., Reading, U.K; Applied Research, Suffolk, U.K; Applied Research, Suffolk, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; InterDigital Communications Inc., Wilmington, DE, USA; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K","IEEE Access","7 Nov 2022","2022","10","","113808","113826","Radio access network (RAN) technologies continue to evolve, with Open RAN gaining the most recent momentum. In the O-RAN specifications, the RAN intelligent controllers (RICs) are software-defined orchestration and automation functions for the intelligent management of RAN. This article introduces principles for machine learning (ML), in particular, reinforcement learning (RL) applications in the O-RAN stack. Furthermore, we review the state-of-the-art research in wireless networks and cast it onto the RAN framework and the hierarchy of the O-RAN architecture. We provide a taxonomy for the challenges faced by ML/RL models throughout the development life-cycle: from the system specification to production deployment (data acquisition, model design, testing and management, etc.). To address the challenges, we integrate a set of existing MLOps principles with unique characteristics when RL agents are considered. This paper discusses a systematic model development, testing and validation life-cycle, termed: RLOps. We discuss fundamental parts of RLOps, which include: model specification, development, production environment serving, operations monitoring and safety/security. Based on these principles, we propose the best practices for RLOps to achieve an automated and reproducible model development process. At last, a holistic data analytics platform rooted in the O-RAN deployment is designed and implemented, aiming to embrace and fulfil the aforementioned principles and best practices of RLOps.","2169-3536","","10.1109/ACCESS.2022.3217511","Innovate UK/CELTIC-NEXT European collaborative project on AI-enabled Massive MIMO (AIMM); Next-Generation Converged Digital Infrastructure (NG-CDI) Project; BT and Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R004935/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931127","O-RAN;machine learning;reinforcement learning;MLOps;RLOps;digital twins;data engineering","Radio access networks;Computer architecture;Reinforcement learning;Task analysis;Adaptation models;3GPP;Biological system modeling","","7","","96","CCBY","26 Oct 2022","","","IEEE","IEEE Journals"
"Generative AI-Empowered Simulation for Autonomous Driving in Vehicular Mixed Reality Metaverses","M. Xu; D. Niyato; J. Chen; H. Zhang; J. Kang; Z. Xiong; S. Mao; Z. Han","School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Electronics, Peking University, Beijing, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Singapore, Singapore; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA","IEEE Journal of Selected Topics in Signal Processing","15 Nov 2023","2023","17","5","1064","1079","In the vehicular mixed reality (MR) Metaverse, the discrepancy between physical and virtual entities can be overcome by fusing the physical and virtual environments with multi-dimensional communications in autonomous driving systems. Assisted by digital twin (DT) technologies, connected autonomous vehicles (AVs), roadside units (RSUs), and virtual simulators can maintain the vehicular MR Metaverse via simulations for sharing data and making driving decisions collaboratively. However, it is challenging and costly to enable large-scale traffic and driving simulation via realistic data collection and fusion from the physical world for online prediction and offline training in autonomous driving systems. In this paper, we propose an autonomous driving architecture, where generative AI is leveraged to synthesize unlimited conditioned traffic and driving data via simulations for improving driving safety and traffic control efficiency. First, we propose a multi-task DT offloading model for the reliable execution of heterogeneous DT tasks with different requirements at RSUs. Then, based on the preferences of AV's DTs and real-world data, virtual simulators can synthesize unlimited conditioned driving and traffic datasets for improved robustness. Finally, we propose a multi-task enhanced auction-based mechanism to provide fine-grained incentives for RSUs on providing resources for autonomous driving. The property analysis and experimental results demonstrate that the proposed mechanism and architecture are strategy-proof and effective.","1941-0484","","10.1109/JSTSP.2023.3293650","NSF(grant numbers:CNS-2148382); National Key R&D Project of China(grant numbers:2022YFE0111900); National Natural Science Foundation of China(grant numbers:62102099); Guangdong Provincial Pearl River Talents Program(grant numbers:2021QN02S643); Guangzhou Basic Research Program(grant numbers:2023A04J1699); National Natural Science Foundation of China(grant numbers:U22A2054,62101594); National Research Foundation Singapore; Infocomm Media Development Authority through its Future Communications Research and Development Programme; DSO National Laboratories through AI Singapore Programme(grant numbers:AISG2-RP-2020-019); Energy Research Test-Bed and Industry Partnership Funding Initiative; Energy Grid (EG) 2.0 Programme; DesCartes; Campus for Research Excellence and Technological Enterprise (CREATE) Programme(grant numbers:RG87/22); Singapore University of Technology and Design(grant numbers:SRG-ISTD-2021165); SUTD-ZJU IDEA(grant numbers:202102); Ministry of Education - Singapore; SUTD Kickstarter Initiative(grant numbers:20210204); NSF(grant numbers:CNS2107216,CNS-2128368,CMMI-2222810,ECCS-2302469); U.S. Department of Transportation; Toyota Motor Corporation; Amazon; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177684","Autonomous driving;Metaverse;generative artificial intelligence;auction theory","Task analysis;Autonomous vehicles;Data models;Computational modeling;Artificial intelligence;Training;Metaverse","","6","","49","IEEE","10 Jul 2023","","","IEEE","IEEE Journals"
"Rough set based system for effective E-learning","H. Rana; Rajiv; M. Lal","Research Cell, UCMS University College of Medical Sciences, Delhi, India; SOCIS, IGNOU, Delhi, India; SOCIS, IGNOU, Delhi, India","2014 International Conference on Computing for Sustainable Global Development (INDIACom)","12 Jun 2014","2014","","","192","196","To achieve intelligence over the web is underlying research topic and continuous efforts have been made in this direction. The results of these efforts in its practical form of applications have been achieved using modern tools & techniques. Artificial Intelligence (AI) has evolved as one of the promising technology for achieving intelligence over web. To facilitate quality education, the identification & selection of various factors that may influence a students' academic performance is very important. Knowing these factors is important for parents & teachers working positively on these factors may improve the performance of the student. . In this paper we propose an approach of decision rule induction to induce knowledge that can facilitate the proper decision making process. The approach for rule induction process is based on AI based rough set theory. The proposed system may be seen as a helping hand to creators of contents, educators and teachers of the course.","","978-93-80544-12-0","10.1109/IndiaCom.2014.6828126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6828126","AI;DSS;Decision support system;Rule induction;Rough Sets;RSES;RSES 2.2;RST based Decision system","Approximation methods;Rough sets;Decision support systems;Educational institutions","","4","","16","","12 Jun 2014","","","IEEE","IEEE Conferences"
"Overview of an AI-Based Methodology for Design: Case Study of a High Efficiency Electric Vehicle Chassis for the Shell Eco-Marathon","J. A. de la Tejera; R. A. Ramirez-Mendoza; M. R. Bustamante-Bello; P. Orta-Castañón; L. A. Arce-Saenz",School of Engineering and Sciences Tecnologico de Monterrey; School of Engineering and Sciences Tecnologico de Monterrey; School of Engineering and Sciences Tecnologico de Monterrey; School of Engineering and Sciences Tecnologico de Monterrey; School of Engineering and Sciences Tecnologico de Monterrey,"2023 International Symposium on Electromobility (ISEM)","6 Dec 2023","2023","","","1","8","The design process of a chassis for a high-efficiency vehicle involves considering several unique parameters due to its distinct operational needs. The constraints specified in the official regulations for the Shell Eco-Marathon prototype battery electric class could ostensibly limit design innovations. However, this paper introduces a methodological approach employing Machine Learning, facilitated by Large Language Models, which substantially broadens the spectrum of conceptual design possibilities. Further, the widely recognized technique of Computer-Aided Design, coupled with Generative Design, is leveraged to optimize specific sections of the chassis structure. The final stage of this study involves rigorous testing of the designed chassis to assess its mechanical performance, guided by the stringent benchmarks set by the competition.","","979-8-3503-4007-5","10.1109/ISEM59023.2023.10334852","Consejo Nacional de Ciencia y Tecnología (CONACYT)(grant numbers:CVU 923079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10334852","Conceptual design;Shell Eco-Marathon;Electric vehicle;Automotive Engineering;Engineering Design;Artificial Intelligence","Resistance;Technological innovation;Biological system modeling;Prototypes;Machine learning;Robustness;Regulation","","","","25","IEEE","6 Dec 2023","","","IEEE","IEEE Conferences"
"Enhanced Defect Detection in After Develop Inspection with Machine Learning Disposition","M. P. McLaughlin; A. Stamper; G. Barber; J. Paduano; P. Mennell; E. Benn; M. Linnane; J. Zwick; C. Khatumria; R. L. Isaacson; N. Hoffman; C. Menser","GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533; GLOBALFOUNDRIES, NY, 12533","2021 32nd Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)","24 May 2021","2021","","","1","5","A complementary Machine Learning disposition method was generated and tested for after develop inspections in lithography. For lithography coating defects, this new method showed twice the sensitivity and five times the specificity in a controlled experiment versus the baseline system. Applying the detection method along with process improvements, preventative measures and rework for splatter defects, reduced yield loss from splatters by over 30x. Herein we describe learnings on the use of image enhancement for training and disposition, an Explainable AI system to support understanding, and a process flow to train augmentation based on performance.","2376-6697","978-1-7281-8645-0","10.1109/ASMC51741.2021.9435721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435721","Machine Learning;Semiconductor;Smart Manufacturing;ADI;Lithography","Training;Semiconductor device measurement;Sensitivity;Lithography;Machine learning;Inspection;Loss measurement","","2","","10","IEEE","24 May 2021","","","IEEE","IEEE Conferences"
"The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement","E. A. Moroz; V. O. Grizkevich; I. M. Novozhilov","Saint Petersburg Mining University, Saint Petersburg, Russia; Saint Petersburg Mining University, Saint Petersburg, Russia; Department of Automation and Control Processes, Saint Petersburg Electrotechnical University ""LETI"", Saint-Petersburg, Russia","2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering (ElConRus)","20 Apr 2022","2022","","","386","390","Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.","2376-6565","978-1-6654-0993-3","10.1109/ElConRus54750.2022.9755659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9755659","Automated Software Engineering;Machine Learning;Neural Networks;Natural Language Processing;Artificial Intelligence Techniques;Software Development Productivity","Productivity;Technological innovation;Electric potential;Codes;Neural networks;Machine learning;Software","","1","","10","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Blockchain and AI Empowered Trust-Information-Centric Network for Beyond 5G","Q. Pan; J. Wu; J. Li; W. Yang; Z. Guan","Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, China; Harbin Engineering University, China; North China Electric Power University (NCEPU), China","IEEE Network","2 Dec 2020","2020","34","6","38","45","As the next-generation network, beyond fifth generation (B5G) provides transmission capability up to terabits and processes hundreds of exabytes of content data per day from the internet of Everything. From 5G to B5G, the information-centric network (iCN) is expected to play a vital role due to the strong capabilities of content distribution, caching, and processing. As security is a major concern in B5G, content trust of iCN is of critical importance. Lack of content trust leads to the untrustworthiness and maliciousness of services and applications in B5G, such as malicious accidents resulting from the untrusted content of vehicle navigation and autonomous system. To deal with this issue, we propose a blockchain and artificial intelligence (Ai) empowered trust-information- centric network architecture for B5G. First, we design a blockchain-based trust evaluation and circulation scheme for B5G nodes called TrustCoin, which quantifies the credibility of B5G nodes in a dynamic and fine-grained way, and manages trust quotas of B5G nodes as well as trust-coin circulation. Second, to obtain the content credibility, we devise a credibility decision method based on content status and B5G nodes' behaviors by exploiting the excellent properties of deep reinforcement learning, which provides the intelligent allocation criterion for TrustCoin. Third, we propose a smart incentive mechanism for the endogenous trust of B5G networks according to the allocation criterion, thereby establishing the trust-information-centric network. Experimental results have verified the effectiveness of our proposed mechanism.","1558-156X","","10.1109/MNET.021.1900608","National Natural Science Foundation of China(grant numbers:61972255,61831007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277899","","Artificial intelligence;Blockchain;5G mobile communication;Servers;Resource management;6G mobile communication;Vehicle dynamics;Reinforcement learning;Internet of Things;Trust management","","24","","15","IEEE","2 Dec 2020","","","IEEE","IEEE Magazines"
"Supporting the Incorporation of Individual Patient Preferences for Decision Support in Breast Cancer Therapy","M. Bommersheim; P. Philipp","Fraunhofer Institute of Optronics, System Technologies and Image Exploitation IOSB, Karlsruhe, Germany; Fraunhofer Institute of Optronics, System Technologies and Image Exploitation IOSB, Karlsruhe, Germany","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","1289","1290","With the rise of personalized medicine, the number of individualized treatment options and related decisions is increasing tremendously. Thereby, the acquisition, incorporation and representation of the patient’s individual preferences in upcoming, modern, AI-based medical decision support systems play a decisive role. E.g., for patients with advanced breast cancer, there are various therapeutic options associated with different outcomes to choose from. In our contribution we show a first approach to model Preference Elicitation (PE) via card sorting using a utility function. Based on this, we present further ideas for extending and improving the approach.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799186","Medical Decision Support;Shared Decision Making;Patient Preference Elicitation;Card Sorting;Constant Sum Scaling","Decision support systems;Scientific computing;Precision medicine;Computational modeling;Breast cancer;Computational intelligence;Sorting","","","","11","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"An expert system for automatic cyber risk assessment and its AI-based improvements","G. Gatti; C. Basile; G. Perboli","DAUIN, Politecnico di Torino, Torino, Italy; DAUIN, Politecnico di Torino, Torino, Italy; DIGEP, Politecnico di Torino, Torino, Italy","2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)","2 Aug 2023","2023","","","1434","1440","Evaluating risks against IT Systems is a complex yet crucial process that requires significant resources and competencies. This paper proposes RiskMan, an expert system for the automatic assessment of cyber risks that computes a risk score using information gathering and vulnerability assessment tools, public databases, and leaks from the dark web without involving cybersecurity experts. Moreover, RiskMan uses AI-driven techniques to determine risks also when only partial information is available.","0730-3157","979-8-3503-2697-0","10.1109/COMPSAC57700.2023.00220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196997","cybersecurity risk estimation;expert system;artificial intelligence","Dark Web;Databases;Software;Risk management;Expert systems;Computer security","","","","21","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Secured IoT Malware Detection Framework using AI based Fuzzy Logic Systems","V. S. Saranya; G. Ramachandran; S. Chakaravarthi","Department of Computer Science and Engineering, Annamalai University, Annamalainagar; Dept. of Computer Science and Engineering, Annamalai University, Annamalainagar; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, Tamil Nadu, India","2022 International Conference on Automation, Computing and Renewable Systems (ICACRS)","7 Feb 2023","2022","","","771","779","Internet of Things (IoT) system is emerged enormously today and it is utilized in all the applications of human lives. Security of IoT systems seem more challengeable in terms of malicious software’s which are referred as malwares. IoT malwares are also evolved with the employment of advanced obfuscation and evading techniques. It is a very challengeable job for the security analysts as well as security providers. In this paper, an enhanced IoT malware detection framework is proposed by making use of AI based Fuzzy Logic Systems (AIFLS) by considering the shortcomings of existing recent detection methods. Fuzzy rules are generated automatically without any human intervention. Further, Fuzzy Pattern Trees (FPT) are generated and utilized for fastening classification of IoT malwares and enhancing detection accuracy. Experimentation results provide better results.","","978-1-6654-6084-2","10.1109/ICACRS55517.2022.10029032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029032","IoT malware;Fuzzy Logic Systems;Fuzzy Pattern Tree;Artificial Intelligence;Security","Fuzzy logic;Renewable energy sources;Pandemics;Ecosystems;Malware;Security;Internet of Things","","","","24","IEEE","7 Feb 2023","","","IEEE","IEEE Conferences"
"Artificial Intelligence and Machine Learning Approaches For Aviation Cybersecurity: An Overview","A. B. Garcia; R. F. Babiceanu; R. Seker","Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, FL; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, FL; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, FL","2021 Integrated Communications Navigation and Surveillance Conference (ICNS)","2 Jun 2021","2021","","","1","8","Artificial Intelligence (AI) and Machine Learning (ML) applications are currently found across all engineering domains, including cybersecurity engineering. This paper presents an overview of the AI-systems and technologies that can greatly benefit the security domain and its potential solutions for the aviation industry: anomaly detection for avionics, securing data link communications, and security certification, among others.As showcased in the ""National Strategy for Aviation Security"" report in December 2018 and the U.S. Government Accountability Office report ""Aviation Cybersecurity"" in October 2020, there is a need for resilient cybersecurity practices and approaches to address the current issues that aviation faces today. Designing and implementing solutions to address these issues without exploring the feasibility of harnessing AI-powered cybersecurity tools would overlook the potential advantages these technologies can offer.Therefore, this paper aims to provide a roadmap to adapt well-known ML-cybersecurity approaches to aviation security engineering and airworthiness: (i) autonomous and semi-autonomous cybersecurity for autonomous flight operations security, (ii) game theory models for adversarial and uncertainty modeling, (iii) human-AI interfaces for airport security monitoring and decision-making assistance, (iv) predictive analytics for anomaly detection for avionics and e-enabled aircraft, and (v) AI-based reasoning trustworthiness for software reliability and security certification. This paper also presents the challenges of including AI-cybersecurity in the aviation ecosystem to ground the proposed solutions within an accepted set of industry regulations, such as design verification for AI/ML algorithms and certification specifications for AI/ML solutions for manufacturers and agencies.","2155-4951","978-1-6654-3584-0","10.1109/ICNS52807.2021.9441594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441594","","Industries;Analytical models;Adaptation models;Atmospheric modeling;Machine learning;Aerospace electronics;Predictive models","","7","","33","IEEE","2 Jun 2021","","","IEEE","IEEE Conferences"
"Prevention through Design in major construction projects – Case study from Tata Steel","N. K. Sinha; R. Das; S. B. K. Sinha; K. Shalini; S. Das","Safety (I & SEA), Tata Steel Ltd., Jamshedpur, India; Safety (I & SEA), Tata Steel Ltd., Jamshedpur, India; Safety (I & SEA), Tata Steel Ltd., Jamshedpur, India; Safety (I & SEA), Tata Steel Ltd., Jamshedpur, India; Industrial & Systems Engineering, Indian Institute of Technology, Kharagpur, Kharagpur, India","2021 International Conference on Maintenance and Intelligent Asset Management (ICMIAM)","21 Feb 2022","2021","","","1","5","The construction industry is a dynamic sector involving various kinds of activities, each having their own hazards. Most of these activities are of a constantly changing nature and their specific hazards are not very well known until much later into the construction process. Though the fundamental processes involved in construction remain the same, every construction project is unique & has its own specific jobs & hazards associated with them depending on the design specifications, materials, equipment & processes used & the safety culture followed by the working agency. Construction workers are especially vulnerable to injuries due to fall from height, electrocution, being caught in or between objects, being struck by moving machinery, falling objects, vehicles, etc. which can also lead to fatal incidents. Apart from these, they are also susceptible to irreversible health issues arising out of exposure to dust & other harmful substances.Project execution & construction activities have been one of the most challenging activities in Tata Steel because of a large diversity in geographical locations, types of operations & various process requirements. The organization has undertaken many greenfield as well as brownfield projects which both have different kinds of risks involved. Since the last few years, Tata Steel has taken many initiatives to mitigate the hazards & reduce the incidents in construction activities. One of the major steps taken in this direction was the implementation of Prevention through Design (PtD) in projects. This included adoption of practices like virtual design & construction, use of bolted & prefabricated structures, laser scanning & 3D modeling, powered access system, e-work permit, site access control and AI-based CCTV surveillance for monitoring of site activities among many others. Prevention through design is a transdisciplinary process which aims at reducing the hazards in the design & planning phase itself, making the construction activities inherently safer and their safety management cheaper. Risk identification & prioritization is done for each job according to a risk heat map based on the potential consequences of each hazardous event & its likelihood of occurrence. The top risks are identified & design interventions are proposed to eliminate or substitute them.Prevention through design, powered by automation & digitized safety management systems, is widely gaining use in several operations as well as construction projects due to its advantages and ease of implementation. The adoption of these safety technologies & automation has helped in proactively mitigating risks & significantly increased the effectiveness of health & safety management systems at construction sites. The construction companies should adopt these safety practices & policies, that combined with the implementation of digital health & safety tools & techniques could assist site managers ensure efficiency of their construction projects.This paper discusses the methodologies adopted at Tata Steel to implement prevention through design in construction projects and their effect on the health & safety performance of the organization.","","978-1-6654-6671-4","10.1109/ICMIAM54662.2021.9715221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715221","prevention through design;construction safety;design for safety;PtD;construction projects;digitization;risk;risk mitigation","Automation;Three-dimensional displays;Surveillance;Power lasers;Safety management;Hazards;Planning","","1","","10","IEEE","21 Feb 2022","","","IEEE","IEEE Conferences"
"Agent-based Testing of Extended Reality Systems","R. Prada; I. S. W. B. Prasetya; F. Kifetew; F. Dignum; T. E. J. Vos; J. Lander; J. -y. Donnart; A. Kazmierowski; J. Davidson; P. M. Fernandes","INESC-ID and Instituto Superior Tècnico, Univ. de Lisboa, Portugal; Utrecht Univ, Netherlands; Fondazione Bruno Kessler, Italy; Umea Univ, Sweden; Univ. Politecnica de Valencia, Spain; Gameware, UK; Thales AVS, France; Thales SIX GTS, France; GoodAI, Czech Rep; INESC-ID and Instituto Superior Tècnico, Univ. de Lisboa, Portugal","2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)","5 Aug 2020","2020","","","414","417","Testing for quality assurance (QA) is a crucial step in the development of Extended Reality (XR) systems that typically follow iterative design and development cycles. Bringing automation to these testing procedures will increase the productivity of XR developers. However, given the complexity of the XR environments and the User Experience (UX) demands, achieving this is highly challenging. We propose to address this issue through the creation of autonomous cognitive test agents that will have the ability to cope with the complexity of the interaction space by intelligently explore the most prominent interactions given a test goal and support the assessment of affective properties of the UX by playing the role of users.","2159-4848","978-1-7281-5778-8","10.1109/ICST46399.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159086","agent-based testing;AI-based testing;testing computer game;testing virtual reality;user experience testing","Games;Cognition;Computational modeling;Task analysis;Software testing;Extended reality","","","","20","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"The Drug-Like Molecule Pre-Training Strategy for Drug Discovery","J. Lee; I. -S. Myeong; Y. Kim","Department of Medical and Digital Engineering, College of Engineering, Hanyang University, Seoul, South Korea; College of Pharmacy, Daegu Catholic University, Gyeongsan, South Korea; College of Pharmacy, Daegu Catholic University, Gyeongsan, South Korea","IEEE Access","23 Jun 2023","2023","11","","61680","61687","Recent advances in artificial intelligence (AI) have led to the development of transformer-based models that have shown success in identifying potential drug molecules for therapeutic purposes. However, for a molecule to be considered a viable drug candidate, it must exhibit certain desirable properties such as low toxicity, high druggability, and synthesizability. To address this, we propose an approach that incorporates prior knowledge about these properties during the model training process. In this study, we utilized the PubChem database, which contains 100 million molecules, to filter drug-like molecules based on the quantity of drug-likeliness (QED) score and the Pfizer rule. We then used this filtered dataset of drug-like molecules to train both molecular representation (ChemBERTa) and molecular generation models (MolGPT). To assess the performance of the molecular representation model, we fine-tuned the results on the MoleculeNet benchmark datasets. Meanwhile, we evaluated the performance of the molecular generation model based on the generated samples comprising 10,000 molecules. Despite the limited diversity of the pre-training dataset, the models for molecular representation were able to retain at least 90% of their original performance on benchmark datasets, with an additional improvement of 6% in predicting clinical toxicology. In the domain of molecular generation, the model pre-trained on drug-like molecules exhibited a high rate of desirable molecule properties in the unconditionally generated outputs. Additionally, the diversity of generated structures demonstrated notable performance compared to the conditional generation approach. Moreover, the drug-like molecule pre-training strategy is not limited to a specific model or training method, making it a flexible approach that can be easily modified based on the research interests and criteria of interest.","2169-3536","","10.1109/ACCESS.2023.3285811","Research Grants from Daegu Catholic University, in 2022; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151878","AI-based drug discovery;pre-training;quantity of drug-likeliness;Pfizer rule","Artificial intelligence;Companies;Transformers;Benchmark testing;Drug delivery;Databases;Toxicology","","","","42","CCBYNCND","14 Jun 2023","","","IEEE","IEEE Journals"
"Artificial Learning for Part Identification in Robotic Disassembly Through Automatic Rule Generation in an Ontology","G. Foo; S. Kara; M. Pagnucco","Sustainable Manufacturing and Life Cycle Engineering Research Group, School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, NSW, Australia; Sustainable Manufacturing and Life Cycle Engineering Research Group, School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia","IEEE Transactions on Automation Science and Engineering","5 Jan 2023","2023","20","1","296","309","With the increasing concern for sustainable treatment of waste electrical and electronic equipment (WEEE), methods of robotic disassembly of WEEE to address various challenges of handling end-of-life products has been a trend in research. The main challenge for robotic disassembly is the uncertainties of product structures, models, and conditions. The ability of a robotic disassembly system to learn new product structures and reason about existing knowledge of product structure is vital to addressing this challenge. This paper presents an effective learning framework and demonstrates the system’s ability to learn relevant information for the disassembly of LCD monitors. The learning algorithm uses a database of previous disassembly experience of the product family and analyses it to create rules and relations between the components and disassembly concepts before expanding the generic ontology for future disassembly runs. The results show a significant increase from 11% to 87% in successful part identification of LCD monitors after being trained on past disassembly experience. The proposed method can greatly aid robotic disassembly of any product family. Note to Practitioners—Robotic systems struggle to disassemble electronic waste due to the complexity and uncertainties in end-of-life products and variations in models and parts. An artificially intelligent method is proposed to enable a robotic disassembly system to address these uncertainties. The method uses a computing technique resembling the cognitive reasoning of a human mind in the form of a map of disassembly concepts connected by relationships. Artificial learning by the robotic system occurs by collecting data from previous disassembly runs of a product, analyzing the data, and expanding the map of knowledge with new concepts and relational rules found. The approach is tested on the robotic disassembly system’s ability to identify parts of LCD monitors which possess uncertainties. An improvement from 11% of successful part identification to 87% is found, which demonstrate that learning has taken place. This approach will be implemented in a larger robotic disassembly system and tested with real robotic disassembly runs in the near future.","1558-3783","","10.1109/TASE.2022.3149242","Australian Government Research Training Program Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708413","AI-based methods;disassembly;learning from demonstration;robotics in hazardous fields","Robots;Uncertainty;Ontologies;Electronic waste;Cognition;Monitoring;Liquid crystal displays","","3","","49","IEEE","9 Feb 2022","","","IEEE","IEEE Journals"
"SignExplainer: An Explainable AI-Enabled Framework for Sign Language Recognition With Ensemble Learning","D. R. Kothadiya; C. M. Bhatt; A. Rehman; F. S. Alamri; T. Saba","U & P U Patel Department of Computer Engineering, Faculty of Technology (FTE), Chandubhai S. Patel Institute of Technology (CSPIT), Charotar University of Science and Technology (CHARUSAT), Changa, India; Department of Computer Science and Engineering, School of Engineering and Technology, Pandit Deendayal Energy University, Gujarat, Gandhinagar, India; Artificial Intelligence and Data Analytics Laboratory (AIDA),College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia; Department of Mathematical Sciences, College of Science, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Artificial Intelligence and Data Analytics Laboratory (AIDA),College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia","IEEE Access","19 May 2023","2023","11","","47410","47419","Deep learning has significantly aided current advancements in artificial intelligence. Deep learning techniques have significantly outperformed more than typical machine learning approaches, in various fields like Computer Vision, Natural Language Processing (NLP), Robotics Science, and Human-Computer Interaction (HCI). Deep learning models are ineffective in outlining their fundamental mechanism. That’s the reason the deep learning model mainly consider as Black-Box. To establish confidence and responsibility, deep learning applications need to explain the model’s decision in addition to the prediction of results. The explainable AI (XAI) research has created methods that offer these interpretations for already trained neural networks. It’s highly recommended for computer vision tasks relevant to medical science, defense system, and many more. The proposed study is associated with XAI for Sign Language Recognition. The methodology uses an attention-based ensemble learning approach to create a prediction model more accurate. The proposed methodology used ResNet50 with the Self Attention model to design ensemble learning architecture. The proposed ensemble learning approach has achieved remarkable accuracy at 98.20%. In interpreting ensemble learning prediction, the author has proposed SignExplainer to explain the relevancy (in percentage) of predicted results. SignExplainer has illustrated excellent results, compared to other conventional Explainable AI models reported in state of the art.","2169-3536","","10.1109/ACCESS.2023.3274851","Princess Nourah bint Abdulrahman University Researchers Supporting through Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia(grant numbers:PNURSP2023R346); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122570","Deep learning;computer vision;explainable AI;SignExplainer;classification;sign language;technological development","Deep learning;Artificial intelligence;Computational modeling;Predictive models;Assistive technologies;Computer vision;Gesture recognition","","5","","45","CCBYNCND","10 May 2023","","","IEEE","IEEE Journals"
"A Survey on Ethical Principles of AI and Implementations","J. Zhou; F. Chen; A. Berry; M. Reed; S. Zhang; S. Savage","Data Science Institute University of Technology Sydney, Sydney, Australia; Data Science Institute University of Technology Sydney, Sydney, Australia; Data Science Institute University of Technology Sydney, Sydney, Australia; Reejig Pty Ltd, Sydney, Australia; Reejig Pty Ltd, Sydney, Australia; Reejig Pty Ltd, Sydney, Australia","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","3010","3017","AI has powerful capabilities in prediction, automation, planning, targeting, and personalisation. Generally, it is assumed that AI can enable machines to exhibit human-like intelligence, and is claimed to benefit to different areas of our lives. Since AI is fueled by data and is a distinct form of autonomous and self-learning agency, we are seeing increasing ethical concerns related to AI uses. In order to mitigate various ethical concerns, national and international organisations including governmental organisations, private sectors as well as research institutes have made extensive efforts by drafting ethical principles of AI, and having active discussions on ethics of AI within and beyond the AI community. This paper investigates these efforts with a focus on the identification of fundamental ethical principles of AI and their implementations. The review found that there is a convergence around limited principles and the most prevalent principles are transparency, justice and fairness, responsibility, non-maleficence, and privacy. The investigation suggests that ethical principles need to be combined with every stages of the AI lifecycle in the implementation to ensure that the AI system is designed, implemented and deployed in an ethical manner. Similar to ethical framework used in biomedical and clinical research, this paper suggests checklist-style questionnaires as benchmarks for the implementation of ethical principles of AI.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308437","AI;ethical principles;implementation","Artificial intelligence;Ethics;Standards;Guidelines;Face recognition;Privacy;Speech recognition","","23","","50","IEEE","5 Jan 2021","","","IEEE","IEEE Conferences"
"AI-Based and Digital Mental Health Apps: Balancing Need and Risk","S. Hamdoun; R. Monteleone; T. Bookman; K. Michael","School for the Future of Innovation in Society, Arizona State University, Tempe, AZ, USA; Disability Studies Program, University of Toledo, Toledo, OH, USA; Independent Editor and Journalist, Ontario, NY, USA; School for the Future of Innovation in Society, Arizona State University, Tempe, AZ, USA","IEEE Technology and Society Magazine","7 Mar 2023","2023","42","1","25","36","Mental health and well-being are increasingly important topics in discussions on public health [1]. The COVID-19 pandemic further revealed critical gaps in existing mental health services as factors such as job losses and corresponding financial issues, prolonged physical illness and death, and physical isolation led to a sharp rise in mental health conditions [2]. As such, there is increasing interest in the viability and desirability of digital mental health applications. While these dedicated applications vary widely, from platforms that connect users with healthcare professionals to diagnostic tools to self-assessments, this article specifically explores the implications of digital mental health applications in the form of chatbots [3]. Chatbots can be text based or voice enabled and may be rule based (i.e., linguistics based) or based on machine learning (ML). They can utilize the power of conversational agents well-suited to task-oriented interactions, like Apple’s Siri, Amazon’s Alexa, or Google Assistant. But increasingly, chatbot developers are leveraging conversational artificial intelligence (AI), which is the suite of tools and techniques that allow a computer program to seemingly carry out a conversational experience with a person or a group.","1937-416X","","10.1109/MTS.2023.3241309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10063146","","COVID-19;Pandemics;Virtual assistants;Mental health;Machine learning;Linguistics;Chatbots","","8","","71","IEEE","7 Mar 2023","","","IEEE","IEEE Magazines"
"Toward an Intelligent Edge: Wireless Communication Meets Machine Learning","G. Zhu; D. Liu; Y. Du; C. You; J. Zhang; K. Huang","University of Hong Kong, Hong Kong, China; University of Hong Kong, Hong Kong, China; University of Hong Kong, Hong Kong, China; National University of Singapore, Singapore, Singapore; Hong Kong Polytechnic University, Hong Kong, China; University of Hong Kong, Hong Kong, China","IEEE Communications Magazine","27 Jan 2020","2020","58","1","19","25","The recent revival of AI is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and IoT devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interest in realizing an ""intelligent edge"" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, has emerged, which crosses and revolutionizes two disciplines: wireless communication and machine learning. A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design guidelines for wireless communication in edge learning, collectively called learning- driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design guidelines. Unique research opportunities are identified.","1558-1896","","10.1109/MCOM.001.1900103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970161","","Servers;Atmospheric modeling;Artificial intelligence;Distributed databases;Wireless communication;Machine learning;Computational modeling","","328","","15","IEEE","27 Jan 2020","","","IEEE","IEEE Magazines"
"A Deep Learning Methodology to Detect Trojaned AI-based DDoS Defend Model","Y. -H. Chen; Y. -C. Lai; C. -H. Lu; Y. -C. Huang; S. -C. Chang; P. -T. Jan","Department of Information Management, National Taipei University of Nursing and Health Sciences, Taipei, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Applied Informatics, Fo Guang University, Yilan, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Business Administration, Shih Hsin University, Taipei, Taiwan","2022 8th International Conference on Automation, Robotics and Applications (ICARA)","22 Mar 2022","2022","","","243","246","DDoS attack arranges bots to send low-speed traffic to backbone links and paralyze all servers in the target area. DDoS is difficultly defended due to the two research problems (1) indistinguishability of the changing DDoS characteristics and (2) the time series attack pattern, leading that the raising attention of developing varying DDoS defending methodologies. The conventional methods to defend DDoS apply a rules-based methodology that relies on the experience of algorithm designers and cannot reflect the changing attack characteristics of DDoS in a timely manner. Numerous artificial intelligence (AI) methodologies, therefore, are introduced to defend DDoS through end-to-end functionality (Input: network status; Output: defending action) without any manual intervention. However, the AI-based DDoS Defending model often outsources training to a machine-learning-as-a-service (MLaaS) provider because of the scarce training dataset and high hardware requirement. This may cause the model been trained maliciously, which is called the Artificial Intelligence Trojan attack (AI Trojan). AI Trojan means an AI model encounters a malicious training process and then have a good performance on normal data but behaves maliciously with certain data. This study proposes GAN based AI Robustness test algorithm, Deep Learning Attack Generator (DLAG), to verify that the artificial intelligence model has been fully trained to ensure the robustness of the model. DLAG can be divided into five steps: (1) DLAG randomly generates a sample, (2) generates noise that participates in the generation of a confrontation network (DLAG), (3) input the synthetic sample to the testing AI, (4) the test results will be recorded in the test report and fed back to GAN, and (5) a new synthetic sample will be generated again for the next test cycle. The simulation shows that our proposed DLAG can detect that the AI based DDoS/LFA detector is trained by imbalance data. The simulation results also demonstrate the potential and suggested development trait of AI Trojan detection methodology.","2767-7745","978-1-6654-8383-4","10.1109/ICARA55094.2022.9738571","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9738571","Artificial Intelligence;AI Trojan;GAN;Deep Learning;Imbalance Classification","Training;Deep learning;Time series analysis;Generative adversarial networks;Robustness;Data models;Trojan horses","","","","10","IEEE","22 Mar 2022","","","IEEE","IEEE Conferences"
"AI based Diagnostic Service for IOT enabled Smart Refrigerators","T. Bansal; S. S. Agrawal; D. Kumar; M. T. Shambu; P. Inbarajan","IoT Products & Analytics, Samsung R&D Institute, Bangalore, India; IoT Products & Analytics, Samsung R&D Institute, Bangalore, India; IoT Products & Analytics, Samsung R&D Institute, Bangalore, India; IoT Products & Analytics, Samsung R&D Institute, Bangalore, India; IoT Products & Analytics, Samsung R&D Institute, Bangalore, India","2021 8th International Conference on Future Internet of Things and Cloud (FiCloud)","9 Nov 2021","2021","","","163","168","High end refrigerators come with an ice dispensing unit that provides ice cubes and crushed ice. These refrigerators often face “Ice Maker Freeze” issue causing them to stop dispensing ice. As a user, this is highly undesirable who is often left wondering as to what caused this issue. Recent trends have seen an increase in consumers opting for IoT enabled devices. These devices log their device state at regular intervals and this data can be leveraged to help predict such issues in the refrigerator before they happen. Such predictive maintenance solutions would require Machine Learning and Big Data processing wherein trends are studied and behaviors learnt for future prediction. In this paper, we propose a cloud based AI (Artificial Intelligence) solution which uses refrigerator sensor data to figure out if the device is going to have an ice-dispensing problem in the near future. This information can be shared to end users with a set of preventive steps, which in turn results in lower maintenance costs and improved user experience. This solution is built by analyzing the data gathered from 300K refrigerator devices and we were able to achieve a 90% precision in predicting possible fault scenarios.","","978-1-6654-2574-2","10.1109/FiCloud49777.2021.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590224","Smart Refrigerator;Data analysis;Artificial Intelligence;Internet of Things (IoT);Big Data analytics;Machine Learning (ML)","Cloud computing;Costs;Refrigerators;Machine learning;Market research;Ice;Internet of Things","","1","","15","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Generative AI-empowered Effective Physical-Virtual Synchronization in the Vehicular Metaverse","M. Xu; D. Niyato; H. Zhang; J. Kang; Z. Xiong; S. Mao; Z. Han","School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Electronics, Peking University, Beijing, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Singapore, Singapore; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA","2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)","6 Oct 2023","2023","","","607","611","Metaverse seamlessly blends the physical world and virtual spaces through ubiquitous communication and computing equipment and infrastructure. In intelligent transportation systems, the vehicular Metaverse can provide a fully immersive and hyperreal travel experience (e.g., via augmented reality head-up displays, AR-HUDs) to drivers and passengers in autonomous vehicles (AVs) through roadside units (RSUs). However, providing real-time and immersive services requires effective physical-virtual synchronization between AVs and virtual simulators. This paper proposes a generative AI-empowered physical-virtual synchronization framework for the vehicular Metaverse. In physical-to-virtual synchronization, digital twin (DT) tasks generated by AVs are offloaded for execution in RSUs with future route generation. In virtual-to-physical synchronization, virtual simulators customize diverse and personalized AR content via generative AI models based on user preferences. Furthermore, we propose a multi-task enhanced auction-based mechanism to match and price AVs and virtual simulators for RSUs to provide real-time and effective services. Finally, property analysis and experimental results demonstrate that the proposed mechanism is strategy-proof and adverse-selection free while increasing social surplus.","","979-8-3503-3333-6","10.1109/MetaCom57706.2023.00106","National Research Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271797","Vehicular Metaverse;generative artificial intelligence;digital twin;augmented reality;auction theory","Metaverse;Head-up displays;Multitasking;Real-time systems;Space exploration;Synchronization;Task analysis","","5","","13","IEEE","6 Oct 2023","","","IEEE","IEEE Conferences"
"Foundations of an AI-based, cross-plattform companion app for lifelong learning optimization","D. B. O. Boesl; T. Achtenberg; L. Bergler","Hochschule der Bayerischen Wirtschaft, Munich, Germany; Hochschule der Bayerischen Wirtschaft, Munich, Germany; Hochschule der Bayerischen Wirtschaft, Munich, Germany","2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)","26 Jan 2024","2023","","","1","4","Artificial Intelligence (AI) has revolutionized various domains, including education. It has the potential to transform traditional educational models and provide personalized learning experiences. Lifelong learning and continuing education have become essentials pillars for expanding personal growth and skill profiles in the professional world. This paper outlines the basis of lifelong learning and continuing education and presents assumptions, analyses, and a framework for the development of an Ai-based, cross-Platform cOmpanion-app [for] Lifelong Learning Optimization (acronym: APOLLO) as part of a 36-month funding project kindly supported by the German Federal Ministry of Education and Research (BMBF) and supervised by the German Federal Institute for Vocational Education and Training (BIBB) as part of the funding guideline of the innovation competition INVITE. It outlines the project idea, describes the motivation and the problem in the field of education.","","978-1-6654-5331-8","10.1109/TALE56641.2023.10398394","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398394","AI;lifelong learning;education;learning assistant;future of education;education model;digital assistant","Continuing education;Technological innovation;Terminology;Law;Transforms;Artificial intelligence;Optimization","","","","28","IEEE","26 Jan 2024","","","IEEE","IEEE Conferences"
"An Efficient Vertical Handoff Choice in Subsequent Generation Wireless Networks","S. Kkhera; K. Kumar","Lovely Professional University, Phagwara, Punjab, IN; School of Electrical and Electrical Electronics, Lovely Professional University, Jalandhar","2018 International Conference on Intelligent Circuits and Systems (ICICS)","4 Oct 2018","2018","","","195","200","Next Generation (4G) wireless networks tend to be diverse, integrating unlike networks to provide constant admission for mobile users with multi mode access potential. The Next creation communications systems are about a worldwide wireless communications system and define a cost efficient, adapted according to the users' needs concept. Within this research paper an efficient vertical handoff conclusion is planned. A refined, intelligent Associative Rule Mining (ARM) and Artificial Intelligence (AI) based technique is mandatory to execute the vertical handoff system in subsequent generation wireless networks to create an valuable service which reduces handoff delay and convolution.","","978-1-5386-6483-4","10.1109/ICICS.2018.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8479569","4G;Vertical Handover decision (VHD);ARM;AI","Handover;Bandwidth;Wireless LAN;Wireless networks;Delays;Artificial intelligence","","","","34","IEEE","4 Oct 2018","","","IEEE","IEEE Conferences"
"Potential Information Security Risks in The Implementation of AI - Based Systems","P. S. Lozhnikov; S. S. Zhumazhanova","Department of Complex Information Protection, Omsk State Technical University, Omsk, Russia; Department of Complex Information Protection, Omsk State Technical University, Omsk, Russia","2022 Dynamics of Systems, Mechanisms and Machines (Dynamics)","18 Jan 2023","2022","","","1","4","At present, technological solutions based on artificial intelligence (AI) are being accelerated in various sectors of the economy and social relations in the world. Practice shows that fast-developing information technologies, as a rule, carry new, previously unidentified threats to information security (IS). It is quite obvious that identification of vulnerabilities, threats and risks of AI technologies requires consideration of each technology separately or in some aggregate in cases of their joint use in application solutions. Of the wide range of AI technologies, data preparation, DevOps, Machine Learning (ML) algorithms, cloud technologies, microprocessors and public services (including Marketplaces) have received the most attention. Due to the high importance and impact on most AI solutions, this paper will focus on the key AI assets, the attacks and risks that arise when implementing AI-based systems, and the issue of building secure AI.","2644-2760","978-1-6654-6527-4","10.1109/Dynamics56256.2022.10014814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10014814","information security;artificial intelligence;information security risks;machine learning;neural networks","Machine learning algorithms;Heuristic algorithms;Microprocessors;Biological system modeling;Buildings;Information security;Machine learning","","","","10","IEEE","18 Jan 2023","","","IEEE","IEEE Conferences"
"A Review on AI-Enabled Congestion Control Schemes for Content Centric Networks","A. Masood; N. -N. Dao; H. Kim; Y. Son; H. T. Lee; J. Paek; S. Cho","School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea","2023 14th International Conference on Information and Communication Technology Convergence (ICTC)","23 Jan 2024","2023","","","659","662","Content centric networks (CCN) offer more advantages over conventional TCP/IP networks in areas like content distribution. However, congestion control functionalities in CCN present challenges such as detecting congestion, over-reducing windows for non-congested paths, and addressing fairness issues. Most existing studies employed congestion control mechanisms similar to those in TCP. In addition, the existing mechanisms were based on conventional optimization rules to adjust the rate at which Interest packets are sent to request data from downstream nodes. However, such existing mechanisms do not consider the changes in network status and caching strategy due to multi-path and multi-source transmission. Moreover, they are based on assumptions about link bandwidth. In this paper, we study the problem of congestion control in CCN and discuss its challenges. In addition, we review the existing congestion control schemes in CCN based on machine learning. Finally, we highlight the open research issues to spur further investigations.","2162-1241","979-8-3503-1327-7","10.1109/ICTC58733.2023.10393556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10393556","Content centric networks;in-network caching;congestion control","TCPIP;Machine learning;Bandwidth;Information and communication technology;Optimization;Convergence","","","","15","IEEE","23 Jan 2024","","","IEEE","IEEE Conferences"
"A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle","S. Shahriar; S. Allana; S. M. Hazratifard; R. Dara","School of Computer Science, University of Guelph, Guelph, Canada; School of Computer Science, University of Guelph, Guelph, Canada; Department of Electrical and Computer Engineering, University of Victoria, Victoria, Canada; School of Computer Science, University of Guelph, Guelph, Canada","IEEE Access","23 Jun 2023","2023","11","","61829","61854","Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual’s privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.","2169-3536","","10.1109/ACCESS.2023.3287195","Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155147","Artificial intelligence;machine learning;AI life cycle;privacy risk;privacy legislation;privacy enhancing solutions","Artificial intelligence;Privacy;Data privacy;Surveys;Regulation;Machine learning;Security","","1","","192","CCBYNCND","19 Jun 2023","","","IEEE","IEEE Journals"
"Space Applications of a Trusted AI Framework: Experiences and Lessons Learned","L. Mandrake; G. Doran; A. Goel; H. Ono; R. Amini; M. S. Feather; L. Fesq; P. Slingerland; L. Perry; B. Bycroft; J. Kaufman","Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA","2022 IEEE Aerospace Conference (AERO)","10 Aug 2022","2022","","","1","20","Artificial intelligence (AI), which encompasses machine learning (ML), has become a critical technology due to its well-established success in a wide array of applications. However, the proper application of AI remains a central topic of discussion in many safety-critical fields. This has limited its success in autonomous systems due to the difficulty of ensuring AI algorithms will perform as desired and that users will understand and trust how they operate. In response, there is growing demand for trustability in AI to address both the expectations and concerns regarding its use. The Aerospace Corporation (Aerospace) developed a Framework for Trusted AI (henceforth referred to as the framework) to encourage best practices for the implementation, assessment, and control of AI-based applications. It is generally applicable, being based on terms and definitions that cut across AI domains, and thus is a starting point for practitioners to tailor to their particular application. To help demonstrate how the framework can be tailored into mission assurance guidance for the space domain, Aerospace sought the involvement of the Jet Propulsion Laboratory (JPL) to engage with actual examples of AI-based space autonomy. We report here on the framework's application to two JPL projects. The first, Machine learning-based Analytics for Automated Rover Systems (MAARS), is a suite of algorithms that is intended to run onboard a rover to enhance its safety and productivity. The second, the Ocean Worlds Life Surveyor (OWLS), is comprised of an instrument suite and onboard software that is designed to search for life on an icy moon using microscopy and mass spectrometry while judiciously summarizing and prioritizing science data for downlink. Both MAARS and OWLS are intended to have minimal manual control while relying on complex autonomy software to operate within the unforgiving environment of deep space. Therefore, trusted AI for these systems is required for successful adoption of the autonomy software. To capture the needs for trust, interviews with a variety of JPL personnel responsible for developing autonomy solutions were conducted and are summarized here. Additionally, the application of the framework is presented as a means to lower the barrier for AI deployment. The intent of this document is to encourage researchers, engineers, and program managers to adopt new strategies when considering whether to leverage AI in autonomous systems.","1095-323X","978-1-6654-3760-8","10.1109/AERO53065.2022.9843322","Jet Propulsion Laboratory; California Institute of Technology; National Aeronautics and Space Administration(grant numbers:80NM0018D0004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843322","","Machine learning algorithms;Autonomous systems;Space missions;OWL;Software;Artificial intelligence;Research and development","","12","","49","IEEE","10 Aug 2022","","","IEEE","IEEE Conferences"
"Model-Driven Prompt Engineering","R. Clarisó; J. Cabot","Universitat Oberta de Catalunya (UOC), Barcelona, Spain; Universitat Oberta de Catalunya (UOC), Barcelona, Spain","2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS)","12 Dec 2023","2023","","","47","54","Generative artificial intelligence (AI) systems are capable of synthesizing complex content such as text, source code or images according to the instructions described in a natural language prompt. The quality of the output depends on crafting a suitable prompt. This has given rise to prompt engineering, the process of designing natural language prompts to best take advantage of the capabilities of generative AI systems.Through experimentation, the creative and research communities have created guidelines and strategies for creating good prompts. However, even for the same task, these best practices vary depending on the particular system receiving the prompt. Moreover, some systems offer additional features using a custom platform-specific syntax, e.g., assigning a degree of relevance to specific concepts within the prompt.In this paper, we propose applying model-driven engineering to support the prompt engineering process. Using a domain-specific language (DSL), we define platform-independent prompts that can later be adapted to provide good quality outputs in a target AI system. The DSL also facilitates managing prompts by providing mechanisms for prompt versioning and prompt chaining. Tool support is available thanks to a Langium-based Visual Studio Code plugin.","","979-8-3503-2480-8","10.1109/MODELS58315.2023.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343974","prompt engineering;model-driven engineering;domain-specific language;generative AI;large language models","Visualization;Source coding;Natural languages;Syntactics;Model driven engineering;DSL;Artificial intelligence","","","","52","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Effects of Extended Stochastic Gradient Descent Algorithms on Improving Latent Factor-Based Recommender Systems","X. Luo; M. Zhou","Chongqing Engineering Research Center of Big Data Application for Smart Cities, and the Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA","IEEE Robotics and Automation Letters","28 Jan 2019","2019","4","2","618","624","High-dimensional and sparse (HiDS) matrices from recommender systems contain various useful patterns. A latent factor (LF) analysis is highly efficient in grasping these patterns. Stochastic gradient descent (SGD) is a widely adopted algorithm to train an LF model. Can its extensions be capable of further improving an LF models' convergence rate and prediction accuracy for missing data? To answer this question, this work selects two of representative extended SGD algorithms to propose two novel LF models. Experimental results from two HiDS matrices generated by real recommender systems show that compared standard SGD, extended SGD algorithms enable an LF model to achieve a higher prediction accuracy for missing data of an HiDS matrix, a faster convergence rate, and a larger model diversity.","2377-3766","","10.1109/LRA.2019.2891986","National Natural Science Foundation of China(grant numbers:61772493,91646114); Chongqing Research Program of Technology Innovation and Application(grant numbers:cstc2017rgzn-zdyfX0020,cstc2017zdcy-zdyf0554,cstc2017rgzn-zdyf0118); Chongqing Cultivation Program of Innovation and Entrepreneurship Demonstration(grant numbers:cstc2017kjrc-cxcytd0149); Chongqing Overseas Scholars Innovation Program(grant numbers:cx2017012,cx2018011); Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607099","Big data in robotics and automation;AI-based methods;machine learning","Data models;Stochastic processes;Predictive models;Recommender systems;Standards;Prediction algorithms;Convergence","","14","","35","IEEE","10 Jan 2019","","","IEEE","IEEE Journals"
"Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations","J. Bang; S. Kim; J. W. Nam; D. -G. Yang","Electronics and Telecommunications Research Institute, Daejun, Republic of Korea; Ewha Womans University, Seoul, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea; University of Science and Technology, Daejun, Republic of Korea","2021 International Conference on Platform Technology and Service (PlatCon)","20 Jan 2022","2021","","","1","5","AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.","","978-1-6654-1766-2","10.1109/PlatCon53246.2021.9680760","Korean National Police Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680760","conversational chatbot;ethical design;framework","Ethics;Privacy;Systematics;Chatbots;Social factors;Stakeholders;Artificial intelligence","","7","","33","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Applying a Trustworthy AI Framework to Mitigate Bias and Increase Workforce Gender Diversity","X. M. Liu; D. Murphy","School of Technology and Innovation, Marymount University, Arlington, Virginia, USA; School of Technology and Innovation, Marymount University, Arlington, Virginia, USA","2022 IEEE International Symposium on Technology and Society (ISTAS)","28 Aug 2023","2022","1","","1","5","Organizations increasingly use artificial intelligence (AI) technologies in their screening and recruiting process. However, AI-enabled recruiting and talent management tools have also introduced risks of unfair bias that may compromise workforce diversity. This conceptual paper frames an ethical discussion regarding gender equity in AI-enabled workforce decision applications. The authors examined several real-world cases in which AI was used in talent acquisition. The ensuing question is whether the use of AI in the hiring process can be turned into an advantage to improve gender equity. To address the question, a multi-faceted trustworthy AI framework was reviewed and applied to the workforce decision context. A list of implementation guidelines is proposed to mitigate bias and increase diversity in the IT workforce. The authors aim to stimulate further discussions and investigation on this complex topic and to call for action to develop educational programs or awareness campaigns on trustworthy AI, so improving gender equity in technology hiring.","2158-3412","978-1-6654-8410-7","10.1109/ISTAS55053.2022.10227119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10227119","Artificial intelligence (AI);bias;trustworthy;gender equity;diversity;workforce","Training;Ethics;Gender equity;Shape;Software;Regulation;Artificial intelligence","","","","38","IEEE","28 Aug 2023","","","IEEE","IEEE Conferences"
"AI Based Chat-Bot Using Azure Cognitive Services","K. Tajane; S. Dave; P. Jahagirdar; A. Ghadge; A. Musale","Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India; Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India; Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India; Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India; Department of Computer Engineering, Pimpri Chinchwad College of Engineering, Pune, India","2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)","25 Apr 2019","2018","","","1","4","Letters ruled the earlier era in communication. Then with emergence of Telephones and subsequently mobile phones, voice conversations ruled the communication. However, currently, with the emergence of Internet and lots of social media, chat conversations are ruling the world. Think of your closest friend and ask yourself, have you talked more or chatted more? So, with popularity of chat in today's world, many technologists envisioned that chat couldn't just be a mode of communication between humans but also between a human and a computer. That's what chat-bot is. In some cases it is powered by machine learning (the more you interact with the chat-bot the smarter it gets). Or, more commonly, it is driven using intelligent rules (i.e. if a person says this, respond with that). A chat-bot can be useful in providing services in a variety of scenarios. These services include life-saving health messages, it may also include weather forecast or to purchase a new laptop, smartphone, and anything else in between. Many of the big companies like Google (Google Assistant), Amazon (Alexa), Microsoft (Cortana) and Oracle are spending good amount of energy and money for research on personal assistants. The following subjects would be touched upon for the development of chat-bot: · Using Azure Bot Architecture · Using NLP for Language Understanding from the user and for the Language Generation · Using Custom Vision services for the image recognition.","","978-1-5386-5257-2","10.1109/ICCUBEA.2018.8697737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697737","Azure;NLP;Computer Vision","","","5","","19","IEEE","25 Apr 2019","","","IEEE","IEEE Conferences"
"AI-Based Military Decision Support Using Natural Language","M. Möbius; D. Kallfass; T. Doll; D. Kunde","Dept. Operational Analysis and Studies, Airbus Defence and Space GmbH, Immenstaad, Germany; Dept. Operational Analysis and Studies, Airbus Defence and Space GmbH, Immenstaad, Germany; Army Concepts and Capabilities Development Centre, Division I, Cologne, Germany; German Army Headquarters von-Hardenberg-Kaserne, Strausberg, Germany","2022 Winter Simulation Conference (WSC)","23 Jan 2023","2022","","","1","12","To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.","1558-4305","978-1-6654-7661-4","10.1109/WSC57314.2022.10015234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10015234","","Visualization;Natural languages;Reinforcement learning;Cognition;Artificial intelligence","","","","12","IEEE","23 Jan 2023","","","IEEE","IEEE Conferences"
"AI Based Smart Remedial Observants in COVID-19 Crisis","S. Kumar; A. Panwal; S. Gharat; N. Ghatte; D. Karia","Electronics Department, Sardar Patel Institute of Technology, Mumbai, India; Electronics Department, Sardar Patel Institute of Technology, Mumbai, India; Electronics Department, Sardar Patel Institute of Technology, Mumbai, India; Electronics Department, Sardar Patel Institute of Technology, Mumbai, India; Electronics Department, Sardar Patel Institute of Technology, Mumbai, India","2021 International Conference on Communication information and Computing Technology (ICCICT)","12 Aug 2021","2021","","","1","5","Coronavirus disease (COVID-19) is a contagious [1] disease caused by becoming infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [2]. Numerous nations have acquainted social distancing measures to slow down the spread of the COVID-19 pandemic as people can spread the virus before they know they are sick. The solution focuses on a web-based solution to alert the residents and outsiders in case of any non-compliance of rules. In this work, an AI-powered solution is developed that leverages Machine learning based algorithm to guarantee that individuals are keeping up a safe distance from one another. A software-based approach is taken for providing a simple and engaging user experience to the user that will help the society and other authorities track and analyses the implications of such rules. The web application will be used to alert the users in case of any breaking of the law. Along with this, a system that detects if people are wearing a mask or not will also be verified by the algorithm. The model built can be deployed in the existing CCTV cameras to monitor each and every place of gathering without the need for any additional hardware systems.","","978-1-6654-0430-3","10.1109/ICCICT50803.2021.9510051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510051","Social Distancing;Mask Detection;OpenCV;Convolutional Neural Networks (CNN);Deep Learning;COVID","COVID-19;Pandemics;Surveillance;Neural networks;Nose;Human factors;Social factors","","","","15","IEEE","12 Aug 2021","","","IEEE","IEEE Conferences"
"Implementation of A Fuzzy Logic Progression For Alcohol Addicts Using Fuzzy Control System(FCS)","O. M. Omone; E. Aggrey; M. Takács; M. Kozlovszky","BioTech Research Center, EKIK, Óbuda University, Budapest, Hungary; Faculty of Informatics, University of Debrecen, Debrecen, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary; John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary","2020 IEEE 18th International Symposium on Intelligent Systems and Informatics (SISY)","8 Oct 2020","2020","","","161","166","The use of the Reduced Alcohol Intake (RAI) logic model is to help monitor alcoholic addicts and help them reduce alcohol intake for a better life and improved academic performance. The purpose of this study is to use the Mamdani Fuzzy Inference System (MFIS) component, which includes the application of a T-S (Takagi-Sugeno) model-based Fuzzy Control System (FCS) and a Fuzzy Logic System (FLS) as a rule-based system (Fuzzy Control System - FCS) to assemble all inputs in the RAI model to achieve classified fuzzy outputs. As initiated in the theoretical logic model (the RAI logic model), there is a direct identification of breakpoints for a transition between phases in the model. Thus, it can be used as an AI system that is efficient to monitor and examine the progression of alcohol addicts (to know what percentage of improvement they have reached overtime). Using the T-S method, the core parameters (motivation and self-determined state) of the RAI model were analyzed to find a linear interaction between the existing variables. In this paper, the variables of motivation and self-determined state are scaled between 0 to 10 to predict the level of improvement in percentage (%).","1949-0488","978-1-7281-7352-8","10.1109/SISY50555.2020.9217079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217079","Alcohol Addicts;Mamdani Fuzzy Inference System (MFIS);Motivation;Reduced Alcohol Intake (RAI) Logic Model;Self-determined State","Fuzzy logic;Fuzzy control;Alcoholic beverages;Fuzzy sets;Computational modeling;Monitoring;Predictive models","","1","","10","IEEE","8 Oct 2020","","","IEEE","IEEE Conferences"
"AI-based speed control models for the autonomous train: a literature review","A. Plissonneau; D. Trentesaux; W. Ben-Messaoud; A. Bekrar","LAMIH UMR CNRS 8201, UPHF Railenium, Valenciennes, France; LAMIH UMR CNRS 8201, UPHF Railenium, Valenciennes, France; Railenium, Valenciennes, France; LAMIH UMR CNRS 8201, UPHF Railenium, Valenciennes, France","2021 Third International Conference on Transportation and Smart Technologies (TST)","27 Aug 2021","2021","","","9","15","The railway industry recently showed interest in the potential use of AI to render trains autonomous in order to reduce cost and improve security and performance. This paper focuses on the integration of AI into Automatic Train Operation (ATO) systems to control train speed. The objective of this paper is to present and analyze a review of the literature made in that context. The review is done according to a typology based on three axis: the inputs and objectives of the model, the AI method used by authors and last, the validation process. Our review shows that AI based approaches outperform classical approaches and that learning based methods are superior to rule-based systems. Meanwhile, the contributions present incomplete validation processes, difficulties to generalize the proposed AI method and last, a lack of use of perceptual data during decision making. This analysis enables us to draw some prospects relevant to the solving of the listed limitations.","","978-1-6654-2903-0","10.1109/TST52996.2021.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516336","","Learning systems;Industries;Velocity control;Decision making;Transportation;Control systems;Rail transportation","","3","","23","IEEE","27 Aug 2021","","","IEEE","IEEE Conferences"
"A Spectroscopy-Based Sensor for the AI-Based Classification of Lipemic and Hematic Parameters","L. Carletti; D. Bagnoli; D. Paci; G. Ciuti","Department of Information Engineering, University of Pisa, Pisa, Italy; Medica S.p.A., Medolla, Italy; Medica S.p.A., Medolla, Italy; The BioRobotics Institute, Scuola Superiore Sant'Anna, Pisa, Italy","IEEE Sensors Letters","23 Oct 2023","2023","7","11","1","4","Dyslipidemias are chronic conditions characterized by elevated levels of LDL cholesterol and/or triglycerides in the bloodstream. Guidelines from the European Society of Cardiology recommended lipoprotein apheresis (LA) as the last-resort therapy for severe cases of familial hypercholesterolemia. However, LA devices equipped with a blood leak detector (BLD) sensor often generate false alarms due to turbidity caused by serum lipoproteins. This letter presents a protocol for creating hyperlipemic plasma samples and proposes the use of a microspectrometer-based BLD sensor to collect the spectra. Furthermore, to address the false alarm problem (blood rate ≥0.7%), we developed a first approach using thresholding and linear support vector machine (SVM). In addition, to improve data classification performance, three artificial neural networks (ANNs) were developed with different classification tasks, then applied to four different databases. ANNs aim to solve the problem of false alarms and accurately classify samples based on blood and phospholipids concentration, achieving 99% accuracy for data classification based on the combination of phospholipids and blood percentage.","2475-1472","","10.1109/LSENS.2023.3316878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10258326","Sensor applications;microspectrometer-based sensor;artificial neural network (ANN);biomedical sensors;blood leak detector (BLD);lipoprotein apheresis (LA)","Blood;Sensors;Plasmas;Databases;Task analysis;Support vector machines;Optical variables measurement","","","","18","IEEE","22 Sep 2023","","","IEEE","IEEE Journals"
"Software Engineering for Machine Learning: A Case Study","S. Amershi; A. Begel; C. Bird; R. DeLine; H. Gall; E. Kamar; N. Nagappan; B. Nushi; T. Zimmermann","Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; University of Zurich, Zurich, Switzerland; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA","2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)","19 Aug 2019","2019","","","291","300","Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.","","978-1-7281-1760-7","10.1109/ICSE-SEIP.2019.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804457","artifical intelligence;machine learning;software engineering;process;data","Software;Machine learning;Software engineering;Buildings;Organizations;Data models","","357","","37","IEEE","19 Aug 2019","","","IEEE","IEEE Conferences"
"Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information","I. Naja; M. Markovic; P. Edwards; W. Pang; C. Cottrill; R. Williams","Department of Computing Science, University of Aberdeen, Aberdeen, U.K.; Department of Computing Science, University of Aberdeen, Aberdeen, U.K.; Department of Computing Science, University of Aberdeen, Aberdeen, U.K.; School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, U.K.; School of Engineering and Centre for Transport Research, University of Aberdeen, Aberdeen, U.K. (Deceased); Faculty of Law and Pembroke College, University of Oxford, Oxford, U.K.","IEEE Access","20 Jul 2022","2022","10","","74383","74411","To enhance trustworthiness of AI systems, a number of solutions have been proposed to document how such systems are built and used. A key facet of realizing trust in AI is how to make such systems accountable - a challenging task, not least due to the lack of an agreed definition of accountability and differing perspectives on what information should be recorded and how it should be used (e.g., to inform audit). Information originates across the life cycle stages of an AI system and from a variety of sources (individuals, organizations, systems), raising numerous challenges around collection, management, and audit. In our previous work, we argued that semantic Knowledge Graphs (KGs) are ideally suited to address those challenges and we presented an approach utilizing KGs to aid in the tasks of modelling, recording, viewing, and auditing accountability information related to the design stage of AI system development. Moreover, as KGs store data in a structured format understandable by both humans and machines, we argued that this approach provides new opportunities for building intelligent applications that facilitate and automate such tasks. In this paper, we expand our earlier work by reporting additional detailed requirements for knowledge representation and capture in the context of AI accountability; these extend the scope of our work beyond the design stage, to also include system implementation. Furthermore, we present the RAInS ontology which has been extended to satisfy these requirements. We evaluate our approach against three popular baseline frameworks, namely, Datasheets, Model Cards, and FactSheets, by comparing the range of information that can be captured by our KGs against these three frameworks. We demonstrate that our approach subsumes and extends the capabilities of the baseline frameworks and discuss how KGs can be used to integrate and enhance accountability information collection processes.","2169-3536","","10.1109/ACCESS.2022.3188967","Realising Accountable Intelligent Systems (RAInS) Project through the UK Research and Innovation (UKRI) Digital Economy Program(grant numbers:EP/R033846/1,EP/R03379X/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815594","Accountability;AI systems;machine learning;ontology;provenance","Artificial intelligence;Ontologies;Rain;Law;Task analysis;Recording;Inspection","","1","","54","CCBY","6 Jul 2022","","","IEEE","IEEE Journals"
"State of AI-Based Monitoring in Smart Manufacturing and Introduction to Focused Section","H. Ding; R. X. Gao; A. J. Isaksson; R. G. Landers; T. Parisini; Y. Yuan","School of Mechanical Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Case Western Reserve University, Cleveland, OH, USA; ABB Corporate Research Center, Västerås, Sweden; Missouri University of Science and Technology, Rolla, MO, USA; Department of Electrical and Electronic Engineering, Imperial College London, London; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China","IEEE/ASME Transactions on Mechatronics","14 Oct 2020","2020","25","5","2143","2154","Over the past few decades, intelligentization, supported by artificial intelligence (AI) technologies, has become an important trend for industrial manufacturing, accelerating the development of smart manufacturing. In modern industries, standard AI has been endowed with additional attributes, yielding the so-called industrial artificial intelligence (IAI) that has become the technical core of smart manufacturing. AI-powered manufacturing brings remarkable improvements in many aspects of closed-loop production chains from manufacturing processes to end product logistics. In particular, IAI incorporating domain knowledge has benefited the area of production monitoring considerably. Advanced AI methods such as deep neural networks, adversarial training, and transfer learning have been widely used to support both diagnostics and predictive maintenance of the entire production process. It is generally believed that IAI is the critical technologies needed to drive the future evolution of industrial manufacturing. This article offers a comprehensive overview of AI-powered manufacturing and its applications in monitoring. More specifically, it summarizes the key technologies of IAI and discusses their typical application scenarios with respect to three major aspects of production monitoring: fault diagnosis, remaining useful life prediction, and quality inspection. In addition, the existing problems and future research directions of IAI are also discussed. This article further introduces the papers in this focused section on AI-based monitoring in smart manufacturing by weaving them into the overview, highlighting how they contribute to and extend the body of literature in this area.","1941-014X","","10.1109/TMECH.2020.3022983","National Key Research and Development Program of China(grant numbers:2018YFB1701202); European Union's Horizon 2020 Research and Innovation Programme(grant numbers:739551); Italian Ministry for Research(grant numbers:2017YKXYXJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189823","Artificial intelligence (AI);deep learning;fault diagnosis (FD);machine learning;quality inspection (QI);remaining useful life prediction (RULP);smart manufacturing","Production;Monitoring;Smart manufacturing;Fault diagnosis;Machine learning","","63","","59","IEEE","9 Sep 2020","","","IEEE","IEEE Journals"
"A Study on Product Recommendation System based on Deep Learning and Collaborative Filtering","M. D. Bhagat; P. N. Chatur","Department of Computer Science & Engineering, Govt. College of Engineering, Amravati, India; Department of Computer Science & Engineering, Govt. College of Engineering, Amravati, India","2023 Third International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)","15 May 2023","2023","","","1","5","This essay analyses and contrasts the literature that has already been written about various product recommendation systems and the mechanisms that underlie them. Although there are many research contributions in the literature, in this article I have critically and thoroughly examined recent research and review papers that are relevant to AI-based product recommendation systems. The present techniques are divided into groups based on the fundamental ideas included into their processes. The idea put out by the concerned writers, the experimental technique, and the performance assessment criteria are highlighted. Also noted are the researchers' assertions. The flaws that have been found are highlighted together with our results from the thorough literature study. This work is crucial for the comparison of different AI-based product recommendation systems, which is a necessary step before dealing with related problems. Following a review of the literature, I have put up a system for recommending products to users, in which the tool suggests products that a particular user would want to buy. I have gathered information about items and users by using ML algorithms. The suggested system establishes a link between the people and the products.","","978-1-6654-9400-7","10.1109/ICAECT57570.2023.10117628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10117628","Artificial Intelligence;Collaborative Filtering;Deep Learning;Machine Learning;Product Recommendation Systems","Deep learning;Collaborative filtering;Collaboration;Filtering algorithms;Recommender systems","","1","","10","IEEE","15 May 2023","","","IEEE","IEEE Conferences"
"Intelligent Traffic Management System: AI-Enabled IoT Traffic Lights to Mitigate Accidents and Minimize Environmental Pollution","S. Usmonov; A. Pradeep; Z. Fakhriddinov; T. Sanjar; A. Abdurakhim; M. Khusniddinova","Software Engineering, New Uzbekistan University, Tashkent, Uzbekistan; Software Engineering, New Uzbekistan University, Tashkent, Uzbekistan; Software Engineering, New Uzbekistan University, Tashkent, Uzbekistan; Software Engineering, New Uzbekistan University, Tashkent, Uzbekistan; Mechanical Engineering, New Uzbekistan University, Tashkent, Uzbekistan; Software Engineering, New Uzbekistan University, Tashkent, Uzbekistan","2023 3rd International Conference on Intelligent Technologies (CONIT)","7 Aug 2023","2023","","","1","6","Reducing traffic and pollution is crucial for the well-being of both people and the planet. These issues mainly affect developing nations due to rapid urbanization and limited infrastructure. This paper emphasizes the development of smart traffic management systems that monitor and control traffic flow, lessen congestion, and shorten travel times using IoT and LoRa. Lowering the number of vehicles on the road can lower fuel use and emissions. IoT can also gather real-time data on air quality, which can help pollution reduction efforts and inform air quality policies.","","979-8-3503-3860-7","10.1109/CONIT59222.2023.10205868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10205868","Traffic Management;AI Traffic Control;LoRa;Smart Camera;Adaptive neuro-fuzzy inference system","Pollution;Standards organizations;Traffic control;Real-time systems;Safety;Internet of Things;Fuels","","","","19","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"What is Software Quality for AI Engineers? Towards a Thinning of the Fog","V. Golendukhina; V. Lenarduzzi; M. Felderer","University of Innsbruck, Innsbruck, Austria; University of Oulu, Oulu, Finland; University of Innsbruck, Innsbruck, Austria","2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN)","17 Jun 2022","2022","","","1","9","It is often overseen that AI-enabled systems are also software systems and therefore rely on software quality assurance (SQA). Thus, the goal of this study is to investigate the software quality assurance strategies adopted during the development, integration, and maintenance of AI/ML components and code. We conducted semi-structured interviews with representatives of ten Austrian SMEs that develop AI-enabled systems. A qualitative analysis of the interview data identified 12 issues in the development of AI/ML components. Furthermore, we identified when quality issues arise in AI/ML components and how they are detected. The results of this study should guide future work on software quality assurance processes and techniques for AI/ML components.","","978-1-4503-9275-4","10.1145/3522664.3528599","Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796383","AI;Machine Learning;Software Quality;Empirical Study","Training;Codes;Software quality;Maintenance engineering;Programming;Software systems;Libraries","","2","","0","","17 Jun 2022","","","IEEE","IEEE Conferences"
"Neuro-Inspired Plasticity for Biologically Realistic Self-Adaptation of Neural Network Weights","R. Kalahasty",NA,"2023 IEEE International Conference on Development and Learning (ICDL)","25 Dec 2023","2023","","","113","120","The Prefrontal Cortex is the core of higher level learning and memory. It currently operates much like an AI system, in the sense that its actions are guided via a dopamine based reward function, however there is one critical difference, the PFC has the ability to rewire itself - plasticity. Here, we look to biological studies to find the governing rules of plasticity - competitiveness, memory, and correlation - to create a biologically plausible implementation of plasticity called Hybrid Plasticity. We implement it in continuous time recurrent neural networks (CTRNNS) completing simple working memory tasks. We show that the implementation of plasticity increases the adaptability of the working memory process within networks, while also resulting in a significant decrease in active neurons within the network indicating higher efficiency. We further demonstrate that plasticity results in an increased small world index, indicating high levels of efficiency, parallel processing, and cognitive integration as proposed by Global Workspace Theory. Plasticity CTRNNs are also shown to self organize into brain-like connectivity patterns including inhibitory clusters, excitatory clusters, and inhibitory autapses during their forward pass. Hence, Hybrid Plasticity represents a proof-of-concept solution for bringing forth biologically realistic phenomena within neural networks resulting in increased efficiency and generalizability.","","978-1-6654-7075-9","10.1109/ICDL55364.2023.10364505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10364505","","Recurrent neural networks;Correlation;Neurons;Memory management;Parallel processing;Biology;Indexes","","","","25","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"Predicting the Time Until a Vehicle Changes the Lane Using LSTM-Based Recurrent Neural Networks","F. Wirthmüller; M. Klimke; J. Schlechtriemen; J. Hipp; M. Reichert","Mercedes-Benz AG, Böblingen, Germany; RWTH Aachen University, Aachen, Germany; Mercedes-Benz AG, Böblingen, Germany; Mercedes-Benz AG, Böblingen, Germany; Institute of Databases and Information Systems (DBIS), Ulm University, Ulm, Germany","IEEE Robotics and Automation Letters","15 Mar 2021","2021","6","2","2357","2364","To plan safe and comfortable trajectories for automated vehicles on highways, accurate predictions of traffic situations are needed. So far, a lot of research effort has been spent on detecting lane change maneuvers rather than on estimating the point in time a lane change actually happens. In practice, however, this temporal information might be even more useful. This letter deals with the development of a system that accurately predicts the time to the next lane change of surrounding vehicles on highways using long short-term memory-based recurrent neural networks. An extensive evaluation based on a large real-world data set shows that our approach is able to make reliable predictions, even in the most challenging situations, with a root mean squared error around 0.7 seconds. Already 3.5 seconds prior to lane changes the predictions become highly accurate, showing a median error of less than 0.25 seconds. In summary, this article forms a fundamental step towards downstreamed highly accurate position predictions.","2377-3766","","10.1109/LRA.2021.3058930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353203","Intelligent Transportation Systems;AI-Based Methods;Automated Driving;Vehicle Motion Prediction","Task analysis;Road transportation;Recurrent neural networks;Trajectory;Forestry;History;Computer architecture","","19","","25","CCBY","11 Feb 2021","","","IEEE","IEEE Journals"
"AI-Powered Ransomware Detection Framework","S. Poudyal; D. Dasgupta","Department of Computer Science, The University of Memphis, Memphis, TN, USA; Department of Computer Science, The University of Memphis, Memphis, TN, USA","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","1154","1161","Ransomware attacks are taking advantage of the ongoing pandemics and attacking the vulnerable systems in business, health sector, education, insurance, bank, and government sectors. Various approaches have been proposed to combat ransomware, but the dynamic nature of malware writers often bypasses the security checkpoints. There are commercial tools available in the market for ransomware analysis and detection, but their performance is questionable. This paper aims at proposing an AI-based ransomware detection framework and designing a detection tool (AIRaD) using a combination of both static and dynamic malware analysis techniques. Dynamic binary instrumentation is done using PIN tool, function call trace is analyzed leveraging Cuckoo sandbox and Ghidra. Features extracted at DLL, function call, and assembly level are processed with NLP, association rule mining techniques and fed to different machine learning classifiers. Support vector machine and Adaboost with J48 algorithms achieved the highest accuracy of 99.54% with 0.005 false-positive rates for a multi-level combined term frequency approach.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308387","Ransomware detection;Reverse Engineering;Artificial Intelligence;Dynamic Binary Instrumentation;AI Tool;NLP;FP-Growth","Ransomware;Tools;Instruments;Encryption;Cryptography;Reverse engineering;Feature extraction","","14","","31","IEEE","5 Jan 2021","","","IEEE","IEEE Conferences"
"Analysis of Crypto-Ransomware Using ML-Based Multi-Level Profiling","S. Poudyal; D. Dasgupta","Department of Computer Science, Center for Information Assurance, The University of Memphis, Memphis, TN, USA; Department of Computer Science, Center for Information Assurance, The University of Memphis, Memphis, TN, USA","IEEE Access","9 Sep 2021","2021","9","","122532","122547","Crypto-ransomware is the most prevalent form of modern malware, has affected various industries, demanding a significant amount of ransom. Mainly, small businesses, healthcare, education, and government sectors have been under continuous attacks by these adversaries. Various static and dynamic analysis techniques exist, but these methods become less efficient as the malware writers continuously trick the defenders. Numerous research of ransomware with AI techniques often lack the behavioral analysis and its correlation mapping. In this work, we developed an AI-powered hybrid approach overcoming the recent challenges to detect ransomware. Specifically, we proposed a deep inspection approach for multi-level profiling of crypto-ransomware, which captures the distinct features at Dynamic link library, function call, and assembly levels. We showed how the code segments correlate at these levels for studied samples. Our hybrid multi-level analysis approach includes advanced static and dynamic methods and a novel strategy of analyzing behavioral chains with AI techniques. Moreover, association rule mining, natural language processing techniques, and machine learning classifiers are integrated for building ransomware validation and detection model. We experimented with crypto-ransomware samples (collected from VirusTotal). One of the machine learning algorithms achieved the highest accuracy of 99.72% and a false positive rate of 0.003 with two class datasets. The result exhibited that multi-level profiling can better detect ransomware samples with higher accuracy. The multi-level feature sequence can be extracted from most of the applications running in the different operating systems; therefore, we believe that our method can detect ransomware for devices on multiple platforms. We designed a prototype, AIRaD (AI-based Ransomware Detection) tool, which will allow researchers and the defenders to visualize the analysis with proper interpretation.","2169-3536","","10.1109/ACCESS.2021.3109260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9526633","Artificial intelligence;hybrid malware analysis;machine learning;multi-level profiling;ransomware detection;reverse engineering","Ransomware;Malware;Cryptography;Tools;Phishing;Feature extraction;Encryption","","12","","31","CCBYNCND","31 Aug 2021","","","IEEE","IEEE Journals"
"iART: Learning From Demonstration for Assisted Robotic Therapy Using LSTM","S. Pareek; T. Kesavadas","Department of Industrial and Enterprise Systems Engineering, University of Illinois, Urbana-Champaign, USA; Department of Industrial and Enterprise Systems Engineering, University of Illinois, Urbana-Champaign, USA","IEEE Robotics and Automation Letters","10 Jan 2020","2020","5","2","477","484","In this letter, we present an intelligent Assistant for Robotic Therapy (iART), that provides robotic assistance during 3D trajectory tracking tasks. We propose a novel LSTM-based robot learning from demonstration (LfD) paradigm to mimic a therapist's assistance behavior. iART presents a trajectory agnostic LfD routine that can generalize learned behavior from a single trajectory to any 3D shape. Once the therapist's behavior has been learned, iART enables the patient to modify this behavior as per their preference. The system requires only a single demonstration of 2 minutes and exhibits a mean accuracy of 91.41% in predicting, and hence mimicking a therapist's assistance behavior. The system delivers stable assistance in realtime and successfully reproduces different types of assistance behaviors.","2377-3766","","10.1109/LRA.2019.2961845","National Science Foundation(grant numbers:1502339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939469","Rehabilitation robotics;deep learning in robotics and automation;learning from demonstration;AI-based methods","Robots;Task analysis;Trajectory;Medical treatment;Trajectory tracking;Performance evaluation;Erbium","","6","","18","IEEE","23 Dec 2019","","","IEEE","IEEE Journals"
"A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System","M. Grote; J. Bogner","Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany; Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany","2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)","4 Jul 2023","2023","","","145","157","Today, many systems use artificial intelligence (AI) to solve complex problems. While this often increases system effectiveness, developing a production-ready AI-based system is a difficult task. Thus, solid AI engineering practices are required to ensure the quality of the resulting system and to improve the development process. While several practices have already been proposed for the development of AI-based systems, detailed practical experiences of applying these practices are rare.In this paper, we aim to address this gap by collecting such experiences during a case study, namely the development of an autonomous stock trading system that uses machine learning functionality to invest in stocks. We selected 10 AI engineering practices from the literature and systematically applied them during development, with the goal to collect evidence about their applicability and effectiveness. Using structured field notes, we documented our experiences. Furthermore, we also used field notes to document challenges that occurred during the development, and the solutions we applied to overcome them. Afterwards, we analyzed the collected field notes, and evaluated how each practice improved the development. Lastly, we compared our evidence with existing literature.Most applied practices improved our system, albeit to varying extent, and we were able to overcome all major challenges. The qualitative results provide detailed accounts about 10 AI engineering practices, as well as challenges and solutions associated with such a project. Our experiences therefore enrich the emerging body of evidence in this field, which may be especially helpful for practitioner teams new to AI engineering.","","979-8-3503-0113-7","10.1109/CAIN58948.2023.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164761","AI engineering practices;case study;autonomous stock trading","Training;Measurement;Machine learning;Solids;Stakeholders;Artificial intelligence;Task analysis","","","","53","IEEE","4 Jul 2023","","","IEEE","IEEE Conferences"
"AI Augmentation for Trustworthy AI: Augmented Robot Teleoperation","D. L. Marino; J. Grandio; C. S. Wickramasinghe; K. Schroeder; K. Bourne; A. V. Filippas; M. Manic","Virginia Commonwealth University, Richmond, Virginia; Virginia Commonwealth University, Richmond, Virginia; Virginia Commonwealth University, Richmond, Virginia; Commonwealth Center for Advanced Manufacturing (CCAM), Disputanta, Virginia; Commonwealth Center for Advanced Manufacturing (CCAM), Disputanta, Virginia; Commonwealth Center for Advanced Manufacturing (CCAM), Disputanta, Virginia; Virginia Commonwealth University, Richmond, Virginia","2020 13th International Conference on Human System Interaction (HSI)","17 Jul 2020","2020","","","155","161","Despite the performance of state-of-the-art Artificial Intelligence (AI) systems, some sectors hesitate to adopt AI because of a lack of trust in these systems. This attitude is prevalent among high-risk areas, where there is a reluctance to remove humans entirely from the loop. In these scenarios, Augmentation provides a preferred alternative over complete Automation. Instead of replacing humans, AI Augmentation uses AI to improve and support human operations, creating an environment where humans work side by side with AI systems. In this paper, we discuss how AI Augmentation can provide a path for building Trustworthy AI. We exemplify this approach using Robot Teleoperation. We lay out design guidelines and motivations for the development of AI Augmentation for Robot Teleoperation. Finally, we discuss the design of a Robot Teleoperation testbed for the development of AI Augmentation systems.","2158-2254","978-1-7281-7392-4","10.1109/HSI49210.2020.9142659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142659","Augmentation;Trustworthy AI;Teleoperation;Shared Autonomy","Artificial intelligence;Robustness;Robots;Task analysis;Automation;Buildings;Uncertainty","","4","","46","IEEE","17 Jul 2020","","","IEEE","IEEE Conferences"
"Automatic Alert Generation against Pre-defined Rules-set for Perimetric Security of Sensitive Premises using YOLOv3","M. Asif; A. Ilyas; S. M. Sajjad; A. Masood","Independent Scholar, Islamabad, Pakistan; Independent Scholar, Islamabad, Pakistan; Department of Cybersecurity and Data Science, Riphah International University, Islamabad, Pakistan; Independent Scholar, Islamabad, Pakistan","2019 15th International Conference on Emerging Technologies (ICET)","13 Feb 2020","2019","","","1","6","Adaptation of artificial intelligence (AI) based solutions at sensitive locations is growing rapidly. Use of these techniques along with surveillance cameras has become a primary requirement of smart cities to convert data into intelligible information. Consequently, these solutions are minimizing the effort of training and reliance on human resource. In this research paper, we have devised use cases of object detection with focus on human and luggage detection in real-time using a Convolutional Neural Network (CNN) technique YOLOv3. This technique, trained on MS-COCO dataset, has not been able to produce desirable results when tested on images from subcontinent region containing luggage, human or both. As a case study, we enhanced MS-COCO dataset by incorporating our own collection of realistic images. The study is carried out on a commodity hardware to strengthen our claim to use technology over humans. The proposed solution is developed for analysing video streams in real time against a predefined rules-set. Idea to automate the process of surveillance at strategic locations without human intervention opens a new window of research for literary community to develop cost effective solutions.","","978-1-7281-5403-9","10.1109/ICET48972.2019.8994686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994686","","","","","","22","IEEE","13 Feb 2020","","","IEEE","IEEE Conferences"
"AI-Augmented Early Warning Models for Commercial and SME Segments: Leveraging Unstructured Data and Time-Series Analytics","G. Atasoy; G. Aydindoğan; S. Arslan","Data Science and Artificial Intelligence Prometeia SPA İstanbul Merkez Şubesi, İstanbul, Türkiye; Data Science and Artificial Intelligence Prometeia SPA İstanbul Merkez Şubesi, İstanbul, Türkiye; Data Science and Artificial Intelligence Prometeia SPA İstanbul Merkez Şubesi, İstanbul, Türkiye","2023 8th International Conference on Computer Science and Engineering (UBMK)","24 Oct 2023","2023","","","91","96","The Early Warning System is a critical application that uses advanced AI algorithms to monitor large amounts of data to detect potential payment difficulties f or c lients. In this paper, we present a novel approach to generate time-series indicators from new data sources such as Trade Registry Gazette announcements and records of the number of days of delinquency. Our method leverages machine learning algorithms such as Extreme Gradient Boosting (XGBoost) to identify hidden patterns and trends in these data sources, thus overcoming the problems with the traditional rule-based models. By analyzing this data, we can identify time-series anomalies and predict the likelihood of 10 days of delinquency 6 months ahead for the clients in the SME (Small and medium-sized enterprises) and Commercial segments. Our analysis demonstrates that our approach can achieve high accuracy in delinquency prediction, enabling financial i nstitutions t o t ake p roactive m easures to prevent potential losses. Our proposed method can enrich credit monitoring systems and enhance the ability of financial institutions to mitigate financial risk.","2521-1641","979-8-3503-4081-5","10.1109/UBMK59864.2023.10286634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286634","Early warning system;days past due;XGBoost;time-series;Tsfresh","Computer science;Machine learning algorithms;Soft sensors;Computational modeling;Alarm systems;Market research;Boosting;Data models;Risk management;Monitoring","","","","20","IEEE","24 Oct 2023","","","IEEE","IEEE Conferences"
"An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations","R. Khummongkol; M. Yokota","Department of Computer Engineering, University of Phayao, Phayao, Thailand; Department of System Management, Fukuoka Institute of Technology, Fukuoka, Japan","2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST)","15 Jan 2018","2017","","","254","259","It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL.","2325-5994","978-1-5386-2965-9","10.1109/ICAwST.2017.8256457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256457","natural language understanding;human — robot interaction;semantic interpretation","Robots;Semantics;Natural languages;Rivers;Conferences;Artificial intelligence;Cognition","","1","","14","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"“Black Box Justice”: Robot Judges and AI-based Judgment Processes in China’s Court System","N. Wang","Department of Science, Technology, and Society, Virginia Tech, Falls Church, USA","2020 IEEE International Symposium on Technology and Society (ISTAS)","28 Jun 2021","2020","","","58","65","Artificial Intelligence (AI) has been widely adopted in China's court system to improve work efficiency to better serve the public. This paper evaluates the three stages of how AI is transforming China's court system: from being a simple auxiliary tool, performing basic tasks through reconciliation of case and trial information; to assisting judges in decision-making by providing recommendations via the AI's ability to learn from past precedent and standardized evidence review; and finally, to developing into autonomous agents able to take charge of the court and make judgments as robot judges. However, public skepticism around the credibility of the so-called “black box” of AI algorithms in ensuring fair judgment and achieving justice is escalating, with the concern that efficiency does not guarantee effectiveness or ensure public interest. This paper aims to analyze “black box” issues in each stage and demonstrates why China's effort to pursue AI as an innovative technical practice to realize judicial fairness should take complex social and ethical contexts into consideration. In order to serve for public good in China's court system, the new technology must ensure its representation of human values and include public participation.","2158-3412","978-1-6654-1507-1","10.1109/ISTAS50296.2020.9462216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462216","law and society;artificial intelligence;robot judge;public interest;ethics;justice","Training;Ethics;Government;Decision making;Transforms;Tools;History","","8","","37","IEEE","28 Jun 2021","","","IEEE","IEEE Conferences"
"Data-Driven AI-Based Parameters Tuning Using Grid Partition Algorithm for Predicting Climatic Effect on Epidemic Diseases","S. B. Abdullahi; K. Muangchoo; A. B. Abubakar; A. H. Ibrahim; K. O. Aremu","Zonal Criminal Investigation Department, Force Criminal Investigation and Intelligence Department, Nigeria Police, Abuja, Nigeria; Department of Mathematics and Statistics, Faculty of Science and Technology, Rajamangala University of Technology Phra Nakhon (RMUTP), Bangkok, Thailand; Department of Mathematical Sciences, Faculty of Physical Sciences, Bayero University at Kano, Kano, Nigeria; Department of Mathematics, Faculty of Science, KMUTTFixed Point Research Laboratory, Room SCL 802 Fixed Point Laboratory, Science Laboratory Building, King Mongkut’s University of Technology Thonburi (KMUTT), Bangkok, Thailand; Department of Mathematics and Applied Mathematics, Sefako Makgatho Health Sciences University, Ga-Rankuwa, South Africa","IEEE Access","14 Apr 2021","2021","9","","55388","55412","Adaptive Neuro-fuzzy Inference System (ANFIS) remains one of the promising AI techniques to handle data over-fitting and as well, improves generalization. Presently, many ANFIS optimization techniques have been synergized and found effective at some points through trial and error procedures. In this work, we tune ANFIS using Grid partition algorithm to handle unseen data effectively with fast convergence. This model is initialized using a careful selection of effective parameters that discriminate climate conditions; minimum temperature, maximum temperature, average temperature, wind speed and relative humidity. These parameters are used as inputs for ANFIS, whereas confirmed cases of COVID-19 is chosen as dependent values for two consecutive months and first ten days of December for new COVID-19 confirmed cases according to the Department of disease control (DDC) Thailand. The proposed ANFIS model provides outstanding achievement to predict confirmed cases of COVID-19 with R2 of 0.99. Furthermore, data set trend analysis is done to compare fluctuations of daily climatic parameters, to satisfy our proposition, and illustrates the serious effect of these parameters on COVID-19 epidemic virus spread.","2169-3536","","10.1109/ACCESS.2021.3068215","Rajamangala University of Technology Phra Nakhon (RMUTP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400168","Adaptive neuro fuzzy inference system;artificial Intelligence;COVID-19;climatic impacts;epidemic diseases;grid partition algorithm;parameters tuning","COVID-19;Viruses (medical);Meteorology;Wind speed;Humidity;Temperature distribution;Mathematics","","6","","50","CCBY","12 Apr 2021","","","IEEE","IEEE Journals"
"Procedure2Command: an AI-based Nuclear Power Plant Control Command Code Generation Prototype System","C. Lu; X. Cao; Y. Zhu; T. Huang; Z. Pan; X. Li","State Key Laboratory of Nuclear Power Safety Monitoring Tech. and Eqpt., China Nuclear Power Engineering Co., Ltd, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; State Key Laboratory of Nuclear Power Safety Monitoring Tech. and Eqpt., China Nuclear Power Engineering Co., Ltd, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China","2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","13 May 2021","2020","","","653","659","Nuclear power plant control systems are complex and require extremely high safety. Safety operation procedure flowcharts drawn by experts with many pages are often used as the guidebooks to help human operators avoid improper operations. To help operators better use these flowcharts and reduce their mental burden, here we propose a control command code generation prototype system, which involves artificial intelligence technologies, especially natural language processing, to automatically translate the nuclear power plant safety operation procedure flowcharts into executable codes. The proposed system includes three components: a flowchart decomposition tool, a text-code translation dataset, and a deep-learning based code generation model. Experimental results show that our proposed method can generate command codes with comparable accuracy as manual translation in a much higher inference speed.","","978-1-6654-2314-4","10.1109/ICMCCE51767.2020.00144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421891","nuclear power plant;control system;code generation;natural language processing","Flowcharts;Shape;Prototypes;Process control;Manuals;Tools;Natural language processing","","","","21","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"An AI Based Automatic Translator for Ancient Hieroglyphic Language—From Scanned Images to English Text","A. Sobhy; M. Helmy; M. Khalil; S. Elmasry; Y. Boules; N. Negied","Faculty of Electrical and Computer Engineering, University of Ottawa, Ottawa, ON, Canada; Faculty of Electrical and Computer Engineering, University of Ottawa, Ottawa, ON, Canada; Faculty of Electrical and Computer Engineering, University of Ottawa, Ottawa, ON, Canada; Faculty of Electrical and Computer Engineering, University of Ottawa, Ottawa, ON, Canada; Faculty of Electrical and Computer Engineering, University of Ottawa, Ottawa, ON, Canada; School of Communication and Information Engineering, Zewail City of Science and Technology, Giza, Egypt","IEEE Access","24 Apr 2023","2023","11","","38796","38804","Recent advancements in the fields of Machine Learning and Deep Learning made a huge transformation in other fields that are not related to Computer Science. In this work, a new framework is proposed to tackle the problem of translating the old Egyptian Hieroglyphic writings to English language through deploying both Image Processing and Natural Language Processing techniques combined with AI approaches. Our primary goal is to design an application that completely revolutionizes a tourist’s experience while navigating Egyptian Historical sites. This work utilize different AI techniques to automatically convert the scanned photos of hieroglyphic language to understandable and readable English language, through two main sub-tasks: The automatic detection and recognizing of the scanned glyphs images and the translation of them into English language. Different data sources of this low-resource language were explored and augmented to train and test our models. Results of different models and algorithms are assessed and analyzed to evaluate our work. State-of-the-art results are achieved compared to literature in both automatic glyphs recognition, and glyphs-to-English translation.","2169-3536","","10.1109/ACCESS.2023.3267981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103702","Machine translation;glyph;image processing;classification;object detection;natural language processing","Natural language processing;Artificial intelligence;Symbols;Image segmentation;Object detection;Machine translation;Image resolution","","","","21","CCBYNCND","17 Apr 2023","","","IEEE","IEEE Journals"
"AI Based Periodic Forecasting Rate Prediction with Secured Optimized Cryptographic Method Sales Forecasting in Retail Business Sector","R. Ronaldo; T. K. Arora; S. Agarwal; A. Lobanova; V. T. Vladimirovna; A. S. Yadav","Islamic Banking, STEBI Lampung University, Lampung, Indonesia; Department of Applied Sciences & Humanities, ABES Engineering College, India; Department of Mathematics, SRM Institute of Science and Technology, Modinagar, India; Department of Design, International Education Corporation, Kazakhstan; Department of Design, International Education Corporation, Kazakhstan; Department of Mathematics, SRM Institute of Science and Technology, Modinagar, India","2022 International Interdisciplinary Humanitarian Conference for Sustainability (IIHC)","17 Mar 2023","2022","","","1040","1046","Artificial intelligence is the recent development in security and data analysis 8n business sector for maximize profits using data processing technology. Today's business is managing huge databases to store more information need to safety. The amount of data is expected to increase further based on the business needs to forecasting the developing trends. The retail business sectors need new data processing technologies and intelligent forecast models of sales trends with greater potential accuracy in security and reliability. This is an important prerequisite for planning and decision making of a company is a big issue. To resolve this problem, we propose a security surveillance and sales forecasting in the retail business sector based on periodic forecasting rate (PFR) and advanced encryption security (AES) to protect the data. This provides decision making based data forecasting based on the previous data detains which is applied beads n successive feature prediction rate. Then the prediction result processed in business sector in secure cryptography using advance verified authentication to protect the data. This proposed system produces higher prediction rate in forecasting rate and security in higher level as well than other methods.","","978-1-6654-5687-6","10.1109/IIHC55949.2022.10059792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059792","Sales forecasting;security analysis;Artificial intelligence;decision planning;prediction;cryptographic approach","Surveillance;Decision making;Authentication;Prediction algorithms;Market research;Encryption;Forecasting","","","","14","IEEE","17 Mar 2023","","","IEEE","IEEE Conferences"
"CoupHM: Task Scheduling Using Gradient Based Optimization for Human-Machine Computing Systems","H. Wang; Z. Ren; Z. Yu; Y. Zhang; J. Liu; H. Cui","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China","2022 IEEE 28th International Conference on Parallel and Distributed Systems (ICPADS)","27 Mar 2023","2023","","","859","866","We witnessed great advancement in Artificial Intelligence (AI) powered technologies in recent years, and yet, when applied to certain high-stake contexts, such as medical diagnosis, automatic driving and criminal justice, they are not qualified. This matter can be greatly settled by Human-Machine Computing (HMC), which is an effective computing paradigm that couples the expertise and demonstration abilities of humans with the high-performance computing power of machines. This work studies an optimal task scheduling problem for HMC systems, where various tasks are decomposed and dispatched to humans and AI-enabled machines to provide significantly better benefits compared to either type of computing resources in isolation. However, designing such optimal task scheduling is challenging because of the stochastic hybrid features of machines, as well as various human professional abilities. Considering the Quality of Service (QoS) and the heterogeneity of human-machine computing resources, we propose CoupHM, a feasible task scheduler using gradient based optimization for HMC systems. In particular, we firstly present the underlying architecture of HMC system and details of the task-driven workload model. On that basis, we then formulate the objective optimization problem to be solved and describe the composition of the CoupHM scheduler. Finally, the performance of our solution is evaluated by the simulation experiments, and the results indicate that the proposed scheduler has preferable performance both in balancing resources and guaranteeing QoS, which can serve as guidelines for future research on HMC systems.","2690-5965","978-1-6654-7315-6","10.1109/ICPADS56603.2022.00116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10077975","Human-machine computing;Task scheduling;Gradient based optimization;Quality of service","Adaptation models;Processor scheduling;Computational modeling;Quality of service;Computer architecture;Dynamic scheduling;Task analysis;Man-machine systems;Optimization;Guidelines","","","","26","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"Leveraging Traditional Design for Reliability Techniques for Artificial Intelligence","B. Werner; B. Schumeg",Combat Capabilities Development Command Armaments Center; Combat Capabilities Development Command Armaments Center,"2022 Annual Reliability and Maintainability Symposium (RAMS)","20 Sep 2022","2022","","","1","6","Across academia, industry, and government there has been a resurgence of interest and development of Artificial Intelligence (AI) as it emerges from a second winter. With advances in microchips, networks, sensors, and data storage, AI and Machine Learning (ML) are becoming more accessible and feasible for utilization in fielded products to assist end Users with faster decision making and lightened cognitive load. However, with these advances in technology there is also concern of deploying products that may behave in unpredictable, erratic – or, in general, unreliable ways. These concerns, among others, have been voiced by boards, organizations, and government appointed commissions such as the Defense Innovation Board (DIB) and National Security Commission on AI (NSCAI). Even at the highest levels of leadership, the Secretary of Defense has stated that “Our development, deployment, and use of AI must always be responsible, equitable, traceable, reliable, and governable” [1]. All the voices and reports have a common theme and request: a push for means and methods to ensure assurance of AI enabled systems, and ultimately trust from evaluators and users.","2577-0993","978-1-6654-2432-5","10.1109/RAMS51457.2022.9893957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893957","design for reliability;artificial intelligence;machine learning;trust and assurance","Integrated circuits;Technological innovation;Leadership;Government;Random access memory;Machine learning;Reliability engineering","","1","","18","USGov","20 Sep 2022","","","IEEE","IEEE Conferences"
"Checklist for Validating Trustworthy AI","S. -H. Han; H. -J. Choi","School of Computing, KAIST, Daejoen, Republic of Korea; School of Computing, KAIST, Daejoen, Republic of Korea","2022 IEEE International Conference on Big Data and Smart Computing (BigComp)","23 Mar 2022","2022","","","391","394","In the recent years AI technologies have been improved and utilized in the various real-world fields such as life, economy, finance, transportation, game, etc. Especially, the deep learning, one of the learning-based machine learning methods, has shown remarkable performance improvement in a broad variety of studies. As the widespread use of AI systems including the deep learning, however, the issue of reliability of AI-based systems has recently emerged. In the case of the many AI systems, they use a huge amount of data to train their models as well as the system is very complex for humans to comprehend. Hence, humans cannot be able to understand AI systems and have no confidence in the results they generate. Furthermore, it can cause various problems such as unexplained system error or uncontrollable system behavior when using AI systems in the real-world, and even can lead to very serious situations in sensitive services such as aviation, medical care, and security. In this paper, we examine a checklist to improve a reliability of AI system. Specifically, we introduce considerations with regard to the life cycle of an AI system.","2375-9356","978-1-6654-2197-3","10.1109/BigComp54360.2022.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736560","Trustworthy AI;Explainable AI;AI Trustability Guidelines","Deep learning;Transportation;Finance;Medical services;Games;Robustness;Safety","","2","","31","IEEE","23 Mar 2022","","","IEEE","IEEE Conferences"
"Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions","H. Pearce; B. Ahmad; B. Tan; B. Dolan-Gavitt; R. Karri","Department of ECE, New York University, Brooklyn, NY, USA; Department of ECE, New York University, Brooklyn, NY, USA; Department of ESE, University of Calgary, Calgary, CA, Alberta; Department of CSE, New York University, Brooklyn, NY, USA; Department of ECE, New York University, Brooklyn, NY, USA","2022 IEEE Symposium on Security and Privacy (SP)","27 Jul 2022","2022","","","754","768","There is burgeoning interest in designing AI-based systems to assist humans in designing computing systems, including tools that automatically generate computer code. The most notable of these comes in the form of the first self-described ‘AI pair programmer’, GitHub Copilot, which is a language model trained over open-source GitHub code. However, code often contains bugs—and so, given the vast quantity of unvetted code that Copilot has processed, it is certain that the language model will have learned from exploitable, buggy code. This raises concerns on the security of Copilot’s code contributions. In this work, we systematically investigate the prevalence and conditions that can cause GitHub Copilot to recommend insecure code. To perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, e.g. those from MITRE’s “Top 25” Common Weakness Enumeration (CWE) list. We explore Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40% to be vulnerable.","2375-1207","978-1-6654-1316-9","10.1109/SP46214.2022.9833571","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833571","Cybersecurity;Artificial Intelligence (AI);code generation;Common Weakness Enumerations (CWEs)","Privacy;Codes;Computational modeling;Keyboards;Computer crime;Open source software;Software development management","","39","","30","IEEE","27 Jul 2022","","","IEEE","IEEE Conferences"
"AI Toolbox Concept for the Arrowhead Framework","D. Ficzere; G. Hollósi; A. Frankó; P. Varga","Dept. of Telecommunications and Media Informatics, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Dept. of Telecommunications and Media Informatics, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Dept. of Telecommunications and Media Informatics, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Dept. of Telecommunications and Media Informatics, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary","2023 19th International Conference on Network and Service Management (CNSM)","28 Nov 2023","2023","","","1","7","Artificial Intelligence (AI) has become a game-changer across numerous industrial areas, revolutionizing the way businesses operate and enhancing their competitiveness. The Arrowhead Framework, renowned for its service-oriented architecture and interconnectivity principles, presents an ideal platform for the development and deployment of AI-driven solutions for industrial Cyber-physical System of Systems (CPSoS). This paper delves into the formulation of an AI Toolbox that enhances the capabilities of the Arrowhead Framework, aiming to harness the synergies between AI and a robust architectural foundation. The paper presents the main objectives and requirements for the AI Toolbox, and also describes its concept, operation, and deployment principles. For a better understanding, the paper demonstrates how the AI Toolbox works through a generic industrial safety use case. In conclusion, this paper contributes a comprehensive perspective on the formulation of the Arrowhead AI Toolbox, demonstrating how the Arrowhead Framework can offer AI-based services for industrial use cases.","2165-963X","978-3-903176-59-1","10.23919/CNSM59352.2023.10327821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10327821","AI;machine learning;artificial intelligence;Arrowhead;industrial AI;edge AI;industrial automation;SOA;intelligent services","Scalability;Cyber-physical systems;Service-oriented architecture;Safety;Security;Reliability;Artificial intelligence","","","","48","","28 Nov 2023","","","IEEE","IEEE Conferences"
"From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where","I. Ahmed; G. Jeon; F. Piccialli","Center of Excellence in Information Technology, Institute of Management Sciences, Hayatabad, Peshawar, Pakistan; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea; Department of Mathematics and Applications “R.Caccioppoli,”, University of Naples Federico II, Naples, Italy","IEEE Transactions on Industrial Informatics","10 May 2022","2022","18","8","5031","5042","Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications.","1941-0050","","10.1109/TII.2022.3146552","4I: mixed reality, machine learning, gamification and educational for Industry(grant numbers:F/190130/01-03/X44); Fondo per la Crescita Sostenibile—Sportello; Fabbrica Intelligente; PON I & C(grant numbers:CUP: B66G21000040005,COR: 4641138); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9695219","Artificial intelligence (AI);cloud computing;cyber-physical system;explainable artificial intelligence (XAI);Industry 4.0;Internet of Things (IoT)","Fourth Industrial Revolution;Artificial intelligence;Industries;Hidden Markov models;Manufacturing;Service robots;Robots","","164","","84","IEEE","27 Jan 2022","","","IEEE","IEEE Journals"
"Realtime Safety Analysis System using Deep Learning for Fire Related Activities in Construction Sites","U. K. Dwivedi; C. Wiwatcharakoses; Y. Sekimoto","Hazama Ando Corporation, Tokyo, Japan; Hazama Ando Corporation, Tokyo, Japan; Department of Civil Engineering, University of Tokyo, Tokyo, Japan","2022 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)","30 Dec 2022","2022","","","1","5","The era of digital transformation focuses on the integration of digital and AI based technology in construction industry for sustainable economic growth and high quality of life. This paper aims to provide a real-time detection and tracking of various construction activities and provide immediate practical safety guidelines and alert for probable accidental scenarios to ensure the safety of construction site and workers by using deep learning algorithms with vision-based edge devices and smartphone. Proposed paper develops a hybrid algorithm using scene classification first, and dependent object detection and tracking second to analyze vast category of fire related activities from video and images in real-time using computationally challenging devices. To cover the ever-changing construction location, easy to move smartphone-based applications were developed with AI as an API solution. The review of the results confirms superior real-time performance in successfully identifying and providing clear safety guidelines for indoor and outdoor fire related activities such as welding work and fire safety equipment and workers safety gear such as hardhat helmet. The study validated the practicality of IoT and deep learning-based solutions for construction jobsites with indoor and outdoor locations.","","978-1-6654-7095-7","10.1109/ICECCME55909.2022.9987855","University of Tokyo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9987855","Internet of things (IoT);Edge computing;deep learning;smart construction;real-time","Deep learning;Performance evaluation;Tracking;Welding;Streaming media;Real-time systems;Safety","","4","","30","IEEE","30 Dec 2022","","","IEEE","IEEE Conferences"
"AI-Empowered Management and Orchestration of Vehicular Systems in the Beyond 5G Era","N. Slamnik-Kriještorac; M. Camelo; C. -Y. Chang; P. Soto; L. Cominardi; D. De Vleeschauwer; S. Latré; J. M. Marquez-Barja","University of Antwerp, Belgium; University of Antwerp, Belgium; Nokia Bell Labs, Belgium; University of Antwerp, Belgium; Zettascale, France; Nokia Bell Labs, Belgium; University of Antwerp, Belgium; University of Antwerp, Belgium","IEEE Network","24 Oct 2023","2023","37","4","305","313","The complexity of orchestrating Beyond 5G services, such as vehicular, demands novel approaches to remove limitations of existing techniques, as these might cause a large delay in orchestration operations, and thus, negatively impact the service performance. For instance, the human-in-the-loop approach is slow and prone to errors, and closed loop control using rule-based algorithms is difficult to design, as an abundant number of parameters need to be configured. Applying Artificial Intelligence (Al)/Machine Learning (ML), in combination with Network Function Virtualization (NFV) and Software Defined Networking (SDN), seems a promising solution for enabling automation and intelligence that will optimize orchestration operations. In this article, we study the challenges in current ETSI NFV orchestration solutions for B5G C-V2X edge services; propose an Al/ML-based closed-loop orchestration framework; propose how and which Al/ML techniques can alleviate the identified challenges and what are the implications resulting from applying certain Al/ML techniques; and discuss A//ML-based system enablers for B5G C-V2X services.","1558-156X","","10.1109/MNET.008.2300024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10293244","","Automation;5G mobile communication;Software algorithms;Learning (artificial intelligence);Human in the loop;Network function virtualization;Delays;Complexity theory;Software defined networking","","","","15","IEEE","24 Oct 2023","","","IEEE","IEEE Magazines"
"Unsupervised Hebbian Learning on Point Sets in StarCraft II","B. Kang; H. Kumar; S. Dash; S. Mukhopadhyay","School of Electrical and Computer Engineering Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering Georgia Institute of Technology, Atlanta, GA, USA","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Learning the evolution of real-time strategy (RTS) game is a challenging problem in artificial intelligent (AI) system. In this paper, we present a novel Hebbian learning method to extract the global feature of a point set in StarCraft II game units, and its application to predict the movement of the points. Our model includes encoder, LSTM, and decoder, and we train the encoder with the unsupervised learning method. We introduce the concept of neuron activity aware learning combined with k-Winner-Takes-All. The optimal value of neuron activity is mathematically derived, and experiments support the effectiveness of the concept over the downstream task. Our Hebbian learning rule benefits the prediction with lower loss compared to self-supervised learning. Also, our model significantly saves the computational cost such as activations and FLOPs compared to a frame-based approach.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892259","Office of Naval Research(grant numbers:N000142012432); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892259","Point Set;Hebbian Learning;Winner-Takes-All;Long Short-Term Memory;Game AI","Computational modeling;Neurons;Self-supervised learning;Games;Feature extraction;Mathematical models;Computational efficiency","","1","","16","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"SRL-ORCA: A Socially Aware Multi-Agent Mapless Navigation Algorithm in Complex Dynamic Scenes","J. Qin; J. Qin; J. Qiu; Q. Liu; M. Li; Q. Ma","Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China","IEEE Robotics and Automation Letters","20 Nov 2023","2024","9","1","143","150","For real-world navigation, it is important to endow robots with the capabilities to navigate safely and efficiently in a complex environment with both dynamic and static obstacles. However, achieving path-finding in non-convex complex environments without maps as well as enabling multiple robots to follow social rules for obstacle avoidance remain challenging problems. In this letter, we propose a socially aware mapless navigation algorithm, namely Safe Reinforcement Learning-Optimal Reciprocal Collision Avoidance (SRL-ORCA). This is a multi-agent safe reinforcement learning algorithm by using ORCA as external knowledge to provide safety guarantees. This algorithm further introduces traffic norms of human society to improve social comfort and achieve cooperative avoidance by following human social customs. The result of experiments shows that SRL-ORCA learns strategies to obey specific traffic rules. Compared to RL, SRL-ORCA shows a significant improvement in navigation success rate in different complex scenarios. SRL-ORCA is able to cope with non-convex obstacle environments without falling into local minima and has a 14.5% improvement in average time to goal compared to ORCA.","2377-3766","","10.1109/LRA.2023.3331621","National Key Research and Development Program of China(grant numbers:2022ZD0120002); National Natural Science Foundation of China(grant numbers:62003322,62303435); Fundamental Research Funds for the Central Universities(grant numbers:2022SMECP04); Science and Technology Major Project of Anhui Province(grant numbers:202203a06020011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313936","AI-Enabled robotics;autonomous vehicle navigation;robot safety","Navigation;Collision avoidance;Safety;Robots;Vehicle dynamics;Heuristic algorithms;Task analysis","","","","25","IEEE","9 Nov 2023","","","IEEE","IEEE Journals"
"Smart tourism chatbot system using Multi-domain Tourism Information DST","H. -C. Kang; K. -B. Kang; D. -H. Kim; M. -C. Jwa; T. -S. Ko; J. -W. Jwa","Dept. of Smart Electronic Control, Jeju Campus of Korea Polytechnic, Jeju, South Korea; National federation of fisheries cooperatives, Jeju, South Korea; Dept. of Telecomm. Eng., Jeju National University, Jeju, South Korea; School of Computer Science and Eng, Korea University of Technology and Education, Cheonan-si, South Korea; Dept. of Telecomm. Eng., Jeju National University, Jeju, South Korea; Dept. of Telecomm. Eng., Jeju National University, Jeju, South Korea","2023 Fourteenth International Conference on Ubiquitous and Future Networks (ICUFN)","7 Aug 2023","2023","","","608","612","The smart tourism service provides tourists with travel planner services and tour guide services for easy and convenient travel throughout the entire travel process. In this paper, we develop the AI-based chatbot service using a pretrained language model (PLM) and provide tourism information so that tourists can make their travel plans. The proposed chatbot system consists of the DST server, the Neo4J graph DB and MySQL DB servers, and the natural language generation (NLG) server. The dialogue state tracking (DST) server understands the intention of tourists’ questions to overcome the shortcomings of the previous rule-based chatbot system [7]. We define the domains and slots of the tourism information DST model with the 4W1H method and develop the dataset [12] for transfer learning of the SOM DST model [14]. The Neo4J and MySQL web servers search tourism information from the tourism information knowledgebase and the smart tourism information system, respectively. The NLG server provides the searched tourism information to the smart tourism app.","2165-8536","979-8-3503-3538-5","10.1109/ICUFN57995.2023.10200288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200288","AI-based Chatbot;Smart Tourism;Dialogue State Tracking;Pre-trained Language Model;Tourism Information Knowledgebase","Transfer learning;Natural languages;Chatbots;Web servers;Information systems","","","","15","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"Role of Artificial Intelligence in Haematological Disorder","D. Guleria; V. K. Garg","Department of Medical Lab Technology, Chandigarh University, Mohali, India; Department of Medical Lab Technology, Chandigarh University, Mohali, India","2023 3rd International Conference on Innovative Sustainable Computational Technologies (CISCT)","21 Dec 2023","2023","","","1","4","Artificial intelligence (AI) is a branch of computer science that uses a computational framework to replicate human brain functions. The primary non-natural neuron was created in 1943, and the primary non-natural neural system (ANN) was applied to hereditary procedures soon afterward. Researchers and scientists have already recognized the potential for a comparable technology in medicine. The capability of this technology to retain and analyses altogether medicinal information consumes it very alluring to complement or perhaps replace clinician in creation a designs. The routine of skilled or knowledge-based organizations in dull scientific use for analysis, healing management, and predictive assessment are examples of requests of artificial intelligence in medicine. New samples contain procedures practical to analysis in, psychiatry, heart illnesses etc. Biomedical applications include protein structure prediction, analysis and clustering of gene expression data, genome sequencing The first AI-based gadgets have been used in hematology to manage routine laboratory data. Created on neural systems expert by information since marginal plasma study, new methods for the differential diagnosis of certain diseases, such as anemias, thalassemia, and leukemia, are now available.","","979-8-3503-0336-0","10.1109/CISCT57197.2023.10351237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10351237","Artificial intelligence;artificial neural network;machine learning","Proteins;Sequential analysis;Protein engineering;Neurons;Knowledge based systems;Organizations;Learning (artificial intelligence)","","","","12","IEEE","21 Dec 2023","","","IEEE","IEEE Conferences"
"Privacy-Preserving Gesture Recognition with Explainable Type-2 Fuzzy Logic Based Systems","J. Rožman; H. Hagras; J. A. Perez; D. Clarke; B. Müller; S. F. Data","The Computational Intelligence Centre, School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; The Computational Intelligence Centre, School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; The Computational Intelligence Centre, School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK; Exploitation Group, Plextek Plextek Ltd., Great Chesterford, UK; Exploitation Group, Plextek Plextek Ltd., Great Chesterford, UK; Exploitation Group, Plextek Plextek Ltd., Great Chesterford, UK","2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","26 Aug 2020","2020","","","1","8","Smart homes are a growing market in need of privacy preserving sensors paired with explainable, interpretable and reliable control systems. The recent boom in Artificial Intelligence (AI) has seen an ever-growing persistence to incorporate it in all spheres of human life including the household. This growth in AI has been met with reciprocal concern for the privacy impacts and reluctance to introduce sensors, such as cameras, into homes. This concern has led to research of sensors not traditionally found in households, mainly short range radar. There has been also increasing awareness of AI transparency and explainability. Traditional AI black box models are not trusted, despite boasting high accuracy scores, due to the inability to understand what the decisions were based on. Interval Type-2 Fuzzy Logic offers a powerful alternative, achieving close to black box levels of performance while remaining completely interpretable. This paper presents a privacy preserving short range radar sensor coupled with an Explainable AI system employing a Big Bang Big Crunch (BB-BC) Interval Type-2 Fuzzy Logic System (FLS) to classify gestures performed in an indoor environment.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177768","Type-2 Fuzzy Logic;Big Bang - Big Crunch;Privacy Preserving Sensing;Explainable Artificial Intelligence (XAI)","Fuzzy logic;Sensors;Uncertainty;Radar;Three-dimensional displays;Privacy;Artificial intelligence","","3","","29","IEEE","26 Aug 2020","","","IEEE","IEEE Conferences"
"A Novel Implementation of an AI-Based Smart Construction Safety Inspection Protocol in the UAE","M. Z. Shanti; C. -S. Cho; Y. -J. Byon; C. Y. Yeun; T. -Y. Kim; S. -K. Kim; A. Altunaiji","Department of Civil, Infrastructure and Environmental Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Civil, Infrastructure and Environmental Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Civil, Infrastructure and Environmental Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Civil, Infrastructure and Environmental Engineering, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates","IEEE Access","24 Dec 2021","2021","9","","166603","166616","The safety of workers at construction sites is one of the most important aspects that should be considered while performing their required tasks. Many rules and regulations have been implemented in the UAE to reduce injuries and fatalities in the jobsites. However, the number of accidents continues to increase. For instance, an accident category of fall-from-height is considered as the top cause of injuries and fatalities. Thus, this paper develops a novel technique that monitors the workers whether they are complying with a safety standard of the Personal Fall Arrest System (PFAS). This paper establishes a real time detection algorithm based on a Convolutional Neural Network (CNN) model in order to detect two main components of the PFAS that are, safety harness and life-line, in addition to a standard safety measure of using a safety helmet. The YOLOv3 algorithm is adopted for a deep learning network used to train the desired model. The model achieved an accuracy rate of 91.26% and around 99% precision. Moreover, the overall recall of the model was 90.2%. The obtained results verify the effectiveness of our proposed model in construction sites to control potential violations and to avoid unnecessary accidents. The main contribution of this paper is to provide an AI-based image detection framework to mitigate the likelihood of fall-from-height accidents.","2169-3536","","10.1109/ACCESS.2021.3135662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650892","Accidents;CNN;detection;fall from heights;PFAS;YOLOv3","Safety;Artificial intelligence;Accidents;Injuries;Regulation;Inspection;Head","","11","","35","CCBY","14 Dec 2021","","","IEEE","IEEE Journals"
"Safety vs. Efficiency: AI-Based Risk Mitigation in Collaborative Robotics","A. Terra; H. Riaz; K. Raizer; A. Hata; R. Inam","GFTL ER AI, Ericsson AB, Stockholm, Sweden; GFTL ER AI, Ericsson AB, Stockholm, Sweden; GFTL ER AI, Ericsson Telecomunicacoes S.A., Indaiatuba, Brazil; GFTL ER AI, Ericsson AB, Stockholm, Sweden; GFTL ER AI, Ericsson Telecomunicacoes S.A., Indaiatuba, Brazil","2020 6th International Conference on Control, Automation and Robotics (ICCAR)","4 Jun 2020","2020","","","151","160","The use of AI-based risk mitigation is increasing to provide safety in the areas of smart manufacturing, automated logistics etc, where the human-robot collaboration operations are in use. This paper presents our work on implementation of fuzzy logic system (FLS) and reinforcement learning (RL) to build risk mitigation modules for human-robot collaboration scenarios. Risk mitigation using FLS strategy is developed by manually defining the linguistic values, tuning the membership functions and generating the rules based on ISO/TS15066:2016. RL-based risk mitigation modules are developed using three different Qnetworks to estimate the Q-value function. Our purpose is twofold: to perform a comparative analysis of FLS and RL in terms of safety perspectives and further to evaluate the efficiency to accomplish the task. Our results present that all the proposed risk mitigation strategies improve the safety aspect by up to 26% as compared to a default setup where the robot is just relying on a navigation module without risk mitigation. The efficiency of using FLS model is maintained to the default setup, while the efficiency of using RL model is reduced by 26% from the default setup. We also compare the computation performance of risk mitigation between centralized and edge execution where the edge execution is 27.5 times faster than the centralized one.","2251-2446","978-1-7281-6139-6","10.1109/ICCAR49639.2020.9108037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108037","human-robot collaboration;risk mitigation;safety analysis;ISO/TS15066:2016;fuzzy logic system;reinforcement learning;automated warehouse;smart manufacturing","Fuzzy logic;Computational modeling;Collaboration;Reinforcement learning;Safety;Risk management;Task analysis","","11","","26","IEEE","4 Jun 2020","","","IEEE","IEEE Conferences"
"Preventing and Controlling Epidemics Through Blockchain-Assisted AI-Enabled Networks","S. Otoum; I. Al Ridhawi; H. T. Mouftah","Zayed University, United Arab Emirates; Kuwait College of Science and Technology, Kuwait; University of Ottawa, Canada","IEEE Network","14 Jun 2021","2021","35","3","34","41","The COVID-19 pandemic, which spread rapidly in late 2019, has revealed that the use of computing and communication technologies provides significant aid in preventing, controlling, and combating infectious diseases. With the ongoing research in next-generation networking (NGN), the use of secure and reliable communication and networking is of utmost importance when dealing with users' health records and other sensitive information. Through the adaptation of artificial-intelligence-enabled NGN, the shape of healthcare systems can be altered to achieve smart and secure healthcare capable of coping with epidemics that may emerge at any given moment. In this article, we envision a cooperative and distributed healthcare framework that relies on state-of-the-art computing, communication, and intelligence capabilities, namely, federated learning, mobile edge computing, and blockchain, to enable epidemic (or suspicious infectious disease) discovery, remote monitoring, and fast health authority response. The introduced framework can also enable secure medical data exchange at the edge and between different health entities. This technique, coupled with the low latency and high bandwidth functionality of 5G and beyond networks, would enable mass surveillance, monitoring, and analysis to occur at the edge. Challenges, issues, and design guidelines are also discussed in this article with highlights on some trending solutions.","1558-156X","","10.1109/MNET.011.2000628","Zayed University(grant numbers:RIF-20130); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454578","","Infectious diseases;COVID-19;Pandemics;Surveillance;Design methodology;Medical services;Reliability;Epidemics;Coronaviruses;Viruses (medical)","","10","","15","IEEE","14 Jun 2021","","","IEEE","IEEE Magazines"
"Stroke Medical Ontology for Supporting AI-based Stroke Prediction System using Bio-Signals","S. Kwon; J. Yu; S. Park; J. -A. Jun; C. -S. Pyo","Department of KSB Convergence Research, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea; Department of KSB Convergence Research, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea; Research Team for Health & Safety Convergence Korea Research Institute of Standards and Science (KRISS), Daejeon, Republic of Korea; Department of KSB Convergence Research, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea; Department of KSB Convergence Research, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea","2021 Twelfth International Conference on Ubiquitous and Future Networks (ICUFN)","13 Sep 2021","2021","","","53","59","In this paper, we propose a stroke medical ontology that provides medical knowledge to accompany AI-based stroke disease prediction system's results that were arrived at based on EMG information. This system was developed as a result of the limitations mentioned above being encountered in previous studies. We approached the problem from a viewpoint of knowledge engineering with the aim of modeling medical knowledge related to strokes. Using web ontology language (OWL), a standard ontology language, we developed schema-level stroke ontologies with concepts and properties based on the brain's anatomical structures, lesions, and disease related to strokes. Also, we developed an instance-level medical terms ontology that can span standard medical terms such as those in the international classification diseases (ICD), systematized nomenclature of medicine - clinical terms (SNOMED-CT), and foundational model of anatomy (FMA). The above schema ontology and instance ontology are meaningfully mapped to each other to apply layered ontology modeling techniques that separate schemas from instances. Through semantic web rule language (SWRL)-based inference, we predict lesions, diseases, and anatomical brain structural ripple effects based on the patient's current lesions and diseases. The inferred knowledge information is provided via the SPARQL protocol and RDF query language (SPARQL), a standard ontology query language. To verify the stroke medical ontology proposed in this paper, we developed an ontology-based stroke disease prediction system. This system achieved knowledge augmentation performance of 67.82% by comparing the patients' current lesions and diseases with the lesions, diseases, and areas of disability found by SWRL-based inference using actual stroke emergency data from 37 patients.","2165-8536","978-1-7281-6476-2","10.1109/ICUFN49451.2021.9528529","National Research Council of Science & Technology (NST)(grant numbers:CRC-15-05-ETRI); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528529","stroke medical ontology;ontology;SWRL-based inference;stroke;mini stroke","Knowledge engineering;Senior citizens;OWL;Stroke (medical condition);Ontologies;Brain modeling;Electromyography","","5","","19","IEEE","13 Sep 2021","","","IEEE","IEEE Conferences"
"Design & Development of Smart Electric Vehicle Safety Device by using IoT and AI","S. Thombare; S. Baral; A. Gangrade; R. Jaiswal","Electrical Engineering & ATDC Department, Indian Institute of Technology IIT Kharagpur, Kolkata, India; Electronic and Telecommunication Engineering, Pune Institute of Computer Technology, PICT, Pune, India; Electronic and Telecommunication Engineering, Pune Institute of Computer Technology, PICT, Pune, India; Electronic and Telecommunication Engineering, Pune Institute of Computer Technology, PICT, Pune, India","2022 Fourth International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT)","15 Mar 2023","2022","","","1","6","As the usage of electric vehicles grows in popularity, the risk of accidents caused by them is also drastically increased. High speed, drink-driving, distracting thoughts, overstress, and malfunctioning electronic gadgets, over the temperature in charging are the leading causes of accidents & fire. Also, in electric battery-operated cars, if the battery charging mechanism is not properly thermally stabilized, the battery may catch fire. As a result, the proposed system deals with accident detection systems that occur as a result of a driver's carelessness or system failure while operating an electric vehicle. Proposed Device created with a cardiac sensor in the seat belt and vehicle along with battery temperature, vibration & accelerometer sensors which can help to analyze the vehicle's yaw, roll, pitch, and slip motions. All of the data collected is a synced to ESP-32 controller through IoT-based cloud storage analysis to notify a neighboring helpline center about the accident. This data is also utilized in an AI-based model to detect one of the sovereign sources of death in growing countries i.e., cardiovascular disease, and it's cited by several throughout the globe. Cardiovascular disease, on the opposite hand, is called heart disease. This consolidates some dangerous factors of heart disease and the desire of the era of promoting correct, reliable and smart approaches that enable early identification to achieve quick treatment for the disease. This analysis paper also presents numerous attributes associated with a heart condition, and also the model is based on supervised algorithms of machine learning such as Support Vector Machines, Logistic Regression, Naïve Bayes, Decision tree, and random forest and algorithms of deep learning such as Artificial Neural Network, TabNet etc. It uses the prevailing dataset from V.A. Medical Center, Long Beach, and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D. It includes 303 occurrences and 76 attributes. Only 13 attributes are considered for testing out of 76 attributes. This is important to prove the performance of various algorithms. This analysis paper targets to visualize the likelihood of blooming heart conditions within the drivers with the comparison of traditional algorithms with deep learning techniques and will alert drivers by sending information via personal email, text message, or on the app.","","978-1-6654-5635-7","10.1109/ICERECT56837.2022.10059784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10059784","Internet of Things (IoT);ESP-32;Cloud;Vehicle motion sensors;Health monitoring device;GPS;GSM;Heart disease prediction;Cardiovascular diseases (CVD)","Temperature sensors;Deep learning;Cloud computing;Machine learning algorithms;Electric vehicles;Batteries;Automobiles","","1","","30","IEEE","15 Mar 2023","","","IEEE","IEEE Conferences"
"Human Thinking in the Age of Generative A.I.: Values of Openness and Higher Education for the Future","V. Zinchenko; Y. Mielkov; T. Nych; M. Abasov; M. Trynyak","Dept. of Research Activities of Universities, Institute of Higher Education of the National Academy of Educational Sciences of Ukraine, Kyiv, Ukraine; Dept. of Research Activities of Universities, Institute of Higher Education of the National Academy of Educational Sciences of Ukraine, Kyiv, Ukraine; Dept. of Philosophy and Social, Sciences Educational-Scientific Institute of International Relations and Social Sciences, Interregional Academy of Personnel Management, Kyiv, Ukraine; Dept. of Economics, Azerbaijan Tourism and Management University, Baku, Azerbaijan; Dept. of Philosophy, H. S. Skovoroda Kharkiv, National Pedagogical University, Kharkiv, Ukraine","2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)","22 Jan 2024","2023","","","1","6","The paper is dedicated to the philosophical analysis of the specifics of artificial intelligence and its relation to human intelligence, as well as of the very notion of generative artificial intelligence and its abilities and inabilities. Emphasis is placed on such feature of human thinking as openness, which is argued to clearly distinguish it from machine thinking, as well as on such aspects of human intelligence as nonlinearity, morality, emotionality and evaluation that could be described as extra-rational and thus unobtainable for the artificial intelligence. It is argued that artificial intelligence cannot think openly, “out of the box”, going beyond the boundaries of purely rational reasoning and formal logic peculiar to classical type of rationality. The authors also conclude that the development of AI-based technologies makes it necessary to shift the higher education in the direction of strengthening the emphasis on the ethical, emotional, and volitional sphere of human intelligence.","","979-8-3503-2781-6","10.1109/ICECET58911.2023.10389449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10389449","artificial intelligence (A.I;AI);machine thinking;human intelligence;openness;higher education","Computers;Ethics;Humanities;Generative AI;Human intelligence;Learning (artificial intelligence);Cognition","","","","27","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"CELS: Counterfactual Explanations for Time Series Data via Learned Saliency Maps","P. Li; O. Bahri; S. F. Boubrahimi; S. M. Hamdi","Department of Computer Science, Utah State University, Logan, UT; Department of Computer Science, Utah State University, Logan, UT; Department of Computer Science, Utah State University, Logan, UT; Department of Computer Science, Utah State University, Logan, UT","2023 IEEE International Conference on Big Data (BigData)","22 Jan 2024","2023","","","718","727","As the demand for interpretable machine learning approaches increases, there is an increasing need for human involvement to provide diverse explanations for model decisions. This is crucial for enhancing trust and transparency in AI-based systems, leading to the emergence of the Explainable Artificial Intelligence (XAI) field. In this paper, we design a novel counterfactual explanation model, CELS, which learns a saliency map for the interest of an instance and generates a counterfactual explanation guided by the learned saliency map. CELS adopts a gradient-based approach composed of three interdependent modules that combine to generate sparse counterfactual explanations that are easily understood by end users. To the best of our knowledge, this is the first attempt to guide the perturbation to generate a counterfactual explanation via a learned saliency map. To validate our model, we conducted experiments using five popular real-world time-series datasets obtained from the UCR repository. The experimental results demonstrate the superiority of our model in achieving higher sparsity, proximity, and interpretability of counterfactual explanations when compared to other state-of-the-art baselines.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386229","Explainable Artificial Intelligence (XAI);counterfactual explanations;time series classification;saliency map","Perturbation methods;Time series analysis;Machine learning;Learning (artificial intelligence);Big Data;Task analysis","","","","29","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"Simulation-Based Deep Reinforcement Learning For Modular Production Systems","N. Feldkamp; S. Bergmann; S. Strassburger","Information Technology in Production and Logistics, Technische Universität Ilmenau, Ilmenau, GERMANY; Information Technology in Production and Logistics, Technische Universität Ilmenau, Ilmenau, GERMANY; Information Technology in Production and Logistics, Technische Universität Ilmenau, Ilmenau, GERMANY","2020 Winter Simulation Conference (WSC)","29 Mar 2021","2020","","","1596","1607","Modular production systems aim to supersede the traditional line production in the automobile industry. The idea here is that highly customized products can move dynamically and autonomously through a system of flexible workstations without fixed production cycles. This approach has challenging demands regarding planning and organization of such systems. Since each product can define its way through the system freely and individually, implementing rules and heuristics that leverage the flexibility in the system in order to increase performance can be difficult in this dynamic environment. Transport tasks are usually carried out by automated guided vehicles (AGVs). Therefore, integration of AI-based control logics offer a promising alternative to manually implemented decision rules for operating the AGVs. This paper presents an approach for using reinforcement learning (RL) in combination with simulation in order to control AGVs in modular production systems. We present a case study and compare our approach to heuristic rules.","1558-4305","978-1-7281-9499-8","10.1109/WSC48552.2020.9384089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384089","","Production systems;Reinforcement learning;Organizations;Workstations;Planning;Vehicle dynamics;Task analysis","","9","","33","IEEE","29 Mar 2021","","","IEEE","IEEE Conferences"
"What Would You do? An Ethical AI Quiz","W. Teo; Z. Teoh; D. A. Arabi; M. Aboushadi; K. Lai; Z. Ng; A. Pant; R. Hoda; C. Tantithamthavorn; B. Turhan","Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of IT, Monash University, Melbourne, Australia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia; Faculty of IT, Monash University, Melbourne, Australia; Faculty of Engineering, Monash University, Subang Jaya, Malaysia","2023 IEEE/ACM 45th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","12 Jul 2023","2023","","","112","116","The resurgence of Artificial Intelligence (AI) has been accompanied by a rise in ethical issues. AI practitioners either face challenges in making ethical choices when designing AI-based systems or are not aware of such challenges in the first place. Increasing the level of awareness and understanding of the perceptions of those who develop AI systems is a critical step toward mitigating ethical issues in AI development. Motivated by these challenges, needs, and the lack of engaging approaches to address these, we developed an interactive, scenario-based ethical AI quiz. It allows AI practitioners, including software engineers who develop AI systems, to self-assess their awareness and perceptions about AI ethics. The experience of taking the quiz, and the feedback it provides, will help AI practitioners understand the gap areas, and improve their overall ethical practice in everyday development scenarios. To demonstrate these expected outcomes and the relevance of our tool, we also share a preliminary user study. The video demo can be found at https://zenodo.org/record/7601169#.Y9xgA-xBxhF.","2574-1934","979-8-3503-2263-7","10.1109/ICSE-Companion58688.2023.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172891","ethics;AI ethics;AI practitioners;self- assessment tools;ethical AI quiz","Ethics;Software;Artificial intelligence;Faces;Software engineering","","","","21","IEEE","12 Jul 2023","","","IEEE","IEEE Conferences"
"AI-based Load Forecasts - Research and Application","C. Krug; S. Sauerbaum",NA; NA,"ETG Congress 2023","4 Jul 2023","2023","","","1","7","The climate targets require a transformation of the energy supply, which brings new challenges. The volatile generation of renewable energies and dynamic consumption due to the expansion of electricity-consuming systems such as e-mobility and heat pumps make a digitized and intelligent distribution network indispensable. To plan and optimize load distribution in a grid with volatile flexibilities and consumers, accurate load forecasts are needed. According to the current state of the art, these are carried out using Artificial Intelligence (AI) algorithms. An expert group appointed by the European Commission developed guidelines for trustworthy AI in 2019 and augmented them with a list for assessing AI in 2020. The requirements for trustworthy AI, identified in these guidelines, are crucial for the safe application of AI in practice, but they also bring challenges, as new AI methods are often very complex. The challenges, open research questions, and potential solutions are described and discussed in this article.","","978-3-8007-6108-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172985","","","","","","","","4 Jul 2023","","","VDE","VDE Conferences"
"FAILS: a tool for assessing risk in ML systems","G. A. Dominguez; K. Kawaai; H. Maruyama","Preferred Networks Inc., Tokyo, Japan; Preferred Networks Inc., Tokyo, Japan; Preferred Networks Inc., Tokyo, Japan","2021 28th Asia-Pacific Software Engineering Conference Workshops (APSEC Workshops)","28 Feb 2022","2021","","","1","4","Quality assurance of AI based systems presents a unique set of challenges to software engineers, making it difficult to assess the risks involved when deploying them. We present a risk assessment tool based on the widely used failure mode effect analysis (FMEA) methodology, as well as quality assurance guidelines released in recent years. The tool aims to support the search for potential risks in machine learning (ML) components used in the design and development of AI products. A preliminary evaluation showed its effectiveness and pointed toward areas for future improvement.","","978-1-6654-3813-1","10.1109/APSECW53869.2021.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719942","AI engineering;quality assurance;software engineering;machine learning","Quality assurance;Conferences;Machine learning;Software;Risk management;Software engineering;Guidelines","","3","","10","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"RRPDG: A Graph Model to Enable AI-Based Production Reconfiguration and Optimization","S. Gaiardelli; M. Lora; S. Spellini; F. Fummi","Department of Engineering for Innovation Medicine (DIMI), University of Verona, Verona, Italy; Department of Engineering for Innovation Medicine (DIMI), University of Verona, Verona, Italy; FACTORYAL S.r.l., San Giovanni Lupatoto, Italy; Department of Engineering for Innovation Medicine (DIMI), University of Verona, Verona, Italy","IEEE Transactions on Industrial Informatics","","2024","PP","99","1","11","This article introduces the regionalized resource process dependence graphs (RRPDGs): a manufacturing processes representation inspired by the regionalized value state dependence graphs traditionally used in software compilers. An RRPDG is an ordered sequence of nodes, each characterized by stereotyped input and output parameters, encapsulating a transformation of the process state (e.g., a manufacturing operation). RRPDG allow defining complex transformations by composing a set of nodes (i.e., regions), hiding the internal details. Then, RRPDGs are used to automatically reasoning over dynamic reconfiguration and process optimization: an instance of the A-star search algorithm is used to search for possible transformations while pursuing an optimization function. The rules defined in this article over RRPDG models enforce the transformations' correctness. We use RRPDGs to model a real production system while the transformation rules are applied to optimize the system's processes. The proposed representation reduced the search complexity in each experiment, allowing to reach an optimal solution also in the case for which classical approaches were unable to complete before reaching the timeout. In all the experiments, the cost of the solution produced by using the regionalized representation is minor than the the solution produced by using the classical representation.","1941-0050","","10.1109/TII.2024.3352645","European Union's Horizon 2020 research and innovation program through the Marie Skłodowska-Curie(grant numbers:894237); European Union Next-GenerationEU; Piano Nazionale di Ripresa e Resilienza; Missione 4 Componente 2, Investimento 1.5(grant numbers:1058 23/06/2022); PNRR research activities of the consortium iNEST(grant numbers:ECS_00000043); PRIN(grant numbers:2022T7YSHJ); SMART-IC-Next Generation EU project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414265","Modeling;smart manufacturing;process control in manufacturing automation","Production;Optimization;Manufacturing;Task analysis;Computational modeling;Technological innovation;Process control","","","","","CCBY","25 Jan 2024","","","IEEE","IEEE Early Access Articles"
"MOSAIC: Multiobjective Optimization Strategy for AI-Aided Internet of Things Communications","H. Lee; S. H. Lee; T. Q. S. Quek","Department of Information and Communications Engineering, Pukyong National University, Busan, South Korea; School of Electrical Engineering, Korea University, Seoul, South Korea; Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singapore","IEEE Internet of Things Journal","24 Aug 2022","2022","9","17","15657","15673","Future Internet of Things (IoT) communication trends toward heterogeneous services and diverse quality-of-service requirements pose fundamental challenges for network management strategies. In particular, multiobjective optimization (MOO) is necessary in resolving the competition among different nodes sharing limited wireless network resources. A unified coordination mechanism is essential such that individual nodes conduct the opportunistic maximization of heterogeneous local objectives for efficient distributed resource allocation. To such a problem, this article proposes an artificial intelligence (AI)-based framework, which is termed as MOO strategy for AI-aided IoT communications (MOSAIC). This framework enables to tackle numerous MOO tasks in IoT network management with simple reconfiguration of learning rules. In this strategy, a component unit associated with an individual network node includes a pair of deep neural networks (DNNs) to learn optimal local functions responsible for calculation and distributed coordination, respectively. The resultant AI module swarm called DNN tiles realizes the node cooperation that collectively seeks distributed MOO calculation rules. The advantage of MOSAIC is characterized by Pareto tradeoffs among conflicting performance metrics in diverse wireless networking configurations subject to severe interference and distinct criteria for multiple targets.","2327-4662","","10.1109/JIOT.2022.3150747","NRF Grant Funded by the Korea Government Ministry of Science and ICT (MSIT)(grant numbers:2021R1I1A3054575); Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant Funded by MSIT (Intelligent 6G Wireless Access System and Research on LEO Inter-Satellite Links)(grant numbers:2021-0-00467,2021-0-00260); Korea University Grant; National Research Foundation, Singapore and Infocomm Media Development Authority under its Future Communications Research and Development Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711565","Deep learning (DL);distributed network management;multiobjective optimization;primal–dual training","Wireless communication;Optimization;Task analysis;Evolutionary computation;Training;Internet of Things;Linear programming","","","","53","IEEE","11 Feb 2022","","","IEEE","IEEE Journals"
"Requirements for Fuzzy Logic in Personalisation of Fire Emergency Alerts","N. Alonistioti; E. A. Tsichrintzi; K. Chrysafiadi; E. Alepis","Dpt. of Informatics and Telecommunications, National & Kapodistrian University of Athens, Athens, Greece; Dpt. of Informatics and Telecommunications, National & Kapodistrian University of Athens, Athens, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","8","During major natural disasters like extreme weather events and wildfires, it is very important to notify citizens when the danger level exceeds certain thresholds. However, defining these thresholds in an entirely discrete manner is challenging, despite their major importance. Conversely, triggering an alarm without sufficient justification can be costly for the state and unnecessarily disrupt the lives of citizens. In this regard, employing a more flexible approach, such as fuzzy logic, in the context of artificial intelligence empowerment of the whole process, can provide rules to mitigate the discreteness of alarm thresholds. Failing to raise an alarm, when necessary, can result in significant human and property losses. In this article, we present a new approach that utilises fuzzy logic to classify danger thresholds in a smoother and more effective manner for the civil protection. The paper offers valuable insights into the practical implementation of Fuzzy Logic and the entire life cycle of the proposed Fuzzy logic-based approach. This approach is designed to be iterative, involving key stakeholders to ensure the validity and reliability of the results.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345861","fuzzy logic;electronic civil protection;natural disasters;artificial intelligence in civil protection;agile AI-Based software","Fuzzy logic;Wildfires;Reliability engineering;Software;Software reliability;Stakeholders;Iterative methods","","","","31","IEEE","15 Dec 2023","","","IEEE","IEEE Conferences"
"Semantic Grasping Via a Knowledge Graph of Robotic Manipulation: A Graph Representation Learning Approach","J. H. Kwak; J. Lee; J. J. Whang; S. Jo","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea","IEEE Robotics and Automation Letters","25 Jul 2022","2022","7","4","9397","9404","Semantic grasping aims to make stable robotic grasps suitable for specific object manipulation tasks. While existing semantic grasping models focus only on the grasping regions of objects based on their affordances, reasoning about which gripper to use for grasping, e.g., a rigid parallel-jaw gripper or a soft gripper, and how strongly to grasp the target object allows more sophisticated robotic manipulation. In this letter, we create a knowledge graph of robotic manipulation named roboKG to represent information about objects (e.g., the material and the components of an object), tasks, and appropriate robotic manipulation such as which component of an object to grasp, which gripper to use, and how strongly to grasp. Using knowledge graph embedding, we generate semantic representations of the entities and relations in roboKG, enabling us to make predictions on robotic manipulation. Based on the predicted gripper type, grasping component, and grasping force, a real robot performs seven different real-world tasks on 42 household objects, achieving an accuracy of 95.21%.","2377-3766","","10.1109/LRA.2022.3191194","IITP, Korean government(grant numbers:2017-0-00432,2022-0-00369,2020-0-00153); NRF of Korea, Korean Government(grant numbers:2016R1A5A1938472,2018R1A5A1059921,2022R1A2C4001594); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9830861","AI-enabled robotics;representation learning;grasping","Robots;Grasping;Task analysis;Grippers;Semantics;Affordances;Force","","3","","40","IEEE","15 Jul 2022","","","IEEE","IEEE Journals"
"Modelling and analysis of artificial intelligence based MPPT techniques for PV applications","P. Vinay; M. A. Mathews","Mar Baselios College of Engineering & Technology, Kerala, India; Mar Baselios College of Engineering & Technology, Kerala, India","2014 International Conference on Advances in Green Energy (ICAGE)","26 Feb 2015","2014","","","56","65","Solar Photovoltaic« plays a vital role in meeting the power requirements of the current generation. In fact it is the only mode of renewable energy that enables the decentralization of power. The output of an individual PV Module depends on the environmental conditions such as Temperature and Insolation level. For tracking down the maximum power available at a particular instant, we make use of Maximum Power Point Techniques. The heart of an MPPT system is a DC-DC Converter and for better performance any of the Buck-Boost converters are used. The Artificial Intelligence based methods have found to outperform the conventional methods in all the fields. In MPPT also, the AI based methods are found to be better than the conventional load line based methods. In this paper, a 1 kW PV Array is considered and three AI based MPPT techniques are analyzed with a Sepie converter. The loads connected to the converter are a Permanent Magnet DC Motor and a Grid tied Inverter. The temperature and Insolation levels are provided from historically available data for Thiruvananthapuram, Kerala, India.","","978-1-4799-8050-5","10.1109/ICAGE.2014.7050144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050144","Photovoltaic;Sepic Converter;Maximum Power Point Tracking;Permanent Magnet DC Motor;Fuzzy Logic Control Neural Network;Adaptive Neuro Fuzzy Interface System;Grid Tied Inverter","Maximum power point trackers;Fuzzy logic;Artificial intelligence;Arrays;Mathematical model;Niobium;Biological neural networks","","10","","11","IEEE","26 Feb 2015","","","IEEE","IEEE Conferences"
"AI Ethics Impact Assessment based on Requirement Engineering","I. Nitta; K. Ohashi; S. Shiga; S. Onodera","Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan; Fujitsu Limited, Kawasaki, Japan","2022 IEEE 30th International Requirements Engineering Conference Workshops (REW)","20 Oct 2022","2022","","","152","161","This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.","2770-6834","978-1-6654-6000-2","10.1109/REW56159.2022.00037","Stanford University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9920150","AI ethics;AI governance;responsible AI;impact assessment;risk-based approach","Ethics;Philosophical considerations;Conferences;Europe;Organizations;Regulation;Requirements engineering","","2","","27","IEEE","20 Oct 2022","","","IEEE","IEEE Conferences"
"When Smart Metaverse Meets Affective Computing: Opportunities and Design Guidelines","R. W. L. Coutinho; A. Boukerche","Concordia University, Canada; University of Ottawa, Canada","IEEE Communications Magazine","26 Oct 2023","2023","61","10","46","52","Metaverse and affective computing are two promising areas. We envision a new generation of smart metaverse that will consider affective computing to develop artificial intelligence (AI)-empowered avatars capable of expressing emotions and enhancing interactions on users' metaverse sessions. This article advocates for the symbiotic design of affective computing and metaverse. We discuss some of the unique challenges faced during the design of metaverse and affective computing and the current research trends to overcome them. We highlight how affective computing can tackle unique challenges in metaverse applications and how metaverse can be considered to deal with limitations faced in affective computing applications. Finally, we present some future research directions in need of attention.","1558-1896","","10.1109/MCOM.004.2300009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10210477","","Metaverse;Affective computing;Physiology;Haptic interfaces;Computational modeling;Sensors;Symbiosis","","","","15","IEEE","7 Aug 2023","","","IEEE","IEEE Magazines"
"AI-Based Stroke Disease Prediction System Using ECG and PPG Bio-Signals","J. Yu; S. Park; S. -H. Kwon; K. -H. Cho; H. Lee","Department of Knowledge-Converged Super Brain (KSB) Convergence Research, Electronics and Telecommunications Research Institute, Daejeon, South Korea; Safety Measurement Institute, Korea Research Institute of Standards and Science, Daejeon, South Korea; Department of Knowledge-Converged Super Brain (KSB) Convergence Research, Electronics and Telecommunications Research Institute, Daejeon, South Korea; Department of Rehabilitation Medicine, College of Medicine, Chungnam National University, Daejeon, South Korea; School of Creative Convergence, Andong National University, Andong, South Korea","IEEE Access","29 Apr 2022","2022","10","","43623","43638","Since stroke disease often causes death or serious disability, active primary prevention and early detection of prognostic symptoms are very important. Stroke diseases can be divided into ischemic stroke and hemorrhagic stroke, and they should be minimized by emergency treatment such as thrombolytic or coagulant administration by type. First, it is essential to detect in real time the precursor symptoms of stroke, which occur differently for each individual, and to provide professional treatment by a medical institution within the proper treatment window. However, prior studies have focused on developing acute treatment or clinical treatment guidelines after the onset of stroke rather than detecting the prognostic symptoms of stroke. In particular, in recent studies, image analysis such as magnetic resonance imaging (MRI) or computed tomography (CT) has mostly been used to detect and predict prognostic symptoms in stroke patients. Not only are these methodologies difficult to diagnose early in real-time, but they also have limitations in terms of a long test time and a high cost of testing. In this paper, we propose a system that can predict and semantically interpret stroke prognostic symptoms based on machine learning using the multi-modal bio-signals of electrocardiogram (ECG) and photoplethysmography (PPG) measured in real-time for the elderly. To predict stroke disease in real-time while walking, we designed and implemented a stroke disease prediction system with an ensemble structure that combines CNN and LSTM. The proposed system considers the convenience of wearing the bio-signal sensors for the elderly, and the bio-signals were collected at a sampling rate of 1,000Hz per second from the three electrodes of the ECG and the index finger for PPG while walking. According to the experimental results, C4.5 decision tree showed a prediction accuracy of 91.56% while RandomForest showed a prediction accuracy of 97.51% during walking by the elderly. In addition, the CNN-LSTM model using raw data of ECG and PPG showed satisfactory prediction accuracy of 99.15%. As a result, the real-time prediction of the elderly stroke patients simultaneously showed high prediction accuracy and performance.","2169-3536","","10.1109/ACCESS.2022.3169284","National Research Council of Science and Technology (NST) grant; Korean Government [Ministry of Science, ICT and Future Planning (MSIP)](grant numbers:CRC-15-05-ETRI); Korea Institute of Planning and Evaluation for Technology in Food, Agriculture and Forestry (IPET) through Smart Farm Innovation Technology Development Program, funded; Ministry of Agriculture, Food and Rural Affairs (MAFRA) and Rural Development Administration (RDA) and Ministry of Science and ICT (MSIT)(grant numbers:421028-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761215","Deep learning;machine learning;electrocardiogram (ECG);photo plethysmography (PPG);multi-modal bio-signal;real-time stroke prediction;stroke disease analysis","Diseases;Electrocardiography;Stroke (medical condition);Real-time systems;Older adults;Heart;Aging","","24","","60","CCBY","21 Apr 2022","","","IEEE","IEEE Journals"
"An AI-Based Medical Chatbot Model for Infectious Disease Prediction","S. Chakraborty; H. Paul; S. Ghatak; S. K. Pandey; A. Kumar; K. U. Singh; M. A. Shah","Computer Science and Engineering Department, Techno International Newtown, Kolkata, India; Computer Science and Engineering Department, JIS University, Kolkata, India; Computer Science and Engineering Department, JIS University, Kolkata, India; Department of Computer Engineering and Applications, GLA University, Mathura, India; Department of Computer Engineering and Applications, GLA University, Mathura, India; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Economics, Kebri Dehar University, Kebri Dehar, Ethiopia","IEEE Access","14 Dec 2022","2022","10","","128469","128483","The purpose of this paper is to show concisely how we can promote chatbots in the medical sector and cure infectious diseases. We can create awareness through the users and the users can get proper medical solutions to prevent disease. We created a preliminary training model and a study report to improve human interaction in databases in 2021. Through natural language processing, we describe the human behaviors and characteristics of the chatbot. In this paper, we propose an AI Chatbot interaction and prediction model using a deep feedforward multilayer perceptron. Our analysis discovered a gap in knowledge about theoretical guidelines and practical recommendations for creating AI chatbots for lifestyle improvement programs. A brief comparison of our proposed model concerning the time complexity and accuracy of testing is also discussed in this paper. In our work, the loss is a minimum of 0.1232 and the highest accuracy is 94.32%. This study describes the functionalities and possible applications of medical chatbots and explores the accompanying challenges posed by the use of these emerging technologies during such health crises mainly posed by pandemics. We believe that our findings will help researchers get a better understanding of the layout and applications of these revolutionary technologies, which will be required for continuous improvement in medical chatbot functionality and will be useful in avoiding COVID-19.","2169-3536","","10.1109/ACCESS.2022.3227208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9970731","Artificial intelligence;chatbot;LSTM algorithm;machine learning;natural language processing;query processing","Chatbots;COVID-19;Artificial intelligence;Medical services;Machine learning;Computer science;Analytical models","","8","","35","CCBY","6 Dec 2022","","","IEEE","IEEE Journals"
"Indian Traffic Sign Board Recognition and Driver Alert System Using CNN","A. Sivasangari; S. Nivetha; Pavithra; P. Ajitha; R. M. Gomathi","SOC, Sathyabama Institute of Science and Technology, Chennai, India; SOC, Sathyabama Institute of Science and Technology, Chennai, India; SOC, Sathyabama Institute of Science and Technology, Chennai, India; SOC, Sathyabama Institute of Science and Technology, Chennai, India; SOC, Sathyabama Institute of Science and Technology, Chennai, India","2020 4th International Conference on Computer, Communication and Signal Processing (ICCCSP)","15 Jan 2021","2020","","","1","4","Affirmation of traffic signs (TSR) is a popular bit of some ADA (ADAS) and vehicle drivers ' (ADS) schemes. As either the leading main technology of TSR, unveiling of traffic signs (TSD) is a worrying issue due to various styles, small size, complicated riding scenarios and obstacles. From late on various TSD figurations also relied on the view of the computer and even the pattern. A full description of the TSD structure is given in this article. We recommend splitting the field procedures under review into two rule groups: possibility-based, form-based systems. The proposed system is exhaustively apportioned into, data planning, data gathering, and getting ready and testing. System uses variety of picture planning strategies to improve the image quality and to oust non-illuminating pixel, and recognizing edges. Feature extractors are used to find the features of picture. Moved AI figuring Convolutional Neural Networks (CNN) is used to gather the differing traffic sign pictures reliant on their features by using the progressing camera.","","978-1-7281-6509-7","10.1109/ICCCSP49186.2020.9315260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315260","Internet of Things;Traffic Sign Board;AI based recognition","Vehicles;Cameras;Artificial intelligence;Image color analysis;Signal processing algorithms;Roads;Real-time systems","","10","","8","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"AI-Based Technique to Enhance Transient Response and Resiliency of Power Electronic Dominated Grids via Grid-Following Inverters","M. Hosseinzadehtaher; A. Zare; A. Khan; M. F. Umar; S. D'silva; M. B. Shadmand","Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA; Electrical and Computer Engineering Department, University of Illinois at Chicago, Chicago, IL, USA","IEEE Transactions on Industrial Electronics","19 Sep 2023","2024","71","3","2614","2625","This article presents a frequency restoration method to enhance power electronic dominated grid (PEDG) resiliency and transient response via redefining grid following inverters (GFLIs) role at the grid-edge. An artificial intelligence-based power reference correction (AI-PRC) module is developed for GFLIs to autonomously adjust their power setpoints during transient disturbances. A detailed analytical validation is provided that shows control rules in PEDG intrinsically follow the underlying dynamic of the swing-based machines to extend its stability boundary. Considering this fact, comprehensive transient and steady state-based mathematical models are used for constructing the learning database of the proposed AI-PRC. The proposed training approach can deal with grid's characteristics alterations and uncertainties. Thus, this approach incorporates PEDG's effective variables that shapes its dynamic response during transient disturbances. Subsequently, a neural network is trained by Bayesian regularization algorithm to realize the proposed AI-PRC scheme for frequency support via GFLIs. Several simulation and experimental case studies results validate the functionality of the proposed AI-PRC toward enhancing the PEDG's transient response and resiliency via GFLIs. The provided case studies demonstrate significant improvement in frequency restoration in response to transient disturbances.","1557-9948","","10.1109/TIE.2023.3265067","Qatar National Research Fund; Qatar Foundation(grant numbers:NPRP12C-33905-SP-213,NPRP12C-33905-SP-220); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100631","Artificial neural network (ANN);Bayesian regularization algorithm (BRA);power electronic dominated grid (PEDG);resiliency;transient stability","Frequency control;Transient analysis;Power system stability;Resilience;Circuit stability;Thermal stability;Artificial intelligence","","4","","28","CCBY","11 Apr 2023","","","IEEE","IEEE Journals"
"Intelligent Agents in Educational Institutions: NEdBOT - NLP-based Chatbot for Administrative Support Using DialogFlow","M. S. Ali; F. Azam; A. Safdar; M. W. Anwar","Department of Computer & Software Engineering, CEME, National University of Sciences & Technology (NUST), Islamabad, Pakistan; Department of Computer & Software Engineering, CEME, National University of Sciences & Technology (NUST), Islamabad, Pakistan; Department of Computer & Software Engineering, CEME, National University of Sciences & Technology (NUST), Islamabad, Pakistan; Department of Computer & Software Engineering, CEME, National University of Sciences & Technology (NUST), Islamabad, Pakistan","2022 IEEE International Conference on Agents (ICA)","29 Dec 2022","2022","","","30","35","Artificial intelligence (AI)-based chatbot systems have seen increased adaption in the educational domain in recent years owing to increased sophistication in the AI domain. However, most of the communication between students and educational institutions is still performed physically and causes major administrative overhead, especially during the time of admission. Contemporary pattern-matching-based and generative-based chatbots underperform to queries outside a limited scope, grammatically and structurally ambiguous inputs, outliers to pre-defined rule-set, and longer response times for a huge knowledge base. We proposed a NEdBOT-An NLP-based Educational Bot, developed by Natural Language Processing models integrated within the DialogFlow platform utilizing a Retrieval-based approach. We evaluate the developed chatbot on a custom dataset generated for the admissions use case of a prominent university. We used an objective evaluation criterion with real-world users to achieve an intent classification accuracy of 76.8% at an average mean response time of 216.43ms per query and a user-friendliness score of 72% on the System Usability Scale (SUS). The results demonstrate the proposed approach's ability to create robust, reliable, responsive, and user-friendly web-based smart chatbots that are highly scalable with the capability to handle wider scopes and vague inputs with ease.","","978-1-6654-6936-4","10.1109/ICA55837.2022.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999103","Educational Chatbot;Artificial Intelligence;DialogFlow;Natural Language Processing;Retrieval-based approach","Training;Text mining;Text recognition;Text categorization;Knowledge based systems;Chatbots;Time factors","","1","","29","IEEE","29 Dec 2022","","","IEEE","IEEE Conferences"
"Explainable Artificial Intelligence for Energy-Efficient Radio Resource Management","A. -D. Marcu; S. K. Gowtam Peesapati; J. Moysen Cortes; S. Imtiaz; J. Gross","KTH Royal Institute of Technology, Stockholm, Sweden; Huawei Technologies Sweden AB, Stockholm, Sweden; Huawei Technologies Sweden AB, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden; KTH Royal Institute of Technology, Stockholm, Sweden","2023 IEEE Wireless Communications and Networking Conference (WCNC)","12 May 2023","2023","","","1","6","As wireless systems evolve, the problems of radio resource management (RRM) become harder to solve. Once the additional constraint of energy-efficient utilization of resources is factored in, these problems become even more challenging. Thus, experts started developing solutions based on complex artificial intelligence (AI) models that, unfortunately, suffer from a performance-explainability trade-off. In this work, we propose an explainable AI (XAI) methodology for addressing this tradeoff. Our methodology can be used to generate feature importance explanations of AI models through three XAI methods: (i) Kernel SHapley Additive exPlanations (SHAP), (ii) Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI), and (iii) Anchors. For Anchors, we formulate a new feature importance score based on the feature’s presence within the rules built by the method. We then use the generated explanations to improve the understanding of the model and reduce its complexity through a feature selection process. By applying our methodology to a reinforcement learning (RL) agent designed for energy-efficient RRM, we were able to reduce its complexity by approximately 27%−62% according to various metrics, without losing performance. Additionally, we show the possibility to replace the AI-based inference process with an Anchors-based inference process with similar performance and higher interpretability for humans.","1558-2612","978-1-6654-9122-8","10.1109/WCNC55385.2023.10119130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10119130","5G Networks;Energy Efficiency;Radio Resource Management;Reinforcement Learning;Explainable AI","Wireless communication;Measurement;Reinforcement learning;Feature extraction;Energy efficiency;Robustness;Complexity theory","","","","15","IEEE","12 May 2023","","","IEEE","IEEE Conferences"
"Development of AI-Based Optimum Energy Resource Management System for Prosumers with Solar Rooftops","D. H. N. R. Weerasekara; W. A. P. K. Wella Arachchi; S. R. G. Wellala; A. S. Rodrigo","Department of Electrical Engineering, University of Moratuwa, Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa, Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa, Moratuwa, Sri Lanka; Department of Electrical Engineering, University of Moratuwa, Moratuwa, Sri Lanka","2023 Moratuwa Engineering Research Conference (MERCon)","22 Dec 2023","2023","","","7","12","Solar installations are becoming popular around the world and have emerged as a promising solution to address the increased energy needs while reducing carbon emissions. To harness the full potential of solar photovoltaic (PV) systems, efficient resource management systems play a vital role. This research paper proposes an efficient solar PV energy resource management system to optimize performance and increase the profits of the prosumers. Utility providers have introduced several tariff systems for the financial motivation of customers. In the proposed method, the load demand and Solar PV generation are forecasted for the next 48 hours using the Long Short-Term Memory (LSTM) model. Then, the cost function is optimized using the Sequential Least Squares Programming (SLSQP) algorithm, and an energy dispatch schedule is provided for the customer: The results of the study show that the electricity cost is reduced for the prosumer by the proposed method than the conventional rule-based energy management systems.","2691-364X","979-8-3503-4521-6","10.1109/MERCon60487.2023.10355519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10355519","hybrid solar PV System;SLSQP;LSTM;resource management system","Schedules;Costs;Energy resources;Tariffs;Programming;Predictive models;Batteries","","","","16","IEEE","22 Dec 2023","","","IEEE","IEEE Conferences"
"TrueAdaptTM- AI Based Maskless Patterning to Compensate for Die-Shift in Fan-Out Wafer Level Packaging","G. Sabbir; K. Sahoo; H. Sun; S. Iver; G. Ouyang; Y. Wu","Department of Materials Science and Engineering, UCLA; Department of Electrical and Computing Engineering, UCLA; Department of Electrical and Computing Engineering, UCLA; Department of Electrical and Computing Engineering, UCLA; Department of Materials Science and Engineering, UCLA; Department of Computer Science, UCLA","2023 IEEE 73rd Electronic Components and Technology Conference (ECTC)","3 Aug 2023","2023","","","2240","2246","TrueAdapt™ offers an attractive solution to fan-out-wafer-level-packaging (FOWLP) and fan-out-panel-level-packaging, which offers significant cost savings as compared to similar bridge connection technology or interposers. Due to die-placement error and shift during molding, die assemblies on FOWLP can have significant die-shift. Design rules must ensure the accommodation of die-shift and as a result fine-pitch patterning is limited. TrueAdapt™ aims to solve that by utilizing in-line characterization of the die shift, generation of a new layout using the measured offsets, and patterning with direct-write lithography for high throughput wafer-level and panel-level fabrication at fine-pitches. In this work we present the fabrication of an assembly of dies interconnected in a daisy chain network with 10 µm pitch wiring on the FlexTrate™, a bio-compatible polydimethylsiloxane (PDMS) based FOWLP architecture. We measure die shift using optical metrology techniques to generate a stitched image of the assembly. The image is then processed using artificial intelligence (AI) computer vision to identify critical features on the dies (which are used to generate die-offsets for each die). Furthermore, we generate a layout based on measured die-shift that adaptively routes the wiring in between dies. Via and metal layers are subsequently patterned using direct-write lithography using a 405 nm lase. Direct-write lithography enables fine-pitch patterning at the wafer/panel level without the need for mask fabrication, promising significant cost savings. We further demonstrate a novel exposure technique based on focal extension that can be utilized to pattern over 100 µm of topography, making this a truly adaptive patterning process.","2377-5726","979-8-3503-3498-2","10.1109/ECTC51909.2023.00388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10195750","FOWLP;fine-pitch;adaptive patterning;design;EDA","Wiring;Fabrication;Costs;Lithography;Layout;Surfaces;Optical variables measurement","","","","8","IEEE","3 Aug 2023","","","IEEE","IEEE Conferences"
"LoLTV: A Low Light Two-Wheeler Violation Dataset With Anomaly Detection Technique","S. Bose; M. H. Kolekar; S. Nawale; D. Khut","Department of Electrical Engineering, Indian Institute of Technology Patna, Dayalpur Daulatpur, Bihar, India; Department of Electrical Engineering, Indian Institute of Technology Patna, Dayalpur Daulatpur, Bihar, India; Department of Information Technology, Bharatiya Vidya Bhavan’s Sardar Patel Institute of Technology, Mumbai, Maharashtra, India; Department of Information Technology, Bharatiya Vidya Bhavan’s Sardar Patel Institute of Technology, Mumbai, Maharashtra, India","IEEE Access","10 Nov 2023","2023","11","","124951","124961","Detecting traffic violations is essential for improving road safety, ensuring rule compliance, and maintaining smooth traffic flow. It also aids in holding violators accountable and supports data-driven decision-making for infrastructure enhancements. To address these challenges, the integration of AI-based methods for automated violation detection is increasingly vital, reducing the need for manual oversight. Low-light conditions pose additional difficulties, as violations become harder to detect. In this study, we created a novel dataset containing 1032 images with 1475 two-wheeler violations under low-light conditions. We propose a real-time deep learning system using YOLO-v8 for two-wheeler violation detection. Our system addresses the challenge of low-light conditions by incorporating a real-time low-light video enhancement module. Through comprehensive evaluations, our system has achieved an average precision of 98.2%, recall of 97.5%, and an accuracy of 97.05% when tested on our custom dataset. Notably, it successfully detected 172 out of 188 violations in the test dataset and exhibited 60% faster processing compared to other state-of-the-art methods. This suggests that our system not only outperforms existing methods on public datasets but also excels in terms of performance and accuracy when applied to the specifically constructed low-light traffic dataset. Furthermore, our system’s practical scalability is evident through its integration with multiple devices and CCTV systems.","2169-3536","","10.1109/ACCESS.2023.3329737","Technology Innovation Hub, Indian Institute of Technology Patna. Project title: Real-Time Anomaly Detection in Traffic Video Streams(grant numbers:TIH/EE/RTDT/017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305149","Deep learning;low light enhancement;road safety;two wheeler violation detection","Real-time systems;Feature extraction;Cameras;Road safety;Computer architecture;Deep learning;Lighting","","","","30","CCBYNCND","2 Nov 2023","","","IEEE","IEEE Journals"
"Standardization on Bias in Artificial Intelligence as Industry Support","E. Szczekocka; C. Tarnec; J. Pieczerak","Orange Innovation Poland Orange Polska S.A., Poland; Orange Innovation Orange S.A, France; Orange Innovation Poland Orange Polska S.A., Poland","2022 IEEE International Conference on Big Data (Big Data)","26 Jan 2023","2022","","","5090","5099","Industry strives for trustworthy Artificial Intelligence (AI) systems through recognizing and implementing Responsible AI principles. Solutions supporting that goal are of the utmost interest in that context. Standardization is an essential element here, as it provides a platform for industry to discuss and facilitate not only the development of practical rules and requirements but also ways to implement AI based systems. One of Responsible AI principles is fairness, and bias is a serious obstacle against it. First, we explain the concept of Responsible AI and highlight results of our analysis on bias and fairness in ongoing international standardization works and AI Act (AIA). We identified a gap between the principles defined by high-level studies, including the AIA, and their practical implementations, and differences within standardization and research works. Second, we draw a standardization map for AI works. Finally, we state how international standardization bodies may fill this gap?","","978-1-6654-8045-1","10.1109/BigData55660.2022.10020735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10020735","fairness;bias;Responsible AI;standardization","Industries;Ethics;Regulators;Law;Standards organizations;Standardization;Organizations","","","","17","IEEE","26 Jan 2023","","","IEEE","IEEE Conferences"
"Orchestrating Game Generation","A. Liapis; G. N. Yannakakis; M. J. Nelson; M. Preuss; R. Bidarra","Institute of Digital Games, University of Malta, Msida, Malta; Institute of Digital Games, University of Malta, Msida, Malta; MetaMakers Institute, Falmouth University, Falmouth, U.K.; University of Münster, Münster, Germany; Delft University of Technology,, Delft, CD, The Netherlands","IEEE Transactions on Games","15 Mar 2019","2019","11","1","48","68","The design process is often characterized by and realized through the iterative steps of evaluation and refinement. When the process is based on a single creative domain such as visual art or audio production, designers primarily take inspiration from work within their domain and refine it based on their own intuitions or feedback from an audience of experts from within the same domain. What happens, however, when the creative process involves more than one creative domain such as in a digital game? How should the different domains influence each other so that the final outcome achieves a harmonized and fruitful communication across domains? How can a computational process orchestrate the various computational creators of the corresponding domains so that the final game has the desired functional and aesthetic characteristics? To address these questions, this paper identifies game facet orchestration as the central challenge for artificial-intelligence-based game generation, discusses its dimensions, and reviews research in automated game generation that has aimed to tackle it. In particular, we identify the different creative facets of games, propose how orchestration can be facilitated in a top-down or bottom-up fashion, review indicative preliminary examples of orchestration, and conclude by discussing the open questions and challenges ahead.","2475-1510","","10.1109/TG.2018.2870876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466898","Artificial-intelligence (AI)-based game generation;computational creativity;orchestration;procedural content generation (PCG)","Games;Visualization;Generators;Instruments;Art;Creativity;Phonocardiography","","31","","121","IEEE","16 Sep 2018","","","IEEE","IEEE Journals"
"Time-Optimized Online Planning For Parallel Parking With Nonlinear Optimization and Improved Monte Carlo Tree Search","S. Song; H. Chen; H. Sun; M. Liu; T. Xia","School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China","IEEE Robotics and Automation Letters","24 Jan 2022","2022","7","2","2226","2233","Automatic parallel parking is critical to increase safety in urban narrow parking spots, maximize the traffic efficiency, and provide human drivers with mobility and convenience. Recent research integrates Monte Carlo tree search (MCTS) and artificial neural networks (ANNs) to calculate optimal lateral motions without considering the longitudinal aspect and narrow spots; advances in nonlinear programming-based (NPB) parking methods consider time-optimal parking motion in narrow spots using the time-consuming optimization calculation. To address the computational efficiency of the planning of time-optimal parking maneuvers, a complete framework relying on the two compositions was introduced. First, nonlinear optimization that formulates the minimum motion time and vehicle constraint was used to generate the data of parking motions offline. These motions were subsequently learned by ANNs. Second, the ANNs trained on the offline data were employed by an improved MCTS to generate approximate time-optimal parking motions online. The time-optimized performance and run-time performance of the proposed method were confirmed by comparing with that of NPB and other mainstream methods. A success rate of 100% for parking slots with merely 10% larger length than the vehicle was realized in simulations. Experiments were conducted on a full-sized pure electric vehicle to further confirm the effectiveness of the proposed method.","2377-3766","","10.1109/LRA.2021.3139950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669069","Motion and path planning;AI-based methods;intelligent transportation systems","Planning;Optimization;Kinematics;Trajectory;Training;Safety;Monte Carlo methods","","6","","29","IEEE","4 Jan 2022","","","IEEE","IEEE Journals"
"Task and Motion Informed Trees (TMIT*): Almost-Surely Asymptotically Optimal Integrated Task and Motion Planning","W. Thomason; M. P. Strub; J. D. Gammell","Department of Computer Science, Rice University, Houston, TX, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Estimation, Search, and Planning (ESP) Group, Oxford Robotics Institute, University of Oxford, Oxford, U.K.","IEEE Robotics and Automation Letters","29 Aug 2022","2022","7","4","11370","11377","High-level autonomy requires discrete and continuous reasoning to decide both what actions to take and how to execute them. Integrated Task and Motion Planning (TMP) algorithms solve these hybrid problems jointly to consider constraints between the discrete symbolic actions (i.e., the task plan) and their continuous geometric realization (i.e., motion plans). This joint approach solves more difficult problems than approaches that address the task and motion subproblems independently. TMP algorithms combine and extend results from both task and motion planning. TMP has mainly focused on computational performance and completeness and less on solution optimality. Optimal TMP is difficult because the independent optima of the subproblems may not be the optimal integrated solution, which can only be found by jointly optimizing both plans. This letter presents Task and Motion Informed Trees (TMIT*), an optimal TMP algorithm that combines results from makespan-optimal task planning and almost-surely asymptotically optimal motion planning. TMIT* interleaves asymmetric forward and reverse searches to delay computationally expensive operations until necessary and perform an efficient informed search directly in the problem's hybrid state space. This allows it to solve problems quickly and then converge towards the optimal solution with additional computational time, as demonstrated on the evaluated robotic-manipulation benchmark problems.","2377-3766","","10.1109/LRA.2022.3199676","National Defense Science and Engineering Graduate Fellowship; U.K. Research and Innovation/EPSRC(grant numbers:EP/S030832/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869707","Task and motion planning;AI-based methods;manipulation planning;motion and path planning","Costs;Search problems;Cost function;Path planning;Hybrid power systems;Planning;Delays","","5","","38","IEEE","29 Aug 2022","","","IEEE","IEEE Journals"
"GNGraph: Self-Organizing Maps for Autonomous Aerial Vehicle Planning","E. P. Herrera-Alarcón; M. Satler; M. Vannucci; C. A. Avizzano","Perceptual Robotics Laboratory at the IIM Institute, Department of Excellence in Robotics and A.I., Scuola Superiore Sant'Anna, Pisa, Italy; Perceptual Robotics Laboratory at the IIM Institute, Department of Excellence in Robotics and A.I., Scuola Superiore Sant'Anna, Pisa, Italy; ICT-COISP at the TeCIP Institute, Department of Excellence in Robotics and A.I., Scuola Superiore Sant'Anna, Pisa, Italy; Perceptual Robotics Laboratory at the IIM Institute, Department of Excellence in Robotics and A.I., Scuola Superiore Sant'Anna, Pisa, Italy","IEEE Robotics and Automation Letters","9 Aug 2022","2022","7","4","10721","10728","The present letter tackles the problem of planning a collision-free path in a known environment from a general point of view. We address the problem by using an unsupervised learning algorithm to generate a sparse graph representing the topological structure of the environment and use it for planning paths in 3D spaces. We propose GNGraph, an integrated solution combining the Growing Neural Gas algorithm to generate the sparse graph, a stop criterion to guarantee the graph's connectivity and a collision check to assess the edges and nodes validity. The proposed solution has been tested on simulated and real environment maps, and compared against a state-of-the-art graph planning algorithm among other global planning methods.","2377-3766","","10.1109/LRA.2022.3195192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9846934","Aerial systems: perception and autonomy;aerial systems: applications;AI-based methods;autonomous vehicle navigation;integrated planning and learning","Planning;Topology;Three-dimensional displays;Navigation;Skeleton;Robots;Location awareness","","1","","35","IEEE","1 Aug 2022","","","IEEE","IEEE Journals"
"A Deployment Model to Extend Ethically Aligned AI Implementation Method ECCOLA","J. Antikainen; M. Agbese; H. -K. Alanen; E. Halme; H. Isomäki; M. Jantunen; K. -K. Kemell; R. Rousi; H. Vainio-Pekka; V. Vakkuri","Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland","2021 IEEE 29th International Requirements Engineering Conference Workshops (REW)","27 Oct 2021","2021","","","230","235","There is a struggle in Artificial intelligence (AI) ethics to gain ground in actionable methods and models to be utilized by practitioners while developing and implementing ethically sound AI systems. AI ethics is a vague concept without a consensus of definition or theoretical grounding and bearing little connection to practice. Practice involving primarily technical tasks like software development is not aptly equipped to process and decide upon ethical considerations. Efforts to create tools and guidelines to help people working with AI development have been concentrating almost solely on the technical aspects of AI. A few exceptions do apply, such as the ECCOIA method for creating ethically aligned AI -systems. ECCOIA has proven results in terms of increased ethical considerations in AI systems development. Yet, it is a novel innovation, and room for development still exists. This study aims to extend ECCOIA with a deployment model to drive the adoption of ECCOIA, as any method - no matter how good -is of no value without adoption and use. The model includes simple metrics to facilitate the communication of ethical gaps or outcomes of ethical AI development. It offers the opportunity to assess any AI system at any given life-cycle phase, e.g., opening possibilities like analyzing the ethicality of an AI system under acquisition.","","978-1-6654-1898-0","10.1109/REW53955.2021.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582298","Artificial intelligence;AI ethics;ECCOIA;software engineering;product lifecycle;adoption model","Measurement;Ethics;Technological innovation;Conferences;Tools;Software;Requirements engineering","","1","","28","IEEE","27 Oct 2021","","","IEEE","IEEE Conferences"
"End-to-End From Human Hand Synergies to Robot Hand Tendon Routing","D. Hidalgo-Carvajal; C. Herneth; A. Naceri; S. Haddadin","Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Chair of Robotics and Systems Intelligence, MIRMI - Munich Institute of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany","IEEE Robotics and Automation Letters","1 Aug 2022","2022","7","4","10057","10064","The human hand capabilities are paramount for highly dexterous manipulation interactions. Unfortunately, the limitations of current technologies make replicating such capabilities unfeasible. Although several works have focused on directly attempting to create robot hands able to mimic human ones closely, few of them have attempted to create generalizable platforms, where robotic hand mechanisms can be iteratively selected and customized to different tasks. In order to build highly dexterous robotic hands in the future, it is crucial to understand not only human manipulation, but also develop methods to leverage robotic mechanisms limitations to mimic human hand interactions accurately. In this letter, we propose an end-to-end framework capable of generating underactuated tendon routings that allow a generic robot hand model to reproduce desired observed human grasp motion synergies accurately. Our contributions are threefold: (1) an end to end framework to generate task-oriented robot hand tendon routings, with the potential to implement desired synergies, (2) a novel grammar based representation of robot hand tendon routings, and (3) a schematic visualization of robot hand tendon routings. The latter two contributions have the potential to embed and compare properties among robot hands. Our results in simulation show that the proposed method produces tendon routing mechanisms that are able to closely mimic the joint trajectories of human subjects performing the same experimental tasks, while achieving dynamically stable grasping postures.","2377-3766","","10.1109/LRA.2022.3192649","Deutsche Forschungsgemeinschaft; Deutsche Forschungsgemeinschaft; Technische Universität Dresden(grant numbers:390696704); Lighthouse Initiative Geriatronics; StMWi Bayern(grant numbers:IUK-1807-0007//IUK582/001); LongLeif GaPa gGmbH; Bavarian State Ministry for Economic Affairs, Regional Development and Energy(grant numbers:DIK0249); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9834078","Multifingered hands;In-Hand manipulation;grasping;AI-based methods;dexterous manipulation","Robots;Tendons;Routing;Grammar;Grasping;Task analysis;Robot kinematics","","","","33","IEEE","20 Jul 2022","","","IEEE","IEEE Journals"
"A Review on Various Artificial Intelligence Techniques Used for Transmission Line Fault Location","S. Chakrabarti; S. Chakrabarti; A. Swetapadma","School of Computer Engineering, KIIT University, Bhubaneswar, India; School of Computer Engineering, KIIT University, Bhubaneswar, India; School of Computer Engineering, KIIT University, Bhubaneswar, India","2018 3rd International Conference on Inventive Computation Technologies (ICICT)","12 Mar 2020","2018","","","105","109","Transmission line fault location has been estimated using various methods such as conventional distance relaying, differential relaying, artificial intelligent (AI) methods etc. Among all the methods AI based methods locates fault more accurately than others. In this work various AI methods used for transmission line fault location has been discussed with their advantages and limitations. Different AI methods that have been discussed are nearest neighbor algorithm, linear regression, logistic regression, artificial neural network, support vector machine, decision tree. With the various advantages of AI methods, it can be used effectively for locating faults in transmission lines.","","978-1-5386-4985-5","10.1109/ICICT43934.2018.9034333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9034333","Fault Location;Transmission Lines;Artificial Intelligence","Artificial intelligence;Linear regression;Power transmission lines;Artificial neural networks;Support vector machines;Neurons;Decision trees","","2","","8","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Wearables as Part of Decision Support System in Parkinson's Disease Prediagnosis: A Case Study","P. Faragó; A. -S. Popescu; L. Perju-Dumbravă; R. R. Ileşan","Bases of Electronics Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Department of Neurology and Pediatric Neurology, “Iuliu Hatieganu” University of Medicine and Pharmacy, Cluj-Napoca, Romania; Department of Neurology and Pediatric Neurology, “Iuliu Hatieganu” University of Medicine and Pharmacy, Cluj-Napoca, Romania; Clinic of Oral and Cranio-Maxillofacial Surgery, University Hospital Basel, Basel, Switzerland","2022 E-Health and Bioengineering Conference (EHB)","2 Jan 2023","2022","","","1","4","Parkinson's disease (PD) is a progressive neurodegenerative disorder which affects 6.1million people worldwide and bears enormous financial implications. Trends to reduce the costs of PD management target early diagnosis and are oriented towards wearables and artificial intelligence support. This paper presents a case study which investigates the applicability of our previously developed small-size wearable physiograph with an AI-based assessment procedure to provide intelligent decision support in the diagnosis of PD. Our case study presents a 56-year-old female patient that undergone a three-task examination: writing, speaking, and walking. A discussion regarding contextual interpretation of the examination results is provided.","2575-5145","978-1-6654-8557-9","10.1109/EHB55594.2022.9991543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9991543","Artificial intelligence;biomedical monitoring;convolutional neural networks;diagnostics;Parkinson's disease","Legged locomotion;Decision support systems;Pathology;Musculoskeletal system;Protocols;Parkinson's disease;Wearable computers","","1","","13","IEEE","2 Jan 2023","","","IEEE","IEEE Conferences"
"Beyond Industry 4.0: Leveraging AI-powered Anomalous Sound Detection for Smart Maintenance","B. Mrazovac; V. Ilian; M. Hulea","Department for R&D and Future Technologies, Faculty of Technical Science Novi Sad, NTT Data Romania, Serbia; Department for R&D and Future Technologies, NTT Data Romania, Bucharest, Romania; Department for R&D and Future Technologies, NTT Data Romania Technical University of Cluj-Napoca, Cluj-Napoca, Romania","2021 Zooming Innovation in Consumer Technologies Conference (ZINC)","2 Aug 2021","2021","","","43","47","The ongoing global changes, pushing the digital transformation to Industry 4.0, have been reflected in the launch of new services and process innovations tackling the existing pressure on costs and prices. In this context, AI is becoming an integral part of all future smart maintenance endeavors. The new generation of intelligent maintenance systems, driven by big data analysis and advanced diagnostics, are already guiding automated predictive innovation towards the idea of zero-failure activity. Automated detection of failures is crucial for smart maintenance, for building AI-based factory automation. In this context, the paper describes a solution for detecting failures based on sound obtained from the target machines. Abnormal sound data is difficult to collect, as it rarely occurs and is being hard to extract from a noisy environment and could have various patterns. The proposed solution detects anomalous sound after training the machine-learning model only with the normal operating sound of machines in a factory environment.","","978-1-6654-0417-4","10.1109/ZINC52049.2021.9499309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499309","sound anomaly detection;predictive maintenance","Training;Industries;Technological innovation;Machine learning;Maintenance engineering;Real-time systems;Production facilities","","","","18","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"A Evolutionary Behavior Tree AI for Neural MMO Challenge","K. Zhang; C. Xu","Department of Information Systems, Dalian Naval Academy, Dalian, China; Department of Information Systems, Dalian Naval Academy, Dalian, China","2022 4th International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM)","27 Mar 2023","2022","","","327","332","The Neural MMO Challenge aims to study robustness and teamwork in large-scale multi-agent environments. AI needs to explore, search and fight in large-scale environments, and get higher scores than other competitors. Therefore, we developed AI based on evolutionary behavior tree, which has the advantages of strong interpretability, low coupling between modules and strong robustness. Specifically, the AI adopts the idea of divide and conquer, divides the decision-making into two levels: team and individual, divides the four task achievements into several subtasks, finds appropriate agents for each subtask according to the current advantages, and then completes specific actions such as attack, foraging, avoidance and collaboration, and optimizes the parameters with evolutionary strategy algorithm.AI won the silver medal in IJCAI 2022 Neural MMO Challenge.","","978-1-6654-6399-7","10.1109/AIAM57466.2022.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10071388","Behavior tree;evolutionary algorithm;nmmo;multi-agent decision-making","Couplings;Silver;Machine learning algorithms;Decision making;Neural networks;Robustness;Behavioral sciences","","","","11","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"Artificial intelligence in boiler control","K. Raghupathy; R. K. Yadav","Department of Atomic Energy, Indira Gandhi Centre for Atomic Research, Kalpakkam, India; Department of Atomic Energy, Indira Gandhi Centre for Atomic Research, Kalpakkam, India","2015 International Conference on Robotics, Automation, Control and Embedded Systems (RACE)","30 Apr 2015","2015","","","1","6","Artificial Intelligence (AI) techniques are becoming useful as alternate approaches to conventional techniques. They have been used to solve complicated practical problems and now a day is very popular. They can learn from examples, fault tolerant in the sense they are able to handle noisy and incomplete data and once trained can perform faster prediction and generalization. AI based systems are used mainly because of their symbolic reasoning, flexibility and explanation capabilities. This paper briefly presents the main AI techniques and outlines an application in boiler control. Master controller is required for a steam generating system having multiple boilers operating in parallel. AI technique of Fuzzy logic controller is proposed as master controller. The optimum performance of individual boilers is achieved by the master controller meeting the varying load demands of the steam system.","","978-8-1925-9743-0","10.1109/RACE.2015.7097268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097268","fuzzy control;optimization;boilers;load manager","Boilers;Fuzzy logic;Combustion;Artificial intelligence;Pragmatics;Input variables","","","","4","","30 Apr 2015","","","IEEE","IEEE Conferences"
"An Intelligent Two-Phase Automated Architecture for Securing SDN-Based IoT Infrastructure","M. SafaeiSisakht; C. -H. Hsu; P. -Y. Hsu; M. -Y. Chen","Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan; Department of Mechanical Engineering, National Chung Cheng University, Chiayi, Taiwan; Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan","2023 IEEE 3rd International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)","7 Jul 2023","2023","","","12","16","The Internet of Things (IoT) will bring many opportunities in the next years. However, IoT devices have processing and power limitation. Thus, security remains one of the main challenges. Software-defined networking (SDN) helps traditional IoT infrastructure become manageable and flexible in a centralized fashion. The SDN-IoT architecture tackles the security issue of IoT networks. The proposed architecture adds a new security engine to the controller. The security engine consists of the monitoring, intelligent sub-layer, analyzing/detection engine, reaction, and config engine to automatically monitor, analyze, classify, detect, and generate a proper reaction to the possible threads in two phases. The config engine automatically rearranges the security rules and applies the set of rules as a new configuration to the devices (switches) in the data layer. The intelligent sub-layer uses AI-based feature selection (Bat Algorithm) and classification (Random Forest) algorithms to reveal the possible threats and forward its output to the analyzing/detecting engine to examine it and make the alerts. The cooperation of the intelligent sub-layer and analyzing/detection engine in the two mentioned steps help the system improve the overall system performance and false positive alerts. The proposed architecture follows new security rules based on the network status such as bandwidth minimization and traffic. All the process automatically makes by the security engine and protects the entire network from different threats and attacks.","","979-8-3503-3386-2","10.1109/ICEIB57887.2023.10170386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10170386","IoT;SDN;Security;Random forest;Bat algorithm","Radio frequency;System performance;Feature extraction;Classification algorithms;Security;Internet of Things;Software defined networking","","","","14","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"Can Deep Learning Improve Technical Analysis of Forex Data to Predict Future Price Movements?","M. Fisichella; F. Garolla","L3S Research Center, Leibniz University of Hannover, Hannover, Germany; SLR Engineering, Graz, Austria","IEEE Access","19 Nov 2021","2021","9","","153083","153101","The foreign exchange market (Forex) is the world’s largest market for trading foreign money, with a trading volume of over 5.1 trillion dollars per day. It is known to be very complicated and volatile. Technical analysis is the observation of past market movements with the aim of predicting future prices and dealing with the effects of market movements. A trading system is based on technical indicators derived from technical analysis. In our work, a complete trading system with a combination of trading rules on Forex time series data is developed and made available to the scientific community. The system is implemented in two phases: In the first phase, each trading rule, both the AI-based rule and the trading rules from the technical indicators, is tested for selection; in the second phase, profitable rules are selected among the qualified rules and combined. Training data is used in the training phase of the trading system. The proposed trading system was extensively trained and tested on historical data from 2010 to 2021. To determine the effectiveness of the proposed method, we also conducted experiments with datasets and methodologies used in recent work by Hernandez-Aguila et al., 2021 and by Munkhdalai et al., 2019. Our method outperforms all other methodologies for almost all Forex markets, with an average percentage gain of 20.2%. A particular focus was on training our AI-based rule with two different architectures: the first is a widely used convolutional network for image classification, i.e. ResNet50; the second is an attention-based network Vision Transformer (ViT). The results provide a clear answer to the main question that guided our research and which is the title of this paper.","2169-3536","","10.1109/ACCESS.2021.3127570","European Commission for the eXplainable Artificial Intelligence in healthcare Management (xAIM) Project(grant numbers:INEA/CEF/ICT/A2020/2276680); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612217","Forex;expert advisor;genetic algorithm;metatrader;technical analysis;technical indicators;trading rules;trading system","Currencies;Neural networks;Support vector machines;Predictive models;Optimization;Training;Genetic algorithms","","15","","32","CCBY","11 Nov 2021","","","IEEE","IEEE Journals"
"On STPA for Distributed Development of Safe Autonomous Driving: An Interview Study","A. Nouri; C. Berger; F. Törner","Volvo Cars, Gothenburg, Sweden; Sweden Department of Computer Science and Engineering, University of Gothenburg; Volvo Cars, Gothenburg, Sweden","2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","1 Jan 2024","2023","","","5","12","Safety analysis is used to identify hazards and build knowledge during the design phase of safety-relevant functions. This is especially true for complex AI-enabled and software intensive systems such as Autonomous Drive (AD). System-Theoretic Process Analysis (STPA) is a novel method applied in safety-related fields like defense and aerospace, which is also becoming popular in the automotive industry. However, STPA assumes prerequisites that are not fully valid in the automotive system engineering with distributed system development and multi-abstraction design levels. This would inhibit software developers from using STPA to analyze their software as part of a bigger system, resulting in a lack of traceability. This can be seen as a maintainability challenge in continuous development and deployment (DevOps). In this paper, STPA’s different guidelines for the automotive industry, e.g. J31887/ISO21448/STPA handbook, are firstly compared to assess their applicability to the distributed development of complex AI-enabled systems like AD. Further, an approach to overcome the challenges of using STPA in a multilevel design context is proposed. By conducting an interview study with automotive industry experts for the development of AD, the challenges are validated and the effectiveness of the proposed approach is evaluated.","2376-9521","979-8-3503-4235-2","10.1109/SEAA60479.2023.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371692","System Theoretic Process Analysis;STPA;safety-related function;autonomous driving;functional safety (FUSA);safety of the intended function (SOTIF)","Industries;DevOps;Systems engineering and theory;Software;Hazards;Interviews;Autonomous vehicles","","","","16","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"Neuromorphic Near-Sensor Computing: From Event-Based Sensing to Edge Learning","A. Safa; J. Van Assche; M. D. Alea; F. Catthoor; G. G. E. Gielen","IMEC and KU Leuven, Leuven, Belgium; KU Leuven, Leuven, Belgium; KU Leuven, Leuven, Belgium; IMEC and KU Leuven, Leuven, Belgium; IMEC and KU Leuven, Leuven, Belgium","IEEE Micro","31 Oct 2022","2022","42","6","88","95","Neuromorphic near-sensor computing has recently emerged as a low-power and low-memory paradigm for the design of artificial intelligence (AI)-enabled IoT devices working at the extreme edge. Compared to conventional sensing and learning techniques, neuromorphic sampling, and processing reduces data bandwidth requirements, induces large savings on power and area consumption, and enables online learning and adaptation. In this article, we discuss recent studies made in the design of event-based sampling and learning circuits. We show that our event-based sampling methods outperform conventional techniques in terms of power consumption. We also show that our spiking neural network (SNN), learning through spike-timing-dependent plasticity (STDP), outperforms the state-of-the-art SNN-STDP systems in terms of inference accuracy while being orders of magnitude more power efficient than conventional deep-learning systems. We hope that the opportunities discussed in this summary article will inspire future research.","1937-4143","","10.1109/MM.2022.3195634","Flemish Government; INTUITIVE—EU Horizon 2020 project(grant numbers:861166); KUL internal; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847074","","Neurons;Neuromorphics;Encoding;Sensors;Cameras;System-on-chip;Power demand;Low power electronics;Event detection;Edge computing","","4","","18","IEEE","1 Aug 2022","","","IEEE","IEEE Magazines"
"A New Fracture Liaison Service Using the Mobile Application and IoT Sensor","S. -W. Kim; Y. -J. Won; D. -S. Chae; H. -J. Chang","Cardio-vascular Information Communication Technology Research Center, Yonsei University College of Medicine, Seoul, South Korea; Cardio-vascular Information Communication Technology Research Center, Yonsei University College of Medicine, Seoul, South Korea; Cardio-vascular Information Communication Technology Research Center, Yonsei University College of Medicine, Seoul, South Korea; Cardio-vascular Information Communication Technology Research Center, Yonsei University College of Medicine, Seoul, South Korea","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","7 Oct 2019","2019","","","3486","3489","While the clinical design of a Fracture Liaison Service(FLS) has been used as a localized healthcare service in a previous study, thus far there has not been an international mobile application, such as a FLS using smart phones. In addition, we developed a safety monitoring system using IoT sensor for a smart wheelchair. Our FLS is able to give patient various fall-related predictions with a safety monitoring system on this mobile application. The goal of our study is to improve the prevention of secondary fractures from our FLS application. We have developed a Fracture Liaison Service as an Android-OS application and released this service as a secondary fracture prevention program for osteoporotic fracture patients. We have released the final version of the FLS mobile application in Google's PlayStore. The new model of the FLS mobile application can be practically commercialized, and the effective second-order fracture prevention system is based on an open policy platform. We hope to contribute to the prevention and management of osteoporotic fractures and osteoporosis worldwide via this FLS mobile application. In the future, an intelligent personal FLS is definitely possible, by applying a Medical AI based on a huge DB.","1558-4615","978-1-5386-1311-5","10.1109/EMBC.2019.8857094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8857094","FLS;osteoporosis;fracture prevention;patient education;smartphone applications;IoT sensor","Wheelchairs;Guidelines;Safety;Monitoring;Osteoporosis;Mobile applications","Bone Density Conservation Agents;Humans;Mobile Applications;Osteoporosis;Osteoporotic Fractures;Secondary Prevention","","","12","IEEE","7 Oct 2019","","","IEEE","IEEE Conferences"
"Sea-battlefield situation assessment based on a new method combining dynamic Bayesian network with pattern matching","J. Ma; L. Liu","National Key Laboratory of Science and Technology on Integrated Control Technology Beihang University, Beijing, China; National Key Laboratory of Science and Technology on Integrated Control Technology Beihang University, Beijing, China","Proceedings of 2014 IEEE Chinese Guidance, Navigation and Control Conference","15 Jan 2015","2014","","","1764","1769","Sea-battlefield situation is a dynamic, nonlinear and multi-dimensional system where Artificial Intelligence (AI) system has a good role to play. Bayesian Network has a strong knowledge skills and reasoning ability to solve the problem of sea-battlefield situation assessment. After constructing the network, giving the probability, considering the time factor and then combining with Pattern Matching using a rule set, sea-battlefield situation assessment can be achieved. The knowledge representation will be discussed and how to complete reasoning through Bayesian Network and Pattern Matching will be researched. In the end, a simulation will illustrate the combining method has a good performance in sea-battle-field situation assessment.","","978-1-4799-4699-0","10.1109/CGNCC.2014.7007450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7007450","Sea-battlefield;Situation assessment;Bayesian Network;Pattern Matching","Bayes methods;Pattern matching;Cognition;Aircraft;Real-time systems;Meteorology;Time factors","","2","","18","IEEE","15 Jan 2015","","","IEEE","IEEE Conferences"
"Driving style imitation in simulated car racing using style evaluators and multi-objective evolution of a fuzzy logic controller","T. Wang; K. -T. Liaw","Department of Computer Science, National Chiao Tung University, Hsinchu City, Taiwan, R.O.C.; Department of Computer Science, National Chiao Tung University, Hsinchu City, Taiwan, R.O.C.","2014 IEEE Conference on Norbert Wiener in the 21st Century (21CW)","8 Sep 2014","2014","","","1","7","This paper describes a new approach to driving style imitation in simulated car racing games. Our goal is to be able to create non-personal characters (NPCs) that both run competitively and exhibit some driving style traits of the player being imitated. We introduce a style evaluator function that can measure the style similarity between driving records even from different tracks. The effectiveness of such style evaluators are verified using driving records of both NPCs and human players. To build NPC drivers that can imitate particular human players, we use a base driver AI based on a fuzzy logic controller and optimizes its parameters using multi-objective evolution. This is the first work on driver imitation that actually allows several human players to drive in their only natural, not instructed, styles. Our results show evidences that the created imitator NPCs do possess traits of styles of the respective human players being modeled.","","978-1-4799-4562-7","10.1109/NORBERT.2014.6893872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893872","simulated car racing;TORCS;fuzzy rules;multi-objective evolution;computer games;player imitation","Target tracking;Acceleration;Sensors;Games;Training;Vehicles;Accidents","","4","","14","IEEE","8 Sep 2014","","","IEEE","IEEE Conferences"
"An Explainable AI Model for Interpretable Lung Disease Classification","V. Pitroda; M. M. Fouda; Z. M. Fadlullah","Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada; Department of Electrical and Computer Engineering, Idaho State University, Pocatello, ID, USA; Department of Computer Science, Lakehead University, Thunder Bay, Ontario, Canada","2021 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS)","7 Dec 2021","2021","","","98","103","In this paper, we develop a framework for lung disease identification from chest X-ray images by differentiating the novel coronavirus disease (COVID-19) or other disease-induced lung opacity samples from normal cases. We perform image processing tasks, segmentation, and train a customized Convolutional Neural Network (CNN) that obtains reasonable performance in terms of classification accuracy. To address the black-box nature of this complex classification model, which emerged as a key barrier to applying such Artificial Intelligence (AI)-based methods for automating medical decisions raising skepticism among clinicians, we address the need to quantitatively interpret the performance of our adopted approach using a Layer-wise Relevance Propagation (LRP)-based method. We also used a pixel flipping-based, robust performance metric to evaluate the explainability of our adopted LRP method and compare its performance with other explainable methods, such as Local Interpretable Model Agnostic Explanation (LIME), Guided Backpropagation (GB), and Deep Taylor Decomposition (DTD).","","978-1-6654-2035-8","10.1109/IoTaIS53735.2021.9628573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9628573","Deep learning;explainable AI;Layer-wise Relevance Propagation;LIME;Deep Taylor Decomposition;Guided Backpropagation;medical diagnosis;chest X-ray;COVID-19","Measurement;COVID-19;Pulmonary diseases;Lung;Bones;Convolutional neural networks;Artificial intelligence","","7","","23","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"An Overview of Fuzzy Logic Approaches for Fault Diagnosis in Energy Conversion Devices","G. Demidova; A. Rassõlkin; T. Vaimann; A. Kallaste; J. Zakis; A. Suzdalenko","Department of Electrical Power Engineering and Mechatronics, Tallinn University of Technology, Tallinn, Estonia; Department of Electrical Power Engineering and Mechatronics, Tallinn University of Technology, Tallinn, Estonia; Department of Electrical Power Engineering and Mechatronics, Tallinn University of Technology, Tallinn, Estonia; Department of Electrical Power Engineering and Mechatronics, Tallinn University of Technology, Tallinn, Estonia; Institute of Industrial Electronics and Electrical Engineering, Riga Technical University, Riga, Latvia; Institute of Industrial Electronics and Electrical Engineering, Riga Technical University, Riga, Latvia","2021 28th International Workshop on Electric Drives: Improving Reliability of Electric Drives (IWED)","22 Mar 2021","2021","","","1","7","Any energy conversion devices, such as industrial motor-drives, propulsion drives of electric vehicles, pump systems, wind turbines, and others, are prone to failures. Usually, failures result in increased economic costs that come through additional energy losses, loss of production, or in a worst-case even environmental hazard. To prevent failures, energy conversion systems may be checked through particular routines developed and specified by the manufactures. However, it may be challenging due to the complex construction of energy conversion devices or devices' failure between the routine checks. Such schedule-based condition monitoring approaches provide minor information on the remaining lifetime (separate components and whole system) of the devices and do not allow proper prognostic or full exploitation. To overcome traditional two-level Boolean approaches with healthy/faulty states an Artificial Intelligence (AI)-based control techniques are used. The Fuzzy Logic approach is based on inspired by human perception processes and cognition that are often uncertain or empirical. However, Fuzzy Logic is already successfully applied in various control applications of energy conversion devices, even when the analytical models are unknown. This paper argues for developing new fault detection algorithms based on fuzzy logic methods to allow energy conversion systems designers to develop reliability factors for apparatus, which included electrical machines and power electronics subsystems.","","978-1-6654-1456-2","10.1109/IWED52055.2021.9376389","EEA(grant numbers:2014–2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376389","fuzzy logic;fault-tolerant control;fault diagnosis;fault detection","Fuzzy logic;Condition monitoring;Digital twin;Energy conversion;Propulsion;Reliability engineering;Wind turbines","","3","","58","IEEE","22 Mar 2021","","","IEEE","IEEE Conferences"
"Verification of Intelligent Transportation Systems: Challenges And Possibilities","I. Phillips; R. Kenley","School of Industrial Engineering, Purdue University, West Lafayette, USA; School of Industrial Engineering, Purdue University, West Lafayette, USA","2022 17th Annual System of Systems Engineering Conference (SOSE)","6 Jul 2022","2022","","","127","131","Intelligent Transportation Systems (ITS) have been touted and proven to be an advanced-technology improvement in transport systems and commuters’ operational performance, efficiency, and safety. The nature of ITS as an integrated metasystem of information and data, operational management, safety, ICT infrastructure, and logistic systems permits their observation as a System of Systems (SoS). In addition, the prevalence of real-time information processing and the subsequent data explosion requires the utilization of Artificial Intelligence (AI) solutions. ITS characteristics depict them as AIbased SoS, which presents challenges to the verification and certification of these systems. This paper will frame ITS as Systems of Systems, considering their SoS classification from literature while outlining the role of AI applications in fostering effective and adequate mobility for these systems. With the understanding of the architecture and nature of ITS, it becomes easier to understand how the emergence and the complexity of modeling and evaluating these systems, among other challenges, contribute to the verification difficulty that will be encountered – key to certifying these systems. We propose some solutions from literature meant to serve as components of a holistic suite of solutions towards resolving the verification challenges posed by AI-based Systems of Systems like ITS.","","978-1-6654-9623-0","10.1109/SOSE55472.2022.9812702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9812702","Intelligent Transportation Systems;System of Systems;Artificial Intelligence;Verification;Challenges","Transportation;Information processing;Real-time systems;Safety;Information and communication technology;Artificial intelligence;Certification","","2","","39","IEEE","6 Jul 2022","","","IEEE","IEEE Conferences"
"GitHub Considered Harmful? Analyzing Open-Source Projects for the Automatic Generation of Cryptographic API Call Sequences","C. Tony; N. E. Díaz Ferreyra; R. Scandariato","Institute of Software Security, Hamburg University of Technology, Hamburg, Germany; Institute of Software Security, Hamburg University of Technology, Hamburg, Germany; Institute of Software Security, Hamburg University of Technology, Hamburg, Germany","2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)","20 Mar 2023","2022","","","896","906","GitHub is a popular data repository for code examples. It is being continuously used to train several AI-based tools to automatically generate code. However, the effectiveness of such tools in correctly demonstrating the usage of cryptographic APIs has not been thoroughly assessed. In this paper, we investigate the extent and severity of misuses, specifically caused by incorrect cryptographic API call sequences in GitHub. We also analyze the suitability of GitHub data to train a learning-based model to generate correct cryptographic API call sequences. For this, we manually extracted and analyzed the call sequences from GitHub. Using this data, we augmented an existing learning-based model called DeepAPI to create two security-specific models that generate cryptographic API call sequences for a given natural language (NL) description. Our results indicate that it is imperative to not neglect the misuses in API call sequences while using data sources like GitHub, to train models that generate code.","2693-9177","978-1-6654-7704-8","10.1109/QRS57517.2022.00094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10062390","Cryptography;APIs;JCA;security;API misuses","Training;Computer languages;Codes;Natural languages;Software quality;Programming;Data models","","1","","25","IEEE","20 Mar 2023","","","IEEE","IEEE Conferences"
"A Semantic Workbench for Editing, Querying, Navigating and Distributing Ontologies for Cognitive Manufacturing","B. R. Ferrer; W. M. Mohammed; J. L.; M. Lastra; S. Strzelczak","Faculty of Engineering and Natural Sciences, FAST-Lab, Tampere University, P. O. Box. 600, Tampere, Finland; Faculty of Engineering and Natural Sciences, FAST-Lab, Tampere University, P. O. Box. 600, Tampere, Finland; FAST-Lab, Tampere University, Tampere, Finland; Faculty of Engineering and Natural Sciences, FAST-Lab, Tampere University, P. O. Box. 600, Tampere, Finland; Faculty of Production Engineering, Lab of Industrial Ecosystemics, Warsaw University of Technology, Warsaw, Poland","IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society","9 Dec 2019","2019","1","","2767","2772","Manufacturing-oriented enterprises are investing in novel solutions to adapt their cyber and physical resources to the fast and, yet, unexpected changes of global industrial environment. One of the important trends is to work towards development of cognitive systems which are capable to process and analyze complex data using Artificial Intelligence (AI)-based tools and techniques. Therefore, cognition can be already viewed as a requirement for hyper-connected environments e.g., the factories of the future or the Internet of Things (IoT). In this context, there is a need to represent and store the data collected from machines in a format that can be understood and manipulated by both humans and machines. This is feasible by designing and implementing semantic models i.e., ontologies which, in turn, enable inferring implicit data of explicit knowledge, leading to cognition. Moreover, there is a need of granting the access to such information remotely and at system runtime. Within this conceptual article, the authors present a semantic workbench that was developed during a European project aiming at utilization of ontologies for knowledge representation and reasoning in industrial automation systems. Further, this research work proposes the encapsulation of semantic workbench as a service in order to be deployed in cloud-based platforms, hence, enabling remote access of authorized clients at system runtime. The proposed functionalities are also of critical importance in highly complex and distributed environments, like the IoT or industrial ecosystems.","2577-1647","978-1-7281-4878-6","10.1109/IECON.2019.8927430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8927430","Cognitive manufacturing;industrial internet;knowledge representation;ontology;cloud-based systems","Ontologies;Semantics;Cognition;Manufacturing;Cloud computing;Production facilities;Industries","","","","40","IEEE","9 Dec 2019","","","IEEE","IEEE Conferences"
"KIAAA: An AI Assistant for Teaching Programming in the Field of Automation","S. Eilermann; L. Wehmeier; O. Niggemann; A. Deuter","Computer science in mechanical engineering, Helmut-Schmidt University, Hamburg, Germany; Computer science for engineering and production, University of applied Science and Arts Ostwestfalen-Lippe, Lemgo, Germany; Computer science in mechanical engineering, Helmut-Schmidt University, Hamburg, Germany; Computer science for engineering and production, University of applied Science and Arts Ostwestfalen-Lippe, Lemgo, Germany","2023 IEEE 21st International Conference on Industrial Informatics (INDIN)","22 Aug 2023","2023","","","1","7","Especially in highly interdisciplinary fields such as automation engineering, contemporary programming education with tailored assignments and individual feedback is a major challenge for educational institutions due to the increasing number of students per teacher and the ever-increasing demand for computer science professionals. To address this gap, we present ”KIAAA” an AI Assistant for Automation Engineering Teaching, a work-in-progress approach for an integrated, customized, and AI-based learning support system for automation and programming courses based on instructor-defined course objectives. Thereby in the KIAAA system, the individual knowledge level of the students is determined and individually tailored virtual learning scenarios are generated based on the knowledge and learning profile of the students. These are iteratively adapted based on the answers given. To achieve this, KIAAA uses several AI components, a hybrid rule-based scenario generation component, a Help-DKT-based cognitive model, and a solution assessor that uses a combination of traditional code analysis methods and AI-based analyses methods for automated programming task assessment. These components are the main parts of KIAAA to generate customized programming scenarios as well as visualization and simulation based on a modern game and physics engine.","2378-363X","978-1-6654-9313-0","10.1109/INDIN51400.2023.10218157","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10218157","intelligent tutoring system;ai-based adaptive task generation;automated programming task assessment","Visualization;Automation;Education;Games;Hybrid power systems;Task analysis;Artificial intelligence","","","","43","IEEE","22 Aug 2023","","","IEEE","IEEE Conferences"
"Integrated Multiple DEA Specifications and Visualization Technique for Advanced Management Analysis and Decision","T. -m. Chang; F. -H. Chen; S. -J. Lin; M. -F. Hsu","Department of Information, Management National Sun Yat-sen University, Kaohsiung, Taiwan, R.O.C.; Department of Accounting, Chinese Culture University, Taipei, Taiwan, R.O.C.; Department of Accounting, Chinese Culture University, Taipei, Taiwan, R.O.C.; English Program of Global Business, Chinese Culture University, Taipei, Taiwan, R.O.C.","2019 20th IEEE International Conference on Mobile Data Management (MDM)","8 Aug 2019","2019","","","491","496","In recent years, financial troubles (such as, financial crisis, credit risk, and default) have begun to appear and continue to grow rapidly, which has shocked the confidence of stack market participants as well as has frozen the circulation of valuable economic resource. Most previous works only laid much more emphasis on well-examined studies, such as financial crisis prediction and credit risk prediction, the work on forecasting corporate operating performance that has been widely deemed as the main trigger for financial troubles is quite rare. To fill this research gap, we introduces an artificial intelligence (AI)-based hybrid architecture that integrated dominance-based rough set theory (DBRST), support vector machine with particle swarm optimization (SVM-PSO) and rule generation. The introduced model, tested by real-cases, is a promising alternative for corporate operating performance forecasting and it can assist in both internal and external market participants.","2375-0324","978-1-7281-3363-8","10.1109/MDM.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788835","artificial intelligence, decision making, forecasting, rule generation","Support vector machines;Biological system modeling;Forecasting;Predictive models;Principal component analysis;Reliability;Kernel","","","","26","IEEE","8 Aug 2019","","","IEEE","IEEE Conferences"
"Fuzzy Logic-based MPPT Control for Bifacial Photovoltaic Module","N. Siddiqui; A. Verma; D. Shrivastava","Department of Electrical Engineering, Institute of Engineering and Technology, Lucknow, India; Department of Electrical Engineering, Institute of Engineering and Technology, Lucknow, India; Department of Electrical Engineering, Institute of Engineering and Technology, Lucknow, India","2023 Second International Conference on Electronics and Renewable Systems (ICEARS)","5 Apr 2023","2023","","","1","6","Solar Photovoltaics (PV) is crucial to meeting the energy needs of the current generation. Bifacial PV modules can generate high power density and higher energy yield with cost-effective operation due to their diffused and reflected irradiance-capturing capability. The power output of the PV system varies with varying temperatures and solar irradiance. The bifacial solar cell takes the independent value of irradiance for the front side and rear sides of the cell. Bifacial solar cells, like any other solar cell, are variable sources and their power output must be controlled, which is accomplished using the maximum power point tracking (MPPT) control techniques. Various Artificial Intelligence (AI) based algorithms are available for maximizing the power of the PV systems. AI-based methods have huge applications in PV systems to provide better responses. To get the Bifacial PV module's maximum operational power, this study proposes AI-based, fuzzy logic MPPT control with boost converter topology.","","979-8-3503-4664-0","10.1109/ICEARS56392.2023.10085389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10085389","Irradiance modeling;PV modeling;Bifacial cell modeling;MPPT;Fuzzy logic system;DC-DC converter","Maximum power point trackers;Photovoltaic systems;Fuzzy logic;Renewable energy sources;Power system measurements;Photovoltaic cells;Topology","","","","16","IEEE","5 Apr 2023","","","IEEE","IEEE Conferences"
"Comprehensive IoT SIM Card Anomaly Detection Algorithm Based on Big Data","T. Zhang; H. Li; L. Xu; J. Gao; J. Guan; X. Cheng","China United Network Communications Corporation, Network Technology Research Institute, Beijing, P.R. China; Network Development Department, China United Network Communications Group Corporation, Beijing, P.R. China; China United Network Communications Corporation, Network Technology Research Institute, Beijing, P.R. China; China United Network Communications Corporation, Network Technology Research Institute, Beijing, P.R. China; China United Network Communications Corporation, Network Technology Research Institute, Beijing, P.R. China; China United Network Communications Corporation, Network Technology Research Institute, Beijing, P.R. China","2019 IEEE International Conferences on Ubiquitous Computing & Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS)","6 Feb 2020","2019","","","602","606","The mobile Internet of Things (IoT) industry in China has developed rapidly and is expected to maintain rapid growth in the next decade. For the three mobile operators in China, IoT gradually becomes the new/key engine for profit growth. However, at the early stage of IoT development, due to the low cost of IoT SIM card, some illegal organizations and individuals take advantage of this loophole to earn illegal profits, which cause huge losses for mobile operators. In this paper, we explore comprehensive abnormal IoT SIM card detection algorithm based on IoT big data. For different IoT scenarios, this paper proposes two kinds of algorithms, including various rule-based detection algorithm (RDA) and AI-based detection algorithm (AIDA). The result of use case also shows that RDA and AIDA can greatly improve the anomaly detection accuracy and can benefit both of the telecommunication operators and enterprise customers.","","978-1-7281-5209-7","10.1109/IUCC/DSCI/SmartCNS.2019.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982655","anomaly detection;IoT;clustering;classification","","","11","","13","IEEE","6 Feb 2020","","","IEEE","IEEE Conferences"
"Improving Circuit Miniaturization and Its Efficiency Using Rough Set Theory","S. S. S. Rawat; D. D. Mor; S. S. Roy; A. Kumar; R. Ramesh","VIT University, Vellore, Tamil Nadu, IN; School of Electronics and Instrumentation, VIT University, Vellore, India; School of Electronics and Instrumentation, VIT University, Vellore, India; School of Electronics and Instrumentation, VIT University, Vellore, India; School of Electronics and Instrumentation, VIT University, Vellore, India","2013 International Conference on Machine Intelligence and Research Advancement","9 Oct 2014","2013","","","374","378","High-speed, accuracy, meticulousness and quick responses are the notion of the vital necessities for modern digital world. An efficient electronic circuit unswervingly affects the maneuver of the whole system. Different tools are required to unravel different types of engineering tribulations. Improving the efficiency, accuracy and low power consumption in an electronic circuit is always been a bottle neck problem. So the need of circuit miniaturization is always there. It saves a lot of time and power while switching of gates and reduces the wiring-crises. Therefore to trounce with this problem we have proposed an artificial intelligence (AI) based approach that makes use of Rough Set Theory for its implementation. Theory of rough set has been proposed by Z Pawlak in the year 1982. Rough set theory is a new mathematical tool which deals with uncertainty and vagueness. Decisions can be generated using rough set theory by reducing the unwanted and superfluous data. We have condensed the number of gates without upsetting the productivity of the given circuit. This paper proposes an approach using artificial intelligence technique with the help of rough set theory which basically lessens the number of gates in the circuit, based on decision rules.","","978-0-7695-5013-8","10.1109/ICMIRA.2013.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918856","digital world;electronic circuit;rough set","Set theory;Logic gates;Approximation methods;Artificial intelligence;Educational institutions;Accuracy;Electronic circuits","","1","","7","IEEE","9 Oct 2014","","","IEEE","IEEE Conferences"
"GPT-K: A GPT-based model for generation of text in Kannada","K. H. Manodnya; A. Giri","Department of Computer Science and Engineering, PES University, Bangalore, India; Department of Computer Science and Engineering, PES University, Bangalore, India","2022 IEEE 4th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA)","22 Dec 2022","2022","","","534","539","Large AI-based language models are changing how we work with language. They are becoming increasingly popular because they allow us to create complex linguistic structures without requiring a lot of resources. A language model must have access to a large corpus of linguistic data (e.g., word frequencies) to learn and generate new words. GPT-2, a language model, can generate coherent paragraphs independently, without any input on what to write about or guidance on grammar rules. Although multiple pre-trained GPT-2 models exist for English and other high-resource languages, there are few to no such models for Indic languages like Kannada. In this study, we propose GPT-K, a GPT-2 based model for language modeling in Kannada. GPT-K has been trained on a large corpus of Kannada text and can effectively perform language modeling tasks in Kannada. The model generated syntactically correct text in most cases.","","978-1-6654-6246-4","10.1109/ICCCMLA56841.2022.9989289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989289","GPT-2;large language models;language modeling;model training;hyperparameter finetuning;Indic languages","Prototypes;Machine learning;Linguistics;Data models;Cognition;Grammar;Task analysis","","","","17","IEEE","22 Dec 2022","","","IEEE","IEEE Conferences"
"Comparison of ANN and ANFIS based MPPT Controller for grid connected PV systems","A. Arora; P. Gaur","Dept. of Instrumentation and Control Engineering, Netaji Subhas Institute of Technology (NSIT), University of Delhi, India; Dept. of Instrumentation and Control Engineering, Netaji Subhas Institute of Technology (NSIT), University of Delhi, India","2015 Annual IEEE India Conference (INDICON)","31 Mar 2016","2015","","","1","6","This paper presents comparison analysis of artificial neural network (ANN) and adaptive neuro fuzzy inference system (ANFIS) artificial intelligence (AI) based maximum power point tracking (MPPT) techniques for tracking maximum power from the Photovoltaic (PV) array. These algorithms are essential since PV arrays have non-linear characteristics with its firm dependence on changing solar irradiation and temperature. To increase the power extracted from solar panel, PV array must operate at a maximum power point (MPP) under given load conditions. Conventional algorithms such as Perturb and Observe (P&O) and Incremental-Conductance (Inc-Cond) suffers, with high oscillations during changing solar irradiation leading to low efficiency, therefore AI based techniques are designed and presented in this paper. ANFIS is more efficient in tracking MPP with less settling time, less overshoot, less oscillations and less time taken to track MPP than ANN based Controller.","2325-9418","978-1-4673-7399-9","10.1109/INDICON.2015.7443568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7443568","Maximum power point tracking;Artificial Neural Network;Adaptive Neuro Fuzzy Inference System;Photovoltaic","Artificial neural networks;Radiation effects;Maximum power point trackers;Oscillators;Training;Voltage control;Algorithm design and analysis","","20","","10","IEEE","31 Mar 2016","","","IEEE","IEEE Conferences"
"How Artificial Intelligence and Mobile Crowd Sourcing are Inextricably Intertwined","M. Abououf; H. Otrok; R. Mizouni; S. Singh; E. Damiani","Center for Cyber-Physical Systems, Khalifa University, UAE; Center for Cyber-Physical Systems, Khalifa University, UAE; Center for Cyber-Physical Systems, Khalifa University, UAE; Center for Cyber-Physical Systems, Khalifa University, UAE; Center for Cyber-Physical Systems, Khalifa University, UAE","IEEE Network","14 Jun 2021","2021","35","3","252","258","Mobile Crowd Sourcing (MCS) has been an enabler in the development of artificial intelligence (AI) in general, and machine learning in particular. From collecting data to giving meaning to the data, there has been considerable work supporting the use of MCS in AI. While successful, current MCS solutions still suffer from limitations such as workers recruitment, data quality, trust, and so on, that can benefit a great deal from AI. However, the integration of AI in MCS is still at a nascent stage, thus opening various opportunities for further research. In this article, we review and discuss the integration of AI in MCS solutions, highlight its research challenges, and suggest means to address them. We also propose a novel architecture for AI-based MCS, where AI techniques are integrated and embedded in the different layers of MCS framework to provide efficient and trusted MCS applications. In particular, a machine learning (ML)-based selection using behaviors of individual workers is proposed, and its efficacy is gauged by analyzing a use-case study. The results show that by implementing a hybrid approach, the efficiency of selection was considerably improved. This article demonstrates a clear overview of AI-based MCS solutions and provide guidelines on applying AI to solve the current challenges and open issues.","1558-156X","","10.1109/MNET.011.2000516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261959","","Artificial intelligence;Task analysis;Data integrity;Adaptation models;Training data;Market research;Guidelines","","4","","15","IEEE","17 Nov 2020","","","IEEE","IEEE Magazines"
"Intrusion Detection Systems Based on Machine Learning Using Feature Expansion Methods","J. Myung; Y. Ko; T. Kwon; J. Lee; K. Kim; J. Song","Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea; Science and Technology Security R&D Center, Korea Institute of Science and Technology Information, Daejeon, Republic of Korea","2023 18th Asia Joint Conference on Information Security (AsiaJCIS)","29 Dec 2023","2023","","","32","38","With the development of computer networks, the amount of network traffic is explosively increasing. In addition, the importance of cyber security is being highlighted as cyber threats increase accordingly. In general, rule-based detection approaches have been used to detect cyber threats. The detection rules used in these are broadly set up to reliably detect cyber threats, resulting in too many unnecessary events. This leads to unanalyzed events, which can lead to severe security incidents. To solve this problem, recently, researches on AI-based cyber threat detection system that learns network traffic information and automatically generates detection rules are being conducted. Most of them have used complex model with sophisticated structures or feature engineering techniques so that AI models can learn as much information as possible. But, these are difficult to use in real-world security monitoring environment where quick decisions need to be made in real time, and are not suitable for that environments because they have been trained and verified through only open datasets. In this paper, we propose an AI-based cyber threat detection system that efficiently learns security event characteristics without any complicated process using tree-based model which efficient to learning tabular data. The proposed system detects cyber threats by learning security event characteristics using only information provided from security devices without complicated feature extraction process. In addition, rather than using the used information as a simple value, the value is transformed through a simple process so that the model can learn the event characteristics more effectively. Using the simplicity of the proposed method, it is expected that it can be applied to the real-world environments, and the possibility of this is demonstrated through real-world data.","2765-9712","979-8-3503-4163-8","10.1109/AsiaJCIS60284.2023.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10367904","Network Security;Intrusion Detection and Prevention;Artificial Intelligence","Telecommunication traffic;Feature extraction;Market research;Threat assessment;Data models;Real-time systems;Security","","","","19","IEEE","29 Dec 2023","","","IEEE","IEEE Conferences"
"AI Augmentation to Remote Sensing Imagery in Forestry Conservation & Restoration for Increased Responsive Capabilities","D. M. Gandikota; T. Gladkova; K. -A. Tran; S. Bapat; J. Richkus; D. J. Arnold","Artificial Intelligence Research Engineer, The MITRE Corporation, Mclean, Virginia; Mechanical and Human Factors Engineer, The MITRE Corporation, Bedford, Massachusets; Geospatial Computing Engineer, The MITRE Corporation, Mclean, Virginia; Artificial Intelligence Research Engineer, The MITRE Corporation, Bedford, Massachusets; Climate Strategist, The MITRE Corporation, Mclean, Virginia; Chief Climate & Environmental Scientist, The MITRE Corporation, Mclean, Virginia","2022 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","10 Apr 2023","2022","","","1","16","Responsive forestry management is critical to carbon management and climate change mitigation. The United Nation’s Intergovernmental Panel on Climate Change (IPCC) Special Report stated that mitigation measures in forests from 2010-2019 have delivered approximately 80% of carbon mitigation from Land Use sectors. Advancements in Remote Sensing (RS) and Artificial Intelligence (AI) technologies hold significant potential to increase the necessary coverage and speed of forestry management; however, there is a delay in the current capability integration due to technical, cost, and human-factor constraints that prevent adoption and deployment. This research details the formation of the ART3MIS-AI (Augmented Real-Time 3D Mapping with Intelligent Sensing AI) system framework, an AI-augmentation framework design that minimizes these constraints. It is tailored for responsive deployment in forestry agencies and provides long-term robustness and extensibility for all four functions of forestry management. Our research analyzes AI capabilities in forestry RS from 75 research papers and assesses the potential integration pathways of these capabilities into the post-processing infrastructures of RS within forestry management for augmented-data transformation and critical metric extraction. The ART3MIS-AI system framework optimizes these observed capabilities for additional high levels of interpretability and extensibility given the technical and sensing platform constraints of forestry agencies. We generated a set of objectives and guidelines to facilitate the responsive deployment and integration of AI-augmentation frameworks within forestry agencies. The guidelines are based on established work in Human Machine Teaming, AI-Assurance, and prior research, in addition to consultation from our forestry professional partners in United States forestry agencies. The proposed ART3MIS-AI system framework is a detailed four-phase, automated and pipelined system implemented in Python and C++. It transforms RS imagery into ""Smart"" Point Clouds with augmented hyperspectral information, vegetation classification, and structural mission metrics to an individual tree scale (canopy height/width, timber volume/fuel loading, species identification, etc.). The ART3MIS-AI system framework accelerates structured tactical data delivery to forestry professionals and provides capabilities in tailored virtual planning. The system framework design, integration analysis, and additional guidelines within this paper provide the foundations for the large-scale and methodological integration of AI-augmentation into RS forestry conservation and restoration capabilities.","2332-5615","978-1-6654-7729-1","10.1109/AIPR57179.2022.10092215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10092215","Artificial Intelligence;Machine Learning;Remote Sensing;Climate Change;Forest;Wildfire","Measurement;Point cloud compression;Climate change;Forestry;Extensibility;Real-time systems;Sensors","","1","","112","IEEE","10 Apr 2023","","","IEEE","IEEE Conferences"
"Trustworthiness of Artificial Intelligence","S. Jain; M. Luthra; S. Sharma; M. Fatima","Department of Electrical and Electronics, Engineering Amity University, Uttar Pradesh, India; Department of Electrical and Electronics, Engineering Amity University, Uttar Pradesh, India; Department of Electrical and Electronics, Engineering Amity University, Uttar Pradesh, India; Department of Electrical and Electronics, Engineering Amity University, Uttar Pradesh, India","2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)","23 Apr 2020","2020","","","907","912","This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.","2575-7288","978-1-7281-5197-7","10.1109/ICACCS48705.2020.9074237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074237","Artificial Intelligence;ethical;lawful;robust;trustworthy;fundamental rights;democracy","Artificial intelligence;Ethics;Communication systems;Technological innovation;Data privacy;Cultural differences;Robustness","","8","","8","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Delivering Health Intelligence For Healthcare Services","M. Murray; M. Macedo; C. Glynn","AI-KEN, Dublin, Ireland; Computer Science, Universidade Atlantica, Valoriza Barcarena, Portugal; Applied Social Sciences Limerick Institute of Technology, Limerick, Ireland","2019 First International Conference on Digital Data Processing (DDP)","6 Jan 2020","2019","","","88","91","The systems barrier for clinical information interoperability and standards has now evolved from a technology barrier to a semantic barrier. The processes to gather clinical data and to build clinical information and knowledge cannot be fully implemented, owing to semantic dissonances and limited data normalization. According to [1], “Just over a half of entered codes were appropriate for a given scenario and about a quarter were omitted.” This is a significant data and financial gap for healthcare provision. Huge amount of addition to the financial cost, lack of data integration and loss of information affects the ability to maintain standards in clinical care delivery and patient outcomes. This paper proposes that the solution to these issues is an augmented network of clinical note taking, where coding is automatically generated by an AI system as clinicians write their clinical notes. The system (AI-KEN) offers enhanced web support that is integrated to local clinical systems, whereby clinical notes are prompted by suggested predictive text options in real time. The anticipated benefits include reducing financial loss for acute services, support for clinical standard maintenance and enhanced advancements for clinical practice and research in real time.","","978-1-7281-5363-6","10.1109/DDP.2019.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948727","artificial-intelligence;healthcare;clinical-decision-support-system","Semantics;Maintenance engineering;Real-time systems;Encoding;Clinical diagnosis;Standards;Interoperability","","3","","8","IEEE","6 Jan 2020","","","IEEE","IEEE Conferences"
"Mamdani fuzzy logic-based smart measuring device as quality determination for grain post-harvest technology","M. S. Hadi; S. Bhima Satria Rizki; M. A. As-Shidiqi; M. A. Mizar; D. Lestari; M. Irvan","Faculty of Engineering, Universitas Negeri Malang, Malang, Indonesia; Faculty of Engineering, Universitas Negeri Malang, Malang, Indonesia; Faculty of Engineering, Universitas Negeri Malang, Malang, Indonesia; Faculty of Engineering, Universitas Negeri Malang, Malang, Indonesia; Faculty of Engineering, Universitas Negeri Malang, Malang, Indonesia; Graduate School of Information Science and Technology The University of Tokyo, Tokyo, Japan","2021 1st International Conference on Electronic and Electrical Engineering and Intelligent System (ICE3IS)","27 Dec 2021","2021","","","7","11","Agriculture is one sector that has a maj or role in the national economy, where agriculture has a contribution of 13.53 percent of GP A in Indonesia. The most widely produced agricultural products are types of grains such as corn, rice, and beans. However, the price of these commodities is often controlled by brokers, several aspects that become the benchmark for brokers to price these commodities are the quality of the seeds. The quality of rice or corn seeds is considered good if it meets a very small level of moisture content. Therefore, sometimes farmers dry their harvests for a long time without knowing the level of water content contained in their harvests so that it will hamper the distribution of crops. The solution to the problems experienced by the farmers is a device that can detect the moisture content in harvested seeds at low prices and an easy-to-use process, and is supported by an AI system that can assist farmers in making decisions about crop quality. This device works by reading the level of moisture in the grain using a humidity sensor that is plugged into the harvest container such as sacks and others. If it is felt that the moisture level is low, the device will provide suggestions to the user to support decision-making through the OLED screen installed on the device. The features make it easier for users to make decisions whether the harvest is worth selling or not.","","978-1-6654-0546-1","10.1109/ICE3IS54102.2021.9649685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649685","post-harvest technology;Mamdani fuzzy;smart device","Measurement uncertainty;Linear regression;Moisture;Crops;Humidity;Organic light emitting diodes;Mathematical models","","","","13","IEEE","27 Dec 2021","","","IEEE","IEEE Conferences"
"AI Engineering to Deploy Reliable AI in Industry","J. Mattioli; X. L. Roux; B. Braunschweig; L. Cantat; F. Tschirhart; B. Robert; R. Gelin; Y. Nicolas","Thales, France; IRT SystemX, France; IRT SystemX, France; IRT SystemX, France; IRT SystemX, France; IRT SystemX, France; IRT SystemX, France; IRT SystemX, France","2023 Fifth International Conference on Transdisciplinary AI (TransAI)","16 Jan 2024","2023","","","228","231","To bring competitive advantage to industry through a sound AI deployment, we need an end-to-end “AI systems engineering” process covering the overall lifecycle of an AI system, both at component level and at system level, regardless of whether the specifications come from regulation and reliability concerns.","","979-8-3503-5801-8","10.1109/TransAI60598.2023.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387654","AI engineering;reliability;ODD","Industries;Analytical models;Costs;Reliability engineering;Data engineering;Regulation;Data models","","","","7","IEEE","16 Jan 2024","","","IEEE","IEEE Conferences"
"SuperDriverAI: Towards Design and Implementation for End-to-End Learning-Based Autonomous Driving","S. Aoki; I. Yamamoto; D. Shiotsuka; Y. Inoue; K. Tokuhiro; K. Miwa","National Institute of Informatics, Japan; TURING, Inc., Japan; TURING, Inc., Japan; TURING, Inc., Japan; TURING, Inc., Japan; TURING, Inc., Japan","2023 IEEE Vehicular Networking Conference (VNC)","1 Jun 2023","2023","","","195","198","Fully autonomous driving has been widely studied and is becoming increasingly feasible. However, such autonomous driving has yet to be achieved on public roads, because of various uncertainties due to surrounding human drivers and pedestrians. In this paper, we present an end-to-end learning-based autonomous driving system named SuperDriver AI, where Deep Neural Networks (DNNs) learn the driving actions and policies from the experienced human drivers and determine the driving maneuvers to take while guaranteeing road safety. In addition, to improve robustness and interpretability, we present a slit model and a visual attention module. We build a data-collection system and emulator with real-world hardware, and we also test the SuperDriver AI system with real-world driving scenarios. Finally, we have collected 150 runs for one driving scenario in Tokyo, Japan, and have shown the demonstration of SuperDriver AI with the real-world vehicle.","2157-9865","979-8-3503-3549-1","10.1109/VNC57357.2023.10136277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136277","","Deep learning;Visualization;Uncertainty;Scalability;Neural networks;Robustness;Road safety","","","","13","IEEE","1 Jun 2023","","","IEEE","IEEE Conferences"
"MLoC: A Cloud Framework adopting Machine Learning for Industrial Automation","Y. -L. Huang; W. -L. Sun; K. -W. Yeh","Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2019 12th Asian Control Conference (ASCC)","18 Jul 2019","2019","","","1413","1418","By leveraging the modern machine learning algorithms, we can build up more Artificial Intelligence (AI) systems, like self-driving cars, smart factories and financial analysis systems, to improve our daily life. In addition to building up an AI system, several prerequisites are required to drive the system, including data collection, data storage, machine learning models, training dataset, parameters tuning, and so on. To obtain the benefit of scalability and flexibility, most AI systems are built on a cloud platform, which shares resources with others in the same infrastructure. Though the above concept is trivial, the implementation faces big challenges when realizing it. In this paper, an easy-to-use cloud framework for machine learning as well as its implementation guideline is presented for building up a cloud-based development platform. We conduct several experiments on analyzing and monitoring the health condition of bearings of motors. We compare and analyze the feasibility of the proposed framework.","","978-4-88898-300-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764986","","Data models;Containers;Cloud computing;Sensors;Logic gates;Machine learning algorithms;Testing","","","","9","","18 Jul 2019","","","IEEE","IEEE Conferences"
"Clean Code and Design Educational Tool","S. Prokić; K. -G. Grujić; N. Luburić; J. Slivka; A. Kovačević; D. Vidaković; G. Sladić","Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia","2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)","15 Nov 2021","2021","","","1601","1606","Many different code snippets can implement the same software feature. However, a significant subset of these possible solutions contains difficult-to-understand code that harms the software's maintainability and evolution. Such low-quality code snippets directly harm profit, as frequent and fast code change enables businesses to seize new opportunities. Unfortunately, they are also prevalent in an industry that consists mostly of junior programmers. We developed a platform called Clean CaDET to tackle the prevalence of low-quality code from two angles. The Smell Detector module presents a framework for integrating AI-based code quality assessment algorithms to identify low-quality code as the programmer is writing it. The Smart Tutor module hosts a catalog of educational content that helps the programmer understand the identified issue and suggests possible solutions. By combining the quality assessment with the educational aspect, our integrated solution presents a novel approach for increasing the quality of code produced by our industry.","2623-8764","978-953-233-101-1","10.23919/MIPRO52101.2021.9597196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597196","clean code;code smells;maintainability;readability","Industries;Training;Codes;Software design;Detectors;Tools;Writing","","","","21","","15 Nov 2021","","","IEEE","IEEE Conferences"
"Automated Brittle Fracture Rate Estimator for Steel Property Evaluation Using Deep Learning After Drop-Weight Tear Test","G. Koo; C. Shin; H. Choi; J. -H. Lee; S. W. Kim; J. P. Yun","Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; School of Electronics Engineering College of IT Engineering, Kyungpook National University, Daegu, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Technical Research Laboratories POSCO, Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; AI System Engineering Group, Korea Institute of Industrial Technology, Cheonan, South Korea","IEEE Access","14 Oct 2019","2019","7","","145095","145103","This study proposes an automated brittle fracture rate (BFR) estimator using deep learning. As the demand for line-pipes increases in various industries, the need for BFR estimation through drop-weight tear test (DWTT) increases to evaluate steel's property. Conventional BFR or ductile fracture rate (DFR) estimation methods require an expensive 3D scanner. Alternatively, a rule-based approach is used with a single charge-coupled device (CCD) camera. However, it is sensitive to the hyper-parameter. To solve these problems, we propose an approach based on deep learning that has recently been successful in the fields of computer vision and image processing. The method proposed in this study is the first to use deep learning approach for BFR estimation. The proposed method consists of a VGG-based U-Net (VU-Net) which is inspired by U-Net and fully convolutional network (FCN). VU-Net includes a deep encoder and a decoder. The encoder is adopted from VGG19 and transferred with a pre-trained model with ImageNet. In addition, the structure of the decoder is the same as that of the encoder, and the decoder uses the feature maps of the encoder through concatenation operation to compensate for the reduced spatial information. To analyze the proposed VU-Net, we experimented with different depths of networks and various transfer learning approaches. In terms of accuracy used in real industrial application, we compared the proposed VU-Net with U-Net and FCN to evaluate the performance. The experiments showed that VU-Net was the accuracy of approximately 94.9 %, and was better than the other two, which had the accuracies of about 91.8 % and 93.7 %, respectively.","2169-3536","","10.1109/ACCESS.2019.2945563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859257","Computer vision;DWTT;industrial application;semantic segmentation;steel industry;transfer learning","Discrete wavelet transforms;Deep learning;Decoding;Estimation;Steel;Semantics;Feature extraction","","3","","31","CCBY","4 Oct 2019","","","IEEE","IEEE Journals"
"Interpreting AI for Networking: Where We Are and Where We Are Going","T. Zhang; H. Qiu; M. Mellia; Y. Li; H. Li; K. Xu","Nokia Bell Labs, France; Tsinghua University, China; Politecnico di Torino, Italy; Tsinghua University, China; Tsinghua University, China; Tsinghua University, China","IEEE Communications Magazine","28 Feb 2022","2022","60","2","25","31","In recent years, artificial intelligence (AI) techniques have been increasingly adopted to tackle networking problems. Although AI algorithms can deliver high-quality solutions, most of them are inherently intricate and erratic for human cognition. This lack of interpretability tremendously hinders the commercial success of AI-based solutions in practice. To cope with this challenge, networking researchers are starting to explore explainable AI (XAI) techniques to make AI models interpretable, manageable, and trustworthy. In this article, we overview the application of AI in networking and discuss the necessity for interpretability. Next, we review the current research on interpreting AI-based networking solutions and systems. At last, we envision future challenges and directions. The ultimate goal of this article is to present a general guideline for AI and networking practitioners and motivate the continuous advancement of AI-based solutions in modern communication networks.","1558-1896","","10.1109/MCOM.001.2100736","Natural Science Foundation of China(grant numbers:62106127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9722797","","Cognition;Communication networks;Artificial intelligence;Telecommunication network management","","6","","15","IEEE","28 Feb 2022","","","IEEE","IEEE Magazines"
"Towards Training Reproducible Deep Learning Models","B. Chen; M. Wen; Y. Shi; D. Lin; G. K. Rajbahadur; Z. M. Jiang","Centre for Software Excellence, Huawei Canada, Kingston, Canada; Huawei Technologies, Shenzhen, China; Huawei Technologies, Shenzhen, China; Centre for Software Excellence, Huawei Canada, Kingston, Canada; Centre for Software Excellence, Huawei Canada, Kingston, Canada; York University, Toronto, Canada","2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)","20 Jun 2022","2022","","","2202","2214","Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794033","Artificial Intelligence;Deep Learning;Software Engineering;Reproducibility","Training;Deep learning;Systematics;Reproducibility of results;Software;Hardware;Artificial intelligence","","3","","69","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Prediction of MEMS-based INS Error Using Interval Type-2 Fuzzy Logic System in INS/GPS Integration","H. Hamidi; E. S. Abdolkarimi; M. R. Mosavi","Department of Electrical Engineering, Iran University of Science and Technology, Theran, Iran; Department of Electrical Engineering, Iran University of Science and Technology, Theran, Iran; Department of Electrical Engineering, Iran University of Science and Technology, Theran, Iran","2020 25th International Computer Conference, Computer Society of Iran (CSICC)","30 Mar 2020","2020","","","1","5","In recent years, for reliable, accurate, and robust navigation, Global Positioning System (GPS) and Inertial Navigation System (INS) has been integrated to use their complementary advantages and overcome their drawbacks. Kalman Filtering methods such as Extended Kalman Filter (EKF) have been used for INS/GPS integration widely. The EKF-based navigation systems are complex, and they might not have effective real-time performance, especially with the MicroElectro Mechanical System (MEMS)-based INS when GPS is blocked. To overcome these problems, Artificial Intelligence (AI) based integration was proposed over the Kalman filtering models. Due to the stochastic noise, bias, and drift of the low-cost MEMS-based inertial sensor outputs over time, in this study, we propose an Interval Type-2 Fuzzy Logic System (IT2FLS) to predict the MEMS-based sensor errors in GPS blockage. The IT2FLS can model uncertainty and stochastic noise of both input and training data in complex, noisy environments such as our application. Therefore, we use the IT2FLS to forecast the cumulative INS error during GPS outages to improve the accuracy of the navigation system. The experimental tests show that the IT2FLS has acceptable realtime performance and accuracy in predicting the INS error during the long-term GPS outages.","","978-1-7281-5937-9","10.1109/CSICC49403.2020.9050081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050081","GPS;INS;Integration;EKF;AI;IT2FLS","Fuzzy logic;Uncertainty;Filtering;Stochastic processes;Training data;Real-time systems;Kalman filters","","3","","26","IEEE","30 Mar 2020","","","IEEE","IEEE Conferences"
"Use of Expert System in Requirements Engineering Process A Systematic Literature Review","B. Haq; M. Nadeem; I. Ali; K. Ali; M. Raza; M. U. Rehmanr","BUITEMS, Quetta, Pakistan; BUITEMS, Quetta, Pakistan; BUITEMS, Quetta, Pakistan; Middlesex University London, London, UK; Middlesex University London, London, UK; University of Glasgow, Glasgow, UK","2019 UK/ China Emerging Technologies (UCET)","24 Oct 2019","2019","","","1","5","Requirements Engineering (RE) process deals with elicitation, analysis, negotiation, validation, management, and documentation of requirements. Several artificial intelligence (AI) based approaches have been proposed to automate RE activities. However, the requirements engineering community still lacks a comprehensive understanding on how expert system are used in RE process. The objectives of this study are (1) to explore the different AI approaches which are employed in requirements engineering, (2) to identify the main phases addressed by these approaches, (3) to identify AI tools that used in RE process, and (4) we tried to find the contributions and the benefits of applying expert system in RE. We found that expert system can partially facilitate the RE process, however no expert system can fully automate the RE process.","","978-1-7281-2797-2","10.1109/UCET.2019.8881880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8881880","Artificial Intelligence;Knowledge Based Systems;Expert Systems;Ontology;Requirements Engineering","Tools;Requirements engineering;Expert systems;Ontologies;Documentation;Linguistics","","2","","23","IEEE","24 Oct 2019","","","IEEE","IEEE Conferences"
"Adaptive Fuzzy-PI Control of Wind Energy Conversion System Based DFIG Under Voltage Dip","I. Kharchouf; T. Nasser; A. Essadki; M. Fdaili","Research Center in Sciences and Technologies of Engineering and Health (STIS), Higher Normal School of Technical Education (ENSET), Rabat, Morocco; Research Center in Sciences and Technologies of Engineering and Health (STIS), Higher National School of Computer Science and Systems Analysis (ENSIAS), Rabat, Morocco; Research Center in Sciences and Technologies of Engineering and Health (STIS), Higher Normal School of Technical Education (ENSET), Rabat, Morocco; Research Center in Sciences and Technologies of Engineering and Health (STIS), Higher Normal School of Technical Education (ENSET), Rabat, Morocco","2020 International Conference on Electrical and Information Technologies (ICEIT)","10 Jun 2020","2020","","","1","6","The Proportional-Integral (PI) and Fuzzy Logic Controllers (FLC) cannot deal accurately with the system variation. To overcome the drawbacks of PI and FLC regulators, the Adaptive Fuzzy-PI Controllers (AFPICs) are configured. This paper presents a comparison between three different controllers based control methodology for Variable Speed Wind Energy Conversion Systems (WECSs) by means of Doubly Fed Induction Generator (DFIG). Artificial Intelligence (AI) based FLCs is performed to improve the system efficiency and performance under Small Disturbance (SD) and Large Disturbance (LD) cases. To test the PI, FLC, and AFPIC robustness, simulations are done during abrupt wind speed variation (SD), and voltage dip fault (LD). The simulation results show that the proposed AFPIC delivers improved power control, better response rise time, reduced overshoot, undershoot, and settling time compared to classical PI and Fuzzy controllers. The proposed control is proved by simulation using Matlab/Simulink-R2016b.","","978-1-7281-4341-5","10.1109/ICEIT48248.2020.9113215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113215","Wind Energy Conversion System (WECS);Proportional and Integral (PI) controller;Fuzzy Logic Controller (FLC);Adaptive Fuzzy-PI Controller (AFPIC);Rotor Side Converter (RSC);Grid Side Converter (GSC);Voltage Dip (VD)","Voltage fluctuations;Regulators;Wind speed;Simulation;Doubly fed induction generators;Robustness;Time factors","","2","","10","IEEE","10 Jun 2020","","","IEEE","IEEE Conferences"
"Speed control of Induction Motor via Fuzzy Proportional Integral (FPI) controller","M. Asad; M. Arif; U. Khan","COMSATS institute of information technology, Abbottabad; COMSATS institute of information technology, Abbottabad; COMSATS institute of information technology, Abbottabad","2016 International Conference on Computing, Electronic and Electrical Engineering (ICE Cube)","23 Jun 2016","2016","","","186","189","The Induction Motor (IM) control in industrial drives is widely acknowledged for robustness and low maintenance. The vector control technique is mostly used for the speed control of IM. The hybrid control e.g. Fuzzy with classic PI control provide adequate response with load variations of motor. Speed control is a challenging task as IM is characterized by its nonlinear dynamics. In case of complex systems, the traditional control theory fails. To address the aforesaid problem, artificial intelligence (AI) based control systems are proposed. Moreover Fuzzy control is one of such options to provide an alternative to past conventional control methodology for dealing with complex systems. This paper presents the Fuzzy Proportional Integral (FPI) control scheme designed for speed the control of IM.","","978-1-5090-1252-7","10.1109/ICECUBE.2016.7495220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7495220","Artificial Intelligence;Fuzzy Control;Induction Motors (IM);Vector Control;MATLAB Simulink","Induction motors;Rotors;Niobium;Torque;Stator windings;Velocity control","","","","10","IEEE","23 Jun 2016","","","IEEE","IEEE Conferences"
"Detection of Malicious Domains in the Cyberspace using Machine Learning & Deep Learning: A Survey","S. L; V. K; M. P. M. Y","Department of Computer and Information Science, Annamalai University, Tamil Nadu, India; Department of Computer and Information Science, Annamalai University, Tamil Nadu, India; Department of Computer and Information Science, Annamalai University, Tamil Nadu, India","2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART)","24 Feb 2023","2022","","","1540","1543","People have daily access to a wide range of services through the World Wide Web, which serves as a platform for global information exchange. Businesses uses web as a low-cost communication channel for their business promotion and communications. As a result, millions of domains are created and registered every day. This immense development allows cyber criminals to play as well. Cybercriminals use a variety of methods to exploit the web security. Recent cyber security reports states that security breaches are 17% higher in 2021 than in 2020. Cybercriminals use URLs (domain name) as an easy tool to carry out malicious activities. Through email, SMS, and social media sites like Face book and Twitter, malicious URLs are disseminated. As soon as victims click on the URL, fraudsters will steal their personal data or place malware on their computer to get access to other systems. It is very important to detect such malicious domain names in advance using AI based techniques. Researchers have proposed several methods to classify malicious domain names and malicious domain names. Recently they preferred to use machine learning and deep learning techniques for automated classification. This paper presents a recent research work in this field and research issues. This will serve as source of new research in this domain.","2767-7362","978-1-6654-8734-4","10.1109/SMART55829.2022.10047254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10047254","Malicious URL;Domain names;Machine Learning;Deep Learning;CNN;RNN;Cyber Security;Web Security","Deep learning;Uniform resource locators;Social networking (online);Cyberspace;Market research;Malware;Security","","","","17","IEEE","24 Feb 2023","","","IEEE","IEEE Conferences"
"Decision Making Algorithm for Blind Navigation Assistance using Deep Learning","Z. B. S; H. K. P; H. S; L. S. J","Dept. of Computer Science and Engineering, VSB Engineering College, Karudayampalayam, Karur, Tamil Nadu, India; II Year, Dept. of Artificial Intelligence and Data Science, VSB Engineering College, Karudayampalayam, Karur, Tamil Nadu, India; II Year, Dept. of Artificial Intelligence and Data Science, VSB Engineering College, Karudayampalayam, Karur, Tamil Nadu, India; II Year, Dept. of Artificial Intelligence and Data Science, VSB Engineering College, Karudayampalayam, Karur, Tamil Nadu, India","2022 1st International Conference on Computational Science and Technology (ICCST)","14 Feb 2023","2022","","","268","272","Blind people face several obstacles in their daily lives and technological interventions can help overcome these obstacles. In this research, we provide an AI-based autonomous assisting device that recognizes many objects and it will provide acoustic input to the user to help visually blind people to understand the surrounding better to understand their environment better. Multiple photos of objects relevant to visually impaired people were used to build a deep-learning model. Training photos are enhanced and manually annotated to improve the trained model's resilience. A distance-measuring sensor is included which recognise the objects using computer vision. The gadget is made more inclusive by recognizing the obstacles coming out of one place to another. After stage segmentation and obstacle detection, the aural information sent to the user is adj usted to get a lot of details in minimum time and speed up video processing.","","978-1-6654-7655-3","10.1109/ICCST55948.2022.10040269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10040269","Deep learning model;Image processing;Speech recognition;RCNN;Image recognition;Voice output","Deep learning;Training;Navigation;Scientific computing;Computational modeling;Blindness;Libraries","","","","18","IEEE","14 Feb 2023","","","IEEE","IEEE Conferences"
"Residential Energy Management System Using Fuzzy Logic","S. Shinkhede; S. Mujumdar; S. Shah","Electrical Engg. Dept, The Maharaja Sayajirao University of Baroda, Vadodara, India; CivilEngg. Dept, The Maharaja Sayajirao University of Baroda, Vadodara, India; Department of Climate Change, Govt. of Gujarat","2023 IEEE 8th International Conference for Convergence in Technology (I2CT)","23 May 2023","2023","","","1","4","Electricity demand is a crucial indicator of a country's economic growth, but a change in environmental factors significantly impacts this factor. India has set a target of 500 GW of renewable energy by 2030 as part of its climate mitigation efforts at the COP-26 Summit in Glasgow to minimize electricity demand. In India, electrical energy is generated from thermal, hydro, nuclear, and renewable sources. There are various measures taken for energy conservation by industries. Due to technological development, advanced power generation technologies, and a rise in per capita income, there is a rise in residential energy consumption too. Energy conservation in the residential sector is a challenge. It needs social awareness. This paper contains an AI based fuzzy model that gives low, moderate, and high levels of residential energy consumption. That helps the consumer understand the level of energy they are using, and the cost of energy can be reduced by optimizing the energy consumption.","","979-8-3503-3401-2","10.1109/I2CT57861.2023.10126420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126420","Energy Demand;Economic Status;Demand Response;Fuzzy logic;Linguistic Variables","Industries;Fuzzy logic;Energy consumption;Renewable energy sources;Climate change;Costs;Energy measurement","","","","7","IEEE","23 May 2023","","","IEEE","IEEE Conferences"
"Learning-Based Diagnostics for Fault Detection and Isolation in Linear Stochastic Systems","E. Noorani; C. Somarakis; R. Goyal; A. Feldman; S. Rane","Palo Alto Research Center - A Xerox Company, Palo Alto, CA, USA; Palo Alto Research Center - A Xerox Company, Palo Alto, CA, USA; Palo Alto Research Center - A Xerox Company, Palo Alto, CA, USA; Palo Alto Research Center - A Xerox Company, Palo Alto, CA, USA; Palo Alto Research Center - A Xerox Company, Palo Alto, CA, USA","2022 30th Mediterranean Conference on Control and Automation (MED)","1 Aug 2022","2022","","","761","766","AI-enabled mechanisms are deployed to guard controlled systems against sensor anomalies. We explore a two-level architecture design in which a low-level feedback controller of a linear system uses measurements from one or more potentially unreliable sensors. These observations are prone both to sensor noise but unknown additive faults. Our proposed, high-level, guard mechanism consists of a Reinforcement Learning (RL) agent that monitors available vitals of the system. In the event of a fault on the sensor components, the RL agent automatically detects, estimates the fault, localizes and takes action to cancel the fault. In addition, we develop design methodologies for efficient training of the RL agent that take advantage of system dynamics and sensor fusion schemes. We show that the associated training cost functions can be designed so that their optimal policy achieves efficient of arbitrary constant or piece-wise constant sensor faults. To illustrate our theoretical results, we consider a linearized version of a chemical process with multiple sensors, controlled by a Linear Quadratic Gaussian (LQG) Servo-Controller with Integral Action. Our simulations show that the RL-agent is successful in localizing the faulty sensors and mitigating the effects of faults in an online fashion.","2473-3504","978-1-6654-0673-4","10.1109/MED54222.2022.9837165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837165","","Training;Linear systems;System dynamics;Stochastic systems;Fault detection;Design methodology;Reinforcement learning","","","","17","IEEE","1 Aug 2022","","","IEEE","IEEE Conferences"
"The impact of Artificial Intelligence, Blockchain, Big Data and evolving technologies in Coronavirus Disease - 2019 (COVID-19) curtailment","S. Ahir; D. Telavane; R. Thomas","Vivekanand Education Society’s Institute of Technology, Mumbai, India; EbixCash Financial Technologies, Mumbai, India; Vivekanand Education Society’s Institute of Technology, Mumbai, India","2020 International Conference on Smart Electronics and Communication (ICOSEC)","7 Oct 2020","2020","","","113","120","The pandemic of Coronavirus Disease 2019 (COVID-19) is proliferating across the globe obnoxiously and it is the most heard buzzword in recent times. Every person ranging from older people, persons with disabilities, youth, indigenous people have become a part of this chain and are most likely to suffer in the upcoming chronology. Social distancing is likely to become a new norm where “Work from Home”, Online Lectures” and “Meetings” ensue on social media applications. Technology has always lent a helping hand for mankind's problems. The idea focuses on highlighting the advancements in technology in the midst of a bizarre situation. Deep Learning applications to detect the symptoms of COVID-19, AI based robots to maintain social distancing, Blockchain technology to maintain patient records, Mathematical modeling to predict and assess the situation and Big Data to trace the spread of the virus and other technologies. These technologies have immensely contributed to curtailing this pandemic. Strong will power, patience and optimistic guidelines catered by the respective government are some of the altercations to COVID-19.","","978-1-7281-5461-9","10.1109/ICOSEC49089.2020.9215294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9215294","COVID-19;coronavirus;Society;Social Distancing;Technology;Guidelines;Precautions;Diseases;Machine Learning;Deep Learning;Blockchain;Artificial Intelligence;Robotics;Big Data","Diseases;Hospitals;Machine learning;Lung;Viruses (medical);Vaccines","","24","","16","IEEE","7 Oct 2020","","","IEEE","IEEE Conferences"
"Artificial Intelligence Based Early Diagnosis of Sepsis","A. Kareem; R. B. Sulaiman; S. Vaseem Akram; M. Maurya; I. S. Chakrapani; P. Sasikala","School of Computer Science and Technology, University of Bedfordshire, Luton, United Kingdom; School of Computer Science and Technology, University of Bedfordshire, Luton, United Kingdom; Uttaranchal Institute of Technology, Uttaranchal University; Department of Public Health Dentistry, JSS Dental College & Hospital, JSSAHER, Mysuru; Department of Zoology, PRR&VS Govt College, Vidavalur, AP; Costume Design and Fashion, Kongunadu Arts and Science College, Coimbatore, Tamilnadu","2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)","24 Jul 2023","2023","","","1557","1562","Sepsis is a major killer of those who are already in a serious condition. The morbidity and death rates in this field remain high, despite the fact that medical technology has been advancing steadily over the last several years. This is due mostly to people not beginning therapy quickly enough and doctors not following best practices. Medical decision support solutions have advanced greatly with the help of artificial intelligence (AI), a rapidly developing sector in the medical industry. Great promise has been shown in its ability to anticipate patients' clinical conditions and aid clinical decision-making. Early prediction, prognosis evaluation, mortality prediction, and optimum treatment are just few of the areas where algorithms developed using artificial intelligence may be put to use. This article summarizes the most recent research on AI based clinical decision support in sepsis as well as explains how this cutting-edge technology might aid in sepsis prediction, identification, sub phenotyping, prognostic evaluation, and clinical treatment. We also spoke about the difficulties of using this non-conventional approach in clinical practice.","","979-8-3503-9926-4","10.1109/ICACITE57410.2023.10182599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10182599","Sepsis;Artificial Intelligence;Machine Learning;Disease Prediction using AI.","Industries;Fluids;Decision making;Medical services;Sepsis;Safety;Artificial intelligence","","","","23","IEEE","24 Jul 2023","","","IEEE","IEEE Conferences"
"ECCOLA - a Method for Implementing Ethically Aligned AI Systems","V. Vakkuri; K. -K. Kemell; P. Abrahamsson","Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland","2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","16 Oct 2020","2020","","","195","204","Various recent Artificial Intelligence (AI) system failures, some of which have made the global headlines, have highlighted issues in these systems. These failures have resulted in calls for more ethical AI systems that better take into account their effects on various stakeholders. However, implementing AI ethics into practice is still an on-going challenge. High-level guidelines for doing so exist, devised by governments and private organizations alike, but lack practicality for developers. To address this issue, in this paper, we present a method for implementing AI ethics. The method, ECCOLA, has been iteratively developed using a cyclical action design research approach. The method aims at making the high-level AI ethics principles more practical, making it possible for developers to more easily implement them in practice.","","978-1-7281-9532-2","10.1109/SEAA51224.2020.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226275","Artificial Intelligence;AI ethics;Ethics;implementing;method","Artificial intelligence;Ethics;Guidelines;Software engineering;Tools;Kernel;Standards organizations","","8","","19","IEEE","16 Oct 2020","","","IEEE","IEEE Conferences"
"Distributed and Democratized Learning: Philosophy and Research Challenges","M. N. H. Nguyen; S. R. Pandey; K. Thar; N. H. Tran; M. Chen; W. Saad Bradley; C. S. Hong","Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Kyung Hee University, South Korea; Kyung Hee University, South Korea; The University of Sydney, Australia; Princeton University, USA; Virginia Tech, USA; Kyung Hee University, South Korea","IEEE Computational Intelligence Magazine","13 Jan 2021","2021","16","1","49","62","Due to the availability of huge amounts of data and processing abilities, current artificial intelligence (AI) systems are effective in solving complex tasks. However, despite the success of AI in different areas, the problem of designing AI systems that can truly mimic human cognitive capabilities such as artificial general intelligence, remains largely open. Consequently, many emerging cross-device AI applications will require a transition from traditional centralized learning systems towards large-scale distributed AI systems that can collaboratively perform multiple complex learning tasks. In this paper, we propose a novel design philosophy called democratized learning (Dem-AI) whose goal is to build large-scale distributed learning systems that rely on the self-organization of distributed learning agents that are wellconnected, but limited in learning capabilities. Correspondingly, inspired by the societal groups of humans, the specialized groups of learning agents in the proposed Dem-AI system are selforganized in a hierarchical structure to collectively perform learning tasks more efficiently. As such, the Dem-AI learning system can evolve and regulate itself based on the underlying duality of two processes which we call specialized and generalized processes. In this regard, we present a reference design as a guideline to realize future Dem-AI systems, inspired by various interdisciplinary fields. Accordingly, we introduce four underlying mechanisms in the design such as plasticity-stability transition mechanism, self-organizing hierarchical structuring, specialized learning, and generalization. Finally, we establish possible extensions and new challenges for the existing learning approaches to provide better scalable, flexible, and more powerful learning systems with the new setting of Dem-AI.","1556-6048","","10.1109/MCI.2020.3039068","National Research Foundation of Korea(grant numbers:2020R1A4A1018607); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321418","","Learning systems;Task analysis;Guidelines;Artificial intelligence","","8","","49","IEEE","13 Jan 2021","","","IEEE","IEEE Magazines"
"An Explainable Artificial Intelligence (xAI) Framework for Improving Trust in Automated ATM Tools","C. S. Hernandez; S. Ayo; D. Panagiotakopoulos","School of Aerospace, Transport and Manufacturing, Cranfield University, U.K; School of Aerospace, Transport and Manufacturing, Cranfield University, U.K; School of Aerospace, Transport and Manufacturing, Cranfield University, U.K","2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)","15 Nov 2021","2021","","","1","10","With the increased use of intelligent Decision Support Tools in Air Traffic Management (ATM) and inclusion of non-traditional entities, regulators and end users need assurance that new technologies such as Artificial Intelligence (AI) and Machine Learning (ML) are trustworthy and safe. Although there is a wide amount of research on the technologies themselves, there seem to be a gap between research projects and practical implementation due to different regulatory and practical challenges including the need for transparency and explainability of solutions. In order to help address these challenges, a novel framework to enable trust on AI-based automated solutions is presented based on current guidelines and end user feedback. Finally, recommendations are provided to bridge the gap between research and implementation of AI and ML-based solutions using our framework as a mechanism to aid advances of AI technology within ATM.","2155-7209","978-1-6654-3420-1","10.1109/DASC52595.2021.9594341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594341","Air Traffic Management;Artificial Intelligence;Machine Learning;Trust Framework","Regulators;Machine learning;Tools;Aerospace electronics;Air traffic control;Guidelines","","3","","75","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"The Two Faces of AI in Green Mobile Computing: A Literature Review","W. Siemers; J. Sallou; L. Cruz","Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands","2023 49th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","1 Jan 2024","2023","","","301","309","Artificial intelligence is bringing ever new functionalities to the realm of mobile devices that are now considered essential (e.g., camera and voice assistants, recommender systems). Yet, operating artificial intelligence takes up a substantial amount of energy. However, artificial intelligence is also being used to enable more energy-efficient solutions for mobile systems. Hence, artificial intelligence has two faces in that regard, it is both a key enabler of desired (efficient) mobile functionalities and a major power draw on these devices, playing a part in both the solution and the problem. In this paper, we present a review of the literature of the past decade on the usage of artificial intelligence within the realm of green mobile computing. From the analysis of 34 papers, we highlight the emerging patterns and map the field into 13 main topics that are summarized in details.Our results showcase that the field is slowly increasing in the past years, more specifically, since 2019. Regarding the double impact AI has on the mobile energy consumption, the energy consumption of AI-based mobile systems is under-studied in comparison to the usage of AI for energy-efficient mobile computing, and we argue for more exploratory studies in that direction. We observe that although most studies are framed as solution papers (94%), the large majority do not make those solutions publicly available to the community. Moreover, we also show that most contributions are purely academic (28 out of 34 papers) and that we need to promote the involvement of the mobile software industry in this field.","2376-9521","979-8-3503-4235-2","10.1109/SEAA60479.2023.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10371497","mobile software;energy consumption;artificial intelligence","Industries;Energy consumption;Mobile handsets;Energy efficiency;Software;Stakeholders;Artificial intelligence","","","","61","IEEE","1 Jan 2024","","","IEEE","IEEE Conferences"
"AI Ethics in Smart Healthcare","S. Pasricha","Colorado State University, Fort Collins, CO, USA","IEEE Consumer Electronics Magazine","6 Jun 2023","2023","12","4","12","20","This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.","2162-2256","","10.1109/MCE.2022.3220001","National Science Foundation(grant numbers:CNS-2132385); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940606","","Artificial intelligence;Ethics;Medical services;Medical diagnostic imaging;Consumer electronics;Behavioral sciences;Safety","","","","38","IEEE","7 Nov 2022","","","IEEE","IEEE Magazines"
"Development of Artificial Intelligence for Variable Rate Application Based Oil Palm Fertilization Recommendation System","E. Firmansyah; B. Pardamean; C. Ginting; H. G. Mawandha; D. Pratama Putra; T. Suparyanto","Faculty of Agriculture, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Faculty of Agriculture, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Faculty of Agriculture, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Faculty of Agriculture, Institute of Agriculture STIPER, Yogyakarta, Indonesia; Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia","2021 International Conference on Information Management and Technology (ICIMTech)","14 Sep 2021","2021","1","","6","11","The need for fertilization knowledge that meets good cultivation principles is the background for the need for a platform that can help provide advice on fertilization implementation. The conventional method through leaf and soil analysis to determine the dose of fertilization has many obstacles in its implementation. The availability of experts to provide advice is also not available at all times. One way to transfer knowledge to non-experts is to use Artificial Intelligence (AI) in the form of a dynamic expert system. The purpose of this research is to create a dynamic expert system that can provide advice and apply fertilization quickly, cheaply, accurately, and available at all times. In building this AI system, a knowledge base, working memory, inference engine, and interface are needed. The implementation of dynamic expert system development consists of four stages, namely (1) literature study, (2) laboratory analysis, (3) construction of an inference engine, and (4) interface creation. Based on the literature study that has been carried out, it is known that there are three domains of knowledge of oil palm fertilization, namely the domain of soil, plants and climate. Each of these knowledge domains consists of attributes, sub-attributes, and facts of knowledge which are then arranged in the form of mathematical rules. The relationship between the three knowledge domains is used as the basis for making fertilization rules. The result of this research is an application with Artificial Intelligence to provide information on nutritional needs according to plant age, population, production, land area and location. The application provides recommendations for the type, frequency, amount of fertilizer, and time of application.","","978-1-6654-4937-3","10.1109/ICIMTech53080.2021.9535082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535082","artificial intelligence;oil palm;fertilization;VRA","Time-frequency analysis;Oils;Soil;Artificial intelligence;Expert systems;Statistics;Engines","","6","","30","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"AI Loyalty: A New Paradigm for Aligning Stakeholder Interests","A. Aguirre; G. Dempsey; H. Surden; P. B. Reiner","Future of Life Institute, University of California at Santa Cruz, Santa Cruz, USA; 7th Future, Santa Barbara, USA; Law School, University of Colorado at Boulder, Boulder, USA; Department of Psychiatry, University of British Columbia, Vancouver, Canada","IEEE Transactions on Technology and Society","10 Sep 2020","2020","1","3","128","137","When we consult a doctor, lawyer, or financial advisor, we assume that they are acting in our best interests. But what should we assume when we interact with an artificial intelligence (AI) system? AI-driven personal assistants, such as Alexa and Siri, already serve as interfaces between consumers and information on the Web, and users routinely rely upon these and similar systems to take automated actions or provide information. Superficially, they may appear to be acting according to user interests, but many are designed with embedded conflicts of interests. To address this problem, we introduce the concept of AI loyalty. AI systems are loyal to the degree that they minimize and make transparent, conflicts of interest, and act in ways that prioritize the interests of users. Loyal AI products hold obvious appeal for the end-user and could promote the alignment of the long-term interests of AI developers and customers. To this end, we suggest criteria for assessing whether an AI system is acting in a manner that is loyal to the user, and argue that AI loyalty should be deliberately considered during the technological design process alongside other important values in AI ethics, such as fairness, accountability privacy, and equity.","2637-6415","","10.1109/TTS.2020.3013490","Social Science and Humanities Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157977","Artificial intelligence (AI) assistant;AI ethics;conflict of interest;fiduciary duty;loyalty;value alignment","Artificial intelligence;Ethics;Task analysis;Law;Privacy","","3","","58","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"Running Pace Adjustment and Training Distance Fitting with Fuzzy Logic and Machine Learning","A. Dziomdziora; D. Taibi","Lodz University of Technology Institute of Information Technology, Lodz, Poland; Tampere University, Tampere, Finland","2022 21st International Symposium on Communications and Information Technologies (ISCIT)","8 Nov 2022","2022","","","189","194","A sedentary lifestyle and lack of sports favor the occurrence of many civilization diseases. To address the problem, the UN set 17 Sustainable Development Goals to be achieved glob-ally by 2030. They assume an enduring improvement in the life quality of present and future generations. One of the UN objects is “Goal 3: Good health and well-being”, focusing on ensuring a healthy life for all people and promoting well-being. An active lifestyle improves health by reducing the number and frequency of illnesses. This paper aims to develop an Artificial Intelligence (AI) system to provide training recommendations and evaluate decision-making algorithms for running pace adjustment and training distance fitting based on fuzzy logic. The data collected from running sessions enabled the construction of an AI system based on the data from the sports watch and personal feelings from the athlete regarding his emotions during each kilometer of the run. Comparing the system indications with information from the user due to fuzzy inference allowed a runner to increase endurance. Hence, using the provided recommendations, training can be intensified and training sensations - maintained.","2643-6175","978-1-6654-9851-7","10.1109/ISCIT55906.2022.9931228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931228","fuzzy logic in running knowledge-based systems;machine learning in sports activity;artificial intelligence;recom-mendation system","Training;Fuzzy logic;Fitting;Sociology;Knowledge based systems;Training data;Sustainable development","","","","14","IEEE","8 Nov 2022","","","IEEE","IEEE Conferences"
"Semi-Automatic Validation and Verification Framework for CV&AI-Enhanced Railway Signaling and Landmark Detector","M. Labayen; X. Mendialdua; N. Aginako; B. Sierra","Autonomous Vehicle Department, CAF Signalling, Donostia, Spain; Dependable Embedded Systems, Ikerlan Technology Research Centre, Basque Research and Technology Alliance, Arrasate, Spain; Computer Sciences and Artificial Intelligence Department, University of Basque Country, Donostia, Spain; Computer Sciences and Artificial Intelligence Department, University of Basque Country, Donostia, Spain","IEEE Transactions on Instrumentation and Measurement","27 Jun 2023","2023","72","","1","13","The automation of railway operations is an activity in constant growth. Different railway stakeholders are already developing their research activities for the future driverless autonomous driving based on computer vision (CV) and artificial intelligence (AI)-enhanced perception technologies (e.g., obstacle detection). Unfortunately, the AI models are opaque in nature, and there are no certification accepted rules for CV&AI-enhanced functionality certification. Capturing and labeling camera image in real environment is expensive in terms of time and resources and it does not guarantee enough variation in edge visibility conditions, which makes the resulting database less valuable for the validation and verification (V&V) processes. To meet the increasing needs of trusted CV&AI-based solutions, numerous V&V approaches have been proposed in other sectors such as automotive, most of them based on virtual simulators. Unfortunately, there is currently no virtual perception simulator for railway scenario. This work aims to create a semi-automatic system based on virtual scenarios measuring the CV&AI-enhanced system performance facing different visibility conditions. It will be based on the global accuracy metrics and detected potential safety and operation rules’ violations. This work also demonstrates the quantitative and qualitative improvements while reducing current V&V cost.","1557-9662","","10.1109/TIM.2023.3284928","Electronic Components and Systems for European Leadership (ECSEL); Industrial Leadership [Information and Communication Technology (ICT)] Programs(grant numbers:876852); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10151685","Artificial intelligence (AI);autonomous train;certification;perception system;validation;verification","Rail transportation;Testing;Safety;Video games;Certification;Artificial intelligence;Virtual environments","","","","44","IEEE","13 Jun 2023","","","IEEE","IEEE Journals"
"Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack","N. Wang; Y. Luo; T. Sato; K. Xu; Q. A. Chen","University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine","2023 IEEE/CVF International Conference on Computer Vision (ICCV)","15 Jan 2024","2023","","","4389","4400","In autonomous driving (AD), accurate perception is indispensable to achieving safe and secure driving. Due to its safety-criticality, the security of AD perception has been widely studied. Among different attacks on AD perception, the physical adversarial object evasion attacks are especially severe. However, we find that all existing literature only evaluates their attack effect at the targeted AI component level but not at the system level, i.e., with the entire system semantics and context such as the full AD pipeline. Thereby, this raises a critical research question: can these existing researches effectively achieve system-level attack effects (e.g., traffic rule violations) in the real-world AD context? In this work, we conduct the first measurement study on whether and how effectively the existing designs can lead to system-level effects, especially for the STOP sign-evasion attacks due to their popularity and severity. Our evaluation results show that all the representative prior works cannot achieve any system-level effects. We observe two design limitations in the prior works: 1) physical model-inconsistent object size distribution in pixel sampling and 2) lack of vehicle plant model and AD system model consideration. Then, we propose SysAdv, a novel system-driven attack design in the AD context and our evaluation results show that the system-level effects can be significantly improved, i.e., the violation rate increases by around 70%.","2380-7504","979-8-3503-0718-4","10.1109/ICCV51070.2023.00407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10376538","","Computer vision;Analytical models;Computational modeling;Semantics;Pipelines;Security;Artificial intelligence","","","","74","IEEE","15 Jan 2024","","","IEEE","IEEE Conferences"
"We Are Not Pontius Pilate: Acknowledging Ethics and Policy","J. A. Hughes; W. Hannah; P. Kikkert; B. MacKenzie; W. Ashlock; S. Houghten; D. Ashlock; M. Stoodley; M. Dubé; R. Brown; A. Saunders","St. Francis Xavier University Computer Science, Antigonish, NS, Canada; St. Francis Xavier University, Antigonish, NS, Canada; St. Francis Xavier University Brian Mulroney Institute of Government, Antigonish, NS, Canada; St. Francis Xavier University History, Antigonish, NS, Canada; Ashlock & McGuinness Cons. Inc, Guelph, ON, Canada; Brock University Computer Science St, Catharines, ON, Canada; University of Guelph Mathematics and Statistics, Guelph, ON, Canada; University of Guelph Bioinformatics, Guelph, ON, Canada; Brock University Computer Science St, Catharines, ON, Canada; University of Guelph Bioinformatics, Guelph, ON, Canada; University of Guelph Bioinformatics, Guelph, ON, Canada","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","2975","2984","A new AI system is being developed to optimize vaccination strategies based on the structure and shape of a community's social contact network. The technology is minimally constrained and not bound by preconceived notions or human biases. With this come novel outside the box strategies; however, the system is only capable of optimizing what it is instructed to optimize, and does not consider any ethical or political concerns. With the growing concern for systematic discrimination as a result of artificial intelligence, we acknowledge a number of relevant issues that may arise as a consequence of our new technology and categorize them into three classes. We also introduce four normative ethical approaches that are used as a framework for decision-making. Despite the focus on vaccination strategies, our goal is to improve the discussions surrounding public concern and trust over artificial intelligence and demonstrate that artificial intelligence practitioners are addressing these concerns.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308312","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308312","Artificial Intelligence;COVID-19;Epidemic;Ethics;Optimization;Pandemic;Policy;SARS-CoV-2;Simulation;Vaccinations","Statistics;Sociology;Vaccines;Artificial intelligence;Guidelines;Ethics;COVID-19","","1","","57","IEEE","5 Jan 2021","","","IEEE","IEEE Conferences"
"Development of System for Detection and Prevention of Cyber Attacks Using Artifıcial Intelligence Methods","G. Abdiyeva-Aliyeva; M. Hematyar; S. Bakan","Cyber Security (Docent/Program Manager), Baku Engineering University, Baku, Azerbaijan; Cyber Security (Senior Lecturer), Azerbaijan Technical University, Baku, Azerbaijan; Cyber Security (Lecturer), Azerbaijan Technical University, Baku, Azerbaijan","2021 2nd Global Conference for Advancement in Technology (GCAT)","9 Nov 2021","2021","","","1","5","Artificial intelligence (AI) technologies have given the cyber security industry a huge leverage with the possibility of having significantly autonomous models that can detect and prevent cyberattacks – even though there still exist some degree of human interventions. AI technologies have been utilized in gathering data which can then be processed into information that are valuable in the prevention of cyberattacks. These AI-based cybersecurity frameworks have commendable scalability about them and are able to detect malicious activities within the cyberspace in a prompter and more efficient manner than conventional security architectures. However, our one or two completed studies did not provide a complete and clear analyses to apply different machine learning algorithms on different media systems. Because of the existing methods of attack and the dynamic nature of malware or other unwanted software (adware etc.) it is important to automatically and systematically create, update and approve malicious packages that can be available to the public. Some of Complex tests have shown that DNN performs maybe can better than conventional machine learning classification. Finally, we present a multiple, large and hybrid DNN torrent structure called Scale-Hybrid-IDS-AlertNet, which can be used to effectively monitor to detect and review the impact of network traffic and host-level events to warn directly or indirectly about cyber-attacks. Besides this, they are also highly adaptable and flexible, with commensurate efficiency and accuracy when it comes to the detection and prevention of cyberattacks.There has been a multiplicity of AI-based cyber security architectures in recent years, and each of these has been found to show varying degree of effectiveness. Deep Neural Networks, which tend to be more complex and even more efficient, have been the major focus of research studies in recent times. In light of the foregoing, the objective of this paper is to discuss the use of AI methods in fighting cyberattacks like malware and DDoS attacks, with attention on DNN-based models.","","978-1-6654-1836-2","10.1109/GCAT52182.2021.9587584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9587584","Black hole;Rushing;Flooding;Wormhole;Neighbor attacks;ANN;GAIS;DNN-based models","Deep learning;Scalability;Computer architecture;Telecommunication traffic;Malware;Real-time systems;Computer crime","","1","","24","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"AI-Powered Edge-Cloud Continuum for In-Flight Entertainment and Connectivity","B. Mafakheri; L. Schmidt; A. Prakash; R. Richter; M. Harasic; M. Heindlmaier; P. Hecker; L. Goratti","Safran Passenger Innovations GmbH, Munich, Germany; Technische Universität Braunschweig, Braunschweig, Germany; Fraunhofer FOKUS, Berlin, Germany; Dresden University of Technology, Dresden, Germany; Fraunhofer FOKUS, Berlin, Germany; Cadami GmbH, Munich, Germany; Technische Universität Braunschweig, Braunschweig, Germany; Safran Passenger Innovations GmbH, Munich, Germany","IEEE Aerospace and Electronic Systems Magazine","12 Dec 2023","2023","38","12","14","27","The aviation industry is moving toward a greener, more sustainable, integrated, and digital ecosystem, with Artificial Intelligence (AI) and machine learning showing potential key roles in the transformation process. Travelers, who are now increasingly used to ubiquitous data access, are restarting their air travels with higher expectations and demands for connectivity services. This trend highlights the importance of the in-flight entertainment and connectivity system, which should adapt to such changes and be designed to focus on network security and privacy. In this article, we provide experimental demonstration of an AI-based edge-computing platform developed within the cloud-enabled Aircraft Network and ARtificial Intelligence-based data Analysis (CANARIA) project, which targets to deliver proof-of-concept of an in-flight edge network. The CANARIA edge-computing platform offers a set of AI-based and containerized applications to not only improve the in-flight experience for cabin crew and passengers, but also to underpin the cabin digital transformation while increasing the safety and security of the connectivity system.","1557-959X","","10.1109/MAES.2023.3334686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323468","AI;ML;Distributed Storage;Edge Computing;Edge Management;Federated Learning;IFEC","Cloud computing;Computer architecture;Servers;Logic gates;Entertainment industry;Backhaul networks;Media","","","","20","IEEE","20 Nov 2023","","","IEEE","IEEE Magazines"
"A Multiple Linear Regression Model for Crop Production using Machine Learning and Neural Network","R. Singh; R. Deorari","Uttaranchal University, Dehradun, India; Uttaranchal University, Dehradun, India","2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)","13 Dec 2022","2022","","","1","6","Wireless sensors and artificial intelligence (AI)-based monitoring systems are in great demand and provide precise data extraction and analysis. Finding the best plant development parameters is the main goal of this paper. In this essay, the idea of lowering agricultural risks and fostering intelligent farming is presented. Agriculture has always advanced, however the AI-based sensor devices will set a new standard for smart agriculture. This research objective is to use machine learning methods using image processing to enhance the prediction state. The detection and management of cotton leaf disease detection is the paper's major goal, as stated above. This study includes numerous components, such as soil sensing, remote monitoring based on a server, moisture and temperature sensing, and detection of leaf disease. Plant illnesses that decrease yield if not treated in a timely manner are often brought on by insects and pathogens. In this study, a technique for maintaining soil quality and preventing diseases of cotton leaves is presented. To recognize and categorise leaf diseases, the recommended method employs a regression approach of artificial intelligence. The neural network using linear regression algorithm in the proposed model exhibits the highest level of efficiency in the identification and control of various illnesses by enhancing farmer-friendly farming practises.","","978-1-6654-9790-9","10.1109/MysuruCon55714.2022.9972651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9972651","crop production;machine learning;neural networks;multiple linear regression;and leaf diseases prediction","Wireless communication;Smart agriculture;Wireless sensor networks;Neural networks;Linear regression;Machine learning;Soil","","","","35","IEEE","13 Dec 2022","","","IEEE","IEEE Conferences"
"Energy Storage Management for Microgrids Using n-Step Bootstrapping","N. Aksoy; I. Genc","Department of Electrical Engineering, Istanbul Technical University, Istanbul, Turkey; Department of Electrical Engineering, Istanbul Technical University, Istanbul, Turkey","IEEE Canadian Journal of Electrical and Computer Engineering","26 May 2023","2023","46","2","107","116","Microgrids offer superiorities such as reducing energy costs and increasing the quality of energy, with the use of renewable energy sources and the effective use of energy storage unit created with innovative batteries. Furthermore, this structure, which helps to reduce the carbon footprint, will become undeniably critical to use in near future with the nanogrid and smart grid. As another development, an artificial intelligence (AI)-based control infrastructure brought to us by machine learning stands out as more beneficial than classical control methods. With this framework, which is called reinforcement learning (RL), it is promised that the system to be controlled can be more efficient. At this point, the thrifty use of energy storage unit, which is the most important tool that will increase the profitability of microgrids and enhance the proficiency of energy use, is associated with an RL-based energy control system. While this study focuses on an AI-based control infrastructure, it proposes a method utilizing an RL agent trained with a novel environmental model proposed specifically for the energy storage unit of microgrids. The advantages of this method demonstrated with the results are obtained, are shown and examined.","2694-1783","","10.1109/ICJECE.2022.3232213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126129","Artificial intelligence (AI);energy management;energy storage;microgrid;n-step bootstrapping;reinforcement learning (RL)","Microgrids;Dynamic programming;Mathematical models;Process control;Heuristic algorithms;Costs;Batteries","","","","24","IEEE","16 May 2023","","","IEEE","IEEE Journals"
"Early Concept Evaluation of a Runtime Monitoring Approach for Safe Automated Driving","A. Mehmed; A. Čaušević; W. Steiner; S. Punnekkat","Mälardalen University, Vienna, Austria; Mälardalen University, Västerås, Sweden; TTTech Computertechnik AG, Vienna, Austria; Mälardalen University, Västerås, Sweden","2022 IEEE Zooming Innovation in Consumer Technologies Conference (ZINC)","8 Aug 2022","2022","","","53","58","Being used in key features, such as sensing and intelligent path planning, Artificial Intelligence (AI) has become an inevitable part of automated vehicles (AVs). However, their usage in the automotive industry always comes with a “label” that questions their impact on the overall AV safety. This paper focuses on the safe deployment of AI-based AVs. Among the various ways for ensuring the safety of AI-based AVs is to monitor the safe execution of the system responsible for automated driving (i.e., Automated Driving System (ADS)) at runtime (i.e., runtime monitoring). Most of the research done in the past years focused on verifying whether the path or trajectory generated by the ADS does not immediately collide with objects on the road. However, as we will show in this paper, there are other unsafe situations that do not immediately result in a collision but the monitor should check for them. To build our case, we have looked into the National Highway Traffic Safety Administration (NHTSA) database of 5.9 million police-reported light-vehicle accidents and categorized these accidents into five main categories of unsafe vehicle operations. Furthermore, we have performed a high-level evaluation of the runtime monitoring approach proposed in [1], by estimating what percentage of the total population of 5.9 million of unsafe operations the approach would be able to detect. Lastly, we have performed the same evaluation on other existing runtime monitoring approaches to make a basic comparison of their diagnostic capabilities.","","978-1-6654-8374-2","10.1109/ZINC55034.2022.9840649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9840649","","Runtime;Roads;Time measurement;Safety;Trajectory;Artificial intelligence;Vehicle dynamics","","","","13","IEEE","8 Aug 2022","","","IEEE","IEEE Conferences"
"Pros and Cons of Artificial Intelligence—Lessons From E-Government Services in the COVID-19 Pandemic","J. Cheng; H. Luo; W. Lin; G. Hu","School of Emergency Management, Jinan University, Guangzhou, China; School of Emergency Management, Jinan University, Guangzhou, China; School of Emergency Management, Jinan University, Guangzhou, China; School of Public Administration, Guangdong University of Foreign Studies, Guangzhou, China","2021 2nd International Conference on Artificial Intelligence and Education (ICAIE)","15 Sep 2021","2021","","","167","173","How to understand the role and impact of information technology and artificial intelligence has triggered a big debate. To explore the pros and cons of artificial intelligence and its applications, this article takes the face mask distribution programs in the COVID-19 pandemic as research objects, conducting a multi-case comparative study of three cities in China. By manual coding of a total of 4560 We Chat official account messages, and by analyzing information related to the distribution process, it was found that: (1) On the demand side, the task complexity, the demand diversity, and the unstructured decision-making process in the public health emergency have exposed some limitations of AI in data collecting and unstructured problem-solving. (2) On the supply side, the procedural and substantive rules designed, together with the reliability of an AI system, will shape the performance of the AI service channel. (3) Though AI and other new technologies are advancing drastically in the pandemic, there is still much room for improvement whether by the optimization of AI systems, or by political control and social participation, and by the supplement of alternative channels such as the community service delivery.","","978-1-6654-2492-9","10.1109/ICAIE53562.2021.00042","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534573","artificial intelligence;e-government;public service delivery;public health emergency;pandemic","COVID-19;Pandemics;Shape;Urban areas;Process control;User experience;Social factors","","1","","20","IEEE","15 Sep 2021","","","IEEE","IEEE Conferences"
"The Deficiency of “Redline/Greenline” Approach to Risk Management in AI Applications","A. Kuleshov; A. Ignatiev; A. Abramova","Moscow Institute of Physics and Technology; MGIMO University, Center for Global IT Cooperation; MGIMO University","2021 International Conference Engineering Technologies and Computer Science (EnT)","29 Nov 2021","2021","","","49","55","Expanding application of technologies classified as AI draws public attention to associated risks and effective measures for risk mitigation. Policy makers in most countries are currently looking for effective approaches to securing the public interest against AI-related risks and unforeseen consequences of widening AI use. In this connection, there is widespread talk of defining “red” and “green” areas for AI technologies, frequently leading to calls to draw “red lines” and “green lines” for technological innovation. The authors draw on the analysis of AI related risks in a number of international fora and question the efficacy of this “redline/greenline” approach in terms of making the benefits of AI available in the society, while not impeding innovation and technological progress. The authors propose that a more nuanced approach is required, which could involve certification of AI system in sensitive applications, or could apply codified ethical principles to derive specific rules for AI use dependent on the risks created by AI in a particular application.","","978-1-6654-2674-9","10.1109/EnT52731.2021.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622996","Artificial intelligence;Risk management;Codification;Ethics;Regulation;Safety;Human rights;Innovation","Computer science;Technological innovation;Ethics;Regulation;Safety;Risk management;Artificial intelligence","","","","21","IEEE","29 Nov 2021","","","IEEE","IEEE Conferences"
"An Assurance Case for the DoD Ethical Principles of Artificial Intelligence","B. D. Werner; B. J. Schumeg; T. M. Mills; E. V. Velilla",U.S. Army Combat Capability Development Command Armaments Center; U.S. Army Combat Capability Development Command Armaments Center; U.S. Army Combat Capability Development Command Armaments Center; U.S. Army Combat Capability Development Command Armaments Center,"2023 Annual Reliability and Maintainability Symposium (RAMS)","5 Apr 2023","2023","","","1","7","SUMMARY & CONCLUSIONSThe Ethical Principles of Artificial Intelligence (AI) [1] laid out by the Defense Innovation Board were one of the first publications from the Department of Defense to outline the expectations for AI enabled systems and technologies. This document served as the first guidance for developing agencies and was reviewed to understand the requirements for these new systems. As engineers, the desire is to view the Ethical Principles as evaluation criteria and identify the means by which a system can be qualified against the language laid out by the Defense Innovation Board.One of the first parallels that was identified with this document was the concept of an assurance case. The Ethical Principles do not explicitly lay out any requirements but are more so suggestions or guidelines so the question was how to demonstrate adherence or fulfillment. To this extent the Materiel Release process [2], the process the U.S. Army follows to deploy and field a system, was reviewed as a means to demonstrate fulfillment through the requirements and documentation dictated by that process.This paper demonstrates how the processes and procedures followed by the U.S. Army, in pursuit of mitigating risks for fielding, also in turn fulfill the intent of the Ethical Principles. Upon further review of the principles, it can be observed as design best practices to ensure the development of trusted and assured products. The Materiel Release process is proposed as an assurance case for the adherence to the Ethical Principles of AI. The MR process and associated feeder processes are here compared to the language embodied in the Ethical Principles to the extent that the application of the same rigorous processes done for traditional systems may be applied to AI enabled systems – and in some cases adapted – to ensure justified confidence in the delivered product. Systems that have gone through a Materiel Release review can thus also be said to have demonstrated, as a byproduct, adherence to the Ethical Principles of AI.","2577-0993","978-1-6654-6053-8","10.1109/RAMS51473.2023.10088273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10088273","Artificial Intelligence;Machine Learning;Assurance Case;Ethical Principles;TEVV;Reliability;Safety","Ethics;Technological innovation;Random access memory;Documentation;US Department of Defense;Reliability;Artificial intelligence","","","","16","USGov","5 Apr 2023","","","IEEE","IEEE Conferences"
"Artificial Intelligence in 5G Technology: A Survey","M. E. Morocho Cayamcela; W. Lim","Department of Electronic Engineering, Kumoh National Institute of Technology Gumi, Gyeongsangbuk-do, South Korea; Department of Electronic Engineering, Kumoh National Institute of Technology Gumi, Gyeongsangbuk-do, South Korea","2018 International Conference on Information and Communication Technology Convergence (ICTC)","18 Nov 2018","2018","","","860","865","A fully operative and efficient 5G network cannot be complete without the inclusion of artificial intelligence (AI) routines. Existing 4G networks with all-IP (Internet Protocol) broadband connectivity are based on a reactive conception, leading to a poorly efficiency of the spectrum. AI and its subcategories like machine learning and deep learning have been evolving as a discipline, to the point that nowadays this mechanism allows fifth-generation (5G) wireless networks to be predictive and proactive, which is essential in making the 5G vision conceivable. This paper is motivated by the vision of intelligent base stations making decisions by themselves, mobile devices creating dynamically-adaptable clusters based on learned data rather than pre-established and fixed rules, that will take us to a improve in the efficiency, latency, and reliability of the current and real-time network applications in general. An exploration of the potential of AI-based solution approaches in the context of 5G mobile and wireless communications technology is presented, evaluating the different challenges and open issues for future research.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539642","5G Networks;Artificial Intelligence;IT Convergence;Machine Learning;Deep Learning;Next Generation Network","Wireless communication;5G mobile communication;Supervised learning;Artificial neural networks;Task analysis;Adaptation models","","44","","30","IEEE","18 Nov 2018","","","IEEE","IEEE Conferences"
"Securing Data With Blockchain and AI","K. Wang; J. Dong; Y. Wang; H. Yin","School of Computer and Control Engineering, Yantai University, Shandong, China; Research Institute of Information Technology, Tsinghua University, Beijing, China; School of Computer Science and Technology, Wuhan University of Technology, Wuhan, China; Research Institute of Information Technology, Tsinghua University, Beijing, China","IEEE Access","24 Jun 2019","2019","7","","77981","77989","Data is the input for various artificial intelligence (AI) algorithms to mine valuable features, yet data in Internet is scattered everywhere and controlled by different stakeholders who cannot believe in each other, and usage of the data in complex cyberspace is difficult to authorize or to validate. As a result, it is very difficult to enable data sharing in cyberspace for the real big data, as well as a real powerful AI. In this paper, we propose the SecNet, an architecture that can enable secure data storing, computing, and sharing in the large-scale Internet environment, aiming at a more secure cyberspace with real big data and thus enhanced AI with plenty of data source, by integrating three key components: 1) blockchain-based data sharing with ownership guarantee, which enables trusted data sharing in the large-scale environment to form real big data; 2) AI-based secure computing platform to produce more intelligent security rules, which helps to construct a more trusted cyberspace; 3) trusted value-exchange mechanism for purchasing security service, providing a way for participants to gain economic rewards when giving out their data or service, which promotes the data sharing and thus achieves better performance of AI. Moreover, we discuss the typical use scenario of SecNet as well as its potentially alternative way to deploy, as well as analyze its effectiveness from the aspect of network security and economic revenue.","2169-3536","","10.1109/ACCESS.2019.2921555","China Postdoctoral Science Foundation(grant numbers:2017M620786); Natural Science Foundation of Shandong Province(grant numbers:ZR2017BF018); National Natural Science Foundation of China(grant numbers:61702439); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733072","Data security;data systems;artificial intelligence;cyberspace","Artificial intelligence;Data security;Blockchain;Big Data;Internet;Cyberspace","","32","","28","OAPA","10 Jun 2019","","","IEEE","IEEE Journals"
"Hybrid Al Framework for Remote Patient Heart Failure Risk Prediction","W. Xu; J. Zhao; K. Parvataneni; V. Zhang; S. Lin; H. Wang","Emory University, Atlanta, USA; Thayer Academy, Braintree, USA; BISV, SanJose, USA; Academies of Loudoun, Leesburg, USA; TJHSST, Alexandria, USA; EHS, Sammamish, USA","2022 Global Reliability and Prognostics and Health Management (PHM-Yantai)","14 Nov 2022","2022","","","1","8","Heart failure is a lethal disease with a high risk of death. Once it is diagnosed, it cannot be cured definitively. Continuous attention needs to be given to such patients in both hospital and home environment. Due to the lack of measurement and risk analysis at home, the chance of early intervention is dramatically reduced. This research aims to offer a hybrid AI-based approach for patients to monitor and assess their daily risk at home. Highly personalized AI models are trained with continuous data stream from wearable devices and demographic information. The personalized risk assessment is based on individual’s benchmark of the daily routine and bio pattern. Also, the rule-based algorithms are developed based on clinical well-established thresholds. This hybrid approach yields 87.5% accuracy. Our approach can provide a cost-efficient method for at-home patients’ heart failure prediction.","","978-1-6654-9631-5","10.1109/PHM-Yantai55411.2022.9941764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9941764","artificial intelligence;heart failure;remote patient;risk prediction;-wearable device","Wearable computers;Predictive models;Prediction algorithms;Data models;Cardiovascular diseases;Risk management;Reliability","","","","58","IEEE","14 Nov 2022","","","IEEE","IEEE Conferences"
"Scalable and Secure Architecture for Distributed IoT Systems","N. Dhieb; H. Ghazzai; H. Besbes; Y. Massoud","School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Higher School of Communications of Tunis, University of Carthage, Tunisia; School of Systems & Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA","2020 IEEE Technology & Engineering Management Conference (TEMSCON)","15 Jul 2020","2020","","","1","6","Internet-of-things (IoT) is perpetually revolutionizing our daily life and rapidly transforming physical objects into an ubiquitous connected ecosystem. Due to their massive deployment and moderate security levels, those devices face a lot of security, management, and control challenges. Their classical centralized architecture is still cloaking vulnerabilities and anomalies that can be exploited by hackers for spying, eavesdropping, and taking control of the network. In this paper, we propose to improve the IoT architecture with additional security features using Artificial Intelligence (AI) and blockchain technology. We propose a novel architecture based on permissioned blockchain technology in order to build a scalable and decentralized end-to-end secure IoT system. Furthermore, we enhance the IoT system security with an AI-component at the gateway level to detect and classify suspected activities, malware, and cyber-attacks using machine learning techniques. Simulations and practical implementation show that the proposed architecture delivers high performance against cyber-attacks.","","978-1-7281-4224-1","10.1109/TEMSCON47658.2020.9140108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140108","Internet-of-Things;Blockchain;Cyber Security;Machine Learning","Malware;Computer architecture;Machine learning;Computer hacking","","7","","27","IEEE","15 Jul 2020","","","IEEE","IEEE Conferences"
"Eat This, Not That! – a Personalised Restaurant Menu Decoder That Helps You Pick the Right Food","W. U. Hasan; K. Tuz Zaman; M. S. A. T. Zadeh; J. Li","Department of Computer Science, North Dakota State University, Fargo, USA; Department of Computer Science, North Dakota State University, Fargo, USA; Department of Computer Science, North Dakota State University, Fargo, USA; Department of Computer Science, North Dakota State University, Fargo, USA","2022 IEEE International Conference on E-health Networking, Application & Services (HealthCom)","21 Dec 2022","2022","","","43","48","Picking the right food from a restaurant menu sometimes is not an easy thing for many people: visitors who are not familiar with local restaurants' meal names and their ingredients, people with religious diet constraints, patients with nutrition requirements, and people with special diet preferences. It is not easy for these diners to choose meals from restaurant menus as they do not provide enough information for the diners to make decisions in a brief period. In this paper, we propose an AI-empowered personalized restaurant menu decoder app that can help users make wise choices from any menu in any restaurant. With an easy-to-use interface, the app can quickly rank the restaurant's menu items based on the user’s preferences and concerns. Preliminary test results have demonstrated the good usability of the proposed system.","","978-1-6654-8016-1","10.1109/HealthCom54947.2022.9982770","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982770","Artificial Intelligence;multi-criteria decision making;Semantic Web;AHP;TOPSIS;Food Recommendation;Restaurant Menu Recommendation","Prototypes;Mobile applications;Decoding;Usability","","3","","25","IEEE","21 Dec 2022","","","IEEE","IEEE Conferences"
"Design of Real-Time Multiplayer Word Game for the Android Platform Using Firebase and Fuzzy Logic","T. Michail; E. Alepis","Department of Informatics, University of Piraeus, Piraeus, Greece; Department of Informatics, University of Piraeus, Piraeus, Greece","2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Dec 2023","2023","","","1","8","In this paper, a real-time, multi-player Android application is proposed, specifically a word game. The suggested application enables users to compete with other players in coming up with words using the same letters under time constraints. In certain scenarios, the system may match users with bots for gameplay. The user is given the impression that he is playing against a real opponent given the bot is adjusted to his skill level through an AI-empowered bot. Prefix tree (Trie) data structure and fuzzy logic have been utilized to develop the abovementioned system, which determines when to play and how many words to generate. The common AES method with a 128-bit key has been implemented for messaging encryption.","","979-8-3503-1806-7","10.1109/IISA59645.2023.10345901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345901","Android;Firebase;Multiplayer Game;Real-Time App;Fuzzy Logic;Prefix Tree;Trie;AES;Encryption;Decryption;Secure Chat","Fuzzy logic;Tree data structures;Operating systems;Games;Chatbots;Real-time systems;Encryption","","","","41","IEEE","15 Dec 2023","","","IEEE","IEEE Conferences"
"Combining Human and Machine Intelligence to Foster Wider Adoption of e-Services","K. Zabaleta; A. B. Lago; D. López-De-Ipiña; G. Di Modica; R. Santos De La Cámara; M. Pistore","Deusto Institute of Technology DeustoTech, University of Deusto, Bilbao, Spain; Deusto Institute of Technology DeustoTech, University of Deusto, Bilbao, Spain; Deusto Institute of Technology DeustoTech, University of Deusto Bilbao, Bilbao, Spain; BEng Business Engineering s.r.l., Catania, Italy; R&D Department, HI Iberia Ingenierıa y Proyectos, S.L., Madrid, Spain; FBK, Trento, Italy","2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","9 Apr 2020","2019","","","1854","1859","Hybrid Intelligence (HI) combines machine and human intelligence to overcome the shortcomings of existing AI systems, i.e. prevent the mistakes and failures that would be caused by an AI system working alone. This paper describes how the SIMPATICO project has used HI to contribute towards a further democratisation of e-services, i.e. making easier for citizens to complete the web-based services offered by public administrations (PAs). The Open Government solution proposed has been deployed and evaluated in three European pilots. This paper reflects on the results obtained applying the SIMPATICO solution to one of those PAs, i.e. regional government of Galicia in Spain. This reflection should help illustrating the ample potential of applying HI to give place to smarter more accessible humanfacing services.","","978-1-7281-4034-6","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060327","Open Government;Artificial Intelligence;Human Computation","Government;Stakeholders;Tools;Syntactics;Artificial intelligence;Collaboration;Engines","","1","","14","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Towards Explainable Linguistic Summaries","C. Wrede; M. H. M. Winands; E. Smirnov; A. Wilbik","Department of Advanced Computing Sciences (DACS), Maastricht University, Maastricht, The Netherlands; Department of Advanced Computing Sciences (DACS), Maastricht University, Maastricht, The Netherlands; Department of Advanced Computing Sciences (DACS), Maastricht University, Maastricht, The Netherlands; Department of Advanced Computing Sciences (DACS), Maastricht University, Maastricht, The Netherlands","2023 IEEE International Conference on Fuzzy Systems (FUZZ)","9 Nov 2023","2023","","","1","6","As more AI solutions are implemented in every aspect of our lives, the need for Explainable Artificial Intelligence (XAI) rises. Explanations can have different forms, such as a number (or an equation), a figure, or a text. This paper investigates textual explanations to effectively communicate the reason for a decision made by an AI system. In previous works, linguistic summaries, as an example of a textual explanation, have already been tested and shown to have explanatory potential. In this paper, we explore this topic further and present a roadmap for linguistic summaries to become a proper XAI tool as Explainable Linguistic Summaries (XLSs). We discuss the challenges that an XLS has to overcome. We outline possible solutions and state their consequences. We consider different protoforms, the definition of the membership function, heuristics for the selection of XLS and personalizing the explanations as well as options to gain more insights into the explanations.","1558-4739","979-8-3503-3228-5","10.1109/FUZZ52849.2023.10309707","Netherlands Enterprise Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10309707","Explainable Artificial Intelligence;Linguistic Summaries;Roadmap;Explainable Linguistic Summary (XLS)","Linguistics;Artificial intelligence;Fuzzy systems","","","","56","IEEE","9 Nov 2023","","","IEEE","IEEE Conferences"
"Neuro Intel: A System for Clinical Diagnosis of Attention Deficit Hyperactivity Disorder (ADHD) Using Artificial Intelligence","S. Batsakis; E. Papadakis; I. Tachmazidis; T. Chen; G. Antoniou; M. Adamou","Technical University of Crete, Chania, Greece; University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK; University of Huddersfield, Huddersfield, UK; South West Yorkshire Partnership NHS Foundation Trust, Wakefield, UK","2023 IEEE Symposium on Computers and Communications (ISCC)","28 Aug 2023","2023","","","1","6","Attention-Deficit Hyperactivity Disorder (ADHD) is a mental condition characterised by a pattern of inattention, hyperactivity, and/or impulsivity that causes significant impairment across various domains. Delayed diagnosis and treatment for ADHD can be harmful to people, leading to broader mental health conditions. This paper presents a fully functional system for diagnosing ADHD using an Artificial Intelligence (AI) system called Neuro Intel. Positive results from our research has led to the development of Neuro Intel, which incorporates both expert clinician knowledge and historical clinical data using Machine Learning to assist clinicians in the diagnosis of ADHD in adults.","2642-7389","979-8-3503-0048-2","10.1109/ISCC58397.2023.10218313","Federal Ministry of Education and Research (BMBF), Germany(grant numbers:01DD20003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10218313","Attention-deficit hyperactivity disorder (ADHD);Diagnostic system;Artificial Intelligence;Machine Learning;Knowledge Based System","Computers;Mental health;Machine learning;Clinical diagnosis","","","","18","IEEE","28 Aug 2023","","","IEEE","IEEE Conferences"
"Software-based bus dispatching system for Epifanio Delos Santos Avenue","R. C. D. Intal; E. P. Dadios; A. M. Fillone","Gokongwei College of Engineering De La Salle University Manila, Manila, Philippines; MEM Department Head, Gokongwei College of Engineering De La Salle University Manila, Manila, Philippines; Civil Engineering Department, De La Salle University Manila, Manila, Philippines","2015 International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)","28 Jan 2016","2015","","","1","6","In this study a Software-based Artificial Intelligence (AI) System and Neural Network (NN) System were combined to achieve a highly responsive and a self-learning machine capable in predicting the dispatch time and scheduling of buses in Epifanio Delos Santos Avenue (EDSA) which is a congested road in Metro Manila. The AI system is a software-based program that can learn through data gathering and use its pre-defined rules. The NN system used the learned data generated by the AI system to do a quick determination of bus schedule.","","978-1-5090-0360-0","10.1109/HNICEM.2015.7393238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393238","Epifanio Delos Santos Avenue;Artificial Intelligence System;Neural Network System","Artificial intelligence;Schedules;Artificial neural networks;Biological neural networks;Training data;Testing","","","","7","IEEE","28 Jan 2016","","","IEEE","IEEE Conferences"
"A Robust Methodology for Building an Artificial Intelligent (AI) Virtual Assistant for Payment Processing","A. P. Sam; B. Singh; A. S. Das","Deloitte (USI), Bengaluru, India; Deloitte, New-York, US; Deloitte (USI), Bengaluru, India","2019 IEEE Technology & Engineering Management Conference (TEMSCON)","29 Aug 2019","2019","","","1","6","The evolution of business interactions with customers has defined a new paradigm of human-machine interaction through AI enabled conversations. In such scenarios, the machine interacts with the human (also referred to as customers) by applying NLP, NLU and NLG techniques that are used to process, understand and generate. dynamic and rapidly changing course of conversations to keep it meaningful and within context. With the changing landscape, today's NLU and NLP components are supported by the latest deep learning algorithms, making them highly palatable of understanding customers intent, forming a cogent response, or taking an appropriate action than was possible in the recent past. But such sophisticated techniques require good quality of sample examples to learn. In this work, we discuss a step-by-step approach to enhance and enable the NLU behind the AI virtual assistant to robustly interpret customers utterances. As a system for interaction, we developed an AI virtual assistant for a payment process to help customer process the due amount in invoice, which is an integral part of several industries, like Banking, Utilities, Telcos, Retailers, etc. We tested our model by processing sample interactions of which a significant percentage of interactions (approximately 75%) went through finishing the intended task of completing the payment.","","978-1-7281-1139-1","10.1109/TEMSCON.2019.8813584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8813584","","","","5","","15","IEEE","29 Aug 2019","","","IEEE","IEEE Conferences"
"Platform and Model Design for Responsible AI: Design and build resilient, private, fair, and transparent machine learning models","A. Kapoor; S. Chatterjee",NA; NA,"Platform and Model Design for Responsible AI: Design and build resilient, private, fair, and transparent machine learning models","","2023","","","","","Craft ethical AI projects with privacy, fairness, and risk assessment features for scalable and distributed systems while maintaining explainability and sustainability Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesLearn risk assessment for machine learning frameworks in a global landscapeDiscover patterns for next-generation AI ecosystems for successful product designMake explainable predictions for privacy and fairness-enabled ML trainingBook DescriptionAI algorithms are ubiquitous and used for tasks, from recruiting to deciding who will get a loan. With such widespread use of AI in the decision-making process, it’s necessary to build an explainable, responsible, transparent, and trustworthy AI-enabled system. With Platform and Model Design for Responsible AI, you’ll be able to make existing black box models transparent. You’ll be able to identify and eliminate bias in your models, deal with uncertainty arising from both data and model limitations, and provide a responsible AI solution. You’ll start by designing ethical models for traditional and deep learning ML models, as well as deploying them in a sustainable production setup. After that, you’ll learn how to set up data pipelines, validate datasets, and set up component microservices in a secure and private way in any cloud-agnostic framework. You’ll then build a fair and private ML model with proper constraints, tune the hyperparameters, and evaluate the model metrics. By the end of this book, you’ll know the best practices to comply with data privacy and ethics laws, in addition to the techniques needed for data anonymization. You’ll be able to develop models with explainability, store them in feature stores, and handle uncertainty in model predictions.What you will learnUnderstand the threats and risks involved in ML modelsDiscover varying levels of risk mitigation strategies and risk tiering toolsApply traditional and deep learning optimization techniques efficientlyBuild auditable and interpretable ML models and feature storesUnderstand the concept of uncertainty and explore model explainability toolsDevelop models for different clouds including AWS, Azure, and GCPExplore ML orchestration tools such as Kubeflow and Vertex AIIncorporate privacy and fairness in ML models from design to deploymentWho this book is forThis book is for experienced machine learning professionals looking to understand the risks and leakages of ML models and frameworks, and learn to develop and use reusable components to reduce effort and cost in setting up and maintaining the AI ecosystem.","","9781803249773","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=10251240.pdf&bkn=10251239&pdfType=book","","","","","","","","14 Sep 2023","","","Packt Publishing","Packt Publishing eBooks"
"Survey on Quantum Circuit Compilation for Noisy Intermediate-Scale Quantum Computers: Artificial Intelligence to Heuristics","J. Kusyk; S. M. Saeed; M. U. Uyar","Computer Systems Technology, New York City College of Technology, Brooklyn, NY, USA; Department of Electrical Engineering, City College of the City University of New York, New York, NY, USA; Department of Electrical Engineering, City College of the City University of New York, New York, NY, USA","IEEE Transactions on Quantum Engineering","28 May 2021","2021","2","","1","16","Computationally expensive applications, including machine learning, chemical simulations, and financial modeling, are promising candidates for noisy intermediate scale quantum (NISQ) computers. In these problems, one important challenge is mapping a quantum circuit onto NISQ hardware while satisfying physical constraints of an underlying quantum architecture. Quantum circuit compilation (QCC) aims to generate feasible mappings such that a quantum circuit can be executed in a given hardware platform with acceptable confidence in outcomes. Physical constraints of a NISQ computer change frequently, requiring QCC process to be repeated often. When a circuit cannot directly be executed on a quantum hardware due to its physical limitations, it is necessary to modify the circuit by adding new quantum gates and auxiliary qubits, increasing its space and time complexity. An inefficient QCC may significantly increase error rate and circuit latency for even the simplest algorithms. In this article, we present artificial intelligence (AI)-based and heuristic-based methods recently reported in the literature that attempt to address these QCC challenges. We group them based on underlying techniques that they implement, such as AI algorithms including genetic algorithms, genetic programming, ant colony optimization and AI planning, and heuristics methods employing greedy algorithms, satisfiability problem solvers, dynamic, and graph optimization techniques. We discuss performance of each QCC technique and evaluate its potential limitations.","2689-1808","","10.1109/TQE.2021.3068355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384317","Artificial intelligence (AI);noisy intermediate scale quantum (NISQ);quantum algorithms;quantum circuit compilation (QCC);quantum circuit mapping;quantum computing","Logic gates;Qubit;Quantum circuit;Hardware;Computer architecture;Computers;Artificial intelligence","","18","","97","CCBY","23 Mar 2021","","","IEEE","IEEE Journals"
"Pitako - Recommending Game Design Elements in Cicero","T. Machado; D. Gopstein; A. Nealen; J. Togelius","Game Innovation Lab, New York University, New York, USA; Game Innovation Lab, New York University, New York, USA; School of Cinematic Arts, University of Southern California, Los Angeles, USA; Game Innovation Lab, New York University, New York, USA","2019 IEEE Conference on Games (CoG)","26 Sep 2019","2019","","","1","8","Recommender Systems are widely and successfully applied in e-commerce. Could they be used for designƒ In this paper, we introduce Pitako1, a tool that applies the Recommender System concept to assist humans in creative tasks. More specifically, Pitako provides suggestions by taking games designed by humans as inputs, and recommends mechanics and dynamics as outputs. Pitako is implemented as a new system within the mixed-initiative AI-based Game Design Assistant, Cicero. This paper discusses the motivation behind the implementation of Pitako as well as its technical details and presents usage examples. We believe that Pitako can influence the use of recommender systems to help humans in their daily tasks.","2325-4289","978-1-7281-1884-0","10.1109/CIG.2019.8848081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848081","AI-Game Design Assistant;Recommender Systems;Frequent Itemset Data Mining;Exploratory design","Games;Sprites (computer);Recommender systems;Artificial intelligence;Tools;Task analysis;Technological innovation","","10","","42","IEEE","26 Sep 2019","","","IEEE","IEEE Conferences"
"More knowledge on the table: Planning with space, time and resources for robots","M. Mansouri; F. Pecora","Center for Applied Autononous Sensor Systems, Orebro University, Sweden; Center for Applied Autononous Sensor Systems, Orebro University, Sweden","2014 IEEE International Conference on Robotics and Automation (ICRA)","29 Sep 2014","2014","","","647","654","AI-based solutions for robot planning have so far focused on very high-level abstractions of robot capabilities and of the environment in which they operate. However, to be useful in a robotic context, the model provided to an AI planner should afford both symbolic and metric constructs; its expressiveness should not hinder computational efficiency; and it should include causal, spatial, temporal and resource aspects of the domain. We propose a planner grounded on well-founded constraint-based calculi that adhere to these requirements. A proof of completeness is provided, and the flexibility and portability of the approach is validated through several experiments on real and simulated robot platforms.","1050-4729","978-1-4799-3685-4","10.1109/ICRA.2014.6906923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906923","","Robots;Cognition;Measurement;Spatial resolution;Semantics;Planning;Algebra","","9","","27","IEEE","29 Sep 2014","","","IEEE","IEEE Conferences"
"New Artificial Intelligence approaches for future UAV Ground Control Stations","C. Ramirez-Atencia; V. Rodríguez-Fernández; A. Gonzalez-Pardo; D. Camacho","Department of Computer Engineering, Universidad Autónoma de Madrid, Spain; Department of Computer Engineering, Universidad Autónoma de Madrid, Spain; Department of Computer Engineering, Universidad Autónoma de Madrid, Spain; Department of Computer Engineering, Universidad Autónoma de Madrid, Spain","2017 IEEE Congress on Evolutionary Computation (CEC)","7 Jul 2017","2017","","","2775","2782","The increasing interest in the use of Unmanned Aerial Vehicles (UAV) in the last years has opened up a new complex area of research applications. Many works have been focused on the applicability of new Artificial Intelligence techniques to facilitate the successfully execution of UAV operations from the Ground Control Stations (GCSs). Some of the most demanded applications in this field are the reduction of the workload of operators and the automation of training processes. This paper presents new algorithms focused on this field: a Multi-Objective Genetic Algorithm for solving Mission Planning and Replanning problems and a Procedure Following Evaluation methodology based on Petri Nets. This paper is based on a framework that simulates a GCS with support for multiple UAVs. The functionality of this framework has been extended in two different directions: on the one hand, to deal with Mission Designing, Automated Mission Planning and Replanning, and Alert Generation; and, on the other hand, to perform different analysis tasks of the UAV operators. Using this framework, a test mission has been executed and debriefed, focusing on the main AI-based issues described in this work.","","978-1-5090-4601-0","10.1109/CEC.2017.7969645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7969645","","Training;Planning;Unmanned aerial vehicles;Genetic algorithms;Materials requirements planning;Approximation algorithms;Sensors","","8","","32","IEEE","7 Jul 2017","","","IEEE","IEEE Conferences"
"Real-Time Decision Making for a Car Manufacturing Process Using Deep Reinforcement Learning","T. P. Gros; J. Groß; V. Wolf","Saarland Informatics Campus Saarland University, Saarbrücken, GERMANY; Saarland Informatics Campus Saarland University, Saarbrücken, GERMANY; Saarland Informatics Campus Saarland University, Saarbrücken, GERMANY","2020 Winter Simulation Conference (WSC)","29 Mar 2021","2020","","","3032","3044","Computer simulations of manufacturing processes are in widespread use for optimizing production planning and order processing. If unforeseeable events are common, real-time decisions are necessary to maximize the performance of the manufacturing process. Pre-trained AI-based decision support offers promising opportunities for such time-critical production processes. Here, we explore the effectiveness of deep reinforcement learning for real-time decision making in a car manufacturing process. We combine a simulation model of a central production part, the line buffer, with deep reinforcement learning algorithms, in particular with deep Q-Learning and Monte Carlo tree search. We simulate two different versions of the buffer, a single-agent and a multi-agent one, to generate large amounts of data and train neural networks to represent near-optimal strategies. Our results show that deep reinforcement learning performs extremely well and the resulting strategies provide near-optimal decisions in real-time, while alternative approaches are either slow or give strategies of poor quality.","1558-4305","978-1-7281-9499-8","10.1109/WSC48552.2020.9383884","European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383884","","Manufacturing processes;Decision making;Reinforcement learning;Production;Real-time systems;Automobiles;Time factors","","6","","23","IEEE","29 Mar 2021","","","IEEE","IEEE Conferences"
"Gaussian Processes for Personalized Interpretable Volatility Metrics in the Step-Down Ward","G. W. Colopy; S. J. Roberts; D. A. Clifton","University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.","IEEE Journal of Biomedical and Health Informatics","3 May 2019","2019","23","3","949","959","Patients in a hospital step-down unit require a level of care that is between that of the intensive care unit (ICU) and that of the general ward. While many patients remain physiologically stabilized, others will suffer clinical emergencies and be readmitted to the ICU, with a subsequent high risk of mortality. Had the associated physiological deterioration been detected early, the emergency may have been less severe or avoided entirely. Current clinical monitoring is largely heuristic, requiring manual calculation of risk scores and the use of heuristic decision criteria. Technical drawbacks include ignoring the time-series dynamics of physiological measurements, and lacking patient-specificity (i.e., personalization of models to the individual patient). In this paper, we demonstrate how Gaussian process regression models can supplement current monitoring practice by providing interpretable and intuitive illustrations of erratic vital-sign volatility. These personalized volatility metrics may provide significantly advanced warning of deterioration, while minimizing the false alarms that induce so-called alarm fatigue. While many AI-based approaches to healthcare are criticized for being uninterpretable “blackbox” methods, the cause of alarms generated from the proposed methods are explicitly interpretable and intuitive. We conclude that intelligent computational inference using methods such as those proposed can enhance current clinical decision making and potentially save lives.","2168-2208","","10.1109/JBHI.2019.2890823","Royal Academy of Engineering/Man-AHL Research Chair; Royal Academy of Engineering Research Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621007","Precision medicine;forecasting;Gaussian processes;patient monitoring;statistical learning;time series analysis","Biomedical monitoring;Hospitals;Ground penetrating radar;Monitoring;Gaussian processes;Informatics","Adult;Clinical Alarms;Critical Care;Diagnosis, Computer-Assisted;Forecasting;Humans;Intensive Care Units;Monitoring, Physiologic;Normal Distribution;Precision Medicine;Support Vector Machine;Vital Signs","5","","35","CCBY","22 Jan 2019","","","IEEE","IEEE Journals"
"Considerations for Using Artificial Intelligence to Manage Authorized Push Payment (APP) Scams","K. W. F. Ma; T. Dhot; M. Raza","Science and Technology Studies Graduate Program, York University, Toronto, ON, Canada; TD Bank, Toronto, ON, Canada; TD Bank, Toronto, ON, Canada","IEEE Engineering Management Review","12 Sep 2023","2023","51","3","166","179","Artificial Intelligence (AI)-based security intelligence modeling can be used to prevent, detect, and manage cyber threats. Data-driven AI solutions are currently undergoing rigorous research and design changes in their own field, but few scholars or practitioners frame authorized push payment (APP) scams as a unique cybersecurity concern, or tailor technical solutions based on local regulatory contexts. Drawing on a recent consultation publication by the UK Payment Systems Regulator on APP scams (November 2021), this article shows how AI can be leveraged to manage APP scams and explores some of the opportunities and risks one should consider when adopting such an approach. We highlight three scenarios: 1) Liability on payment service provider; 2) Liability on payor; and 3) Liability on payor with substantial public sector involvement. These examples illustrate how sociotechnical systems can play a design role, and consequently assist industry leaders and engineering management in prioritizing investment focus, strategic approaches, and technical solutions.","1937-4178","","10.1109/EMR.2023.3288432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168910","Artificial intelligence (AI);cybersecurity;leadership;management insights;prioritization;public policy;regulation;scams;strategic solutions","Artificial intelligence;Computer security;Fraud;Industries;Regulation;Investment;Biological system modeling","","2","","78","IEEE","30 Jun 2023","","","IEEE","IEEE Journals"
"Optimization of Soft Mobility Localization with Sustainable Policies and Open Data","S. Kleisarchaki; L. Gürgen; Y. Mitike Kassa; M. Krystek; D. González Vidal","Kentyou, Grenoble, France; Kentyou, Grenoble, France; Eurecat, Barcelona, Spain; PSNC, Poznan, Poland; Eurecat, Barcelona, Spain","2022 18th International Conference on Intelligent Environments (IE)","15 Jul 2022","2022","","","1","8","A quarter of global greenhouse emissions come from transport, with modern cities producing more than 60% of these emissions. To reduce carbon footprint, several solutions on soft mobility (e.g., optimizing electric vehicles locations) have been proposed using IoT resources and AI techniques. However, these solutions either lack replicability since they ignore city’s needs per area and economic restrictions or lack algorithmic fairness since they account no social criteria (e.g., disabled, age, gender). In this work, we developed AI-based methods to automatically detect the different areas (e.g., rural, urban) and propose two heuristics which incorporate social, environmental and economic criteria of the area in their decision making in the form of sustainability policy templates. Our heuristics solve the p-median problem; they minimize the distance of stations to important points constrained by the cost of new stations. We show that our proposed solution is able to disperse the new stations within the city while covering local neighbourhoods. This work is replicated in two big European cities adapted to different open data and demonstrated by a dedicated visual dashboard.","2472-7571","978-1-6654-6934-0","10.1109/IE54923.2022.9826779","UBS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826779","soft mobility;optimization;sustainability policy;fairness;open data","Location awareness;Visualization;Smart cities;Urban areas;Europe;Safety;Artificial intelligence","","2","","33","IEEE","15 Jul 2022","","","IEEE","IEEE Conferences"
"Policy enabled caching for distributed AI","D. C. Verma; G. Bent","IBM T. J. Watson Research Center Yorktown Heights, NY, U.S.A.; IBM Research UK, Warrington, UK","2017 IEEE International Conference on Big Data (Big Data)","15 Jan 2018","2017","","","3017","3023","Web Caching has established itself as a key enabling technology within the Internet. It enables efficient browsing of websites and web-based services on networks that are bandwidth constrained. However, similar techniques are not available for AI based solutions. Many AI solutions are based on deep neural networks or similar approaches which require creation of machine learning models trained with huge amounts of data. Such models are best created in centralized locations with significant processing power. In many environments, sending the data to a centralized location is infeasible or undesirable. A judicious combination of ideas borrowed from web-caching paradigm, with ideas from AI and machine learning can provide an effective solution for exploitation of deep learning models in bandwidth constrained environments. Allowing such caches to generate their own policies using a generative policy approach can enable the creation of a generic edge caching system which can be used with a wide variety of backend AI systems.","","978-1-5386-2715-0","10.1109/BigData.2017.8258273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258273","Edge Computing;Fog Computing;Distributed AI;Semantic Caching;Generative Policy","Artificial intelligence;Training;Speech;Data models;Drones;Hospitals;Computational modeling","","2","","8","IEEE","15 Jan 2018","","","IEEE","IEEE Conferences"
"Multi-Controller Architecture for Reliable Autonomous Vehicle Navigation: Combination of Model-Driven and Data-Driven Formalization","D. Iberraken; L. Adouanc; D. Denis","CNRS, Institut Pascal, Clermont-Ferrand, France; CNRS, Institut Pascal, Clermont-Ferrand, France; R&D Department La Garenne Colombe, Sherpa Engineering Company, France","2019 IEEE Intelligent Vehicles Symposium (IV)","29 Aug 2019","2019","","","245","251","In this paper, a design of a multi-controller architecture (MCA) is presented. It effectively links model-based approaches and Artificial Intelligence (AI) developments for intelligent vehicles navigation in a highway. In this MCA, the model-based approach appears in the path planning (based on analytical target set-points definition) and the control law (based on a Lyapunov stability analysis). The AI-based approach appears in the proposed Two-Sequential Level Bayesian Decision Network (TSLBDN) for handling lane change maneuvers in uncertain environment and changing dynamic/behaviors of the surrounding vehicles. In addition, a combination of both trajectory prediction (based on dynamic target set-points and elliptic limit-cycles) and maneuver recognition based on Dynamic Bayesian Network (DBN) is proposed to infers surrounding vehicles actions. Several simulation results show the efficiency of the model-driven/data driven overall proposed control architecture.","2642-7214","978-1-7281-0560-4","10.1109/IVS.2019.8813830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8813830","","","","2","","28","IEEE","29 Aug 2019","","","IEEE","IEEE Conferences"
"Trust-aware Control for Intelligent Transportation Systems","M. Cheng; J. Zhang; S. Nazarian; J. Deshmukh; P. Bogdan","Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA","2021 IEEE Intelligent Vehicles Symposium (IV)","1 Nov 2021","2021","","","377","384","Many intelligent transportation systems are multiagent systems, i.e., both the traffic participants and the subsystems within the transportation infrastructure can be modeled as interacting agents. The use of AI-based methods to achieve coordination among the different agents systems can provide greater safety over transportation systems containing only human-operated vehicles, and also improve the system efficiency in terms of traffic throughput, sensing range, and enabling collaborative tasks. However, increased autonomy makes the transportation infrastructure vulnerable to compromised vehicular agents or infrastructure. This paper proposes a new framework by embedding the trust authority into transportation infrastructure to systematically quantify the trustworthiness of agents using an epistemic logic known as subjective logic. In this paper, we make the following novel contributions: (i) We propose a framework for using the quantified trustworthiness of agents to enable trust-aware coordination and control. (ii) We demonstrate how to synthesize trust-aware controllers using an approach based on reinforcement learning. (iii) We comprehensively analyze an autonomous intersection management (AIM) case study and develop a trust-aware version called AIM-Trust that leads to lower accident rates in scenarios consisting of a mixture of trusted and untrusted agents.","","978-1-7281-5394-0","10.1109/IV48863.2021.9576045","National Science Foundation(grant numbers:CPS/CNS-1453860,SHF-2048094); Northrop Grumman; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576045","","Intelligent vehicles;Transportation;Collaboration;Reinforcement learning;Throughput;Sensors;Safety","","1","","30","IEEE","1 Nov 2021","","","IEEE","IEEE Conferences"
"Social lane-based cognitive model for simulating pedestrian flow in games","D. J. Howden; S. Y. Chen","Centre for Information Technology Research, Swinburne University of Technology, Melbourne, Australia; School of Information Technology, York University, Toronto, Canada","2013 IEEE Congress on Evolutionary Computation","15 Jul 2013","2013","","","837","843","In computer game software, the implementation of simulated urban crowds is widespread. Representation of pedestrians in computer games has, to date, lagged behind what has been shown possible in academic studies and simulation software. Primary reasons for this are the strict CPU budgets that game AI has to function under, and algorithm implementation which is frequently complex for even a baseline approach (i.e. before performance optimisations). This paper presents a novel lane-based approach to pedestrian AI which combines the verisimilitude of AI based on behavioural studies, with the intuitive implementation and minimal computation cost required for games development. To achieve this, each agent filters its surroundings into virtual lanes, and then sidesteps or continues forward as dictated by social convention.","1941-0026","978-1-4799-0454-9","10.1109/CEC.2013.6557655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557655","Lane;pedestrian;game;embodiment;social;crowd;artificial life;simulation","Games;Artificial intelligence;Computational modeling;Planning;Decision trees;Navigation;Collision avoidance","","1","","20","IEEE","15 Jul 2013","","","IEEE","IEEE Conferences"
"Deep Learning Framework for Student Course Recommender System for Higher Educational Institutions","S. Rallapalli; D. M. R","Department of Master of Computer Applications, Nitte Meenakshi Institute of Technology, Bengaluru, India; Department of Master of Computer Applications, Nitte Meenakshi Institute of Technology, Bengaluru, India","2023 International Conference on Ambient Intelligence, Knowledge Informatics and Industrial Electronics (AIKIIE)","22 Jan 2024","2023","","","1","6","With the advancement in technology like Artificial Intelligence (AI) and Machine Learning (ML) there are many sub fields which are emerged from the core areas. Deep Learning (DL) is one such field which is gaining vast importance and is often mentioned as branch of ML and AI. In order to quickly and efficiently find the relevant information on the internet based on our past browsing history, recommender systems are playing a major role. Many such systems has been proposed in recent works. Recommender system has been implemented in major E-commerce sites like Amazon, Flipkart, Netflix, YouTube and many other giants have introduced AI based recommendation systems. Most of these systems uses the algorithms which can efficiently collect user behavioral data, filter it and recommends the user various choices based on the previous data. These systems often need to develop their own framework and algorithms which can solve the purpose. Students are often confused to opt for courses out of various options available in today's digital world. Based on their skill, interest the system should recommend a course. A general framework where it can handle data diversity, various dimensions and stimulation types is needed. Deep learning based generalized framework can solve such type of issues. In this paper we propose such generalized and effective Deep learning framework for a student course recommendation system for students who wish to pursue a course in various Higher Educational Institutions. The recommender system can be useful for the students who wish to opt a particular course based on their past history of interest and data collected from the logs. In this paper we use the Intel OpenVino toolkit for the deployment of the recommender system. The recommender system which is based on deep learning will provide the student with the exact set of modules he need to choose based on his skill set. The result of a student recommender system using deep learning can vary depending on several factors, including the quality of the data, the effectiveness of the model, and the specific goals of the recommender system. In this paper we focused on better performance, personalized learning paths and enhanced student satisfaction.","","979-8-3503-1646-9","10.1109/AIKIIE60097.2023.10390085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10390085","Algorithms;Artificial Intelligence;Deep Learning Framework;Machine Learning;Recommender System","Deep learning;Industrial electronics;Video on demand;Optimized production technology;Predictive models;Prediction algorithms;History","","","","27","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"A Marketplace Solution for Distributed Network Management and Orchestration of Slices","E. Zeydan; L. Blanco; S. Barrachina-Muñoz; F. Rezazadeh; L. Vettori; J. Mangues","Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain; Centre Tecnològic de Telecomunicacions de Catalunya (CTTC), Barcelona, Spain","2023 19th International Conference on Network and Service Management (CNSM)","28 Nov 2023","2023","","","1","6","The H2020 Distributed management of Network Slices in beyond 5G(MonB5G) project aims to provide zero-touch management and orchestration to support network slicing at scale to reduce the management burden on mobile operators by leveraging distribution of operations along with advanced data-driven Artificial Intelligence (AI)-based mechanisms. However, while this approach shows promise and large companies with abundant data and ML expertise are developing powerful MLdriven services, a critical aspect that remains to be analyzed is its business case. The vast majority of potentially valuable ML services, such as predictive maintenance, Quality of Service (QoS) optimization, network security enhancements, remain stuck at the idea or prototype stage. This paper delves into an analysis of how the MonB5G solutions in particular the tuples (Monitoring System (MS), Analytics Engine (AE), Decision Engine (DE) and Actuator (ACT) could be applied within the network management and orchestration market while investigating various business models and value chains. Numerical results based on experimental data have also been performed to evaluate the OpEX (Operational Expenditure) benefits associated with different network management techniques, for centralized and distributed systems.","2165-963X","978-3-903176-59-1","10.23919/CNSM59352.2023.10327832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10327832","business models;network slicing;network management;closed loop","Technological innovation;Network slicing;Prototypes;Quality of service;Numerical models;Engines;Commercialization","","","","13","","28 Nov 2023","","","IEEE","IEEE Conferences"
"Data-driven Transient Stability Assessment Using Sparse PMU Sampling and Online Self-check Function","G. Wang; J. Guo; S. Ma; X. Zhang; Q. Guo; S. Fan; H. Xu","Department of Electrical Engineering, Tsinghua University, Beijing, China; Department of Power System, China Electric Power Research Institute, Beijing, China; Department of Power System, China Electric Power Research Institute, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; Department of Electrical Engineering, Tsinghua University, Beijing, China; Department of Power System, China Electric Power Research Institute, Beijing, China; Department of Power System, China Electric Power Research Institute, Beijing, China","CSEE Journal of Power and Energy Systems","5 Jun 2023","2023","9","3","910","920","Artificial intelligence technologies provide a new approach for the real-time transient stability assessment (TSA) of large-scale power systems. In this paper, we propose a data-driven transient stability assessment model (DTSA) that combines different AI algorithms. A pre-AI based on the time-delay neural network is designed to locate the dominant buses for installing the phase measurement units (PMUs) and reducing the data dimension. A post-AI is designed based on the bidirectional long-short-term memory network to generate an accurate TSA with sparse PUM sampling. An online self-check function of the online TSA's validity when the power system changes is further added by comparing the results of the pre-AI and the post-AI. The IEEE 39-bus system and the 300-bus AC/DC hybrid system established by referring to China's existing power system are adopted to verify the proposed method. Results indicate that the proposed method can effectively reduce the computation costs with ensured TSA accuracy as well as provide feedback for its applicability. The DTSA provides new insights for properly integrating varied AI algorithms to solve practical problems in modern power systems.","2096-0042","","10.17775/CSEEJPES.2021.05890","National Key R&D Program of China(grant numbers:2018AAA0101500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682673","Artificial intelligence;phasor measurement units;recurrent neural networks;transient stability assessment","Power system stability;Phasor measurement units;Transient analysis;Training;Stability criteria;Satellite broadcasting;Feature extraction","","","","28","","14 Jan 2022","","","CSEE","CSEE Journals"
"Implication and Advantages of Machine Learning-based Chatbots in Diverse Disciplines","V. Asha; G. P. Reddy; B. Nithya; K. Tungal; V. Durgaprasad; T. N. Kruthik","Department of MCA, New Horizon College of Engineering, Bengaluru, India; Department of MCA, New Horizon College of Engineering, Bengaluru, India; Department of MCA, New Horizon College of Engineering, Bengaluru, India; Department of MCA, New Horizon College of Engineering, Bengaluru, India; Department of MCA, New Horizon College of Engineering, Bengaluru, India; Department of MCA, New Horizon College of Engineering, Bengaluru, India","2023 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)","25 Apr 2023","2023","","","22","28","Artificial Intelligence (AI) and Machine Learning (ML) are the techniques, which helps in enacting system with the human beings. Now a days chatbots are playing a vital role in changing the mode of conversation between humans and computer systems. The implementation of these chatbots helps to improve the conversation between computers and humans. Chatbots are the software programmed virtual machines which are intended to make ready for building conversation with the humans and to deploy this system the Artificial Intelligence (AI) techniques are used in all the message plans, these virtual machines are not only bounded for only one area but can be used in many of the areas like education sector, medical, social media, banking and finance etc. Chatbots are essential in educational institutes for handling administrative activities. Chatbots acts as a platform for solving queries of individual with ease. Natural Language input and the deep neural networks are the major tools, which are used in the development of these chatbots. These tools use a LSTM mechanism to understand the related user query. By using these techniques, the chatbots are trained and that helps in giving instantaneous answers for the user queries. All the data from the user will be collected and stored in the specified database and that data will be used for further references. This study depicts the importance of chatbots in various fields with their working principle using Machine Learning(ML) and Artificial Intelligence (AI)-based algorithms.","","978-1-6654-9199-0","10.1109/ICSCDS56580.2023.10104649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10104649","Chatbot;Natural Language Processing (NLP);Training data;Machine Learning;Deep Learning;Long Short-Term Memory (LSTM)","Machine learning algorithms;Social networking (online);Neural networks;Natural languages;Education;Finance;Oral communication","","","","16","IEEE","25 Apr 2023","","","IEEE","IEEE Conferences"
"Production Flow Analysis in the Era of Industry 4.0 : How Digital Technologies can Support Decision-Making in the Factory of the Future","L. Tomidei; N. Sick; J. Deuse; L. Clemon","Faculty of Engineering and IT, Centre for Advanced Manufacturing, University of Technology Sydney, Australia; Faculty of Engineering and IT, Centre for Advanced Manufacturing, University of Technology Sydney, Australia; Faculty of Engineering and IT, Centre for Advanced Manufacturing, University of Technology Sydney, Australia; Faculty of Engineering and IT, Centre for Advanced Manufacturing, University of Technology Sydney, Australia","2022 Portland International Conference on Management of Engineering and Technology (PICMET)","14 Sep 2022","2022","","","1","15","In the context of Industry 4.0, manufacturing companies have been increasingly adopting digital technologies such as Internet of Things, data analytics and cyber-physical systems to seize opportunities for productivity improvements. At the same time, established manufacturing philosophies such as Group Technology have assisted companies in managing the complexity of production processes for decades. To support manufacturing management with more informed decision-making tools, the literature has been proposing new approaches that exploit the potential of digital technologies to enhance the effectiveness of traditional manufacturing techniques. This study focuses on Production Flow Analysis (PFA) as an established approach for Group Technology. Although the existing literature has been focusing on Artificial Intelligence (AI) based approaches to plan the change to Group Technology for decades, few studies rely on production data directly extracted from the factory floor. This is partly due to the fact that technologies such as sensors and data analytics have been increasingly adopted in recent years, and this has led to an increasing amount of data that can be exploited to develop models that can support decisions. In particular, in the context of Industry 4.0, process mining has gained increasing interest, as it provides a data-driven methodology to capture real production processes. The goal of this study is to explore how PFA has evolved in the last decade thanks to the adoption of digital technologies, and to investigate potential synergies between PFA and process mining. This study uses a structured literature review to map advances in industrial applications of PFA in relation to digital technologies, as well as process mining applications in manufacturing to present a future research agenda. This provides manufacturing managers with a structured overview of existing industrial applications and the digital technologies adopted to enhance decision-making tools.","2159-5100","978-1-890843-41-0","10.23919/PICMET53225.2022.9882711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882711","","Group technology;Analytical models;Decision making;Production;Companies;Production facilities;Data models","","","","151","","14 Sep 2022","","","IEEE","IEEE Conferences"
"Defining Quality Requirements for a Trustworthy AI Wildflower Monitoring Platform","P. Heck; G. Schouten","Fontys University of Applied Science, Eindhoven, The Netherlands; Fontys University of Applied Science, Eindhoven, The Netherlands","2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)","4 Jul 2023","2023","","","119","126","For an AI solution to evolve from a trained machine learning model into a production-ready AI system, many more things need to be considered than just the performance of the machine learning model. A production-ready AI system needs to be trustworthy, i.e. of high quality. But how to determine this in practiceƒ For traditional software, ISO25000 and its predecessors have since long time been used to define and measure quality characteristics. Recently, quality models for AI systems, based on ISO25000, have been introduced. This paper applies one such quality model to a real-life case study: a deep learning platform for monitoring wildflowers. The paper presents three realistic scenarios sketching what it means to respectively use, extend and incrementally improve the deep learning platform for wildflower identification and counting. Next, it is shown how the quality model can be used as a structured dictionary to define quality requirements for data, model and software. Future work remains to extend the quality model with metrics, tools and best practices to aid AI engineering practitioners in implementing trustworthy AI systems.","","979-8-3503-0113-7","10.1109/CAIN58948.2023.00029","Naturalis Biodiversity Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164774","Index Terms—software product quality;trustworthy AI;quality requirements;biodiversity monitoring;wildflowers","Deep learning;Dictionaries;Data models;Software;Time measurement;Software measurement;Artificial intelligence","","","","26","IEEE","4 Jul 2023","","","IEEE","IEEE Conferences"
"Deep Recurrent Learning versus Q-Learning for Energy Management Systems in Next Generation Network","A. Dridi; C. Boucetta; H. Moungla; H. Afifi","SAMOVAR Lab. Telecom SudParis, Institut Polytechnique de Paris, Palaiseau, France; CReSTIC EA 3804, Université de Reims Champagne-Ardenne, REIMS, France; LIPADE, University of Paris, Paris, France; SAMOVAR Lab. Telecom SudParis, Institut Polytechnique de Paris, Palaiseau, France","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","An AI based energy management system (EMS) for microgrids is proposed. It is composed of three modules: a strategy based module, a deep learning (DL) and a reinforcement learning module (RL). This framework determines heuristically the optimal actions for the microgrid system under different time-dependent environmental conditions. In essence, a main innovation is applied to the EMS. Our deep learning algorithm uses recurrent neural networks (RNNs) instead of the habitual State Action Reward (SAR) approach (whether classical or deep). Learning is hence guided by successful actions rather than by blind exploration. A large improvement in learning rates is hence observed when compared to classical Q-learning on real datasets that present a large diversity in energy consumption profiles, acquired in French premises over a long period. It leads to question about the best appropriate reinforcement policies to adopt when solving large state environments.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685620","Reinforcement Learning;Deep reinforcement Learning;Q-Learning;Smart Microgrid;Optimization","Deep learning;Energy consumption;Technological innovation;Q-learning;Recurrent neural networks;Microgrids;Prediction algorithms","","","","16","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Advancing Cybersecurity with Explainable Artificial Intelligence: A Review of the Latest Research","P. Ramya; S. V. Babu; G. Venkatesan","Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India; Department of CSE, SNS College of Engineering, Coimbatore, India; Department of EEE, Sri Sai Ram Engineering College, Chennai, India","2023 5th International Conference on Inventive Research in Computing Applications (ICIRCA)","28 Aug 2023","2023","","","1351","1357","The use of artificial intelligence (AI) in cybersecurity has become increasingly common, but a key challenge is the lack of transparency and interpretability of AI models. Explainable Artificial Intelligence (XAI) can address this issue by providing a means of enhancing the transparency and interpretability of AI models, enabling cybersecurity professionals to better understand the decisions made by these models and to identify errors or biases. This review article provides a comprehensive overview of the latest research on the application of Explainable Artificial Intelligence (XAI) in the context of cybersecurity, with a focus on its benefits and challenges. Specifically, it analyses the most recent techniques and tools for implementing XAI in cybersecurity, while also highlighting several successful use cases. Furthermore, it delves into the ethical and regulatory considerations associated with XAI in cybersecurity and provides recommendations for future research in this area. The ultimate objective of this review article is to furnish cybersecurity professionals with a detailed understanding of the potential of XAI to enhance the efficacy of AI-based tools in cybersecurity, underscoring the significance of transparency and interpretability in assuring the security and dependability of AI systems.","","979-8-3503-2142-5","10.1109/ICIRCA57980.2023.10220797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220797","Explainable Artificial Intelligence;Intrusion Detection System;Botnet;Cybersecurity","Ethics;Law;Collaboration;Standardization;Cognition;Stakeholders;Reliability","","","","32","IEEE","28 Aug 2023","","","IEEE","IEEE Conferences"
"Agent Architecture for Adaptive Behaviors in Autonomous Driving","M. D. Lio; R. Donà; G. P. R. Papini; K. Gurney","Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Psychology, The University of Sheffield, Sheffield, U.K.","IEEE Access","1 Sep 2020","2020","8","","154906","154923","Evolution has endowed animals with outstanding adaptive behaviours which are grounded in the organization of their sensorimotor system. This paper uses inspiration from these principles of organization in the design of an artificial agent for autonomous driving. After distilling the relevant principles from biology, their functional role in the implementation of an artificial system are explained. The resulting Agent, developed in an EU H2020 Research and Innovation Action, is used to concretely demonstrate the emergence of adaptive behaviour with a significant level of autonomy. Guidelines to adapt the same principled organization of the sensorimotor system to other agents for driving are also obtained. The demonstration of the system abilities is given with example scenarios and open access simulation tools. Prospective developments concerning learning via mental imagery are finally discussed.","2169-3536","","10.1109/ACCESS.2020.3007018","European Commission through the EU Horizon 2020 Dreams4Cars Research and Innovation Action Project(grant numbers:H2020 731593); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133080","Adaptive behaviour;affordance competition hypothesis;autonomous driving;explainable artificial intelligence","Trajectory;Organizations;Autonomous vehicles;Brain modeling;Computational modeling;Computer architecture","","13","","52","CCBY","3 Jul 2020","","","IEEE","IEEE Journals"
"A Customisable AI Deck for Pitch Reports and Automated III Umpire Decision Review System DRS","P. Ramya; C. P. Gowtham; S. K. Kumar; T. P. Silpica; P. Renugadevi","Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India; Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India; Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India; Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India; Department of AI and DS, PSNA College of Engineering and Technology, Dindigul, India","2023 2nd International Conference on Edge Computing and Applications (ICECAA)","16 Aug 2023","2023","","","952","957","Nowadays giving fair verdict is a quite challenging task because of certain contentious aspects in modern cricket. So, in order to avoid making wrong decisions, we develop an automated AI-based solution. This project focus on a technology that helps both the main umpire and third umpire to makes critical determination for Leg Before the Wicket (LBW) regarding whether the batsman is out or not-out and also minimizes the waiting time for players until the third umpire go through the trajectory of the ball to make a correct decision. The main purpose of our AI-DRS is to remove the umpires call which plays a vital role in giving third umpires decision because whether any one of the cases shows umpires call the decision will be stick with on-field umpires call whether it may be out or not-out. The pitch report and comprehensive cricket laws are also included for the sake of the game. The pitch report will be examined with several key wicket characteristics, such as kind of soil, cracks, amount of grass cover, and wetness, etc. using drone we capture the video of the match day pitch. To determine the field crack, canny edge detection is performed and soil moisture sensor is used to determine the moisture content of the soil. This information help cricket team to make a decision about whether to bat or field after winning the toss and helps to choose the strongest 11 players through which can win the match on that pitch on that day. Utilizing support vector machine (SVM) and histograms of gradients (HOG), objects are classified and recognized. In order to monitor and forecast the velocity of the ball, linear regression and quadratic regression are applied. Finally, Tkinter is used for GUI development, imutils and OpenCV are used as implementation tools. Due to the controversy of rare wicket calls, boundary and penalty runs, we bring a voice recognized AI system which gave fans to easily understand why this decision is made by the umpire and sometime umpires found difficulty to remember some rules which is rarely used in cricket it will also give assist to on-field umpires to give a very clear idea why he made the decision, the on-field umpires can easily access the laws through voice recognition which use Alan-AI. The Voice recognition web app was developed using react-js.","","979-8-3503-4757-9","10.1109/ICECAA58104.2023.10212245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10212245","Drone;SVM;HOG;Tkinter;linear and quadratic regression;imutils;OpenCV;Alan-AI;reactjs","Support vector machines;Histograms;Soil moisture;Speech recognition;Games;Trajectory;Object recognition","","","","9","IEEE","16 Aug 2023","","","IEEE","IEEE Conferences"
"Adapting a Trusted AI Framework to Space Mission Autonomy","P. Slingerland; L. Perry; J. Kaufman; B. Bycroft; E. Linstead; L. Mandrake; G. Doran; A. Goel; M. S. Feather; L. Fesq; H. Ono; R. Amini","The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; The Aerospace Corporation, El Segundo, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA","2022 IEEE Aerospace Conference (AERO)","10 Aug 2022","2022","","","1","20","As artificial intelligence (AI) is increasingly proposed for new and future capabilities in space missions, the question of how to trust AI-enabled space autonomy has been explored. Recently, a collaboration between The Aerospace Corporation (Aerospace) and NASA's Jet Propulsion Laboratory (JPL) investigated how Aerospace's Trusted AI Framework could be applied to two JPL projects that planned on leveraging AI for critical autonomous tasks. This combined effort led to many insights into the practical implementation of trust-ed AI along with considerable updates to the Trusted AI Framework that tailored its topic threads to space exploration. This document summarizes the enhanced framework as tailored to space missions as well as estimation of the level of trust required as a function of mission criticality and key stakeholders. The goal of this work is to provide a set of best practices to guide autonomy researchers, flight engineers, mission and proposal reviewers, and instrument and mission principal investigators (PIs) towards AI-based autonomy that maximizes trust and lowers the barriers to mission adoption for both science and engineering applications.","1095-323X","978-1-6654-3760-8","10.1109/AERO53065.2022.9843376","Jet Propulsion Laboratory; California Institute of Technology; National Aeronautics and Space Administration(grant numbers:80NM0018D0004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843376","","Schedules;Shape;Space missions;Propulsion;Stakeholders;Proposals;Artificial intelligence","","9","","67","IEEE","10 Aug 2022","","","IEEE","IEEE Conferences"
"AI for CSI Feedback Enhancement in 5G-Advanced","J. Guo; C. -K. Wen; S. Jin; X. Li",NA; NA; NA; NA,"IEEE Wireless Communications","","2022","PP","99","1","8","The 3rd Generation Partnership Project started the study of Release 18 in 2021. Artificial intelligence (AI)-native air interface is one of the key features of Release 18, where AI for channel state information (CSI) feedback enhancement is selected as the representative use case. This article provides an overview of AI for CSI feedback enhancement in 5G-Advanced. Several representative non-AI and AI-enabled CSI feedback frameworks are first introduced and compared. Then, the standardization of AI for CSI feedback enhancement in 5G-advanced is presented in detail. First, the scope of the AI for CSI feedback enhancement in 5G-Advanced is presented and discussed. Then, the main challenges and open problems in the standardization of AI for CSI feedback enhancement, especially focusing on performance evaluation and the design of new protocols for AI-enabled CSI feedback, are identified and discussed. This article provides a guideline for the standardization study of AI-based CSI feedback enhancement.","1558-0687","","10.1109/MWC.010.2200304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9970357","","Artificial intelligence;Precoding;Standardization;Downlink;5G mobile communication;Complexity theory;3GPP","","7","","","IEEE","5 Dec 2022","","","IEEE","IEEE Early Access Articles"
"Application of Artificial Intelligence in Project Planning to Solve Late and Over-Budgeted Construction Projects","K. Rathod; A. Sonawane","Mit-Adt University, Pune, India; Mit-Adt University, Pune, India","2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)","27 Apr 2022","2022","","","424","431","Advance use of Artificial Intelligence (AI), has reduced the need of human intervention within several tasks that are repetitive and rule-based. AI can have a great impact on the workforce of a project within the construction industry. Use of Machine learning techniques within the project process can be beneficial for a project manager to manage financial aspects and time scheduling both. The major problem that construction project managers face is ineffective tracking process, cost management process. This is the main reason, the AI-based solution are needed within construction sites. The aim of this research is to identify the role of AI in time management as well as cost management of a construction project in India. Intelligence robotics is a major AI-based tool that is used within construction project for marinating cost. Some challenges are also found within construction project that might have a huge effect within its implementation process such as cultural barriers, high-cost of maintenance and unavailability of similar input parameters in all projects. As per the findings, ANN, SVM, Regression and many other AI-based are effective Ai-based machine learning tools that are used within construction project to replace various time consuming process by modern technologies. Construction delays are the major effective factor for cost overrun and time overrun within a project. As per this research article, it has been found that, use of AI, especially ANN model can reduce the tendency of delay in construction projects and mismanagement of costs.","","978-1-6654-7884-7","10.1109/ICSCDS53736.2022.9761027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761027","Artificial Intelligence;Construction Delays;Intelligent calculation Robot;NN (Artificial Neural Network);Support Vector Mechanism (SVM);Optimal Hyperplane;CoGence","Support vector machines;Costs;Job shop scheduling;Artificial neural networks;Machine learning;Maintenance engineering;Delays","","1","","18","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Ethics Aspects of Embedded and Cyber-Physical Systems","A. Thekkilakattil; G. Dodig-Crnkovic","Malardalen University, Västerås, Sweden; Chalmers Technical University and University of Gothenburg, Gothenburg, Sweden","2015 IEEE 39th Annual Computer Software and Applications Conference","24 Sep 2015","2015","2","","39","44","The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the ""responsibility"" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical ""responsibility"" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities.","0730-3157","978-1-4673-6564-2","10.1109/COMPSAC.2015.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273594","Ethics;Cyber-physical systems;Software-responsibility;Extra-functional Properties","Cyber-physical systems;Software;Safety;Ethics;Stakeholders;Artificial intelligence;Ethical aspects","","16","","16","IEEE","24 Sep 2015","","","IEEE","IEEE Conferences"
"Development Of Methodology for Precise Diagnosis of Ecg By Artificial Intelligent","R. N. Patel; M. P. Barot","Department of Computer Engineering, LDRP Institute of technology and Research, Gandhinagar, Gujarat, India; Department of Computer Engineering, LDRP Institute of technology and Research, Gandhinagar, Gujarat, India","2019 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)","17 Oct 2019","2019","","","1","5","Implementation of Artificial Intelligence in medical diagnosis is a subject of intense study in nowadays. One of the current interests of developing an Artificial Intelligent is to develop an AI system for diagnosis of heart disease from Electrocardiogram (ECG). Few AI programs have also been developed for ECG diagnosis system, but most of them are based on pattern comparison algorithm which can never achieve the sufficient precision and accuracy for diagnosis task. To eliminate these deficiencies, this paper proposes a new methodology that makes AI system more capable for ECG diagnosis. The proposed methodology and design for AI diagnosis system is based on the statistical analysis of ECG and implementation of standard ECG Interpretation Principles for diagnosis of cardiac arrhythmias. This method is completely knowledge based and it applies the same methods and rules of cardiology which are implemented by a medical expert (cardiologist) to make a report of patient's ECG. The proposed methodology also provides an ability of self learning to AI system in order to utilize the experiences in further diagnosis service.","","978-1-5386-8158-9","10.1109/ICECCT.2019.8869413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869413","Electrocardiogram (ECG);Electrocardiograph;Sinus rhythm;Cardiology;Cardiac anatomy;Cardiac Arrhythmias;Rhythm-Strip;ECG-Complex;Ventricular Systole;Ventricular Diastole.","Electrocardiography;Artificial intelligence;Rhythm;Strips;Medical diagnostic imaging;Task analysis","","4","","6","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Efficient Automated Processing of the Unstructured Documents Using Artificial Intelligence: A Systematic Literature Review and Future Directions","D. Baviskar; S. Ahirrao; V. Potdar; K. Kotecha","Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India; Blockchain Research and Development Laboratory, Curtin University, Perth, WA, Australia; Symbiosis Centre for Applied Artificial Intelligence, Symbiosis International (Deemed University), Pune, India","IEEE Access","21 May 2021","2021","9","","72894","72936","The unstructured data impacts 95% of the organizations and costs them millions of dollars annually. If managed well, it can significantly improve business productivity. The traditional information extraction techniques are limited in their functionality, but AI-based techniques can provide a better solution. A thorough investigation of AI-based techniques for automatic information extraction from unstructured documents is missing in the literature. The purpose of this Systematic Literature Review (SLR) is to recognize, and analyze research on the techniques used for automatic information extraction from unstructured documents and to provide directions for future research. The SLR guidelines proposed by Kitchenham and Charters were adhered to conduct a literature search on various databases between 2010 and 2020. We found that: 1. The existing information extraction techniques are template-based or rule-based, 2. The existing methods lack the capability to tackle complex document layouts in real-time situations such as invoices and purchase orders, 3. The datasets available publicly are task-specific and of low quality. Hence, there is a need to develop a new dataset that reflects real-world problems. Our SLR discovered that AI-based approaches have a strong potential to extract useful information from unstructured documents automatically. However, they face certain challenges in processing multiple layouts of the unstructured documents. Our SLR brings out conceptualization of a framework for construction of high-quality unstructured documents dataset with strong data validation techniques for automated information extraction. Our SLR also reveals a need for a close association between the businesses and researchers to handle various challenges of the unstructured data analysis.","2169-3536","","10.1109/ACCESS.2021.3072900","Research Support Fund of Symbiosis International (Deemed University); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402739","Artificial Intelligence (AI);document analysis;information extraction;named entity recognition (NER);optical character recognition (OCR);robotics process automation (RPA);unstructured data","Organizations;Information retrieval;Optical character recognition software;Data mining;Automation;Standards organizations;Bibliographies","","23","","117","CCBY","13 Apr 2021","","","IEEE","IEEE Journals"
"Firewall Design and Implementation","L. Reznik",NA,"Intelligent Security Systems: How Artificial Intelligence, Machine Learning and Data Science Work For and Against Computer Security","","2022","","","57","108","The chapter introduces firewalls and their design as the first line of defense mechanism. This chapter's goal is twofold: (i) to cover major aspects of the firewall design and operation for security professional education and (ii) explain how artificial intelligence and machine learning techniques and technologies are employed for enhancing firewalls and the security they provide. For the first goal, it provides the firewall definition, discusses the functions, possible architectures, and operational models concentrating on the presentation of their advantages and drawbacks. It includes the step‐by‐step guide to the firewall design and implementation process ranging from planning to deployment and maintenance. For the second goal, the chapter moves the reader from basic rules design to sophisticated AI and ML employment algorithms that improve it. The major emphasis is placed on using rules to set up, configure, and modify the firewall's policy. Both generic and specific rules are discussed as well as their formulation and editing with firewall tools. Substantial rules design principles and conflict avoidance and resolution are presented. The modern AI‐based developments are presented at the end.","","9781119771555","10.1002/9781119771579.ch2","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9562701.pdf&bkn=9562694&pdfType=chapter","","Firewalls (computing);Hardware;Software;Security;Filtering;Grippers;Telecommunication traffic","","","","","","7 Oct 2021","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Artificial Intelligence In Interferometric Synthetic Aperture Radar Phase Unwrapping: A Review","L. Zhou; H. Yu; Y. Lan; m. xing","School of Computer Science and Engineering, Changshu Institute of Technology, Suzhou, China; Department of Civil and Environmental Engineering, National Center for Airborne Laser Mapping, University of Houston, Texas, USA; Signal and Information Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Magazine","15 Jun 2021","2021","9","2","10","28","Interferometric synthetic aperture radar (InSAR) is a radar technique widely used in geodesy and remote sensing applications, e.g., topography reconstruction and subsidence estimation. Phase unwrapping (PU) is one of the key procedures of InSAR signal processing. Artificial intelligence (AI) techniques have proven to be potentially powerful in many fields and have been introduced into the PU domain, achieving superior performance. In this article, we provide a comprehensive overview of AI-based PU techniques in InSAR. We survey the AI-based single-baseline (SB) PU methods and then review the AI techniques related to multibaseline (MB) PU. In addition, we show several experimental examples of these methods, from both simulated and real InSAR data sets, which gives readers an overview of AI-based PU processing's potential and limitations. It is our hope that this article will provide researchers with guidelines and inspiration to further enhance the development of AI-based PU.","2168-6831","","10.1109/MGRS.2021.3065811","China National Science Fund for Distinguished Young Scholars(grant numbers:61825105); National Natural Science Foundation of China(grant numbers:42071438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410354","","Artificial intelligence;Synthetic aperture radar;Estimation;Interferometry;Volcanoes;Surface topography;Remote sensing","","45","","73","IEEE","21 Apr 2021","","","IEEE","IEEE Magazines"
"Assessing Trustworthy AI in Times of COVID-19: Deep Learning for Predicting a Multiregional Score Conveying the Degree of Lung Compromise in COVID-19 Patients","H. Allahabadi; J. Amann; I. Balot; A. Beretta; C. Binkley; J. Bozenhard; F. Bruneault; J. Brusseau; S. Candemir; L. A. Cappellini; S. Chakraborty; N. Cherciu; C. Cociancig; M. Coffee; I. Ek; L. Espinosa-Leal; D. Farina; G. Fieux-Castagnet; T. Frauenfelder; A. Gallucci; G. Giuliani; A. Golda; I. van Halem; E. Hildt; S. Holm; G. Kararigas; S. A. Krier; U. Kühne; F. Lizzi; V. I. Madai; A. F. Markus; S. Masis; E. W. Mathez; F. Mureddu; E. Neri; W. Osika; M. Ozols; C. Panigutti; B. Parent; F. Pratesi; P. A. Moreno-Sánchez; G. Sartor; M. Savardi; A. Signoroni; H. -M. Sormunen; A. Spezzatti; A. Srivastava; A. F. Stephansen; L. B. Theng; J. J. Tithi; J. Tuominen; S. Umbrello; F. Vaccher; D. Vetter; M. Westerlund; R. Wurth; R. V. Zicari","Enterprise Intelligence Department, EY Netherlands, Amsterdam, The Netherlands; Department of Health Sciences and Technology, Health Ethics and Policy Lab, ETH Zurich, Zürich, Switzerland; Postgraduate Studies in Diplomacy and International Relations, Center for Diplomatic & Strategic Studies, Paris, France; Institute of Information Science and Technologies, National Research Council of Italy (CNR), Pisa, Italy; Bioethics Center, Hackensack Meridian Health, Edison, NJ, USA; Faculty of Philosophy, University of Oxford, Oxford, U.K.; Philosophie Department, Collège André- Laurendeau, Montreal, Canada; Philosophy Department, Pace University, New York, NY, USA; Department of Radiology, Wexner Medical Center, The Ohio State University, Columbus, OH, USA; Department of Radiology, Humanitas Research Hospital, Milan, Italy; Faculty of Science, Agriculture, Business and Law, University of New England, Armidale, NSW, Australia; European Centre of Excellence on the Regulation of Robotics & AI, Scuola Superiore Sant’Anna, Pisa, Italy; Group of Computer Architecture, University of Bremen, Bremen, Germany; Department of Medicine, Division of Infectious Diseases and Immunology, New York University Grossman School of Medicine, New York, NY, USA; AI Research Section, Digital Institute, Stockholm, Sweden; Department of Business Management and Analytics, Arcada University of Applied Sciences, Helsinki, Finland; Department of Medical and Surgical Specialties, Radiological Sciences, and Public Health, University of Brescia, Brescia, Italy; Ethique Groupe, SNCF Reseau SA, La Plaine, France; Institute of Diagnostic and Interventional Radiology, University Hospital Zurich, Zürich, Switzerland; Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands; Data Privacy Advisor, Ericsson, Stockholm, Sweden; Department of Cardiology, 4th Gliwice Municipal Hospital, Gliwice, Poland; Z-Inspection® Initiative, Frankfurt, Germany; Center for the Study of Ethics in the Professions, Illinois Institute of Technology, Chicago, IL, USA; Department of Food and Resource Economics, University of Copenhagen, Copenhagen, Denmark; Department of Physiology, Faculty of Medicine, University of Iceland, Reykjavik, Iceland; Cyber Policy Center, Stanford University, Stanford, CA, USA; Department for Dermatology, Hautmedizin Bad Soden, Bad Soden, Germany; Data Science Department, Scuola Normale Superiore, Pisa, Italy; Department of Neurosurgery, the QUEST Centre for Responsible Research, Charité Lab for Artificial Intelligence in Medicine, Berlin Institute of Health at Charité, Charité Universitätsmedizin Berlin, Berlin, Germany; Department of Medical Informatics, Erasmus University Medical Center, Rotterdam, The Netherlands; CADS Department, Syngenta, Research Triangle Park, NC, USA; Z-Inspection® Initiative, Frankfurt, Germany; Policy Research, The Lisbon Council, Brussels, Belgium; Department of Translational Research, Academic Radiology, University of Pisa, Pisa, Italy; Department of Clinical Neuroscience, Center for Psychiatry Research, Karolinska Institutet, Stockholm, Sweden; Department of Medicine, The University of Cambridge, Addenbrooke’s Hospital, Cambridge, U.K.; Department of Computer Science, University of Pisa, Pisa, Italy; Department of Population Health, Division of Medical Ethics, NYU Grossman School of Medicine, New York, NY, USA; Institute of Information Science and Technologies, National Research Council of Italy (CNR), Pisa, Italy; School of Healthcare and Social Work, Seinäjoki University of Applied Sciences, Seinäjoki, Finland; Law Department, European University Institute, Firenze, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Department of Information Engineering, University of Brescia, Brescia, Italy; Advanced Analytics, Finnish Tax Administration, Helsinki, Finland; Artificial Intelligence Research, AI for Good Foundation, El Cerrito, CA, USA; Data Services Function in Roche Diagnostics, Roche, Pune, India; Digital Systems, NORCE Norwegian Research Centre AS, Bergen, Norway; School of Research, Swinburne University of Technology (Sarawak), Kuching, Malaysia; Parallel Computing Labs, Intel, Santa Clara, CA, USA; Department of Psychology and Speech- Language Pathology, University of Turku, Turku, Finland; Department of Values, Technology and Innovation, Delft University of Technology, Delft, The Netherlands; Department of Medical and Surgical Specialties, Radiological Sciences, and Public Health, University of Brescia, Brescia, Italy; Computational Vision and Artificial Intelligence Lab, Goethe University Frankfurt, Frankfurt, Germany; Department of Business Management and Analytics, Arcada University of Applied Sciences, Helsinki, Finland; T. H. Chan School of Public Health, Harvard University, Boston, MA, USA; Department of Business Management and Analytics, Arcada University of Applied Sciences, Helsinki, Finland","IEEE Transactions on Technology and Society","15 Dec 2022","2022","3","4","272","289","This article’s main contributions are twofold: 1) to demonstrate how to apply the general European Union’s High-Level Expert Group’s (EU HLEG) guidelines for trustworthy AI in practice for the domain of healthcare and 2) to investigate the research question of what does “trustworthy AI” mean at the time of the COVID-19 pandemic. To this end, we present the results of a post-hoc self-assessment to evaluate the trustworthiness of an AI system for predicting a multiregional score conveying the degree of lung compromise in COVID-19 patients, developed and verified by an interdisciplinary team with members from academia, public hospitals, and industry in time of pandemic. The AI system aims to help radiologists to estimate and communicate the severity of damage in a patient’s lung from Chest X-rays. It has been experimentally deployed in the radiology department of the ASST Spedali Civili clinic in Brescia, Italy, since December 2020 during pandemic time. The methodology we have applied for our post-hoc assessment, called Z-Inspection®, uses sociotechnical scenarios to identify ethical, technical, and domain-specific issues in the use of the AI system in the context of the pandemic.","2637-6415","","10.1109/TTS.2022.3195114","European Union’s Horizon 2020 Research and Innovation Program(grant numbers:777107 (PRECISE 4Q)); ERC Advanced through XAI Science and Technology for the Explanation of AI Decision Making(grant numbers:2018-834756); European Union’s Horizon 2020 Research and Innovation Program(grant numbers:101016233 (PERISCOPE)); Wellcome Trust(grant numbers:206194); European Union’s Justice Programme (2014– 2020) through the H2020 ERC Project “CompuLaw”(grant numbers:833647); Italian Ministry of University and Research (“ResponsiX: Responsible and Deployable AI-Driven Evaluation of COVID- 19 Disease Severity on Chest X-Rays”)(grant numbers:FISR2020IP_02278); European Union’s Horizon 2020 Research and Innovation Program(grant numbers:101016233 (PERISCOPE)); Connecting Europe Facility of the European Union(grant numbers:INEA/CEF/ICT/A2020/2276680 (xAIM)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9845195","Artificial intelligence;case study;COVID-19;ethical tradeoff;ethics;explainable AI;healthcare;pandemic;radiology;trust;trustworthy AI;Z-Inspection®","Artificial intelligence;COVID-19;Pandemics;Medical services;Ethics;Radiology;Lung;Deep learning","","11","","38","CCBYNCND","29 Jul 2022","","","IEEE","IEEE Journals"
"A New Markov Decision Process Based Behavioral Prediction System for Airborne Crews","Y. Zhang; K. Yao; J. Zhang; F. Jiang; M. Warren","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Centre for Cyber Security Research and Innovation (CSRI), Deakin University, Geelong, Australia; Centre for Cyber Security Research and Innovation (CSRI), Deakin University, Geelong, Australia","IEEE Access","13 Feb 2020","2020","8","","28021","28032","In order to ensure the normal and stable flights in the aircraft, a variety of sensors and corresponding instrumentation systems have been applied on the aircraft to monitor/control the current flight status, and the resulted data ensure the flight safety with a heavy burden on the pilot. In views of this, nowadays, the aircraft cockpit automation assistance system has become a hot topic. This paper is based on the pilot's future operational behavior which can be predicted through different stages of flight operations after the automated assistance system is triggered, thus providing the pilot with assistance in accordance with his operating habits. We have established a MDP (Markov Decision Process) model via analyzing and modeling of pilot operational behavior and mission requirements for flight processes, and we also use value iterative algorithm to find the optimal prediction sequence, lastly, we verify the operability of the algorithm by flight operation simulation experiment. It provides a new solution for the safety of pilot operations and the intrusiveness of the cockpit adaptive automation assistance system.","2169-3536","","10.1109/ACCESS.2019.2961239","Aeronautical Science Foundation of China(grant numbers:2017ZC53033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937552","Cockpit automation assistance;Markov decision process;behavioral prediction","Automation;Aircraft;Markov processes;Safety;Accidents;Predictive models;Atmospheric modeling","","1","","23","CCBY","20 Dec 2019","","","IEEE","IEEE Journals"
"Keynote: Algorithmic Targeting of Social Policies: Fairness, Accuracy, and Distributed Governance","A. N. Campero","Human Dynamics, Media Lab, MIT, USA","2020 Seventh International Conference on eDemocracy & eGovernment (ICEDEG)","1 Jul 2020","2020","","","14","14","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and wide-spread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them - and who is not - are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.","2573-1998","978-1-7281-5882-2","10.1109/ICEDEG48599.2020.9096679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096679","","Artificial intelligence;Statistics;Standards;Sociology;Media;Interviews;Industries","","","","","IEEE","1 Jul 2020","","","IEEE","IEEE Conferences"
"Traffic Analytics Development Kits (TADK): Enable Real-Time AI Inference in Networking Apps","K. Qiu; H. Chang; Y. Wang; X. Yu; W. Zhu; Y. Liu; J. Ma; W. Li; X. Liu; S. Dai",Intel Corporation; Intel Corporation; Intel Corporation; Intel Corporation; Intel Corporation; Intel Corporation; Intel Corporation; Intel Corporation; ZTE Corporation; ZTE Corporation,"2022 Thirteenth International Conference on Ubiquitous and Future Networks (ICUFN)","20 Jul 2022","2022","","","392","398","Sophisticated traffic analytics, such as the encrypted traffic analytics and unknown malware detection, emphasizes the need for advanced methods to analyze the network traffic. Traditional methods of using fixed patterns, signature matching, and rules to detect known patterns in network traffic are being replaced with AI (Artificial Intelligence) driven algorithms. However, the absence of a high-performance AI networking-specific framework makes deploying real-time AI-based processing within networking workloads impossible. In this paper, we describe the design of Traffic Analytics Development Kits (TADK), an industry-standard framework specific for AI-based networking workloads processing. TADK can provide real-time AI-based networking workload processing in networking equipment from the data center out to the edge without the need for specialized hardware (e.g., GPUs, Neural Processing Unit, and so on). We have deployed TADK in commodity WAF and 5G UPF, and the evaluation result shows that TADK can achieve a throughput up to 35.3Gbps per core on traffic feature extraction, 6.5Gbps per core on traffic classification, and can decrease SQLi/XSS detection down to 4.5µs per request with higher accuracy than fixed pattern solution.","2165-8536","978-1-6654-8550-0","10.1109/ICUFN55119.2022.9829628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829628","","5G mobile communication;Scalability;Telecommunication traffic;Feature extraction;Throughput;Real-time systems;Malware","","","","33","IEEE","20 Jul 2022","","","IEEE","IEEE Conferences"
"Security considerations for the procurement and acquisition of Artificial Intelligence (AI) systems","P. Kieseberg; C. Buttinger; L. Kaltenbrunner; M. Temper; S. Tjoa","Institute of IT Security Research, St. Pölten University of Applied Sciences, St. Pölten, Austria; Austrian Armed Forces, Vienna, Austria; Institute of IT Security Research, St. Pölten University of Applied Sciences, St. Pölten, Austria; Institute of IT Security Research, St. Pölten University of Applied Sciences, St. Pölten, Austria; Institute of IT Security Research, St. Pölten University of Applied Sciences, St. Pölten, Austria","2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","14 Sep 2022","2022","","","1","7","Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.","1558-4739","978-1-6654-6710-0","10.1109/FUZZ-IEEE55066.2022.9882675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882675","Artificial Intelligence;AI;Security;Procurement;AI Act;High Risk AI;Compliance","Procurement;Ecosystems;Regulation;Security;Risk management;Artificial intelligence;Faces","","","","19","IEEE","14 Sep 2022","","","IEEE","IEEE Conferences"
"Optimization of Dominance Testing in Skyline Queries Using Decision Trees","J. -H. Choi; F. Hao; Y. -S. Kim; A. Nasridinov","Bigdata Research Institute, Chungbuk National University, Cheongju, South Korea; Department of Computer Science, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, U.K.; Department of Artificial Intelligence, Inha University, Incheon, South Korea; Bigdata Research Institute, Chungbuk National University, Cheongju, South Korea","IEEE Access","27 Sep 2021","2021","9","","130170","130184","Skyline queries identify skyline points, the minimal set of data points that dominate all other data points in a large dataset. The main challenge with skyline queries is executing the skyline query in the shortest possible time. To address and solve skyline query performance issues, we propose a decision tree-based method known as the decision tree-based comparator (DC). This method minimizes unnecessary dominance tests (i.e., pairwise comparisons) by constructing a decision tree based on the dominance testing. DC uses dominance relations that can be obtained from the decision rules of the decision tree to determine incomparability between data points. DC can also be easily applied to improve the performance of various existing skyline query methods. After describing the theoretical background of DC and applying it to existing skyline queries, we present the results of various experiments showing that DC can improve skyline query performance by up to 23.15 times.","2169-3536","","10.1109/ACCESS.2021.3113697","Institute of Information and Communications Technology Planning and Evaluation (IITP) grant; Korean Government (MSIT), Development of 5G-Based Predictive Visual Security Technology for Preemptive Threat Response(grant numbers:2019-0-00203); Industrial Strategic Technology Development Program, Development of Korean Wave Convergence Service for AI-Based Motion Evaluation and Learning Technology; Ministry of Trade, Industry and Energy (MOTIE), South Korea(grant numbers:200003991); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540863","Database;decision tree;incomparability;query processing;skyline query","Decision trees;Testing;Sorting;Query processing;Entropy;Limiting","","","","34","CCBYNCND","17 Sep 2021","","","IEEE","IEEE Journals"
"Exploring customer behavior and enhanced revenue generation in e-commerce using interpretable and explainable artificial intelligence","S. Azad","Excelinnova Consultancy Services Pvt Ltd, New Delhi, India","8th International Conference on Computing in Engineering and Technology (ICCET 2023)","31 Aug 2023","2023","2023","","324","332","We live in a world whose rules and procedures are governed by rich data and algorithms. For example, there are certain rules as who to qualify for credit and whose social media posts or account get censored. Black-Box algorithms make forecasting based on large volume of training data and these model often demonstrate higher accuracy compared to other ML/DL Model and bring low degree of confidence to the end user of AI System. Oftentimes, these Black-Box models are not capable of providing a justification or proper reasoning to the predicted output by the Model. For high stake decision for of e-commerce industry such as purchasing intention of end user, top management wants to know exactly why Black-Box system chose to show no purchasing intention for a particular customer based on training data. Unfortunately, it is difficult for e-commerce owner to fully understand black-box output based on skewed training data, input errors and unintended biases captured while building black-box system, even the developers of this black-box system does not have ideas of internal functionality of black-box model. Due to GDPR data regulation, there is a growing concern in the field of explainable artificial intelligence to explain the classification rules and procedures behind the final feature recommendations and final prediction.","","978-1-83953-917-6","10.1049/icp.2023.1511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235862","","","","","","","","31 Aug 2023","","","IET","IET Conferences"
"Advancing Industrial Analytics Using Machine Learning (ML) and Mathematical Optimization","S. Rajagopalan; S. S. Iyer",The Dow Chemical Company; The Dow Chemical Company,"2022 American Control Conference (ACC)","5 Sep 2022","2022","","","1065","1065","Machine Learning (ML) models offer a convenient framework to gather insights and deploy sustainable Artificial Intelligence (AI) enabled solutions to empower industrial analytics. Moreover, ML models have wide adoption across researchers from multiple disciplines. However, direct application of ML models may be restrictive in enforcing certain physics or operations-based rules. Augmenting ML models with model-based optimization tools, which can include constraints and rules through mathematical programming, can significantly improve the prescriptive nature and adaptability of such ML models .","2378-5861","978-1-6654-5196-3","10.23919/ACC53348.2022.9867615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9867615","","Adaptation models;Analytical models;Machine learning;Mathematical models;Optimization;Physics;Mathematical programming","","","","0","","5 Sep 2022","","","IEEE","IEEE Conferences"
"Experimental Analysis of Trustworthy In-Vehicle Intrusion Detection System Using eXplainable Artificial Intelligence (XAI)","H. Lundberg; N. I. Mowla; S. F. Abedin; K. Thar; A. Mahmood; M. Gidlund; S. Raza","Department of Information Systems & Technology, Mid Sweden University, Sundsvall, Sweden; RISE, Lindholmspiren 3A, Gothenburg, Sweden; Department of Information Systems & Technology, Mid Sweden University, Sundsvall, Sweden; Department of Information Systems & Technology, Mid Sweden University, Sundsvall, Sweden; Department of Information Systems & Technology, Mid Sweden University, Sundsvall, Sweden; Department of Information Systems & Technology, Mid Sweden University, Sundsvall, Sweden; RISE, Lindholmspiren 3A, Gothenburg, Sweden","IEEE Access","4 Oct 2022","2022","10","","102831","102841","Anomaly-based In-Vehicle Intrusion Detection System (IV-IDS) is one of the protection mechanisms to detect cyber attacks on automotive vehicles. Using artificial intelligence (AI) for anomaly detection to thwart cyber attacks is promising but suffers from generating false alarms and making decisions that are hard to interpret. Consequently, this issue leads to uncertainty and distrust towards such IDS design unless it can explain its behavior, e.g., by using eXplainable AI (XAI). In this paper, we consider the XAI-powered design of such an IV-IDS using CAN bus data from a public dataset, named “Survival”. Novel features are engineered, and a Deep Neural Network (DNN) is trained over the dataset. A visualization-based explanation, “VisExp”, is created to explain the behavior of the AI-based IV-IDS, which is evaluated by experts in a survey, in relation to a rule-based explanation. Our results show that experts’ trust in the AI-based IV-IDS is significantly increased when they are provided with VisExp (more so than the rule-based explanation). These findings confirm the effect, and by extension the need, of explainability in automated systems, and VisExp, being a source of increased explainability, shows promise in helping involved parties gain trust in such systems.","2169-3536","","10.1109/ACCESS.2022.3208573","European Union (EU) H2020 nIoVE(grant numbers:833742); Cybersecurity KP project, and by the VINNOVA Fordonsstrategisk Forskning och Innovation (FFI) Project CyReV (Phase 2); Knowledge Foundation Sweden (KKS) Research Profile Next Generation Industrial IoT (NIIT) and by MERIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9899390","Automotive;intrusion detection system;machine learning;deep learning;XAI;trustworthiness","Artificial intelligence;Intrusion detection;Automotive engineering;Behavioral sciences;Random forests;Deep learning;Trust management","","8","","42","CCBYNCND","22 Sep 2022","","","IEEE","IEEE Journals"
"Artificial Intelligence-Based Techniques for Emerging Heterogeneous Network: State of the Arts, Opportunities, and Challenges","X. Wang; X. Li; V. C. M. Leung","Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada","IEEE Access","20 May 2017","2015","3","","1379","1391","Recently, mobile networking systems have been designed with more complexity of infrastructure and higher diversity of associated devices and resources, as well as more dynamical formations of networks, due to the fast development of current Internet and mobile communication industry. In such emerging mobile heterogeneous networks (HetNets), there are a large number of technical challenges focusing on the efficient organization, management, maintenance, and optimization, over the complicated system resources. In particular, HetNets have attracted great interest from academia and industry in deploying more effective solutions based on artificial intelligence (AI) techniques, e.g., machine learning, bio-inspired algorithms, fuzzy neural network, and so on, because AI techniques can naturally handle the problems of large-scale complex systems, such as HetNets towards more intelligent and automatic-evolving ones. In this paper, we discuss the state-of-the-art AI-based techniques for evolving the smarter HetNets infrastructure and systems, focusing on the research issues of self-configuration, self-healing, and self-optimization, respectively. A detailed taxonomy of the related AI-based techniques of HetNets is also shown by discussing the pros and cons for various AI-based techniques for different problems in HetNets. Opening research issues and pending challenges are concluded as well, which can provide guidelines for future research work.","2169-3536","","10.1109/ACCESS.2015.2467174","Canadian Natural Sciences and Engineering Research Council(grant numbers:RGPIN-2014-06119,RGPAS-462031-2014); Chinese Scholarship Council through the Four-Year Post-Graduate Scholarship; National Natural Science Foundation of China(grant numbers:61271182); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7185326","Artificial Intelligence;Genetic Algorithms;Ant Colony Optimization;Self-Organization Networks;Heterogeneous Networks;Artificial intelligence;genetic algorithms;ant colony optimization;self-organization networks;heterogeneous networks","Mobile communication;Genetic algorithms;Ant colony optimization;Artificial intelligence;Heterogeneous networks;Biological system modeling;Complexity theory;Neural networks","","124","","92","OAPA","11 Aug 2015","","","IEEE","IEEE Journals"
"Application of Artificial Intelligence in Predicting Earthquakes: State-of-the-Art and Future Challenges","M. H. A. Banna; K. A. Taher; M. S. Kaiser; M. Mahmud; M. S. Rahman; A. S. M. S. Hosen; G. H. Cho","Department of Information and Communication Technology, Bangladesh University of Professionals, Dhaka, Bangladesh; Department of Information and Communication Technology, Bangladesh University of Professionals, Dhaka, Bangladesh; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Department of Computer Science, Nottingham Trent University, Nottingham, U.K.; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, South Korea; Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, South Korea","IEEE Access","29 Oct 2020","2020","8","","192880","192923","Predicting the time, location and magnitude of an earthquake is a challenging job as an earthquake does not show specific patterns resulting in inaccurate predictions. Techniques based on Artificial Intelligence (AI) are well known for their capability to find hidden patterns in data. In the case of earthquake prediction, these models also produce a promising outcome. This work systematically explores the contributions made to date in earthquake prediction using AI-based techniques. A total of 84 scientific research papers, which reported the use of AI-based techniques in earthquake prediction, have been selected from different academic databases. These studies include a range of AI techniques including rule-based methods, shallow machine learning and deep learning algorithms. Covering all existing AI-based techniques in earthquake prediction, this article provides an account of the available methodologies and a comparative analysis of their performances. The performance comparison has been reported from the perspective of used datasets and evaluation metrics. Furthermore, using comparative analysis of performances the paper aims to facilitate the selection of appropriate techniques for earthquake prediction. Towards the end, it outlines some open challenges and potential research directions in the field.","2169-3536","","10.1109/ACCESS.2020.3029859","Information and Communication Technology Division of the Government of the People’s Republic of Bangladesh(grant numbers:19FS12048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218936","AI;deep learning;earthquake;machine learning;review","Earthquakes;Neural networks;Predictive models;Machine learning;Prediction algorithms;Earth","","50","","117","CCBY","9 Oct 2020","","","IEEE","IEEE Journals"
"A comparison between PLSR, SVMR and NARX network for the mint treatment day prediction based on multisensor system","A. Amkor; N. E. Barbri; K. Maaider","Laboratory of Sciences and Techniques for the Engineer (LaSTI), National School of applied sciences (ENSA), Khouribga, Morrocco; Laboratory of Sciences and Techniques for the Engineer (LaSTI), National School of applied sciences (ENSA), Khouribga, Morrocco; Laboratory of Sciences and Techniques for the Engineer (LaSTI), National School of applied sciences (ENSA), Khouribga, Morrocco","2021 7th International Conference on Optimization and Applications (ICOA)","31 May 2021","2021","","","1","5","The ability to distinguish between edible aromatic plants treated with insecticides holds the attention of researchers in view of the toxicity of insecticides in human health. The malathion has a distinctive smell it an insecticide widely used to protect mint crops. In the present paper, three regression and artificial intelligence (AI)-based methods such as partial least squares (PLS) regression, support vector machine (SVM) regression, and the nonlinear autoregressive with exogenous input (NARX) were investigated to predict the mint treatment day with malathion. The data used in this work are collected using a multi-sensor system designed based on commercial gas sensors. In this case, the nonlinear autoregressive with exogenous input (NARX) was found the most effective achieving a correlation coefficient (R) of 0.99 with a very minimal mean squared error (MSE) of about 1.10288e-14. Thanks to the right choice of the appropriate algorithm, the mint treatment day could be predicted with a simple multisensor gas array.","","978-1-6654-4103-2","10.1109/ICOA51614.2021.9442652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442652","PLS Regression;SVM Regression;NARX Network;artificial intelligence (AI)","Support vector machines;Correlation coefficient;Toxicology;Prediction algorithms;Agriculture;Artificial intelligence;Optimization","","3","","19","IEEE","31 May 2021","","","IEEE","IEEE Conferences"
"Cooperative Traffic Control where Autonomous Cars Meet Human Drivers","A. Ghosh; S. Huang","Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, Florida, USA; Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, Florida, USA","2019 SoutheastCon","5 Mar 2020","2019","","","1","6","Co-adaptive system is a close coupling between human and software system cooperating to achieve shared goals. This co-adaption requires adaptive actions to react to unpredictable circumstances. One of the challenges is to deal with uncertainties, and consequently, decision making under uncertainty, which may arise because of the change in the environment, the unpredictable resources, etc. Human behavior does contribute to large amounts of uncertainty. This paper presents an approach for using a simulator as a means of feedback to a human's decision under uncertainty that can assist human in automated planning to generate cooperative and symbiotic strategy of human and the system to achieve given tasks. To validate the approach, this paper presents a customizable traffic simulator to measure the delays associated with passing vehicles through intersections. The simulator contains AI-based self-adaptive vehicles which can evaluate the quality of traffic at an intersection and change their driving behavior. The human operator from the outside of the system can manipulate the signaling time, the number of predicates per driving rule, number of rules per rule set, learning factor (adaption) etc. to overcome any unexpected traffic. This research proves that our simulator is more efficient than the individual human-operated and automated traffic system and makes a true cooperative traffic example.","1558-058X","978-1-7281-0137-8","10.1109/SoutheastCon42311.2019.9020663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020663","Self-adaptive;co-adaptive;cooperative;human-computer interface;Reinforcement Learning;AI.","Automobiles;Delays;Uncertainty;Protocols;Roads;Software systems","","1","","20","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"A User-Centered Design of Natural Language Processing for Maternal Monitoring Chatbot System","S. H. Afrizal; N. Hakiem; A. Erna Permanasari; H. Syaifullah Albab; G. Yoki Sanjaya; L. Lazuardi","Department of Health Policy and Management, Universitas Gadjah Mada, Jakarta, Indonesia; Department of Informatics, Universitas Islam Negeri Syarif Hidayatullah, Jakarta, Indonesia; Department of Electrical Engineering and Information Technology, Universitas Gadjah Mada, Yogyakarta, Indonesia; Department of Informatics, Universitas Islam Negeri Syarif Hidayatullah, Jakarta, Indonesia; Department of Health Policy and Management, Universitas Gadjah Mada, Jakarta, Indonesia; Department of Health Policy and Management, Universitas Gadjah Mada, Jakarta, Indonesia","2022 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)","20 Jan 2023","2022","","","244","248","A self-monitoring device and remote counseling system for pregnant mothers using interactive chat is an effective method due to the reduction of maternal care visits caused during the pandemic. The employment of an artificial intelligence (AI) based system using natural language processing (NLP) for decision support has prospectively enhanced the conversational access of patient to improve health awareness and knowledge. This research was conducted to develop an AI-based system which focuses on education and monitoring with regard to danger signs during pregnancy using NLP. The Telegram chatbot was used to develop the system after investigating user needs based on the danger sign monitoring guideline from WHO and the Ministry of Health of the Republic of Indonesia. The inputs from users were recognized by NLP and forwarded to the testing data for decision system. Furthermore, the analysis result was sent to the user which provides educational information and a personalized monitoring result. System Usability Scale (SUS) was undertaken to assess the user ability to use the application. The SUS score average for the chatbot system was 62.3 which was classified as “OK” for the adjective ratings. The implication of the maternal monitoring using a chatbot system is the improvement of maternal care with regard to early detection of danger signs and relevant suggestions using an effective and interactive system which could be very promising especially in a limited healthcare resource environment.","","978-1-6654-7327-9","10.1109/ICIMCIS56303.2022.10017517","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017517","Danger signs;pregnancy;natural language processing;interactive chat;chatbot","Pregnancy;Pandemics;Multimedia systems;User centered design;Medical services;Chatbots;Artificial intelligence","","1","","25","IEEE","20 Jan 2023","","","IEEE","IEEE Conferences"
"AI in Blockchain Towards Realizing Cyber Security","R. Salama; F. Al-Turjman","Department of Computer Engineering, AI and Robotics Institute, Research Center for AI and IoT, Near East University, Nicosia, Mersin 10, Turkey; Artificial Intelligence Engineering Dept., AI and Robotics Institute, Near East University, Nicosia, Mersin 10, Turkey","2022 International Conference on Artificial Intelligence in Everything (AIE)","26 Sep 2022","2022","","","471","475","Blockchain and artificial intelligence are two technologies that, when combined, have the ability to help each other realize their full potential. Blockchains can guarantee the accessibility and consistent admittance to integrity safeguarded big data indexes from numerous areas, allowing AI systems to learn more effectively and thoroughly. Similarly, artificial intelligence (AI) can be used to offer new consensus processes, and hence new methods of engaging with Blockchains. When it comes to sensitive data, such as corporate, healthcare, and financial data, various security and privacy problems arise that must be properly evaluated. Interaction with Blockchains is vulnerable to data credibility checks, transactional data leakages, data protection rules compliance, on-chain data privacy, and malicious smart contracts. To solve these issues, new security and privacy-preserving technologies are being developed. AI-based blockchain data processing, either based on AI or used to defend AI-based blockchain data processing, is emerging to simplify the integration of these two cutting-edge technologies.","","978-1-6654-7400-9","10.1109/AIE57029.2022.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9898694","blockchain;Internet of Things (IoT);artificial intelligence;Cyber Security","Industries;Smart contracts;Education;Medical services;Data processing;Blockchains;Safety","","11","","20","IEEE","26 Sep 2022","","","IEEE","IEEE Conferences"
"Artificial Intelligence-Based Surveillance System for Railway Crossing Traffic","P. Sikora; L. Malina; M. Kiac; Z. Martinasek; K. Riha; J. Prinosil; L. Jirik; G. Srivastava","Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Telecommunications, Brno University of Technology, Brno, Czech Republic; Department of Mathematics and Computer Science, Brandon University, Brandon, Canada","IEEE Sensors Journal","15 Jul 2021","2021","21","14","15515","15526","The application of Artificial Intelligence (AI) based techniques has strong potential to improve safety and efficiency in data-driven Intelligent Transportation Systems (ITS) as well as in the emerging Internet of Vehicles (IoV) services. This paper deals with the practical implementation of deep learning methods for increasing safety and security in a specific ITS scenario: railway crossings. This research work presents our proposed system called Artificial Intelligence-based Surveillance System for Railway Crossing Traffic (AISS4RCT) that is based on a combination of detection and classification methods focusing on various image processing inputs: vehicle presence, pedestrian presence, vehicle trajectory tracking, railway barriers at railway crossings, railway warnings, and light signaling systems. The designed system uses cameras that are suitably positioned to capture an entire crossing area at a given railway crossing. By employing GPU accelerated image processing techniques and deep neural networks, the system autonomously detects risky and dangerous situations at railway crossing in real-time. In addition, camera modules send data to a central server for further processing as well as notification to interested parties (police, emergency services, railway operators). Furthermore, the system architecture employs privacy-by-design and security-by-design best practices in order to secure all communication interfaces, protect personal data, and to increase personal privacy, i.e., pedestrians, drivers. Finally, we present field-based results of detection methods, and using the YOLO tiny model method we achieve average recall 89%. The results indicate that our system is efficient for evaluating the occurrence of objects and situations, and it's practicality for use in railway crossings.","1558-1748","","10.1109/JSEN.2020.3031861","Czech Ministry of Industry and Trade (MPO)(grant numbers:FV40372); Natural Sciences Research Council of Canada (NSERC) Discovery Grant Program(grant numbers:RGPIN-2020-05363); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226453","Artificial intelligence;image processing;intelligent transportation system;object detection;railway crossing barrier;safety;security;traffic light","Rail transportation;Detectors;Feature extraction;Safety;Deep learning","","24","","54","IEEE","16 Oct 2020","","","IEEE","IEEE Journals"
"SHAPES Project Pilots' Self-assessment for Trustworthy AI","J. Rajamäki; P. A. Lebre Rocha; M. Perenius; F. Gioulekas","Laurea University of Applied Sciences, Espoo, Finland; Department of Behavioural Sciences, University of Porto, Porto, Portugal; Laurea University of Applied Sciences, Espoo, Finland; 5th Regional Health Authority of Thessaly & Sterea, Larissa, Greece","2022 12th International Conference on Dependable Systems, Services and Technologies (DESSERT)","30 Jan 2023","2022","","","1","7","The Assessment List for Trustworthy AI (ALTAI) was developed by the High-Level Expert Group on Artificial Intelligence (AI HLEG) set up by the European Commission to help assess whether the AI system that is being developed, deployed, procured, or used, complies with the seven requirements of Trustworthy AI, as specified in the AI HLEG's Ethics Guidelines for Trustworthy AI. This paper describes the self-evaluation process of the SHAPES pilot campaign and presents some individual case results applying the prototype of an interactive version of the Assessment List for Trustworthy AI. Finally, the available results of two individual cases are combined. The best results are obtained from the evaluation category ‘transparency’ and the worst from ‘technical robustness and safety’. Future work will be combining the missing self-assessment results and developing mitigation recommendations for AI-based risk reduction recommendations for new SHAPES services.","","979-8-3503-3304-6","10.1109/DESSERT58054.2022.10018790","European Union's Horizon 2020(grant numbers:857159); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10018790","SHAPES Project;Trustworthy AI;Assessment List for Trustworthy AI;ALTAI;Artificial Intelligence;Self-assessment","Ethics;Shape;Prototypes;Europe;Organizations;Data transfer;Robustness","","1","","15","IEEE","30 Jan 2023","","","IEEE","IEEE Conferences"
"Management of Information Support and Automation of Energy Systems based on Artificial Intelligence","Y. Viedienina; L. Sakun; K. Mazharenko; M. Kovalenko","Management Department Kremenchuk Mykhailo Ostrohradskyi, National University, Kremenchuk, Ukraine; Management Department Kremenchuk Mykhailo Ostrohradskyi, National University, Kremenchuk, Ukraine; Management Department Kremenchuk Mykhailo Ostrohradskyi, National University, Kremenchuk, Ukraine; Management Department Kremenchuk Mykhailo Ostrohradskyi, National University, Kremenchuk, Ukraine","2023 IEEE 5th International Conference on Modern Electrical and Energy System (MEES)","29 Jan 2024","2023","","","1","6","This article investigates the impact of artificial intelligence (AI) on information support and automation in energy systems. It adopts a multi-method approach, combining literature review, case studies, and data analysis to explore various AI techniques and their applications in the energy sector. The findings show that AI-based tools can enhance the prediction, optimization, extraction, analysis, and recommendation of energy-related data, leading to improved efficiency, reliability, and sustainability of energy systems. The article also discusses AI technologies such as deep learning, reinforcement learning, and Internet of Things (IoT) integration, which offer novel opportunities for information support and automation in the energy sector. The article provides practical recommendations on the implementation of AI tools in energy systems, highlighting best practices and key considerations.","","979-8-3503-5978-7","10.1109/MEES61502.2023.10402493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402493","artificial intelligence;information support;automation;energy systems;smart energy","Deep learning;Automation;Reinforcement learning;Reliability;Internet of Things;Artificial intelligence;Optimization","","","","29","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Introduction to AI Assurance for Policy Makers","L. Biersmith; P. Laplante","Graduate School of Public Policy, University of Maryland, College Park, USA; Engineering Penn State, Malvem, USA","2022 IEEE 29th Annual Software Technology Conference (STC)","18 Nov 2022","2022","","","51","56","The deployment of artificial intelligence (AI) applications has accelerated faster than most scientists, policymakers and business leaders could have predicted. AI enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risk either in the form of physical injury or unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective and requires oversight, therefore depending on experts opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations.While not comprehensive, this work provides an overview of AI legislation and directives at the international, U.S. state and federal levels. It also covers business standards, and technical society initiatives. This work can serve as a resource for policymakers and other key stakeholders and an entry point to their understanding of AI policy.","","978-1-6654-8864-8","10.1109/STC55697.2022.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951032","artificial intelligence;public policy;critical systems","Consumer products;Legislation;Software;Regulation;Stakeholders;Artificial intelligence;Standards","","","","5","IEEE","18 Nov 2022","","","IEEE","IEEE Conferences"
"Comparative assessment of cyber-physical threats to megacities","J. Dennis; C. Grady; S. Rajtmajer","College of Information Sciences and Technology, Penn State University, University Park, PA, U.S.A.; Department of Civil and Environmental, Engineering and Rock Ethics Institute Penn State University, University Park, PA, USA; Department of Civil and Environmental, Engineering and Rock Ethics Institute Penn State University, University Park, PA, USA","2021 IEEE International Symposium on Technology and Society (ISTAS)","6 Dec 2021","2021","","","1","1","By 2030, forecasts suggest that urban areas will house 60 percent of the world’s population and one in every three people will live in cities with at least half a million inhabitants. Within the same time frame, the number of global megacities is expected to jump from 33 today to 43 in 2030 [1]. Underpinning these large urban areas will be an interconnected network of critical physical infrastructures reliant on Internet-connected Industrial Control Systems and susceptible to increasingly sophisticated, e.g., AI-enabled, cyber threats. In hand, the cyber threat landscape is shifting rapidly. We are seeing a sharp rise in the number of cyberattacks on critical infrastructure [2] with significant impacts cascading across multiple sectors and causing disruption to the provisioning of essential goods and services. Security scholars suggest that these impacts are not always equitable and that disruption to critical infrastructure can affect vulnerable groups differently [3], which further emphasizes the need to improve cybersecurity between critical infrastructure sectors [4]. Through structured analysis of city statistics, demographic information, cyber incidents, and current cyber policy, our presentation will articulate potential social implications of megacity growth through the lens of cyber-physical infrastructure disruption. We investigate the largest 15 megacities in the world and find that megacities continue to grow in population but not in cyber policy. We highlight recent examples of cyber-physical disruption in Mumbai and New York City with focus on implications for vulnerable populations. Our work suggests the need for future research on social responsibility regarding security of these critical infrastructure sectors and on the need for technology-focused law, policy, and regulation guidelines.","2158-3412","978-1-6654-3580-2","10.1109/ISTAS52410.2021.9629170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629170","critical infrastructure;urbanization;megacities;interconnectivity;interdependency;cyberattacks","Industrial control;Urban areas;Sociology;Regulation;Critical infrastructure;Statistics;Computer crime","","","","4","IEEE","6 Dec 2021","","","IEEE","IEEE Conferences"
"A Behavioral Chatbot Using Encoder-Decoder Architecture : Humanizing conversations","T. Jalaja; D. T. Adilakshmi; M. S. Sharat Chandra; M. Imran Mirza; M. Kumar","Department of CSE, VCE; Department of CSE, VCE; Department of CSE, Vasavi College of Engineering; Department of CSE, Vasavi College of Engg.; Department of CSE, VCE","2022 Second International Conference on Interdisciplinary Cyber Physical Systems (ICPS)","10 Nov 2022","2022","","","51","54","Though there are so many ways of building conversational chatbots, they lack the human touch and sound very robotic. We don’t have any chatbots that aim to imitate even a speck of a personality or human-like traits, while we very well possess everything that we need in terms of data and computation. This project aims to make both efficient and human-like chatbot using the modern encoder-decoder architecture. There are many frameworks and libraries available to develop AI-based chatbots including program-based, rule-based and interface-based. But they lack the flexibility in developing real dialogues and understanding humans. The popular chatbot models don’t aim to hold conversations that imitate real human-like interactions. Current chatbots employ a rule-based approach, basic machine learning algorithms, or a retrieval-based strategy that does not provide humanized outputs, i.e., these chatbots are incapable of producing engaging dialogues. In this paper, we tried to develop a Behavioural chatbot, using modern deep learning techniques like Seq2Seq aiming to develop chatbots to understand humans and make some situation agnostic conversations that remind us of our desirable personalities. This chatbot model was trained on real human conversations extracted out of Hollywood movies, hence the dataset possesses around 2.3 lakh truly organic dialogues. The model was trained with ~4.2 million parameters, 250 epochs and attained an accuracy of 95%. This chatbot is capable of displaying subtle sarcasm and also tries to be funny at times, thanks to the dramatic Hollywood dialogue writers.","","978-1-6654-7022-3","10.1109/ICPS55917.2022.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9941244","Chatbots;Seq2Seq;Encoder-Decoder;LSTM;RNN","Deep learning;Machine learning algorithms;Computational modeling;Buildings;Oral communication;Computer architecture;Chatbots","","2","","9","IEEE","10 Nov 2022","","","IEEE","IEEE Conferences"
"Practical use of Artificial Intelligence for Clinical Staff Other than Physicians","E. Hanada; K. Wada; K. Oda; K. Nishi; K. Kawazoe","Dept. Information Science, Saga University, Saga, Japan; Dept. Information Science, Saga University, Saga, Japan; Dept. of system support, Kimura Information Technology Co. Ltd., Saga, Japan; Dept. of system support, Kimura Information Technology Co. Ltd., Saga, Japan; Dept. of system support, Kimura Information Technology Co. Ltd., Saga, Japan","2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)","16 Dec 2018","2018","","","1","4","Trials to introduce artificial intelligence (AI) in clinical settings have been done for several decades, but the movement toward such introduction remains slow. In the past, AI systems were mainly to support physicians. They were ”rule-based” and specifically designed to assist in diagnosis or to recommend drugs to be prescribed to patients. Current clinical medicine is not performed by a physician acting alone, but through cooperation between staff with various occupations. Kimura Information Technology Co., Ltd. (KIT, Japan) has built a system named ”AI-Q” that works on the Japanese version of IBM's Watson and with which it is possible to build arbitrary problem solving systems. AI-Q was made to serve a variety of purposes, and a system for pharmacists has been built for drug information. In this paper, we illustrate how practical applications of AI can be designed for use by medical staff other than physicians and discuss how the system can be extended to other fields. We converted an AI system previously used to support pharmacists into one for certified clinical engineers (CCE). The purpose of this paper is to give the background of the system for CCE and to evaluate it.","2166-6822","978-1-5386-6095-9","10.1109/ICCE-Berlin.2018.8576166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576166","Artificial Intelligence;Clinical Medicine;Certified Clinical Engineers;Question and Answer System","Artificial intelligence;Medical diagnostic imaging;Maintenance engineering;Drugs;Reliability;Information technology","","1","","4","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review","F. Giuste; W. Shi; Y. Zhu; T. Naren; M. Isgut; Y. Sha; L. Tong; M. Gupte; M. D. Wang","Wallace H. Coulter School of Biomedical Engineering, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Nuclear and Radiological Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Biology, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter School of Biomedical Engineering, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Wallace H. Coulter School of Biomedical Engineering, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Wallace H. Coulter School of Biomedical Engineering, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Wallace H. Coulter School of Biomedical Engineering, Georgia Institute of Technology, Emory University, Atlanta, GA, USA","IEEE Reviews in Biomedical Engineering","5 Jan 2023","2023","16","","5","21","Despite the myriad peer-reviewed papers demonstrating novel Artificial Intelligence (AI)-based solutions to COVID-19 challenges during the pandemic, few have made a significant clinical impact, especially in diagnosis and disease precision staging. One major cause for such low impact is the lack of model transparency, significantly limiting the AI adoption in real clinical practice. To solve this problem, AI models need to be explained to users. Thus, we have conducted a comprehensive study of Explainable Artificial Intelligence (XAI) using PRISMA technology. Our findings suggest that XAI can improve model performance, instill trust in the users, and assist users in decision-making. In this systematic review, we introduce common XAI techniques and their utility with specific examples of their application. We discuss the evaluation of XAI results because it is an important step for maximizing the value of AI-based clinical decision support systems. Additionally, we present the traditional, modern, and advanced XAI models to demonstrate the evolution of novel techniques. Finally, we provide a best practice guideline that developers can refer to during the model experimentation. We also offer potential solutions with specific examples for common challenges in AI model experimentation. This comprehensive review, hopefully, can promote AI adoption in biomedicine and healthcare.","1941-1189","","10.1109/RBME.2022.3185953","Wallace H. Coulter Distinguished Faculty Fellowship; Petit Institute Faculty Fellowship; Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9804787","COVID-19;electronic health records;expla- inable artificial intelligence;explanation evaluation;explanation generation;explanation representation;medical imaging","Artificial intelligence;COVID-19;Biological system modeling;Data models;Pandemics;Training;Systematics","Humans;Artificial Intelligence;COVID-19;Pandemics;Delivery of Health Care","29","","119","CCBY","23 Jun 2022","","","IEEE","IEEE Journals"
"Curriculum and Training Development in the METIS project","B. Medgyes; B. Illés; O. Krammer; S. Tzanova; S. Gavra","Department of Electronics Technology, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Department of Electronics Technology, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Department of Electronics Technology, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Department of Microelectronics, Technical University of Sofia, Sofia, Bulgaria; SEMI Europe, Brussels, Belgium","2021 IEEE 27th International Symposium for Design and Technology in Electronic Packaging (SIITME)","6 Jan 2022","2021","","","258","263","To improve its competitiveness, the EU microelectronics area needs to overcome critical skills deficits. In this context, METIS (MicroElectronics Training, Industry and Skills) gives an individual European partnership establishing a sustainable structure to: analyze main global biases effecting on the area and offer strategic insights and foresights, predict rising skills demands, identify job rules/jobs of the future, determine important occupational profiles and observe progress in the domain of human capital for microelectronics, develop a Sector Skills Strategy to support the global leadership of the EU microelectronics industry, establishing operational linkages between skills and the future of the area, federate European synergies towards the needs of data-driven technologies such as artificial intelligence (AI) enabled by advanced microelectronics and its skills demands, establish an EU Microelectronics Observatory & Skills Council, plan and produce a modular and blended curriculum, integrating work-oriented learning that uses open education resources (OER), pave the way for the pan-European recognition of innovative Vocational Education and Training (VET), use innovative tools such as industry mentoring to facilitate inter-generational transfer of knowledge in the area, embed social (diversity & inclusion) and environmental sustainability (circular economy) subjects and EU policy aims in the development of workforce.","2642-7036","978-1-6654-2110-2","10.1109/SIITME53254.2021.9663582","Erasmus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663582","MicroElectronics;Training development;Modules;Skills","Training;Industries;Leadership;Observatories;Green products;Europe;Learning (artificial intelligence)","","1","","3","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Two-Wheeler Vehicle Traffic Violations Detection and Automated Ticketing for Indian Road Scenario","R. S. Charran; R. K. Dubey","Department of Management and Studies, Indian Institute of Science, Bengaluru, Karnataka, India; Robert Bosch Engineering and Business Solutions Private Ltd., Bengaluru, Karnataka, India","IEEE Transactions on Intelligent Transportation Systems","8 Nov 2022","2022","23","11","22002","22007","Traffic violation monitoring and control is a major concern in India due to excess crowd, increasing commuters, bad traffic signal management, and rider mentality. It is obvious that physical traffic police-based monitoring alone is insufficient to monitor such large traffic volumes and simultaneously track violations. This has led to many violators going unnoticed. The violators, in turn, cause more serious mishaps on the road resulting in danger to their own life as well as to other’s life. Thus, there is a need for incorporating Artificial Intelligence (AI)-based techniques to eliminate manual intervention for the detection and catching of violators. In this paper, we propose a system to automatically detect two-wheeler violations like not wearing a helmet, usage of a phone while riding, triple riding, wheeling, and illegal parking for Indian road scenarios and eventually automating the ticketing process by capturing the violations and corresponding vehicle number in a database. We propose using a custom trained Yolo-v4 + DeepSORT for violation detection and tracking and Yolo-v4 + Tesseract for number plate detection and extraction. This implementation obtained a mean average precision (mAP) of 98.09% for violation detection and an accuracy of 99.41% for number plate detection on the test data. Further, the system detected 77 out of 93 violations with zero false positives in real-life scenarios. Thus,showing that the traffic violation system developed can be used to automate traffic violation ticketing. The developed system would be particularly useful in deriving various safety-related policies and will help to enforce strong regulation of traffic rules and build towards a smart city ecosystem via the automated AI-based traffic violation and ticketing system.","1558-0016","","10.1109/TITS.2022.3186679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827996","Artificial intelligence (AI);detection;smart city;traffic violation","Head;Safety;Feature extraction;Object detection;Detectors;Monitoring;Roads","","14","","19","IEEE","12 Jul 2022","","","IEEE","IEEE Journals"
"Towards a Data Engineering Process in Data-Driven Systems Engineering","P. Petersen; H. Stage; J. Langner; L. Ries; P. Rigoll; C. Philipp Hohl; E. Sax","FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany; FZI Research Center for Information Technology, Germany","2022 IEEE International Symposium on Systems Engineering (ISSE)","10 Jan 2023","2022","","","1","8","Highly Automated Driving (HAD) has become one of the leading trends in the automotive industry. Mandatory tasks like environment perception and scene understanding challenge existing rule-based methods. Thus, data-driven technologies and Artificial Intelligence (AI) have been introduced to automotive software development. Utilizing data in the development process has become essential as these systems are no longer developed with classical systems engineering methods, but rather by deriving requirements from and training the algorithms with recorded real-world data. This entails the introduction of data-driven workflows and data-management as new aspects of Automotive Systems Engineering (ASE). Tasks related to the development of Artificial Intelligence (AI) software differ from their classical engineering and programming counterparts. Thus, engineers require new tools and methods for developing safe and accurate AI-based software and handling data efficiently during ASE. Another important aspect of data-driven development is ensuring data quality throughout the systems engineering process. Hence, this paper aims to take a step towards the introduction of a data engineering process in data-driven automotive systems engineering. Putting a spotlight on developing well-designed data sets as the central element for training and validating AI-based software. Besides determining the quality of data sets, we present steps towards improving data and data set quality.","2687-8828","978-1-6654-8182-3","10.1109/ISSE54508.2022.10005441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005441","automotive systems engineering;data-driven development;ai-engineering","Training;Industries;Software algorithms;Programming;Data engineering;Market research;Software","","2","","38","IEEE","10 Jan 2023","","","IEEE","IEEE Conferences"
"Dimmer: Self-Adaptive Network-Wide Flooding with Reinforcement Learning","V. Poirot; O. Landsiedel","Kiel University, Germany; Kiel University, Germany","2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)","4 Oct 2021","2021","","","293","303","The last decade saw an emergence of Synchronous Transmissions (ST) as an effective communication paradigm in low-power wireless networks. Numerous ST protocols provide high reliability and energy efficiency in normal wireless conditions, for a large variety of traffic requirements. Recently, with the EWSN dependability competitions, the community pushed ST to harsher and highly-interfered environments, improving upon classical ST protocols through the use of custom rules, hand-tailored parameters, and additional retransmissions. The results are sophisticated protocols, that require prior expert knowledge and extensive testing, often tuned for a specific deployment and envisioned scenario. In this paper, we explore how ST protocols can benefit from self-adaptivity; a self-adaptive ST protocol selects itself its best parameters to (1) tackle external environment dynamics and (2) adapt to its topology over time. We introduce Dimmer as a self-adaptive ST protocol. Dimmer builds on LWB and uses Reinforcement Learning to tune its parameters and match the current properties of the wireless medium. By learning how to behave from an unlabeled dataset, Dimmer adapts to different interference types and patterns, and is able to tackle previously unseen interference. With Dimmer, we explore how to efficiently design AI-based systems for constrained devices, and outline the benefits and downfalls of AI-based low-power networking. We evaluate our protocol on two deployments of resource-constrained nodes achieving 95.8 % reliability against strong, unknown WiFi interference. Our results outperform baselines such as non-adaptive ST protocols (~27%) and PID controllers, and show a performance close to hand-crafted and more sophisticated solutions, such as Crystal (~99 %).","2575-8411","978-1-6654-4513-9","10.1109/ICDCS51616.2021.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546507","low-power wireless networks;synchronous transmissions;reinforcement learning;deep Q-network;WSN;IoT","Protocols;Wireless networks;Interference;Reinforcement learning;Crystals;Energy efficiency;Reliability","","2","","32","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"safe.trAIn – Engineering and Assurance of a Driverless Regional Train","M. Zeller; M. Rothfelder; C. Klein","Siemens AG, Munich, Germany; Siemens AG, Munich, Germany; Siemens AG, Munich, Germany","2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN)","4 Jul 2023","2023","","","197","197","Traditional automation technologies alone are not sufficient to enable the fully automated operation of trains. However, Artificial Intelligence (AI) and Machine Learning (ML) offers great potential to realize the mandatory novel functions to replace the tasks of a human train driver, such as obstacle detection on the tracks. The problem, which still remains unresolved, is to find a practical way to link AI/ML techniques with the requirements and approval processes that are applied in the railway domain. The safe.trAIn project aims to lay the foundation for the safe use of AI/ML to achieve the driverless operation of rail vehicles and thus addresses this key technological challenge hindering the adoption of unmanned rail transport. The project goals are to develop guidelines and methods for the reliable engineering and safety assurance of ML in the railway domain. Therefore, the project investigates methods to reliable design ML models and to prove the trustworthiness of AI-based functions taking robustness, uncertainty, and transparency aspects of the AI/ML model into account.","","979-8-3503-0113-7","10.1109/CAIN58948.2023.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10164744","Driverless regional train;AI/ML engineering processes;safety approval;rail;autonomous driving","Rails;Uncertainty;Reliability engineering;Rail transportation;Robustness;Software reliability;Safety","","","","0","IEEE","4 Jul 2023","","","IEEE","IEEE Conferences"
"Practical Reinforcement Learning for Adaptive Photolithography Scheduler in Mass Production","E. Kim; T. Kim; D. Lee; H. Kim; S. Kim; J. Kim; W. Kim; E. Kim; Y. Jin; T. -E. Lee","Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Mechatronics Technology Research Center, Samsung Display Co. Ltd, 1, Samsung-ro, Yongin-si, Republic of Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea","IEEE Transactions on Semiconductor Manufacturing","","2023","PP","99","1","1","This work introduces a practical reinforcement learning (RL) techniques to address the complex scheduling challenges in producing Active Matrix Organic Light Emitting Diode displays. Specifically, we focus on autonomous optimization of the photolithography process, a critical bottleneck in the fabrication. This provides an outperforming scheduling method compared with the existing rule-based approach which requires diverse rules and engineer experience on adapting dynamic environments. Our purposing RL network was designed to make effective schedules aligning with layered structures of the planning and scheduling modules for mass production. In the training phase, historical production data is utilized to create a representative discrete event simulation environment. The RL agent, based on the Deep Q-Network, undergoes episodic training to learn optimal scheduling policies. To ensure safe and reliable scheduling decisions, we further introduce action filters and parallel competing schedulers. The performance of RL-based Scheduler (RLS) is compared to the Rule-Based Scheduler (RBS) over actual fabrication in a year-long period. Based on Key performance indicators, we validate the RLS outperforms the RBS, with a remarkable improvement in step target matching, reduced setup times, and enhanced lot assignments. This work also paves a way for the gradual integration of AI-based algorithms into smart manufacturing practices.","1558-2345","","10.1109/TSM.2023.3336909","Samsung Display Co. LTD.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10330650","active matrix light emitting diode display;photolithography;reinforcement learning;scheduling","Job shop scheduling;Manufacturing;Active matrix organic light emitting diodes;Lithography;Fabrication;Production;Backplanes","","","","","IEEE","28 Nov 2023","","","IEEE","IEEE Early Access Articles"
"An Integrated Expert System with a Supervised Machine Learning based Probabilistic Approach to Play Tic-Tac-Toe","M. S. K. Inan; R. Hasan; T. T. Prama","Dept. of Computer Science & Engineering, East Delta University, Chittagong, Bangladesh; Dept. of Computer Science & Engineering, East Delta University, Chittagong, Bangladesh; Dept. of Computer Science & Engineering, Jahangirnagar University, Dhaka, Bangladesh","2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","10 Jan 2022","2021","","","0116","0120","Tic-Tac-Toe, also known as Noughts and Crosses, is a widely popular game among people of all ages. In recent times, due to the rapid development of Artificial Intelligence (AI) based algorithms, AI in Games has become an interesting topic for research in both academia and industry. Due to the complicated yet competent nature of AI algorithms, the design and implementation of such AI-driven approaches in games are challenging and time intensive. In this regard, we propose a supervised Machine Learning (ML)-based approach that contributes in designing an innovative and less complex Tic-Tac-Toc expert system. Integrating AI and ML in the solution process will lead the concerned community toward a more lightweight and computationally efficient systems for playing games. In this study, we propose a novel algorithmic solution by combining an ensemble-based boosting approach and rule-based inference to build a probabilistic expert system that strategically chooses the best optimal move for next possible state of the game. A benchmark dataset containing 255,168 unique game states of Tic Tac Toe was utilized at training stage. The proposed strategy is able to successfully settle a draw against never-loosing MiniMax algorithm in 18 standard test cases.","","978-1-6654-0690-1","10.1109/UEMCON53757.2021.9666728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666728","noughts and crosses;machine learning in games;xgboost;tic tac toe;ai in games","Training;Machine learning algorithms;Merging;Games;Reinforcement learning;Probabilistic logic;Mobile communication","","3","","22","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"An Energy Management Strategy in Hybrid Electric Vehicles: The Present and The Future Scenario","S. G; M. N. A; S. M. K; M. P. S; G. C; S. R","Dept of Electronics and Instrumentation Engineering, Kumraguru College of Technology, Coimbatore, India; Dept of Electronics and Instrumentation Engineering, Kumraguru College of Technology, Coimbatore, India; Dept of Electronics and Instrumentation Engineering, Kumraguru College of Technology, Coimbatore, India; Dept of Electronics and Instrumentation Engineering, Kumaraguru College of Technology, Coimbatore, India; Dept of Computer and Communication Engineering, Rajalakshmi Institute of Technology, Chennai, India; Dept of Electrical and Electronics Engineering, Sri Ramakrishna College of Engineering, Coimbatore, India","2023 2nd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation (ICAECA)","7 Aug 2023","2023","","","1","5","There has been a significant increase in interest towards ""The electrification of transportation"" in the past decade. The environmental crisis caused due to global warming and the depletion of oil supplies are factors that have made the automobile sector adopt strategies to produce eco-friendly, sustainable vehicles instead of their commercial fuel propelled vehicles. Most governments have expressed their interest in alleviating the environmental impact caused due to vehicle pollution by introducing various policies that eventually help people switch to Electric Vehicles (EV). Though there has been a surge of interest among people to adopt environmentally friendly, economically affordable electric vehicles, the major concern is the state of charge and range offered by these EVs. The global automobile sector has started to invest in research dedicated to the energy management system in EVs to overcome these issues. The emergence of artificial intelligence (AI) and the advancement of control systems are clear signs for developing smart-energy management systems in EV. This paper reviews the methods of energy storage and usage in EV following the various Energy Management Systems (EMS) present in EV such as Rule-based EMS and Optimization-based EMS and its types. Also, it gives an insight into the emergence of futuristic AI-based chips that would revolutionize the energy-management system in E-vehicles.","","979-8-3503-0681-1","10.1109/ICAECA56562.2023.10200140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10200140","Artificial Intelligence(AI);Battery Electric Vehicles(BEV);Artificial Neural Network(ANN);Plug in Hybrid EV(PHEV);Distributed Drive EV(DDEV);State of Charge(SOC);Energy Management System(EMS);Fuzzy Logic;Hybrid Electric Vehicle(HEV);Smart grid;Virtual Power Plant(VPP);Internal Combustion Enginer(ICE)","Torque;Wind energy;Transportation;Batteries;Telecommunication computing;Hybrid electric vehicles;Automobiles;Climate change;Energy management","","","","12","IEEE","7 Aug 2023","","","IEEE","IEEE Conferences"
"Melanoma Boundaries Detection Techniques using Artificial Intelligence","K. J. Velmurugan; P. Srinivasan; A. Gayathri; S. Yuvarani","Department of Computer Science and Engineering, Jeppiaar Engineering College, Chennai, Tamil Nadu, India; Department of Electronics and Communication Engineering, Sona College of Technology, Salem, Tamil Nadu, India; Department of CSE, Saveetha School of Engineering, Saveetha Insititute of Medical And Technical Sciences (SIMATS), Chennai, Tamil Nadu, India; Department of Computer Applications, Thanthai Hans Roever College (Autonomous), Perambalur, Tamil Nadu, India","2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)","27 Mar 2023","2023","","","647","651","Melanoma is the 6th most successive disease in the United States, with more than 9000 individuals kicking the bucket every year. Fast acknowledgment of melanoma expands an individual's life expectancy, but further developed analytic advancements are as yet required. Skin injury limit anomaly, which addresses the ""B"" includes in the ""ABCD rule"", is viewed as a critical clinical component for the early discovery of melanoma. What's more, blue-white line structure evacuation additionally further develops the identification proficiency. In this paper, an AI based location method for distinguishing skin injury limit inconsistencies is presented. The technique involves extricating the skin injury from the dermoscopic images, recognizing the skin sore line, estimating line inconsistency, and prepared famous directed learning models called SVM, RF, DT, and gathering move learning calculations to distinguish line anomaly naturally, bringing about a true choice on whether the skin sore boundary is customary or unpredictable. The method produces excellent results, with 92.6 percent accuracy, 91.3 percent sensitivity, 92.5 percent specificity, and 95.1 percent F-Score, respectively.","","978-1-6654-6216-7","10.1109/ICAIS56108.2023.10073936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10073936","Boundary detection;Dermoscopic images;Melanoma;Machine learning;Skin lesion segmentation;Support vector machine;Random Forest;Decision tree","Support vector machines;Radio frequency;Sensitivity;Image recognition;Melanoma;Skin;Power capacitors","","","","15","IEEE","27 Mar 2023","","","IEEE","IEEE Conferences"
"A Multi-agent Simulation for the Research on the Market Equilibrium Phenomena Using Q-Network Algorithm","J. Wang; B. Chen","College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian Province, China; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian Province, China","2019 IEEE 19th International Conference on Communication Technology (ICCT)","2 Jan 2020","2019","","","356","361","For the problems related to market equilibrium in complex market environments, analyses are conducted in the past, using some mathematical models and the game theory. These methods are based on the economic structural equations themselves, ignoring the interactions between economic subjects, and the hypothesis of subject homogeneity has no reference in the real world. On contrast, this paper proposes a multi-agent simulation model, from the microscopic point of view. In such simulation, agents interact with each other, and the decisions are made by agent-embedded AI systems, the Q-network. Therefore, there is no need to elaborate the behavioral rule for each agent, or manually set up too many assumptions. This paper assumes that the simulated market operates in a hypothetical way, in which there are two types of economic entities, namely, banks and enterprises. Banks and enterprises lending behaviors lead to a symbiotic relationship between the banks and the enterprises, while business-to-business transactions make the enterprises symbiotically compete with each other. In the experiment, the observed behavior of each agent can be reasonably explained. Agents endogenously generate intelligent behavioral patterns compatible with the environment. Therefore, this AI-based method can replace the artificially designated decision-making strategy in simulations of market, thus facilitating related economic researches.","2576-7828","978-1-7281-0535-2","10.1109/ICCT46805.2019.8947047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947047","multi-agent simulation;markov decision process;Q-network;artificial intelligence","Economics;Mathematical model;Companies;Decision making;Markov processes;Training;Computational modeling","","","","17","IEEE","2 Jan 2020","","","IEEE","IEEE Conferences"
"Experimental Investigation of Model Predictive Control for Thermal Energy Storage System Using Artificial Intelligence","D. Lee; R. Ooka; Y. Matsuda; S. Ikeda; W. Choi","Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Tokyo, Japan; Technical Research Laboratory, DAI-DAN Co., Ltd, Saitama, Japan; Tokyo Institute of Technology, Tokyo, Japan; Institute of Industrial Science, The University of Tokyo, Tokyo, Japan","2021 29th Mediterranean Conference on Control and Automation (MED)","15 Jul 2021","2021","","","961","966","A model predictive control (MPC) strategy was developed using artificial intelligence (AI) and investigated using an experimental setup. The experimental system for the cooling operation includes a chiller, thermal energy storage (TES), heat exchangers, and variable-speed pumps. The air-conditioning space was replaced with a water tank, and the cooling load was assigned by an electric immersion heater. Control variables included the flow rates of pumps in the water loop for the primary side. In the MPC framework, artificial neural networks (ANNs) were used as surrogate models, and a metaheuristics optimization solver was employed to minimize the total operating costs. The developed AI-based MPC strategy could save operating costs by 9.7-22.5% compared to the rule-based control strategies that prioritize TES operation.","2473-3504","978-1-6654-2258-1","10.1109/MED51440.2021.9480324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9480324","Model Predictive Control (MPC);Operation Optimization;Thermal Energy Storage (TES);Artificial Neural Network (ANN);Metaheuristics","Water heating;Space cooling;Storage tanks;Artificial intelligence;Thermal energy;Space heating;Optimization","","","","20","IEEE","15 Jul 2021","","","IEEE","IEEE Conferences"
"Manual Abstraction in the Wild: A Multiple-Case Study on OSS Systems’ Class Diagrams and Implementations","W. Zhang; W. Zhang; D. Strüber; R. Hebig","Chalmers University of Technology, Gothenburg, SE; Chalmers | University of Gothenburg, Gothenburg, SE; Chalmers | University of Gothenburg, Gothenburg, SE; University of Rostock, Rostock, DE","2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS)","12 Dec 2023","2023","","","36","46","Models are a useful tool for software design, analysis, and to support the onboarding of new maintainers. However, these benefits are often lost over time, as the system implementation evolves and the original models are not updated. Reverse engineering methods and tools could help to keep models and implementation code in sync; however, automatically reverse-engineered models are typically not abstract and contain extensive information that prevents understanding. Recent advances in AI-based content generation make it likely that we will soon see reverse engineering tools with support for human-grade abstraction. To inform the design and validation of such tools, we need a principled understanding of what manual abstraction is, a question that has received little attention in the literature so far.Towards this goal, in this paper, we present a multiple-case study of model-to-code differences, investigating five substantial open-source software projects retrieved via repository mining. To explore characteristics of model-to-code differences, we, all in all, manually matched 466 classes, 1352 attributes, and 2634 operations from source code to 338 model elements (classes, attributes, operations, and relationships). These mappings precisely capture the differences between a provided class diagram design and implementation codebase. Studying all differences in detail allowed us to derive a taxonomy of difference types and to provide a sorted list of cases corresponding to the identified types of differences. As we discuss, our contributions pave the way for improved reverse engineering methods and tools, new mapping rules for model-to-code consistency checks, and guidelines for avoiding over-abstraction and over-specification during design.","","979-8-3503-2480-8","10.1109/MODELS58315.2023.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10343882","software design;modeling","Analytical models;Codes;Source coding;Reverse engineering;Taxonomy;Manuals;Synchronization","","","","37","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"IoTwins: Design and Implementation of a Platform for the Management of Digital Twins in Industrial Scenarios","A. Borghesi; G. Di Modica; P. Bellavista; V. Gowtham; A. Willner; D. Nehls; F. Kintzler; S. Cejka; S. R. Tisbeni; A. Costantini; M. Galletti; M. Antonacci; J. C. Ahouangonou","DISI, University of Bologna; DISI, University of Bologna; DISI, University of Bologna; Fraunhofer FOKUS / TU, Berlin; Fraunhofer FOKUS / TU, Berlin; Fraunhofer FOKUS / TU, Berlin; Siemens AG Austria, Vienna; Siemens AG Austria, Vienna; INFN-CNAF, Bologna; INFN-CNAF, Bologna; INFN-CNAF, Bologna; INFN, Bari; ESI GROUP, Rungis","2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)","2 Aug 2021","2021","","","625","633","With the increase of the volume of data produced by IoT devices, there is a growing demand of applications capable of elaborating data anywhere along the IoT-to-Cloud path (Edge/Fog). In industrial environments, strict real-time constraints require computation to run as close to the data origin as possible (e.g., IoT Gateway or Edge nodes), whilst batch-wise tasks such as Big Data analytics and Machine Learning model training are advised to run on the Cloud, where computing resources are abundant. The H2020 IoTwins project leverages the digital twin concept to implement virtual representation of physical assets (e.g., machine parts, machines, production/control processes) and deliver a software platform that will help enterprises, and in particular SMEs, to build highly innovative, AI-based services that exploit the potential of IoT/Edge/Cloud computing paradigms. In this paper, we discuss the design principles of the IoTwins reference architecture, delving into technical details of its components and offered functionalities, and propose an exemplary software implementation.","","978-1-7281-9586-5","10.1109/CCGrid51090.2021.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499575","IoTwins;Digital Twins;Cloud;Edge;IoT;Service Orchestration","Training;Technical requirements;Cloud computing;Digital twin;Computer architecture;Machine learning;Software","","12","","15","IEEE","2 Aug 2021","","","IEEE","IEEE Conferences"
"How Do Manufacturing Firms Manage Artificial Intelligence to Drive Iterative Product Innovation?","X. Jiang; X. Jiang; W. Sun; W. Fan","School of Management, Xi'an Jiaotong University, Xi'an, China; School of Management, Xi'an Jiaotong University, Xi'an, China; School of Management, Xi'an Jiaotong University, Xi'an, China; Department of Management Sciences, Tippie College of Business, University of Iowa, Iowa City, IA, USA","IEEE Transactions on Engineering Management","","2023","PP","99","1","13","In this article, we attempt to investigate how manufacturing firms can effectively manage artificial intelligence (AI) to deal with the tension posed by both the opportunities and risks associated with AI applications to drive iterative product innovation. We present empirical insights from three cases involving a typical Chinese manufacturing firm engaged in AI-driven iterative product innovation. We followed our sample firm for 12 months, relying on interviews, observations, and external archival data to collect rich data about its innovation process, and conducted text coding and text analytics to gain insights into the data. Our findings reveal that AI provides opportunities for broad, deep, and agile stakeholder interactions with the support of AI-enabled interactive digital platforms, intelligent manufacturing, and intelligent machines. During this process, risks emerge around data leakage, over-reliance on online intelligence decision-making, and unpredictable AI behaviors. Manufacturing firms need to manage AI by focusing on key principles relating to formulating guidelines for data management, integrating offline decision-makers’ experience into online intelligence analysis, and establishing management standards for intelligent devices. We combine these insights into a framework to illustrate how manufacturing firms manage AI to facilitate progress in iterative product innovation.","1558-0040","","10.1109/TEM.2023.3259396","National Nature Science Foundation of China(grant numbers:72272121,71772148); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10094229","Artificial intelligence (AI)-driven innovation;iterative product innovation;managing AI;stakeholder interaction","Technological innovation;Artificial intelligence;Stakeholders;Iterative methods;Manufacturing;Hardware;Interviews","","","","","IEEE","6 Apr 2023","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient Pattern Recognition Hardware With Elementary Cellular Automata","A. Morán; C. F. Frasser; M. Roca; J. L. Rosselló","Department of Physics, Electronics Engineering Group, University of the Balearic Islands, Palma de Mallorca, Spain; Department of Physics, Electronics Engineering Group, University of the Balearic Islands, Palma de Mallorca, Spain; Department of Physics, Electronics Engineering Group, University of the Balearic Islands, Palma de Mallorca, Spain; Department of Physics, Electronics Engineering Group, University of the Balearic Islands, Palma de Mallorca, Spain","IEEE Transactions on Computers","10 Feb 2020","2020","69","3","392","401","The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) is able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy.","1557-9956","","10.1109/TC.2019.2949300","Spanish Ministry of Economy and Competitiveness; Regional European Development Funds(grant numbers:TEC2017-84877-R); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883070","Reservoir computing;machine learning;pattern recognition;cellular automata;hardware implementation","Reservoirs;Hardware;Training;Automata;Pattern recognition;Machine learning","","13","","49","IEEE","25 Oct 2019","","","IEEE","IEEE Journals"
"Towards Domain-Specific Explainable AI: Model Interpretation of a Skin Image Classifier using a Human Approach","F. Stieler; F. Rabe; B. Bauer",University of Augsburg; University of Augsburg; University of Augsburg,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1802","1809","Machine Learning models have started to outperform medical experts in some classification tasks. Meanwhile, the question of how these classifiers produce certain results is attracting increasing research attention. Current interpretation methods provide a good starting point in investigating such questions, but they still massively lack the relation to the problem domain. In this work, we present how explanations of an AI system for skin image analysis can be made more domain-specific. We apply the synthesis of Local Interpretable Model-agnostic Explanations (LIME) with the ABCD-rule, a diagnostic approach of dermatologists, and present the results using a Deep Neural Network (DNN) based skin image classifier.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00199","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522689","","Deep learning;Computer vision;Image analysis;Computational modeling;Conferences;Skin;Pattern recognition","","10","","31","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Does Artificial Intelligence Help Reduce Audit Risks?","O. Adamyk; V. Benson; B. Adamyk; H. Al-Khateeb; A. Chinnaswamy","Loughborough Business School, Accounting and Finance Group, Loughborough University, Loughborough, United Kingdom; Operations and Information Management Department, Aston University, Birmingham, United Kingdom; Operations and Information Management Department, Aston University, Birmingham, United Kingdom; Operations and Information Management Department, Aston University, Birmingham, United Kingdom; Operations and Information Management Department, Aston University, Birmingham, United Kingdom","2023 13th International Conference on Advanced Computer Information Technologies (ACIT)","17 Oct 2023","2023","","","294","298","This article aims to discover how AI-powered systems facilitate auditing, what risks emerge for AI-assisted audits and how to deal with these new risks. The paper studies the impact of cognitive computing on audit risk. AI-powered software is capable of self-learn so that it can identify patterns in data and codify them in predictions, rules and decisions. This self-learning ability can become both a benefit and, at the same time, insecurity. Although AI-self-learning helps make the process more efficient and calculations more accurate by improving the algorithm, eliminating errors and reducing risks, it creates new previously unknown threats. We discovered inherent limitations of cognitive-based technologies and risks for the audit process associated with using AI systems. We also proposed a complex security model that can reduce the uncertainty of AI-enabled audit and provides insight into future research opportunities.","2770-5226","979-8-3503-1167-9","10.1109/ACIT58437.2023.10275661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10275661","artificial intelligence;machine learning;automation;audit;risk","Uncertainty;Software algorithms;Sociology;Prediction algorithms;Software;Security;Risk management","","","","21","IEEE","17 Oct 2023","","","IEEE","IEEE Conferences"
"A Survey on Artificial Intelligence-Based Modeling Techniques for High Speed Milling Processes","A. J. Torabi; M. J. Er; X. Li; B. S. Lim; L. Zhai; R. J. Oentaryo; G. O. Peen; J. M. Zurada","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Singapore Institute of Manufacturing Technology, Singapore; Singapore Institute of Manufacturing Technology, Singapore; Nanyang Technological University, Singapore; Living Analytics Research Centre, Singapore Management University, Singapore; Singapore Institute of Manufacturing Technology, Singapore; University of Louisville, Spoleczna Akademia Nauk, Lodz, KY, Poland","IEEE Systems Journal","19 May 2017","2015","9","3","1069","1080","The process of high speed milling is regarded as one of the most sophisticated and complicated manufacturing operations. In the past four decades, many investigations have been conducted on this process, aiming to better understand its nature and improve the surface quality of the products as well as extending tool life. To achieve these goals, it is necessary to form a general descriptive reference model of the milling process using experimental data, thermomechanical analysis, statistical or artificial intelligence (AI) models. Moreover, increasing demands for more efficient milling processes, qualified surface finishing, and modeling techniques have propelled the development of more effective modeling methods and approaches. In this paper, an extensive literature survey of the state-of-the-art modeling techniques of milling processes will be carried out, more specifically of recent advances and applications of AI-based modeling techniques. The comparative study of the available methods as well as the suitability of each method for corresponding types of experiments will be presented. In addition, the weaknesses of each method as well as open research challenges will be presented. Therefore, a comprehensive comparison of recent developments in the field will be a guideline for choosing the most suitable modeling technique for this process regarding its goals, conditions, and specifications.","1937-9234","","10.1109/JSYST.2013.2282479","A*Star, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6663603","Artificial intelligence (AI);high speed machining (HSM);milling process;modeling techniques;Artificial intelligence (AI);high speed machining (HSM);milling process;modeling techniques","Hidden Markov models;Milling;Rough surfaces;Surface roughness;Surface treatment;Artificial neural networks;Support vector machines","","16","","92","IEEE","13 Nov 2013","","","IEEE","IEEE Journals"
"“The Robot-Arm Talks Back to Me” - Human Perception of Augmented Human-Robot Collaboration in Virtual Reality","A. Arntz; S. C. Eimler; H. U. Hoppe","University of Applied Sciences Ruhr West, Institute of Computer Science, Bottrop, Germany; University of Applied Sciences Ruhr West, Institute of Computer Science, Bottrop, Germany; Department of Computer Science and Applied Cognitive Science, University of Duisburg-Essen, Duisburg, Germany","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","307","312","The usage of AI enhanced robots in shared task environments is likely to become more and more common with the increase of digitalization in different industrial sectors. To take up this new challenge, research on the design of Human-Robot-Collaboration (HRC) involving AI-based systems has yet to establish common targets and guidelines. This paper presents results from an explorative qualitative study. Participants (N= 80) were either exposed to a virtual representation of an industrial robot-arm equipped with several augmentation channels for communication with the human operator (lights, textual statements about intentions, etc.) or one with no communicative functions at all. Across all conditions, participants recognized the benefit of collaborating with robots in industrial scenarios regarding work efficiency and alleviation of working conditions. However, a communication channel from the robot to the human is crucial for achieving these benefits. Participants interacting with the non-communicative robot expressed dissatisfaction about the workflow. In both conditions we found remarks about the insufficient speed of the robot-arm for an efficient collaborative process. Our results indicate a wider spectrum of questions to be further explored in the design of collaborative experiences with intelligent technological counterparts considering efficiency, safety, economic success and well-being.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319082","Human-Robot Collaboration;Virtual Reality;Augmented Communication;Shared Task;Artificial Intelligence","Robots;Service robots;Collaboration;Task analysis;Robot kinematics;Safety;Collision avoidance","","7","","29","IEEE","15 Jan 2021","","","IEEE","IEEE Conferences"
"Severe Analysis of Cardiac Disease Detection using the Wearable Device by Artificial Intelligence","M. Khan; Q. Yaseen; A. Mumtaz; A. Saleem; S. Ishaq; H. Udeen","Information Technology, University of Sialkot, Sialkot, Pakistan; Information Technology, University of Sialkot, Sialkot, Pakistan; Information Technology, University of Sialkot, Sialkot, Pakistan; Information Technology, University of Sialkot, Sialkot, Pakistan; Information Technology, University of Sialkot, Sialkot, Pakistan; Information Technology, University of Sialkot, Sialkot, Pakistan","2020 IEEE International Conference for Innovation in Technology (INOCON)","1 Jan 2021","2020","","","1","8","In the current era of technology, Artificial Intelligence (AI) is playing a vital role in the health care sector especially cardiac disease detection which is a major cause of sudden death. Both the elderly and young are at the risk of sudden cardiac death at the ratio of 1-2% all around the world. Although AI technology with wearable technology is being used to detect heart diseases for quite some time now, sometimes it fails due to multiple reasons which include algorithm failure, high cost of treatment, limited battery time wearable device, data training issues, security and privacy issue in IoT, slow working of devices, poor internet or patients don't reach the hospital on time. Which gives rise to false results. Security and privacy issues in the old devices are the biggest flaws due to which old devices work slowly and the internet issues are common, it helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload, cost issues and to line onward. Meanwhile, these problems can be overcome by using modern models such as ECG assessment, AI-based guidelines, Visy's model which can recognize five critical diseases. A Wearable ECG patch is a very lightweight model that provides high accuracy and efficiency. These devices are trained by using a machine learning algorithm, and AI plays a prime role to detect the diseases. It helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload and cost issues, and the devices provide updated information as real-time data is stored online and secured with firebase authentication. It is concluded that all modern devices are more efficacious, cost-effective, user friendly, and more secure.","","978-1-7281-9744-9","10.1109/INOCON50539.2020.9298388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298388","artificial intelligence;machine learning;biosensors;wearable device;CAD diagnosis;electrocardiogram;IoT","Electrocardiography;Diseases;Heart rate;Machine learning;Wearable computers;Medical diagnostic imaging;Information technology","","2","","15","IEEE","1 Jan 2021","","","IEEE","IEEE Conferences"
"Team Roles & Rhetorical Intelligence in Human-Machine Writing","H. A. McKee; J. E. Porter",Miami University; Miami University,"2022 IEEE International Professional Communication Conference (ProComm)","12 Sep 2022","2022","","","384","391","This paper examines AI-based writing systems and how humans might partner with these systems to produce effective professional communication. We offer a taxonomy for examining roles in human-machine teaming for writing: Resource Tool, Assistant, Writer, and Executive Decision-Maker (whether at the beginning or end of the project). In particular, we focus on humanmachine teaming in relation to what we call rhetorical intelligence, the ability to invent and write for audience, purpose, and context. We examine human-machine writing by focusing on two cases: GameChanger and Phrazor by vPhrase. We conclude by proposing some guidelines for human-machine teaming for the production of professional communication.","2158-1002","978-1-6654-9517-2","10.1109/ProComm53155.2022.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881773","artificial intelligence;collaborative writing;human-computer interaction;human machine teaming;rhetoric;rhetorical intelligence","Training;Uncertainty;Taxonomy;Collaboration;Production;Writing;Artificial intelligence","","1","","28","IEEE","12 Sep 2022","","","IEEE","IEEE Conferences"
"IEEE Draft Guide for an Architectural Framework for Explainable Artificial Intelligence","",,"P2894/D9, August 2023","15 Nov 2023","2023","","","1","51","Dramatic success in machine learning has led to a new wave of artificial intelligence applications that offer extensive benefits to our daily lives. The loss of explainability during this transition, however, means vulnerability to vicious data, poor model structure design, and suspicion of stakeholders and the general public -- all with a range of legal implications. The dilemma has called for the study of explainable AI (XAI) which is an active research field that aims to make AI systems results more understandable to humans. This is a field with great hopes for improving the trust and transparency of AI-based systems and is considered a necessary route for AI to move forward. This guide provides a technological blueprint for building, deploying and managing machine learning models while meeting the requirements of transparent and trustworthy AI by adopting a variety of XAI methodologies. It defines the architectural framework and application guidelines for explainable AI, including: 1) description and definition of XAI, 2) the types of XAI methods and the application scenarios to which each type applies, 3) performance evaluation of XAI.","","979-8-8557-0314-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319438","","IEEE Standards;Artificial intelligence;Computer architecture","","","","","","15 Nov 2023","","","IEEE","IEEE Standards"
"Delay Root Cause Analysis and 3D Modeling of LTE Control Communication Using Machine Learning","S. Q. Mohammed; M. Ilyas","Department of Computer Engineering, Altinbas University, Istanbul, Turkey; Department of Computer Engineering, Altinbas University, Istanbul, Turkey","2022 International Conference on Artificial Intelligence of Things (ICAIoT)","15 May 2023","2022","","","1","7","This study investigates and evaluates delay root cause analysis and 3D modeling of LTE control communication utilizing sophisticated machine learning for network testing. The research studied LTE protocols for 5th-generation mobile telephony and provided guidelines for controlling LTE frequency for background knowledge, although it used an independent technique that did not employ LTE standards. 512 elements of input-output MIMO were employed for 100-GHz and 128 elements for mid-band sub-6-GHz. LOS is always 0.5. This paper is about LTE, not 3D modeling of LTE control path loss type communication using machine learning. This work’s route loss depends on cross-pol beam LTE polarization (±45o). The receiver (Rx) operations and transmitter (Tx) activities in the estimated distance of 0.5 km at an approximate altitude of 15.25 m. Distance, handover authentication, rain, atmosphere, and sub-6GHz vs 100GHz weather conditions affect path loss. The methodology has enhanced the spatial variety by boosting transmitting power and transmitting efficiency. Authorizing and sanctioning ANN-based LTE frequency for both mid-band sub-6-GHz and 100-GHz is possible due to its planning and development using open-source material and strategy with high transmission power and rate under doubtful handover confirmation using MIMO input/yield receiving wires. This theory examines LTE innovation dimensioning as unbiased for various handover verification and allows input boundary alterations for various organization arrangement setups for LTE recurrent data transmission from 6 GHz to 100 GHz for three climate sorts. This cycle should be seen as an undeniable level way to examine LTE networks under various air conditions. Using signal handling tool compartment and explicit AI-based ANN calculation from AI toolkit in MATLAB R2019a, it is possible to create a result answer for three climate types in a dataset with an LTE communication level of exactness of downpour assimilation and abundance foliage miss fort.","","979-8-3503-9676-8","10.1109/ICAIoT57170.2022.10121830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10121830","investigation;MIMO;artificial neural network;antennas;authentication","Root cause analysis;Three-dimensional displays;Wires;Authentication;Artificial neural networks;Handover;Delays","","","","32","IEEE","15 May 2023","","","IEEE","IEEE Conferences"
"Requirement analysis for an artificial intelligence model for the diagnosis of the COVID-19 from chest X-ray data","T. Kalliokoski","Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","3157","3164","There are multiple papers published about different AI models for the COVID-19 diagnosis with promising results. Unfortunately according to the reviews many of the papers do not reach the level of sophistication needed for a clinically usable model. In this paper I go through multiple review papers, guidelines, and other relevant material in order to generate more comprehensive requirements for the future papers proposing a AI based diagnosis of the COVID-19 from chest X-ray data (CXR). Main findings are that a clinically usable AI needs to have an extremely good documentation, comprehensive statistical analysis of the possible biases and performance, and an explainability module.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669525","COVID-19;AI;CXR;requirement analysis","COVID-19;Statistical analysis;Conferences;Documentation;Data models;Clinical diagnosis;Artificial intelligence","","","","90","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Markov Chain Based Explainable Pattern Forecasting","D. Paul; C. Wijaya; S. Yamaura; K. Miura; Y. Tajika","Singapore Technology Center, Panasonic Industry Devices, Singapore; Singapore Technology Center, Panasonic Industry Devices, Singapore; Singapore Technology Center, Panasonic Industry Devices, Singapore; Engineering Division, Panasonic Industry Co., Ltd, Japan; Engineering Division, Panasonic Industry Co., Ltd, Japan","IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society","16 Nov 2023","2023","","","1","7","The explosive penetration of artificial intelligence (AI) and machine learning (ML) based technologies are dramatically transforming the traditional decision support systems. We consider the pattern recognition and forecasting for demand timeseries in a business-to-business supply chain where demand exhibits high volatilities, non-stationarities, and skewness. We develop a pattern forecasting system by developing a data driven, feature dependent Markov chain-based framework. This may include any arbitrary user defined pattern qualitative in nature, such as plummet or recovery from plummet. To increase adoption of AI based techniques among the various stakeholders (e.g., sales, marketing, procurement, production planning) the inherent modeling and forecasting of different patterns needs to be explained in terms of domain knowledge the user is more familiar with. We therefore define two metrices to evaluate explainability to enable cross scenario comparison as the notion of explainability lacks mathematical precision. These are, namely, relevance and informativeness. Relevance is measured by direct scoring from the user whereas informativeness is inspired by the fundamental concept of measuring differences or discrepancies between distributions and for the sake of simplicity in our case measured by the variance in the main attribute of explainability. Moreover, our dataset is high dimensional where number of columns are much higher than number of rows and therefore the method for selecting features for fitting the Markov chain is extremely critical. To provide guidelines on selecting different attributes of our pipeline, we compare between feature selection methods from two families, one advanced and one traditional. We perform extensive evaluation with real dataset obtained from a business division belonging to the Panasonic Industry Co. Ltd and observe a sparsity promoting feature selection method performs better in terms of accuracy and explainability.","2577-1647","979-8-3503-3182-0","10.1109/IECON51785.2023.10312192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10312192","Markov chain;explainable artificial intelligence;change point detection;feature selection;shapley value","Procurement;Fitting;Supply chains;Production planning;Markov processes;Predictive models;Feature extraction","","","","18","IEEE","16 Nov 2023","","","IEEE","IEEE Conferences"
"IEEE Draft Guide for an Architectural Framework for Explainable Artificial Intelligence","",,"IEEE P2894/D8, August 2023","19 Sep 2023","2023","","","1","51","Dramatic success in machine learning has led to a new wave of artificial intelligence applications that offer extensive benefits to our daily lives. The loss of explainability during this transition, however, means vulnerability to vicious data, poor model structure design, and suspicion of stakeholders and the general public -- all with a range of legal implications. The dilemma has called for the study of explainable AI (XAI) which is an active research field that aims to make AI systems results more understandable to humans. This is a field with great hopes for improving the trust and transparency of AI-based systems and is considered a necessary route for AI to move forward. This guide provides a technological blueprint for building, deploying and managing machine learning models while meeting the requirements of transparent and trustworthy AI by adopting a variety of XAI methodologies. It defines the architectural framework and application guidelines for explainable AI, including: 1) description and definition of XAI, 2) the types of XAI methods and the application scenarios to which each type applies, 3) performance evaluation of XAI.","","978-1-5044-9689-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255703","","IEEE Standards;Artificial intelligence;Software architecture","","","","","","19 Sep 2023","","","IEEE","IEEE Standards"
"BookMate: Leveraging Deep Learning to Empower Caregivers of People with ASD in Generation of Social Stories","D. Bhati; A. Guercio; V. Rossano; R. Francese","Dept. of Computer Science, Kent State University, Canton, OH, USA; Dept. of Computer Science, Kent State University, Canton, OH, USA; Dept. of Computer Science, Univ. of Bari, Bari, Italy; Dept. of Computer Science, Univ. of Salerno, Fisciano, Italy","2023 27th International Conference Information Visualisation (IV)","6 Nov 2023","2023","","","403","408","People with Autism Spectrum Disorder (ASD) have difficulties in social communication and interaction. Their caregivers help them in overcoming these challenges. Social stories are tools largely adopted to improve the interaction and communication capabilities of people with ASD. The creation of a social story is not an easy task. Several guidelines have been defined to build them. In this paper, we propose an interactive mobile application aimed at empowering caregivers of people with ASD in generating social stories. The application integrates AI processing and AI-based audio transcription for story generation, effective audio data extraction, and data processing. The stories are presented in a slide-show format to the learner in different modalities according to the learner's capabilities. A preliminary usability study of the application has been performed and the first results are encouraging.","2375-0138","979-8-3503-4161-4","10.1109/IV60283.2023.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10303403","Autism Spectrum Disorder;Social Stories;Digital Storytelling;Artificial Intelligence;ChatGPT","Deep learning;Autism;Data processing;Mobile applications;Data mining;Usability;Task analysis","","","","29","IEEE","6 Nov 2023","","","IEEE","IEEE Conferences"
"Exploring the Feasibility of the Meta-Analysis of Randomized Controlled Trials on Artificial Intelligence Chatbots for Use in Healthcare Based on a Published Systematic Review","J. T. Czere; M. Péntek","Doctoral School of Applied Informatics and Applied Mathematics, Obuda University, Budapest, Hungary; Health Economics Research Center, University Research and Innovation Center, Obuda University, Budapest, Hungary","2022 IEEE 20th Jubilee International Symposium on Intelligent Systems and Informatics (SISY)","13 Feb 2023","2022","","","000053","000058","Usage of artificial intelligence (AI) based chatbot systems has been increasing not only in many industrial fields but also in the health care system. The effectiveness of AI chatbot systems as therapeutic tools has to be confirmed by clinical trials. Meta-analysis, a statistical method that synthetizes results of multiple studies thus increases the power of the findings. In this paper, our focus is on randomized controlled trials (RCTs) for the purpose of studying the effectiveness of AI chatbots used for healthcare purposes and analyzing step by step their applicability for meta-analysis. This article is based on a systematic literature review that identified eight RCTs. Only two RCTs (in the field of mental health) were feasible for meta-analysis. Standardization of the RCTs, development of points to consider as guidelines for conducting clinical trials with AI chatbots in diverse clinical areas could efficiently increase the strength of the studies and enable meta-analyses.","1949-0488","978-1-6654-8988-1","10.1109/SISY56759.2022.10036294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10036294","artificial intelligence;chatbot;clinical trial;systematic literature review;meta-analysis","Systematics;Statistical analysis;Medical services;Mental health;Clinical trials;Chatbots;Artificial intelligence","","","","31","IEEE","13 Feb 2023","","","IEEE","IEEE Conferences"
"IoT DoS and DDoS Attack Detection using ResNet","F. Hussain; S. G. Abbas; M. Husnain; U. U. Fayyaz; F. Shahzad; G. A. Shah","Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science (KICS), Lahore, Pakistan","2020 IEEE 23rd International Multitopic Conference (INMIC)","20 Jan 2021","2020","","","1","6","The network attacks are increasing both in frequency and intensity with the rapid growth of internet of things (IoT) devices. Recently, denial of service (DoS) and distributed denial of service (DDoS) attacks are reported as the most frequent attacks in IoT networks. The traditional security solutions like firewalls, intrusion detection systems, etc., are unable to detect the complex DoS and DDoS attacks since most of them filter the normal and attack traffic based upon the static predefined rules. However, these solutions can become reliable and effective when integrated with artificial intelligence (AI) based techniques. During the last few years, deep learning models especially convolutional neural networks achieved high significance due to their outstanding performance in the image processing field. The potential of these convolutional neural network (CNN) models can be used to efficiently detect the complex DoS and DDoS by converting the network traffic dataset into images. Therefore, in this work, we proposed a methodology to convert the network traffic data into image form and trained a state-of-the-art CNN model, i.e., ResNet over the converted data. The proposed methodology accomplished 99.99% accuracy for detecting the DoS and DDoS in case of binary classification. Furthermore, the proposed methodology achieved 87% average precision for recognizing eleven types of DoS and DDoS attack patterns which is 9% higher as compared to the state-of-the-art.","2049-3630","978-1-7281-9893-4","10.1109/INMIC50486.2020.9318216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318216","Internet of Things;Convolution Neural Networks;ResNet;Intrusion Detection;IoT Attacks;DoS and DDoS Attack Detection","Denial-of-service attack;Computer crime;Deep learning;Data models;IP networks;Computational modeling;Intrusion detection","","64","","22","IEEE","20 Jan 2021","","","IEEE","IEEE Conferences"
"Security Threats and Artificial Intelligence Based Countermeasures for Internet of Things Networks: A Comprehensive Survey","S. Zaman; K. Alhazmi; M. A. Aseeri; M. R. Ahmed; R. T. Khan; M. S. Kaiser; M. Mahmud","Department of Computer Science and Engineering, Brac University, Dhaka, Bangladesh; National Center for Robotics and Internet of Things Technology, Communication and Information Technology Research Institute, King Abdulaziz City for Science and Technology (KACST), Riyadh, Saudi Arabia; National Centre for Telecommunication and Defense Systems Technologies, Communication and Information Technology Research Institute, King Abdulaziz City for Science and Technology (KACST), Riyadh, Saudi Arabia; Radio and Radar Communication, Military Technological College, Muscat, Oman; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Department of Computer Science, Nottingham Trent University, Nottingham, U.K.","IEEE Access","8 Jul 2021","2021","9","","94668","94690","The Internet of Things (IoT) has emerged as a technology capable of connecting heterogeneous nodes/objects, such as people, devices, infrastructure, and makes our daily lives simpler, safer, and fruitful. Being part of a large network of heterogeneous devices, these nodes are typically resource-constrained and became the weakest link to the cyber attacker. Classical encryption techniques have been employed to ensure the data security of the IoT network. However, high-level encryption techniques cannot be employed in IoT devices due to the limitation of resources. In addition, node security is still a challenge for network engineers. Thus, we need to explore a complete solution for IoT networks that can ensure nodes and data security. The rule-based approaches and shallow and deep machine learning algorithms- branches of Artificial Intelligence (AI)- can be employed as countermeasures along with the existing network security protocols. This paper presented a comprehensive layer-wise survey on IoT security threats, and the AI-based security models to impede security threats. Finally, open challenges and future research directions are addressed for the safeguard of the IoT network.","2169-3536","","10.1109/ACCESS.2021.3089681","Brac University; Nottingham Trent University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456954","Fuzzy logic;machine leaning;attack vector;IoT protocols;IoT applications","Security;Internet of Things;Encryption;Artificial intelligence;Cryptography;Protocols;Computer crime","","44","","167","CCBYNCND","16 Jun 2021","","","IEEE","IEEE Journals"
"GRA_Net: A Deep Learning Model for Classification of Age and Gender From Facial Images","A. Garain; B. Ray; P. K. Singh; A. Ahmadian; N. Senu; R. Sarkar","Department of Computer Science and Engineering, Jadavpur University, Kolkata, India; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India; Department of Information Technology, Jadavpur University, Kolkata, India; Institute of Industry Revolution 4.0, The National University of Malaysia (UKM), Selangor, Malaysia; Institute for Mathematical Research, Universiti Putra Malaysia, Serdang, Malaysia; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India","IEEE Access","18 Jun 2021","2021","9","","85672","85689","The problem of gender and age identification has been addressed by many researchers, however, the attention given to it compared to the other related problems of face recognition in particular is far less. The success achieved in this domain has not seen much improvement compared to the other face recognition problems. Any language in the world has a separate set of words and grammatical rules when addressing people of different ages. The decision associated with its usage, relies on our ability to demarcate these individual characteristics like gender and age from the facial appearances at one glance. With the rapid usage of Artificial Intelligence (AI) based systems in different fields, we expect that such decision making capability of these systems match as much as to the human capability. To this end, in this work, we have designed a deep learning based model, called GRA_Net (Gated Residual Attention Network), for the prediction of age and gender from the facial images. This is a modified and improved version of Residual Attention Network where we have included the concept of Gate in the architecture. Gender identification is a binary classification problem whereas prediction of age is a regression problem. We have decomposed this regression problem into a combination of classification and regression problems for achieving better accuracy. Experiments have been done on five publicly available standard datasets namely FG-Net, Wikipedia, AFAD, UTKFAce and AdienceDB. Obtained results have proven its effectiveness for both age and gender classification, thus making it a proper candidate for the same against any other state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3085971","Fundamental Research Grant Scheme (FRGS) grant provided by the Ministry of Education, Malaysia(grant numbers:FRGS/1/2018/STG06/UPM/02/2); Universiti Putra Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446083","Age identification;gender classification;gated residual attention network;facial image;MAE;regression","Task analysis;Feature extraction;Estimation;Deep learning;Logic gates;Face recognition;Residual neural networks","","18","","53","CCBY","3 Jun 2021","","","IEEE","IEEE Journals"
"Living with Artificial Intelligence: A Paradigm Shift toward Future Network Traffic Control","J. Xu; K. Wu",Shenzhen University; Shenzhen University,"IEEE Network","29 Nov 2018","2018","32","6","92","99","Future Internet is expected to meet explosive traffic growth and extremely complex architecture, which tend to make the traditional NTC strategies inefficient and even ineffective. Inspired by the latest breakthroughs of AI and its power to address large-scale and complex difficulties, the network community has begun to consider shifting the NTC paradigm from legacy rule-based to novel AI-based. As an applied inter-discipline, design and implementation are important. Although there have been some preliminary explorations along this frontier, they are either limited by only envisioning the prospects, or too scattered to provide high-level insight into a general methodology. To this end, we start with the domain knowledge relationships of AI and NTC, summarizing a baseline workflow toward deep reinforcement learning, which will be the dominant method for the AI-NTC paradigm. On top of that, we argue that AI-NTC training and running must be carried out in online environments in closed-loop fashion for the purpose of putting ti into practice. A series of challenges and opportunities are discussed from a realistic viewpoint, and a set of new architecture and mechanism to enable the online and closed-loop AI-NTC paradigm are proposed. Hopefully, this work can help the AI community to better understand NTC and the NTC community to better live with AI.","1558-156X","","10.1109/MNET.2018.1800119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553661","","Support vector machines;Feature extraction;Computer architecture;Telecommunication traffic;Traffic control;Networked control systems;Artificial intelligence","","8","","15","IEEE","29 Nov 2018","","","IEEE","IEEE Magazines"
"Intelligent Automatic Door System based on Supervised Learning","M. U. Kiru; B. Belaton; S. M. S. Mohamad; G. M. Usman; A. A. Kazaure","School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Department of Computer Science, Ibrahim Badamasi University Lapai, Minna, Nigeria; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia","2020 IEEE Conference on Open Systems (ICOS)","21 Dec 2020","2020","","","43","47","The widespread adoption of automatic sliding doors in both commercial and non-commercial environments globally has necessitated the need to improve their efficiency, safety, and mode of operation. The automatic door gives access to go into or outside a building by sensing the approaching individual using sensors. However, it does not have the intuition to understand when a person is not authorized to go outside based on their age limit, for example, children. To address this problem, researchers have proposed solutions ranging from the use of fuzzy logic to rule-based approaches to make automatic doors better than the previous ones. In this study, an AI-based automatic door system is proposed, which uses a supervised machine learning approach to train classifiers using human body measurement. Our evaluation of different classifiers indicates that SVM is capable of classifying the instances correctly while achieving about 88.9% F-score. Thus, the proposed approach is expected to improve the safety of automatic doors, thereby making them smarter and more intelligent.","2473-3660","978-1-7281-9020-4","10.1109/ICOS50156.2020.9293673","Universiti Sains Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293673","Automatic door;Body measurement;Machine Learning;Supervised Learning","Sensors;Sensor systems;Intelligent sensors;Feature extraction;Machine learning;Buildings;Support vector machines","","7","","12","IEEE","21 Dec 2020","","","IEEE","IEEE Conferences"
"Experimental Study on Generating Multi-modal Explanations of Black-box Classifiers in terms of Gray-box Classifiers","J. M. Alonso; J. Toja-Alamancos; A. Bugarín","Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, SPAIN; Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, SPAIN; Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, SPAIN","2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","26 Aug 2020","2020","","","1","8","Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177770","Explainable Artificial Intelligence;Interpretable Machine Learning;Classification;Open Source Software","Artificial intelligence;Decision trees;Radio frequency;Linguistics;Data models;Forestry;Computational modeling","","4","","36","IEEE","26 Aug 2020","","","IEEE","IEEE Conferences"
"A Hybrid Approach of Web Based Heart Disease Diagnosis with Neural Networks","S. K. Prasad; N. Mathur","Department of Computer Science and Engineering, Galgotias University, Greater Noida, India; Department of Life & Basic Sciences, Jaipur National University, Jaipur, India","2022 Second International Conference on Advanced Technologies in Intelligent Control, Environment, Computing & Communication Engineering (ICATIECE)","24 Feb 2023","2022","","","1","5","The prescient displaying approach for assessing cardiovascular gamble in medical services informatics is extremely challenging. Consequently, utilizing delicate figuring innovations to clinically assess clinical data sets and prescient displaying is viewed as a beneficial and practical decision for clinical specialists. Accordingly, delicate registering advances are essential in the present medical services applications since they can perform information examination and demonstrating and assist specialists with making ideal, precise clinical decisions. Information mining is the most common way of finding designs in a data set of wellbeing science factors that connect indicator factors. The displaying of convoluted, powerful frameworks is OK for existing information mining approaches. In this review, we propose a group model system for coordinating the prescient force of various classifiers' models for further developed expectation precision. To foresee and analyze the repeat of cardiovascular disease, this review utilizes group figuring out how to consolidate the demonstrating approaches of five classifiers, including support vector machines, fake neural networks, Credulous Bayesian, relapse examination, and arbitrary woods. Cleveland and Hungarian cardiovascular information records were taken from the UCI archive. The two most significant elements in myocardial localized necrosis determination are timing and exactness. Minor demonstrative slip-ups can essentially affect the length and cost of treatment as well as seriously jeopardized the patient. This study portrays a choice emotionally supportive network (DSS) for myocardial localized necrosis (MI) finding and the board, along with persistent pulse checking of the patient, based on neural networks and factual interaction control diagrams. In the whole world, heart disease is viewed as one of the main sources of death. Clinical experts find it challenging to foresee on the grounds that a complicated undertaking calls for experience and high level information. Presently, information mining and AI based clinical strong advances assume a huge part in the forecast of cardiovascular diseases. In this review, we propose a clever hybrid strategy for the expectation of cardiovascular disease utilizing an assortment of AI techniques, including Calculated Relapse (LR), Versatile Helping (AdaBoostM1), Multi-Objective Developmental Fluffy Classifier (MOEFC), Fluffy Unordered Rule Enlistment (FURIA), Hereditary Fluffy Framework LogitBoost (GFS-LB), and Fluffy Hybrid Hereditary Based AI.","","978-1-6654-9396-3","10.1109/ICATIECE56365.2022.10047363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10047363","Hybrid Approach;Neural Network;Heart Disease;Web-Based;Prognosis","Heart;Support vector machines;Technological innovation;Medical services;Myocardium;Timing;Cardiovascular diseases","","","","15","IEEE","24 Feb 2023","","","IEEE","IEEE Conferences"
"Usage of AI and Wearable IoT Devices for Healthcare Data: A Study","S. Nandi; M. Mishra; S. Majumder","Department of Information Technology, Tripura University, Agartala, Tripura, India; Department of ECE, NERIST, Nirjuli, Arunachal Pradesh, India; Department of Information Technology, Tripura University, Agartala, Tripura, India","Machine Learning Algorithms for Signal and Image Processing","","2023","","","315","337","In this present situation, the importance of drawing the efficient learning footsteps should be necessary for describing mortal performances with the help of wearable‐internet of things (W‐IoT) sensors for analyzing body parameters, such as average‐accuracy analysis, tracking performance, work‐offloading wage and possibility analysis, power‐consumption analysis, and reliability‐ratio analysis. In the healthcare department, data storing/collection are done by using artificial intelligence (AI) based cognitive factor tools use wearing sensors for control where cloud support internet of things (IoT) are introduced. In spite of the fact that several current set of rules with deep‐learning patterns shows hopeful outcomes in sensor facts and statistics resolution for identification of mortal attitudes, appreciation of uncertainty in cognitive factor is yet harder and few common processes are more complicated. On account of the reserved computing ability, W‐IoT devices want most effective use of network to handle the maintenance and improvement of physical‐ and mental‐health information practically and effectively for feasible interpretation. Therefore, a modern ethical mobility determination is introduced that fully worked on improved Bayesian convolution network (IBCN), which permits to deliver everyone and every knowledgeable process to copy information via either basic telecommunications technique or lower ability back diffraction informing with cloud facilitation. IBCN consists of an adjustment of the pattern's dormant fickle is planned and the shape are uprooted using fold layers, the achievement of the W‐IoT has been uplifted by assembling a volatile auto‐encoder with a grade sound genuine classifier. In addition, the IBCN provides assistance to locate the privacy consignment where EDL is developed with a useful offloading AI technique. These explorative outcomes display the collection of information from the W‐IoT sensors side is impressionable to various productions of doubtfulness, such as noise and reliability. In addition, lab‐scale explorative solution on sick person's hygiene info grouping appropriateness has been displayed with the help of IBCN, which is a usual designed with the help of cognitive radio (CR) learning, DL‐SAR and cloud‐assisted agent‐based smart environment (CASE).","","9781119861836","10.1002/9781119861850.ch18","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9960925.pdf&bkn=9960833&pdfType=chapter","","Internet of Things;Smart glasses;Biomedical monitoring;Hearing aids;Wearable sensors;Tunneling;Thermometers","","","","","","22 Nov 2022","","","IEEE","Wiley-IEEE Press eBook Chapters"
"AEPRS-EF: Advanaced Eelectricity Plan Recommendation System utilizing Efficient Fuzzy Logic","P. A. Deshpande; D. S. Kumar; D. A. Junnarkar","Kalinga University, Raipur, Raipur, India; Kalinga University, Raipur, Raipur, India; Kalinga University, Raipur, Raipur, India","2022 2nd Asian Conference on Innovation in Technology (ASIANCON)","11 Oct 2022","2022","","","1","9","this paper was to propose novel advanced electricity plan recommendation utilizing Efficient Fuzzy logic algorithms (AEPRS-EF). To solve the problems related to sparsity, recommendation accuracy, & computation efficiency. For sparsity, we introduced the advanced Efficient Fuzzy logic under which we applied the set of fuzzy rules to optimize the recommendation process. For the accuracy & computation efficiency, we propose the advanced relevance feedback approach which may automatically recommends the advanced electricity planes based on end user feedbacks on previous recommendation results for the same user. The main goal & objectives is to propose & evaluate a unique data mining-based advanced electricity plan extraction framework. This research investigates the use of an advanced recommender system as compare to existing method, an AI-based rapid creation technique, to the task regards recommending power plans for a single private customer. Five basic advanced measures, including Normalized Discontinued Cumulative Gain (NDCG), Precision, Recall, Area under Precision & Recall Curve (AUPR), & Average Recommendation Time, have been utilized to evaluate the performance regards method under this study (ART). We computed the following performance metrics for the top K suggestion outcomes.","","978-1-6654-6851-0","10.1109/ASIANCON55314.2022.9908936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9908936","Recommendation system;Electricity plan;Extraction;Efficient Fuzzy logic","Fuzzy logic;Technological innovation;Subspace constraints;Area measurement;Gain measurement;Time measurement;Computational efficiency","","","","52","IEEE","11 Oct 2022","","","IEEE","IEEE Conferences"
"Beyond 160 applications of an expert system: key to a better usability","G. Tóth-Haász; Z. Baracskai","SzEEDs Doctoral Program, Széchenyi István University, Gyór, Hungary; SzEEDs Doctoral Program, Széchenyi István University, Gyór, Hungary","2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","2 Nov 2020","2020","","","000563","000568","The most influential relevant thinkers have complained of the “poverty” of Expert Systems (ES) both in the past (Dreyfus and Dreyfus, 1986) and in recently studies as well (Müller and Bostrom, 2016). We developed our own AI-Based Expert System shell for rule-based and case-based reasoning three decades ago and now there are 160 Knowledge Engineering (KE) process behind us with this system. We hope that this experience give us the right to formulate an opinion about that what is the key to a better usability and user experience in understanding of the result of the decision making process. While we do not think that ES is an omnipotent panacea, we also do not think that its applicability is determined only by the shell capabilities. However, one ability is essential; namely, presenting the result as simply as possible in order to that the decision-maker also can understand it. Our finding is that ES shells are only able to be transparent if they are designed by people who have an understanding of the human thinking process instead of a strong math-based software development approach.","2380-7350","978-1-7281-8213-1","10.1109/CogInfoCom50765.2020.9237822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237822","Knowledge Representation;Knowledge Acquisition;KBS applications;User Interface","Knowledge engineering;Conferences;Decision making;User experience;Software;Expert systems;Usability","","","","24","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Influence-Based Nano Fuzzy Swarm Oxygen Deficiency Detection and Therapy","N. R. Raz; M. -R. Akbarzadeh-T; S. Setayeshi","Department of Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing, Ferdowsi University of Mashhad, Mashhad, Iran; Department of Electrical Engineering and the Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing, Ferdowsi University of Mashhad, Mashhad, Iran; Department of Energy Engineering and Physics, Amirkabir University, Tehran, Iran","IEEE Transactions on Systems, Man, and Cybernetics: Systems","18 Jul 2023","2023","53","8","4994","5005","Oxygen deficiency is a serious health problem that may occur as a result of many diseases. In this article, we present an influence-based nano fuzzy swarm (INFS) for oxygen deficiency detection and therapy using a swarm of oxygen carrier nanomachines operating in three cognitive fields of control, influence, and interest. In particular, we propose a long short-term memory (LSTM) deep neural network for detecting apnea by analyzing the irregular peripheral oxygen saturation (SpO2) signal. Using the proposed sleep-in-the-loop strategy and the desaturated blood biomarkers, including oxygen and hydrogen ion concentrations, an in-silico multithreshold nano fuzzy swarm noninvasive therapeutic method is then performed. We also analytically prove the stability of the INFS using swarm control theory. We apply our strategy to sleep apnea, as one of the most common instances of oxygen deficiency. Furthermore, we compare the accuracy of INSF by using LSTM, bidirectional LSTM (BiLSTM), multilayer perceptron (MLP), convolutional neural network (CNN), and support vector machines (SVM). The detection and therapy results are then compared with other apnea detection methods. The input variables and structure of INSF, i.e., the number of rules and width of membership functions, are studied in terms of robustness to noise. As the results show, the proposed artificial intelligence (AI)-based noninvasive nano detection and therapy method could outperform the competing approaches in treating oxygen deficiency emergencies such as apnea.","2168-2232","","10.1109/TSMC.2023.3252899","Ferdowsi University of Mashhad(grant numbers:FUM-7868); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10097768","Apnea;complex systems;fuzzy basis functions (FBFs);fuzzy systems;nanonetworks;swarm intelligence","Medical treatment;Sleep apnea;Complex systems;Sensors;Feature extraction;Red blood cells;Oxygen","","","","57","IEEE","10 Apr 2023","","","IEEE","IEEE Journals"
"A Bus Arrival Time Prediction Method Based on Position Calibration and LSTM","Q. Han; K. Liu; L. Zeng; G. He; L. Ye; F. Li","School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Computer Science, Chongqing University, Chongqing, China; School of Computer Science, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing, China","IEEE Access","9 Mar 2020","2020","8","","42372","42383","Bus arrival time prediction not only provides convenience for passengers, but also helps to improve the efficiency of intelligent transportation system. Unfortunately, the low precision of bus-mounted GPS system, lack of real-time traffic information and poor performance of prediction model lead to low estimation accuracy - greatly influence bus service performance. Hence, in this paper, a GPS calibration method is put forward, while projection rules of specific road shapes are discussed. Moreover, two traffic factors, travel factor and dwelling factor, are defined to express real-time traffic state. Then, considering both historic data and real-time traffic condition, a hybrid dynamic BAT prediction factor, which achieves accuracy enhancement by taking into account traffic flow evaluation results and GPS position calibration, is defined. A LSTM training model is construct to realize BAT prediction. Experiment results demonstrate that our technique can provide a higher level of accuracy compared to methods based on traditional time-of-arrival techniques, especially in the accuracy of multi-stops BAT prediction.","2169-3536","","10.1109/ACCESS.2020.2976574","National Natural Science Foundation of China(grant numbers:61601066); Key Research and Development Projects of Chongqing Special Industries for Technological Innovation and Application Demonstration(grant numbers:cstc2018jszx-cyzdX0064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015964","Bus arrival time prediction;LSTM model;GPS data calibration","Predictive models;Global Positioning System;Roads;Real-time systems;Calibration;Data models;Meteorology","","17","","28","CCBY","27 Feb 2020","","","IEEE","IEEE Journals"
