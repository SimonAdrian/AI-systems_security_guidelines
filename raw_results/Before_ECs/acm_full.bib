@inproceedings{10.1007/978-3-030-77772-2_1,
author = {B\"{o}ckle, Martin and Yeboah-Antwi, Kwaku and Kouris, Iana},
title = {Can You Trust the Black Box? The Effect of Personality Traits on Trust in AI-Enabled User Interfaces},
year = {2021},
isbn = {978-3-030-77771-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77772-2_1},
doi = {10.1007/978-3-030-77772-2_1},
abstract = {Human-centred artificial intelligence is a fast-growing research stream within the artificial intelligence (AI) and human–computer interaction (HCI) communities. One key focus of this stream is the enablement of trust between end users and the intelligent solution. Although, the current body of literature discusses and proposes a range of best practices for the design of user interfaces for intelligent solutions, there is a dearth of research how such interfaces are perceived by users and especially focusing on trust in these interfaces. In this paper, we investigate how the Big Five personality traits affect trust in AI-enabled user interfaces. We then experimentally verify which design best practices and guidelines proposed by Google enable trust in AI-enabled user interfaces for the different personality types. Initial results (n = 211) reveal that three of the Big Five personality traits – Extraversion, Agreeableness and Open-Mindedness – show a significant correlation between the degree of the personality trait and trust in the proposed storyboards. In addition, we identified significant positive relationships between the perception of trust by users and four out of the twelve design principles: review implicit feedback; connect the feedback to UX changes; create opportunities for feedback; fail gracefully and highlight failure. This paper is of a highly explorative character and provides first experimental results on designing for trust to the HCI/AI community and also highlights future research directions in the form of a research agenda.},
booktitle = {Artificial Intelligence in HCI: Second International Conference, AI-HCI 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings},
pages = {3–20},
numpages = {18},
keywords = {Big five, HCI/AI, Personality traits, Human-centred AI}
}

@inproceedings{10.1007/978-3-031-11647-6_21,
author = {Marsh Runyon, K. Rebecca and D. Montilus, Kinta and Nachman, Larisa and Smith Herrick, Kristen and Ferrara, Lisa},
title = {ETS® AI Labs™ Ways of Working Tutorial: How to Build Evidence-Based, User-Obsessed, AI-Enabled Learning Solutions in an Agile Framework},
year = {2022},
isbn = {978-3-031-11646-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-11647-6_21},
doi = {10.1007/978-3-031-11647-6_21},
abstract = {How do you advance the science and engineering of digital learning solutions at your institution, business, or organization? Bring your current ways of working to this tutorial and get ready to innovate them alongside your fellow researchers, practitioners, business owners, and policy makers. As we work together to share our knowledge and lived experiences, presenters will assist participants in co-creating action plans for how they can utilize best practices from user-centered design (UCD), Design thinking, and Agile to deliver user-obsessed, AI-enabled, efficacious learning solutions.},
booktitle = {Artificial Intelligence  in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium: 23rd International Conference, AIED 2022, Durham, UK, July 27–31, 2022, Proceedings, Part II},
pages = {119–122},
numpages = {4},
keywords = {UCD, Design Thinking, Agile},
location = {Durham, United Kingdom}
}

@inproceedings{10.1007/978-3-030-40124-5_3,
author = {Anwar, Syed Muhammad and Altaf, Tooba and Rafique, Khola and RaviPrakash, Harish and Mohy-ud-Din, Hassan and Bagci, Ulas},
title = {A Survey on Recent Advancements for AI Enabled Radiomics in Neuro-Oncology},
year = {2019},
isbn = {978-3-030-40123-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-40124-5_3},
doi = {10.1007/978-3-030-40124-5_3},
abstract = {Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistance in diagnosis of cancer, planning of treatment strategy, and prediction of survival. Radiomics in neuro-oncology has progressed significantly in the recent past. Deep learning has outperformed conventional machine learning methods in most image-based applications. Convolutional neural networks (CNNs) have seen some popularity in radiomics, since they do not require hand-crafted features and can automatically extract features during the learning process. In this regard, it is observed that CNN based radiomics could provide state-of-the-art results in neuro-oncology, similar to the recent success of such methods in a wide spectrum of medical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology.},
booktitle = {Radiomics and Radiogenomics in Neuro-Oncology: First International Workshop, RNO-AI 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings},
pages = {24–35},
numpages = {12},
keywords = {Deep learning, Classification, Neuro-oncology, Radiomics},
location = {Shenzhen, China}
}

@inproceedings{10.1007/978-3-031-21388-5_4,
author = {Morales, Sergio and Claris\'{o}, Robert and Cabot, Jordi},
title = {Towards a&nbsp;DSL for&nbsp;AI Engineering Process Modeling},
year = {2022},
isbn = {978-3-031-21387-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21388-5_4},
doi = {10.1007/978-3-031-21388-5_4},
abstract = {Many modern software products embed AI components. As a result, their development requires multidisciplinary teams with diverse skill sets. Diversity may lead to communication issues or misapplication of best practices. Process models, which prescribe how software should be developed within an organization, can alleviate this problem. In this paper, we introduce a domain-specific language for modeling AI engineering processes. The DSL concepts stem from our analysis of scientific and gray literature that describes how teams are developing AI-based software. This DSL contributes a structured framework and a common ground for designing, enacting and automating AI engineering processes.},
booktitle = {Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyv\"{a}skyl\"{a}, Finland, November 21–23, 2022, Proceedings},
pages = {53–60},
numpages = {8},
keywords = {Process modeling, AI engineering, Domain-specific language},
location = {Jyv\"{a}skyl\"{a}, Finland}
}

@inproceedings{10.1145/3340435.3342718,
author = {Diosan, Laura and Motogna, Simona},
title = {Artificial intelligence meets software engineering in the classroom},
year = {2019},
isbn = {9781450368520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340435.3342718},
doi = {10.1145/3340435.3342718},
abstract = {We aimed to assess the reliability of teaching Artificial Intelligencefor Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements.We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence},
pages = {35–38},
numpages = {4},
keywords = {theory and algorithms for application domain, Software engineering education, Software creation},
location = {Tallinn, Estonia},
series = {EASEAI 2019}
}

@article{10.1016/j.asoc.2023.110421,
author = {Ahmad, Khlood and Abdelrazek, Mohamed and Arora, Chetan and Bano, Muneera and Grundy, John},
title = {Requirements practices and gaps when engineering human-centered Artificial Intelligence systems},
year = {2023},
issue_date = {Aug 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {143},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2023.110421},
doi = {10.1016/j.asoc.2023.110421},
journal = {Appl. Soft Comput.},
month = {aug},
numpages = {15},
keywords = {Survey research, Human-centered, Machine learning, Artificial Intelligence, Software engineering, Requirements engineering}
}

@inproceedings{10.1145/3494193.3494260,
author = {Rak, Richard},
title = {Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems},
year = {2022},
isbn = {9781450390118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494193.3494260},
doi = {10.1145/3494193.3494260},
abstract = {The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.},
booktitle = {Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance},
pages = {481–484},
numpages = {4},
keywords = {telehealth, privacy, eHealth, data protection, data governance, Internet of Things, Internet of Healthcare, AI},
location = {Athens, Greece},
series = {ICEGOV '21}
}

@inproceedings{10.1145/3581754.3584137,
author = {Wijekoon, Anjana and Wiratunga, Nirmalie and Palihawadana, Chamath and Nkisi-Orji, Ikeckukwu and Corsar, David and Martin, Kyle},
title = {iSee: Intelligent Sharing of Explanation Experience by Users for Users},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584137},
doi = {10.1145/3581754.3584137},
abstract = {The right to obtain an explanation of the decision reached by an Artificial Intelligence&nbsp;(AI) model is now an EU regulation. Different stakeholders of an AI system&nbsp;(e.g. managers, developers, auditors, etc.) may have different background knowledge, competencies and goals, thus requiring different kinds of interpretations and explanations. Fortunately, there is a growing armoury of tools to interpret ML models and explain their predictions, recommendations and diagnoses which we will refer to collectively as explanation strategies. As these explanation strategies mature, practitioners will gain experience that helps them know which strategies to deploy in different circumstances. What is lacking, and is addressed by iSee, is capturing, sharing and re-using explanation strategies based on past positive experiences. The goal of the iSee platform is to improve every user’s experience of AI, by harnessing experiences and best practices in Explainable AI.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {79–82},
numpages = {4},
keywords = {Interactive Explanations, Explainable AI, Conversation AI},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@article{10.1145/3626234,
author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Whittle, Jon and Zowghi, Didar and Jacquet, Aurelie},
title = {Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3626234},
doi = {10.1145/3626234},
abstract = {Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The Responsible AI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and responsible-AI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement responsible AI.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {oct},
keywords = {best practice, pattern, software architecture, software engineering, MLOps, AI engineering, AI governance, trustworthy AI, ethical AI, Responsible AI}
}

@inproceedings{10.1109/COMPSAC.2015.41,
author = {Thekkilakattil, Abhilash and Dodig-Crnkovic, Gordana},
title = {Ethics Aspects of Embedded and Cyber-Physical Systems},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.41},
doi = {10.1109/COMPSAC.2015.41},
abstract = {The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the "responsibility" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical "responsibility" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {39–44},
numpages = {6},
keywords = {Software-responsibility, Extra-functional Properties, Ethics, Cyber-physical systems},
series = {COMPSAC '15}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00042,
author = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
title = {Software engineering for machine learning: a case study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00042},
doi = {10.1109/ICSE-SEIP.2019.00042},
abstract = {Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be "entangled" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {291–300},
numpages = {10},
keywords = {software engineering, process, data, AI},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1007/978-3-031-28238-6_22,
author = {Agarwal, Anmol and Gupta, Shrey and Bonagiri, Vamshi and Gaur, Manas and Reagle, Joseph and Kumaraguru, Ponnurangam},
title = {Towards Effective Paraphrasing for&nbsp;Information Disguise},
year = {2023},
isbn = {978-3-031-28237-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-28238-6_22},
doi = {10.1007/978-3-031-28238-6_22},
abstract = {Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors’ posts on the Internet. Research on ID becomes important when authors’ written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author’s post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit “r/AmItheAsshole” as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach. ()},
booktitle = {Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2–6, 2023, Proceedings, Part II},
pages = {331–340},
numpages = {10},
keywords = {Computational ethics, Information disguise, Paraphrasing, Adversarial retrieval, Neural information retrieval},
location = {Dublin, Ireland}
}

@inproceedings{10.1145/3383583.3398496,
author = {Fox, Edward A.},
title = {How Should One Explore the Digital Library of the Future?},
year = {2020},
isbn = {9781450375856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383583.3398496},
doi = {10.1145/3383583.3398496},
abstract = {Motivated by the Foreword of Licklider's "Libraries of the Future" (dedicated to Vannevar Bush), this keynote focuses on users, exploration, and future directions of the digital library (DL) field, which moves toward procognitive systems. Many different digital library "users," each a member of a Society, engage in a diversity of Scenarios, often involving some aspect of exploration, usually of the DL content Streams. Services -- e.g., searching, browsing, recommending, and visualizing -- help those users leverage knowledge Structures and Spatial representations. Following on the final sentence of Licklider's book, we "call for a formal base plus an overlay of experience, " leading to a new way to build better DLs. Licklider said we seek "the facts, concepts, principles, and ideas that lie behind the visible and tangible aspects of documents," to help us acquire and use knowledge. Put simply: "The console of the procognitive system will have two special buttons, a silver one labeled 'Where am I" and a gold one labeled 'What should I do next?' "How can we build and use this?For more than 55 years, researchers have applied artificial intelligence (AI), natural language processing (NLP), representations (data, information, knowledge), question-answering, databases, human-computer interaction, and other techniques described by Licklider, to these challenges. We have a vast range of hardware and software services available, but without a more formal approach, will not enable adaptive self-organization and tailored exploration.The 5S framework can help us build, apply, and improve digital libraries to facilitate exploration, through a formal approach that will simplify such efforts, making them extensible through both human and computing agents. For example, to more easily build DLs, we propose collaboratively building knowledge graphs -- involving both User eXperience designers, subject matter experts, and developers -- that specify connections to services and workflows, enabling DL operation atop a workflow engine. User exploration, additional help by UX designers, recommendations of adaptations of existing workflows, and AI-based optimizations and solutions to new problems, will all expand the knowledge graph to ensure new and more helpful assistance.When this is accomplished, we must teach and learn about this next generation of digital libraries, further developing suitable curriculum and educational modules, that rest upon a solid theoretical foundation, helping spread understanding of key concepts and best practices.},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020},
pages = {1–2},
numpages = {2},
keywords = {structures, streams, spaces, societies, scenarios, procognitive, licklider, adaptive self-organization, NLP, HCI, AI, 5S},
location = {Virtual Event, China},
series = {JCDL '20}
}

@inproceedings{10.1145/3616961.3616969,
author = {Raftopoulos, Marigo},
title = {[WORKSHOP] Augmented Humans: Provocations for collaborative AI system design},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616969},
doi = {10.1145/3616961.3616969},
abstract = {This workshop is designed to facilitate an exploration of collaborative methodologies from both academia and industry practice to advance insight into the emergent problem space of designing AI-enabled information systems. The recent developments and implementations of AI-enabled technologies have seen a parallel proliferation of practical approaches to ensure human-centred and ethical design principles are imbedded into AI development which has largely been in response to widespread industry criticism of unethical practices and unintended negative consequences of ‘black box’ algorithmic decision making. Our prototype design cards and collaborative design process are targeted at current problems and limitations with intelligent human-machine systems that can be averted with more inclusive collaboration with users as stakeholders in system design. Our intention is to refine our AI design methodology and design cards over several international workshops and to provide them to the public as a free open-source tool for AI researchers and practitioners.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {294–297},
numpages = {4},
keywords = {stakeholder collaborative design methods, design cards, artificial intelligence},
location = {<conf-loc>, <city>Tampere</city>, <country>Finland</country>, </conf-loc>},
series = {Mindtrek '23}
}

@inproceedings{10.1007/978-3-031-15342-6_7,
author = {Kabudi, Tumaini and Pappas, Ilias O. and Olsen, Dag H.},
title = {Deriving Design Principles for AI-Adaptive Learning Systems: Findings from Interviews with Experts},
year = {2022},
isbn = {978-3-031-15341-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-15342-6_7},
doi = {10.1007/978-3-031-15342-6_7},
abstract = {AI applications are increasing in the field of education, from laboratory set-ups to contemporary and complex learning systems. A great example of such systems is AI-enabled adaptive learning systems (AI-ALS) that promote adaptive learning. Despite its promised potential, there are challenges such as design issues, highly complex models, and lack of evidence-based guidelines and design principles that hinder the large-scale adoption and implementation of AI-ALS. The goal of this paper thus is to establish a set of empirically grounded design principles (DPs) of AI-ALS, that would serve well in a university context. 22 interviews were con-ducted with experts knowledgeable about the design and development of AI-ALS. Several rounds of coding and deep analysis of the expert interviews revealed features and functionalities of AI-ALS; purposes for designing and using AI-ALS; and recommended improvements for AI-ALS as requirements. These requirements were translated to 13 preliminary DPs. The findings of this study serve as a guide on how to better design AI-ALS, that will improve the learning experiences of students.},
booktitle = {The Role of Digital Technologies in Shaping the Post-Pandemic World: 21st IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2022, Newcastle upon Tyne, UK, September 13–14, 2022, Proceedings},
pages = {82–94},
numpages = {13},
keywords = {Adaptive learning, Adaptive learning systems, Design principles, AIEd, AI},
location = {Newcastle upon Tyne, United Kingdom}
}

@article{10.1007/s00146-021-01285-y,
author = {Nandutu, Irene and Atemkeng, Marcellin and Okouma, Patrice},
title = {Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda},
year = {2021},
issue_date = {Feb 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {1},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-021-01285-y},
doi = {10.1007/s00146-021-01285-y},
abstract = {With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.},
journal = {AI Soc.},
month = {sep},
pages = {245–257},
numpages = {13},
keywords = {Artificial intelligence, AI Ethics integration, AI in wildlife conservation, AI Ethics, Human–wildlife conflicts, Wildlife conservation concerns}
}

@inproceedings{10.1007/978-3-031-32808-4_7,
author = {Bunde, Enrico and Eisenhardt, Daniel and Sonntag, Daniel and Profitlich, Hans-J\"{u}rgen and Meske, Christian},
title = {Giving DIAnA More TIME – Guidance for the Design of XAI-Based Medical Decision Support Systems},
year = {2023},
isbn = {978-3-031-32807-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-32808-4_7},
doi = {10.1007/978-3-031-32808-4_7},
abstract = {Future healthcare ecosystems integrating human-centered artificial intelligence (AI) will be indispensable. AI-based healthcare technologies can support diagnosis processes and make healthcare more accessible globally. In this context, we conducted a design science research project intending to introduce design principles for user interfaces (UIs) of explainable AI-based (XAI) medical decision support systems (XAI-based MDSS). We used an archaeological approach to analyze the UI of an existing web-based system in the context of skin lesion classification called DIAnA (Dermatological Images – Analysis and Archiving). One of DIAnA’s unique characteristics is that it should be usable for the stakeholder groups of physicians and patients. We conducted the in-situ analysis with these stakeholders using the think-aloud method and semi-structured interviews. We anchored our interview guide in concepts of the Theory of Interactive Media Effects (TIME), which formulates UI features as causes and user psychology as effects. Based on the results, we derived 20 design requirements and developed nine design principles grounded in TIME for this class of XAI-based MDSS, either associated with the needs of physicians, patients, or both. Regarding evaluation, we first conducted semi-structured interviews with software developers to assess the reusability of our design principles. Afterward, we conducted a survey with user experience/interface designers. The evaluation uncovered that 77% of the participants would adopt the design principles, and 82% would recommend them to colleagues for a suitable project. The findings prove the reusability of the design principles and highlight a positive perception by potential implementers.},
booktitle = {Design Science Research for a New Society: Society 5.0: 18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023, Pretoria, South Africa, May 31 – June 2, 2023, Proceedings},
pages = {107–122},
numpages = {16},
keywords = {Healthcare, Medical Decision Support Systems, Explainable Artificial Intelligence, Design Principles, Design Science Research},
location = {Pretoria, South Africa}
}

@article{10.1007/s10796-022-10284-3,
author = {V\"{o}ssing, Michael and K\"{u}hl, Niklas and Lind, Matteo and Satzger, Gerhard},
title = {Designing Transparency for Effective Human-AI Collaboration},
year = {2022},
issue_date = {Jun 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-022-10284-3},
doi = {10.1007/s10796-022-10284-3},
abstract = {The field of artificial intelligence (AI) is advancing quickly, and systems can increasingly perform a multitude of tasks that previously required human intelligence. Information systems can facilitate collaboration between humans and AI systems such that their individual capabilities complement each other. However, there is a lack of consolidated design guidelines for information systems facilitating the collaboration between humans and AI systems. This work examines how agent transparency affects trust and task outcomes in the context of human-AI collaboration. Drawing on the 3-Gap framework, we study agent transparency as a means to reduce the information asymmetry between humans and the AI. Following the Design Science Research paradigm, we formulate testable propositions, derive design requirements, and synthesize design principles. We instantiate two design principles as design features of an information system utilized in the hospitality industry. Further, we conduct two case studies to evaluate the effects of agent transparency: We find that trust increases when the AI system provides information on its reasoning, while trust decreases when the AI system provides information on sources of uncertainty. Additionally, we observe that agent transparency improves task outcomes as it enhances the accuracy of judgemental forecast adjustments.},
journal = {Information Systems Frontiers},
month = {jun},
pages = {877–895},
numpages = {19},
keywords = {Trust, Human-AI interaction, Human-AI collaboration, Design science research, Agent transparency}
}

@inproceedings{10.1007/978-3-031-35891-3_8,
author = {Kutz, Janika and Neuh\"{u}ttler, Jens and Bienzeisler, Bernd and Spilski, Jan and Lachmann, Thomas},
title = {Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services},
year = {2023},
isbn = {978-3-031-35890-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35891-3_8},
doi = {10.1007/978-3-031-35891-3_8},
abstract = {AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.},
booktitle = {Artificial Intelligence in HCI: 4th International Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I},
pages = {115–130},
numpages = {16},
keywords = {Design Principles, Human-Centered AI, Industrial AI},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1109/ICCRD.2010.11,
author = {Mozgovoy, Maxim and Umarov, Iskander},
title = {Building a Believable Agent for a 3D Boxing Simulation Game},
year = {2010},
isbn = {9780769540436},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCRD.2010.11},
doi = {10.1109/ICCRD.2010.11},
abstract = {This paper describes an approach used to build a practical AI solution for a 3D boxing simulation game. The features of the designed AI agent are based on our deliberate concentration on believability, i.e. human-likeness of agent’s behavior. We show how learning by observation and case-based reasoning techniques can be used to create an AI decision-making system for an industrial-level computer game. The chosen AI design principles support high usability and maintainability, which is important for game developers. We prove experimentally that our AI system provides both believable and effective behavior.},
booktitle = {Proceedings of the 2010 Second International Conference on Computer Research and Development},
pages = {46–50},
numpages = {5},
keywords = {learning by observation, believability, behavior-capture},
series = {ICCRD '10}
}

@article{10.1016/j.chb.2023.107737,
author = {J\"{a}rvel\"{a}, Sanna and Nguyen, Andy and Vuorenmaa, Eija and Malmberg, Jonna and J\"{a}rvenoja, Hanna},
title = {Predicting regulatory activities for socially shared regulation to optimize collaborative learning},
year = {2023},
issue_date = {Jul 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {144},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2023.107737},
doi = {10.1016/j.chb.2023.107737},
journal = {Comput. Hum. Behav.},
month = {jul},
numpages = {10},
keywords = {Artificial intelligence (AI), Episode rule mining, Physiological signal, Multimodal data, Collaborative learning, Socially shared regulation}
}

@inproceedings{10.1007/978-3-030-98404-5_23,
author = {Park, Sunyoung and Kim, Hyun K. and Lee, Yuryeon and Park, Gyuwon and Lee, Danbi},
title = {User Experience Design for Defense Systems with AI},
year = {2021},
isbn = {978-3-030-98403-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98404-5_23},
doi = {10.1007/978-3-030-98404-5_23},
abstract = {As artificial intelligence (AI) is applied at an increasing frequency in various fields, the number of studies on the user experience (UX) design of human-AI interaction is also increasing. However, the results of these studies on AI UX design principles are insufficient for actual AI systems. In light of this fact, the purpose of this study was to upgrade the UX design of a defense system that uses AI technology to detect land changes and targets. In order to upgrade the UX design of this AI system, a three-step procedure was executed. First, AI UX principles were derived by analyzing literature related to human-AI interaction. Second, ideation was performed to improve the interface. Finally, the results of the ideation were utilized to construct the UX prototype of the AI system with Adobe XD. The results of this study are expected to be used as fundamental data for future research that will develop UX principles and advanced methods for AI systems.},
booktitle = {Intelligent Human Computer Interaction: 13th International Conference, IHCI 2021, Kent, OH, USA, December 20–22, 2021, Revised Selected Papers},
pages = {242–247},
numpages = {6},
keywords = {AI system design process, AI usability, AI system design, AI UX, User experience, Artificial intelligence},
location = {Kent, OH, USA}
}

@inproceedings{10.1007/978-3-031-32808-4_29,
author = {Oberste, Luis and R\"{u}ffer, Florian and Ayding\"{u}l, Okan and Rink, Johann and Heinzl, Armin},
title = {Designing User-Centric Explanations for Medical Imaging with Informed Machine Learning},
year = {2023},
isbn = {978-3-031-32807-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-32808-4_29},
doi = {10.1007/978-3-031-32808-4_29},
abstract = {A flawed algorithm released in clinical practice can cause unintended harm to patient health. Risks, regulation, responsibility, and ethics shape the demand of clinical users to understand and rely on the outputs made by artificial intelligence. Explainable artificial intelligence (XAI) offers methods to render a model’s behavior understandable from different perspectives. Extant XAI, however, is mainly data-driven and designed to meet developers’ demands to correct models rather than clinical users’ expectations to reflect clinically relevant information. To this end, informed machine learning (IML) utilizes prior knowledge jointly with data to generate predictions, a promising paradigm to enrich XAI with medical knowledge. To explore how IML can be used to generate explanations that are congruent to clinical users’ demands and useful to medical decision-making, we conduct Action Design Research (ADR) in collaboration with a team of radiologists. We propose an IML-based XAI system for clinically relevant explanations of diagnostic imaging predictions. With the help of ADR, we reduce the gap between implementation and user evaluation and demonstrate the effectiveness of the system in a real-world application with clinicians. While we develop design principles of using IML for user-centric XAI in diagnostic imaging, the study demonstrates that an IML-based design adequately reflects clinicians’ conceptions. In this way, IML inspires greater understandability and trustworthiness of AI-enabled diagnostic imaging.},
booktitle = {Design Science Research for a New Society: Society 5.0: 18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023, Pretoria, South Africa, May 31 – June 2, 2023, Proceedings},
pages = {470–484},
numpages = {15},
keywords = {User-Centric Design, Medical Image Analysis, Action Design Research, Informed Machine Learning, Explainable Artificial Intelligence},
location = {Pretoria, South Africa}
}

@inproceedings{10.1145/3491101.3519809,
author = {Lu, Yuwen and Zhang, Chengzhi and Zhang, Iris and Li, Toby Jia-Jun},
title = {Bridging the Gap Between UX Practitioners’ Work Practices and AI-Enabled Design Support Tools},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519809},
doi = {10.1145/3491101.3519809},
abstract = {User interface (UI) and user experience (UX) design have become an indispensable part of today’s tech industry. Recently, much progress has been made in machine-learning-enabled design support tools for UX designers. However, few of these tools have been adopted by practitioners. To learn the underlying reasons and understand user needs for bridging this gap, we conducted a retrospective analysis with 8 UX professionals to understand their practice and identify opportunities for future research. We found that the current AI-enabled systems to support UX work mainly work on graphical interface elements, while design activities that involve more ‘design thinking” such as user interviews and user testings are more helpful for designers. Many current systems were also designed for overly-simplistic and generic use scenarios. We identified 4 areas in the UX workflow that can benefit from additional AI-enabled assistance: design inspiration search, design alternative exploration, design system customization, and design guideline violation check.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {7},
keywords = {design-support tools, data-driven design, User Experience (UX), Human-AI Collaboration},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@phdthesis{10.5555/AAI28541283,
author = {Ebrahimi, Mohammadreza and F., Nunamaker, Jay and A, Brown, Susan},
advisor = {Hsinchun, Chen,},
title = {AI-Enabled Cybersecurity Analytics: Detecting and Defending against Cyber Threats},
year = {2021},
isbn = {9798534685190},
publisher = {The University of Arizona},
abstract = {Cyber attacks are estimated to cost the global economy $6 trillion annually by 2021. To combat these attacks, many cybersecurity organizations rely on manual cyber threat detection and mitigation approaches for cyber defense. However, the fast-paced nature of the cyber threat landscape and the sheer volume of the data preclude effective cyber defense via manual approaches or ad-hoc software programs. Artificial Intelligence (AI)-enabled cybersecurity is an emerging approach that draws upon statistical and machine learning theories to yield AI agents that address this issue. These agents can automatically conduct cyber defense operations at a large scale, provide predictive insights in complex tasks, and improve incident response. Consequently, major cybersecurity analytics firms are increasingly incorporating AI agents into their cyber defense fabric. Despite their promise, AI agents are vulnerable to adversarial attacks from AI-enabled adversaries. These adversarial attacks incur damage by automatically generating malicious input data that misleads these AI agents. Given the societal impact of AI-enabled cybersecurity and the crucial need for resistant cybersecurity AI agents, this dissertation presents six essays to contribute to two broad aspects of AI-enabled cybersecurity: AI agents for cybersecurity – designing AI agents to automate detecting cyber threats (three essays), and (2) security of AI agents – designing AI agents for defending against adversarial attacks (three essays). To make concrete contributions to cyber defense, each of these aspects is focused on a high-impact cybersecurity application domain. The first aspect concerns dark web analytics – focusing on cyber threat detection in international hidden anonymous platforms. The second area focuses on malware analytics – targeting the robustness of malware detectors against adversarial attacks. The essays follow design science guidelines to draw on statistical machine learning theories to develop Information Technology (IT) artifacts that address cybersecurity research inquiries via novel designs that enhance IS (information systems) knowledge base. Each proposed design also contributes to the state-of-the-art in the reference discipline (i.e., statistical machine learning) via one or more novel algorithms in transductive learning, transfer learning, adversarial learning, and reinforcement learning theory. Essays I-III are dedicated to AI for cybersecurity. Specifically, Essay I offers a cybersecurity AI agent to identify key cyber threats in English dark net markets using transductive learning. Essay II generalizes the first essay to a multilingual setting for detecting cyber threats within the international dark web using transfer and adversarial learning. Essay III extends the second essay from text to image analytics in illegal e-commerce markets by presenting a more general framework leveraging adversarial kernel learning and deep dictionary learning. Essays IV-VI target the security of AI agents. Specifically, Essay IV focuses on a high-impact application of AI for improving the security of AI-enabled malware detectors as the first line of defense in cybersecurity. Essay V generalizes Essay IV to improve the robustness of any cybersecurity AI agent against adversarial attacks via reinforcement learning (RL) and robust optimization theory. Finally, Essay VI offers a generalized approach to defend against adversarial attacks based on sequential decision making and learning action representations in RL to minimize reliance on insider knowledge about the attack target.},
note = {AAI28541283}
}

@article{10.1016/j.eswa.2022.118002,
author = {Devagiri, Jeevan S. and Paheding, Sidike and Niyaz, Quamar and Yang, Xiaoli and Smith, Samantha},
title = {Augmented Reality and Artificial Intelligence in industry: Trends, tools, and future challenges},
year = {2022},
issue_date = {Nov 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {207},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2022.118002},
doi = {10.1016/j.eswa.2022.118002},
journal = {Expert Syst. Appl.},
month = {nov},
numpages = {13},
keywords = {Deep learning, Industrial applications, Machine learning, Artificial Intelligence, Augmented Reality}
}

@inproceedings{10.1007/978-3-540-30537-8_26,
author = {Wang, Shouyang and Yu, Lean and Lai, K. K.},
title = {A novel hybrid AI system framework for crude oil price forecasting},
year = {2004},
isbn = {3540239871},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-30537-8_26},
doi = {10.1007/978-3-540-30537-8_26},
abstract = {In this study, a novel hybrid AI system framework is developed by means of a systematic integration of artificial neural networks (ANN) and rulebased expert system (RES) with web-based text mining (WTM) techniques. Within the hybrid AI system framework, a fully novel hybrid AI forecasting approach with conditional judgment and correction is proposed for improving prediction performance. The proposed framework and approach are also illustrated with an example here.},
booktitle = {Proceedings of the 2004 Chinese Academy of Sciences Conference on Data Mining and Knowledge Management},
pages = {233–242},
numpages = {10},
location = {Beijing, China},
series = {CASDMKM'04}
}

@inproceedings{10.1145/3544548.3580900,
author = {Yildirim, Nur and Pushkarna, Mahima and Goyal, Nitesh and Wattenberg, Martin and Vi\'{e}gas, Fernanda},
title = {Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580900},
doi = {10.1145/3544548.3580900},
abstract = {Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {356},
numpages = {13},
keywords = {people AI guidebook, human-AI interaction, human-AI guidelines},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}

@inproceedings{10.1109/IMSCCS.2007.56,
author = {Liu, Gang and Liu, Qun and Zhang, Wentao},
title = {Model-Based Testing and Validation on Artificial Intelligence Systems},
year = {2007},
isbn = {0769530397},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IMSCCS.2007.56},
doi = {10.1109/IMSCCS.2007.56},
abstract = {In this paper, we discuss how viewing an Artificial Intelligence (AI) System as a model leads to certain criteria for testing methodologies. This includes a discussion of how certain mathematical techniques for testing AI systems can be used as criteria for determining the AI System's adequacy when no other models are available. We give an example of an error due to widespread rule interactions. Such errors are the keys to understanding why the independent rule assumption does not work, and therefore why AI systems must be modeled. We examine how testing can be applied both to individual system components as well as to the system as a whole. We also submit different criteria by which a set of test cases can be assembled and the problems in determining whether or not the performance of an AI system on a set of test cases is acceptable. In the end, the article shows the results of applying this model to a real case. Keywords: AI Systems, Testing, Model},
booktitle = {Proceedings of the Second International Multi-Symposiums on Computer and Computational Sciences},
pages = {445–449},
numpages = {5},
series = {IMSCCS '07}
}

@inproceedings{10.1145/3419249.3420105,
author = {Komatsu, Tomoko and Gutierrez Lopez, Marisela and Makri, Stephann and Porlezza, Colin and Cooper, Glenda and MacFarlane, Andrew and Missaoui, Sondess},
title = {AI should embody our values: Investigating journalistic values to inform AI technology design},
year = {2020},
isbn = {9781450375795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419249.3420105},
doi = {10.1145/3419249.3420105},
abstract = {In the current climate of shrinking newsrooms and revenues, journalists face increasing pressures exerted by the industry’s for-profit focus and the expectation of intensified output. While AI-enabled journalism has great potential to help alleviate journalists’ pressures, it might also disrupt journalistic norms and, at worst, interfere with their duty to inform the public. For AI systems to be as useful as possible, designers should understand journalists’ professional values and incorporate them into their designs. We report findings from interviews with journalists to understand their perceptions of how professional values that are important to them (such as truth, impartiality and originality) might be supported and/or undermined by AI technologies. Based on these findings, we provide design insight and guidelines for incorporating values into the design of AI systems. We argue HCI design can achieve the strongest possible value alignment by moving beyond merely supporting important values, to truly embodying them.},
booktitle = {Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
articleno = {11},
numpages = {13},
keywords = {values, value sensitive design, automated journalism, artificial intelligence, algorithmic systems},
location = {Tallinn, Estonia},
series = {NordiCHI '20}
}

@inproceedings{10.1145/3325413.3329793,
author = {Almeida, Mario and Laskaridis, Stefanos and Leontiadis, Ilias and Venieris, Stylianos I. and Lane, Nicholas D.},
title = {EmBench: Quantifying Performance Variations of Deep Neural Networks across Modern Commodity Devices},
year = {2019},
isbn = {9781450367714},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325413.3329793},
doi = {10.1145/3325413.3329793},
abstract = {In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators.},
booktitle = {The 3rd International Workshop on Deep Learning for Mobile Systems and Applications},
pages = {1–6},
numpages = {6},
keywords = {on-device inference, mobile devices, deep neural networks},
location = {Seoul, Republic of Korea},
series = {EMDL '19}
}

@article{10.1109/MIC.2022.3182349,
author = {Sheth, Amit and Gaur, Manas and Roy, Kaushik and Venkataraman, Revathy and Khandelwal, Vedant and Sheth, Amit},
title = {Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety},
year = {2022},
issue_date = {Sept.-Oct. 2022},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {26},
number = {5},
issn = {1089-7801},
url = {https://doi.org/10.1109/MIC.2022.3182349},
doi = {10.1109/MIC.2022.3182349},
abstract = {AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.},
journal = {IEEE Internet Computing},
month = {sep},
pages = {76–84},
numpages = {9}
}

@inproceedings{10.1145/2007052.2007087,
author = {Kumar, Gulshan and Kumar, Krishan},
title = {AI based supervised classifiers: an analysis for intrusion detection},
year = {2011},
isbn = {9781450306355},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2007052.2007087},
doi = {10.1145/2007052.2007087},
abstract = {Researchers investigated Artificial Intelligence (AI) based classifiers for intrusion detection to cope the weaknesses of knowledge based systems. AI based classifiers can be utilized in supervised and unsupervised mode.Here, we perform a blind set of experiments to compare &amp; evaluate performance of the supervised classifiers by their categories using variety of metrics. The performance of the classifiers is analyzed using subset of benchmarked KDD cup 1999 dataset as training &amp; Test dataset. This work has significant aspect of using variety of performance metrics to evaluate the supervised classifiers because some classifiers are designed to optimize some specific metric. This empirical analysis is not only a comparison of various classifiers to identify best classifier on the whole and best classifiers for individual attack classes, but also reveals guidelines for researchers to apply AI based classifiers to field of intrusion detection and directions for further research in this field.},
booktitle = {Proceedings of the International Conference on Advances in Computing and Artificial Intelligence},
pages = {170–174},
numpages = {5},
keywords = {intrusion detection, intrusion, feature reduction, classifiers, artificial intelligence},
location = {Rajpura/Punjab, India},
series = {ACAI '11}
}

@article{10.1145/3636508,
author = {Schelenz, Laura and Segal, Avi and Adelio, Oduma and Gal, Kobi},
title = {Transparency-Check: An Instrument for the Study and Design of Transparency in AI-based Personalization Systems},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636508},
doi = {10.1145/3636508},
abstract = {As AI-based systems become commonplace in our daily lives, they need to provide understandable information to their users about how they collect, process, and output information that concerns them. The importance of such transparency practices has gained significance due to recent ethical guidelines and regulation, as well as research suggesting a positive relationship between the transparency of AI-based systems and users’ satisfaction. This paper provides a new tool for the design and study of transparency in AI-based systems that use personalization. The tool, called Transparency-Check, is based on a checklist of questions about transparency in four areas of a system: input (data collection), processing (algorithmic models), output (personalized recommendations) and user control (user feedback mechanisms to adjust elements of the system). Transparency-Check can be used by researchers, designers, and end users of computer systems. To demonstrate the usefulness of Transparency-Check from a researcher perspective, we collected the responses of 108 student participants who used the transparency checklist to rate five popular real-world systems (Amazon, Facebook, Netflix, Spotify, and YouTube). Based on users’ subjective evaluations, the systems showed low compliance with transparency standards, with some nuances about individual categories (specifically data collection, processing, user control). We use these results to compile design recommendations for improving transparency in AI-based systems, such as integrating information about the system’s behavior during the user’s interactions with it.},
note = {Just Accepted},
journal = {ACM J. Responsib. Comput.},
month = {dec},
keywords = {Personalization, Artifical Intelligence, Design, Ethics, User Study, Best Practice, Guideline, Transparency}
}

@inproceedings{10.1145/3522664.3528590,
author = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
title = {Data smells: categories, causes and consequences, and detection of suspicious data in AI-based systems},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528590},
doi = {10.1145/3522664.3528590},
abstract = {High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {229–239},
numpages = {11},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@inproceedings{10.1145/3394486.3409557,
author = {Amershi, Saleema},
title = {Toward Responsible AI by Planning to Fail},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3409557},
doi = {10.1145/3394486.3409557},
abstract = {The potential for AI technologies to enhance human capabilities and improve our lives is of little debate; yet, neither is their potential to cause harm and social disruption. While preventing or minimizing AI biases and harms is justifiably the subject of intense study in academic, industrial and even legal communities, an approach centered on acknowledging and planning for AI-based failures has the potential to shed new light on how to develop and deploy responsible AI-based systems.In this talk, I will discuss the sociotechnical nature of several inherent and unavoidable AI failures and why it is important for the industry to systematically and proactively identify, assess, and mitigate harms caused by such failures in our AI-based products and services. I will then present Microsoft's recently released Guidelines for Human-AI Interaction and how we've been using them at Microsoft to help teams think through and prepare for different types of AI failures.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3607},
numpages = {1},
keywords = {responsible and ethical ai, human-ai interaction, guidelines},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{10.1145/3411764.3445591,
author = {Rietz, Tim and Maedche, Alexander},
title = {Cody: An AI-Based System to Semi-Automate Coding for Qualitative Research},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445591},
doi = {10.1145/3411764.3445591},
abstract = {Qualitative research can produce a rich understanding of a phenomenon but requires an essential and strenuous data annotation process known as coding. Coding can be repetitive and time-consuming, particularly for large datasets. Existing AI-based approaches for partially automating coding, like supervised machine learning (ML) or explicit knowledge represented in code rules, require high technical literacy and lack transparency. Further, little is known about the interaction of researchers with AI-based coding assistance. We introduce Cody, an AI-based system that semi-automates coding through code rules and supervised ML. Cody supports researchers with interactively (re)defining code rules and uses ML to extend coding to unseen data. In two studies with qualitative researchers, we found that (1) code rules provide structure and transparency, (2) explanations are commonly desired but rarely used, (3) suggestions benefit coding quality rather than coding speed, increasing the intercoder reliability, calculated with Krippendorff’s Alpha, from 0.085 (MAXQDA) to 0.33 (Cody).},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {394},
numpages = {14},
keywords = {User-centered design, Supervised machine learning, Rule-based coding, Qualitative research, Qualitative coding, Artifact design},
location = {<conf-loc>, <city>Yokohama</city>, <country>Japan</country>, </conf-loc>},
series = {CHI '21}
}

@article{10.1109/MCOM.001.1900103,
author = {Zhu, Guangxu and Liu, Dongzhu and Du, Yuqing and You, Changsheng and Zhang, Jun and Huang, Kaibin},
title = {Toward an Intelligent Edge: Wireless Communication Meets Machine Learning},
year = {2020},
issue_date = {January 2020},
publisher = {IEEE Press},
volume = {58},
number = {1},
issn = {0163-6804},
url = {https://doi.org/10.1109/MCOM.001.1900103},
doi = {10.1109/MCOM.001.1900103},
abstract = {The recent revival of AI is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and IoT devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interest in realizing an "intelligent edge" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, has emerged, which crosses and revolutionizes two disciplines: wireless communication and machine learning. A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design guidelines for wireless communication in edge learning, collectively called learning- driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design guidelines. Unique research opportunities are identified.},
journal = {Comm. Mag.},
month = {jan},
pages = {19–25},
numpages = {7}
}

@inproceedings{10.1109/IS3C.2012.153,
author = {Chan, Hui-Chun and Chen, Jong-Chen and Chien, Shou-Wei and Chen, Yung-Fu and Bau, Cho-Tsan},
title = {Evaluation of Intelligent System to the Control of Diabetes},
year = {2012},
isbn = {9780769546551},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/IS3C.2012.153},
doi = {10.1109/IS3C.2012.153},
abstract = {Diabetes, as the 4th death cause, has become a vital issue in the 21th century. However, blood sugar levels of most diabetic patients are not well controlled. For a patient with chronic disease, treatment efficiency could be influenced by the disease, remedy, and mental condition, in addition to his/her physiological status. Therefore, there is a great deal of difficulty in establishing a guideline to decide the reasonable dosage for a particular patient. To address this difficulty, this study, via team cooperation with the Department of Endocrinology and Metabolism, Taichung Hospital, has designed an artificial intelligence (AI) system. This AI system may provide a real-time monitoring of patient s physical condition and adjust the insulin dosage from AI system to facilitate the monitoring, caring, and management of patients. Furthermore, abnormal condition may be detected earlier and then emergency treatment may be provided in time to prevent the occurrence of any unfortunate events caused by negligence. With this system, data of 4 patients was partitioned into training data set (3/2) and test data set (1/3). Training data set was entered into ANM system for an analysis of learning stage to build a prediction model for insulin dosage. Upon the completion, the test data set was tested with this prediction model for the accuracy of dosage control by bioartificial pancreas. Results showed that ANM system may effectively predict the occurrence of problems related to insulin dosage of bioartificial pancreas, with a satisfactory accuracy.},
booktitle = {Proceedings of the 2012 International Symposium on Computer, Consumer and Control},
pages = {585–588},
numpages = {4},
keywords = {Evolutionary learning, Diabetes, Artificial neuromolecular networks, Artificial neural network},
series = {IS3C '12}
}

@article{10.1016/j.asoc.2023.110455,
author = {Ahmad, Khlood and Abdelrazek, Mohamed and Arora, Chetan and Agrahari Baniya, Arbind and Bano, Muneera and Grundy, John},
title = {Requirements engineering framework for human-centered artificial intelligence software systems},
year = {2023},
issue_date = {Aug 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {143},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2023.110455},
doi = {10.1016/j.asoc.2023.110455},
journal = {Appl. Soft Comput.},
month = {aug},
numpages = {19},
keywords = {Empirical software engineering, Virtual reality, Conceptual modeling, Human-centered, Machine learning, Artificial intelligence, Software engineering, Requirements engineering}
}

@inproceedings{10.1609/aiide.v18i1.21955,
author = {Kreminski, Max and Dickinson, Melanie and Wardrip-Fruin, Noah and Mateas, Michael},
title = {Loose ends: a mixed-initiative creative interface for playful storytelling},
year = {2022},
isbn = {978-1-57735-877-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aiide.v18i1.21955},
doi = {10.1609/aiide.v18i1.21955},
abstract = {We present Loose Ends, a mixed-initiative co-creative storytelling play experience in which a human player and an AI system work together to compose a story. Loose Ends specifically aims to provide computational support for managing multiple parallel plot threads and bringing these threads to satisfying conclusions—something that has proven difficult in past attempts to facilitate playful mixed-initiative storytelling. We describe the overall human-AI interaction loop in Loose Ends, including the implementation of the rules-based AI system that enables this interaction loop; discuss four examples of desirable mixed-initiative interactions that are possible in Loose Ends, but not in similar systems; and present results from a preliminary expert evaluation of Loose Ends. Altogether, we find that Loose Ends shows promise for creating a sense of coauthorship in the player while also mitigating the directionlessness reported by players of earlier systems.},
booktitle = {Proceedings of the Eighteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
articleno = {15},
numpages = {9},
location = {Pomona, CA, USA},
series = {AIIDE'22}
}

@article{10.1145/1044818.1044821,
author = {Cochran, Duane R. and Stocker, Frederick R.},
title = {RIPL: an environment for rapid prototyping with intelligent support},
year = {1985},
issue_date = {October 1985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {0736-6906},
url = {https://doi.org/10.1145/1044818.1044821},
doi = {10.1145/1044818.1044821},
abstract = {Rapid prototyping of the User-System Interface (USI) has proven to be an effective design, validation, and optimization technique. This paper describes the conceptual design of the Rapid Intelligent Prototyping Language (RIPL) environment. RIPL provides an automated environment that supports the USI designer with an Artificial Intelligence (AI) System, Display and Dialogue Definition Systems, and a User-System Simulator. With RIPL, dialogues are specified and edited interactively using state transition model graphics. Also, prototypes can be automatically instrumented to measure human performance.The AI components of RIPL are its most significant and unique elements. The RIPL AI System includes an expert system for USI design as well as other designer aids. These tools not only result in faster generation of prototypes, but increase USI quality from the human factors perspective. The expert system uses a knowledge base codified from USI design guidelines to answer designer queries and perform USI evaluation.},
journal = {SIGCHI Bull.},
month = {oct},
pages = {29–36},
numpages = {8}
}

@inproceedings{10.1007/978-3-031-40837-3_11,
author = {Tavolato-W\"{o}tzl, Christina and Tavolato, Paul},
title = {Enhancing Trust in Machine Learning Systems by Formal Methods: With an Application to a Meteorological Problem},
year = {2023},
isbn = {978-3-031-40836-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-40837-3_11},
doi = {10.1007/978-3-031-40837-3_11},
abstract = {With the deployment of applications based on machine learning techniques the need for understandable explanations of these systems’ results becomes evident. This paper clarifies the concept of an “explanation”: the main goal of an explanation is to build trust in the recipient of the explanation. This can only be achieved by creating an understanding of the results of the AI systems in terms of the users’ domain knowledge. In contrast to most of the approaches found in the literature, which base the explanation of the AI system’s results on the model provided by the machine learning algorithm, this paper tries to find an explanation in the specific expert knowledge of the system’s users. The domain knowledge is defined as a formal model derived from a set of if-then-rules provided by experts. The result from the AI system is represented as a proposition in a temporal logic. Now we attempt to formally prove this proposition within the domain model. We use model checking algorithms and tools for this purpose. If the proof is successful, the result of the AI system is consistent with the model of the domain knowledge. The model contains the rules it is based on and hence the path representing the proof can be translated back to the rules: this explains, why the proposition is consistent with the domain knowledge. The paper describes the application of this approach to a real world example from meteorology, the short-term forecasting of cloud coverage for particular locations.},
booktitle = {Machine Learning and Knowledge Extraction: 7th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2023, Benevento, Italy, August 29 – September 1, 2023, Proceedings},
pages = {170–187},
numpages = {18},
keywords = {Meteorology, Solar Radiation Forecast, Model Checking, Formal Methods, Machine Learning, Explainable AI},
location = {Benevento, Italy}
}

@article{10.1145/3631614,
author = {Larasati, Retno and De Liddo, Anna and Motta, Enrico},
title = {Meaningful Explanation Effect on User’s Trust in an AI Medical System: Designing Explanations for Non-Expert Users},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2160-6455},
url = {https://doi.org/10.1145/3631614},
doi = {10.1145/3631614},
abstract = {Whereas most research in AI system explanation for healthcare applications looks at developing algorithmic explanations targeted at AI experts or medical professionals, the question we raise is: How do we build meaningful explanations for laypeople? And how does a meaningful explanation affect user’s trust perceptions? Our research investigates how the key factors affecting human-AI trust change in the light of human expertise, and how to design explanations specifically targeted at non-experts. By means of a stage-based design method, we map the ways laypeople understand AI explanations in a User Explanation Model. We also map both medical professionals and AI experts’ practice in an Expert Explanation Model. A Target Explanation Model is then proposed, which represents how experts’ practice and layperson’s understanding can be combined to design meaningful explanations. Design guidelines for meaningful AI explanations are proposed, and a prototype of AI system explanation for non-expert users in a breast cancer scenario is presented and assessed on how it affect users’ trust perceptions.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {dec},
articleno = {30},
numpages = {39},
keywords = {artificial intelligence explanation, trust, Explanation}
}

@inproceedings{10.1145/3593434.3593453,
author = {Agbese, Mamia and Mohanani, Rahul and Khan, Arif and Abrahamsson, Pekka},
title = {Implementing AI Ethics: Making Sense of the Ethical Requirements},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3593453},
doi = {10.1145/3593434.3593453},
abstract = {Society’s increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {62–71},
numpages = {10},
keywords = {Ethical requirements stack, Ethical requirements, Agile portfolio management, AI ethics principles, AI ethics, AI},
location = {Oulu, Finland},
series = {EASE '23}
}

@article{10.1016/j.compbiomed.2022.106337,
author = {Vahadane, Abhishek and Sharma, Shreya and Mandal, Devraj and Dabbeeru, Madan and Jakthong, Josephine and Garcia-Guzman, Miguel and Majumdar, Shantanu and Lee, Chung-Wein},
title = {Development of an automated combined positive score prediction pipeline using artificial intelligence on multiplexed immunofluorescence images},
year = {2023},
issue_date = {Jan 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2022.106337},
doi = {10.1016/j.compbiomed.2022.106337},
journal = {Comput. Biol. Med.},
month = {jan},
numpages = {9},
keywords = {Deep learning, Artificial intelligence, AI, Formalin-fixed, paraffin-embedded, FFPE, Immune checkpoint inhibitors, ICI, Programmed cell death ligand 1, PD-L1, Program cell death protein 1, PD1, Head and neck squamous cell carcinoma, HNSCC, Immunohistochemistry, IHC, Multiplex immunofluorescence, mIF, Combined positive score, CPS}
}

@article{10.1007/s10462-022-10260-y,
author = {Nguyen, Khanh T. P. and Medjaher, Kamal and Tran, Do T.},
title = {A review of artificial intelligence methods for engineering prognostics and health management with implementation guidelines},
year = {2022},
issue_date = {Apr 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-022-10260-y},
doi = {10.1007/s10462-022-10260-y},
abstract = {The past decade has witnessed the adoption of artificial intelligence (AI) in various applications. It is of no exception in the area of prognostics and health management (PHM) where the capacity of AI has been highlighted through numerous studies. In this paper, we present a comprehensive review of AI-based solutions in engineering PHM. This review serves as a guideline for researchers and practitioners with varying levels of experience seeking to broaden their know-how about AI-based PHM. Specifically, we provide both a broad quantitative analysis and a comprehensive qualitative examination of the roles of AI in PHM. The quantitative analysis offers an insight into the research community’s interest in AI-based approaches, focusing on the evolution of research trends and their developments in different PHM application areas. The qualitative survey gives a complete picture on the employment of AI in each stage of the PHM process, from data preparation to decision support. Based on the strengths and weaknesses of existing methods, we derive a general guideline for choosing proper techniques for each specific PHM task, aiming to level up maintenance practitioners’ efficiency in implementing PHM solutions. Finally, the review discusses challenges and future research directions in the development of autonomous intelligent PHM solutions.},
journal = {Artif. Intell. Rev.},
month = {sep},
pages = {3659–3709},
numpages = {51},
keywords = {Decision-making support, Predictive maintenance, Machine learning, Condition monitoring, Prognostics and health management, Artificial intelligence}
}

@inproceedings{10.1145/3583780.3614732,
author = {Zong, Zefang and Yan, Huan and Sui, Hongjie and Li, Haoxiang and Jiang, Peiqi and Li, Yong},
title = {An AI-based Simulation and Optimization Framework for Logistic Systems},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614732},
doi = {10.1145/3583780.3614732},
abstract = {Improving logistics efficiency is a challenging task in logistic systems, since planning the vehicle routes highly relies on the changing traffic conditions and diverse demand scenarios. However, most existing approaches either neglect the dynamic traffic environment or adopt manually designed rules, which fails to efficiently find a high-quality routing strategy. In this paper, we present a novel artificial intelligence (AI) based framework for logistic systems. This framework can simulate the spatio-temporal traffic conditions to form a dynamic environment in a data-driven manner. Under such a simulated environment, it adopts deep reinforcement learning techniques to intelligently generate the optimized routing strategy. Meanwhile, we also design an interactive frontend to visualize the simulated environment and routing strategies, which help operators evaluate the task performance. We will showcase the results of AI-based simulation and optimization in our demonstration.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5138–5142},
numpages = {5},
keywords = {vehicle routing problem, travel time estimation, time-dependent graph, logistic system, deep reinforcement learning},
location = {<conf-loc>, <city>Birmingham</city>, <country>United Kingdom</country>, </conf-loc>},
series = {CIKM '23}
}

@inproceedings{10.1007/978-981-99-8024-6_8,
author = {Ji, Ilhwan and Jeon, Seungho and Seo, Jung Taek},
title = {AE-LSTM Based Anomaly Detection System for Communication Over DNP 3.0},
year = {2024},
isbn = {978-981-99-8023-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-981-99-8024-6_8},
doi = {10.1007/978-981-99-8024-6_8},
abstract = {Energy Management System (EMS) communicates with power plants and substations to maintain the reliability and efficiency of power supplies. EMS collects and monitors data from these sources and controls power flow through commands to ensure uninterrupted power supply, frequency and voltage maintenance, and power recovery in the event of a power outage. EMS works in a Distributed Network Protocol (DNP) 3.0-based network environment that is considered secure due to its unique security features and communication methods. However, cyberattacks exploiting the vulnerability of the DNP 3.0 protocol can manipulate the power generation output, resulting in serious consequences such as facility malfunction and power outages. To address this issue, this paper identifies security threats in power system networks, including DNP 3.0, and proposes an AI-based anomaly detection system based on DNP 3.0 network traffic. Existing network traffic target rule-based detection methods and signature-based detection methods have defects. We propose an AI-based anomaly detection system to compensate for defects in existing anomaly detection methods and perform efficient anomaly detection. To evaluate the performance of the AI-based anomaly detection system proposed in this paper, we used a dataset containing normal network traffic and nine types of attack network traffic obtained from the DNP 3.0 communication testbed, and experiments showed 99% accuracy, 98% TPR, and 1.6% FPR, resulting in 99% F-1 score. By implementing these security measures, power system network environments, including EMS, can be better protected against cyber threats.},
booktitle = {Information Security Applications: 24th International Conference, WISA 2023, Jeju Island, South Korea, August 23–25, 2023, Revised Selected Papers},
pages = {91–104},
numpages = {14},
keywords = {ICS, SCADA, EMS, AI-based Anomaly Detection System},
location = {<conf-loc content-type="InPerson">Jeju Island, Korea (Republic of)</conf-loc>}
}

@article{10.4018/JOEUC.308814,
author = {Yang, Yin and Siau, Keng and Xie, Wen and Sun, Yan},
title = {Smart Health: Intelligent Healthcare Systems in the Metaverse, Artificial Intelligence, and Data Science Era},
year = {2022},
issue_date = {Sep 2022},
publisher = {IGI Global},
address = {USA},
volume = {34},
number = {1},
issn = {1546-2234},
url = {https://doi.org/10.4018/JOEUC.308814},
doi = {10.4018/JOEUC.308814},
abstract = {In recent decades, healthcare organizations around the world have increasingly appreciated the value of information technologies for a variety of applications. Three of the new technological advancements that are impacting smart health are metaverse, artificial intelligence (AI), and data science. The metaverse is the intersection of three major technologies — AI, augmented reality (AR), and virtual reality (VR). Metaverse provides new possibilities and potential that are still emerging. The increased work efficiency enabled by artificial intelligence and data science in hospitals not only improves patient care but also cuts costs and workload for healthcare providers. Artificial intelligence, coupled with machine learning, is transforming the healthcare industry. The availability of big data enables data scientists to use the data for descriptive, predictive, and prescriptive analytics. This article reviews multiple case studies and the literature on AI and data science applications in hospital administration. The article also presents unresolved research questions and challenges in the applications of the metaverse, AI, and data science in the smart health context. For researchers, in addition to providing a good synopsis of the development and applications of the metaverse, AI, and data science in the healthcare area, this article identifies possible future research directions and discusses the possibilities of the metaverse, artificial intelligence, and data science in smart health. For practitioners, this article provides both hospital decision-makers and healthcare workers with practical guidelines and a smart health management model.},
journal = {J. Organ. End User Comput.},
month = {aug},
pages = {1–14},
numpages = {14},
keywords = {Smart Hospital, Smart Health, Hospital Management, Data Science, Artificial Intelligence}
}

@article{10.1016/S0360-8352(02)00213-9,
author = {Yu, H. and Reyes, A. and Cang, S. and Lloyd, S.},
title = {Combined Petri net modelling and AI-based heuristic hybrid search for flexible manufacturing systems-part II: heuristic hybrid search},
year = {2003},
issue_date = {April 2003},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {44},
number = {4},
issn = {0360-8352},
url = {https://doi.org/10.1016/S0360-8352(02)00213-9},
doi = {10.1016/S0360-8352(02)00213-9},
abstract = {This two-part paper presents modelling and scheduling approaches of flexible manufacturing systems using Petri nets (PNs) and artificial intelligence (AI)-based heuristic search methods. In Part I, PN-based modelling approaches and basic AI-based heuristic search algorithms were presented. In Part II, a new heuristic function that exploits PN information is proposed. Heuristic information obtained from the PN model is used to dramatically reduce the search space. This heuristic is derived from a new concept, the resource cost reachability matrix, which builds on the properties of B-nets proposed in Part I. Two hybrid search algorithms, (1) an approach to model dispatching rules using analysis information provided by the PN simulation and (2) an approach of the modified stage-search algorithm, are proposed to reduce the complexity of large systems. A random problem generator is developed to test the proposed methods. The experimental results show promising results.},
journal = {Comput. Ind. Eng.},
month = {apr},
pages = {545–566},
numpages = {22},
keywords = {stage search, resource cost reachability matrix, hybrid search, Petri net modelling, Heuristic search}
}

@inproceedings{10.1007/978-3-031-21707-4_34,
author = {Passalacqua, Mario and Pellerin, Robert and Doyon-Poulin, Philippe and Del-Aguila, Laur\`{e}ne and Boasen, Jared and L\'{e}ger, Pierre-Majorique},
title = {Human-Centred AI in the Age of Industry 5.0: A Systematic Review Protocol},
year = {2022},
isbn = {978-3-031-21706-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21707-4_34},
doi = {10.1007/978-3-031-21707-4_34},
abstract = {Research within AI-based Industry 4.0 (I4.0) work systems has predominantly focused on technical and process performance, while human and psychosocial factors are rarely examined. These factors must be considered to design human-centred systems that cultivate sustainable human-AI interaction, i.e., human-AI interaction that promotes long-term well-being, engagement, and performance. The European Commission has brought forward a new vision of I4.0 called Industry 5.0, where well-being and technological advancement are jointly considered, thus overcoming the weaknesses of I4.0. To move forward with Industry 5.0, it is necessary to consolidate our knowledge of human-technology interaction within I4.0. This systematic review aims to uncover the antecedents and consequences of human and psychosocial factors within AI-based I4.0 systems, with an end goal of providing guidelines for the sustainable design, implementation, and use of these systems. This protocol presents the background and the methodology behind our review, as well as preliminary results and expected contributions.},
booktitle = {HCI International 2022 – Late Breaking Papers: Interacting with EXtended Reality and Artificial Intelligence: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings},
pages = {483–492},
numpages = {10},
keywords = {Human factors, Psychosocial factors, Industry 4.0, Industry 5.0, Human-centred AI}
}

@article{10.1007/s10462-022-10381-4,
author = {Levshun, Diana and Kotenko, Igor},
title = {A survey on artificial intelligence techniques for security event correlation: models, challenges, and opportunities},
year = {2023},
issue_date = {Aug 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {8},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-022-10381-4},
doi = {10.1007/s10462-022-10381-4},
abstract = {Information systems need to process a large amount of event monitoring data. The process of finding the relationships between events is called correlation, which creates a context between independent events and previously collected information in real time and normalizes it for subsequent processing. In cybersecurity, events can determine the steps of attackers and can be analyzed as part of a specific attack strategy. In this survey, we present the systematization of security event correlation models in terms of their representation in AI-based monitoring systems as: rule-based, semantic, graphical and machine learning based-models. We define the main directions of current research in the field of AI-based security event correlation and the methods used for the correlation of both single events and their sequences in attack scenarios. We also describe the prospects for the development of hybrid correlation models. In conclusion, we identify the existing problems in the field and possible ways to overcome them.},
journal = {Artif. Intell. Rev.},
month = {jan},
pages = {8547–8590},
numpages = {44},
keywords = {Cybersecurity, Knowledge representation, Situational awareness, Data mining, Security event, Event correlation}
}

@inproceedings{10.1109/FUZZ-IEEE55066.2022.9882675,
author = {Kieseberg, Peter and Buttinger, Christina and Kaltenbrunner, Laura and Temper, Marlies and Tjoa, Simon},
title = {Security considerations for the procurement and acquisition of Artificial Intelligence (AI) systems},
year = {2022},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FUZZ-IEEE55066.2022.9882675},
doi = {10.1109/FUZZ-IEEE55066.2022.9882675},
abstract = {Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.},
booktitle = {2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
pages = {1–7},
numpages = {7},
location = {Padua, Italy}
}

@inproceedings{10.1145/3514094.3534187,
author = {Deshpande, Advait and Sharp, Helen},
title = {Responsible AI Systems: Who are the Stakeholders?},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534187},
doi = {10.1145/3514094.3534187},
abstract = {As of 2021, there were more than 170 guidelines on AI ethics and responsible, trustworthy AI in circulation according to the AI Ethics Guidelines Global Inventory maintained by AlgorithmWatch, an organisation which tracks the effects of increased digitalisation on everyday lives. However, from the perspective of day-to-day work, for those engaged in designing, developing, and maintaining AI systems identifying relevant guidelines and translating them into practice presents a challenge.The aim of this paper is to help anyone engaged in building a responsible AI system by identifying an indicative long-list of potential stakeholders. This list of impacted stakeholders is intended to enable such AI system builders to decide which guidelines are most suited to their practice. The paper draws on a literature review of articles short-listed based on searches conducted in the ACM Digital Library and Google Scholar. The findings are based on content analysis of the short-listed literature guided by probes which draw on the ISO 26000:2010 Guidance on social responsibility.The paper identifies three levels of potentially relevant stakeholders when responsible AI systems are considered: individual stakeholders (including users, developers, and researchers), organisational stakeholders, and national / international stakeholders engaged in making laws, rules, and regulations. The main intended audience for this paper is software, requirements, and product engineers engaged in building AI systems. In addition, business executives, policy makers, legal/regulatory experts, AI researchers, public, private, and third sector organisations developing responsible AI guidelines, and anyone interested in seeing functional responsible AI systems are the other intended audience for this paper.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {227–236},
numpages = {10},
keywords = {stakeholder identification, responsible AI systems, corporate social responsibility, ISO 26000:2010 guidance on social responsibility, AI system builders, AI ethics},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@article{10.1016/j.ipm.2022.103212,
author = {Charef, Nadia and Ben Mnaouer, Adel and Aloqaily, Moayad and Bouachir, Ouns and Guizani, Mohsen},
title = {Artificial intelligence implication on energy sustainability in Internet of Things: A survey},
year = {2023},
issue_date = {Mar 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {60},
number = {2},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2022.103212},
doi = {10.1016/j.ipm.2022.103212},
journal = {Inf. Process. Manage.},
month = {mar},
numpages = {42},
keywords = {Data aggregation and fusion, Swarm intelligence, AI, Machine learning, Energy awareness, Energy harvesting, Sustainability, IoT}
}

@article{10.1287/isre.2020.0980,
author = {Jussupow, Ekaterina and Spohrer, Kai and Heinzl, Armin and Gawlitza, Joshua},
title = {Augmenting Medical Diagnosis Decisions? An Investigation into Physicians’ Decision-Making Process with Artificial Intelligence},
year = {2021},
issue_date = {September 2021},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {32},
number = {3},
issn = {1526-5536},
url = {https://doi.org/10.1287/isre.2020.0980},
doi = {10.1287/isre.2020.0980},
abstract = {Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions, but they are not without errors and biases. Failure to detect those may result in wrong diagnoses and medical errors. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Thus, it is difficult, yet critical, for physicians to carefully evaluate AI advice. This study uncovers the cognitive challenges that medical decision makers face when they receive potentially incorrect advice from AI-based diagnosis systems and must decide whether to follow or reject it. In experiments with 68 novice and 12 experienced physicians, novice physicians with and without clinical experience as well as experienced radiologists made more inaccurate diagnosis decisions when provided with incorrect AI advice than without advice at all. We elicit five decision-making patterns and show that wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial evaluation of the AI advice. Our study has implications for the training of physicians and spotlights the crucial role of human actors in compensating for AI errors.Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Much research currently aims to improve AI technologies and debates their societal implications. Surprisingly little effort is spent on understanding the cognitive challenges of decision augmentation with AI-based systems although these systems make it more difficult for decision makers to evaluate the correctness of system advice and to decide whether to reject or accept it. As little is known about the cognitive mechanisms that underlie such evaluations, we take an inductive approach to understand how AI advice influences physicians’ decision-making process. We conducted experiments with a total of 68 novice and 12 experienced physicians who diagnosed patient cases with an AI-based system that provided both correct and incorrect advice. Based on qualitative data from think-aloud protocols, interviews, and questionnaires, we elicit five decision-making patterns and develop a process model of medical diagnosis decision augmentation with AI advice. We show that physicians use second-order cognitive processes, namely metacognitions, to monitor and control their reasoning while assessing AI advice. These metacognitions determine whether physicians are able to reap the full benefits of AI or not. Specifically, wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial information search. Our findings provide a first perspective on the metacognitive mechanisms that decision makers use to evaluate system advice. Overall, our study sheds light on an overlooked facet of decision augmentation with AI, namely, the crucial role of human actors in compensating for technological errors.},
journal = {Info. Sys. Research},
month = {sep},
pages = {713–735},
numpages = {23},
keywords = {advice taking, dual process, healthcare, metacognition, decision support, artificial intelligence, decision making}
}

@inproceedings{10.1145/3506469.3506473,
author = {Khullar, Aman and Panjal, Paramita and Pandey, Rachit and Burnwal, Abhishek and Raj, Prashit and Jha, Ankit Akash and Hitesh, Priyadarshi and Reddy, R Jayanth and Himanshu, Himanshu and Seth, Aaditeshwar},
title = {Experiences with the Introduction of AI-based Tools for Moderation Automation of Voice-based Participatory Media Forum},
year = {2022},
isbn = {9781450396073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3506469.3506473},
doi = {10.1145/3506469.3506473},
abstract = {Voice-based discussion forums where users can record audio messages which are then published for other users to listen and comment, are often moderated to ensure that the published audios are of good quality, relevant, and adhere to editorial guidelines of the forum. There is room for the introduction of AI-based tools in the moderation process, such as to identify and filter out blank or noisy audios, use speech recognition to transcribe the voice messages in text, and use natural language processing techniques to extract relevant metadata from the audio transcripts. We design such tools and deploy them within a social enterprise working in India that runs several voice-based discussion forums. We present our findings in terms of the time and cost-savings made through the introduction of these tools, and describe the feedback of the moderators towards the acceptability of AI-based automation in their workflow. Our work forms a case-study in the use of AI for automation of several routine tasks, and can be especially relevant for other researchers and practitioners involved with the use of voice-based technologies in developing regions of the world.},
booktitle = {Proceedings of the 12th Indian Conference on Human-Computer Interaction},
pages = {30–39},
numpages = {10},
keywords = {content moderation, automation, artificial intelligence, Interactive Voice Response systems},
location = {Virtual Event, India},
series = {IndiaHCI '21}
}

@inproceedings{10.1109/ISTAS52410.2021.9629170,
author = {Dennis, Jordyn and Grady, Caitlin and Rajtmajer, Sarah},
title = {Comparative assessment of cyber-physical threats to megacities},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISTAS52410.2021.9629170},
doi = {10.1109/ISTAS52410.2021.9629170},
abstract = {By 2030, forecasts suggest that urban areas will house 60 percent of the world’s population and one in every three people will live in cities with at least half a million inhabitants. Within the same time frame, the number of global megacities is expected to jump from 33 today to 43 in 2030 [1]. Underpinning these large urban areas will be an interconnected network of critical physical infrastructures reliant on Internet-connected Industrial Control Systems and susceptible to increasingly sophisticated, e.g., AI-enabled, cyber threats. In hand, the cyber threat landscape is shifting rapidly. We are seeing a sharp rise in the number of cyberattacks on critical infrastructure [2] with significant impacts cascading across multiple sectors and causing disruption to the provisioning of essential goods and services. Security scholars suggest that these impacts are not always equitable and that disruption to critical infrastructure can affect vulnerable groups differently [3], which further emphasizes the need to improve cybersecurity between critical infrastructure sectors [4]. Through structured analysis of city statistics, demographic information, cyber incidents, and current cyber policy, our presentation will articulate potential social implications of megacity growth through the lens of cyber-physical infrastructure disruption. We investigate the largest 15 megacities in the world and find that megacities continue to grow in population but not in cyber policy. We highlight recent examples of cyber-physical disruption in Mumbai and New York City with focus on implications for vulnerable populations. Our work suggests the need for future research on social responsibility regarding security of these critical infrastructure sectors and on the need for technology-focused law, policy, and regulation guidelines.},
booktitle = {2021 IEEE International Symposium on Technology and Society (ISTAS)},
pages = {1},
numpages = {1},
location = {Waterloo, ON, Canada}
}

@article{10.1016/j.eswa.2015.03.023,
author = {Mohd Ali, Jarinah and Hussain, M.A. and Tade, Moses O. and Zhang, Jie},
title = {Artificial Intelligence techniques applied as estimator in chemical process systems - A literature survey},
year = {2015},
issue_date = {August 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {14},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.03.023},
doi = {10.1016/j.eswa.2015.03.023},
abstract = {Intensive review of AI applied as estimators in chemical process systems.Provide guidelines to select and design AI-based estimators.Discussed the advantages, limitations and compare each algorithm.Future suggestions and directions of the research. The versatility of Artificial Intelligence (AI) in process systems is not restricted to modelling and control only, but also as estimators to estimate the unmeasured parameters as an alternative to the conventional observers and hardware sensors. These estimators, also known as software sensors have been successfully applied in many chemical process systems such as reactors, distillation columns, and heat exchanger due to their robustness, simple formulation, adaptation capabilities and minimum modelling requirements for the design. However, the various types of AI methods available make it difficult to decide on the most suitable algorithm to be applied for any particular system. Hence, in this paper, we provide a broad literature survey of several AI algorithms implemented as estimators in chemical systems together with their advantages, limitations, practical implications and comparisons between one another to guide researchers in selecting and designing the AI-based estimators. Future research suggestions and directions in improvising and extending the usage of these estimators in various chemical operating units are also presented.},
journal = {Expert Syst. Appl.},
month = {aug},
pages = {5915–5931},
numpages = {17},
keywords = {Soft-sensor, Estimator, Chemical process systems, Artificial Intelligence}
}

@article{10.1016/j.csi.2019.103361,
author = {Turan, Ertan and \c{C}etin, G\"{u}rcan},
title = {Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {66},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2019.103361},
doi = {10.1016/j.csi.2019.103361},
journal = {Comput. Stand. Interfaces},
month = {oct},
numpages = {11},
keywords = {Virtual environment, Unity 3D modeling, Fuzzy logic, Artificial intelligence, Animal behaviors}
}

@inproceedings{10.1145/3311957.3361858,
author = {Bennett, Sarah Joy},
title = {Investigating the Role of Moral Decision-Making in Emerging Artificial Intelligence Technologies},
year = {2019},
isbn = {9781450366922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311957.3361858},
doi = {10.1145/3311957.3361858},
abstract = {In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development.},
booktitle = {Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {28–32},
numpages = {5},
keywords = {ethics, design, artificial intelligence},
location = {Austin, TX, USA},
series = {CSCW '19 Companion}
}

@inproceedings{10.1145/3205946.3205962,
author = {Loi, Daria},
title = {Intelligent, Affective Systems: People's Perspective &amp; Implications},
year = {2018},
isbn = {9781450364294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205946.3205962},
doi = {10.1145/3205946.3205962},
abstract = {AI-based systems are shifting and will increasingly shift how we relate to content, context and each other. This extended keynote abstract discusses insights from a global study that focused on people's perceptions, attitudes, thresholds and expectations of intelligent systems as well as their perspectives on smart home, autonomous cars, and smart workspace. Insights helped create ten design guidelines to assist intelligent systems designers, technologists and decision makers.},
booktitle = {Proceedings of the 4th International Conference on Human-Computer Interaction and User Experience in Indonesia, CHIuXiD '18},
pages = {101–104},
numpages = {4},
keywords = {User Experience, System Design, Artificial Intelligence, Affective Computing},
location = {Yogyakarta, Indonesia},
series = {CHIuXiD '18}
}

@inproceedings{10.1145/3548606.3563539,
author = {Wang, Ningfei and Luo, Yunpeng and Sato, Takami and Xu, Kaidi and Chen, Qi Alfred},
title = {Poster: On the System-Level Effectiveness of Physical Object-Hiding Adversarial Attack in Autonomous Driving},
year = {2022},
isbn = {9781450394505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548606.3563539},
doi = {10.1145/3548606.3563539},
abstract = {In Autonomous Driving (AD) systems, perception is both security and safety-critical. Among different attacks on AD perception, object-hiding adversarial attack is one of the most critical ones due to the direct impact on safety-critical driving decisions such as collision avoidance. However, all of the prior works on physical object-hiding adversarial attacks only study the security of the AI component alone rather than with the entire AD system pipeline with closed-loop control. This thus inevitably raises a critical research question: can these prior works actually achieve system-level effects (e.g., vehicle collisions, traffic rule violation) under real-world AD settings with closed-loop control?To answer this critical question, in this work we take the necessary first step by performing the first measurement study on whether and how effective the existing designs can lead to system-level effects. Our early results find that RP2 and FTE, as two representative examples of prior works, cannot achieve any system-level effect in a representative closed-loop AD setup in common STOP sign-controlled road speeds. In the future, we plan to 1) perform a more comprehensive measurement study using both simulated environments and a real vehicle-sized AD R&amp;D chassis; and 2) analyze the measurement study results and explore new attack designs that can better achieve the system-level effect in AD systems.},
booktitle = {Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3479–3481},
numpages = {3},
keywords = {system-level effect, object hiding attack, autonomous driving (ad) system security},
location = {Los Angeles, CA, USA},
series = {CCS '22}
}

@phdthesis{10.5555/AAI29061985,
author = {Ebbeler, Raymond Walter and Sharon, Kimmel,},
advisor = {Charles, Beverley, and Robert, Davis,},
title = {Following the Path of Small and Medium-Sized Medical Technology Startups Seeking Funding Before FDA Clearance},
year = {2022},
isbn = {9798209987611},
publisher = {Northcentral University},
abstract = {There is a problem for medical technology startups in the US with obtaining funding for the regulation of new medical devices before FDA clearance. The selection criteria identified small and medium medical device companies (SMMDCs) in the top 15 cities for the medical technology industry excluding non-US SMMDCs. Limited responses required secondary data to supplement the interviews conducted. The application of a semi-structure interview allowed a comprehensive data analysis with only three participants. While consensus was observed for all participants regarding the FDA's cybersecurity program with the FDA' medical device breakthrough, the sample size was small which required approval for modifying the study by the Northcentral University' Institutional Review Board. Thus, secondary data was acquired from the SMMDC' websites as press releases, newswires, and branding of a combination medical device. The CEO and decision maker of several SMMDCs depended also on the Securities Exchange Commission's (SEC) EDGAR search engine to identify Form D document, rule 506 (b and c) for private placement. Recommendations for practice is the integration of primary and secondary data with NVivo version 12 software. The thematic analysis indicated two and three-word group associations to infer as saturation and triangulation respectively. Recommendations for future research were telehealth with artificial intelligence (AI), augmented reality (AR), three-dimensional (3-D) Printing, and Blockchain technology a qualitative management system for a combination medical device. Finally, a coalition model addressed technological innovation diffusion with business incubators and accelerators relative to government and non-governmental organizations. Crunchbase, as an accelerator portal, identified SMMDC's pre seed and seed capital for early-stage funding under $1-3 million and late-stage funding for Series A and Series B funding as $20 - $50 million to avoid the valley of death and for expansion and growth.},
note = {AAI29061985}
}

@article{10.1609/aimag.v30i4.2262,
author = {Lau, Tessa},
title = {Why Programming by Demonstration Systems Fail: Lessons Learned for Usable AI},
year = {2009},
issue_date = {Winter 2009},
publisher = {American Association for Artificial Intelligence},
address = {USA},
volume = {30},
number = {4},
issn = {0738-4602},
url = {https://doi.org/10.1609/aimag.v30i4.2262},
doi = {10.1609/aimag.v30i4.2262},
abstract = {Programming by demonstration systems have long attempted to make it possible for people to program computers without writing code. However, while these systems have resulted in many publications in AI venues, none of the technologies have yet achieved widespread adoption. Usability remains a critical barrier to their success. On the basis of lessons learned from three different programming by demonstration systems, we present a set of guidelines to consider when designing usable AI‐based systems.},
journal = {AI Mag.},
month = {dec},
pages = {65–67},
numpages = {3}
}

@article{10.1145/3635715,
author = {Pant, Aastha and Hoda, Rashina and Spiegler, Simone V. and Tantithamthavorn, Chakkrit and Turhan, Burak},
title = {Ethics in the Age of AI: An Analysis of AI Practitioners’ Awareness and Challenges},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3635715},
doi = {10.1145/3635715},
abstract = {Ethics in AI has become a debated topic of public and expert discourse in recent years. But what do people who build AI – AI practitioners – have to say about their understanding of AI ethics and the challenges associated with incorporating it into the AI-based systems they develop? Understanding AI practitioners’ views on AI ethics is important as they are the ones closest to the AI systems and can bring about changes and improvements. We conducted a survey aimed at understanding AI practitioners’ awareness of AI ethics and their challenges in incorporating ethics. Based on 100 AI practitioners’ responses, our findings indicate that the majority of AI practitioners had a reasonable familiarity with the concept of AI ethics, primarily due to workplace rules and policies. Privacy protection and security was the ethical principle that the majority of them were aware of. Formal education/training was considered somewhat helpful in preparing practitioners to incorporate AI ethics. The challenges that AI practitioners faced in the development of ethical AI-based systems included (i) general challenges, (ii) technology-related challenges, and (iii) human-related challenges. We also identified areas needing further investigation and provided recommendations to assist AI practitioners and companies in incorporating ethics into AI development.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {dec},
keywords = {Survey, Challenges, Awareness, AI practitioners, AI ethics}
}

@inproceedings{10.1007/978-3-030-50341-3_32,
author = {Mari, Alex and Mandelli, Andreina and Algesheimer, Ren\'{e}},
title = {The Evolution of Marketing in the Context of Voice Commerce: A Managerial Perspective},
year = {2020},
isbn = {978-3-030-50340-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50341-3_32},
doi = {10.1007/978-3-030-50341-3_32},
abstract = {The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N = 62) revealed the expected impact of voice assistants on the shopping process. Findings show that managers consider voice assistants a disruptive technology assuming a central relational role in the consumer market. However, they often divergence in opinions across industry, function, and seniority level. Besides, managers’ familiarity with voice commerce is correlated to a higher optimism towards voice technologies (opportunity for brands) but also a greater sense of urgency (short-term focus) with implications for marketing strategy. This article offers support to brand owners explaining how voice assistants work and examining their effects on consumption. The authors discuss empirical results while providing managerial guidelines to create resilient and sustainable brands in the era of voice commerce.},
booktitle = {HCI in Business, Government and Organizations: 7th International Conference, HCIBGO 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {405–425},
numpages = {21},
keywords = {Machine behavior, Marketing, Voice commerce, Voice assistant},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3351095.3375784,
author = {Noriega-Campero, Alejandro and Garcia-Bulle, Bernardo and Cantu, Luis Fernando and Bakker, Michiel A. and Tejerina, Luis and Pentland, Alex},
title = {Algorithmic targeting of social policies: fairness, accuracy, and distributed governance},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3375784},
doi = {10.1145/3351095.3375784},
abstract = {Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and widespread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them---and who is not---are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {241–251},
numpages = {11},
keywords = {targeted social programs, proxy means tests, cash transfers, algorithmic fairness, AI for social good},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@article{10.1145/382272.382273,
author = {O'Hare, Anthony B. and Sheth, Amit P.},
title = {The interpreted-compiled range of AI/DB systems},
year = {1989},
issue_date = {March 1989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {0163-5808},
url = {https://doi.org/10.1145/382272.382273},
doi = {10.1145/382272.382273},
abstract = {A range of approaches to integrating rule-based Artificial Intelligence (AI) systems and Database Management Systems are classified according to the degree of compilation that is performed by the AI system. This interpreted—compiled range provides a framework for enumerating several relevant aspects of AI/DB systems, for showing how these aspects vary along the dimension, and for comparing and contrasting previous work on AI/DB systems. In particular, this framework focuses on the nature of the interaction between the two systems as well as some of the consequences of the particular approach with respect to the utilization, functionality, and performance of each of the two systems.},
journal = {SIGMOD Rec.},
month = {mar},
pages = {32–42},
numpages = {11}
}

@article{10.1016/0950-7051(92)90006-2,
author = {Wang, W. and Bell, R.},
title = {Multilevel manufacturing knowledge in an AI-based modelling system for the design of flexible machining cells},
year = {1992},
issue_date = {June 1992},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {5},
number = {2},
issn = {0950-7051},
url = {https://doi.org/10.1016/0950-7051(92)90006-2},
doi = {10.1016/0950-7051(92)90006-2},
abstract = {The design and implementation of flexible machining cells calls for a systematic modelling methodology. An AI-based modelling system is briefly described that is capable of modelling alternative facilities over multiple levels of detail. Emphasis is then placed on the presentation of the manufacturing knowledge embedded within the three levels of modelling. The operational assumptions, the state transformation and the decision making at each level are closely described, and typical behavioural and decision rules are discussed.},
journal = {Know.-Based Syst.},
month = {jun},
pages = {158–166},
numpages = {9},
keywords = {knowledge-based modelling, hierarchical abstraction, flexible machining}
}

@inproceedings{10.1145/3447548.3470823,
author = {Ahmad, Muhammad Aurangzeb and Overman, Steve and Allen, Christine and Kumar, Vikas and Teredesai, Ankur and Eckert, Carly},
title = {Software as a Medical Device: Regulating AI in Healthcare via Responsible AI},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470823},
doi = {10.1145/3447548.3470823},
abstract = {With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4023–4024},
numpages = {2},
keywords = {xai, responsible ai, interpretable machine learning, fairness in machine learning, explainable ai, ai in healthcare},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1007/978-3-031-21648-0_23,
author = {Bhoi, Suman and Sourav, Suman},
title = {Towards Understanding and&nbsp;Improving Handwriting with&nbsp;AI},
year = {2022},
isbn = {978-3-031-21647-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21648-0_23},
doi = {10.1007/978-3-031-21648-0_23},
abstract = {What makes a handwriting good? If the aesthetic judgment of handwriting follows implicit rules, can those rules be recovered by observing good and bad examples? To answer these questions, we apply explainability techniques to the classification of good and bad handwriting. We show that it is indeed possible to recover these inherent rules. We develop an AI system that uses a modified version of LIME Image Explainer and generates images containing suggestions for improvement. We use single-character and word-level datasets labelled with binary labels generated via accepted rules for handwriting classification. We discuss the possible improvements to the current system as well as where this research could be applied, such as user-specific auto-suggestions.},
booktitle = {Frontiers in Handwriting Recognition: 18th International Conference, ICFHR 2022, Hyderabad, India, December 4–7, 2022, Proceedings},
pages = {331–344},
numpages = {14},
keywords = {Feature attribution, Explainability, Handwriting analysis},
location = {Hyderabad, India}
}

@inproceedings{10.5555/846229.848774,
author = {Gimeno, J. M. and Bejar, J. and Lafuente, J.},
title = {Providing wastewater treatment plants with predictive knowledge based on transition networks},
year = {1997},
isbn = {0818682183},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Presents a progress report on integrating predictive skills into an integrated AI system for wastewater treatment plant (WWTP) supervision and control. Although the embedded approaches within the previously developed architecture, called DAI-DEPUR, such as numerical control knowledge, rule-based reasoning and case-based reasoning, are able to cope with the overall supervision task of a plant, one feature is missing: predictive knowledge. With the previous approaches, the supervisory system works reasonably well, but the actuation process always restores the normal operation of a WWTP tardily. Thus, the supervision is implemented in an a posteriori fashion, which can be very dangerous for the environment. The integration of a new kind of knowledge can overcome this problem of control systems.},
booktitle = {Proceedings of the 1997 IASTED International Conference on Intelligent Information Systems (IIS '97)},
pages = {355},
keywords = {water treatment, wastewater treatment plant supervision, transition networks, rule-based reasoning, predictive knowledge, plant control systems, numerical control knowledge, normal operation restoration, integrated AI system, environmental dangers, embedded approaches, case-based reasoning, actuation process, a posteriori implementation, DAI-DEPUR},
series = {IIS '97}
}

@inproceedings{10.1145/3311957.3359433,
author = {Park, Sun Young and Kuo, Pei-Yi and Barbarin, Andrea and Kaziunas, Elizabeth and Chow, Astrid and Singh, Karandeep and Wilcox, Lauren and Lasecki, Walter S.},
title = {Identifying Challenges and Opportunities in Human-AI Collaboration in Healthcare},
year = {2019},
isbn = {9781450366922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311957.3359433},
doi = {10.1145/3311957.3359433},
abstract = {The proposed workshop will identify research questions that will enable the field to uncover the types of work, labor relations, and social impacts that should be considered when designing AI-based healthcare technology. The workshop aims to outline key challenges, guidelines, and future agendas for the field, and provide collaboration opportunities for CSCW researchers, social scientists, AI researchers, clinicians, and relevant stakeholders in healthcare, to share their perspectives and co-create sociotechnical approaches to tackle timely issues related to AI and automation in healthcare work.},
booktitle = {Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {506–510},
numpages = {5},
keywords = {sociotechnical systems, machine learning, healthcare, explainable ai, automation, artificial intelligence, algorithms, ai transparency, ai fairness},
location = {Austin, TX, USA},
series = {CSCW '19 Companion}
}

@book{10.5555/1537129,
author = {Bellazzi, Riccardo and Abu-Hanna, Ameen and Hunter, Jim},
title = {Artificial Intelligence in Medicine: 11th Conference on Artificial Intelligence in Medicine in Europe, AIME 2007, Amsterdam, The Netherlands, July 7-11, ... / Lecture Notes in Artificial Intelligence)},
year = {2007},
isbn = {3540735984},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This book constitutes the refereed proceedings of the 11th Conference on Artificial Intelligence in Medicine in Europe, AIME 2007, held in Amsterdam, The Netherlands in July 2007. The 28 revised full papers and 38 revised short papers presented were carefully reviewed and selected from 137 submissions. The papers are organized in topical sections on agent-based systems, temporal data mining, machine learning and knowledge discovery, text mining, natural language processing and generation, ontologies, decision support systems, applications of AI-based image processing techniques, protocols and guidelines, as well as workflow systems.}
}

@article{10.1016/j.jss.2022.111604,
author = {Heyn, Hans-Martin and Knauss, Eric and Pelliccione, Patrizio},
title = {A compositional approach to creating architecture frameworks with an application to distributed AI systems},
year = {2023},
issue_date = {Apr 2023},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {198},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2022.111604},
doi = {10.1016/j.jss.2022.111604},
journal = {J. Syst. Softw.},
month = {apr},
numpages = {19},
keywords = {Systems engineering, Requirements engineering, Compositional thinking, Architectural frameworks, AI systems}
}

@phdthesis{10.5555/AAI29030873,
author = {Yao, Heming and A., Williamson, Craig and Alan, Boyle, and Harm, Derksen, and Alla, Karnovsky, and S., Omenn, Gilbert and W, Stidham, Ryan},
advisor = {Kayvan, Najarian,},
title = {Machine Learning and Image Processing for Clinical Outcome Prediction: Applications in Medical Data from Patients with Traumatic Brain Injury, Ulcerative Colitis, and Heart Failure},
year = {2021},
isbn = {9798780610069},
publisher = {University of Michigan},
address = {USA},
abstract = {Artificial intelligence (AI) and machine learning (ML) have achieved extensive success in many fields. They are powerful in pattern recognition and function modeling. The digitization of health data provides an important opportunity for improving care delivery and patient management through the AI-based clinical decision-support (CDS) system. Medical images are important components in evaluating the disease severity. While the human's interpretation of medical images is subjective and qualitative, AI-based models can analyze those data in a more reproducible, quantitative, and less expensive way. With clinical observations and quantitative findings extracted from medical images, ML methods can be used to learn and discover knowledge. The automated CDS system can provide recommendations on diagnosis, treatment, and outcome prediction by leveraging massive medical data. Those systems can facilitate drug development, disease pathology research, and clinical practice. This dissertation investigates medical image analysis and CDS systems development in a more reliable, interpretable manner. Limitations exist in applying AI/ML techniques in medical problems. Medical data may have high variability in terms of the patient population, collection site, equipment, and imaging protocols. It is crucial that the ML and image processing algorithms have a good generalizability and can be reliably applied to unseen patient data. In addition, a broad spectrum of AI/ML methods is among the "black box" models. The lack of justification leads to concerns and hesitations of using AI/ML techniques in clinical or research practice. Features with clinical meaning and models that can be well explained can gain more trust and are more favorable to end-users. In this dissertation, several AI-based CDS systems have been designed and implemented to facilitate clinical and research practice. Novel algorithms are proposed to overcome the challenges of applying AI/ML techniques. To improve the generalizability of the deep learning models, a robust learning algorithm is proposed to encourage the network to be invariant to hematoma intensity variability. A Scale Module and filter pruning technique are proposed to reduce the network's size and complexity. To improve the interpretability of the CDS systems, a transparent ML algorithm is proposed based on tropical geometry and fuzzy logic, which can learn humanly understandable rules from the dataset and integrate existing domain knowledge to facilitate the model training. Domain knowledge plays an important role in the design of CDS systems. With automated image analysis methods, quantitative and objective measurements are extracted to capture the patient's condition and disease characteristics in a meaningful and reproducible way. The proposed CDS systems have been validated using data collected from routine practice and clinical trials. The datasets used in this dissertation are from multiple medial centers, which increases the generalizability of the proposed frameworks and trained models. This work aims to research the capacity of AI models toward fully automated CDS systems that can replicate expert judgment and provide insight for the patient. Efforts have been made to improve the generalizability and interpretability of AI/ML models, which are the major limitations that hinder a broad application of AI techniques in practice. The proposed algorithms and strategies in this dissertation leverage big data to improve the healthcare system and disease research. Additionally, the proposed methods are transferable beyond the target application. The contributions of this dissertation have a meaningful impact on applying AI-based systems to clinical and research practice.},
note = {AAI29030873}
}

@article{10.1016/j.jss.2022.111475,
author = {Giordano, Giammaria and Palomba, Fabio and Ferrucci, Filomena},
title = {On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review},
year = {2022},
issue_date = {Nov 2022},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {193},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2022.111475},
doi = {10.1016/j.jss.2022.111475},
journal = {J. Syst. Softw.},
month = {nov},
numpages = {25},
keywords = {Software engineering for IoT, Internet-of-Things, Artificial intelligence, Data privacy}
}

@article{10.1016/j.eswa.2021.115597,
author = {Sachan, Swati and Almaghrabi, Fatima and Yang, Jian-Bo and Xu, Dong-Ling},
title = {Evidential reasoning for preprocessing uncertain categorical data for trustworthy decisions: An application on healthcare and finance},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {185},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115597},
doi = {10.1016/j.eswa.2021.115597},
journal = {Expert Syst. Appl.},
month = {dec},
numpages = {27},
keywords = {Trustworthy, Evidential reasoning, Decision-making, Uncertainty, Categorical}
}

@article{10.1109/TLT.2022.3225432,
author = {Tomi\'{c}, Bojan B. and Kijev\v{c}anin, Anisja D. and \v{S}evarac, Zoran V. and Jovanovi\'{c}, Jelena M.},
title = {An AI-based Approach for Grading Students’ Collaboration},
year = {2023},
issue_date = {June 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {3_Part_1},
issn = {1939-1382},
url = {https://doi.org/10.1109/TLT.2022.3225432},
doi = {10.1109/TLT.2022.3225432},
abstract = {Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made—something that proved to be very important to teachers.},
journal = {IEEE Trans. Learn. Technol.},
month = {jun},
pages = {292–305},
numpages = {14}
}

@article{10.1007/s10044-023-01163-x,
author = {Oommen, B. John and Omslandseter, Rebekka Olsson and Jiao, Lei},
title = {The object migration automata: its field, scope, applications, and future research challenges},
year = {2023},
issue_date = {Aug 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {3},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-023-01163-x},
doi = {10.1007/s10044-023-01163-x},
abstract = {Partitioning, in and of itself, is an NP-hard problem. Prior to the Artificial Intelligence (AI)-based solutions, it was solved in the 1970s by optimization-based strategies. However, AI-based solutions appeared in the 1980s in a pioneering way, by using a Learning Automaton (LA)-motivated strategy known as the so-called Object Migrating Automaton (OMA). Although the OMA and its derivatives have been used in numerous applications since then, the basic kernel has remained the same. Because the number of possible partitions in a partitioning problem can be combinatorially exponential and the underlying tasks are NP-hard, the most advanced OMA algorithms could, until recently, only solve issues involving equally sized groups. Due to our recent innovations cited in the body of this paper, the enhanced OMA now also handles non-equally sized groups. Earlier, we had presented in Omslandseter (Pattern Anal Appl, 2023), a comprehensive survey of the state-of-the-art enhancements of the best-known OMA. We believe that these results will be the benchmark for a few decades and that it will be very hard to beat these results. This is a companion paper, intended to augment the contents of Omslandseter (Pattern Anal Appl, 2023). In this paper, we first discuss the OMA’s prior applications, its historical and current innovations, and the OMA-based algorithms’ relevance to societal needs. We also provide well-specified guidelines for future researchers so that they can use them for unresolved tasks, and also develop further advancements.},
journal = {Pattern Anal. Appl.},
month = {apr},
pages = {917–928},
numpages = {12},
keywords = {Partitioning, Object migration automata, Learning automata}
}

@article{10.1002/smr.2543,
author = {Dzhusupova, Rimma and Banotra, Richa and Bosch, Jan and Olsson, Helena Holmstr\"{o}m},
title = {Using artificial intelligence to find design errors in the engineering drawings},
year = {2023},
issue_date = {December 2023},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {35},
number = {12},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2543},
doi = {10.1002/smr.2543},
abstract = {Artificial intelligence is increasingly becoming important to businesses because many companies have realized the benefits of applying machine learning (ML) and deep learning (DL) in their operations. ML and DL have become attractive technologies for organizations looking to automate repetitive tasks to reduce manual work and free up resources for innovation. Unlike rule‐based automation, typically used for standardized and predictable processes, machine learning, especially deep learning, can handle more complex tasks and learn over time, leading to greater accuracy and efficiency improvements. One of such promising applications is to use AI to reduce manual engineering work. This paper discusses a particular case within McDermott where the research team developed a DL model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). We also present a cost‐benefit analysis and potential scale‐up of the developed software. Our goal is to share the successful experience of AI‐based product development that can substantially reduce the engineering hours and, therefore, reduce the project's overall costs. The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry. It also could motivate practitioners and researchers to create similar products for the various fields within engineering industry.This paper discusses a particular case where the research team developed a deep learning model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry.


image
image},
journal = {J. Softw. Evol. Process},
month = {feb},
numpages = {19},
keywords = {piping and instrumentation diagrams (P&amp;IDs), object recognition, engineering, procurement, and construction (EPC) industry, engineering drawings, deep learning, artificial intelligence}
}

@inproceedings{10.1109/ProComm53155.2022.00078,
author = {McKee, Heidi A. and Porter, James E.},
title = {Team Roles &amp; Rhetorical Intelligence in Human-Machine Writing},
year = {2022},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ProComm53155.2022.00078},
doi = {10.1109/ProComm53155.2022.00078},
abstract = {This paper examines AI-based writing systems and how humans might partner with these systems to produce effective professional communication. We offer a taxonomy for examining roles in human-machine teaming for writing: Resource Tool, Assistant, Writer, and Executive Decision-Maker (whether at the beginning or end of the project). In particular, we focus on humanmachine teaming in relation to what we call rhetorical intelligence, the ability to invent and write for audience, purpose, and context. We examine human-machine writing by focusing on two cases: GameChanger and Phrazor by vPhrase. We conclude by proposing some guidelines for human-machine teaming for the production of professional communication.},
booktitle = {2022 IEEE International Professional Communication Conference (ProComm)},
pages = {384–391},
numpages = {8},
location = {Limerick, Ireland}
}

@inproceedings{10.1145/3514094.3539522,
author = {Xu, Yifan},
title = {Dialogue Explanation With Reasoning for AI},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3539522},
doi = {10.1145/3514094.3539522},
abstract = {Explainable Artificial Intelligence is increasingly gaining attention in domains, such as self-driving cars and medical treatment. One of the most prevalent issues with these explainable models is that they are difficult to comprehend and have not been tested in real-world scenarios. In this research, I propose a dialogue-based explanation with reasoning for a rule-based system with the intention of utilising it in the future with a Neuro Symbolic AI system, to give machines the capacity to explain their actions or decisions using logic. We hypothesize that when a system makes a deduction that was, in some way, unexpected by the user then locating the source of the disagreement or misunderstanding is best achieved through a collaborative dialogue process that allows the participants to gradually isolate the cause. I also conduct a user evaluation for this hypothesis.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {918},
numpages = {1},
keywords = {neuro symbolic, machine reasoning, explainable artificial intelligence (XAI), dialogue for explanation, artificial intelligence (ai)},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@phdthesis{10.5555/AAI29164242,
author = {He, Jingxi and Won, Yoon, Sang and Hiroki, Sayama, and W, Lewis, Harold},
advisor = {Daehan, Won,},
title = {An AI-Based Pick-and-Place Control for Quality Enhancement in Surface Mount Technology},
year = {2022},
isbn = {9798834049036},
publisher = {State University of New York at Binghamton},
address = {USA},
abstract = {The main goal of this dissertation is to investigate an AI-based pick-and-placeclosed-loop control system capable of identifying optimal placement positions in adynamic manufacturing environment. According to the industrial survey, assembly defects account for over 55% of field failures in passive components (the mostfrequently used chips on printed circuit boards). Moreover, the pick and placement(P&amp;P) cause over half of the assembly defects. Thus, the P&amp;P process is criticalto improving surface mount technology (SMT). Components have traditionallybeen aligned with the pad centers, referred to as a place-on-pad (PP), and it isthe most widely used method in the industry. However, with the miniaturizationof electronic components, assembly defects have increased. Recently, an adaptiveplacement strategy has been introduced to improve assembly quality [1], called the"place-on-paste" (PPS). In our experiment with miniature passive components,PPS outperformed PP in some instances. As a result, an advanced placementstrategy should be developed to improve the mini-size component assembly consistently. With limited historical data, this research proposes an AI-based P&amp;Pcontrol system that uses both rule-based and machine learning-based placementmethods. For the former, a PB is used to account for the offsets of the printedpaste. Then, multiple dynamic placement options with synthetic placement dataare generated. A hybrid machine learning algorithm predicts the final componentivmisalignment based on the data. Finally, multiple decision-making rules identify the optimal placement option based on the prediction results. According tothe experimental results, the machine learning-based model outperforms PP in adynamic environment. In various application scenarios, the proposed frameworkoutperforms industrial placement strategies.},
note = {AAI29164242}
}

@inproceedings{10.5555/1867135.1867263,
author = {Doorenbos, Bob and Tambe, Milind and Newell, Allen},
title = {Learning 10,000 chunks: what's it like out there?},
year = {1992},
isbn = {0262510634},
publisher = {AAAI Press},
abstract = {This paper describes an initial exploration into large learning systems, i.e., systems that learn a large number of rules. Given the well-known utility problem in learning systems, efficiency questions are a major concern. But the questions are much broader than just efficiency, e.g., will the effectiveness of the learned rules change with scale? This investigation uses a single problem-solving and learning system, Dispatcher-Soar, to begin to get answers to these questions. Dispatcher-Soar has currently learned 10, 112 new productions, on top of an initial system of 1, 819 productions, so its total size is 11, 931 productions. This represents one of the largest production systems in existence, and by far the largest number of rules ever learned by an AI system. This paper presents a variety of data from our experiments with Dispatcher-Soar and raises important questions for large learning systems.},
booktitle = {Proceedings of the Tenth National Conference on Artificial Intelligence},
pages = {830–836},
numpages = {7},
location = {San Jose, California},
series = {AAAI'92}
}

@phdthesis{10.5555/AAI28767347,
author = {Liu, Bingjie and Beth, Oliver, Mary},
advisor = {Shyam, Sundar, S.},
title = {Effects of Agency Locus and Transparency of Artificial Intelligence: Uncertainty Reduction and Emerging Mind},
year = {2020},
isbn = {9798535587745},
publisher = {The Pennsylvania State University},
abstract = {Existing research and mass media conceptualize interactive technologies, such as social robots and voice assistants, as machines without true agency despite their apparent autonomy and human-likeness. This is because they are often machines fully programmed by humans and act by following human-made rules. However, self-learning artificial intelligence (AI), which is increasingly used in powering many interactive technologies, is not fully programmed and does not merely follow human-made rules, but instead, learns rules from data with so little human interference that we quite often do not even understand the rules it has learned. The shift of agency locus from human to machine and the lack of transparency of the learning outcomes raise new questions for human-machine communication. How do individuals react to machines that learn autonomously yet remain opaque and mysterious? What measures should we take to cultivate appropriate levels of trust in such machines?To answer these questions, the current study examines the effects of an AI system's agency locus, meaning whether it makes decisions by following human-made rules (human-agency AI) or rules it has learned from data by itself (machine-agency AI), and the level of transparency about such rules (no transparency vs. placebic transparency vs. real transparency), upon users' cognitions, affects, and behaviors toward an AI system. Two online experiments following a 2 (agency locus: human vs. machine) X 3 (transparency: no vs. placebic vs. real) factorial design were conducted in two contexts (fake news detection and personality evaluation).Across contexts, the human-agency AI triggered more person presence, homophily, and was more trusted than the machine-agency AI. The machine-agency AI was perceived as more autonomous and triggered more "mind perception," which also enhanced trust. Real transparency about AI's internal states (i.e., rules) reduced uncertainty and increased mind perception, both of which enhanced trust. By reducing uncertainty, real transparency reduced anxiety and induced more excitement. Underlying the influence of agency locus and transparency of AI on trust are both a route of anthropomorphism (person presence → uncertainty reduction → trust) and a non-anthropomorphism route of mind perception (perceived autonomy or direct access → mind perception → trust).The actual processes are found to be governed by laws of intergroup communication, interpersonal communication, and information processing. Specifically, participants were less influenced by peripheral cues with categorical information (i.e., agency locus) when they had enough cognitive resources (i.e., more past experience with AI applications, or with real transparency). Participants were more motivated to scrutinize messages about an AI system's internal states when the need for uncertainty reduction was high (i.e., when interacting with the machine-agency AI). Contexts, as proxies of individuals' goal structures and social densities, were found to influence outcomes of human-machine interaction by potentially influencing their level of involvement and expectancies.Findings suggest that for machine-learning AI, users recognize it as a mind that is not necessarily humanlike, and that having knowledge about its internal states can to some extent help individuals surpass the human-machine ontological boundary, go beyond the anthropomorphism route, and develop trust in AI. Findings shed light on fundamental interpersonal processes and the larger question of the problem of other minds. In addition, findings also have methodological implications for research on human-machine interaction and practical implications for the design of intelligent machines in general and the design of AI transparency in particular, while also informing policy-making about AI regulations in terms of transparency and accountability.},
note = {AAI28767347}
}

@article{10.5555/1384910.1453673,
author = {Duc, LeMinh and Sidhu, Amandeep Singh and Chaudhari, Narendra S.},
title = {Hierarchical pathfinding and AI-based learning approach in strategy game design},
year = {2008},
issue_date = {January 2008},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2008},
issn = {1687-7047},
abstract = {Strategy game and simulation application are an exciting area with many opportunities for study and research. Currently most of the existing games and simulations apply hard coded rules so the intelligence of the computer generated forces is limited. After some time, player gets used to the simulation making it less attractive and challenging. It is also costly and tedious to incorporate new rules for an existing game. The main motivation behind this research project is to improve the quality of artificial intelligence- (AI-) based on various techniques such as qualitative spatial reasoning (Forbus et al., 2002), near-optimal hierarchical pathfinding (HPA*) (Botea et al., 2004), and reinforcement learning (RL) (Sutton and Barto, 1998).},
journal = {Int. J. Comput. Games Technol.},
month = {jan},
articleno = {3},
numpages = {11}
}

@article{10.1007/s00500-023-09330-2,
author = {Song, Yang and He, Yingwei},
title = {Toward an intelligent tourism recommendation system based on artificial intelligence and IoT using Apriori algorithm},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-023-09330-2},
doi = {10.1007/s00500-023-09330-2},
abstract = {In recent years, the rapid development of the Internet has promoted the continuous expansion of the scale of China’s tourism industry, and the amount of tourism data has surged. However, tourists need help bringing personal interest and high-value data from the plethora of tourism information. The rise of artificial intelligence has transformed traditional tourism into an intelligent, data-driven industry. This shift has generated vast tourism data, offering both opportunities and challenges. The paper discusses an AI and IoT-based Intelligent Tourism Recommendation System (ITRS) that offers travelers predefined itineraries, personalized suggestions, and tourism insights. This system simplifies attraction discovery, unveiling hidden value within tourism data at the intersection of AI and IoT. The present study thoroughly investigates AI-based recommendation algorithms before delving into the system’s architecture. It categorizes user-based, project-based, and article-based collaborative filtering methodologies tailored to specific goals. First, thoroughly examine AI-based recommendation algorithms before delving into the system architecture. Second, categorize collaborative filtering methods as user-based, project-based, and article-based, each tailored to specific objectives. Third, delve into the Apriori algorithm’s complexity within the context of weighted association rules and introduce an enhanced iteration for improved efficiency. The proposed scheme encompasses an elaborate ITRS plan featuring a user interest model and a client module, crucial for the computation and analysis of users’ long-term and short-term interests. Rigorous performance testing confirms the ITRS’s superiority across varying support levels, with experimental results demonstrating the Apriori algorithm’s exceptional accuracy, achieving a 94.3% improvement over other methods. The Apriori algorithm is better than traditional recommendation algorithms such as Linear Regression, Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, K-nearest neighbor, Naive Bayes, and XGBoost.},
journal = {Soft Comput.},
month = {oct},
pages = {19159–19177},
numpages = {19},
keywords = {Apriori algorithm, Intelligent tourism recommendation system, Artificial intelligence, Internet}
}

@article{10.1145/3370270,
author = {Ertl, Tanja and Taugerbeck, Sebastian and Esau, Margarita and Aal, Konstantin and Tolmie, Peter and Wulf, Volker},
title = {The Social Mile - How (Psychosocial) ICT can Help to Promote Resocialization and to Overcome Prison},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {GROUP},
url = {https://doi.org/10.1145/3370270},
doi = {10.1145/3370270},
abstract = {There is currently uncertainty in the research community as to how ICT can and should be designed in such a way that it can be convincingly integrated into the everyday lives of prison inmates. In this paper, we discuss a design fiction that closes this research gap. The descriptions and results of the study are purely fictitious. Excluded is the State of the Art as well as the description of the legal situation of prisons in Germany. The analysis of the fictional study data designed here thus refers to the real world in order to derive ethical guidelines and draw practical conclusions. It is our intention to use these results as a possible basis for further research. The paper presents results of an explorative study dealing with the design, development and evaluation of an AI-based Smart Mirror System, Prison AI 2.0, in a German prison. Prison AI 2.0 was developed for daily use and voluntarily tested by eight prisoners over a period of 12 months to gain insight into their individual and social impact, with an emphasis on its ability to actively support rehabilitation. Based on qualitative data, our findings suggest that intelligent AI-based devices can actually help promote such an outcome. Our results also confirm the valuable impact of (Psychosocial) ICT on the psychological, social and individual aspects of prison life, and in particular how prisoners used the Smart Mirror system to improve and maintain their cognitive, mental and physical state and to restore social interactions with the outside world. With the presentation of these results we want to initiate discussions about the use of ICT by prisoners in closed prisons in order to identify opportunities and risks.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {dec},
articleno = {248},
numpages = {31},
keywords = {voice-based technology, social participation, smart mirror, qualitative research, psychosocial ict, prisoners, prison, digital participation, cscw, ai-infused}
}

@inproceedings{10.5555/1620163.1620168,
author = {Dietterich, Thomas G. and Bao, Xinlong},
title = {Integrating multiple learning components through Markov logic},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
abstract = {This paper addresses the question of how statistical learning algorithms can be integrated into a larger AI system both from a practical engineering perspective and from the perspective of correct representation, learning, and reasoning. Our goal is to create an integrated intelligent system that can combine observed facts, hand-written rules, learned rules, and learned classifiers to perform joint learning and reasoning. Our solution, which has been implemented in the CALO system, integrates multiple learning components with a Markov Logic inference engine, so that the components can benefit from each other's predictions. We introduce two designs of the learning and reasoning layer in CALO: the MPE Architecture and the Marginal Probability Architecture. The architectures, interfaces, and algorithms employed in our two designs are described, followed by experimental evaluations of the performance of the two designs. We show that by integrating multiple learning components through Markov Logic, the performance of the system can be improved and that the Marginal Probability Architecture performs better than the MPE Architecture.},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 2},
pages = {622–627},
numpages = {6},
location = {Chicago, Illinois},
series = {AAAI'08}
}

@inproceedings{10.1007/978-3-030-78227-6_38,
author = {Ruiz, Cinthia and Quaresma, Manuela},
title = {UX Aspects of AI Principles: The Recommender System of VoD Platforms},
year = {2021},
isbn = {978-3-030-78226-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78227-6_38},
doi = {10.1007/978-3-030-78227-6_38},
abstract = {This paper aims to investigate the user experience with recommender systems of Video on Demand (VoD) platforms based in Machine Learning (ML), focusing on the Artificial Intelligence (AI) principles. We start from the hypothesis that the inclusion of AI algorithms has the potential to improve the user experience in digital systems, but they are still developed with a greater focus on technology, however, they should also consider more aspects regarding human factors. Nine principles on AI related to UX were selected from a compilation of seven lists of government and industry entities to understand the bases that every AI system should respect to ensure a good user experience. In sequence, we discuss their effects on the user experience of VoD platforms. To finish, the experience with these platforms were explored in a directed storytelling method involving thirty-one participants. Some behaviors and patterns found were analyzed and discussed to suggest guidelines to be applied to ML algorithms of VoD Platforms.},
booktitle = {Design, User Experience, and Usability:  Design for Contemporary Technological Environments: 10th International Conference, DUXU 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part III},
pages = {535–552},
numpages = {18},
keywords = {Recommender system, Artificial Intelligence (AI), User Experience (UX)}
}

@inproceedings{10.1145/3633083.3633223,
author = {Danilevskyi, Mykhailo and Perez Tellez, Fernando},
title = {On the compliance with ethical principles in AI},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633223},
doi = {10.1145/3633083.3633223},
abstract = {In recent years, there has been a lot of discussion around ethics in IT and AI. Researchers and organizations have proposed guidelines to address privacy, fairness, and explainability challenges for creating trustworthy AI. In this work, we outline the importance of compliance with the above-mentioned ethical principles and their influence on the quality of AI systems. We map the relationship between available approaches for compliance with privacy, fairness, explainability principles and the accuracy of AI system decisions. Additionally, we introduce the difference between ensuring fairness for phenomena presented with tabular data and text. Tabular data may contain protected attributes such as gender, age, or race as well as the decision made historically in relation to the people concerned. Data presented in text is not structured and requires sense perception by AI systems to detect bias or unfairness. In the poster, we compare available approaches and present experiments for measuring bias in text data.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {50},
numpages = {1},
keywords = {Bias detection, Ethics in AI, Fairness, Text data},
location = {<conf-loc>, <city>Dublin</city>, <country>Ireland</country>, </conf-loc>},
series = {HCAIep '23}
}

@inproceedings{10.5555/3586210.3586384,
author = {M\"{o}bius, Michael and Kallfass, Daniel and Doll, Thomas and Kunde, Dietmar},
title = {AI-Based Military Decision Support Using Natural Language},
year = {2023},
publisher = {IEEE Press},
abstract = {To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2082–2093},
numpages = {12},
location = {Singapore, Singapore},
series = {WSC '22}
}

@inproceedings{10.1145/3568294.3580127,
author = {Foster, Mary Ellen and Candelaria, Patricia and Dwyer, Lauren J. and Hudson, Summer and Lindsay, Alan and Nishat, Fareha and Pacquing, Mykelle and Petrick, Ronald P. A. and Ram\'{\i}rez-Duque, Andr\'{e}s Alberto and Stinson, Jennifer and Zeller, Frauke and Ali, Samina},
title = {Co-design of a Social Robot for Distraction in the Paediatric Emergency Department},
year = {2023},
isbn = {9781450399708},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568294.3580127},
doi = {10.1145/3568294.3580127},
abstract = {We are developing a social robot to help children cope with painful and distressing medical procedures in the hospital emergency department. This is a domain where a range of interventions have proven effective at reducing pain and distress, including social robots; however, until now, the robots have been designed with limited stakeholder involvement and have shown limited autonomy. For our system, we have defined and validated the necessary robot behaviour together with children, parents/caregivers, and healthcare professionals, taking into account the ethical and social implications of robotics and AI in the paediatric healthcare context. The result of the co-design process has been captured in a flowchart, which has been converted into a set of concrete design guidelines for the AI-based autonomous robot system.},
booktitle = {Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {461–465},
numpages = {5},
keywords = {socially assistive robots, co-design, child-robot interaction},
location = {Stockholm, Sweden},
series = {HRI '23}
}

@article{10.1609/aimag.v16i4.1169,
author = {Senator, Ted E. and Goldberg, Henry G. and Wooton, Jerry and Cottini, Matthew A. and Khan, A. F. Umar and Klinger, Christina D. and Llamas, Winston M. and Marrone, Michael P. and Wong, Raphael W. H.},
title = {The Financial Crimes Enforcement Network AI System (Fais): Identifying Potential Money Laundering from Reports of Large Cash Transactions1},
year = {1995},
issue_date = {Winter 1995},
publisher = {American Association for Artificial Intelligence},
address = {USA},
volume = {16},
number = {4},
issn = {0738-4602},
url = {https://doi.org/10.1609/aimag.v16i4.1169},
doi = {10.1609/aimag.v16i4.1169},
abstract = {The Financial Crimes Enforcement Network (FINCEN) AI system (fais) links and evaluates reports of large cash transactions to identify potential money laundering. The objective of fais is to discover previously unknown, potentially high‐value leads for possible investigation. fais integrates intelligent human and software agents in a cooperative discovery task on a very large data space. It is a complex system incorporating several aspects of AI technology, including rule‐based reasoning and a blackboard. fais consists of an underlying database (that functions as a blackboard), a graphic user interface, and several preprocessing and analysis modules. fais has been in operation at FINCEN since March 1993; a dedicated group of analysts process approximately 200,000 transactions a week, during which time over 400 investigative support reports corresponding to over $1 billion in potential laundered funds were developed. fais's unique analytic power arises primarily from a change in view of the underlying data from a transaction‐oriented perspective to a subject‐oriented (that is, person or organization) perspective.},
journal = {AI Mag.},
month = {dec},
pages = {21–39},
numpages = {19}
}

@inproceedings{10.1007/978-3-031-40878-6_4,
author = {Xu, Yifan and Collenette, Joe and Dennis, Louise and Dixon, Clare},
title = {Dialogue Explanations for Rule-Based AI Systems},
year = {2023},
isbn = {978-3-031-40877-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-40878-6_4},
doi = {10.1007/978-3-031-40878-6_4},
abstract = {The need for AI systems to explain themselves is increasingly recognised as a priority, particularly in domains where incorrect decisions can result in harm and, in the worst cases, death. Explainable Artificial Intelligence (XAI) tries to produce human-understandable explanations for AI decisions. However, most XAI systems prioritize factors such as technical complexities and research-oriented goals over end-user needs, risking information overload. This research attempts to bridge a gap in current understanding and provide insights for assisting users in comprehending the rule-based system’s reasoning through dialogue. The hypothesis is that employing dialogue as a mechanism can be effective in constructing explanations. A dialogue framework for rule-based AI systems is presented, allowing the system to explain its decisions by engaging in “Why?” and “Why not?” questions and answers. We establish formal properties of this framework and present a small user study with encouraging results that compares dialogue-based explanations with proof trees produced by the AI System.},
booktitle = {Explainable and Transparent AI and Multi-Agent Systems: 5th International Workshop, EXTRAAMAS 2023, London, UK, May 29, 2023, Revised Selected Papers},
pages = {59–77},
numpages = {19},
location = {London, United Kingdom}
}

@inproceedings{10.1109/FUZZ48607.2020.9177770,
author = {Alonso, Jose M. and Toja-Alamancos, J. and Bugar\'{\i}n, A.},
title = {Experimental Study on Generating Multi-modal Explanations of Black-box Classifiers in terms of Gray-box Classifiers},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/FUZZ48607.2020.9177770},
doi = {10.1109/FUZZ48607.2020.9177770},
abstract = {Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets.},
booktitle = {2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@inproceedings{10.1007/978-3-030-50334-5_10,
author = {Wallach, Dieter P. and Flohr, Lukas A. and Kaltenhauser, Annika},
title = {Beyond the Buzzwords: On the&nbsp;Perspective of AI in UX and Vice Versa},
year = {2020},
isbn = {978-3-030-50333-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-50334-5_10},
doi = {10.1007/978-3-030-50334-5_10},
abstract = {Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies.},
booktitle = {Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings},
pages = {146–166},
numpages = {21},
keywords = {Autonomous vehicles, Autonomous mobility-on-demand, Intensive care, Clinical decision support systems, ACT-R, Predictive prototyping, Case studies, Design, Human factors, Human-AI Interaction, AI and UX, Artificial Intelligence, User experience},
location = {Copenhagen, Denmark}
}

@inproceedings{10.5555/3524938.3525281,
author = {Gottesman, Omer and Futoma, Joseph and Liu, Yao and Parbhoo, Sonali and Celi, Leo Anthony and Brunskill, Emma and Doshi-Velez, Finale},
title = {Interpretable off-policy evaluation in reinforcement learning by highlighting influential transitions},
year = {2020},
publisher = {JMLR.org},
abstract = {Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares, as well as importance sampling methods. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {343},
numpages = {10},
series = {ICML'20}
}

@inproceedings{10.5555/3504035.3504221,
author = {Oudah, Mayada and Rahwan, Talal and Crandall, Tawna and Crandall, Jacob W.},
title = {How AI wins friends and influences people in repeated games with cheap talk},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as "if you can't say something nice, don't say anything at all" and principles articulated in Carnegie's classic How to Win Friends and Influence People, offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {186},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@article{10.1007/s10676-023-09693-y,
author = {Azafrani, Rachel and Gupta, Abhishek},
title = {Bridging the civilian-military divide in responsible AI principles and practices},
year = {2023},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {1388-1957},
url = {https://doi.org/10.1007/s10676-023-09693-y},
doi = {10.1007/s10676-023-09693-y},
abstract = {Advances in AI research have brought increasingly sophisticated capabilities to AI systems and heightened the societal consequences of their use. Researchers and industry professionals have responded by contemplating responsible principles and practices for AI system design. At the same time, defense institutions are contemplating ethical guidelines and requirements for the development and use of AI for warfare. However, varying ethical and procedural approaches to technological development, research emphasis on offensive uses of AI, and lack of appropriate venues for multistakeholder dialogue have led to differing operationalization of responsible AI principles and practices among civilian and defense entities. We argue that the disconnect between civilian and defense responsible development and use practices leads to underutilization of responsible AI research and hinders the implementation of responsible AI principles in both communities. We propose a research roadmap and recommendations for dialogue to increase exchange of responsible AI development and use practices for AI systems between civilian and defense communities. We argue that generating more opportunities for exchange will stimulate global progress in the implementation of responsible AI principles.},
journal = {Ethics and Inf. Technol.},
month = {apr},
numpages = {5},
keywords = {Military applications, Military, Responsible AI, AI ethics, Machine learning, Artificial intelligence (AI)}
}

@inproceedings{10.5555/1867270.1867314,
author = {Doorenbos, Robert B.},
title = {Matching 100,045 learned rules},
year = {1993},
isbn = {0262510715},
publisher = {AAAI Press},
abstract = {This paper examines several systems which learn a large number of rules (productions), including one which learns 113,938 rules - the largest number ever learned by an AI system, and the largest number in any production system in existence. It is important to match these rules dficiently, in order to avoid the machine learning utility problem. Moreover, examination of such large systems reveals new phenomena and calls into question some common assumptions based on previous observations of smalkr systems. We first show that the Rete and Treat match algorithms do not scale well with the number of rules in our systems, in part because the number of rules affected by a change to working memory increases with the total number of rules in these systems. We also show that the sharing of nodes in the beta part of the Rete network becomes more and more important as the number of rules increases. Finally, we describe and evaluate a new optimization for Rete which improves its scalability and allows two of our systems to learn over 100,000 rules without significant performance degradation.},
booktitle = {Proceedings of the Eleventh National Conference on Artificial Intelligence},
pages = {290–296},
numpages = {7},
location = {Washington, D.C.},
series = {AAAI'93}
}

@inproceedings{10.5555/2832581.2832600,
author = {Sun, Rongju and Lian, Zhouhui and Tang, Yingmin and Xiao, Jianguo},
title = {Aesthetic visual quality evaluation of Chinese handwritings},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
abstract = {Aesthetic evaluation of Chinese calligraphy is one of the most challenging tasks in Artificial Intelligence. This paper attempts to solve this problem by proposing a number of aesthetic feature representations and feeding them into Artificial Neural Networks. Specifically, 22 global shape features are presented to describe a given handwritten Chinese character from different aspects according to classical calligraphic rules, and a new 10-dimensional feature vector is introduced to represent the component layout information using sparse coding. Moreover, a Chinese Handwriting Aesthetic Evaluation Database (CHAED) is also built by collecting 1000 Chinese handwriting images with diverse aesthetic qualities and inviting 33 subjects to evaluate the aesthetic quality for each calligraphic image. Finally, back propagation neural networks are constructed with the concatenation of the proposed features as input and then trained on our CHAED database for the aesthetic evaluation of Chinese calligraphy. Experimental results demonstrate that the proposed AI system provides a comparable performance with human evaluation. Through our experiments, we also compare the importance of each individual feature and reveal the relationship between our aesthetic features and the aesthetic perceptions of human beings.},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {2510–2516},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {IJCAI'15}
}

@techreport{10.5555/897095,
author = {Neiman, Daniel E.},
title = {An Implementation of Multiple Worlds for Partallel Rule-Firing Production Systems},
year = {1993},
publisher = {University of Massachusetts},
address = {USA},
abstract = {One of the principal advantages of parallelizing a rule-based system, or more generally, any A.I. system, is the ability to pursue alternate search paths concurrently. Conventional memory representations for production systems cannot easily or efficiently support parallel search because of the essentially flat structure of working memory and the combinatorics of pursuing pattern matching in a large memory space. A further obstacle to the effective exploitation of parallelism is the problem of maintaining the internal consistency of each search space while performing parallel activities in other spaces. This paper presents an approach to parallel search for rule-based systems which involves maintaining multiple separate worlds, each representing a search space. Constructs for creating, manipulating, and merging separate spaces are discussed. We describe how the addition of a language mechanism for specifying multiple worlds simplifies the design of parallel search algorithms, increases the efficiency of the pattern matcher, provides a framework for implementing advanced control mechanisms such as task-based or hierarchical problem solvers, and reduces or eliminates the overhead of runtime consistency checking.}
}

@inproceedings{10.1007/978-3-031-09342-5_6,
author = {Woensel, William Van and Scioscia, Floriano and Loseto, Giuseppe and Seneviratne, Oshani and Patton, Evan and Abidi, Samina and Kagal, Lalana},
title = {Explainable Clinical Decision Support: Towards Patient-Facing Explanations for Education and Long-Term Behavior Change},
year = {2022},
isbn = {978-3-031-09341-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-09342-5_6},
doi = {10.1007/978-3-031-09342-5_6},
abstract = {There is an increasing shift towards the self-management of long-term chronic illness by patients in a home setting, supported by personal health electronic equipment. Among others, self-management requires comprehensive education on the illness, i.e., understanding the effects of nutritional, fitness, and medication choices on personal health; and long-term health behavior change, i.e., modifying unhealthy lifestyles that contribute to chronic illness. Smart health recommendations, generated using AI-based Clinical Decision Support (CDS), can guide patients towards positive nutritional, fitness, and health behavioral choices. Moreover, we posit that explaining these recommendations to patients, using Explainable AI (XAI) techniques, will effect education and positive behavior change. We present our work towards an explanation framework for rule-based CDS, called EXPLAIN (EXPLanations of AI In N3), which aims to generate human-readable, patient-facing explanations.},
booktitle = {Artificial Intelligence in Medicine: 20th International Conference on Artificial Intelligence in Medicine, AIME 2022, Halifax, NS, Canada, June 14–17, 2022, Proceedings},
pages = {57–62},
numpages = {6},
keywords = {Semantic Web, Clinical Decision Support, Explainable AI},
location = {Halifax, NS, Canada}
}

@inbook{10.5555/2184180.2184191,
author = {Funika, W$#322;odzimierz and Szura, Filip and Kitowski, Jacek},
title = {Automation of system monitoring based on fuzzy logic or rules; comparison of two designed approaches with regard to computational infrastructures},
year = {2012},
isbn = {9783642282669},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper is focused on monitoring automation of distributed systems. In the presented research, AI-based approaches to distributed monitoring related to large distributed systems such as grids, were explored. In both presented concepts knowledge is used to make decisions regarding management actions, using rules and fuzzy logic. The first concept is an agent-less rule-based solution, implemented in a high-level monitoring system called Saude-Net. It allows to define actions for monitored resources, using a kind of expert system. The second solution, which exploits agents and fuzzy logic, is realized in a system called SAMM Compliant Agent. Both presented systems are capable of reacting to observed failures and of modifying their knowledge to better fit possible problems with resources. We also present a short comparison of the two concepts, and an analysis of their usage.},
booktitle = {Building a National Distributed E-Infrastructure - PL-Grid: Scientific and Technical Achievements},
pages = {142–156},
numpages = {15}
}

@article{10.1145/3590151,
author = {Li, Juntao},
title = {Information Processing for Low Resource Processing Based Cognitive Psychology for Second Language Teaching by Opinion Mining using Deep Learning Architecture},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3590151},
doi = {10.1145/3590151},
abstract = {Foreign language instruction is crucial and difficult in every nation. Effective teachers must consider students' attitudes, motivation, and knowledge. Quality teaching determines student success. This study presents an AI-based deep learning method for second language and English instruction. This dataset was collected from students' second language and English teaching preferences. Dimensionality reduction and missing value removal were done on the dataset. Fuzzy set-based clustering with stochastic gradient residual neural network (ResNet) architecture classified this processed data. Students' second language and English teaching opinions were collected using fuzzy rules. Fuzzy clustering and stochastic gradient ResNet architecture classified this data. Student opinion mining was used for experimental study of various datasets and the parametric analysis yielded 96% accuracy, 90% sensitivity, 92% specificity, 82% F-1 score, 72% Mean squared error (MSE), and 88% Area Under the Curve (AUC).},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {apr},
keywords = {classification, English teaching, second language learning, AI, CALL}
}

@article{10.4018/IJEGR.298216,
author = {Kuberkar, Sachin and Singhal, Tarun Kumar and Singh, Shikha},
title = {Fate of AI for Smart City Services in India: A Qualitative Study},
year = {2022},
issue_date = {Mar 2022},
publisher = {IGI Global},
address = {USA},
volume = {18},
number = {2},
issn = {1548-3886},
url = {https://doi.org/10.4018/IJEGR.298216},
doi = {10.4018/IJEGR.298216},
abstract = {With the rollout of the smart city initiative in India, this study explores potential risks and opportunities in adopting artificial intelligence (AI) for citizen services. The study deploys expert interview technique and the data collected from various sources are analyzed using qualitative analysis. It was found that AI implementation needs a critical examination of various socio-technological factors to avoid any undesirable impacts on citizens. Fairness, accountability, transparency, and ethics (FATE) play an important role during the design and execution of AI-based systems. This study provides vital insights into AI implications to smart city managers, citizen groups, and policymakers while delivering promised smart city experience. The study has social implications in terms of ensuring that proper guidelines are developed for using AI technology for citizen services, thereby bridging the ever-critical trust gap between citizens and city administration.},
journal = {Int. J. Electron. Gov. Res.},
month = {mar},
pages = {1–21},
numpages = {21},
keywords = {Transparency, Smart City, Fairness, Ethics, AI}
}

@inproceedings{10.1145/3001773.3001797,
author = {Ishihara, Makoto and Miyazaki, Taichi and Chu, Chun Yin and Harada, Tomohiro and Thawonmas, Ruck},
title = {Applying and Improving Monte-Carlo Tree Search in a Fighting Game AI},
year = {2016},
isbn = {9781450347730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001773.3001797},
doi = {10.1145/3001773.3001797},
abstract = {This paper evaluates the performance of Monte-Carlo Tree Search (MCTS) in a fighting game AI and proposes an improvement for the algorithm. Most existing fighting game AIs rely on rule bases and react to every situation with predefined actions, making them predictable for human players. We attempt to overcome this weakness by applying MCTS, which can adapt to different circumstances without relying on predefined action patterns or tactics. In this paper, an AI based on Upper Confidence bounds applied to Trees (UCT) and MCTS is first developed. Next, the paper proposes improving the AI with Roulette Selection and a rule base. Through testing and evaluation using FightingICE, an international fighting game AI competition platform, it is proven that the aforementioned MCTS-based AI is effective in a fighting game, and our proposed improvement can further enhance its performance.},
booktitle = {Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology},
articleno = {27},
numpages = {6},
keywords = {Roulette Selection, MCTS, FightingICE, Fighting Game, Artificial Intelligence},
location = {Osaka, Japan},
series = {ACE '16}
}

@inproceedings{10.1145/3466933.3466969,
author = {Siqueira de Cerqueira, Jos\'{e} Antonio and Acco Tives, Heloise and Dias Canedo, Edna},
title = {Ethical Guidelines and Principles in the Context of Artificial Intelligence},
year = {2021},
isbn = {9781450384919},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466933.3466969},
doi = {10.1145/3466933.3466969},
abstract = {The interest in Artificial Intelligence (AI) based systems has been gaining momentum at a fast pace, both for software development teams and for society as a whole. This work aims to identify the guidelines and ethical principles for systems based on Artificial Intelligence. Design Science Research methodology was adopted in order to understand the various guidelines and principles existing in the literature. From the current landscape, a body of knowledge in the field of AI ethics is presented, with the purpose of supporting developers and Product Owners in identifying the guidelines and ethical principles in the literature so that they can be used during the software development process. Thus, this work will contribute to the various stakeholders in the development of ethical systems in the context of AI, such as: policy makers, ethicists, users, organizations, data scientists, development teams, among others.},
booktitle = {Proceedings of the XVII Brazilian Symposium on Information Systems},
articleno = {36},
numpages = {8},
location = {Uberl\^{a}ndia, Brazil},
series = {SBSI '21}
}

@inproceedings{10.5555/2040981.2041023,
author = {Gonz\'{a}lez-Ferrer, Arturo and Ten Teije, Annette and Fdez-Olivares, Juan and Milian, Krystyna},
title = {Careflow planning: from time-annotated clinical guidelines to temporal hierarchical task networks},
year = {2011},
isbn = {9783642222177},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Decision-making, care planning and adaptation of treatment are important aspects of the work of clinicians, that can clearly benefit from IT support. Clinical Practice Guidelines (CPG) languages provide formalisms for specifying knowledge related to such tasks, such as decision criteria and time-oriented aspects of the patient treatment. In these CPG languages, little research has been directed to efficiently deal with the integration of temporal and resource constraints, for the purpose of generating patient tailored treatment plans, i.e. care pathways. This paper presents an AI-based knowledge engineering methodology to develop, model, and operationalize care pathways, providing computer-aided support for the planning, visualization and execution of the patient treatment. This is achieved by translating time-annotated Asbru CPG's into temporal HTN planning domains. The proposed methodology is illustrated through a case study based on Hodgkin's disease.},
booktitle = {Proceedings of the 13th Conference on Artificial Intelligence in Medicine},
pages = {265–275},
numpages = {11},
location = {Bled, Slovenia},
series = {AIME'11}
}

@article{10.1016/S0166-3615(01)00124-5,
author = {Reyes, A. and Yu, H. and Kelleher, G. and Lloyd, S.},
title = {Integrating Petri nets and hybrid heuristic search for the scheduling of FMS},
year = {2002},
issue_date = {January 2002},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {47},
number = {1},
issn = {0166-3615},
url = {https://doi.org/10.1016/S0166-3615(01)00124-5},
doi = {10.1016/S0166-3615(01)00124-5},
abstract = {This paper studies modelling and scheduling of Flexible Manufacturing Systems (FMS) using Petri Nets (PNs) and Artificial Intelligence (AI) based on heuristic search methods. A subclass of PNs, Buffer nets or B-nets is obtained by the systematic synthesis of PN models from FMS formulations. Scheduling is performed as heuristic search in the reachability tree, which is guided by a new heuristic function that exploits PN information. This heuristic is derived from a new concept, the Resource Cost Reachability (RCR) matrix which builds on the properties of B-nets. To mitigate the complexity problem, a hybrid search algorithm is proposed. The algorithm combines dispatching rules based on analysis information provided by the PN simulation with a modified stage-search algorithm. Experimental results are provided and indicate the effectiveness of the approach and the potential of PN-based heuristic search for FMS scheduling.},
journal = {Comput. Ind.},
month = {jan},
pages = {123–138},
numpages = {16},
keywords = {scheduling, modelling, heuristic search, flexible manufacturing systems, Petri Nets}
}

@inproceedings{10.5555/3466184.3466363,
author = {Feldkamp, Niclas and Bergmann, Soeren and Strassburger, Steffen},
title = {Simulation-based deep reinforcement learning for modular production systems},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {Modular production systems aim to supersede the traditional line production in the automobile industry. The idea here is that highly customized products can move dynamically and autonomously through a system of flexible workstations without fixed production cycles. This approach has challenging demands regarding planning and organization of such systems. Since each product can define its way through the system freely and individually, implementing rules and heuristics that leverage the flexibility in the system in order to increase performance can be difficult in this dynamic environment. Transport tasks are usually carried out by automated guided vehicles (AGVs). Therefore, integration of AI-based control logics offer a promising alternative to manually implemented decision rules for operating the AGVs. This paper presents an approach for using reinforcement learning (RL) in combination with simulation in order to control AGVs in modular production systems. We present a case study and compare our approach to heuristic rules.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1596–1607},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@inproceedings{10.1145/3544548.3581369,
author = {Lee, Yoonjoo and Kim, Tae Soo and Kim, Sungdong and Yun, Yohan and Kim, Juho},
title = {DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children’s Why and How Questions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581369},
doi = {10.1145/3544548.3581369},
abstract = {Children acquire an understanding of the world by asking “why” and “how” questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children’s questions as they are more readily available than parents or teachers. However, CAs’ answers to “why” and “how” questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children’s engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children’s questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {22},
keywords = {Question Answering, Natural Language, Dialogue, Conversational Agents, Children},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}

@inproceedings{10.1145/3570991.3570998,
author = {Arya, Vijay and Saha, Diptikalyan and Hans, Sandeep and Rajasekharan, Amaresh and Tang, Tony},
title = {Global Explanations for Multivariate time series models},
year = {2023},
isbn = {9781450397971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570991.3570998},
doi = {10.1145/3570991.3570998},
abstract = {Several explainable AI algorithms have been proposed to help make machine learning models more interpretable and trustworthy. However in spite of numerous methodological advancements, there is still a persistent gap between what researchers develop and what business users seek. In this work, we aim to bridge this gap for an AI system that predicts the remaining useful life of an aircraft’s engine using time series data collected from multiple sensors. We propose a novel approach to compute easily understandable explanations by fusing two explainers in sequence wherein explanations of the first explainer are explained by the second. We use this approach to build a global post-hoc model-agnostic explainer for AI models that ingest multivariate time series data. Our approach fuses a local explainer that yields feature importance weights, with a directly interpretable model that outputs global rules. Our experimental results based on the C-MAPSS open-source dataset demonstrate that the proposed two-stage explainer computes global explanations that are amenable to business users and sheds light on how the behavior of an individual and a group of sensors impacts the remaining useful life of an aircraft’s engine.},
booktitle = {Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD)},
pages = {149–157},
numpages = {9},
keywords = {timeseries data, global explanations, AI Explainability},
location = {Mumbai, India},
series = {CODS-COMAD '23}
}

@phdthesis{10.5555/911449,
author = {Silvestro, Kenneth Charles},
title = {Computer knowledge acquisition from natural language explanations},
year = {1984},
publisher = {The University of Connecticut},
abstract = {A practical experimental approach has been applied to the task of computer knowledge acquisition and investigated within an AI system called KBAM (Knowledge Base Acquisitions Mechanism). KBAM operates in conjunction with a natural language analyzer, accepting natural language explanations from which a knowledge base is constructed. Herein lies the practical aspect, knowledge acquisition is accomplished through natural language explanations. KBAM's acquisition processes function at the conceptual level, utilizing Conceptual Dependency (CD) as the basis of its knowledge representations. KBAM is a rule-based mechanism built upon a production system architecture. This means its acquisition processes have been developed within production rules forming what is known as Knowledge Building Rules (KB-RULES). The KB-RULES are in a one-to-one relationship with the different types of utterances found within explanations, therefore, there is a unique acquisition process for each unique utterance type within an explanation.KBAM being an experimental effort in knowledge acquisition, employing a practical approach, has lead to its development as a domain independent AI mechanism. Therefore, at least theoretically, KBAM could acquire the necessary domain specific knowledge for "any" intelligent system, aiding in that system's intelligent behavior.},
note = {AAI8416108}
}

@article{10.1109/TC.2019.2949300,
author = {Mor\'{a}n, Alejandro and Frasser, Christiam F. and Roca, Miquel and Rossell\'{o}, Josep L.},
title = {Energy-Efficient Pattern Recognition Hardware With Elementary Cellular Automata},
year = {2020},
issue_date = {March 2020},
publisher = {IEEE Computer Society},
address = {USA},
volume = {69},
number = {3},
issn = {0018-9340},
url = {https://doi.org/10.1109/TC.2019.2949300},
doi = {10.1109/TC.2019.2949300},
abstract = {The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) is able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy.},
journal = {IEEE Trans. Comput.},
month = {mar},
pages = {392–401},
numpages = {10}
}

@article{10.1016/j.procs.2019.09.463,
author = {Aljaafreh, Ahmad and Al-Oudat, Naeem},
title = {Development of a Computer Player for Seejeh (A.K.A Seega, Siga, Kharbga) Board Game with Deep Reinforcement Learning},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {160},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.463},
doi = {10.1016/j.procs.2019.09.463},
journal = {Procedia Comput. Sci.},
month = {jan},
pages = {241–247},
numpages = {7},
keywords = {Seejeh, self-play, Minimax, MCTS, search, deep reinforcement learning, Board game}
}

@inproceedings{10.1007/978-3-030-68007-7_6,
author = {Rjoob, Khaled and Bond, Raymond and Finlay, Dewar and McGilligan, Victoria and Leslie, Stephen J. and Rababah, Ali and Iftikhar, Aleeha and Guldenring, Daniel and Knoery, Charles and McShane, Anne and Peace, Aaron},
title = {Towards Explainable Artificial Intelligence and Explanation User Interfaces to Open the ‘Black Box’ of Automated ECG Interpretation},
year = {2020},
isbn = {978-3-030-68006-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68007-7_6},
doi = {10.1007/978-3-030-68007-7_6},
abstract = {This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system.},
booktitle = {Advanced Visual Interfaces. Supporting Artificial Intelligence and Big Data Applications: AVI 2020 Workshops, AVI-BDA and ITAVIS, Ischia, Italy, June 9, 2020 and September 29, 2020, Revised Selected Papers},
pages = {96–108},
numpages = {13},
keywords = {Explainable AI (XAI), ECG interpretation, Artificial intelligence (AI)}
}

@article{10.1007/s42979-021-00557-0,
author = {Sarker, Iqbal H. and Furhad, Md Hasan and Nowrozy, Raza},
title = {AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {3},
url = {https://doi.org/10.1007/s42979-021-00557-0},
doi = {10.1007/s42979-021-00557-0},
abstract = {Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or&nbsp;Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or&nbsp;AI-based technical point of view.},
journal = {SN Comput. Sci.},
month = {mar},
numpages = {18},
keywords = {Security intelligence, Intrusion detection, Anomaly, Cyber-attacks, Cyber data analytics, Machine learning, Artificial intelligence, Cybersecurity}
}

@article{10.1145/3579628,
author = {Holstein, Kenneth and De-Arteaga, Maria and Tumati, Lakshmi and Cheng, Yanghuidi},
title = {Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW1},
url = {https://doi.org/10.1145/3579628},
doi = {10.1145/3579628},
abstract = {In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {152},
numpages = {20},
keywords = {unobservables, human-AI complementarity, behavioral experiment, algorithm-assisted decision-making}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {ambiguity, artificial intelligence, medical data analysis},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '20}
}

@inproceedings{10.1145/3593013.3594063,
author = {Petti, Ulla and Nyrup, Rune and Skopek, Jeffrey M. and Korhonen, Anna},
title = {Ethical considerations in the early detection of Alzheimer's disease using speech and AI},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594063},
doi = {10.1145/3593013.3594063},
abstract = {While recent studies indicate that AI could play an important role in detecting early signs of Alzheimer's disease in speech, this use of data from individuals with cognitive decline raises numerous ethical concerns. In this paper, we identify and explain concerns related to autonomy (including consent, depersonalization and disclosure), privacy and data protection (including the handling of personal content and medical information), welfare (including distress, discrimination and reliability), transparency (including the interpretability of language features and AI-based decision-making for developers and clinicians), and fairness (including bias and the distribution of benefits). Our aim is to not only raise awareness of the ethical concerns posed by the use of AI in speech-based Alzheimer's detection, but also identify ways in which these concerns might be addressed. To this end, we conclude with a list of suggestions that could be incorporated into ethical guidelines for researchers and clinicians working in this area.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1062–1075},
numpages = {14},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1007/978-3-319-07221-0_64,
author = {Martinez-Maldonado, Roberto and Clayphan, Andrew and Yacef, Kalina and Kay, Judy},
title = {Towards Providing Notifications to Enhance Teacher's Awareness in the Classroom},
year = {2014},
isbn = {9783319072203},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-07221-0_64},
doi = {10.1007/978-3-319-07221-0_64},
abstract = {Students often need prompt feedback to make the best from the learning activities. Within classrooms, being aware of students' achievements and weaknesses can help teachers decide how to time feedback. However, they usually cannot easily assess student's progress. We present an approach to generate automated notifications that can enhance teacher's awareness in runtime. This paper formulates the theoretical framing and describes the technological infrastructure of a system that can help teachers orchestrate learning activities and monitor small groups in a multi-tabletop classroom. We define the design guidelines underpinning our system, which include: i generating notifications from teacher-designed or AI-based sources; ii enhancing teacher's awareness in the orchestration loop; iii presenting both positive and negative notifications; iv allowing teachers to tune the system; and v providing a private teacher's user interface. Our approach aims to guide research on ways to generate notifications that can help teachers drive their attention and provide relevant feedback for small group learning activities in the classroom.},
booktitle = {12th International Conference on Intelligent Tutoring Systems - Volume 8474},
pages = {510–515},
numpages = {6},
keywords = {Orchestration, Notifications, F2F Collaboration, Classroom, CSCL},
location = {Honolulu, HI, USA},
series = {ITS 2014}
}

@article{10.1016/j.ipm.2022.103099,
author = {Castelnovo, Alessandro and Cosentini, Andrea and Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario},
title = {         FFTree: A flexible tree to handle multiple fairness criteria},
year = {2022},
issue_date = {Nov 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {59},
number = {6},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2022.103099},
doi = {10.1016/j.ipm.2022.103099},
journal = {Inf. Process. Manage.},
month = {nov},
numpages = {14},
keywords = {Discrimination-aware decision tree, Fairness, Explainable AI, Machine learning, 1111, 0000}
}

@inproceedings{10.1145/3386392.3399276,
author = {D\'{\i}az-Rodr\'{\i}guez, Natalia and Pisoni, Galena},
title = {Accessible Cultural Heritage through Explainable Artificial Intelligence},
year = {2020},
isbn = {9781450379502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386392.3399276},
doi = {10.1145/3386392.3399276},
abstract = {Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy.},
booktitle = {Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {317–324},
numpages = {8},
keywords = {natural language processing, image captioning, generative models, explainable artificial intelligence, deep neural networks, deep learning, cultural heritage, computer vision, art},
location = {Genoa, Italy},
series = {UMAP '20 Adjunct}
}

@article{10.1007/s10270-023-01131-3,
author = {Planas, Elena and Mart\'{\i}nez, Salvador and Brambilla, Marco and Cabot, Jordi},
title = {Modeling and enforcing access control policies in conversational user interfaces},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-023-01131-3},
doi = {10.1007/s10270-023-01131-3},
abstract = {Conversational user interfaces (CUIs), such as chatbots, are becoming a common component of many software systems. Although they are evolving in many directions (such as advanced language processing features, thanks to new AI-based developments), less attention has been paid to access control and other security concerns associated with CUIs, which may pose a clear risk to the systems they interface with. In this paper, we apply model-driven techniques to model and enforce access-control policies in CUIs. In particular, we present a fully fledged framework to integrate the role-based access-control (RBAC) protocol into CUIs by: (1) modeling a set of access-control rules to specify permissions over the bot resources using a domain-specific language that tailors core RBAC concepts to the CUI domain; and (2) describing a mechanism to show the feasibility of automatically generating the infrastructure to evaluate and enforce the modeled access control policies at runtime.},
journal = {Softw. Syst. Model.},
month = {nov},
pages = {1925–1944},
numpages = {20},
keywords = {RBAC, Access-control, CUIs, Conversational user interfaces, Model-driven engineering}
}

@inproceedings{10.1007/978-3-031-35708-4_22,
author = {Heuer, Marvin and Lewandowski, Tom and Weglewski, Joffrey and Mayer, Tom and Kubicek, Max and Lembke, Patrick and Ortgiese, Simon and B\"{o}hmann, Tilo},
title = {Rethinking Interaction with Conversational Agents: How to Create a Positive User Experience Utilizing Dialog Patterns},
year = {2023},
isbn = {978-3-031-35707-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35708-4_22},
doi = {10.1007/978-3-031-35708-4_22},
abstract = {Conversational agents (CAs) are increasingly used as an additional convenient and innovative customer service channel to relieve service employees, as in the studied organization. In the process of analyzing and maintaining the present AI-based agent, however, user satisfaction is low as the CA lacks understanding and offers unsatisfactory solutions to users. Nonetheless, solving the requests and providing a positive user experience is crucial to relieve the service employees’ workload permanently. For CAs’ improvement, this study followed action design research (ADR) and used design thinking. We identified the central interaction problems (findability, welcome message, dialog control and fallback issues) with a monitoring process and analysis. Afterward, we interviewed users about their expectations and requirements and addressed these problems by creating user-centric mock-ups. Through a quantitative survey, the most popular solutions were implemented in a prototype. Finally, the resulting CA prototype was evaluated, showing a significantly improved user experience afterward, and design guidelines were discovered.},
booktitle = {Design, User Experience, and Usability: 12th International Conference, DUXU 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part IV},
pages = {283–301},
numpages = {19},
keywords = {artificial intelligence (AI), interaction design, fallback strategy, chatbot user experience (UX), conversational agents},
location = {Copenhagen, Denmark}
}

@techreport{10.5555/887869,
author = {John W., McManus and Kenneth H., Goodrich},
title = {Application of Artificial Intelligence (AI) Programming Techniques to Tactical Guidance For Fighter Aircraft},
year = {1989},
publisher = {NASA Langley Technical Report Server},
abstract = {A research program investigating the use of Artificial Intelligence (AI) techniques to aid in the development of a Tactical Decision Generator (TDG) for Within-Visual-Range (WVR) air combat engagements is discussed. The application of AI methods for development and implementation of the TDG is presented. The history of the Adaptive Maneuvering Logic (AML) program is traced and current versions of the AML program are compared and contrasted with the TDG system. The Knowledge-Based Systems (KBS) used by the TDG to aid in the decision-making process are outlined in detail and example rules are presented. The results of tests to evaluate the performance of the TDG versus a version of AML and versus human pilots in the Langley Differential Maneuvering Simulator (DMS) are presented. To date, these results have shown significant performance gains in one-versus-one air combat engagements, and the AI-based TDG software has proven to be much easier to modify than the updated FORTRAN AML programs.}
}

@inbook{10.5555/778212.778333,
author = {Senator, Ted E. and Goldberg, Henry G.},
title = {Industry: break detection systems},
year = {2002},
isbn = {0195118316},
publisher = {Oxford University Press, Inc.},
address = {USA},
abstract = {Break detection systems are a subclass of KDD-based fraud detection applications in which the fraudulent activity is indicated by complex patterns of transactions, typically involving related entities performing multiple activities and playing several distinct roles over a time period, during which they may also be engaged in legitimate activities of the same types with the same or other entities. Break detection systems take as their input a large transaction stream and provide as their output a set of breaks, or leads, which are used to initiate follow-up investigations by trained human analysts. This article discusses two such systems: the FinCEN AI System (FAIS) and the Advanced Detection System (ADS). FAIS was developed for and is used by the U.S. Department of the Treasury's Financial Crimes Enforcement Network (FinCEN). The purpose of FAIS is to detect instances of potential money laundering from the database of reports of large cash transactions. ADS was developed for and is used by the National Association of Securities Dealers (NASD®) Regulation, Inc., the subsidiary of NASD responsible for regulation of the Nasdaq Stock Market. The purpose of ADS is to detect potential instances of violations of the rules of participation in the Nasdaq® and related stock markets subject to NASD Regulation's oversight and jurisdiction.},
booktitle = {Handbook of Data Mining and Knowledge Discovery},
pages = {863–873},
numpages = {11}
}

@inproceedings{10.1145/3600160.3605052,
author = {Nguyen, Manh-Dung and Bouaziz, Anis and Valdes, Valeria and Rosa Cavalli, Ana and Mallouli, Wissam and Montes De Oca, Edgardo},
title = {A deep learning anomaly detection framework with explainability and robustness},
year = {2023},
isbn = {9798400707728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600160.3605052},
doi = {10.1145/3600160.3605052},
abstract = {The prevalence of encrypted Internet traffic has resulted in a pressing need for advanced analysis techniques for traffic analysis and classification. Traditional rule-based and signature-based approaches have been hindered by the introduction of network encryption methods. With the emergence of machine learning (ML) and deep learning (DL), several preliminary works have been developed for anomaly detection in encrypted network traffic. However, complex Artificial Intelligence (AI) models like neural networks lack explainability, limiting the understanding of their predictions. To address this limitation, eXplainable Artificial Intelligence (XAI) has emerged, aiming to provide users with a rationale for understanding AI system outputs and fostering trust. However, existing explainable frameworks still lack comprehensive support for adversarial attacks and defenses. In this paper, we present Montimage AI Platform (MAIP), a new GUI-based deep learning framework for malicious traffic detection and classification combined with its ability of explaining the decision of the model. We employ popular XAI methods to interpret the prediction of the developed deep learning model. Furthermore, we perform adversarial attacks to assess the accountability and robustness of our model via different quantifiable metrics. We perform extensive experiments with both public and private network traffic. The experimental results demonstrate that our model achieves high performance and robustness, and its outcomes align closely with the domain knowledge.},
booktitle = {Proceedings of the 18th International Conference on Availability, Reliability and Security},
articleno = {134},
numpages = {7},
keywords = {Network Security, Malware Detection, Explainable AI, Encrypted Traffic Analysis, Deep Learning, Adversarial Attacks},
location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>, </conf-loc>},
series = {ARES '23}
}

@inproceedings{10.1145/3278721.3278751,
author = {Vasconcelos, Marisa and Cardonha, Carlos and Gon\c{c}alves, Bernardo},
title = {Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278751},
doi = {10.1145/3278721.3278751},
abstract = {Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.},
booktitle = {Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {323–329},
numpages = {7},
keywords = {semi-automatic decision making, problem of induction, hiring algorithms, constrained models, bias of ai, attempts at refutation},
location = {New Orleans, LA, USA},
series = {AIES '18}
}

@inproceedings{10.1145/3462244.3479926,
author = {Tutul, Abdullah Aman and Nirjhar, Ehsanul Haque and Chaspari, Theodora},
title = {Investigating Trust in Human-Machine Learning Collaboration: A Pilot Study on Estimating Public Anxiety from Speech},
year = {2021},
isbn = {9781450384810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462244.3479926},
doi = {10.1145/3462244.3479926},
abstract = {Trust is a key element in the development of effective collaborative relationships between humans and increasingly complex artificial intelligence (AI) systems. Here, we examine trust in AI in the context of a human-AI partnership that involves a joint decision making task for estimating levels of public speaking anxiety based on speech signals. The AI system is comprised of an explainable machine learning (ML) algorithm, that takes acoustic characteristics as input and outputs the estimate of public speaking anxiety levels, a local explanation about the most important features that contributed to the decision of each speech sample, and a global explanation about the most important features for the data overall. We analyze interactions between AI and human annotators with background in psychological sciences, and measure trust over time via the annotators’ agreement with the AI model and the annotators’ self-reports. We further examine factors of trust that are related to the characteristics of the human annotator and the ML algorithm. Results indicate that trust in AI depends on the openness level of the annotator and the importance level of input features. Findings from this study can provide guidelines to designing solutions that properly calibrate human trust in AI in collaborative human-AI tasks.},
booktitle = {Proceedings of the 2021 International Conference on Multimodal Interaction},
pages = {288–296},
numpages = {9},
keywords = {speech, public speaking anxiety, human-AI interaction, Trustworthy AI},
location = {Montr\'{e}al, QC, Canada},
series = {ICMI '21}
}

@inproceedings{10.1007/978-3-319-92046-7_42,
author = {Kim, Jae Min and Lee, Seung Jun},
title = {Framework to Develop Artificial Intelligent Autonomous Operating System for Nuclear Power Plants},
year = {2018},
isbn = {978-3-319-92045-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-92046-7_42},
doi = {10.1007/978-3-319-92046-7_42},
abstract = {As artificial intelligent (AI) technology has been dramatically developed, various industries have been challenged to apply it. In a view of nuclear power plants (NPP), it seems that AI technology applies to NPPs at the last because NPPs are required the most stringent level of regulatory guideline for safety. To overcome it, AI technology should be applied incrementally into the NPPs rather than all at once. According to the unintended shutdown records during startup and shutdown operation from 1997 to 2017 in Korea, it is reported that human errors accounts for 40% of the total. This is because operators feel heavy burden to monitor hundreds of parameters for a long time of operating time. Also, there are lots of startup and shutdown operating history that can be used for correcting the data from the NPP simulator. Therefore, this work proposes a framework to develop AI automatic operating system for startup and shutdown operations of NPPs. Operating procedures of startup and shutdown operations are categorized. In addition, AI technologies will be introduced to find out the most suitable learning algorithm. It is expected that economic loss from human error during startup and shutdown operation will be reduced as AI system developed.},
booktitle = {Human Interface and the Management of Information. Information in Applications and Services: 20th International Conference, HIMI 2018, Held as Part of HCI International 2018, Las Vegas, NV, USA, July 15-20, 2018, Proceedings, Part II},
pages = {508–517},
numpages = {10},
keywords = {Operating procedure, Startup and shutdown operation, Artificial intelligent},
location = {Las Vegas, NV, USA}
}

@phdthesis{10.5555/125575,
author = {Yuhan, Albert Hanyong},
title = {Dynamic computation of spatial reference frames in narrative understanding},
year = {1991},
publisher = {State University of New York at Buffalo},
address = {USA},
abstract = {For a given natural language directional reference, an orientational system with a determined origin and directionalities in which the reference should be interpreted is called the spatial reference frame. Correct recognition of spatial reference frames is critical in understanding spatial information expressed in natural language narratives. This dissertation presents a model solution to the spatial reference frame problem. The solution is based both on extensive grammatical analysis of input sentences' story context by keeping track of the story's contextual goals and the deictic centers. This research demonstrates the robustness of the proposed model by empirically testing the performace of an AI system that understands a short narrative story. This system (called CASSIE), based on SNePS for its inference capability and on ATN for its natural language sentence parsing and generation, goes through with each input sentence four processing phases: the initial interpretation, the extended interpretation, the immediate inference, and the extended inference. Equipped with powerful narrative understanding capability, CASSIE resolves spatial reference frame problems utilizing seventeen proposed resolution rules derived from three general strategies for narrative processing. The specific objective of this dissertation, namely, the resolution of the spatial reference frame problem is embedded in the global goal of understanding natural language narratives with their full contextual coherence maintained.},
note = {UMI Order No. GAX91-21082}
}

@article{10.1016/j.ijinfomgt.2021.102387,
author = {Akter, Shahriar and McCarthy, Grace and Sajib, Shahriar and Michael, Katina and Dwivedi, Yogesh K. and D’Ambra, John and Shen, K.N.},
title = {Algorithmic bias in data-driven innovation in the age of AI},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {60},
number = {C},
issn = {0268-4012},
url = {https://doi.org/10.1016/j.ijinfomgt.2021.102387},
doi = {10.1016/j.ijinfomgt.2021.102387},
journal = {Int. J. Inf. Manag.},
month = {oct},
numpages = {13},
keywords = {Societal bias, Method bias, Data bias, Data driven innovation, Algorithmic bias}
}

@inproceedings{10.1145/3102071.3102105,
author = {de Mesentier Silva, Fernando and Lee, Scott and Togelius, Julian and Nealen, Andy},
title = {AI-based playtesting of contemporary board games},
year = {2017},
isbn = {9781450353199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102071.3102105},
doi = {10.1145/3102071.3102105},
abstract = {Ticket to Ride is a popular contemporary board game for two to four players, featuring a number of expansions with additional maps and tweaks to the core game mechanics. In this paper, four different game-playing agents that embody different playing styles are defined and used to analyze Ticket to Ride. Different playing styles are shown to be effective depending on the map and rule variation, and also depending on how many players play the game. The performance profiles of the different agents can be used to characterize maps and identify the most similar maps in the space of playstyles. Further analysis of the automatically played games reveal which cities on the map are most desirable, and that the relative attractiveness of cities is remarkably consistent across numbers of players. Finally, the automated analysis also reveals two classes of failures states, where the agents find states which are not covered by the game rules; this is akin to finding bugs in the rules. We see the analysis performed here as a possible template for AI-based playtesting of contemporary board games.},
booktitle = {Proceedings of the 12th International Conference on the Foundations of Digital Games},
articleno = {13},
numpages = {10},
keywords = {ticket to ride, playtesting, contemporary board games, board games, artificial intelligence},
location = {Hyannis, Massachusetts},
series = {FDG '17}
}

@inproceedings{10.5555/1864659.1864669,
author = {Rice, Amy and Hsu, Julie and Angotti, Anthony and Piccolo, Rosanna},
title = {EZ reader: embedded AI for automatic electronic mail interpretation and routing},
year = {1996},
isbn = {9780262510912},
publisher = {AAAI Press},
abstract = {EZ Reader is an intelligent electronic mail (email) reader that employs a unique combination of rulebased parsing and case-based reasoning to automatically and with a high level of accuracy classify and respond to large volumes of incoming email. EZ Reader reduces the time and human resources required to handle incoming email by selecting responses and adding attachments and advice to each incoming message based on how previous similar messages were handled. The application, developed for Chase Manhattan Bank using Brightware, Inc.'s ART*Enterprise® tool, answers emails automatically and decreases processing time for those requiring manual review. Phase I of EZ Reader was deployed in the first quarter of 1996, and handles up to 80% of incoming mail automatically, depending on message content. Later phases will enable automatic processing of a wider variety of messages. By dramatically reducing the effort associated with manual processing, EZ Reader will pay its own development costs within six months and will result in substantial, recurring dollar savings each year. This paper describes EZ Reader in detail, including its AI-based design, testing, implementation and development history.},
booktitle = {Proceedings of the Eighth Annual Conference on Innovative Applications of Artificial Intelligence},
pages = {1507–1517},
numpages = {11},
location = {Portland, Oregon},
series = {IAAI'96}
}

@article{10.1016/j.comnet.2019.106950,
author = {Gupta, Lav and Salman, Tara and Zolanvari, Maede and Erbad, Aiman and Jain, Raj},
title = {Fault and performance management in multi-cloud virtual network services using AI: A tutorial and a case study},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {165},
number = {C},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2019.106950},
doi = {10.1016/j.comnet.2019.106950},
journal = {Comput. Netw.},
month = {dec},
numpages = {22},
keywords = {Deep learning, Machine learning, Performance management, Fault management, Multi-cloud, Virtual Network Functions, Service Function Chains, Virtual Network Services, Network Function Virtualization}
}

@article{10.1016/j.compbiomed.2023.107187,
author = {Wang, Yan and Zhang, Ruochi and Zhang, Shengde and Guo, Liming and Zhou, Qiong and Zhao, Bowen and Mo, Xiaotong and Yang, Qian and Huang, Yajuan and Li, Kewei and Fan, Yusi and Huang, Lan and Zhou, Fengfeng},
title = {OCMR: A comprehensive framework for optical chemical molecular recognition},
year = {2023},
issue_date = {Sep 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {163},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2023.107187},
doi = {10.1016/j.compbiomed.2023.107187},
journal = {Comput. Biol. Med.},
month = {sep},
numpages = {11},
keywords = {OCMR, Molecular graph, Chemical structure recognition, Chemical informatics, OCSR, Bioinformatics}
}

@article{10.1109/5254.653224,
author = {Liu Sheng, Olivia R. and Wei, Chih-Ping and Hu, Paul Jen-Hwa},
title = {Neural Net Learning for Intelligent Patient-Image Retrieval},
year = {1998},
issue_date = {January 1998},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {13},
number = {1},
issn = {1541-1672},
url = {https://doi.org/10.1109/5254.653224},
doi = {10.1109/5254.653224},
abstract = {Referencing prior images of a patient is critical to a radiologist's ability to interpret the images generated as part of a radiological examination. During an image reading, a radiologist typically exercises a series of judgments to determine what prior images are relevant. These judgments are complex, practice-dependent, and fluid in that they may change over a short time. Many health care institutions support image retrieval by prefetching images according to some primitive rules of thumb (such as the same modality and anatomical part as the current image). However, these practices are not sophisticated enough to meet many reading scenarios, so radiologists typically spend considerable time searching for additional prior images.An alternative is intelligent patient-image retrieval using either a knowledge-based system- in which a knowledge base of image-selection rules is manually engineered-or automated learning. For most organizations, the cost of engineering a knowledge base customized to the radiologist or institution may be prohibitive. The sidebar describes these limitations in more detail. We believe a more economic alternative is an AI-based mechanism that learns patient-image-retrieval heuristics. Such a mechanism would be key to the broad implementation and long-term maintenance of intelligent and adaptive image-retrieval systems.In this article, we describe the radiologist behaviors associated with patient-image retrieval and a backpropagation neural net-work that learns patient-image-retrieval heuristics. We compared the learning performance of this network with benchmarks from a system that uses an engineered knowledge base as well as with a real-world image-prefetching practice. We also investigated the network's ability to tolerate imperfect (noisy) data. Results show that, with fine-tuning, the image-prefetching accuracy of the network is comparable to that possible with an engineered knowledge base. The network also acceptably tolerates the noisy and incomplete input data characteristic of patient-image retrieval in this context.These results are significant because they demonstrate that AI-based learning techniques such as ours can provide intelligent information systems with their essential core at a significantly lower cost in time and resources than knowledge engineering. For example, the knowledge engineering of patient-image-retrieval heuristics at the University of Arizona's University Medical Center took eight staff-months to complete and involved multiple radiologists as well as knowledge engineers. The time required for our network learning process was only eight to 12 hours on a DECstation 3100/25 MIPS platform-several orders of magnitude shorter. With this kind of advantage, knowledge-based technology can begin to be feasible for a broader range of real-world applications.},
journal = {IEEE Intelligent Systems},
month = {jan},
pages = {49–57},
numpages = {9}
}

@article{10.1609/aimag.v20i1.1437,
author = {Lathrop, Richard H. and Steffen, Nicholas R. and Raphael, Miriam P. and Deeds‐Rubin, Sophia and Pazzani, Michael J. and Cimoch, Paul J. and See, Darryl M. and Tilles, Jeremiah G.},
title = {Knowledge‐Based Avoidance of Drug‐Resistant HIV Mutants},
year = {1999},
issue_date = {March 1999},
publisher = {American Association for Artificial Intelligence},
address = {USA},
volume = {20},
number = {1},
issn = {0738-4602},
url = {https://doi.org/10.1609/aimag.v20i1.1437},
doi = {10.1609/aimag.v20i1.1437},
abstract = {We describe an AI system (ctshiv) that connects the scientific AIDS literature describing specific human immunodeficiency virus (HIV) drug resistances directly to the customized treatment strategy of a specific HIV patient. Rules in the ctshiv knowledge base encode knowledge about sequence mutations in the HIV genome that have been found to result in drug resistance to the HIV virus. Rules are applied to the actual HIV sequences of the virus strains infecting the specific patient undergoing clinical treatment to infer current drug resistance. A rule‐directed search through mutation sequence space identifies nearby drug‐resistant mutant strains that might arise. The possible combination drug‐treatment regimens currently approved by the U.S. Food and Drug Administration are considered and ranked by their estimated ability to avoid identified current and nearby drug‐resistant mutants. The highest‐ranked treatments are recommended to the attending physician. The result is more precise treatment of individual HIV patients and a decreased tendency to select for drug‐resistant genes in the global HIV gene pool. Initial results from a small human clinical trial are encouraging, and further clinical trials are planned. From an AI viewpoint, the case study demonstrates the extensibility of knowledge‐based systems because it illustrates how existing encoded knowledge can be used to support new knowledge‐based applications that were unanticipated when the original knowledge was encoded.},
journal = {AI Mag.},
month = {mar},
pages = {13–25},
numpages = {13}
}

@inproceedings{10.1145/3597512.3599697,
author = {Ronanki, Krishna and Cabrero-Daniel, Beatriz and Horkoff, Jennifer and Berger, Christian},
title = {RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems},
year = {2023},
isbn = {9798400707346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597512.3599697},
doi = {10.1145/3597512.3599697},
abstract = {Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address these concerns, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.},
booktitle = {Proceedings of the First International Symposium on Trustworthy Autonomous Systems},
articleno = {1},
numpages = {8},
keywords = {Trustworthy AI, Requirements Engineering, Recommendations, Limitations, Guidelines, Frameworks, Ethical AI, EU AI Act, Autonomous Systems},
location = {<conf-loc>, <city>Edinburgh</city>, <country>United Kingdom</country>, </conf-loc>},
series = {TAS '23}
}

@article{10.1007/s00146-022-01442-x,
author = {Murtaza, Mohsin and Cheng, Chi-Tsun and Fard, Mohammad and Zeleznikow, John},
title = {The importance of transparency in naming conventions, designs, and operations of safety features: from modern ADAS to fully autonomous driving functions},
year = {2022},
issue_date = {Apr 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {2},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-022-01442-x},
doi = {10.1007/s00146-022-01442-x},
abstract = {This paper investigates the importance of standardising and maintaining the transparency of advanced driver-assistance systems (ADAS) functions nomenclature, designs, and operations in all categories up until fully autonomous vehicles. The aim of this paper is to reveal the discrepancies&nbsp;in ADAS functions across automakers and discuss the underlying issues and potential solutions. In this pilot study, user manuals of various brands are reviewed systematically and critical analyses of common ADAS functions are conducted. The result shows that terminologies used to describe ADAS functions vary widely across manufacturers and sometimes do not reflect their fundamental functions intuitively. Operational conditions and control procedures also vary across the selected models under this study. Due to this lack of consensus across the industry, drivers are not aware or well informed about ADAS functions in their vehicles, leading to a very low utilization rate and may lead to misuse of those functions. This paper provides insightful suggestions for the transport industry, Artificial Intelligence (AI) experts, and regulators to design frameworks and guidelines in governing the naming convention, operating conditions, control procedures, and information disclosure of ADAS. Such guidelines can be the foundations for regulating future AI-based self-driving functions.},
journal = {AI Soc.},
month = {apr},
pages = {983–993},
numpages = {11},
keywords = {Transparency, Standards, Regulation, Operating conditions, Autonomous vehicles, ADAS}
}

@inproceedings{10.1145/3341162.3349331,
author = {Banerjee, Rohan and Ghose, Avik and Sinha, Aniruddha and Pal, Arpan and Mandana, K M},
title = {A multi-modal approach for non-invasive detection of coronary artery disease},
year = {2019},
isbn = {9781450368698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341162.3349331},
doi = {10.1145/3341162.3349331},
abstract = {Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity = 0.96 and specificity = 0.91 in classifying CAD patients on an in-house hospital dataset, recorded using commercially available sensors.},
booktitle = {Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers},
pages = {543–550},
numpages = {8},
keywords = {feature extraction, coronary artery disease, classification, cardiovascular signals},
location = {London, United Kingdom},
series = {UbiComp/ISWC '19 Adjunct}
}

@inproceedings{10.5555/3006433.3006585,
author = {Montani, Stefania and Bellazzi, Riccardo and Riva, Alberto and Larizza, Cristiana and Portinale, Luigi and Stefanelli, Mario},
title = {Artificial Intelligence techniques for diabetes management: the T-IDDM project},
year = {2000},
publisher = {IOS Press},
address = {NLD},
abstract = {We present a successful application of Artificial Intelligence (AI) methodologies in the context of a telemedicine service for diabetic patients management, developed within the EU-funded T-IDDM project. The system architecture is distributed, and composed by a Patient Unit and by a Medical Unit, connected through a telecommunication link. Several AI methods have been exploited to implement the T-IDDM functionality. The data base relies on an explicit representation of the domain ontology. Temporal Abstractions and other Intelligent Data Analysis techniques are used to analyse the patient's monitoring data; the Case Based Reasoning (CBR) methodology is applied to perform the Knowledge Management task. Finally, CBR is integrated with Rule Based Reasoning to provide physicians with a multi-modal reasoning decision support tool. The T-IDDM service is being tested through a small on field trial in Pavia; the first results, though preliminary, seem to substantiate the hypothesis that the use of an AI-based telemedicine system could present an advantage in the management of type 1 diabetic patients, leading to a more tight control of the patients' metabolic situation, in a cost-effective way.},
booktitle = {Proceedings of the 14th European Conference on Artificial Intelligence},
pages = {716–720},
numpages = {5},
location = {Berlin, Germany},
series = {ECAI'00}
}

@article{10.1109/TVCG.2007.70436,
author = {Healey, Christopher and Kocherlakota, Sarat and Rao, Vivek and Mehta, Reshma and St. Amant, Robert},
title = {Visual Perception and Mixed-Initiative Interaction for Assisted Visualization Design},
year = {2008},
issue_date = {March 2008},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {14},
number = {2},
issn = {1077-2626},
url = {https://doi.org/10.1109/TVCG.2007.70436},
doi = {10.1109/TVCG.2007.70436},
abstract = {This paper describes the integration of perceptual guidelines from human vision with an AI-based mixed-initiative search strategy. The result is a visualization assistant called ViA, a system that collaborates with its users to identify perceptually salient visualizations for large, multidimensional datasets. ViA applies knowledge of low-level human vision to: (1) evaluate the effectiveness of a particular visualization for a given dataset and analysis tasks; and (2) rapidly direct its search towards new visualizations that are most likely to offer improvements over those seen to date. Context, domain expertise, and a high-level understanding of a dataset are critical to identifying effective visualizations. We apply a mixed-initiative strategy that allows ViA and its users to share their different strengths and continually improve ViA's understanding of a user's preferences. We visualize historical weather conditions to compare ViA's search strategy to exhaustive analysis, simulated annealing, and reactive tabu search, and to measure the improvement provided by mixed-initiative interaction. We also visualize intelligent agents competing in a simulated online auction to evaluate ViA's perceptual guidelines. Results from each study are positive, suggesting that ViA can construct high-quality visualizations for a range of real-world datasets.},
journal = {IEEE Transactions on Visualization and Computer Graphics},
month = {mar},
pages = {396–411},
numpages = {16},
keywords = {Multivariate visualization, Interaction techniques, Human information processing, Display algorithms}
}

@phdthesis{10.5555/910414,
author = {Michaelsen, Robert Herman},
title = {A knowledge-based system for individual income and transfer tax planning},
year = {1982},
publisher = {University of Illinois at Urbana-Champaign},
address = {USA},
abstract = {Recent developments in computer science include the creation of systems that are capable of solving difficult applications problems requiring expert knowledge for their solution. This type of system had not yet been developed for solving income and transfer (estate and gift) tax problems. The purpose of the dissertation was to develop such a system for solving problems concerning income and transfer tax planning for individuals so that the feasibility of using an artificial intelligence (AI) model for tax planning could be determined. In order to develop such a system, a theoretical structure and a set of decision rules were specified and programmed using a rule-based system that had already been used for medical diagnosis. Once the system was developed, its problem-solving capabilities were refined and verified by a panel of tax experts. The dissertation is organized in the following manner. In the first chapter, AI is defined and discussed; the apparent convergence of AI, cognitive psychology, and decision theory is explored; and the implications of AI for tax planning models are described. In the next two chapters, the AI system that was utilized and the tax planning decision that was modeled are described. Refinement and verification of the model and results of the study are discussed in chapters four and five. The final chapter includes an interpretation of results and suggested extensions of the research.With respect to Federal tax law, the dissertation is up-to-date through July 31, 1981.},
note = {AAI8218523}
}

@article{10.1016/j.jss.2021.111050,
author = {Myllyaho, Lalli and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi and Mikkonen, Tommi and Nurminen, Jukka K.},
title = {Systematic literature review of validation methods for AI systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111050},
doi = {10.1016/j.jss.2021.111050},
journal = {J. Syst. Softw.},
month = {nov},
numpages = {22},
keywords = {Systematic literature review, V&amp;V, Testing, Validation, Machine learning, Artificial intelligence}
}

@inproceedings{10.1007/978-3-031-16437-8_33,
author = {Yao, Jiawen and Ye, Xianghua and Xia, Yingda and Zhou, Jian and Shi, Yu and Yan, Ke and Wang, Fang and Lin, Lili and Yu, Haogang and Hua, Xian-Sheng and Lu, Le and Jin, Dakai and Zhang, Ling},
title = {Effective Opportunistic Esophageal Cancer Screening Using Noncontrast CT Imaging},
year = {2022},
isbn = {978-3-031-16436-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-16437-8_33},
doi = {10.1007/978-3-031-16437-8_33},
abstract = {Esophageal cancer is the second most deadly cancer. Early detection of resectable/curable esophageal cancers has a great potential to reduce mortality, but no guideline-recommended screening test is available. Although some screening methods have been developed, they are expensive, might be difficult to apply to the general population, and often fail to achieve satisfactory sensitivity for identifying early-stage cancers. In this work, we investigate the feasibility of esophageal tumor detection and classification (cancer or benign) on the noncontrast CT scan, which could potentially be used for opportunistic cancer screening. To capture the global context, a novel position-sensitive self-attention is proposed to augment nnUNet with non-local interactions. Our model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients. In comparison, the mean sensitivity and specificity of four doctors are 75.0% and 83.8%, respectively. For the classification task, our model outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system, our method has comparable performance and is even more sensitive for early-stage cancer and benign tumor. Our proposed method is a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer.},
booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2022: 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part III},
pages = {344–354},
numpages = {11},
keywords = {Noncontrast CT, Self-attention, Cancer screening, Esophageal cancer},
location = {Singapore, Singapore}
}

@inproceedings{10.1007/978-3-030-98464-9_1,
author = {Balasubramaniam, Nagadivya and Kauppinen, Marjo and Hiekkanen, Kari and Kujala, Sari},
title = {Transparency and Explainability of AI Systems: Ethical Guidelines in Practice},
year = {2022},
isbn = {978-3-030-98463-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98464-9_1},
doi = {10.1007/978-3-030-98464-9_1},
abstract = {[Context and Motivation] Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. [Question] The goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems. We analyzed the ethical guidelines in 16 organizations representing different industries and public sector. [Results] In the ethical guidelines, the importance of transparency was highlighted by almost all of the organizations, and explainability was considered as an integral part of transparency. Building trust in AI systems was one of the key reasons for developing transparency and explainability, and customers and users were raised as the main target groups of the explanations. The organizations also mentioned developers, partners, and stakeholders as important groups needing explanations. The ethical guidelines contained the following aspects of the AI system that should be explained: the purpose, role of AI, inputs, behavior, data utilized, outputs, and limitations. The guidelines also pointed out that transparency and explainability relate to several other quality requirements, such as trustworthiness, understandability, traceability, privacy, auditability, and fairness. [Contribution] For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a structured way to define explainability requirements of AI systems.},
booktitle = {Requirements Engineering: Foundation for Software Quality: 28th International Working Conference, REFSQ 2022, Birmingham, UK, March 21–24, 2022, Proceedings},
pages = {3–18},
numpages = {16},
keywords = {AI systems, Ethical guidelines, Quality requirements, Explainability, Transparency},
location = {Birmingham, United Kingdom}
}

@article{10.1016/j.compag.2017.04.015,
author = {Agostini, Alejandro and Aleny, Guillem and Fischbach, Andreas and Scharr, Hanno and Wrgtter, Florentin and Torras, Carme},
title = {A cognitive architecture for automatic gardening},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {138},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2017.04.015},
doi = {10.1016/j.compag.2017.04.015},
abstract = {A cognitive system to autonomously control the growth of plants is proposed.The system integrates artificial intelligence and robotic techniques.Decisions are made using symbolic planning and machine learning.Plants are modelled using 3D model acquisition of deformable objects (leaves).Action rules are learned during run-time under the guidance of a human gardener. In large industrial greenhouses, plants are usually treated following well established protocols for watering, nutrients, and shading/light. While this is practical for the automation of the process, it does not tap the full potential for optimal plant treatment. To more efficiently grow plants, specific treatments according to the plant individual needs should be applied. Experienced human gardeners are very good at treating plants individually. Unfortunately, hiring a crew of gardeners to carry out this task in large greenhouses is not cost effective. In this work we present a cognitive system that integrates artificial intelligence (AI) techniques for decision-making with robotics techniques for sensing and acting to autonomously treat plants using a real-robot platform. Artificial intelligence techniques are used to decide the amount of water and nutrients each plant needs according to the history of the plant. Robotic techniques for sensing measure plant attributes (e.g. leaves) from visual information using 3D model representations. These attributes are used by the AI system to make decisions about the treatment to apply. Acting techniques execute robot movements to supply the plants with the specified amount of water and nutrients.},
journal = {Comput. Electron. Agric.},
month = {jun},
pages = {69–79},
numpages = {11},
keywords = {Optimized plant treatments, Learning planning operators, Human-robot interaction, Cognitive architecture, Automatic gardening}
}

@inproceedings{10.5555/295240.296256,
author = {Lathrop, Richard H. and Steffen, Nicholas R. and Raphael, Miriam P. and Deeds-Rubin, Sophia and Pazzani, Michael J. and Cimoch, Paul J. and See, Darryl M. and Tilles, Jeremiah G.},
title = {Knowledge-based avoidance of drug-resistant HIV mutants},
year = {1998},
isbn = {0262510987},
publisher = {American Association for Artificial Intelligence},
address = {USA},
abstract = {We describe an artificial intelligence (AI) system (CTSHIV) that connects the scientific AIDS literature describing specific HIV drug resistances directly to the Customized Treatment Strategy of a specific HIV patient. Rules in the CTSHIV knowledge base encode knowledge about sequence mutations in the HIV genome that have been found to result in drug resistance in the HIV virus. Rules are applied to the actual HIV sequences of the virus strains infecting the specific patient undergoing clinical treatment in order to infer current drug resistance. A search through mutation sequence space identifies nearby drug resistant mutant strains that might arise. The possible drug treatment regimens currently approved by the US Food and Drug Administration (FDA) are considered and ranked by their estimated ability to avoid identified current and nearby drug resistant mutants. The highest-ranked treatments are recommended to the attending physician. The result is more precise treatment of individual HIV patients, and a decreased tendency to select for drug resistant genes in the global HIV gene pool. The application is currently in use in human clinical trials on HIV patients. Initial results from a small clinical trial are encouraging and further clinical trials are planned. From an AI viewpoint the case study demonstrates the extensibility of knowledge-based systems because it illustrates how existing encoded knowledge can be used to support new applications that were unanticipated when the original knowledge was encoded.},
booktitle = {Proceedings of the Fifteenth National/Tenth Conference on Artificial Intelligence/Innovative Applications of Artificial Intelligence},
pages = {1071–1078},
numpages = {8},
location = {Madison, Wisconsin, USA},
series = {AAAI '98/IAAI '98}
}

@inproceedings{10.1007/978-3-030-77211-6_34,
author = {Parimbelli, Enea and Gabetta, Matteo and Lanzola, Giordano and Polce, Francesca and Wilk, Szymon and Glasspool, David and Kogan, Alexandra and Leizer, Roy and Gisko, Vitali and Veggiotti, Nicole and Panzarasa, Silvia and de Groot, Rowdy and Ottaviano, Manuel and Sacchi, Lucia and Cornet, Ronald and Peleg, Mor and Quaglini, Silvana},
title = {CAncer PAtients Better Life Experience (CAPABLE) First Proof-of-Concept Demonstration},
year = {2021},
isbn = {978-3-030-77210-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77211-6_34},
doi = {10.1007/978-3-030-77211-6_34},
abstract = {The CAncer PAtient Better Life Experience (CAPABLE) project combines the most advanced technologies for data and knowledge management with a socio-psychological approach, to develop a coaching system for improving the quality of life of cancer patients managed at home. The team includes complementary expertise in data- and knowledge-driven AI, data integration, telemedicine and decision support. The time is right to fully exploit Artificial Intelligence for cancer care and bring the benefits right to patients’ homes. CAPABLE relies on predictive models based on both retrospective and prospective data, integrated with computer interpretable guidelines and made available to oncologists. CAPABLE’s Virtual Coach component identifies unexpected needs and provides patient-specific decision support and lifestyle guidance to improve mental and physical wellbeing of patients. The demo, designed around a use-case scenario developed with clinicians involved in the project, addresses the ESMO Diarrhea guideline. It revolves around a prototypical fictional patient named Maria. Maria, 66, is affected by renal cell carcinoma and moderate insomnia. The demo follows Maria during the first three days of using the CAPABLE system. This allows the audience to understand the scope and innovation behind this AI-based decision-support and coaching system that personalizes lifestyle and medication interventions to patients, their carer and clinicians.},
booktitle = {Artificial Intelligence in Medicine: 19th International Conference on Artificial Intelligence in Medicine, AIME 2021, Virtual Event, June 15–18, 2021, Proceedings},
pages = {298–303},
numpages = {6},
keywords = {mHealth, AI, OMOP, FHIR, FAIR, Guideline, Coaching, Personalization, Side effects, Cancer}
}

@inproceedings{10.1145/3510003.3510163,
author = {Chen, Boyuan and Wen, Mingzhi and Shi, Yong and Lin, Dayi and Rajbahadur, Gopi Krishnan and Jiang, Zhen Ming (Jack)},
title = {Towards training reproducible deep learning models},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510163},
doi = {10.1145/3510003.3510163},
abstract = {Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2202–2214},
numpages = {13},
keywords = {software engineering, reproducibility, deep learning, artificial intelligence},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3604321.3604375,
author = {Wright, Craig and Allnutt, Jack and Campbell, Rosie and Evans, Michael and Jolly, Stephen and Shotton, Em and Lechelt, Susan and Phillipson, Graeme and Kerlin, Lianne},
title = {AI in Production: Video Analysis and Machine Learning for Expanded Live Events Coverage},
year = {2023},
isbn = {9798400708459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604321.3604375},
doi = {10.1145/3604321.3604375},
abstract = {As with many industries, TV and video production is likely to be transformed by artificial intelligence (AI) and machine learning (ML), with software and algorithms assisting production tasks that, conventionally, could only be carried out by people. Expanded coverage of a diverse range of live events is particularly constrained by the relative scarcity of skilled people, and it is a strong use case for AI-based automation. This article describes the recent research conducted by the British Broadcasting Corporation (BBC) on the potential production benefits of AI algorithms, using visual analysis and other techniques. Rigging small, static ultra high-definition (UHD) cameras, we have enabled a one-person crew to crop UHD footage in multiple ways and cut between the resulting shots, effectively creating multicamera HD coverage of events that cannot accommodate a camera crew. By working with programme-makers to develop simple deterministic rules and, increasingly, training systems using advanced video analysis, we are developing a system of algorithms to automatically frame, sequence, and select shots, and construct acceptable multicamera coverage of previously untelevised types of events. This paper was published in the proceedings of the International Broadcasting Convention in 2018&nbsp;[1], and in SMPTE Motion Imaging Journal in 2020&nbsp;[2].},
booktitle = {Proceedings of the 2023 ACM International Conference on Interactive Media Experiences Workshops},
pages = {77–78},
numpages = {2},
keywords = {user evaluation, intelligent cinematography, broadcasting, broadcast technology},
location = {Nantes, France},
series = {IMXw '23}
}

@inproceedings{10.1109/SMC42975.2020.9282981,
author = {Fujita, Shigeru and Gidel, Thierry and Kaeri, Yuki and Tucker, Andrea and Sugawara, Kenji and Moulin, Claude},
title = {AI-based Automatic Activity Recognition of Single Persons and Groups During Brainstorming&lt;sup&gt;*&lt;/sup&gt;},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC42975.2020.9282981},
doi = {10.1109/SMC42975.2020.9282981},
abstract = {In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person’s motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person’s activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students’ work sessions.},
booktitle = {2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {3782–3787},
numpages = {6},
location = {Toronto, ON}
}

@inproceedings{10.1145/3494193.3494195,
author = {Mitrou, Lilian and Janssen, Marijn and Loukis, Euripidis},
title = {Human Control and Discretion in AI-driven Decision-making in Government},
year = {2022},
isbn = {9781450390118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494193.3494195},
doi = {10.1145/3494193.3494195},
abstract = {Traditionally public decision-makers have been given discretion in many of the decisions they have to make in how to comply with legislation and policies. In this way, the context and specific circumstances can be taken into account when making decisions. This enables more acceptable solutions, but at the same time, discretion might result in treating individuals differently. With the advance of AI-based decisions, the role of the decision-makers is changing. The automation might result in fully automated decisions, humans-in-the-loop or AI might only be used as recommender systems in which humans have the discretion to deviate from the suggested decision. The predictability of and the accountability of the decisions might vary in these circumstances, although humans always remain accountable. Hence, there is a need for human-control and the decision-makers should be given sufficient authority to control the system and deal with undesired outcomes. In this direction this paper analyzes the degree of discretion and human control needed in AI-driven decision-making in government. Our analysis is based on the legal requirements set/posed to the administration, by the extensive legal frameworks that have been created for its operation, concerning the rule of law, the fairness – non-discrimination, the justifiability and accountability, and the certainty/ predictability.},
booktitle = {Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance},
pages = {10–16},
numpages = {7},
location = {Athens, Greece},
series = {ICEGOV '21}
}

@article{10.3233/IP-211524,
author = {Barkane, Irena and \v{C}as, Johann and De Hert, Paul and Porcedda, Maria Grazia and Raab, Charles D.},
title = {Questioning the EU proposal for an Artificial Intelligence Act: The need for prohibitions and a stricter approach to biometric surveillance1},
year = {2022},
issue_date = {2022},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {2},
issn = {1570-1255},
url = {https://doi.org/10.3233/IP-211524},
doi = {10.3233/IP-211524},
abstract = {Artificial Intelligence (AI)-based surveillance technologies such as facial recognition, emotion recognition and other biometric technologies have been rapidly introduced by both public and private entities all around the world, raising major concerns about their impact on fundamental rights, the rule of law and democracy. This article questions the efficiency of the European Commission’s Proposal for Regulation of Artificial Intelligence, known as the AI Act, in addressing the threats and risks to fundamental rights posed by AI biometric surveillance systems. It argues that in order to meaningfully address risks to fundamental rights the proposed classification of these systems should be reconsidered. Although the draft AI Act acknowledges that some AI practices should be prohibited, the multiple exceptions and loopholes should be closed, and in addition new prohibitions, in particular to emotional recognition and biometric categorisation systems, should be added to counter AI surveillance practices violating fundamental rights. The AI Act should also introduce stronger legal requirements, such as third-party conformity assessment, fundamental rights impact assessment, transparency obligations as well as enhance existing EU data protection law and the rights and remedies available to individuals, thus not missing the unique opportunity to adopt the first legal framework that truly promotes trustworthy AI.},
journal = {Info. Pol.},
month = {jan},
pages = {147–162},
numpages = {16},
keywords = {prohibited artificial intelligence practices, emotion recognition, biometric categorisation, remote biometric identification, ban on mass surveillance, Artificial Intelligence Act}
}

@phdthesis{10.5555/914553,
author = {Manivannan, Sundaravaradhan},
advisor = {Pegden, C. Dennis},
title = {Jitsai--a new rule-based simulator for modeling just-in-time manufacturing systems},
year = {1988},
publisher = {The Pennsylvania State University},
abstract = {Based on the most recent trends in conventional simulation and AI based simulation systems, a new modeling framework for simulating various production related issues in Just-in-time production systems has been developed. Using this framework, a new domain-specific, rule-based simulator, known as JITSAI (Just-in-time simulation with Artificial Intelligence) has been designed and implemented in LISP language. It includes the design of a domain-specific rulebase, an event planner, static and dynamic databases, language constructs or primitives, a forward chaining control mechanism, a rule-adequacy tester, an explanation sub-system and an efficient user-interface. Primarily, three new design concepts are brought out in this simulator. First, an event planner consisting of a set of rules interacts with the rulebase and an event calendar in selecting the next event during the simulation. This reduces the simulation run-time considerably compared to the existing rule-oriented simulators designed for other applications. Second, the process of model creation and simulation program generation is automated using the rulebase and the inference mechanism. Third, a rulebase adequacy tester is designed using a graph theoretic approach for identifying the inadequacy in rules during the rule chaining process. Extensive testing has been performed in evaluating the performance of JITSAI design.},
note = {AAI8826788}
}

@article{10.1155/2021/5754322,
author = {Rathee, Geetanjali and Khelifi, Adel and Iqbal, Razi and Reina, Daniel G.},
title = {Artificial Intelligence- (AI-) Enabled Internet of Things (IoT) for Secure Big Data Processing in Multihoming Networks},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5754322},
doi = {10.1155/2021/5754322},
abstract = {The automated techniques enabled with Artificial Neural Networks (ANN), Internet of Things (IoT), and cloud-based services affect the real-time analysis and processing of information in a variety of applications. In addition, multihoming is a type of network that combines various types of networks into a single environment while managing a huge amount of data. Nowadays, the big data processing and monitoring in multihoming networks provide less attention while reducing the security risk and efficiency during processing or monitoring the information. The use of AI-based systems in multihoming big data with IoT- and AI-integrated systems may benefit in various aspects. Although multihoming security issues and their analysis have been well studied by various scientists and researchers; however, not much attention is paid towards big data security processing in multihoming especially using automated techniques and systems. The aim of this paper is to propose an IoT-based artificial network to process and compute big data processing by ensuring a secure communication multihoming network using the Bayesian Rule (BR) and Levenberg-Marquardt (LM) algorithms. Further, the efficiency and effect on multihoming information processing using an AI-assisted mechanism are experimented over various parameters such as classification accuracy, classification time, specificity, sensitivity, ROC, and F-measure.},
journal = {Wirel. Commun. Mob. Comput.},
month = {jan},
numpages = {9}
}

@inproceedings{10.1007/978-3-031-45368-7_2,
author = {Godoy B. de Oliveira, Cristina and de Paula Albuquerque, Ot\'{a}vio and Liene Belotti, Emily and Ferreira Lopes, Isabella and Brand\~{a}o de A. Silva, Rodrigo and Arbix, Glauco},
title = {Regulation and&nbsp;Ethics of&nbsp;Facial Recognition Systems: An Analysis of&nbsp;Cases in&nbsp;the&nbsp;Court of&nbsp;Appeal in&nbsp;the&nbsp;State of&nbsp;S\~{a}o Paulo},
year = {2023},
isbn = {978-3-031-45367-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-45368-7_2},
doi = {10.1007/978-3-031-45368-7_2},
abstract = {Context: The use of Artificial Intelligence (AI) in various sectors of the economy is already a reality in Brazil. Consequently, since 2019, the number of cases in the Judiciary involving AI has increased. Cases involving facial recognition systems (FRS) for contracting bank credit are increasing annually, so it is necessary to analyze how the Judiciary handles the issues. Problem: Why is the S\~{a}o Paulo Court of Appeal ruling in favor of banks in all cases involving taking out credit through facial recognition technology? Methodology and Methods: Data were collected and processed using automated computer programs. The qualitative analysis used the analytical, comparative and monographic methods. Results: The Court of Appeal of S\~{a}o Paulo considers it difficult to deceive an AI system, therefore, the burden of proof is on the author, even if there is a consumer relationship. That is, the decisions are contrary to the general rule of the Code of Consumer Protection in Brazil, which consists of reversing the burden of proof in consumer relations when one of the parties is underprivileged. Contributions and Solutions: The research points to the path of jurisprudence in cases involving the contracting of credit through FRS, and the Judiciary is deciding against the bank’s customers, dispensing with the production of evidence by the banking sector. Therefore, it is necessary to alert the National Council of Justice and the Central Bank regarding this situation so that it is disciplined adequately since the FRS is fallible and does not guarantee the absence of fraud.},
booktitle = {Intelligent Systems: 12th Brazilian Conference, BRACIS 2023, Belo Horizonte, Brazil, September 25–29, 2023, Proceedings, Part I},
pages = {18–32},
numpages = {15},
keywords = {AI and Jurisprudence, Artificial Intelligence and Law, Facial Recognition Systems and Legal Cases},
location = {Belo Horizonte, Brazil}
}

@article{10.1109/MCI.2020.3039068,
author = {Nguyen, Minh N.H. and Pandey, Shashi Raj and Thar, Kyi and Tran, Nguyen H. and Chen, Mingzhe and Saad Bradley, Walid and Hong, Choong Seon},
title = {Distributed and Democratized Learning: Philosophy and Research Challenges},
year = {2021},
issue_date = {Feb. 2021},
publisher = {IEEE Press},
volume = {16},
number = {1},
issn = {1556-603X},
url = {https://doi.org/10.1109/MCI.2020.3039068},
doi = {10.1109/MCI.2020.3039068},
abstract = {Due to the availability of huge amounts of data and processing abilities, current artificial intelligence (AI) systems are effective in solving complex tasks. However, despite the success of AI in different areas, the problem of designing AI systems that can truly mimic human cognitive capabilities such as artificial general intelligence, remains largely open. Consequently, many emerging cross-device AI applications will require a transition from traditional centralized learning systems towards large-scale distributed AI systems that can collaboratively perform multiple complex learning tasks. In this paper, we propose a novel design philosophy called democratized learning (Dem-AI) whose goal is to build large-scale distributed learning systems that rely on the self-organization of distributed learning agents that are wellconnected, but limited in learning capabilities. Correspondingly, inspired by the societal groups of humans, the specialized groups of learning agents in the proposed Dem-AI system are selforganized in a hierarchical structure to collectively perform learning tasks more efficiently. As such, the Dem-AI learning system can evolve and regulate itself based on the underlying duality of two processes which we call specialized and generalized processes. In this regard, we present a reference design as a guideline to realize future Dem-AI systems, inspired by various interdisciplinary fields. Accordingly, we introduce four underlying mechanisms in the design such as plasticity-stability transition mechanism, self-organizing hierarchical structuring, specialized learning, and generalization. Finally, we establish possible extensions and new challenges for the existing learning approaches to provide better scalable, flexible, and more powerful learning systems with the new setting of Dem-AI.},
journal = {Comp. Intell. Mag.},
month = {feb},
pages = {49–62},
numpages = {14}
}

@inproceedings{10.1007/978-3-030-77967-2_45,
author = {Przybyszewski, Andrzej W.},
title = {Theory of Mind Helps to Predict Neurodegenerative Processes in Parkinson’s Disease},
year = {2021},
isbn = {978-3-030-77966-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77967-2_45},
doi = {10.1007/978-3-030-77967-2_45},
abstract = {Normally, it takes many years of theoretical and clinical training for a physician to be the movement disorder specialist. It takes additional multiple years of the clinical practice to handle various “non-typical” cases. The purpose of our study was to predict neurodegenerative disease development by abstract rules learned from experienced neurologists. Theory of mind (ToM) is human’s ability to represent mental states such as emotions, intensions or knowledge of others. ToM is crucial not only in human social interactions but also is used by neurologists to find an optimal treatment for patients with neurodegenerative pathologies such as Parkinson’s disease (PD). On the basis of doctors’ expertise, we have used supervised learning to build AI system that consists of abstract granules representing ToM of several movement disorders neurologists (their knowledge and intuitions). We were looking for similarities between granules of patients in different disease stages to granules of more advanced PD patients. We have compared group of 23 PD with attributes measured three times every half of the year (G1V1, G1V2, G1V3) to other group of 24 more advanced PD (G2V1). By means of the supervised learning and rough set theory we have found rules describing symptoms of G2V1 and applied them to G1V1, G1V2, and G1V3. We have obtained the following accuracies for all/speed/emotion/cognition attributes: G1V1: 68/59/53/72%; G1V2: 72/70/79/79%; G1V3: 82/92/71/74%. These results support our hypothesis that divergent sets of granules were characteristic for different brain’s parts that might degenerate in non-uniform ways with Parkinson’s disease progression.},
booktitle = {Computational Science – ICCS 2021: 21st International Conference, Krakow, Poland, June 16–18, 2021, Proceedings, Part III},
pages = {542–555},
numpages = {14},
keywords = {Cognition, Rules, Rough set, Granular computing},
location = {Krakow, Poland}
}

@article{10.1016/j.compbiomed.2021.105111,
author = {Salahuddin, Zohaib and Woodruff, Henry C. and Chatterjee, Avishek and Lambin, Philippe},
title = {Transparency of deep neural networks for medical image analysis: A review of interpretability methods},
year = {2022},
issue_date = {Jan 2022},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {140},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.105111},
doi = {10.1016/j.compbiomed.2021.105111},
journal = {Comput. Biol. Med.},
month = {jan},
numpages = {18},
keywords = {Deep neural networks, Interpretability, Explainability, Medical imaging, Explainable artificial intelligence}
}

@article{10.1016/j.chb.2022.107547,
author = {Lim, Lyn and Bannert, Maria and van der Graaf, Joep and Singh, Shaveen and Fan, Yizhou and Surendrannair, Surya and Rakovic, Mladen and Molenaar, Inge and Moore, Johanna and Ga\v{s}evi\'{c}, Dragan},
title = {Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning},
year = {2023},
issue_date = {Feb 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {139},
number = {C},
issn = {0747-5632},
url = {https://doi.org/10.1016/j.chb.2022.107547},
doi = {10.1016/j.chb.2022.107547},
journal = {Comput. Hum. Behav.},
month = {feb},
numpages = {18},
keywords = {Trace data, Process mining, Adaptive support, Personalized scaffolds, Learning analytics, Self-regulated learning}
}

@inproceedings{10.1007/978-3-030-58796-3_10,
author = {Su\'{a}rez-Figueroa, Mari Carmen and Ruckhaus, Edna and L\'{o}pez-Guerrero, Jorge and Cano, Isabel and Cervera, \'{A}lvaro},
title = {Towards the Assessment of Easy-to-Read Guidelines Using Artificial Intelligence Techniques},
year = {2020},
isbn = {978-3-030-58795-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58796-3_10},
doi = {10.1007/978-3-030-58796-3_10},
abstract = {The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities, who have difficulties in reading comprehension. The main goal of the E2R Methodology is to present clear and easily understood documents. This methodology includes a set of guidelines and recommendations that affect the writing of texts, the supporting images, the design and layout of documents, and the final editing format. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. The process of adapting existing documents is cyclic and implies three activities: analysis, transformation, and validation. All these activities are human resource consuming, due to the need of involving people with cognitive disabilities as well as E2R experts. In order to alleviate such processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to perform the analysis and transformation of documents in a (semi)-automatic fashion. In this paper we present our AI-based method for assessing a particular document with respect to the E2R guidelines as well as an initial implementation of such a method; our research on the transformation of documents is out of the scope of this paper. We carried out a comparative evaluation of the results obtained by our initial implementation against the results of the document analysis performed by people with cognitive disabilities.},
booktitle = {Computers Helping People with Special Needs: 17th International Conference, ICCHP 2020, Lecco, Italy, September 9–11, 2020, Proceedings, Part I},
pages = {74–82},
numpages = {9},
keywords = {Artificial intelligence, Cognitive accessibility, E2R methodology},
location = {Lecco, Italy}
}

@inproceedings{10.1145/3514094.3534160,
author = {Cachel, Kathleen and Rundensteiner, Elke},
title = {FINS Auditing Framework: Group Fairness for Subset Selections},
year = {2022},
isbn = {9781450392471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514094.3534160},
doi = {10.1145/3514094.3534160},
abstract = {Subset selection is an integral component of AI systems that is increasingly affecting people's livelihoods in applications ranging from hiring, healthcare, education, to financial decisions. Subset selections powered by AI-based methods include top-k analytics, data summarization, clustering, and multi-winner voting. While group fairness auditing tools have been proposed for classification systems, these state-of-the-art tools are not directly applicable to measuring and conceptualizing fairness in selected subsets. In this work, we introduce the first comprehensive auditing framework, FINS, to support stakeholders in interpretably quantifying group fairness across a diverse range of subset-specific fairness concerns. FINS offers a family of novel measures that provide a flexible means to audit group fairness for fairness goals ranging from item-based, score-based, and a combination thereof. FINS provides one unified easy-to-understand interpretation across these different fairness problems. Further, we develop guidelines through the FINS Fair Subset Chart, that supports auditors in determining which measures are relevant to their problem context and fairness objectives. We provide a comprehensive mapping between each fairness measure and the belief system (i.e., worldview) that is encoded within its measurement of fairness. Lastly, we demonstrate the interpretability and efficacy of FINS in supporting the identification of real bias with case studies using AirBnB listings and voter records.},
booktitle = {Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {144–155},
numpages = {12},
keywords = {subset selection, machine learning fairness, algorithmic fairness},
location = {Oxford, United Kingdom},
series = {AIES '22}
}

@inbook{10.5555/778212.778302,
author = {Levin, Nissan and Zahavi, Jacob},
title = {Case studies: Commercial, multiple mining tasks systems: gainsmarts},
year = {2002},
isbn = {0195118316},
publisher = {Oxford University Press, Inc.},
address = {USA},
abstract = {GainSmarts is a data mining system in support of database marketing decisions, encompassing the entire range of the KDD process, including data import, exploratory data analysis, transformation of variables, feature selection, data mining, knowledge evaluation, and model validation (see Chapters 12, 14.2, 16.1.3, 16.1.7, 19, and 34). The data mining engine contains a profiling module to segment an audience employing automatic decision trees, and predictive modeling involving discrete and continuous regression models and AI-based models to predict customers' choice. Numerous statistical tests are used to evaluate knowledge and validate results. GainSmarts' most unique component is feature selection. Governed by a set of rules, the process automatically selects the best predictors explaining customers' choice. GainSmarts also provides for scoring customer lists and using economic criteria to select customers for promotion. Detailed reporting and visualization tools facilitate understanding and interpretation of the model results. GainSmarts is designed for use either as a standalone or an open system. Migration of the system to additional applications is easy. Written primarily in SAS, GainSmarts can run on many SAS-supported platforms. GainSmarts has already been applied to a variety of problems in diverse industries. It is the two-time winner of the Gold Miner award in the KDD-CUP 97 and KDD-CUP 98 competitions, organized by the American Association of Artificial Intelligence.},
booktitle = {Handbook of Data Mining and Knowledge Discovery},
pages = {601–609},
numpages = {9}
}

@inproceedings{10.1145/3375627.3377139,
author = {Gurumurthy, Anita},
title = {The AI-development Connection - A View from the South},
year = {2020},
isbn = {9781450371100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375627.3377139},
doi = {10.1145/3375627.3377139},
abstract = {The socialisation of Artificial Intelligence and the reality of an intelligence economy mark an epochal moment. The impacts of AI are now systemic - restructuring economic organisation and value chains, public sphere architectures and sociality. These shifts carry deep geo-political implications, reinforcing historical exclusions and power relations and disrupting the norms and rules that hold ideas of equality and justice together.At the centre of this rapid change is the intelligent corporation and its obsessive pursuit of data. Directly impinging on bodies and places, the de facto rules forged by the intelligent corporation are disenfranchising the already marginal subjects of development. Using trade deals to liberalise data flows, tighten trade secret rules and enclose AI-based innovation, Big Tech and their political masters have effectively taken away the economic and political autonomy of states in the global south. Big Tech's impunity extends to a brazen exploitation - enslaving labour through data over-reach and violating female bodies to universalise data markets. Thinking through the governance of AI needs new frameworks that can grapple with the fraught questions of data sovereignty, economic democracy, and institutional ethics in a global world with local aspirations. Any effort towards norm development in this domain will need to see the geo-economics of digital intelligence and the geo-politics of development ideologies as two sides of the same coin.},
booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
pages = {3},
numpages = {1},
keywords = {intelligent corporation, geo-politics of development, digital intelligence},
location = {New York, NY, USA},
series = {AIES '20}
}

@inproceedings{10.1007/978-3-031-16902-1_8,
author = {Puyol-Ant\'{o}n, Esther and Ruijsink, Bram and Sidhu, Baldeep S. and Gould, Justin and Porter, Bradley and Elliott, Mark K. and Mehta, Vishal and Gu, Haotian and Rinaldi, Christopher A. and cowie, Martin and Chowienczyk, Phil and Razavi, Reza and King, Andrew P.},
title = {AI-Enabled Assessment of&nbsp;Cardiac Systolic and&nbsp;Diastolic Function from&nbsp;Echocardiography},
year = {2022},
isbn = {978-3-031-16901-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-16902-1_8},
doi = {10.1007/978-3-031-16902-1_8},
abstract = {Left ventricular (LV) function is an important factor in terms of patient management, outcome, and long-term survival of patients with heart disease. The most recently published clinical guidelines for heart failure recognise that over reliance on only one measure of cardiac function (LV ejection fraction) as a diagnostic and treatment stratification biomarker is suboptimal. Recent advances in AI-based echocardiography analysis have shown excellent results on automated estimation of LV volumes and LV ejection fraction. However, from time-varying 2-D echocardiography acquisition, a richer description of cardiac function can be obtained by estimating functional biomarkers from the complete cardiac cycle. In this work we propose for the first time an AI approach for deriving advanced biomarkers of systolic and diastolic LV function from 2-D echocardiography based on segmentations of the full cardiac cycle. These biomarkers will allow clinicians to obtain a much richer picture of the heart in health and disease. The AI model is based on the ’nn-Unet’ framework and was trained and tested using four different databases. Results show excellent agreement between manual and automated analysis and showcase the potential of the advanced systolic and diastolic biomarkers for patient stratification. Finally, for a subset of 50 cases, we perform a correlation analysis between clinical biomarkers derived from echocardiography and cardiac magnetic resonance and we show a very strong relationship between the two modalities.},
booktitle = {Simplifying Medical Ultrasound: Third International Workshop, ASMUS 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings},
pages = {75–85},
numpages = {11},
keywords = {Deep learning, Cardiac function, Image segmentation, Echocardiography},
location = {Singapore, Singapore}
}

@article{10.1016/j.knosys.2022.108410,
author = {Yang, Long-Hao and Ren, Tian-Yu and Ye, Fei-Fei and Nicholl, Peter and Wang, Ying-Ming and Lu, Haitian},
title = {An ensemble extended belief rule base decision model for imbalanced classification problems},
year = {2022},
issue_date = {Apr 2022},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {242},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2022.108410},
doi = {10.1016/j.knosys.2022.108410},
journal = {Know.-Based Syst.},
month = {apr},
numpages = {15},
keywords = {Oversampling, Inconsistency, Diversity, Imbalanced classification, Belief rule base}
}

@inproceedings{10.1007/978-3-030-63885-6_33,
author = {Lee, Tony Szu-Hsien and Liu, Shiang-Yao and Wei, Yin-Ling and Chang, Li-Yun},
title = {A Comparative Study on Ethics Guidelines for Artificial Intelligence Across Nations},
year = {2020},
isbn = {978-3-030-63884-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63885-6_33},
doi = {10.1007/978-3-030-63885-6_33},
abstract = {This study aimed to investigate the commonality and differences among AI research and development (R&amp;D) guidelines across nations. Content analysis was conducted on AI R&amp;D guidelines issued by more economically developed countries because they may guide the trend of AI-based applications in education. Specifically, this study consisted of three phases: 1) information retrieval, (2) key term extraction, and (3) data visualization. First, Fisher’s exact test was employed to ensure that different AI R&amp;D guidelines (e.g., the latest ones in the US, EU, Japan, Mainland, and Taiwan) were comparable. Second, the Key Word Extraction System was developed to retrieve essential information in the guidelines. Third, data visualization techniques were performed on key terms across multiple guidelines. A word cloud revealed the similarity among guidelines (e.g., key terms that these guidelines share in common) while a color-coding scheme showed the differences (e.g., occurrence of a key term across guidelines and its frequency within a guideline). Importantly, three key terms, namely, AI, human, and development, are identified as essential commonality across guidelines. As for key terms that only extracted from particular guidelines, interestingly, results with the color-coding scheme suggested that these key terms were weighted differently depends on the developmental emphasis of a nation. Collectively, we discussed how these findings concerning ethics guidelines may shed light on AI research and development to educational technology.},
booktitle = {Innovative Technologies and Learning: Third International Conference, ICITL 2020, Porto, Portugal, November 23–25, 2020, Proceedings},
pages = {289–295},
numpages = {7},
keywords = {Text mining, Ethics guidelines, Education, Data visualization technique, Artificial intelligence},
location = {Porto, Portugal}
}

@article{10.1007/s11554-021-01070-6,
author = {Saponara, Sergio and Elhanashi, Abdussalam and Gagliardi, Alessio},
title = {Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-021-01070-6},
doi = {10.1007/s11554-021-01070-6},
abstract = {COVID-19 is a disease caused by a severe respiratory syndrome coronavirus. It was identified in December 2019 in Wuhan, China. It has resulted in an ongoing pandemic that caused infected cases including many deaths. Coronavirus is primarily spread between people during close contact. Motivating to this notion, this research proposes an artificial intelligence system for social distancing classification of persons using thermal images. By exploiting YOLOv2 (you look at once) approach, a novel deep learning detection technique is developed for detecting and tracking people in indoor and outdoor scenarios. An algorithm is also implemented for measuring and classifying the distance between persons and to automatically check if social distancing rules are respected or not. Hence, this work aims at minimizing the spread of the COVID-19 virus by evaluating if and how persons comply with social distancing rules. The proposed approach is applied to images acquired through thermal cameras, to establish a complete AI system for people tracking, social distancing classification, and body temperature monitoring. The training phase is done with two datasets captured from different thermal cameras. Ground Truth Labeler app is used for labeling the persons in the images. The proposed technique has been deployed in a low-cost embedded system (Jetson Nano) which is composed of a fixed camera. The proposed approach is implemented in a distributed surveillance video system to visualize people from several cameras in one centralized monitoring system. The achieved results show that the proposed method is suitable to set up a surveillance system in smart cities for people detection, social distancing classification, and body temperature analysis.},
journal = {J. Real-Time Image Process.},
month = {dec},
pages = {1937–1947},
numpages = {11},
keywords = {Distributed surveillance system, Jetson nano, Temperature analysis, Social distancing, Neural network, COVID-19}
}

@article{10.1016/j.compbiomed.2023.107441,
author = {Seoni, Silvia and Jahmunah, Vicnesh and Salvi, Massimo and Barua, Prabal Datta and Molinari, Filippo and Acharya, U. Rajendra},
title = {Application of uncertainty quantification to artificial intelligence in healthcare: A review of last decade (2013–2023)},
year = {2023},
issue_date = {Oct 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {165},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2023.107441},
doi = {10.1016/j.compbiomed.2023.107441},
journal = {Comput. Biol. Med.},
month = {oct},
numpages = {28},
keywords = {Bayesian models, Healthcare, Signals, Images, PRISMA, Deep learning models, Machine learning models, Uncertainty techniques}
}

@phdthesis{10.5555/AAI28869363,
author = {Banian, Sara and Raymond, Fu, Yun and Sarah, Ostadabbas,},
advisor = {Casper, Harteveld, and Magy, Seif El-Nasr,},
title = {Content-Aware AI-Driven Design Assistance Frameworks for Graphic Design Layouts},
year = {2021},
isbn = {9798762103787},
publisher = {Northeastern University},
address = {USA},
abstract = {Designing user interfaces (UIs) for mobile interaction is widespread but still challenging. It is important for the overall user satisfaction and application success. During the design process, designers express their requirements through images describing the UI's layout, structure, and content. Designers, however, encounter key challenges throughout the design process. For example, searching for inspiring design examples is challenging because current search systems rely on only text-based queries and do not consider the UI structure and content. Furthermore, these systems often focus on overall page-level layout over individual UI components. Also, creating wireframe templates is difficult for many designers as it necessitates an understanding of different design guidelines. Therefore, it is critical to support designers by developing effective design tools to help them be more productive and creative.In this dissertation, I aim to explore how to develop design assistance methodologies to augment the process of UI layout design, with a particular focus on visual search and layout generation. Specifically, for this exploration, I seek to investigate the use of advanced deep learning models in the context of mobile UI layout design. Processing layouts differs from processing pixel-level images in that it necessitates processing both the semantic (e.g., labels) and spatial (e.g., coordinates) content of the layout to model the data properly. To achieve this, I explore the design problems from both the data and the model side. First, I present a large-scale UI dataset that accurately specifies the interface's view hierarchy (i.e., UI components and their location). Second, I contribute the VINS framework, which is composed of three systems LayVis, CompVis, and TransVis that addresses layout-based visual search, component-based visual search, and layout generation, respectively.First, I introduce LayVis, an object-detection layout-based retrieval model. It takes as input a UI image and retrieves visually similar design examples. Next, I introduce CompVis, a component-based visual search system to easily retrieve individual UI components via convolutional neural networks (CNNs). Specifically, for a given query, the system allows to retrieve (1) text label synonyms, (2) similar UI components, and (3) design examples containing such components. Finally, I present TransVis, a transformer-based generative framework that investigate how to generate UI layouts according to user specifications and following design practices. It specifically models UI layouts as an ordered sequence of elements based on spatial and semantic relationships for (1) generating complete UI layouts, (2) auto-completing existing UI layouts seamlessly, and (3) supporting many design elements per layout.Overall, the work presented in this dissertation contributes to augmenting the UI layout design. Through quantitative and qualitative evaluation of VINS, we conclude the following: (1) Advanced deep learning models can aid in the development of design assistance methodologies for layout design; and (2) Designers perceive the use of VINS inspiring and useful. Such insights, combined with the open-sourced large-scale dataset, can help the research community develop more effective AI-based data-driven design tools. This work presents future opportunities to investigate different deep learning models within the context of layout design and how designers interact with these AI-based models.},
note = {AAI28869363}
}

@phdthesis{10.5555/124837,
author = {Raghupathi, Wullianallur Ramappa},
title = {Artificial intelligence systems support for organizational decision-making: the blackboard approach},
year = {1991},
publisher = {University of Texas at Arlington},
address = {USA},
abstract = {This exploratory research examines and models expertise in corporate legal decision making using the blackboard approach. It is theorized that classes of problems exist in organizations for which the blackboard model is an appropriate problem formulation and problem solving tool. It follows from the clear distinction made between the legal function and legal decision making in the legal domain. The legal function comprises the various routine and procedural tasks that are fairly structured. Legal decision making, on the other hand involves the decision processes involved in illstructured problems characterized by complexity and uncertainty. These require multiple experts to cooperatively solve the problem. It is proposed that while rule-based approaches are adequate for the legal function tasks, sophisticated problem solving architectures such as the blackboard are needed for legal decision making.A conceptual blackboard model is developed for the specific "litigate or settle" decision in the product liability area.The conceptual model is operationalized by the implementation of a limited prototype. Both the conceptual model and the prototype are validated for adequacy, completeness and functionality using panels of experts. Validation results strongly indicate the appropriateness of the blackboard model in the "litigate or settle" domain. Experiments involving the analyses of a hypothetical case are conducted to demonstrate the various features of the blackboard model. The blackboard model is operationally compared to a rule-based model by further experiments. Results indicate that this blackboard is operationally superior to this rule-based in the particular "litigate or settle" domain.A taxonomy of expert system application domains is developed. It is proposed from the taxonomy that different classes of problems requires different AI-based problem solving architectures. Design guidelines for potential blackboard-based expert systems are identified from the taxonomy development, conceptual model and prototype application. Future research issues are discussed.},
note = {UMI Order No. GAX91-31759}
}

@inproceedings{10.1007/978-3-031-34017-8_14,
author = {Laarhoven, Thijs and Ponukumati, Aditya},
title = {Towards Transparent Cheat Detection in&nbsp;Online Chess: An Application of&nbsp;Human and&nbsp;Computer Decision-Making Preferences},
year = {2023},
isbn = {978-3-031-34016-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-34017-8_14},
doi = {10.1007/978-3-031-34017-8_14},
abstract = {Online game providers face the challenge of preventing malicious users (cheaters) from breaking the rules and winning games through illegal means. This issue in particular plagues the online chess scene, where the strongest algorithms have long surpassed the world’s best players&nbsp;[4] – any cheater can beat the best human players through computer assistance. Moreover, recent developments in AI-based chess engines have opened the door to even more human-like engines&nbsp;[33], which are increasingly able to mimic legitimate human players. Unfortunately, because major chess websites do not discuss their cheat detection mechanisms publicly, there is limited scientific literature on how to tackle the pervasive problem of cheating in online chess. Certainly, there is no way to validate whether these mechanisms actually work.We take a first step towards formalizing a proper cheat detection framework for online chess by leveraging a large-scale statistical examination of human and computer decision-making tendencies over millions of chess games played online. Although cheaters are not engines (computer players) but centaurs (computer-assisted human players), the insights into computer play serve as a useful guideline for finding the strongest indicators of cheating. We then demonstrate how these findings may distinguish legitimate human players from cheaters in an automated, rules-based manner. Additionally, we argue that the status quo of hiding cheat detection mechanisms from the public eye is dangerous to the integrity of the game, and that cheat detection is foremost a service to society instead of a competitive advantage for chess websites to attract more users. Consistent with Kerckhoffs’ paradigm&nbsp;[24], we believe that the benefits of an open discussion on cheat detection far outweigh the potential drawbacks of cheaters learning about these methods.},
booktitle = {Computers and Games: International Conference, CG 2022, Virtual Event, November 22–24, 2022, Revised Selected Papers},
pages = {163–180},
numpages = {18},
keywords = {decision-making, cheat detection, chess}
}

@inproceedings{10.1145/75427.1030252,
author = {Peschl, Markus F.},
title = {The dead end of symbolic AI and the connectionist approach},
year = {1989},
isbn = {0897912993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/75427.1030252},
doi = {10.1145/75427.1030252},
abstract = {This paper shows, using as well philosophical as logical arguments, the deficiency of the belief, that universal intelligence could be based on the 'physical symbol systems hypothesis'&lt;sup&gt;1&lt;/sup&gt; as it was stated by Newell &amp; Simon. In spite of the (sometimes outstanding) results of orthodox AI, it seems that AI finds it self in a dead end, which is based on the incorrect assumptions of PSSH. The (thought) experiment of SEARLE's Chinese room shows best the problem of symbolic AI: obviously there exist more levels of &lt;i&gt;understanding&lt;/i&gt; -- it can be seen as manipulating symbols (which have in fact &lt;i&gt;no meaning&lt;/i&gt;) or as a &lt;i&gt;subsymbolic&lt;/i&gt; process of spreading (nervous) activations. There is shown, why manipulating meaningless symbols is not the sufficient means for intelligent action:• it is the &lt;i&gt;meaning&lt;/i&gt; and the &lt;i&gt;history&lt;/i&gt; which one closely combines and associates with symbols and sentences - this can not be found in orthodox AI-systems because the meaning is the &lt;i&gt;interpretation&lt;/i&gt; of the observer (user).• it is the &lt;i&gt;relation (junction)&lt;/i&gt; to the &lt;i&gt;physical&lt;/i&gt; world being responsible for the meaning of a symbol -- a symbolic AI-system however does not have this &lt;i&gt;immediate&lt;/i&gt; junction to the real world.• thus it is &lt;i&gt;'lifted up'&lt;/i&gt; from the real world and will never be able to have &lt;i&gt;direct&lt;/i&gt; access to it; i.e. it lacks the &lt;i&gt;'In-der-Welt-Sein&lt;sup&gt;2&lt;/sup&gt;.&lt;/i&gt;• as an orthodox AI-system only uses symbols they are only capable of processing what can be said in natural language -- as M.Polanyi shows, there exists much more knowledge than there can be said in words.• our language is only the &lt;i&gt;'surface'&lt;/i&gt; of our thinking -- i.e. &lt;i&gt;subsymbolic&lt;/i&gt; processes are responsible for our utterances.• thus symbolic AI tries to formulate and simulate processes which can be observed from an outer point of view -- it is trying to model processes which are only the last step of our thinking -- linguistic utterances. There is &lt;i&gt;lost&lt;/i&gt; much of the subsymbolic information which is very important for our decision making, learning and problem solving.• when trying to represent knowledge with symbols there has to be a process of &lt;i&gt;formalizing&lt;/i&gt; a domain -- as I have stated already there is lost very much information in this process.• symbolic AI only uses &lt;i&gt;deduction&lt;/i&gt; for 'enlarging' or gaining new knowledge. Also learning systems which are capable of inductive learning only apply deductive rules for realizing induction.There is shown a way out of this dilemma: &lt;i&gt;neural computing&lt;/i&gt; (i.e. connectionism, parallel distributed processing). This new paradigm seems to satisfy those critiques having been stated in symbolic AI:• the &lt;i&gt;'In-der-Welt-Sein'&lt;/i&gt; is based on a &lt;i&gt;sensory&lt;/i&gt; input and &lt;i&gt;effective&lt;/i&gt; output.• this input/output is not symbolic but it is coded &lt;i&gt;analogously&lt;/i&gt; -- i.e. there is not used a symbolic or mathematical code; there is only percepted the &lt;i&gt;intensity&lt;/i&gt; of the stimulus.• &lt;i&gt;direct interaction with the environment&lt;/i&gt; by using a non-symbolic code.• &lt;i&gt;learning:&lt;/i&gt; there exist very powerful algorithms for learning and categorizing (inductive learning).• &lt;i&gt;independence of domain&lt;/i&gt; is obtained by learning on a subsymbolic (meaningless) level. Thus there is also the possibility for learning non-symbolic information in a process of &lt;i&gt;self-organisation.&lt;/i&gt;There is need of a system being capable of both symbolic and subsymbolic processes -- a &lt;i&gt;hybrid&lt;/i&gt; system which has to be based however on a subsymbolic and 'neural machine'.},
booktitle = {Proceedings of the 17th Conference on ACM Annual Computer Science Conference},
pages = {427},
numpages = {1},
location = {Louisville, Kentucky},
series = {CSC '89}
}

@inproceedings{10.5555/850955.854054,
author = {Xu, Ying and Helt, G. and Einstein, J. R. and Rubin, G. and Uberbacher, E. C.},
title = {Drosophila GRAIL: an intelligent system for gene recognition in Drosophila DNA sequences},
year = {1995},
isbn = {0818671165},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {An AI-based system for gene recognition in Drosophila DNA sequences was designed and implemented. The system consists of two main modules, one for coding exon recognition and one for single gene model construction. The exon recognition module finds a coding exon by recognition of its splice junctions (or translation start) and coding potential. The core of this module is a set of neural networks which evaluate an exon candidate for the possibility of being a true coding exon using the "recognized" splice junction (or translation start) and coding signals. The recognition process consists of four steps: generation of an exon candidate pool, elimination of improbable candidates using heuristic rules, candidate evaluation by trained neural networks, and candidate cluster resolution and final exon prediction. The gene model construction module takes as input the clustered exon candidates and builds a "best" possible single gene model using an efficient dynamic programming algorithm. 129 Drosophila sequences consisting of 441 coding exons including 216358 coding bases were extracted from GenBank and used to build statistical matrices and to train the neural networks. On this training set the system recognized 97% of the coding messages and predicted only 5% false messages. Among the "correctly" predicted exons, 68% match the actual exon exactly and 96% have at least one edge predicted correctly. On an independent test set consisting of 30 Drosophila sequences, the system recognized 96% of the coding messages and predicted 7% false messages.},
booktitle = {Proceedings of the First International Symposium on Intelligence in Neural and Biological Systems (INBS'95)},
pages = {128},
keywords = {statistical matrices, splice junctions, single gene model construction, sequences, pattern recognition, neural networks, neural nets, knowledge based systems, intelligent system, genetics, gene recognition, exon recognition, dynamic programming, coding exon, cluster resolution, candidate evaluation, biology computing, GenBank, Drosophila GRAIL, Drosophila DNA sequences, DNA},
series = {INBS '95}
}

@article{10.1023/B:ISFI.0000005653.53641.b3,
author = {Ragothaman, Srinivasan and Naik, Bijayananda and Ramakrishnan, Kumoli},
title = {Predicting Corporate Acquisitions: An Application of Uncertain Reasoning Using Rule Induction},
year = {2003},
issue_date = {December 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {5},
number = {4},
issn = {1387-3326},
url = {https://doi.org/10.1023/B:ISFI.0000005653.53641.b3},
doi = {10.1023/B:ISFI.0000005653.53641.b3},
abstract = {Artificial Intelligence (AI)-based rule induction techniques such as IXL and ID3 are powerful tools that can be used to classify firms as acquisition candidates or not, based on financial and other data. The purpose of this paper is to develop an expert system that employs uncertainty representation and predicts acquisition targets. We outline in this paper, the features of IXL, a machine learning technique that we use to induce rules. We also discuss how uncertainty is handled by IXL and describe the use of confidence factors. Rules generated by IXL are incorporated into a prototype expert system, ACQTARGET, which evaluates corporate acquisitions. The use of confidence factors in ACQTARGET allows investors to specifically incorporate uncertainties into the decision making process. A set of training examples comprising 65 acquired and 65 non-acquired real world firms is used to generate the rules and a separate holdout sample containing 32 acquired and 32 non-acquired real world firms is used to validate the expert system results. The performance of the expert system is also compared with a conventional discriminant analysis model and a logit model using the same data. The results show that the expert system, ACQTARGET, performs as well as the statistical models and is a useful evaluation tool to classify firms into acquisition and non-acquisition target categories. This rule induction technique can be a valuable decision aid to help financial analysts and investors in their buy/sell decisions.},
journal = {Information Systems Frontiers},
month = {dec},
pages = {401–412},
numpages = {12},
keywords = {uncertain reasoning, rule induction, mergers and acquisitions, machine learning, expert systems}
}

@article{10.1109/TSE.2021.3106280,
author = {Hoda, Rashina},
title = {Socio-Technical Grounded Theory for Software Engineering},
year = {2022},
issue_date = {Oct. 2022},
publisher = {IEEE Press},
volume = {48},
number = {10},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2021.3106280},
doi = {10.1109/TSE.2021.3106280},
abstract = {Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents &lt;italic&gt;Socio-Technical Grounded Theory&lt;/italic&gt; (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.},
journal = {IEEE Trans. Softw. Eng.},
month = {oct},
pages = {3808–3832},
numpages = {25}
}

@article{10.1016/j.ijhcs.2022.102941,
author = {Naiseh, Mohammad and Al-Thani, Dena and Jiang, Nan and Ali, Raian},
title = {How the different explanation classes impact trust calibration: The case of clinical decision support systems},
year = {2023},
issue_date = {Jan 2023},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {169},
number = {C},
issn = {1071-5819},
url = {https://doi.org/10.1016/j.ijhcs.2022.102941},
doi = {10.1016/j.ijhcs.2022.102941},
journal = {Int. J. Hum.-Comput. Stud.},
month = {jan},
numpages = {17},
keywords = {Trust Calibration, Human-AI Interaction, Clinical decision support systems, Explainable AI}
}

@article{10.1007/s10207-023-00729-4,
author = {Farhat, Saida and Abdelkader, Manel and Meddeb-Makhlouf, Amel and Zarai, Faouzi},
title = {CADS-ML/DL: efficient cloud-based multi-attack detection system},
year = {2023},
issue_date = {Dec 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1615-5262},
url = {https://doi.org/10.1007/s10207-023-00729-4},
doi = {10.1007/s10207-023-00729-4},
abstract = {With the increasing adoption of cloud computing, securing cloud-based systems and applications has become a critical concern for almost every organization. Traditional security approaches such as signature-based and rule-based have limited detection capabilities toward new and sophisticated attacks. To address this issue, there has been an increasing focus on implementing Artificial Intelligence (AI) in cloud security measures. In this research article, we present CADS-ML/DL, an efficient cloud-based multi-attack detection system. We investigate the effectiveness of Machine Learning (ML) and Deep Learning (DL) techniques for detecting cloud attacks. Our approach leverages a realistic dataset consisting of both benign and fourteen common attack network flows that meet real-world criteria on the AWS cloud platform. We evaluate eight Intrusion Detection Systems (IDSs) based on ML and DL algorithms, including Decision Tree (DT), Random Forest (RF), Extreme Gradient Boosting (XGBoost), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), Stacked LSTM, and Bidirectional LSTM (Bi-LSTM) models. Experimental results demonstrate that the CADS-ML/DL system, specifically the XGBoost model, outperforms the other models, exhibiting an accuracy of 0.9770 and a false error rate of 0.0230. Furthermore, we validate the effectiveness of our proposed XGBoost model on the AWS benchmark CSE-CICIDS2018 dataset, attaining a remarkable accuracy score of 0.9999 and an exceptionally low false error rate of 0.0001. Our findings suggest that AI-based approaches have the potential to detect cloud attacks effectively and contribute to the development of reliable and efficient IDSs for cloud security.},
journal = {Int. J. Inf. Secur.},
month = {jul},
pages = {1989–2013},
numpages = {25},
keywords = {CSE-CICIDS2018, Multi-attack detection system, Deep learning (DL), Machine learning (ML), CICFlowMeter, Cloud computing}
}

@article{10.1007/s11277-021-08403-5,
author = {Setiawan, Roy and Ganga, Ramakoteswara Rao and Velayutham, Priya and Thangavel, Kumaravel and Sharma, Dilip Kumar and Rajan, Regin and Krishnamoorthy, Sujatha and Sengan, Sudhakar},
title = {Encrypted Network Traffic Classification and Resource Allocation with Deep Learning in Software Defined Network},
year = {2021},
issue_date = {Nov 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {127},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08403-5},
doi = {10.1007/s11277-021-08403-5},
abstract = {The climate has changed absolutely in every area in just a few years as digitized, making high-speed internet service a significant need in the future. Future Internet is supposed to face exponential growth in traffic, and highly complicated infrastructure, threatening to make conventional NTC approaches unreliable and even counterproductive. In recent days, AI Stimulated state-of-the-art breakthroughs with the ability to tackle extensive and multifarious challenges, and the network community is initiated by considering the NTC prototype from legacy rule-based towards a novel AI-based. Design and execution are applied to interdisciplinary become more essential. A smart home network supports various applications and smart devices within the proposed work, including e-health devices, regular computing devices, and home automation devices. Many devices accessible through the Internet by Home GateWay for Congestion (HGC) in a smart home. Throughout this paper, a Software-Defined Network Home GateWay for Congestion (SDNHGC) architecture for improved management of remote smart home networks and protection of the significant network's SDN controller. It enables effective network capacity regulation, focused on real-time traffic analysis and core network resource allocation. It cannot control the Network in dispersed smart homes. Our innovative SDNHGC expands power across the connectivity network, a smart home network enabling improved end-to-end monitoring of networks. The planned SDNHGC directly will gain centralized device identification by classifying traffic through a smart home network. Several of the current traffic classifications approach, checking deep packets, cannot have this real-time device knowledge for encrypted data to solve this issue.},
journal = {Wirel. Pers. Commun.},
month = {mar},
pages = {749–765},
numpages = {17},
keywords = {Data flow, Deep learning, Security, Traffic detection, Software-defined network}
}

@article{10.1016/j.future.2022.12.017,
author = {Eun, Sung-Jong and Kim, Eun Joung and Kim, JungYoon},
title = {Artificial intelligence-based personalized serious game for enhancing the physical and cognitive abilities of the elderly},
year = {2023},
issue_date = {Apr 2023},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {141},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2022.12.017},
doi = {10.1016/j.future.2022.12.017},
journal = {Future Gener. Comput. Syst.},
month = {apr},
pages = {713–722},
numpages = {10},
keywords = {Relative scoring, Difficulty level adjustment, Artificial intelligence (AI), Serious game, Game design, Digital healthcare}
}

@inproceedings{10.1007/978-3-030-58796-3_30,
author = {de Filippis, Maria Laura and Federici, Stefano and Mele, Maria Laura and Borsci, Simone and Bracalenti, Marco and Gaudino, Giancarlo and Cocco, Antonello and Amendola, Massimo and Simonetti, Emilio},
title = {Preliminary Results of a Systematic Review: Quality Assessment of Conversational Agents (Chatbots) for People with Disabilities or Special Needs},
year = {2020},
isbn = {978-3-030-58795-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58796-3_30},
doi = {10.1007/978-3-030-58796-3_30},
abstract = {People with disabilities or special needs can benefit from AI-based conversational agents, which are used in competence training and well-being management. Assessment of the quality of interactions with these chatbots is key to being able to reduce dissatisfaction with them and to understand their potential long-term benefits. This will in turn help to increase adherence to their use, thereby improving the quality of life of the large population of end-users that they are able to serve. We systematically reviewed the literature on methods of assessing the perceived quality of interactions with chatbots, and identified only 15 of 192 papers on this topic that included people with disabilities or special needs in their assessments. The results also highlighted the lack of a shared theoretical framework for assessing the perceived quality of interactions with chatbots. Systematic procedures based on reliable and valid methodologies continue to be needed in this field. The current lack of reliable tools and systematic methods for assessing chatbots for people with disabilities and special needs is concerning, and may lead to unreliable systems entering the market with disruptive consequences for users. Three major conclusions can be drawn from this systematic analysis: (i) researchers should adopt consolidated and comparable methodologies to rule out risks in use; (ii) the constructs of satisfaction and acceptability are different, and should be measured separately; (iii) dedicated tools and methods for assessing the quality of interaction with chatbots should be developed and used to enable the generation of comparable evidence.},
booktitle = {Computers Helping People with Special Needs: 17th International Conference, ICCHP 2020, Lecco, Italy, September 9–11, 2020, Proceedings, Part I},
pages = {250–257},
numpages = {8},
keywords = {Quality of interaction, Usability, People with special needs, People with disability, Conversational agents, Chatbots},
location = {Lecco, Italy}
}

@inproceedings{10.1145/3526073.3527593,
author = {Rahman, Md Saidur and Khomh, Foutse and Rivera, Emilio and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Lehnert, Bernd},
title = {Challenges in machine learning application development: an industrial experience report},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527593},
doi = {10.1145/3526073.3527593},
abstract = {SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers' feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {21–28},
numpages = {8},
keywords = {software engineering for machine learning, error detection and correction, challenges and best practices},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@article{10.1016/j.compbiomed.2021.104660,
author = {Saheb, Tahereh and Saheb, Tayebeh and Carpenter, David O.},
title = {Mapping research strands of ethics of artificial intelligence in healthcare: A bibliometric and content analysis},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104660},
doi = {10.1016/j.compbiomed.2021.104660},
journal = {Comput. Biol. Med.},
month = {aug},
numpages = {19},
keywords = {Ethics, Network visualization, Content analysis, Bibliometric analysis, Robotics, Healthcare, Artificial intelligence}
}

@article{10.1145/3475870,
author = {Jiang, Yizhang and Gu, Xiaoqing and Hua, Lei and Li, Kang and Tao, Yuwen and Li, Bo},
title = {Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted TSK Fuzzy System},
year = {2021},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/3475870},
doi = {10.1145/3475870},
abstract = {Artificial intelligence– (AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ε-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {64},
numpages = {24},
keywords = {COVID-19, multi-task weighted fuzzy c-means clustering, TSK fuzzy system, multi-tasking learning, Fog/edge computing}
}

@inproceedings{10.1007/978-3-030-69781-5_8,
author = {Chandramouli, Krishna and Izquierdo, Ebroul},
title = {An Advanced Framework for Critical Infrastructure Protection Using Computer Vision Technologies},
year = {2020},
isbn = {978-3-030-69780-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-69781-5_8},
doi = {10.1007/978-3-030-69781-5_8},
abstract = {Over the past decade, there has been unprecedented advancements in the field of computer vision by adopting AI-based solutions. In particular, cutting edge computer vision technology based on deep-learning approaches has been deployed with an extraordinary degree of success. The ability to extract semantic concepts from continuous processing of video stream in real-time has led to the investigation of such solutions to enhance the operational security of critical infrastructure against intruders. Despite the success of computer vision technologies validated in a laboratory environment, there still exists several challenges that limit the deployment of these solutions in operational environment. Addressing these challenges, the paper presents a framework that integrates three main computer vision technologies namely (i) person detection; (ii) person re-identification and (iii) face recognition to enhance the operational security of critical infrastructure perimeter. The novelty of the proposed framework relies on the integration of key technical innovations that satisfies the operational requirements of critical infrastructure in using computer vision technologies. One such requirement relates to data privacy and citizen rights, following the implementation of General Data Protection Regulation across Europe for the successful adoption of video surveillance for infrastructure security. The video analytics solution proposed in the paper integrates privacy preserving technologies, high-level rule engine for threat identification and a knowledge model for escalating threat categorises to human operator. The various components of the proposed framework has been validated using commercially available graphical processing units for detecting intruders. The performance o the proposed framework has been evaluated in operational environments of the critical infrastructure. An overall accuracy of 97% is observed in generating alerts against malicious intruders.},
booktitle = {Cyber-Physical Security for Critical Infrastructures Protection: First International Workshop, CPS4CIP 2020, Guildford, UK, September 18,  2020, Revised Selected Papers},
pages = {107–122},
numpages = {16},
keywords = {Privacy preserving technologies, Knowledge model, Un-supervised clustering, Region based Fully Connected Network (RFCN), Face recognition, Intrusion detection, Person re-identification (RE-ID), Person detection},
location = {Guildford, United Kingdom}
}

@article{10.1155/2022/1703696,
author = {Faritha Banu, J. and Neelakandan, S. and Geetha, B.T and Selvalakshmi, V. and Umadevi, A. and Martinson, Eric Ofori and Sharma, Kapil},
title = {Artificial Intelligence Based Customer Churn Prediction Model for Business Markets},
year = {2022},
issue_date = {2022},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2022},
issn = {1687-5265},
url = {https://doi.org/10.1155/2022/1703696},
doi = {10.1155/2022/1703696},
abstract = {The introduction of artificial intelligence (AI) and machine learning (ML) technologies in recent years has resulted in improved company performance. Customer churn forecast is a difficult problem in many corporate sectors, particularly the telecommunications industry. Because customer churns have a direct impact on a company's total revenue, telecommunications firms have begun to develop 76 models to reduce churns at an earlier stage. Previous research has revealed that AI and ML models are effective CCP solutions. According to this viewpoint, this study proposes a unique AI-based CCP model for Telecommunication Business Markets (AICCP-TBM). The AICCP-TBM model's purpose is to control the existence of churners and non-churners in the telecom sector. The proposed AICCP-TBM model employs a Chaotic Salp Swarm Optimization-based Feature Selection (CSSO-FS) method for the best feature assortment. In addition, a Fuzzy Rule-based Classifier(FRC) is used to distinguish between client churners and non-churners. A technique known as Quantum Behaved Particle Swarm Optimization (QPSO) is used to pick the membership functions for the FRC model in order to improve the classification performance of the FRC model. The performance of the AICCP-TBM model is validated using a benchmark CCP dataset and the experimental results are reviewed from several angles. In relations of presentation, the imitation consequences demonstrated that the AICCP-TBM model surpassed the most recent state-of-the-art CPP models. The suggested AICCP-TBM method's comparative accuracy was thoroughly tested on the three datasets used. Using datasets 1-3, this technique obtained better levels of accuracy, with the maximum attainable values being 97.25 %, 97.5 % and 94.33 %. The simulation results for the AICCP-TBM model demonstrated improved prediction performance.},
journal = {Intell. Neuroscience},
month = {jan},
numpages = {14}
}

@article{10.1016/j.infsof.2023.107197,
author = {Balasubramaniam, Nagadivya and Kauppinen, Marjo and Rannisto, Antti and Hiekkanen, Kari and Kujala, Sari},
title = {Transparency and explainability of AI systems: From ethical guidelines to requirements},
year = {2023},
issue_date = {Jul 2023},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {159},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2023.107197},
doi = {10.1016/j.infsof.2023.107197},
journal = {Inf. Softw. Technol.},
month = {jul},
numpages = {15},
keywords = {AI systems, Explainability requirements, Quality requirements, Ethical guidelines, Explainability, Transparency}
}

@article{10.1155/2021/8686469,
author = {Alomari, Mohammad Kamel and Khan, Habib Ullah and Khan, Sulaiman and Al-Maadid, Alanoud Ali and Abu-Shawish, Zaki Khalid and Hammami, Helmi and Chaudhry, Shehzad Ashraf},
title = {Systematic Analysis of Artificial Intelligence-Based Platforms for Identifying Governance and Access Control},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/8686469},
doi = {10.1155/2021/8686469},
abstract = {Artificial intelligence (AI) has become omnipotent with its variety of applications and advantages. Considering the other side of the coin, the eruption of technology has created situations that need more caution about the safety and security of data and systems at all levels. Thus, to hedge against the growing threats of cybersecurity, the need for a robust AI platform supported by machine learning and other supportive technologies is well recognized by organizations. AI is a much sought-after topic, and there is extolling literature available in repositories. Hence, a systematic arrangement of the literature that can help identify the right AI platform that can provide identity governance and access control is the need of the hour. Having this background, the present study is commissioned a Systematic Literature Review (SLR) to accomplish the necessity. Literature related to AI and Identity and Access Management (IAM) is collected from renowned peer-reviewed digital libraries for systematic analysis and assessment purposes using the systematic review guidelines. Thus, the final list of articles relevant to the framed research questions related to the study topic is fetched and is reviewed thoroughly. For the proposed systematic research work, the literature reported during the period ranging from 2016 to 2021 (a portion of 2021 is included) is analyzed and a total of 43 papers were depicted more relevant to the selected research domain. These articles were accumulated from ProQuest, Scopus, Taylor &amp; Franics, Science Direct, and Wiley online repositories. The article's contribution can supplement the AI-based IAM information and steer the entities of diverse sectors concerning seamless implementation. Appropriate suggestions are proposed to encourage research work in the required fields.},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {10}
}

@phdthesis{10.5555/2019948,
author = {Zhu, Jichen},
advisor = {Harrell, D. Fox},
title = {Intentional systems and the artificial intelligence (ai) hermeneutic network: agency and intentionality in expressive computational systems},
year = {2009},
isbn = {9781124255583},
publisher = {Georgia Institute of Technology},
address = {USA},
abstract = {Human interaction with technical artifacts is often mediated by treating them as if they are alive. We exclaim "my car doesn't want to start," or "my computer loves to crash." Of increasing cultural importance are software systems designed explicitly to perform tasks and/or exhibit complex behaviors usually deemed as intentional human phenomena, including creating, improvising, and learning. Compared to the instrumental programs (e.g.,  Adobe Photoshop ), these intentional systems (e.g., George Lewis' musical system  Voyager ) seem to produce output that is "about" certain things in the world rather than the mere execution of algorithmic rules. This dissertation investigates such phenomena with two central research questions: (1) How is system intentionality formed and (2) What are the design implications for building systems that utilize such intentionality as an expressive resource. In the discourse of artificial intelligence (AI) practice, system intentionality is typically seen as a technical and ontological property of a computer program, emerging from its underlying algorithms and knowledge engineering. Distilling from the areas of hermeneutics, actor-network theory, cognitive semantics theory, and philosophy of mind, this dissertation proposes a humanistic and interpretive framework called the  AI hermeneutic network . It accentuates that system intentionality is  narrated  and  interpreted  by its human creators and users in their socio-cultural settings. Special attention is paid to system authors' discursive strategies, a constitutive component of AI, embedded in their source code and technical literature. The utility of the framework is demonstrated by a close analytical reading of a full-scale AI system,  Copycat .The theoretical discovery leads to new design strategies, namely  scale of intentionality  and  agency play . They provide insights for using system intentionality and agency as expressive resources that can be used to convey meanings and express ideas. The fruits of these insights are illustrated by a stream of consciousness literature inspired interactive narrative project  Memory, Reverie Machine,  co-developed using Harrell's  GRIOT  system. It portrays a protagonist whose intentionality and agency vary dynamically in service of narrative needs.},
note = {AAI3425059}
}

@phdthesis{10.5555/1354354,
author = {Cai, Jingfeng},
advisor = {Durkin, John},
title = {Decision tree pruning using expert knowledge},
year = {2006},
isbn = {9780549222910},
publisher = {University of Akron},
address = {USA},
abstract = {Decision tree technology has proven to be a valuable way of capturing human decision making within a computer. It has long been a popular artificial intelligence(AI) technique. During the 1980s, it was one of the primary ways for creating an AI system. During the early part of the 1990s, it somewhat fell out of favor, as did the entire AI field in general. However, during the later 1990s, with the emergence of data mining technology, the technique has resurfaced as a powerful method for creating a decision-making program. How to prune the decision tree is one of the research directions of the decision tree technique, but the idea of cost-sensitive pruning has received much less attention than other pruning techniques even though additional flexibility and increased performance can be obtained from this method. This dissertation reports on a study of cost-sensitive methods for decision tree pruning. A decision tree pruning algorithm called KBP1.0, which includes four cost-sensitive methods, is developed. The intelligent inexact classification is used for first time in KBP1.0 to prune the decision tree. Using expert knowledge in decision tree pruning is discussed for the first time. By comparing the cost-sensitive pruning methods in KBP1.0 with other traditional pruning methods, such as reduced error pruning, pessimistic error pruning, cost complexity pruning, and C4.5, on benchmark data sets, the advantage and disadvantage of cost-sensitive methods in KBP1.0 have been summarized. This research will enhance our understanding of the theory, design and implementation of decision tree pruning using expert knowledge. In the future, the cost-sensitive pruning methods can be integrated into other pruning methods, such as minimum error pruning and critical value pruning, and include new pruning methods in KBP. Using KBP to prune the decision tree and getting the rules from the pruned tree to help us build the expert system is another direction of our future work.},
note = {AAI3280767}
}

@inproceedings{10.1145/3611643.3613882,
author = {Laaber, Christoph and Yue, Tao and Ali, Shaukat and Schwitalla, Thomas and Nyg\r{a}rd, Jan},
title = {Automated Test Generation for Medical Rules Web Services: A Case Study at the Cancer Registry of Norway},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613882},
doi = {10.1145/3611643.3613882},
abstract = {The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN’s practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN’s software system. In particular, we focus on GURI, CRN’s medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster’s black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI’s code. Concerning domain-specific coverage, EvoMaster’s black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster’s black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1937–1948},
numpages = {12},
keywords = {test generation, rule engine, electronic health records, cancer registry, automated software testing, REST APIs},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {ESEC/FSE 2023}
}

@article{10.1007/s00146-022-01478-z,
author = {Ramanayake, Rajitha and Wicke, Philipp and Nallur, Vivek},
title = {Immune moral models? Pro-social rule breaking as a moral enhancement approach for ethical AI},
year = {2022},
issue_date = {Apr 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {38},
number = {2},
issn = {0951-5666},
url = {https://doi.org/10.1007/s00146-022-01478-z},
doi = {10.1007/s00146-022-01478-z},
abstract = {We are moving towards a future where Artificial Intelligence (AI) based agents make many decisions on behalf of humans. From healthcare decision-making to social media censoring, these agents face problems, and make decisions with ethical and societal implications. Ethical behaviour is a critical characteristic that we would like in a human-centric AI. A common observation in human-centric industries, like the service industry and healthcare, is that their professionals tend to break rules, if necessary, for pro-social reasons. This behaviour among humans is defined as pro-social rule breaking. To make AI agents more human-centric, we argue that there is a need for a mechanism that helps AI agents identify when to break rules set by their designers. To understand when AI agents need to break rules, we examine the conditions under which humans break rules for pro-social reasons. In this paper, we present a study that introduces a ‘vaccination strategy dilemma’ to human participants and analyzes their response. In this dilemma, one needs to decide whether they would distribute COVID-19 vaccines only to members of a high-risk group (follow the enforced rule) or, in selected cases, administer the vaccine to a few social influencers (break the rule), which might yield an overall greater benefit to society. The results of the empirical study suggest a relationship between stakeholder utilities and pro-social rule breaking (PSRB), which neither deontological nor utilitarian ethics completely explain. Finally, the paper discusses the design characteristics of an ethical agent capable of PSRB and the future research directions on PSRB in the AI realm. We hope that this will inform the design of future AI agents, and their decision-making behaviour.},
journal = {AI Soc.},
month = {may},
pages = {801–813},
numpages = {13},
keywords = {Artificial Intelligence, Pro-social behaviour, Pro-social rule breaking, Machine ethics}
}

@inproceedings{10.1007/978-3-031-20627-6_17,
author = {Guo, Long Yin and Xia, Lin and Huang, Xin Yi and Fu, Yu Xin and Li, Xin Yi and Zhou, Si Chen and Zhao, Chao and Yang, Bing Xiang},
title = {The Construction and Validation of an Automatic Crisis Balance Analysis Model},
year = {2022},
isbn = {978-3-031-20626-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20627-6_17},
doi = {10.1007/978-3-031-20627-6_17},
abstract = {Background: With the development of Internet, many people with suicide risk tend to express their thoughts on social media platforms. AI-based model can early identify social media users with suicide risk and analyze their cognitive and interpersonal characteristics. Then we can do early intervention to help them.Objective: To build an automatic crisis balance analysis model based on artificial intelligence which can perform automatic early suicide identification, suicide risk classification and analyze cognitive distortion and interpersonal relationship of users. Then to validate the predictive efficiency of model.Method: Firstly, based on the suicide knowledge graph, free annotation data set was generated and then Bert-based model was built. Secondly, the data set was refined by psychology students and experts to build fine-tuning model and Psychology+ model. The Psychology+ model was used as final suicide risk assessment model. We enriched and quantified the variables of cognitive and interpersonal characteristics and built the cognitive distortion and interpersonal relationship analysis model. Using F1 score, precision, recall and accuracy to evaluate the model performance and the consistence of model results with expert judgment and scales results to evaluate the model prediction ability.Results: For the suicide risk assessment model, the F1 score, precision, recall rate and accuracy rate of the model are 77.98%, 80.75%, 75.41% and 78.68% respectively. For the cognitive distortion and interpersonal relationship analysis model, the F1 score, accuracy and recall rate of the model are 77.26%, 78.22% and 76.33% respectively. Comparing the results with the results of the scale by chi square test, there was no significant difference in cognitive distortion(P = 0.521) and interpersonal relationship(P = 0.189) aspect.Conclusion: The model showed good performance and can be used as a guideline and evaluation tool for intervention.},
booktitle = {Health Information Science: 11th International Conference, HIS 2022, Virtual Event, October 28–30, 2022, Proceedings},
pages = {177–188},
numpages = {12},
keywords = {Model validation, Social media, Artificial intelligence, Suicide}
}

@phdthesis{10.5555/192591,
author = {Davern, James John},
title = {An architecture for job shop scheduling with genetic algorithms},
year = {1994},
publisher = {University of Central Florida},
address = {USA},
abstract = {Job Shop Scheduling (JSS) problems continue to be among the most challenging problems to solve. Perhaps the best that can be expected for these difficult NP-complete problems is that near-optimal, better-than-average solutions will be developed. Due to the repetitive and computation intensive nature of scheduling problems, the JSS problem domain is well positioned to take advantage of improved computer hardware and software as-well-as emerging Artificial Intelligence (AI) techniques. Further, a general purpose approach to JSS problems could have the potential for more widespread use than any specialized approach. However, to provide a general purpose scheduling solution approach for real-world problems, it is necessary to establish an architecture to integrate the scheduling problem domain components with the selected AI technique components. This paper offers an architecture and an implementation approach for providing optimal or near-optimal solutions to complex real-world sequencing, scheduling, and rescheduling problems. The architecture combines JSS solution components with the AI-based cognitive computing technology of Genetic Algorithms (GAs). The architecture is based on a constraint structure component, a straightforward rule-based scheduler, and a schedule evaluation component that are integrated with the stochastic process employed in the GA optimizing search component. Using this architecture as the model, a general purpose prototype application for solving JSS problems is developed and demonstrated.Example problems illustrate the architecture's flexibility in solving traditionally difficult problems involving multiple objectives and relaxed constraints. For example, Cmax (makespan) can be minimized while concurrently handling a combination of other scheduling objectives and constraints including job priorities, ready times and due dates, and sequence-dependent setup times. Problem setup for initial scheduling solutions as-well-as for the dynamic cases involving rescheduling are handled within the same architecture.},
note = {UMI Order No. GAX94-24346}
}

@inproceedings{10.1145/3292500.3332281,
author = {Gade, Krishna and Geyik, Sahin Cem and Kenthapadi, Krishnaram and Mithal, Varun and Taly, Ankur},
title = {Explainable AI in Industry},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3332281},
doi = {10.1145/3292500.3332281},
abstract = {Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling.As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks.In this tutorial, we will present an overview of model interpretability and explainability in AI, key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3203–3204},
numpages = {2},
keywords = {ml model transparency and interpretability, industry case studies, explainable ai},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@article{10.1007/s10462-023-10415-5,
author = {El-Sappagh, Shaker and Alonso-Moral, Jose M. and Abuhmed, Tamer and Ali, Farman and Bugar\'{\i}n-Diz, Alberto},
title = {Trustworthy artificial intelligence in Alzheimer’s disease: state of the art, opportunities, and challenges},
year = {2023},
issue_date = {Oct 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {10},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-023-10415-5},
doi = {10.1007/s10462-023-10415-5},
abstract = {Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017–2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer’s Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain.},
journal = {Artif. Intell. Rev.},
month = {mar},
pages = {11149–11296},
numpages = {148},
keywords = {Fairness, accountability, and transparency in AI, Responsible AI, Machine learning in medicine, AI for Alzheimer’s disease diagnosis and progression detection, Trustworthy AI}
}

@article{10.1109/64.511774,
author = {Salvaneschi, Paolo and Cadei, Mauro and Lazzari, Marco},
title = {Applying AI to Structural Safety Monitoring and Evaluation},
year = {1996},
issue_date = {August 1996},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {11},
number = {4},
issn = {0885-9000},
url = {https://doi.org/10.1109/64.511774},
doi = {10.1109/64.511774},
abstract = {Four decision-support systems: Mistral, Damsafe, Kaleidos, and Igor--provide powerful, AI-based tools for evaluating structural data. Safety managers, engineers, and authorities are using the systems to handle safety problems in structures.Civil engineers need significant resources to ensure the safety of structures. They collect data about structural behavior through tests and visual inspections, while using automatic instrumentation and data acquisition systems for real-time monitoring. Interpreting such data is not easy. Several factors are involved, such as the large amount of data; the uncertainty and incompleteness of information; and the need for engineering judgment, knowledge of the particular structure, experience with the behavior of structures in general, and general engineering knowledge to interpret the data.AI concepts and technologies can assist engineers in safety management by providing new software components to the existing information systems, such as real-time interpretation systems linked to the data acquisition units, qualitative models, and reasoning agents supporting the off-line management of information and interpretation.In this article, we describe four decision-support systems that use such concepts and technologies to better manage the safety of civil engineering structures. During the last six years, the software development unit of ISMES--an R&amp;D company involved in structural and mechanical engineering, environmental and land-use engineering, and information and communication technologies--has focused on AI applications to structural safety. We have addressed two main problems: the safety management of dams and monuments, and the seismic risk assessment of buildings. This led to the development of the four systems: Mistral, Damsafe, Kaleidos, and Igor.We exploit AI tools for designing intelligent modules of our support systems, including causal networks of processes, qualitative modeling, model-based reasoning, and hierarchical object-oriented representations. The systems also employ AI techniques such as rule-based systems, pattern matching, and neural networks, in conjunction with conventional techniques, to implement these representation and reasoning schemes.},
journal = {IEEE Expert: Intelligent Systems and Their Applications},
month = {aug},
pages = {24–34},
numpages = {11}
}

@article{10.1016/j.cageo.2022.105281,
author = {Jacinto, Marcos V.G. and Doria Neto, Adri\~{a}o D. and de Castro, David L. and Bezerra, Francisco H.R.},
title = {Karstified zone interpretation using deep learning algorithms: Convolutional neural networks applications and model interpretability with explainable AI},
year = {2023},
issue_date = {Feb 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2022.105281},
doi = {10.1016/j.cageo.2022.105281},
journal = {Comput. Geosci.},
month = {feb},
numpages = {18},
keywords = {Explainable AI, Deep learning, Karstified zones, Ground penetrating radar}
}

@proceedings{10.1145/3194085,
title = {SEFAIS '18: Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems},
year = {2018},
isbn = {9781450357395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Autonomous systems have been a subject of computer science research for many years. Recent advances in hardware and in artificial intelligence have brought autonomous systems within the reach of product development. For example, most major carmakers are working on autonomous driving.During the early years of autonomous systems research, the focus has been on making autonomous functionality possible in the first place. As we move closer to building end-user products, software engineering concerns are becoming at least equally important. Most conventional embedded software products are built on rule-based control engineering approaches. The corresponding software engineering practices are mature and well understood. For autonomous systems, however, the conventional control engineering approaches are extended by modern artificial intelligence techniques, in particular, machine learning. The corresponding product software engineering approaches are less well understood and need attention.The 2018 ACM/IEEE 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS 2018) focuses on software engineering and software architecture approaches that achieve the usual software engineering goals, such as quality, maintainability, scalability, robustness, safety, etc., for systems that are built using a combination of conventional embedded software development and AI. Since many of the relevant techniques are just about to move from the research stage to the product development stage, many of the software engineering ideas and approaches will benefit from the typical "idea/work in progress" discussions that are enabled by this workshop.We want to bring together researchers and practitioners to form a community that shares common interests in building robust autonomous systems. In particular, for the application domain of autonomous driving, our goal is to better understand the techniques necessary to verify and validate AI-based autonomous systems, ensure their robustness, safety, security, and other important system properties, in general. To this end, we have grouped three of the workshop contributions to form a special session on the verification of autonomous driving.},
location = {Gothenburg, Sweden}
}

@phdthesis{10.5555/194293,
author = {Hughes, Lucian Parke},
title = {Societal simulation: an artificial intelligence approach},
year = {1993},
publisher = {Yale University},
address = {USA},
abstract = {The physical sciences have come across complex systems for which global behaviors are difficult to model by traditional mathematical means. For example, it has been difficult to find global equations by which to model turbulence, or predict the weather. Increasingly, scientists have turned to computer-based simulations that model the local rules of behavior of individual elements of the systems. Global phenomena emerge from these local interactions. For example, for turbulence each individual air molecule is modeled and the overall turbulence pattern emerges from their simple local interactions. Clearly, social systems are at least as complex. And similarly social scientists have found it difficult to discover global equations for social systems. And while some social scientists have taken the opposite tack of writing essays--not equations!--that reveal the local complexity of social systems, these efforts fall short in precision. A computational societal simulator offers an opportunity for formal precision while still embracing the complexity of social agents and the relations and rituals that bind them.This thesis describes the construction and use of such a simulator: ChimpWorld. ChimpWorld is a general architecture for societal simulation that has been applied to a particular domain: chimpanzee societies. The individual elements of the system are independent yet socially-linked AI-based agents--in this case chimpanzees. Their socially guided actions and motivations create dynamic societies.Thus, ChimpWorld is a "wind tunnel for the social and organizational sciences": it allows different social organizations, individuals, and physical environments to be dynamically tested so that the results can be compared to real societies. Via such comparisons scientists can build, test, and refine their societal and organizational theories. Hence, this thesis is intended for social scientists interested in a new technology and what has been learned from it about social agents and societies, as well as for cognitive scientists and AI researchers interested in the nature of social minds.},
note = {UMI Order No. GAX94-15863}
}

@phdthesis{10.5555/912195,
author = {Neal, Jeannette Grace},
title = {A knowledge based approach to natural language understanding (computer science, artificial intelligence)},
year = {1985},
publisher = {State University of New York at Buffalo},
address = {USA},
abstract = {An extremely significant feature of any Natural Language (NL) is that it is its own meta-language. One can use a NL to talk about the NL itself and to give instruction in the use and understanding of the same NL. In this thesis we present a language processing expert system that we have implemented in the role of an educable cognitive agent whose domain of expertise is language understanding and whose discourse domain includes its own language knowledge. We present a representation of language processing knowledge and a core of knowledge, including a Kernel Language, which forms the knowledge base for this AI System. Since linguistic knowledge is part of its domain of discourse, the System can be instructed in the processing and understanding of ever more sophisticated language, with instruction initially given in the predefined Kernel Language. As the System's language knowledge is expanded beyond the primitive Kernel Language, instruction of the System is expressed in an increasingly sophisticated subset of the language being taught. Thus the System's language is used as a meta-language for the self-same language. Our NLU System is implemented in the form of a general purpose inference system which reasons according to the rules of its knowledge base. This knowledge base comprises the System's task domain knowledge and includes, but is not restricted to, its language processing knowledge.In this thesis we discuss two experiments that we conducted. In the first experiment, our approach was to teach the System to treat linguistic knowledge in a manner that is commonly used for general knowledge (e.g. property-value pairs) and to use its acquired natural language subset as a meta-language for the same language. In the second experiment, we taught the System to process language according to a subset of a Lexical-Functional Grammar. One of our original objectives was to design a system that was as theory-independent as possible. The purpose of this second experiment was to test, at least to some extent, whether we had achieved this objective.We also discuss the parsing and interpretation strategies of the System. Parsing is performed according to a combined bottom-up top-down strategy with a focusing context resulting from the bi-directional inference sub-system. Parsing and interpretation take place in an integrated manner in our System, governed by the language definition input to the System by a teacher-user.},
note = {AAI8518765}
}

@article{10.1016/j.artmed.2021.102163,
author = {Santra, Debarpita and Goswami, Subrata and Mandal, Jyotsna Kumar and Basu, Swapan Kumar},
title = {Low back pain expert systems: Clinical resolution through probabilistic considerations and poset},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102163},
doi = {10.1016/j.artmed.2021.102163},
journal = {Artif. Intell. Med.},
month = {oct},
numpages = {16},
keywords = {Clinical uncertainty handling, Partially ordered set, Probabilistic inference logic, Knowledge representation, Subgrouping of low back pain, Medical expert system}
}

@phdthesis{10.5555/2521771,
author = {Koch, Jeffrey W.},
advisor = {Cooper, Kendra},
title = {Aovis: reverse engineering and visualization of aspectj/java source code},
year = {2011},
isbn = {9781267165572},
publisher = {University of Texas at Dallas},
address = {USA},
abstract = {The reverse engineering of aspect-oriented projects introduces a number of challenges. Few reverse engineering frameworks are currently available that can extract program facts for AspectJ program facts, in contrast to the variety of reverse engineering tools for more mature languages such as Java. AspectJ tools have been built; however, these tools required modification of existing AspectJ compilers or used non-standard extensions that limited interoperability with other reverse engineering or analysis tools. Even when program facts have been extracted, these facts must be abstracted to models at the desired level of detail. Aspect-specific abstraction challenges include: · Automated and semi-automated architectural modeling is the subject of ongoing research; however, past work has not considered the automated or semi-automated architectural modeling of aspect-oriented systems. · Cross-cutting concerns add to the complexity of a system. Research into techniques to visually represent cross-cutting concerns in a clear fashion is still on-going. · One goal of the aspect-oriented paradigm is to separate cross-cutting concerns from base concerns. It is a challenge to visually represent aspect-oriented models in a manner than separates cross-cutting concerns from base concerns. AOVis (Aspect-Oriented Visualization) is a reverse engineering framework for AspectJ. This approach provides the following unique contributions to the field: · It provides a model-driven graph-based approach for the extraction of object-oriented and aspect-oriented program facts that uses existing AspectJ compilers and standard extensions to UML and XML, enhancing interoperability with existing AspectJ and reverse engineering technologies. · It provides a semi-automated rule-based approach for the abstraction of object-oriented and aspect-oriented program facts to the architectural level with multiple rule-based abstraction engines and AI-based pareto optimal ranking techniques. Tool support includes initial implementation in the form of an Eclipse plugin that extracts program facts, partially analyzes the program fact model in terms of the MVC architecture, and generates program fact and architecture XMI files that can be used by XMI-capable tools. This approach will be extremely useful to other researchers with a need for AspectJ program facts, including projects such as design visualization, traceability relationships, automatic test case generation, code metrics, and product line variation refactoring.},
note = {AAI3494543}
}

@inproceedings{10.1145/3534678.3542617,
author = {Kenthapadi, Krishnaram and Lakkaraju, Himabindu and Natarajan, Pradeep and Sameki, Mehrnoosh},
title = {Model Monitoring in Practice: Lessons Learned and Open Challenges},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3542617},
doi = {10.1145/3534678.3542617},
abstract = {Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges.In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4800–4801},
numpages = {2},
keywords = {responsible ai, model monitoring and model risk management, ethics in ai, case studies from industry},
location = {Washington DC, USA},
series = {KDD '22}
}

@phdthesis{10.5555/AAI28846644,
author = {Subramonyam, Hariharan and Colleen, Seifert, and Steven, Drucker, and Steve, Oney,},
advisor = {Eytan, Adar,},
title = {Designing AI Experiences: Boundary Representations, Collaborative Processes, and Data Tools},
year = {2021},
isbn = {9798471103603},
publisher = {University of Michigan},
address = {USA},
abstract = {Artificial Intelligence (AI) has transformed our everyday interactions with technology through automation, intelligence augmentation, and human-machine partnership. Nevertheless, we regularly encounter undesirable and often frustrating experiences due to AI. A fundamental challenge is that existing software practices for coordinating system and experience designs fall short when creating AI for diverse human needs, i.e., ``human-centered AI'' or HAI. ``AI-first'' development workflows allow engineers to first develop the AI components, and then user experience (UX) designers create end-user experiences around the AI's capabilities. Consequently, engineers encounter end-user blindness when making critical decisions about AI training data needs, implementation logic, behavior, and evaluation. In the conventional ``UX-first'' process, UX designers lack the needed technical understanding of AI capabilities (technological blindness) that limits their ability to shape system design from the ground up. Human-AI design guidelines have been offered to help but neither describe nor prescribe ways to bridge the gaps in needed expertise in creating HAI.  In this dissertation, I investigate collaboration approaches between designers and engineers to operationalize the vision for HAI as technology inspired by human intelligence that augments human abilities while addressing societal needs. In a series of studies combining technical HCI research with qualitative studies of AI production in practice, I contribute (1) an approach to software development that blurs rigid design-engineering boundaries, (2) a process model for co-designing AI experiences, and (3) new methods and tools to empower designers by making AI accessible to UX designers. Key findings from interviews with industry practitioners include the need for ``leaky'' abstractions shared between UX and AI designers. Because modular development and separation of concerns fail with HAI design, leaky abstractions afford collaboration across expertise boundaries and support human-centered design solutions through vertical prototyping and constant evaluation. Further, by observing how designers and engineers collaborate on HAI design in an in-lab study, I highlight the role of design `probes' with user data to establish common ground between AI system and UX design specifications, providing a critical tool for shaping HAI design. Finally, I offer two design methods and tool implementations --- Data-Assisted Affinity Diagramming and Model Informed Prototyping --- for incorporating end-user data into HAI design. HAI is necessarily a multidisciplinary endeavor, and human data (in multiple forms) is the backbone of AI systems. My dissertation contributions inform how stakeholders with differing expertise can collaboratively design AI experiences by reducing friction across expertise boundaries and maintaining agency within team roles. The data-driven methods and tools I created provide direct support for software teams to tackle the novel challenges of designing with data. Finally, this dissertation offers guidance for imagining future design tools for human-centered systems that are accessible to diverse stakeholders.},
note = {AAI28846644}
}

@phdthesis{10.5555/AAI28390929,
author = {Kaur, Navdeep},
advisor = {Sriraam, Natarajan,},
title = {Efficient Combination of Neural and Symbolic Learning for Relational Data},
year = {2020},
isbn = {9798569988662},
publisher = {The University of Texas at Dallas},
abstract = {Much has been achieved in AI but to realize its true potential, it is imperative that the AI system should be able to learn generalizable and actionable higher-level knowledge from lowest level percepts. Inspired by this goal, neuro-symbolic systems have been developed for the past four decades. These systems encompass the complementary strengths of fast adaptive learning of neural networks from low-level input signals and the deliberative, generalizable models of the symbolic systems. The advent of deep networks has accelerated the development of these neuro-symbolic systems. While successful, there are several open problems to be addressed in these systems, a few of which we tackle in this dissertation. These include: (i) several primitive neural network architectures have not been well studied in the symbolic context; (ii) lack of generic neuro-symbolic architectures that are do not make distributional assumptions; (iii) generalization abilities of many such systems are limited. The objective of this dissertation is to develop novel neuro-symbolic models that (i) induce symbolic reasoning capabilities to fundamental yet unexplored neural network architectures, and (ii) provide unique solutions to the generalization issues that occur during neuro-symbolic integration.More specifically, we consider one of the primitive models, Restricted Boltzmann Machines, that was originally employed for pre-training the deep neural networks and propose two unique solutions to lift them for relational model. For the first solution, we employ relational random walks to generate relational features for Boltzmann machines. We train the Boltzmann machines by passing these resulting features through a novel transformation layer. For the second solution, we employ the mechanism of functional gradient boosting to learn the structure and the parameters of the lifted Restricted Boltzmann Machines simultaneously. Next, most of the neuro-symbolic models designed till date have focused on incorporating neural capabilities in specific models, resulting in lack of a general relational neural network architecture. To overcome this, we develop a generic neuro-symbolic architecture that exploits the concept of relational parameter tying and combining rules to incorporate the first-order logic rules into the hidden layers of the proposed architecture. One of the prevalent neuro-symbolic models called knowledge graph embedding models encode the symbols as learnable vectors in Euclidean space and lose an important characteristic of generalizability to newer symbols while doing so. We propose two unique solutions to circumvent this problem by exploiting the text description of entities in addition to the knowledge graph triples in both the models. In our first model, we train both the text and knowledge graph data in generative setting, while in the second model, we posit the two data sources in adversarial setting. Our broad results across these several directions demonstrate the efficacy and efficiency of the proposed approaches on benchmarks and novel data sets.In summary, this dissertation takes one of the first steps towards realizing the grand vision of the neuro-symbolic integration by proposing novel models that allow for symbolic reasoning capabilities inside neural networks.},
note = {AAI28390929}
}

@phdthesis{10.5555/AAI30346245,
author = {Olsson, Henrik},
advisor = {Martin, Eklund, and Anna, Lantz, and Mark, Clements,},
title = {Personalized Prostate Cancer Management : Ai-Assisted Prostate Pathology and Improved Active Surveillance},
year = {2023},
isbn = {9798374490367},
publisher = {Karolinska Institutet (Sweden)},
abstract = {Prostate cancer is a major global health concern and is the most common cancer-related causeof death in Sweden. Prostate cancer screening using PSA has been shown to reduce prostatecancer mortality but also leads to significant overdiagnosis and overtreatment of low-risk cancers.Improved risk stratification and effective active surveillance are crucial to balancing thebenefits of screening with the risk of overdiagnosis and overtreatment.In Study I, we studied the uptake and the follow-up of active surveillance using a retrospectivecohort of patients who were diagnosed with low-risk prostate cancer between 2008 and 2017in Stockholm County. Our results showed that only 50% of eligible active surveillance patientsreceived active surveillance as their primary treatment choice at diagnosis. Most men thatenrolled in active surveillance remained on surveillance during the first years after diagnosis(82% during a median 3.5 years), but did not receive a follow up according to guidelines withregard to repeat biopsies and PSA tests.Current clinical practice has seen an increase in the use of magnetic resonance imaging (MRI)and the incorporation of risk prediction models to select men with the highest suspicion of clinicallysignificant prostate cancer for prostate biopsy. However, the effectiveness and how MRIand risk prediction models should be incorporated into active surveillance follow-up have yet tobe established. Study II evaluated the performance of MRI-targeted biopsies and a blood-basedrisk prediction model (the Stockholm3 test) for monitoring disease progression in patients onactive surveillance and compared this to the conventional follow-up using PSA and systematicbiopsies. When MRI-targeted and systematic biopsies were combined, the detection rateof clinically significant prostate cancer increased when compared to conventional systematicbiopsies. Biopsies performed in MRI-positive men resulted in a 49% reduction in performedbiopsies, at the expense of failing to diagnose 1.4% clinically significant prostate cancer in MRInegativemen. The incorporation of the Stockholm3 test showed a 27% reduction in requiredMRI investigations and a 57% reduction in performed biopsies compared to performing onlysystematic biopsies.In Study III, we digitized biopsy cores from STHLM3 participants to develop an artificialintelligence (AI) for prostate cancer diagnostics. The AI system demonstrated clinically usefulperformance that was comparable to that of the study pathologist for cancer detection (AUCof 0.986) and for predictions of cancer length (correlation of 0.87) and grading performancethat was on par with that of expert prostate pathologists.In Study IV, we developed a conformal predictor to estimate the uncertainty of the predictionsfor the model in Study III. The uncertainty estimates were used to control the error rate so thatonly predictions with high confidence are accepted and unreliable predictions can be detected.The conformal predictor was able to identify unreliable predictions as a result of variations indigital pathology scanners, preparation of tissue in different pathology laboratories, and theexistence of unusual prostate tissue that the AI model was not exposed to during training.Little is known about the relationships between prostate cancer genetic risk factors and themorphology of prostate tissue. In Study V:, we investigated whether weakly supervised deeplearning can learn to detect such possible associations. The findings in this paper imply relationshipsbetween prostatic tissue morphology and genetic risk factors for prostate cancer,particularly in young men. These results provide proof of principle for exploring the use ofmorphological information in multi-modal prostate cancer risk prediction algorithms.In conclusion, the purpose of this thesis was to describe possible extensions to improve prostatecancer active surveillance management, as well as to develop prediction models for improvedprostate cancer diagnostics.},
note = {AAI30346245}
}

@phdthesis{10.5555/AAI28930568,
author = {Chimatapu, Ravikiran},
title = {An Explainable Artificial Intelligence Approach Based on Deep Type-2 Fuzzy Logic System},
year = {2021},
publisher = {University of Essex (United Kingdom)},
abstract = {Artificial intelligence (AI) systems have benefitted from the easy availability of computing power and the rapid increase in the quantity and quality of data which has led to the widespread adoption of AI techniques across a wide variety of fields. However, the use of complex (or Black box) AI systems such as Deep Neural Networks, support vector machines, etc., could lead to a lack of transparency. This lack of transparency is not specific to deep learning or complex AI algorithms; other interpretable AI algorithms such as kernel machines, logistic regressions, decision trees, or rules-based algorithms can also become difficult to interpret for high dimensional inputs. The lack of transparency or explainability reduces the effectiveness of AI models in regulated applications (such as medical, financial, etc.), where it is essential to explain the model operation and how it arrived at a given prediction. The need for explainability in AI has led to a new line of research that focuses on developing Explainable AI techniques. There are three main avenues of research that are being explored to achieve explainability; first, Deep Explanations, which involves the modification of existing Deep learning models to add explainability. The methods proposed to do Deep explanations generally provide details about all the input features that affect the output, generally in a visual format as there might be a large number of features. This type of explanation is useful for tasks such as image recognition, but in other tasks, it might be hard to distinguish the most important features. Second, Model induction, which involves methods that are model agnostic, but these methods might not be suitable for use in regulated applications. The third method is to use existing interpretable models such as decision trees, fuzzy logic, etc., but the problem with them is that they can also become opaque for high dimensional data. Hence, this thesis presents a novel AI system by combining the predictive power of Deep Learning with the interpretability of Interval Type-2 Fuzzy Logic Systems. The advantages of such a system are, first, the ability to be trained via labelled and unlabelled data (i.e., mixing supervised and unsupervised learning). Second, having embedded feature selection abilities (i.e., can be trained by hundreds and thousands of inputs with no need for feature selection) while delivering explainable models with small rules bases composed of short rules to maximize the model's interpretability. The proposed model was developed with data from British Telecom (BT). It achieved comparable performance to the deep models such as Stacked Autoencoder (SAE) and Convolution Neural Networks (CNN). In categorical datasets, the model outperformed the SAE by 2%, performed within 2-3% of the CNN and outperformed Multi-Layer Perceptron (MLP) and IT2FLS by 4%. In the regression datasets, the model performed slightly worse than the SAE, MLP and CNN models, but it outperformed the IT2FLS with a 15% lower error. The proposed model achieved excellent interpretability in a survey where it was rated within 2% of the highly interpretable IT2FLS. It was also rated 20% and 17% better than Deep learning XAI tools LIME and SHAP, respectively. The proposed model shows a small loss in performance for significantly higher interpretability, making it a suitable replacement for the other AI models in applications with many features where interpretability is paramount.},
note = {AAI28930568}
}

@phdthesis{10.5555/925522,
author = {Mantawy, Abdel-Aal Hassan Ismail},
title = {Unit commitment by artificial intelligence techniques},
year = {1997},
isbn = {0591492687},
publisher = {King Fahd University of Petroleum and Minerals (Saudi Arabia)},
abstract = {The present work deals with thermal generation scheduling, which could be considered the major part of the overall scheduling problem of hydrothermal power systems. The scheduling problem of thermal generating units can be considered as two linked optimization problems. It comprises the solution of both the Unit Commitment Problem (UCP) and the Economic Dispatch Problem (EDP). The former is a combinatorial optimization problem with very hard constraints, while the later is a nonlinear programming problem. The growing interest in the application of Artificial Intelligence (AI) techniques to power system engineering has introduced the potentials of using this state-of-the-art technology in the thermal generation scheduling of electric power systems. AI techniques, unlike strict mathematical methods, have the apparent ability to adapt to nonlinearities and discontinuities commonly found in power systems. The best known algorithms in this class include evolution programming, genetic algorithms, simulated annealing, tabu search, and neural networks.In the present work, seven different AI-based algorithms have been developed to solve the UCP. Two of these algorithms namely, simulated annealing and genetic algorithms, are implemented in a novel way. The other five proposed algorithms are applied for the first time to solve the UCP. The algorithms are a Simple Tabu Search Algorithm (STSA), an Advanced Tabu Search (ATSA), a hybrid of Simulated annealing and Tabu search algorithms (ST), a hybrid of Genetic and Tabu search algorithms (GT), and a hybrid of Genetic, Simulated annealing, and Tabu search algorithms (GST).As a first step to solve the UCP, some modifications to the existing problem formulation have been made to render the formulation more generalized. An augmented model including all the problem constraints is presented.A major step in the course of solving the UCP, is the solution of the EDP. In this regard, an efficient and fast nonlinear programming routine is implemented and tested. The implemented routine is based on a linear complementary algorithm for solving the quadratic programming problems as a linear program in a tableau form. Comparing the results of our proposed routine, it is found that the results obtained are more accurate than that obtained using an IMSL quadratic programming routine. The application of this routine to the EDP is original.The corner stone in solving the combinatorial optimization problems is to come up with good rules for finding randomly feasible trial solutions from an existing feasible solution, in an efficient way. Because of the constraints in the UCP this is not a simple matter. The most difficult constraints to satisfy are at the minimum up/down times. A major contribution of this work is the implementation of new rules to get randomly feasible solutions faster.All the proposed algorithms have been tested on several practical systems reported in the literature, with different complexities. The numerical results obtained by the proposed algorithms are superior to the results reported in the literature.},
note = {AAI9738990}
}

@phdthesis{10.5555/AAI30395221,
author = {Hosseinzadehtaher, Mohsen and Danilo, Erricolo, and Line, He, and Sabri, Cetin, and Frede, Blaabjerg,},
advisor = {Mohammad, Shadmand,},
title = {Resilient Operation of Active Distribution Networks via Self-Learning Smart Devices},
year = {2022},
isbn = {9798374420418},
publisher = {University of Illinois at Chicago},
address = {USA},
abstract = {This dissertation focuses on developing Artificial Intelligence (AI)-based and self-healing control techniques to enhance the resiliency of active distribution networks for upcoming power grid challenges. In the first stage of this work, a high bandwidth primary control layer is developed to achieve an ultra-fast predictive controlled dual active bridge converter interfaced grid-following inverter for voltage and frequency support. The primary control layer is developed by a novel model predictive self-healing control (MPSC) scheme. This control technique heals intrinsic drawbacks in commonly used control approaches by decreasing the potential errors in the control processes. However, the frequency restoration process needs more advanced techniques due to the high nonlinearity of the active distribution networks such as power electronic dominated grids (PEDG). Therefore, an artificial intelligence-based power reference correction (AI-PRC) mechanism is developed to address the shortcomings of frequency restoration of the state-of-the-art virtual synchronous generator (VSG)-based or droop-based grid following inverters (GFLIs) and grid forming inverters (GFMIs) via re-defining GFLI role at grid-edge. A detailed analytical validation is provided that shows control rules in PEDG intrinsically follow the underlying dynamic of the swing-based machines to extend its stability boundary. Considering this fact, comprehensive transient and steady state-based mathematical models are used for constructing the learning database of the proposed AI-PRC mechanism. Subsequently, a neural network is trained by Bayesian Regularization Algorithm (BRA) to realize the proposed AI-PRC for GFLIs. The proposed training approach can deal with all grid characteristics alterations and uncertainties. Thus, this approach incorporates all PEDG's effective variables that shape its dynamic response during transient disturbances. Several simulations and experimental case studies were provided that evaluate the functionality of the proposed AI-PRC for GFLIs towards enhancing transient response and resiliency of PEDG. The provided evaluations demonstrate significant improvement in frequency restoration in response to transient disturbances.Moreover, the proposed control technique is exploited as a shadow controller in the case that the attacker aims to threaten the entire grid stability via stealthy attacks. Some stealthy attack scenarios are investigated on the 14-bus PEDG, and the results have proven the effectiveness of the proposed approach in fast supporting of the grid in the event of stealthy attacks, thus the grid resiliency is enhanced in this case as well.Due to the high importance of power grid resiliency, in the final stage of this work, an intrusion detection system (IDS) is developed to provide another layer of security that monitors grid dynamics and vital variables in other time scales. The groundwork of this technique is based on a load forecasting procedure that benefits from an artificial intelligence approach. In more details, an anomaly detection technique based on a condition monitoring vector and ultra-short demand forecasting is designed and developed for achieving the above-mentioned goals. The designed IDS is more robust against attack scenarios that could bypass other primary control layers. Thus, the proposed approach enables grid operators to take proper and prompt actions for providing a secure operation of the grid.},
note = {AAI30395221}
}

@phdthesis{10.5555/AAI29997492,
author = {Suh, Youngjoon and Aparna, Chandramowlishwaran, and Ramin, Bostanabad,},
advisor = {Yoonjin, Won,},
title = {Bridging the Gap: Vision-Inspired Two-Phase Heat Transfer Analysis},
year = {2022},
isbn = {9798368432908},
publisher = {University of California, Irvine},
abstract = {Liquid-vapor phase-change phenomena have been critical to maintaining sustainable and habitable environments on Earth for countless millennia, and are continuing to play central roles in present-day's industries with ever growing presence. Among different types of phase-change processes, boiling and condensation are two of the most widely used in both domestic and industrial applications. Central to the mechanistic understanding of the thermofluidic processes governing the phase-change phenomena is the rapid and high-fidelity extraction of interpretable physical descriptors from the highly-transient nucleation behaviors. However, extracting quantifiable measures out of dynamic objects with conventional imaging technologies poses a challenge to researchers. This thesis focuses on addressing the fundamentally weak connection between phase-change heat and mass transfer and nucleation statistics available in visual data streams. We outline core ideas of current artificial intelligence (AI) technologies connected to thermal energy science to illustrate how they can be used to push the limit of our knowledge boundaries about boiling and condensation physics. The comprehensive review offers insight into the role of recent advances in AI and computer vision in advancing modern boiling and condensation research. Based on foundational literature analysis and problem definition, the remainder of the thesis proposes various AI-based solutions for connecting visual data streams with heat and mass transfer performances at the device and system level. First, we introduce a data-driven learning framework that correlates high-quality imaging on dynamic bubbles with associated boiling curves. The framework leverages cutting-edge machine learning models including convolutional neural networks and object detection algorithms to automatically extract both hierarchical and physics-based features. By training on these features, our model learns physical boiling laws that statistically describe the manner in which bubbles nucleate, coalesce, and depart under boiling conditions, enabling in situ boiling curve prediction with a mean error of 6%. Our framework offers an automated, learning-based, alternative to conventional boiling heat transfer metrology. Next, we demonstrate an intelligent vision-based framework called Vision Inspired Online Nuclei Tracker (VISION-iT), which unites classical thermofluidic imaging techniques with deep learning to fundamentally address the challenge of extracting high-fidelity interpretable physical descriptors for the highly-transient two-phase processes. We introduce and discuss the detailed construction, algorithms, and optimization guidelines of individual modules so that the framework can easily be adjusted to custom datasets. The concepts and procedures that we propose is transferable, and thus can benefit a broader audience dealing with similar problems. Finally, VISION-iT is deployed in practical phase-change heat transfer analysis applications. For boiling applications, the combined efforts of materials design, deep learning techniques, and data-driven approach shed light on the mechanistic relationship between vapor/liquid pathways, bubble statistics, and phase change performance. For condensation applications, the data-centric analysis enabled by VISION-iT conclusively shows that contrary to classical understanding, the overall condensation performance is governed by a key trade-off between heat transfer rate per individual droplet and droplet population density. Our vision-based approach presents a powerful tool for the study of not only phase-change processes but also any nucleation-based process within and beyond the thermal science community through the harnessing of big data.},
note = {AAI29997492}
}

@inproceedings{10.1145/322917.323038,
author = {Smith, Jerry D.},
title = {Implementing knowledge bases on secondary storage (abstract only)},
year = {1987},
isbn = {0897912187},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/322917.323038},
doi = {10.1145/322917.323038},
abstract = {In the past, many knowledge representation (KR) schemes in artificial intelligence (AI) research have assumed a primary storage-resident knowledge base. This approach to knowledge base implementation is becoming less feasible with current demands and expectations for AI-based software, in particular, large knowledge systems. The incorporation of secondary storage-resident knowledge bases into knowledge systems requires considerable rethinking with respect to knowledge structures and knowledge system design. It is the premise of this paper that there are many potential applications for knowledge systems that are based on a tightly-coupled system design, in which traditional AI KR schemes are modified to incorporate file processing techniques, e.g., hashing and signatures.Researchers in both AI and the database field are currently experimenting with a variety of approaches to “merging” AI and database technology. Essentially, there are four approaches:
develop a simple interface between an AI development system, such as PROLOG, and a database system, such as INGRES, i.e., a loose-coupling;extend a database system to accommodate AI tasks, e.g., add inferencing capabilities;extend an AI development system by adding database capabilities; anddevelop a tightly-coupled system with its own AI and database capabilities.Although these four approaches to incorporating secondary storage residency into knowledge systems are very important ones, there is also much potential for incorporating specialized, file processing techniques, i.e., developing systems for applications that do not demand full database-level capabilities—a simplified approach to (4) above. For example, there may be applications that demand large knowledge bases, and therefore require the efficient use of secondary storage, but that do not require concurrent access, recovery capabilities, and so on. In these cases, we believe that knowledge systems with specialized input/output processing, tailored to a particular KR scheme, will be completely adequate and self-contained, and possibly more efficient and cost-effective. Knowledge bases implemented in primary storage on computers with large virtual storage capabilities cannot substitute for the above.There are many issues to be addressed in designing a knowledge system with secondary storage processing, based on either file or database processing techniques. One important issue concerns the lack of (traditional) primary keys during inferencing and query resolution [1]. We are currently investigating partitioning schemes with hashed partitions, where each partition contains “homogeneous” facts and/or rules and uses traditional AI KR schemes, e.g., frame-like knowledge structures, such as PROLOG structures, and tuples in PROLOG relations.Another related issue is partition size, i.e., knowledge-partition resolution and granularity. Partition size can be determined by several criteria, including available primary storage, “natural” partition size of “like” knowledge, traditional bucket size criteria for file processing, and inferencing techniques.Furthermore, the implementation language has a bearing on some of these issues. For example, with PROLOG there must be an explicit accommodation of the default backtracking technique, whereas with LISP the programmer is free to tailor the backtracking algorithm to the knowledge structures from the outset. As another example, consider the default indexing techniques used with PROLOG. Some PROLOG implementations index on the first component of a relation only [2]. Additional code must be introduced to supplement and properly override such defaults.By tightly coupling traditional KR schemes with partitioning, indexing, and hashing schemes it will be possible to develop an efficient knowledge system capable of managing a large knowledge base.},
booktitle = {Proceedings of the 15th Annual Conference on Computer Science},
pages = {377},
location = {St. Louis, Missouri, USA},
series = {CSC '87}
}

@phdthesis{10.5555/1354516,
author = {El-Chabib, Hassan H.},
title = {Modelling properties of special concretes using artifical intelligence},
year = {2006},
isbn = {9780494306970},
publisher = {University of Western Ontario},
address = {CAN},
abstract = {The engineering properties of special concretes depend on the effect of and interaction between complex parameters such as the non-homogeneous nature and inherently different properties of their components, and the dual and/or contradictory effects of several ingredients on the overall performance. Current practice resorts to costly and time-consuming laboratory testing on numerous trial mixtures to investigate such properties. Furthermore, current semi-empirical and regression analysis tools used to predict these properties have fundamental limitations, are based on many simplifying assumptions, and thus are not reliable. Meanwhile, artificial intelligence (AI) methods have recently emerged as powerful techniques for modeling and predicting the behaviour of materials. However, their applications in concrete technology are still at the embryonic stage. Hence, the goal of this work is to lay the ground for more mature applications of AI in concrete materials and structures. This is achieved in this study through selected applications that have proven to be challenging using traditional modeling techniques. The first application focussed on modeling the segregation phenomenon of flowable concrete, which remains to be the least understood of its properties. Data on the ability of flowable concrete mixtures to resist segregation of coarse aggregate particles are practically nonexistent partly due to lack of simple and reliable test methods to measure such a property. In this study, a simple, yet reliable test method for quantitatively evaluating the segregation resistance of flowable concrete mixtures was developed. The test was used to generate a comprehensive database on the segregation of flowable concrete mixtures. A total of 123 self-consolidating concrete mixtures were prepared and tested for segregation resistance, slump flow, slump  T 50(cm)  , and compressive strength. In addition, properties of 175 underwater flowable concrete mixtures were carefully selected from a larger database collected from published research. The database thus generated was used to train artificial neural networks (ANN) models to predict engineering properties of flowable concrete. The ANN models thus developed showed excellent performance not only in predicting the properties of flowable concrete, but also in predicting the effect of basic mixture ingredients on such properties. The second major application focussed on modeling the shear strength of slender concrete beams. Shear strength results for 656 normal and high-strength concrete slender beams (with and without stirrups) were collected from published research. The database was used to train ANN models to study the shear behaviour of normal and high-strength concrete (HSC) slender beams and to investigate the shear capacity contributed by each of the basic shear transfer mechanisms. Results showed that current shear design provisions overestimate the effect of compressive strength of concrete on the shear capacity of HSC beams and that simply adding the shear capacity of stirrups to that of concrete beams without shear reinforcement will significantly underestimate the shear strength of such beams. The ANN models allowed a more advanced understanding of the effect of basic shear design parameters on shear strength.Moreover, the ability of current shear design guidelines to calculate the shear capacity of FRP-reinforced concrete beams was investigated in this study. Analysis of shear strength experimental results for 150 FRP-reinforced concrete beams along with ANN predictions showed that current shear design guidelines for FRP-reinforced concrete members significantly underestimate the shear capacity of beams without shear reinforcement and overestimate the shear capacity of FRP stirrups. The genetic algorithms approach was used to develop and optimize new shear design equations for FRP-reinforced beams. It was shown that the effect of the axial rigidity of FRPlongitudinal reinforcement and FRP stirrups on the shear strength can be best represented by a cubic root and square root functions rather than linear or square root relationships as proposed by current guidelines, respectively, which provided a more accurate design equations compared to other existing methods.The main contribution of this study is that it demonstrates that artificial intelligence techniques can be mobilized to predict the engineering properties of special concretes with accuracy that cannot be matched by existing semi-empirical and regression analysis-based techniques. Furthermore, there are substantial research data on various aspects of concrete materials and structures, but such data remains scattered and not fully exploited. This study demonstrates that databases carefully generated from such existing data can be exploited to develop design equations that outperform current design code provisions by far in terms of accuracy and sensitivity to the effect of the basic design parameters involved. This work can initiate future effort in developing commercial AI-based tools to assist engineers and contractors in the formulation of special concretes and the prediction of their engineering properties.  Keywords . Flowable, high strength, fibre reinforced polymer, artificial neural networks, genetic algorithms, modeling, behaviour, shear, mechanisms.},
note = {AAINR30697}
}

@inproceedings{10.5555/1565362.1565363,
title = {Front Matter},
year = {2006},
isbn = {1586036750},
publisher = {IOS Press},
address = {NLD},
abstract = {BackgroundWith the ever increasing complexity of products and customer demands, companies are adopting new strategies to meet the changing technological requirements, shorter product life cycles, and globalization of manufacturing operations. Product design requires more sophisticated procedures and processes and requires designers and engineers possessing different expertise, knowledge and experience to work together. To address these challenges, techniques based on artificial intelligence (AI) are increasingly being used to improve effectiveness and efficiency in the product-design life cycle. Intelligent systems can be beneficially applied to many aspects of design and also design-related tasks at different stages; for example, identifying customer demands and requirements, design and planning, production, delivery, marketing and customer services, etc. Individual intelligent paradigms (such as fuzzy logic, neural network, genetic algorithm, case-based reasoning, and especially expert systems) have been applied to specific stages of the design process (product planning, conceptual design, detailed design). However, increasingly, hybrid solutions that integrate multiple individual intelligent techniques are required to solve complex design problems. The integrated intelligent environment can provide various types of information and knowledge for supporting rapid and intelligent decision-making throughout the entire design process. This is in line with the evolutionary trends of the product design process, from the traditional CAD systems into the knowledge-based engineering and integrated intelligent design systems through a combination of concurrent engineering, collaborative engineering and integrated intelligent techniques.In recent years, with the advancement of artificial intelligence and information science and technology, there has been a resurgence of work in combining individual intelligent paradigms (knowledge-based systems, fuzzy logic, neural networks, genetic algorithms, case-based reasoning, machine learning and knowledge discovery, data mining algorithms, intelligent agents, soft computing, user intelligent interfaces, etc.) into integrated intelligent systems to solve complex problems. Hybridization of different intelligent systems is an innovative approach to constructing computationally intelligent systems consisting of artificial neural networks, fuzzy inference systems, approximate reasoning and derivative-free optimization methods such as evolutionary computation and so on. The integration of different learning and adaptation techniques, to overcome individual limitations and achieve synergetic effects through hybridization or fusion of these techniques, has contributed to a large number of new intelligent system designs. Hybrid intelligent systems are becoming a very important problem-solving methodology affecting researchers and practitioners in areas ranging from science, technology, business and commerce. Integrated intelligent systems are gaining better acceptance in engineering design. The driving force behind this is that integrated intelligence and distributed 3C (collaboration, cooperation, and coordination) allows the capture of human knowledge and the application of it so as to achieve high-quality designs/products. Further motivation arises from steady advances in individual and hybrid intelligent-systems techniques, and the widespread availability of computing resources and communications capability through intranets and the web.There is a need for an edited collection of articles to reflect emerging integrated intelligent technologies and their applications in engineering design. The great breadth and expanding significance of AI and integrated intelligent systems (IIS) fields on the international scene requires a major reference work for an adequately substantive treatment of the subject. It is intended that this work will fulfill this need.The Objective of the BookThis book aims to describe recent findings and emerging techniques that use intelligent systems (particularly integrated and hybrid paradigms) in engineering design, and examples of applications. The goal is to take a snapshot of progress relating to research into systems for supporting design and to disseminate the way in which recent developments in integrated, knowledge-intensive, and computational AI techniques can improve and enhance such support. The selected articles provide an integrated, holistic perspective on this complex set of challenges and provide rigorous research results. The focus of this book is on the integrated intelligent methodologies, frameworks and systems for supporting engineering design activities. The subject pushes the boundaries of the traditional topic of engineering design into new areas.The Target Audience of the BookWe intend this book to be of interest to researchers, graduate students and practicing engineers involved in engineering design and applications using integrated intelligent techniques. In addition, managers and others can use it to obtain an overview of the subject, and gain a view about the applicability of this technology to their business. As AI and intelligent systems technologies are fast evolving, we certainly hope that this book can serve as a useful insight to the readers on the state-of-the-art applications and developments of such techniques at the time of compilation.The Organization of the BookThe chapters provide an integrated, holistic perspective on the complex set of challenges, combined with practical experiences of leading experts in industry. Some of the chapters provide rigorous research results, while others are in-depth reports from the field. All chapters have been rigorously reviewed and carefully edited. There is a logical flow through this book, starting with intelligence foundations, emerging intelligent techniques, frameworks, systems and tools then continuing integrated and hybrid intelligent systems followed by their applications for engineering design. The treatment of the subject in the book can be described as:1) Examines emerging technologies and recent research results on AI and integrated intelligent systems (IIS) in engineering design, including integrated intelligent systems, soft computing, distributed artificial intelligence (DAI), computer-integrated information systems (CIIS), etc.2) Introduces new knowledge-intensive problem-solving strategies and their implementations based on AI and integrated intelligent systems techniques.3) Presents theoretical fundamental principles and implementation technologies as well as engineering design applications and case studies, including, for example, electro-mechanical assemblies and systems, process control system, embedded and mechatronic systems design.This book consists of 20 chapters organized into three thematic sections. An overview of each section and a brief description of the component chapters are presented here.Part I: Intelligence Foundations for Engineering Design. This section, consisting of Chapters 1 to 5, provides the theoretical foundations of specific AI and IIS-based technologies for engineering design, including the principles of directed mutations for evolutionary algorithms, fuzzy logic and many valued logic, swarm intelligence, constraint satisfaction problem, fuzzy set and logic, fuzzy linear programming, Bayesian model, decision tree, uncertainty, etc.Chapter 1, by Stefan Berlik and Bernd Reusch, introduces directed mutation as well as different operators in one single place. Their characteristics such as a multivariate skew distribution as a mutation operator in a covariance matrix adaptation algorithm are presented. An application scenario and experimental results solving a real world optimization task in this scenario are presented to show how evolutionary algorithms and directed mutation can be applied in engineering design.Chapter 2, by Kalle Saastamoinen, studies the properties and usability of basic many valued-structures known as t-norms, t-conorms, implications and equivalences in comparison tasks. It shows how these measures can be aggregated with generalized mean and what kind of measures for comparison can be achieved from this procedure.Chapter 3, by Arun Khosla, Shakti Kumar, K. Aggarwal, and Jagatpreet Singh, reports a swarm intelligence (SI) technique, Particle Swarm Optimization (PSO), which is a robust stochastic evolutionary computation engine. This is emerging as an innovative and powerful computational metaphor for solving complex problems in design, optimization, control, management, business and finance. The focus of this chapter is to present the use of the PSO algorithm for building optimal fuzzy models from the available data in design of the rapid Nickel-Cadmium (Ni-Cd) battery charger.Chapter 4, by Arijit Bhattacharya and Pandian Vasant, outlines an intelligent fuzzy linear programming (FLP) method that uses a flexible logistic membership function (MF) to determine fuzziness patterns at disparate level of satisfaction for theory of constraints (TOC) based product-mix design problems. The fuzzy-sensitivity of the decision has been focused for a bottle-neck-free, optimal product-mix solution of TOC problem.Chapter 5, by Vitaly Schetinin, Jonathan Fieldsend, Derek Partridge, Wojtek, Krzanowski, Richard Everson, Trevor Bailey, and Adolfo Hernandez, proposes a new approach to decision trees (DTs) for the Bayesian Markov Chain Monte Carlo technique to estimate uncertainty of decisions in safety-critical engineering applications. It also proposes a new procedure of selecting a single DT and describes an application scenario.Part II: Techniques, Frameworks, Tools and Standards. This section, containing Chapters 6 to 11, explores techniques, models and frameworks, both current and emerging, and potential architectures for intelligent integrated engineering design.Chapter 6, by Xiang Li, Junhong Zhou, and WenFeng Lu, presents a set of customer requirement discovery methodologies to achieve broad and complex market studies for new products. The proposed approach uses data mining and text mining technologies to discover customer multi-preference and corresponding customer motivation. A prototype system that allows for on-line customer feedback collection, digitization of the language feedbacks, numerical descriptions of customer preferences and customer motivation of a product is developed to demonstrate the feasibility of the proposed methodologies. It is shown that the proposed work could significantly shorten the survey and analysis time for customer preference and is thus expected to help companies to reduce design cycle time for new product design.Chapter 7, by Paulo Gomes, Nuno Seco, Francisco Pereira, Paulo Paiva, Paulo Carreiro, Jos\'{e} Ferreira and Carlos Bento, introduces an approach to reusing the knowledge gathered in the design phase of software development. An intelligent CASE tool using case-based reasoning (CBR) techniques and WordNet is developed to support software design and provide a framework for storage and reuse of design knowledge. This Chapter presents the approach to exploiting a knowledge base and several reasoning mechanisms that reuse the stored knowledge.Chapter 8, by W.D. Li, S.K. Ong, A.Y.C., Nee, L. Ding, and C.A. Mcmahon, proposes and develops three intelligent optimization methods, i.e., Genetic Algorithm (GA), Simulated Annealing (SA) and Tabu Search (TS). These are applied to the solution of intractable decision-making issues in process planning with complex machining constraints. These algorithms can determine the optimal or near-optimal allocation of machining resources and sequence of machining operations for a process plan simultaneously, and a fuzzy logic-based Analytical Hierarchical Process technique is applied to evaluate the satisfaction degree of the machining constraints for the process plan.Chapter 9, by Andrew Feller, Teresa Wu, and Dan Shunk, reviews existing research and industry-based practices relating to collaborative product design (CPD) information systems. An information framework is proposed called the 'Virtual Environment for Product Development' (VE4PD) that is based on the integration of Web services and agent technologies to manage the CPD process. The VE4PD architecture is designed to support CPD functions such as design synchronization, timely notification, distributed control, role based security, support for distributed intelligent agents, and varying design rule standards. An implementation system including intelligent agents for design negotiation is also described that validates the application approach.Chapter 10, by Zhu Fan, Mogens Andreasen, Jiachuan Wang, Erik Goodman, and Lars Hein, proposes an integrated evolutionary engineering design framework that integrates the chromosome model in the domain theory, the evolutionary design, and human interaction. The evolvable chromosome model can help the designer to improve creativity in the design process, suggesting to them unconventional design concepts, and preventing them from looking for solutions only in a reduced solution space. The systematic analytical process to obtain a chromosome model followed by evolutionary design algorithms also helps the designer to have a complete view of design requirements and intentions. Human interaction is integrated to the framework due to the complex and dynamic nature of engineering design. It also helps the designer to accumulate design knowledge and form a design knowledge base. An example of the design of a vibration absorber for a typewriter demonstrates the feasibility of the technique.Chapter 11, by Xuan F. Zha, proposes an integrated intelligent approach and a multi-agent framework for the evaluation of the assemblability and assembly sequence of electro-mechanical assemblies (EMAs). The proposed approach integrates the STEP (STandard for the Exchange of Product model data, officially ISO 10303) based assembly model and XML schema with a fuzzy analytic hierarchy process. Through integration with the STEP-based product modeling agent system, a CAD agent system and assembly planning agent system, the developed assembly evaluation agent system can effectively incorporate, exchange, and share concurrent engineering knowledge into the preliminary design process so as to provide users with suggestions for improving a design and also helping obtain better design ideas.Part III: Applications. Chapters 12 to 20 in this section address the important issue of the ways that integrated intelligent systems are applied in engineering design. Case studies examine a wide variety of application areas including benchmarking and comparative analysis. The basic question is how accumulated data and expertise from engineering and business operations can be abstracted into useful knowledge, and how such knowledge can be applied to support engineering design. In this part of the book, chapters report case studies of innovative actual IIS-ED applications deploying specific AI-based technologies, such as logic rule-based systems, neural networks, fuzzy logic, cased-based reasoning, genetic algorithms, data mining algorithms, intelligent agents, and user intelligent interfaces, among others, and the integrations of these paradigms.Chapter 12, by Sarawut Sujitjorn, Thanatchai Kulworawanichpong, Deacha Puang-downrecong and Kongpan Areerak,presents detailed step-by-step description of an intelligent search algorithm known as 'Adaptive Tabu Search' (ATS). The proof of its convergence and its performance evaluation are illustrated. The chapter demonstrates the effectiveness and usefulness of the ATS through various engineering applications and designs in the following fields: power system, identification, and control.Chapter 13, by Shi-Shang Jang, David Shun-Hill Wong and Junghui Chen, addresses a technique known as 'experimental design' describes The design of new processes in modern competitive markets is mainly empirical because the short life-cycle does not allow the development of first-principle models. A systematic methodology know as 'experimental design', based on statistical data analysis and decision making, is used to optimise the number of experiments and direct process development. However, such methods are unsatisfactory when the number of design variables becomes very large and there are non-linearities in the input-output relationship. The new approach described in this chapter uses artificial neural networks as a meta-model, and a combination of random-search, fuzzy classification, and information theory as the design tool. An information free energy index is developed which balances the needs for resolving the uncertainty of the model and the relevance to finding the optimal design. The procedure involves iterative steps of meta-model construction, designing new experiments using meta-model and actual execution of designed experiments. The effectiveness of this approach is benchmarked using a simple optimization problem. Three industrial examples are presented to illustrate the applicability of the method to a variety of design problem.Chapter 14, by Miki Fukunari and Charles J. Malmborg, proposes computationally efficient cycle time models for Autonomous Vehicle Storage and Retrieval System that use scalable computational procedures for large-scale design conceptualization. Simulation based validation studies suggest that the models produce high accuracy. The procedure is demonstrated for over 4,000 scenarios corresponding to enumeration of the design spaces for a range of sample problems.Chapter 15, by Hirotaka Nakayama, Koichi Inoue and Yukihiro Yoshimori, discusses approximate optimization methods developed using computational intelligence, in which optimization is performed in parallel with the prediction of the form of the objective function. In this chapter, radial basis function networks (RBFN) are employed in predicting the form of objective function, and genetic algorithms (GA) used in searching for the optimal value of the predicted objective function. The effectiveness of the suggested method is shown through some numerical examples along with an application to seismic design in reinforcement of cablestayed bridges.Chapter 16, by Glenn Semmel, Steven R. Davis, Kurt W. Leucht, Daniel A. Rowe, Kevin E. Smith, Ladislau B\"{o}l\"{o}ni, discusses a rule-based telemetry agent used for Space Shuttle ground processing. It presents the problem domain along with design and development considerations such as information modeling, knowledge capture, and the deployment of the product. It also presents ongoing work with other condition monitoring agents.Chapter 17, by Mitun Bhattacharyya, Ashok Kumar, Magdy Bayoumi, proposes two techniques in two different sub areas of Wireless Sensor Networks (WSN) to reduce energy using learning methods. In the first technique, a watch-dog/blackboard mechanism is introduced to reduce query transmissions, and a learning approach is used to determine the query pattern from the cluster head. Once the pattern is learnt, data are automatically sent back even in the absence of queries from the cluster head. In the second technique a learning agent method of profiling the residual energies of sensors within a cluster is proposed.Chapter 18, Juan Vidal, Manuel Lama, and Alberto Bugarin, describes a knowledge-based system approach that combines problem-solving methods, workflow and machine learning technologies for dealing with the furniture estimate task. The system integrates product design in a workflow-oriented solution, and is built over a workflow management system that delegates the execution of activities to a problem-solving layer. An accurate estimation of the manufacturing cost of a custom furniture client order allows competitive prices, better profits adjustment, and increments the client portfolio too.Chapter 19, by Martin B\"{o}hner, Hans Holm Fr\"{u}hauf and Gabriella K\'{o}kai,discusses the suitability of ant colony optimization (ACO) to an employment with blind adaptation of the directional characteristic of antenna array systems. In order to fulfill the hard real time constraints for beam forming in ranges of few milliseconds a very efficient hardware implementation for a highly parallel distributed logic is proposed in this chapter. The application requirements are given because of the high mobility of wireless subscribers in modern telecommunication networks. Such a dynamic alignment of the directional characteristic of a base-station antenna can be achieved with the help of a hardware-based Ant Colony Optimization methodology, by controlling the steering antenna array system parameters as digital phase shifts and amplitude adjustment. By means of extensive simulations it was confirmed that the suggested ACO fulfills the requirements regarding the highly dynamic changes of the environment. Based on these results a concept is presented to integrate the optimizing procedure as high-parallel digital circuit structure in a customized integrated circuit of a reconfigurable gate array.Chapter 20, by Ankur Agarwal, Ravi Shankar, A. S. Pandya, presents the application of genetic algorithms to system level design flow to provide best effort solutions for two specific tasks, viz., performance tradeoff and task partitioning. Multiprocessor system on chip (MpSoC) platform has set a new innovative trend for the system-on-chip (SoC) design. Demanding Quality of Service (QOS) and performance metrics are leading to the adoption of a new design methodology for MpSoC. These will have to be built around highly scalable and reusable architectures that yield high speed at low cost and high energy efficiency for a variety of demanding applications. Designing such a system, in the presence of such aggressive QOS and Performance requirements, is an NP-complete problem.SummaryThere are over 48 coauthors of this notable work and they come from 19 countries. The chapters are clearly written, self-contained, readable and comprehensive with helpful guides including introduction, summary, extensive figures and examples and future trends in the domain with comprehensive reference lists. The discussions in these parts and chapters provide a wealth of practical ideas intended to foster innovation in thought and consequently, in the further development of technology. Together, they comprise a significant and uniquely comprehensive reference source for research workers, practitioners, computer scientists, academics, students, and others on the international scene for years to come.AcknowledgmentThe original intention of this edited book came from the discussion on the proposition to publish a Special Issue on Integrated and Hybrid Intelligent Systems in Product Design and Development in the International Journal of Knowledge-based and Intelligent Engineering Systems (KES) (Bob is Chief Editor of KES). The special issue was out in June 2005. We thought that based on the Special Issue in KES the selected quality papers could be extended into chapters, supplementing with additional chapters and forming the whole into a book that would fit well into the knowledge-based intelligent engineering systems collection of IOS Press. We then started working together in this direction. We were quite excited about this movement and immediately contacted the contributors and spread call for papers. The response from all the contributors was very positive and the proposal for a book was submitted to IOS for evaluation. The good news that the IOS Editorial Committee had approved the publishing of the book was conveyed to us in August 2005. We were overjoyed that the call-for-papers of the Special Issue and chapters had attracted favorable responses from many top researchers in this field. As the original intention was a peer reviewed Special Issue, and all the papers were either in the process of being reviewed or had already gone through the reviewing process, we informed the contributors that the quality of each paper, now each chapter, had followed the same standard of a rigorously peer-reviewed international journal.We are most grateful to the kind cooperation of all the contributors who had promptly responded to all the questions and had followed our requests for additional information. We would also like to thank IOS for giving us this opportunity of publishing this book.Xuan F. (William) Zha, Gaithersburg, MarylandRobert J. (Bob) Howlett, Brighton, UK},
booktitle = {Proceedings of the 2006 Conference on Integrated Intelligent Systems for Engineering Design},
pages = {i–xiv}
}

@inproceedings{10.1007/978-3-031-35891-3_8,
author = {Kutz, Janika and Neuh\"{u}ttler, Jens and Bienzeisler, Bernd and Spilski, Jan and Lachmann, Thomas},
title = {Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services},
year = {2023},
isbn = {978-3-031-35890-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-35891-3_8},
doi = {10.1007/978-3-031-35891-3_8},
abstract = {AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.},
booktitle = {Artificial Intelligence in HCI: 4th International Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I},
pages = {115–130},
numpages = {16},
keywords = {Design Principles, Human-Centered AI, Industrial AI},
location = {Copenhagen, Denmark}
}

@article{10.1007/s10796-021-10234-5,
author = {Meske, Christian and Bunde, Enrico},
title = {Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection},
year = {2022},
issue_date = {Apr 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-021-10234-5},
doi = {10.1007/s10796-021-10234-5},
abstract = {Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high.},
journal = {Information Systems Frontiers},
month = {mar},
pages = {743–773},
numpages = {31},
keywords = {Local explanations, Explainable artificial intelligence, Hate speech detection, Design principles, Design science research}
}

@article{10.1155/2022/1375009,
author = {Xiang, Jianmin and Tong, Litao and Zhou, Shengfa and Sharma, Kapil},
title = {Design of AI System for National Fitness Sports Competition Action Based on Association Rules Algorithm},
year = {2022},
issue_date = {2022},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2022},
issn = {1687-5265},
url = {https://doi.org/10.1155/2022/1375009},
doi = {10.1155/2022/1375009},
abstract = {In information system construction, online data migration is a very important link. At present, in different fields, people provide protection for online data migration through the way of project management to ensure the speed and efficiency of online migration. However, some problems may occur in the process of online data migration. In the development of contemporary sports, competitive sports, as the high-end stage of sports development, are constantly pursued by ordinary sports enthusiasts. Therefore, in the national fitness activities, how to combine the national fitness and competitive sports data to provide a more professional storage platform is a focus of research but also a problem to be solved in the process of online data migration. Because the data mining ID3 algorithm only supports querying and retrieving RowKey indexes, it does not support non-RowKey column indexing. Therefore, if you want to query non-RowKey indexes, the data mining ID3 algorithm will search the form in the overall scan, but the performance of this method is low. In order to improve the query speed of non-RowKey columns, this paper designs a secondary index function based on HBase. The sports competition action system can retrieve data from the secondary index of the query state, to avoid scanning the whole world and improve the search speed. In this paper, ID3 algorithm is used to combine national fitness and competitive sports data, which provides a guarantee for the migration of competitive sports data in the national fitness system.},
journal = {Intell. Neuroscience},
month = {jan},
numpages = {11}
}

@article{10.1155/2022/9913450,
author = {Ye, Yanping and Arif, Muhammad},
title = {Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology},
year = {2022},
issue_date = {2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2022},
issn = {1939-0114},
url = {https://doi.org/10.1155/2022/9913450},
doi = {10.1155/2022/9913450},
abstract = {With the development of the Internet, “Internet Plus” has been widely used in various fields, and the Internet has become a great opportunity to transform CET. People’s demand for education, especially higher education, has also increased rapidly. With the attention and investment of the state in recent years, higher education has developed rapidly, accounting for half of China’s higher education. However, the increase in the number of students has brought great pressure to CET. How to improve the teaching efficiency of large classes is an urgent problem to be solved. The development of sci and tech, especially computer, has brought us new hope. Computer-assisted instruction has been introduced into CET. However, there are some unreasonable points in the design of computer-aided marking system in China, which is not suitable for CET. It is very important to research and design a computer-aided marking system that can expand CET methods and maximize the integration of English instructional resources. This paper introduces the principle, characteristics, and application fields of AI; analyzes the problems faced by CET; and puts forward a CET path based on computer-aided technology.},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {8}
}

@inproceedings{10.1145/3522664.3528590,
author = {Foidl, Harald and Felderer, Michael and Ramler, Rudolf},
title = {Data smells: categories, causes and consequences, and detection of suspicious data in AI-based systems},
year = {2022},
isbn = {9781450392754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3522664.3528590},
doi = {10.1145/3522664.3528590},
abstract = {High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.},
booktitle = {Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI},
pages = {229–239},
numpages = {11},
location = {Pittsburgh, Pennsylvania},
series = {CAIN '22}
}

@article{10.1155/2023/9758670,
author = {Communication Networks, Security and},
title = {Retracted: Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology},
year = {2023},
issue_date = {2023},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2023},
issn = {1939-0114},
url = {https://doi.org/10.1155/2023/9758670},
doi = {10.1155/2023/9758670},
journal = {Sec. and Commun. Netw.},
month = {jan},
numpages = {1}
}

