"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Link","Abstract","EID"
"Dakheel A.O.; Singh Y.","Dakheel, Ahmed Obaid (58879348500); Singh, Yudhvir (55415379500)","58879348500; 55415379500","Brain Tumor Detection- The Role of Machine Learning Techniques","2024","International Journal of Intelligent Systems and Applications in Engineering","12","14s","","473","478","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184696025&partnerID=40&md5=012fdca93a00ef3e32e0bb5bf1deb345","Brain tumor disease is a dreadful alarming disease worldwide. WHO is providing the guidelines to detect the disease at early stages to protect the life of the patients. To detect the brain tumor at early stages the computational capability should be highly sensitive and identify the slightest changes in brain regions. The research work has explored the previous research papers published in international journals from 2018 to 2023 and presented the fundamental concepts and advanced concepts involved in the brain tumor disease diagnosis. The research work has presented the insights and working mechanism behind the diagnosis of brain tumor diseases with the help of MRIs. The image processing is the main working principle in detecting the brain tumor with distinct grade. The research work has presented the AI based machine learning concepts and deep learning concepts in detecting the diseases. The research work has focused on the most accurately diagnosing deep learning algorithms with advanced options to distinguish the brain tumor of early stages. The results have been presented to support the final result and output of the research work. © 2024, Ismail Saritas. All rights reserved.","2-s2.0-85184696025"
"Mohsen F.; Al-Absi H.R.H.; Yousri N.A.; El Hajj N.; Shah Z.","Mohsen, Farida (57776044300); Al-Absi, Hamada R. H. (35434601400); Yousri, Noha A. (23981703800); El Hajj, Nady (25925846100); Shah, Zubair (56428700200)","57776044300; 35434601400; 23981703800; 25925846100; 56428700200","A scoping review of artificial intelligence-based methods for diabetes risk prediction","2023","npj Digital Medicine","6","1","197","","","","10.1038/s41746-023-00933-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174977122&doi=10.1038%2fs41746-023-00933-5&partnerID=40&md5=944a6d1a9868c992009f1f8fc0bd0bc9","The increasing prevalence of type 2 diabetes mellitus (T2DM) and its associated health complications highlight the need to develop predictive models for early diagnosis and intervention. While many artificial intelligence (AI) models for T2DM risk prediction have emerged, a comprehensive review of their advancements and challenges is currently lacking. This scoping review maps out the existing literature on AI-based models for T2DM prediction, adhering to the PRISMA extension for Scoping Reviews guidelines. A systematic search of longitudinal studies was conducted across four databases, including PubMed, Scopus, IEEE-Xplore, and Google Scholar. Forty studies that met our inclusion criteria were reviewed. Classical machine learning (ML) models dominated these studies, with electronic health records (EHR) being the predominant data modality, followed by multi-omics, while medical imaging was the least utilized. Most studies employed unimodal AI models, with only ten adopting multimodal approaches. Both unimodal and multimodal models showed promising results, with the latter being superior. Almost all studies performed internal validation, but only five conducted external validation. Most studies utilized the area under the curve (AUC) for discrimination measures. Notably, only five studies provided insights into the calibration of their models. Half of the studies used interpretability methods to identify key risk predictors revealed by their models. Although a minority highlighted novel risk predictors, the majority reported commonly known ones. Our review provides valuable insights into the current state and limitations of AI-based models for T2DM prediction and highlights the challenges associated with their development and clinical integration. © 2023, Springer Nature Limited.","2-s2.0-85174977122"
"Darvishi A.; Khosravi H.; Sadiq S.; Gašević D.; Siemens G.","Darvishi, Ali (57219052527); Khosravi, Hassan (27368031300); Sadiq, Shazia (7006420326); Gašević, Dragan (8549413500); Siemens, George (36844717000)","57219052527; 27368031300; 7006420326; 8549413500; 36844717000","Impact of AI assistance on student agency","2024","Computers and Education","210","","104967","","","","10.1016/j.compedu.2023.104967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180370849&doi=10.1016%2fj.compedu.2023.104967&partnerID=40&md5=973af043f2c6fa334ba90a2318191bf7","AI-powered learning technologies are increasingly being used to automate and scaffold learning activities (e.g., personalised reminders for completing tasks, automated real-time feedback for improving writing, or recommendations for when and what to study). While the prevailing view is that these technologies generally have a positive effect on student learning, their impact on students’ agency and ability to self-regulate their learning is under-explored. Do students learn from the regular, detailed and personalised feedback provided by AI systems, and will they continue to exhibit similar behaviour in the absence of assistance? Or do they instead continue to rely on AI assistance without learning from it? To contribute to filling this research gap, we conducted a randomised controlled experiment that explored the impact of AI assistance on student agency in the context of peer feedback. With 1625 students across 10 courses, an experiment was conducted using peer review. During the initial four-week period, students were guided by AI features that utilised techniques such as rule-based suggestion detection, semantic similarity, and comparison with previous comments made by the reviewer to enhance their submissions if the feedback provided was deemed insufficiently detailed or general in nature. Over the following four weeks, students were divided into four different groups: control (AI) received prompts, (NR) received no prompts, (SR) received self-monitoring checklists in place of AI prompts, and (SAI) had access to both AI prompts and self-monitoring checklists. Results of the experiment suggest that students tended to rely on rather than learn from AI assistance. If AI assistance was removed, self-regulated strategies could help fill the gap but were not as effective as AI assistance. Results also showed that hybrid human-AI approaches that complement AI assistance with self-regulated strategies (SAI) were not more effective than AI assistance on its own. We conclude by discussing the broader benefits, challenges and implications of relying on AI assistance in relation to student agency in a world where we learn, live and work with AI. © 2023 The Author(s)","2-s2.0-85180370849"
"Song Y.; He Y.","Song, Yang (58655829100); He, Yingwei (58656453300)","58655829100; 58656453300","Toward an intelligent tourism recommendation system based on artificial intelligence and IoT using Apriori algorithm","2023","Soft Computing","27","24","","19159","19177","18","10.1007/s00500-023-09330-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174488905&doi=10.1007%2fs00500-023-09330-2&partnerID=40&md5=01ec8197b48217642bd2ca3c8ad9fc49","In recent years, the rapid development of the Internet has promoted the continuous expansion of the scale of China’s tourism industry, and the amount of tourism data has surged. However, tourists need help bringing personal interest and high-value data from the plethora of tourism information. The rise of artificial intelligence has transformed traditional tourism into an intelligent, data-driven industry. This shift has generated vast tourism data, offering both opportunities and challenges. The paper discusses an AI and IoT-based Intelligent Tourism Recommendation System (ITRS) that offers travelers predefined itineraries, personalized suggestions, and tourism insights. This system simplifies attraction discovery, unveiling hidden value within tourism data at the intersection of AI and IoT. The present study thoroughly investigates AI-based recommendation algorithms before delving into the system’s architecture. It categorizes user-based, project-based, and article-based collaborative filtering methodologies tailored to specific goals. First, thoroughly examine AI-based recommendation algorithms before delving into the system architecture. Second, categorize collaborative filtering methods as user-based, project-based, and article-based, each tailored to specific objectives. Third, delve into the Apriori algorithm’s complexity within the context of weighted association rules and introduce an enhanced iteration for improved efficiency. The proposed scheme encompasses an elaborate ITRS plan featuring a user interest model and a client module, crucial for the computation and analysis of users’ long-term and short-term interests. Rigorous performance testing confirms the ITRS’s superiority across varying support levels, with experimental results demonstrating the Apriori algorithm’s exceptional accuracy, achieving a 94.3% improvement over other methods. The Apriori algorithm is better than traditional recommendation algorithms such as Linear Regression, Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, K-nearest neighbor, Naive Bayes, and XGBoost. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","2-s2.0-85174488905"
"Guizzardi R.; Amaral G.; Guizzardi G.; Mylopoulos J.","Guizzardi, Renata (8544078300); Amaral, Glenda (57209454310); Guizzardi, Giancarlo (16028392500); Mylopoulos, John (7005652259)","8544078300; 57209454310; 16028392500; 7005652259","An ontology-based approach to engineering ethicality requirements","2023","Software and Systems Modeling","22","6","","1897","1923","26","10.1007/s10270-023-01115-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165614536&doi=10.1007%2fs10270-023-01115-3&partnerID=40&md5=73407cf7637d46aade5d516a6a1ffe5d","In a world where Artificial Intelligence (AI) is pervasive, humans may feel threatened or at risk by giving up control to machines. In this context, ethicality becomes a major concern to prevent AI systems from being biased, making mistakes, or going rogue. Requirements Engineering (RE) is the research area that can exert a great impact in the development of ethical systems by design. However, proposing concepts, tools and techniques that support the incorporation of ethicality into the software development processes as explicit requirements remains a great challenge in the RE field. In this paper, we rely on Ontology-based Requirements Engineering (ObRE) as a method to elicit and analyze ethicality requirements (‘Ethicality requirements’ is adopted as a name for the class of requirements studied in this paper by analogy to other quality requirements studied in software engineering, such as usability, reliability, and portability, etc. The use of this term (as opposed to ‘ethical requirements’) highlights that they represent requirements for ethical systems, analogous to how ‘trustworthiness requirements’ represent requirements for trustworthy systems. To put simply: the predicates ‘ethical’ or ‘trustworthy’ are not meant to be predicated over the requirements themselves). ObRE applies ontological analysis to ontologically unpack terms and notions that are referred to in requirements elicitation. Moreover, this method instantiates the adopted ontology and uses it to guide the requirements analysis activity. In a previous paper, we presented a solution concerning two ethical principles, namely Beneficence and Non-maleficence. The present paper extends the previous work by targeting two other important ethicality principles, those of Explicability and Autonomy. For each of these new principles, we do ontological unpacking of the relevant concepts, and we present requirements elicitation and analysis guidelines, as well as examples in the context of a driverless car case. Furthermore, we validate our approach by analysing the requirements elicitation made for the driverless car case in contrast with a similar case, and by assessing our method’s coverage w.r.t European Union guidelines for Trustworthy AI. © 2023, The Author(s).","2-s2.0-85165614536"
"Chakraborty T.; Wirth C.; Seifert C.","Chakraborty, Tanmay (58858516300); Wirth, Christian (57417028000); Seifert, Christin (8850014900)","58858516300; 57417028000; 8850014900","Post-hoc Rule Based Explanations for Black Box Bayesian Optimization","2024","Communications in Computer and Information Science","1947","","","320","337","17","10.1007/978-3-031-50396-2_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184124730&doi=10.1007%2f978-3-031-50396-2_18&partnerID=40&md5=2d67cbdaeece77199eff0c075098e6e3","Explainable Artificial Intelligence (XAI) aims to enhance transparency and trust in AI systems by providing insights into their decision-making processes. While there has been significant progress in developing explainability methods for AI, such advancements do not consider black-box optimization algorithms. In this paper, we present RX-BO (Rule based Explanations for Bayesian Optimization), a novel framework that brings explainability to black-box Bayesian optimization with a Gaussian process (GP) backbone. Leveraging the GP model’s approximation and uncertainty estimation capabilities, RX-BO extracts distribution-aware rules through a post-hoc rule based explainability method. These rules shed light on different regions of the posterior distribution, enabling transparent and trustworthy decision making. The framework incorporates a pairwise Mahalanobis distance-based hierarchical agglomerative clustering algorithm with Ward criterion for generating rule proposals. It also employs traditional metrics such as support, coverage, and confidence for selecting high-quality explanations. We evaluate RX-BO on an example optimization problem and six hyperparameter optimization tasks involving three machine learning models (classification and regression) across two datasets. The results demonstrate that RX-BO improves rule confidence and rule granularity control compared to decision trees and Rule based XAI frameworks. Furthermore, RX-BO introduces a novel approach by identifying interesting areas in the search space based on likelihood. This measure allows to rank explanations on how interesting they would be for an end user. Overall, RX-BO enhances the understanding and interpretability of black-box Bayesian optimization algorithm results, contributing to the broader field of XAI. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","2-s2.0-85184124730"
"Coutinho R.W.L.; Boukerche A.","Coutinho, Rodolfo W.L. (36006352200); Boukerche, Azzedine (7005819374)","36006352200; 7005819374","When Smart Metaverse Meets Affective Computing: Opportunities and Design Guidelines","2023","IEEE Communications Magazine","61","10","","46","52","6","10.1109/MCOM.004.2300009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167776022&doi=10.1109%2fMCOM.004.2300009&partnerID=40&md5=c5e83a812b68b2000118b1f5d19ae530","Metaverse and affective computing are two promising areas. We envision a new generation of smart metaverse that will consider affective computing to develop artificial intelligence (AI)-empowered avatars capable of expressing emotions and enhancing interactions on users' metaverse sessions. This article advocates for the symbiotic design of affective computing and metaverse. We discuss some of the unique challenges faced during the design of metaverse and affective computing and the current research trends to overcome them. We highlight how affective computing can tackle unique challenges in metaverse applications and how metaverse can be considered to deal with limitations faced in affective computing applications. Finally, we present some future research directions in need of attention. © 1979-2012 IEEE.","2-s2.0-85167776022"
"Khan Mamun M.M.R.; Elfouly T.","Khan Mamun, Mohammad Mahbubur Rahman (57202498841); Elfouly, Tarek (57214653796)","57202498841; 57214653796","AI-Enabled Electrocardiogram Analysis for Disease Diagnosis","2023","Applied System Innovation","6","5","95","","","","10.3390/asi6050095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175001031&doi=10.3390%2fasi6050095&partnerID=40&md5=8fa822b59da0cb7ab649abd4175183ff","Contemporary methods used to interpret the electrocardiogram (ECG) signal for diagnosis or monitoring are based on expert knowledge and rule-centered algorithms. In recent years, with the advancement of artificial intelligence, more and more researchers are using deep learning (ML) and deep learning (DL) with ECG data to detect different types of cardiac issues as well as other health problems such as respiration rate, sleep apnea, and blood pressure, etc. This study presents an extensive literature review based on research performed in the last few years where ML and DL have been applied with ECG data for many diagnoses. However, the review found that, in published work, the results showed promise. However, some significant limitations kept that technique from implementation in reality and being used for medical decisions; examples of such limitations are imbalanced and the absence of standardized dataset for evaluation, lack of interpretability of the model, inconsistency of performance while using a new dataset, security, and privacy of health data and lack of collaboration with physicians, etc. AI using ECG data accompanied by modern wearable biosensor technologies has the potential to allow for health monitoring and early diagnosis within reach of larger populations. However, researchers should focus on resolving the limitations. © 2023 by the authors.","2-s2.0-85175001031"
"Ventura M.D.","Ventura, Michele Della (56564818300)","56564818300","A Deep Learning Algorithm for the Development of Meaningful Learning in the Harmonization of a Musical Melody","2024","Communications in Computer and Information Science","1979","","","3","12","9","10.1007/978-3-031-48981-5_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182518188&doi=10.1007%2f978-3-031-48981-5_1&partnerID=40&md5=42b787367242a6ef61539a12feecfeee","The interest of musicians and computer scientists in AI-based automatic melody harmonization has increased significantly in the last few years. This research area has attracted the attention of both teachers and students of Theory, Analysis and Composition, looking for support tools for the learning process. The main problem is that the systems designed and developed up to now harmonize a melody written by a user without considering the didactic and therefore cognitive aspects at the basis of a “significant learning”: given a melody, the system returns a harmonization finished without any user input. This paper describes a self-learning algorithm capable of harmonizing a musical melody, with the aim of supporting the student during the study of Theory, Analysis and Composition. The algorithm, on the basis of the ascending and descending movement of the sounds of the melody (soprano), proposes the sounds for the bass line: the Viterbi algorithm was applied to evaluate the probability of the best match between the melody sounds and the provided Markov chains, to reach the “optimal” state sequences. Subsequently, the algorithm allows the user to complete the chords for each sound of the bass line (tenor and alto), or to create the complete chords. Examples of musical fragments harmonized in this way demonstrate that the algorithm is able to respect the concatenation rules of the tonal functions which characterize classical tonal music. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85182518188"
"Nguyen M.-D.; Bouaziz A.; Valdes V.; Rosa Cavalli A.; Mallouli W.; Montes De Oca E.","Nguyen, Manh-Dung (57200513270); Bouaziz, Anis (58561553300); Valdes, Valeria (58561553400); Rosa Cavalli, Ana (58561751200); Mallouli, Wissam (14037829000); Montes De Oca, Edgardo (34976546300)","57200513270; 58561553300; 58561553400; 58561751200; 14037829000; 34976546300","A deep learning anomaly detection framework with explainability and robustness","2023","ACM International Conference Proceeding Series","","","134","","","","10.1145/3600160.3605052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169683137&doi=10.1145%2f3600160.3605052&partnerID=40&md5=e5d1426eb2ecaee71e72d1b139fcd738","The prevalence of encrypted Internet traffic has resulted in a pressing need for advanced analysis techniques for traffic analysis and classification. Traditional rule-based and signature-based approaches have been hindered by the introduction of network encryption methods. With the emergence of machine learning (ML) and deep learning (DL), several preliminary works have been developed for anomaly detection in encrypted network traffic. However, complex Artificial Intelligence (AI) models like neural networks lack explainability, limiting the understanding of their predictions. To address this limitation, eXplainable Artificial Intelligence (XAI) has emerged, aiming to provide users with a rationale for understanding AI system outputs and fostering trust. However, existing explainable frameworks still lack comprehensive support for adversarial attacks and defenses. In this paper, we present Montimage AI Platform (MAIP), a new GUI-based deep learning framework for malicious traffic detection and classification combined with its ability of explaining the decision of the model. We employ popular XAI methods to interpret the prediction of the developed deep learning model. Furthermore, we perform adversarial attacks to assess the accountability and robustness of our model via different quantifiable metrics. We perform extensive experiments with both public and private network traffic. The experimental results demonstrate that our model achieves high performance and robustness, and its outcomes align closely with the domain knowledge. © 2023 Owner/Author.","2-s2.0-85169683137"
"Marzouk M.; Zitoun C.; Belghith O.; Skhiri S.","Marzouk, Maryem (58633344000); Zitoun, Cyrine (57440055700); Belghith, Oumaima (57226276028); Skhiri, Sabri (54411426400)","58633344000; 57440055700; 57226276028; 54411426400","The Building Blocks of a Responsible Artificial Intelligence Practice: An Outlook on the Current Landscape","2023","IEEE Intelligent Systems","38","6","","9","18","9","10.1109/MIS.2023.3320438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173377365&doi=10.1109%2fMIS.2023.3320438&partnerID=40&md5=42cded4a608a7ed497d7bf89a165ca32","For artificial intelligence (AI)-driven companies, awareness of the urgency of the responsible application of AI became essential with increased interest from different stakeholders. Responsible AI (RAI) has emerged as a practice to guide the design, development, deployment, and use of AI systems to ensure a benefit to users and those impacted by the systems' outcomes. This benefit is achieved through trustworthy models and strategies that assimilate ethical principles to ensure compliance with regulations and standards for long-term trust. However, RAI comes with the challenge of lack of standardization when it comes to which principles to adopt, what they mean, and how they can be operationalized. This article aims to bridge the gap between principles and practice through a study of different approaches taken in the literature and the proposition of a foundational framework.  © 2001-2011 IEEE.","2-s2.0-85173377365"
"Saha K.; Chandrasekharan E.","Saha, Koustuv (57194395042); Chandrasekharan, Eshwar (57201449769)","57194395042; 57201449769","Future of Workplace Conversational AI-driven Personal Assistants: Promises and Perils","2023","ACM International Conference Proceeding Series","","","","133","135","2","10.1145/3632754.3632939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185397012&doi=10.1145%2f3632754.3632939&partnerID=40&md5=3358c6d5cf8f79ce03dddf40fc31548d","This proposal aims to provide an empirical understanding of how conversational AI-driven personal assistants can operate effectively and ethically in the workplace. In particular, we will carefully design and build a prototype for a new AI-powered workplace assistant called SAILOR, conduct user studies to understand user expectations and concerns around AI-driven personal assistants like SAILOR, and develop a conceptual framework to evaluate the benefits and harms of human-centered AI systems, ensuring their deployment aligns with high standards of functionality and ethics. In addition, we seek to provide a comprehensive set of guidelines and recommendations for the responsible design of such tools. Our findings will have broad implications for the ethical design, development, and deployment of AI-driven systems for human-centered applications like assisting workers in the workplace.  © 2023 Owner/Author.","2-s2.0-85185397012"
"van den Berg M.; Gerlings J.; Kim J.","van den Berg, Martin (7201697066); Gerlings, Julie (57221693279); Kim, Jenia (58867732900)","7201697066; 57221693279; 58867732900","Empirical Research on Ensuring Ethical AI in Fraud Detection of Insurance Claims: A Field Study of Dutch Insurers","2024","Communications in Computer and Information Science","1948 CCIS","","","106","114","8","10.1007/978-3-031-50485-3_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184293011&doi=10.1007%2f978-3-031-50485-3_9&partnerID=40&md5=d0a4c4064117dde0c4c663aeaa4ae7d0","The insurance industry in the Netherlands applies artificial intelligence (AI) in different processes and acknowledges that AI should be implemented in an ethical and responsible manner. Therefore, the Dutch Association of Insurers supported the industry by publishing an ethical framework. However, the framework is a set of high-level requirements, and the question is how these requirements are translated into local practices. Our research question is how ethical requirements are applied by insurance companies when using AI systems to detect fraud in insurance claims. To answer this question, we conducted interviews with representatives of four different organizations. The study demonstrates the awareness amongst interviewees that AI needs to be applied in a responsible way. The ethical framework provides a good starting point for insurers to develop their own practical ethical guidelines. Empirical evidence confirms that accountability, safety, transparency, non-discrimination, and human agency are priorities in the process of AI implementation. The research shows that translation of the ethical framework into operational and actionable instructions is done in-house by each organization and requires a multidisciplinary approach and cooperation between teams. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","2-s2.0-85184293011"
"Larasati R.; de Liddo A.; Motta E.","Larasati, Retno (57197729397); de Liddo, Anna (13008594300); Motta, Enrico (7006092143)","57197729397; 13008594300; 7006092143","Meaningful Explanation Effect on User’s Trust in an AI Medical System: Designing Explanations for Non-Expert Users","2023","ACM Transactions on Interactive Intelligent Systems","13","4","30","","","","10.1145/3631614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181447199&doi=10.1145%2f3631614&partnerID=40&md5=bb6c639b4c8e051241d8bf685c185af2","Whereas most research in AI system explanation for healthcare applications looks at developing algorithmic explanations targeted at AI experts or medical professionals, the question we raise is: How do we build meaningful explanations for laypeople? And how does a meaningful explanation affect user’s trust perceptions? Our research investigates how the key factors affecting human-AI trust change in the light of human expertise, and how to design explanations specifically targeted at non-experts. By means of a stage-based design method, we map the ways laypeople understand AI explanations in a User Explanation Model. We also map both medical professionals and AI experts’ practice in an Expert Explanation Model. A Target Explanation Model is then proposed, which represents how experts’ practice and layperson’s understanding can be combined to design meaningful explanations. Design guidelines for meaningful AI explanations are proposed, and a prototype of AI system explanation for non-expert users in a breast cancer scenario is presented and assessed on how it affect users’ trust perceptions. © 2023 Copyright held by the owner/author(s)","2-s2.0-85181447199"
"Goodarzi P.; Ansari M.; Mahdavinejad M.; Russo A.; Haghighatbin M.; Pour Rahimian F.","Goodarzi, Parichehr (58316222300); Ansari, Mojtaba (23767012400); Mahdavinejad, Mohammadjavad (53164158600); Russo, Alessio (55998612300); Haghighatbin, Mahdi (58317294000); Pour Rahimian, Farzad (57217859353)","58316222300; 23767012400; 53164158600; 55998612300; 58317294000; 57217859353","Morphological analysis of historical lanscapes based on cultural DNA approach","2023","Digital Applications in Archaeology and Cultural Heritage","30","","e00277","","","","10.1016/j.daach.2023.e00277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162088307&doi=10.1016%2fj.daach.2023.e00277&partnerID=40&md5=082f5a6966c408934f644d5a7c7bdeb1","Recent trends in landscape architecture investigate new approaches, methods, and technologies to understand, monitor, manage, continuity, and sustainably develop heritage landscapes. Cultural DNA (CD) represents designs' transferable geometric, behavioural and functional properties. The morphological structure of Persian historical gardens possesses discoverable hidden patterns, computable through the CD's mathematical and computational models. This study aims to investigate and discover effective parameters in the spatial structure of historical Persian gardens using Space Syntax. Six Persian Gardens were surveyed, and spatial structures were analysed using DepthMap10 software. The results show that these spaces follow meaningful mathematical patterns and rules that can be formulated in the context of generative processes and generalized for the evolutionary continuity of gardens. However, further research is proposed to develop more advanced computational methods, such as artificial intelligence (AI) algorithms and AI-based decision support tools, to help to generate design scenarios and to transmit culture through the design process. © 2023","2-s2.0-85162088307"
"Singh J.; Sandhu J.K.; Kumar Y.","Singh, Jagandeep (58729627000); Sandhu, Jasminder Kaur (56712403800); Kumar, Yogesh (57225085312)","58729627000; 56712403800; 57225085312","Metaheuristic-based hyperparameter optimization for multi-disease detection and diagnosis in machine learning","2024","Service Oriented Computing and Applications","","","","","","","10.1007/s11761-023-00382-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182854072&doi=10.1007%2fs11761-023-00382-8&partnerID=40&md5=b0fe5a123a4b9ace0f8c018163367265","Metaheuristic algorithms with machine learning techniques have become popular because it works so well for problems like regression, classification, rule mining, and clustering in health care. This paper’s primary purpose is to design a multi-disease prediction system using AI-based metaheuristic approaches. Initially, the data is collected in the form of diverse classes, which include Id, gender, date of birth, etc. The data has been preprocessed, normalized, and graphically represented to improve its quality and detect any errors. Later, machine learning models, such as decision tree, extra tree classifier, extreme gradient boosting classifier, light gradient boosting machine classifier, random forest, and artificial neural network, are initially trained without optimizing hyperparameters and then fine-tuned by integrating various hyperparameter optimizers such as grid search CV, random search, hyperband, and genetic search. During experimentation, it is found that optimizing the models using random search optimizer computed the highest accuracy of 100% as compared to the rest of the hyperparameter optimizers. In the context of ‘Service Oriented Computing and Applications,’ our multi-disease prediction system offers valuable innovation. It aligns with the goal of enhancing healthcare services, patient outcomes, and healthcare efficiency. Our pioneering integration of metaheuristic algorithms and machine learning introduces intelligent healthcare solutions, with the study’s focus on hyperparameter optimization and achieving 100% accuracy demonstrates practical significance in SOC and its applications. © 2024, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85182854072"
"Schedl M.; Anelli V.W.; Lex E.","Schedl, Markus (8684865900); Anelli, Vito Walter (57078657900); Lex, Elisabeth (25928014700)","8684865900; 57078657900; 25928014700","Trustworthy Recommender Systems: Technical, Ethical, Legal, and Regulatory Perspectives","2023","Proceedings  of the 17th ACM Conference on Recommender Systems, RecSys 2023","","","","1288","1290","2","10.1145/3604915.3609497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174504650&doi=10.1145%2f3604915.3609497&partnerID=40&md5=5972fc68805ae0a44c28f52d40339159","This tutorial provides an interdisciplinary overview about the topics of fairness, non-discrimination, transparency, privacy, and security in the context of recommender systems. These are important dimensions of trustworthy AI systems according to European policies, but also extend to the global debate on regulating AI technology. Since we strongly believe that the aforementioned aspects require more than merely technical considerations, we discuss these topics also from ethical, legal, and regulatory points of views, intertwining different perspectives. The main focus of the tutorial is still on presenting technical solutions that aim at addressing the mentioned topics of trustworthiness. In addition, the tutorial equips the mostly technical audience of RecSys with the necessary understanding of the social and ethical implications of their research and development, and of recent ethical guidelines and regulatory frameworks. © 2023 Owner/Author.","2-s2.0-85174504650"
"Islam M.S.; Rahman W.; Abdelkader A.; Lee S.; Yang P.T.; Purks J.L.; Adams J.L.; Schneider R.B.; Dorsey E.R.; Hoque E.","Islam, Md Saiful (57217440460); Rahman, Wasifur (57213423205); Abdelkader, Abdelrahman (57550775200); Lee, Sangwu (57213418462); Yang, Phillip T. (57550378800); Purks, Jennifer Lynn (57194767116); Adams, Jamie Lynn (57198418505); Schneider, Ruth B. (57187564000); Dorsey, Earl Ray (57202594230); Hoque, Ehsan (26422051800)","57217440460; 57213423205; 57550775200; 57213418462; 57550378800; 57194767116; 57198418505; 57187564000; 57202594230; 26422051800","Using AI to measure Parkinson’s disease severity at home","2023","npj Digital Medicine","6","1","156","","","","10.1038/s41746-023-00905-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168699202&doi=10.1038%2fs41746-023-00905-9&partnerID=40&md5=ec6c413f5f797a1308135f17bcbe2f01","We present an artificial intelligence (AI) system to remotely assess the motor performance of individuals with Parkinson’s disease (PD). In our study, 250 global participants performed a standardized motor task involving finger-tapping in front of a webcam. To establish the severity of Parkinsonian symptoms based on the finger-tapping task, three expert neurologists independently rated the recorded videos on a scale of 0–4, following the Movement Disorder Society Unified Parkinson’s Disease Rating Scale (MDS-UPDRS). The inter-rater reliability was excellent, with an intra-class correlation coefficient (ICC) of 0.88. We developed computer algorithms to obtain objective measurements that align with the MDS-UPDRS guideline and are strongly correlated with the neurologists’ ratings. Our machine learning model trained on these measures outperformed two MDS-UPDRS certified raters, with a mean absolute error (MAE) of 0.58 points compared to the raters’ average MAE of 0.83 points. However, the model performed slightly worse than the expert neurologists (0.53 MAE). The methodology can be replicated for similar motor tasks, providing the possibility of evaluating individuals with PD and other movement disorders remotely, objectively, and in areas with limited access to neurological care. © 2023, Springer Nature Limited.","2-s2.0-85168699202"
"Tukur M.; Saad G.; Alshagathrh F.M.; Househ M.; Agus M.","Tukur, Muhammad (57221497010); Saad, Ghassan (58521084400); Alshagathrh, Fahad M (57023989900); Househ, Mowafa (8667908000); Agus, Marco (57195623616)","57221497010; 58521084400; 57023989900; 8667908000; 57195623616","Telehealth interventions during COVID-19 pandemic: A scoping review of applications, challenges, privacy and security issues","2023","BMJ Health and Care Informatics","30","1","e100676","","","","10.1136/bmjhci-2022-100676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166597753&doi=10.1136%2fbmjhci-2022-100676&partnerID=40&md5=12c2e5e8c7157ed0ef06c5c6445e7c94","Background The COVID-19, caused by the SARS-CoV-2 virus, proliferated worldwide, leading to a pandemic. Many governmental and non-governmental organisations and research institutes are contributing to the COVID-19 fight to control the pandemic. Motivation Numerous telehealth applications have been proposed and adopted during the pandemic to combat the spread of the disease. To this end, powerful tools such as artificial intelligence (AI)/robotic technologies, tracking, monitoring, consultation apps and other telehealth interventions have been extensively used. However, there are several issues and challenges that are currently facing this technology. Objective The purpose of this scoping review is to analyse the primary goal of these techniques; document their contribution to tackling COVID-19; identify and categorise their main challenges and future direction in fighting against the COVID-19 or future pandemic outbreaks. Methods Four digital libraries (ACM, IEEE, Scopus and Google Scholar) were searched to identify relevant sources. Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) was used as a guideline procedure to develop a comprehensive scoping review. General telehealth features were extracted from the studies reviewed and analysed in the context of the intervention type, technology used, contributions, challenges, issues and limitations. Results A collection of 27 studies were analysed. The reported telehealth interventions were classified into two main categories: AI-based and non-AI-based interventions; their main contributions to tackling COVID-19 are in the aspects of disease detection and diagnosis, pathogenesis and virology, vaccine and drug development, transmission and epidemic predictions, online patient consultation, tracing, and observation; 28 telehealth intervention challenges/issues have been reported and categorised into technical (14), non-technical (10), and privacy, and policy issues (4). The most critical technical challenges are: network issues, system reliability issues, performance, accuracy and compatibility issues. Moreover, the most critical non-technical issues are: the skills required, hardware/software cost, inability to entirely replace physical treatment and people's uncertainty about using the technology. Stringent laws/regulations, ethical issues are some of the policy and privacy issues affecting the development of the telehealth interventions reported in the literature. Conclusion This study provides medical and scientific scholars with a comprehensive overview of telehealth technologies' current and future applications in the fight against COVID-19 to motivate researchers to continue to maximise the benefits of these techniques in the fight against pandemics. Lastly, we recommend that the identified challenges, privacy, and security issues and solutions be considered when designing and developing future telehealth applications.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","2-s2.0-85166597753"
"Hacker P.","Hacker, Philipp (57207556651)","57207556651","The European AI liability directives – Critique of a half-hearted approach and lessons for the future","2023","Computer Law and Security Review","51","","105871","","","","10.1016/j.clsr.2023.105871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170636566&doi=10.1016%2fj.clsr.2023.105871&partnerID=40&md5=9f0a5997a531a512b0fe26cac7924b61","The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI). © 2023 Philipp Hacker","2-s2.0-85170636566"
"Zhao T.; Li H.; Di X.; Cai Z.; Wan Y.; Zhang Y.; Wang X.; Peng Y.; Che L.; Xu H.","Zhao, Tingting (57202048748); Li, Hongsheng (58846852900); Di, Xinli (57747674500); Cai, Zhongliang (8338377900); Wan, Yuewu (57748648000); Zhang, Ye (57746689700); Wang, Xinpeng (57303595400); Peng, Yunlu (57218644982); Che, Linlin (57742391700); Xu, Hong (57203120300)","57202048748; 58846852900; 57747674500; 8338377900; 57748648000; 57746689700; 57303595400; 57218644982; 57742391700; 57203120300","A STUDY OF RAPID MAPPING TECHNOLOGY BASED ON ADOBE ILLUSTRATOR","2023","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","48","1/W2-2023","","239","244","5","10.5194/isprs-archives-XLVIII-1-W2-2023-239-2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183310496&doi=10.5194%2fisprs-archives-XLVIII-1-W2-2023-239-2023&partnerID=40&md5=65dcedae51d3ec01a49d527cd1356b90","At present, China's urban and rural construction, national security, emergency and disaster relief have put forward higher and faster requirements for high-quality and current maps. How to use the latest spatial database in the shortest possible time to produce and provide high-quality, highly presentable, content-rich maps is an urgent issue. In this paper, we study the rapid mapping technology based on GIS platform and map mapping software, study the automatic map mapping method under AI environment, design and develop the spatial basic geographic database-driven rapid mapping system, realize the automatic lossless conversion of GIS data to map mapping software according to the established mapping rule base, realize the automatic configuration of symbols and annotations, and realize the automation of processing of element relationship. The AI-based database-driven rapid mapping technology has been used in the practice of map compilation in prefecture-level cities, replacing most of the manual repetitive operations, greatly improving the efficiency of map compilation, and enhancing the capacity of emergency mapping services. © Author(s) 2023.","2-s2.0-85183310496"
"Lukács A.; Váradi S.","Lukács, Adrienn (57209015805); Váradi, Szilvia (55486161800)","57209015805; 55486161800","GDPR-compliant AI-based automated decision-making in the world of work","2023","Computer Law and Security Review","50","","105848","","","","10.1016/j.clsr.2023.105848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166649330&doi=10.1016%2fj.clsr.2023.105848&partnerID=40&md5=066255eb85faac6d21601c635fa68aba","Artificial Intelligence is spreading fast in our everyday life and the world of work is no exception. AI is increasingly shaping the employment context: such emerging areas are augmented and automated decision-making. As AI-based decision-making is fuelled by personal data, compliance with data protection frameworks is inevitable. Even though automated decision-making is already addressed by the European norms on data protection – especially the GDPR –, their application in the world of work raises specific questions. The paper examines, in the light of the ‘general’ data protection background, what specific data protection challenges are raised in the field of AI-based automated decision-making in the context of employment. As a result of the research, the paper provides a detailed overview on the European legal framework on the data protection aspects of AI-based automated decision-making in the employment context. It identifies the main challenges, such as the applicability of the existing legal framework to the current use-cases and the specific questions relating to the lawful bases in the world of work, and provides guidelines on how to address these challenges. © 2023 Adrienn Lukács and Szilvia Váradi","2-s2.0-85166649330"
"Reddy V.J.; Hariram N.P.; Ghazali M.F.; Kumarasamy S.","Reddy, Vennapusa Jagadeeswara (57215487195); Hariram, N.P. (58490230600); Ghazali, Mohd Fairusham (57948707700); Kumarasamy, Sudhakar (57222047391)","57215487195; 58490230600; 57948707700; 57222047391","Pathway to Sustainability: An Overview of Renewable Energy Integration in Building Systems","2024","Sustainability (Switzerland)","16","2","638","","","","10.3390/su16020638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183377217&doi=10.3390%2fsu16020638&partnerID=40&md5=3b62bca816cf7d8c3998d30d309e1c8e","Decarbonizing the building sector is crucial for mitigating climate change, reducing carbon emissions, and achieving an energy production–consumption balance. This research aims to identify key design principles and strategies to enhance energy savings and analyze the integration potential of renewable energy sources (RES) such as solar, wind, geothermal, and biomass, providing in-depth technical exploration and evaluating current building developments. Moreover, the study also examines recent developments, explicitly focusing on integrating hybrid renewable energy systems, energy storage solutions, and AI-based technological innovations. Through comprehensive analysis and critical evaluation, this research provides valuable insights and practical recommendations for achieving building sustainability and advancing the transition towards a low-carbon built environment. © 2024 by the authors.","2-s2.0-85183377217"
"Zaidi S.F.M.; Shafiabady N.; Beilby J.","Zaidi, Syed Fawad M. (57207751176); Shafiabady, Niusha (35615154400); Beilby, Justin (19833339200)","57207751176; 35615154400; 19833339200","Identifying presence of cybersickness symptoms using AI-based predictive learning algorithms","2023","Virtual Reality","27","4","","3613","3620","7","10.1007/s10055-023-00813-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160645005&doi=10.1007%2fs10055-023-00813-z&partnerID=40&md5=6dafc3f0ec412952a6359450ed12f0c6","Cybersickness (CS) affects a large proportion of virtual reality (VR) users causing a combination of nausea, headaches and dizziness which would create barriers to the users, VR designers/developers and the stakeholders in the production industry. Although design principles suggest methods to avoid CS, challenges remain as new demands and systems continue to penetrate the competitive market. The dilemma is whether to use VR technology by experiencing the ultimate virtual world using a head-mounted display (HMD) with possible CS triggers or to avoid the triggers by avoiding using VR. With the huge success and potential in the entertainment industry, it is very important to focus on the solutions to handling CS dilemmas. Therefore, the main observation for the developers is to have a guide around the set of established design principles aiming to broadly reduce CS. In this paper, we provide a method to apply artificial intelligence (AI) techniques and use machine learning (ML) algorithms including support vector machines (SVMs), decision trees (DTs) and K-nearest neighbours (KNNs) to predict CS outcomes. Based on our findings, we have observed that DT and SVM surpassed KNN in test accuracy. Additionally, DT exhibited better results than both SVM and KNN in train accuracy. By exploiting the power of ML, developers will be able to predict the potential occurrence of CS while developing VR projects to find ways to alleviate CS more effectively. © 2023, The Author(s).","2-s2.0-85160645005"
"Chan P.Z.; Ramli M.A.I.B.; Chew H.S.J.","Chan, Pin Zhong (58679104500); Ramli, Muhammad Aqil Irfan Bin (58678979400); Chew, Han Shi Jocelyn (57203411752)","58679104500; 58678979400; 57203411752","Diagnostic Test Accuracy of artificial intelligence-assisted detection of acute coronary syndrome: A systematic review and meta-analysis","2023","Computers in Biology and Medicine","167","","107636","","","","10.1016/j.compbiomed.2023.107636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175644059&doi=10.1016%2fj.compbiomed.2023.107636&partnerID=40&md5=6499fdaae59226da5ee0661d6f5d4f1f","Background: Artificial intelligence (AI) has potential uses in healthcare including the detection of health conditions and prediction of health outcomes. Past systematic reviews had reviewed the accuracy of artificial neural networks (ANN) on Electrocardiogram (ECG) readings but that of other AI models on other Acute Coronary Syndrome (ACS) detection tools remains unclear. Methods: Nine electronic databases were searched from 2012 to 31 August 2022 including grey literature search and hand searching of references of included articles. Risk of bias was assessed by two independent reviewers using the Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2). Test characteristics namely true positives, false positives, true negatives, and false negatives were extracted from all included articles into a 2x2 table. Study-specific estimates of sensitivity and specificity were pooled using hierarchical summary receiver operating characteristic (HSROC) model and displayed using a forest plot and HSROC curve. Results: 66 studies were included in the review. A total of 518,931 patients were included whose mean ages varied from 32.62 to 70 years old. In 66 studies, the sensitivity and specificity of AI-based detection for ACS screening ranged from 64 % to 100 % and 65 %–100 %, respectively. The overall quality of evidence was low due to the inclusion of case-control studies. Conclusion: Results of the study inform the potential of using AI-assisted ACS detection for accurate diagnosis and prompt treatment for ACS. Adherence to the Standards for Reporting of Diagnostic Accuracy (STARD) guideline and having more cohort studies for future Diagnostic Test Accuracy (DTA) studies are necessary to improve the quality of evidence of AI-based detection of ACS. © 2023 Elsevier Ltd","2-s2.0-85175644059"
"Girimurugan B.; Rajeshwari S.; Sreekala S.P.; Revathy S.","Girimurugan, B. (58175417700); Rajeshwari, S. (58705155100); Sreekala, S.P. (57215287837); Revathy, S. (58705315100)","58175417700; 58705155100; 57215287837; 58705315100","The smart and secured AI-powered strategies for optimizing processes in multi-vendor business applications","2023","Toward Artificial General Intelligence: Deep Learning, Neural Networks, Generative AI","","","","287","307","20","10.1515/9783111323749-014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177536844&doi=10.1515%2f9783111323749-014&partnerID=40&md5=ca4d0d0d8120c15a19dd4f649f44fbd5","The development of artificial intelligence (AI)-powered processes in multivendor business applications has created significant opportunities to optimize resources, streamline operations, and reduce costs. However, deploying AI in multi-vendor business applications presents a unique set of challenges, including the potential for data privacy and security issues. To ensure the success of AI-enabled processes, organizations should implement best practices for proper data protection and secure AI-powered strategies. With the proper implementation of data security protocols and usage strategies, organizations can harness the potential of AI-powered processes in multivendor business applications to drive greater efficiency and cost savings. This includes creating greater process efficiency, reducing manual labor costs, and improving customer experiences. This will also enable organizations to remain competitive in the rapidly changing business landscape. © 2024 Walter de Gruyter GmbH, Berlin/Boston.","2-s2.0-85177536844"
"Sadek M.; Kallina E.; Bohné T.; Mougenot C.; Calvo R.A.; Cave S.","Sadek, Malak (58534615800); Kallina, Emma (57218764038); Bohné, Thomas (6507819384); Mougenot, Céline (50162087300); Calvo, Rafael A. (58905548000); Cave, Stephen (57203716558)","58534615800; 57218764038; 6507819384; 50162087300; 58905548000; 57203716558","Challenges of responsible AI in practice: scoping review and recommended actions","2024","AI and Society","","","","","","","10.1007/s00146-024-01880-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185925079&doi=10.1007%2fs00146-024-01880-9&partnerID=40&md5=46a855bd2cf16e01f0361bbdfe74050e","Responsible AI (RAI) guidelines aim to ensure that AI systems respect democratic values. While a step in the right direction, they currently fail to impact practice. Our work discusses reasons for this lack of impact and clusters them into five areas: (1) the abstract nature of RAI guidelines, (2) the problem of selecting and reconciling values, (3) the difficulty of operationalising RAI success metrics, (4) the fragmentation of the AI pipeline, and (5) the lack of internal advocacy and accountability. Afterwards, we introduce a number of approaches to RAI from a range of disciplines, exploring their potential as solutions to the identified challenges. We anchor these solutions in practice through concrete examples, bridging the gap between the theoretical considerations of RAI and on-the-ground processes that currently shape how AI systems are built. Our work considers the socio-technical nature of RAI limitations and the resulting necessity of producing socio-technical solutions. © The Author(s) 2024.","2-s2.0-85185925079"
"Morgan D.","Morgan, Deborah (57985260400)","57985260400","Anticipatory regulatory instruments for AI systems: A comparative study of regulatory sandbox schemes","2023","AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society","","","","980","981","1","10.1145/3600211.3604732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173616122&doi=10.1145%2f3600211.3604732&partnerID=40&md5=ee8b64521ebd90f2059439a8dfa0eb96","Anticipatory regulatory instruments are pre-emptive approaches to identify and anticipate risks arising from new technologies. They can also act as indicators of 'pro-innovation' economic support for digital technologies. The extent to which regulatory agencies can fulfil their regulatory remit, aimed at the protection of the public good, and signal support for innovative and disruptive technologies is an open policy question. Regulatory sandbox schemes are comparatively new anticipatory tools, operating within a small number of regulators, and their potential to assess contextual or cross-sectoral risk is unclear. However, emerging proposals for the regulation of AI increasing feature various models of regulatory sandboxes often aligned to the need to reduce access barriers for SMEs and innovators. Examples include the European Commission's Proposal for a regulation concerning AI [3] and the recent United Kingdom AI White Paper, AI Regulation: A Pro-Innovation Approach [8]. Disentangling the causal dimensions of why regulatory sandboxes are proposed to regulate AI, and their utility as tools of pre-emptive risk assessment are my core research questions. The regulation of emerging digital technologies present challenges for regulators and governments in monitoring rapid global developments and in anticipating novel forms of risk [9]. Nesta introduced the term anticipatory regulation, and such approaches potentially provide 'a set of behaviours and tools - i.e., a way of working - that is intended to help regulators identify, build and test solutions to emerging challenges' [4]. Regulatory sandboxes are a prominent, and arguably the most widespread, example of such an anticipatory regulatory tool. Whilst there are varied definitions of regulatory sandbox schemes, existing schemes allow small-scale, live testing of innovations in a controlled environment under the supervision of a regulatory authority [6]. A small number of regulatory sandbox schemes are in operation within the UK operating within sectoral and cross-sectoral regulatory remits. However, empirical data and academic literature regarding the methodologies and operation of these current schemes, and literature exploring regulatory sandboxes more broadly, is scarce [7, 10]. The ontological focus of my work is critical realist, which accepts the external reality of the design and instrumental aims of sandbox schemes, whilst seeking to understand the underlying causes and drivers for their use and rapid promotion. To locate such causes and explanations it is necessary to examine existing schemes within the 'rules and norms' of their institutional context and structures [1, 2]. Institutional analysis will isolate the key dimensions of each scheme, consider the influence of the regulatory structures, and then test such analysis through empirical research with regulatory and policy actors. The core hypothesis of my research is that regulatory contexts, path dependencies and conceptions of risk are significant causal elements within existing sandbox schemes and, as such, may present a challenge when designing and deploying cross-sectoral sandbox schemes for AI systems. I have already undertaken analysis of the two regulatory sandbox schemes applying the Institutional Analysis and Development framework of Elinor Ostrom [5]. This analysis has highlighted significant dimensions of sandbox schemes including the role and forms of sectoral incentives for participants, how knowledge and conceptions of risk are shared and the potential role of participatory processes and stakeholders. I am drafting a forthcoming paper outlining a typology of incentives for existing regulatory sandbox schemes. I have included policy and wider sectoral stakeholders within my data collection to obtain perspectives regarding perceived utility, understandings, and conceptions of sandbox schemes. Incorporating collaborative processes and inclusive engagement with affected stakeholders is a key principle of anticipatory regulation [4]. The role and extent of such engagement within proposed sandbox schemes for AI is a further dimension of my research to consider how such processes may be developed and operationalised. This work is undertaken at a time of rapid progression within AI systems and in the development of proposed AI regulation and varied forms of decentralised AI governance. I hope that my research will provide understanding of the utility, and potential limitations, of sandboxes as a regulatory tool drawing upon data from existing practices. My work may also impact existing policy discussions around the role of sandbox schemes as risk assessment and information monitoring tools for regulators.  © 2023 Owner/Author.","2-s2.0-85173616122"
"Liu L.; Li Y.; Liu N.; Luo J.; Deng J.; Peng W.; Bai Y.; Zhang G.; Zhao G.; Yang N.; Li C.; Long X.","Liu, Lijue (26643146300); Li, Yaming (58850724000); Liu, Na (58850571200); Luo, Jingmin (57195533647); Deng, Jinhai (58850335500); Peng, Weixiong (58599299300); Bai, Yongping (58850644700); Zhang, Guogang (58847331100); Zhao, Guihu (58850411500); Yang, Ning (58850336000); Li, Chuanchang (58850336100); Long, Xueying (58850725000)","26643146300; 58850724000; 58850571200; 57195533647; 58850335500; 58599299300; 58850644700; 58847331100; 58850411500; 58850336000; 58850336100; 58850725000","Establishment of machine learning-based tool for early detection of pulmonary embolism","2024","Computer Methods and Programs in Biomedicine","244","","107977","","","","10.1016/j.cmpb.2023.107977","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183466094&doi=10.1016%2fj.cmpb.2023.107977&partnerID=40&md5=ba52992ce153efda5985b339adcc8231","Background and objectives: Pulmonary embolism (PE) is a complex disease with high mortality and morbidity rate, leading to increasing society burden. However, current diagnosis is solely based on symptoms and laboratory data despite its complex pathology, which easily leads to misdiagnosis and missed diagnosis by inexperienced doctors. Especially, CT pulmonary angiography, the gold standard method, is not widely available. In this study, we aim to establish a rapid and accurate screening model for pulmonary embolism using machine learning technology. Importantly, data required for disease prediction are easily accessed, including routine laboratory data and medical record information of patients. Methods: We extracted features from patients' routine laboratory results and medical records, including blood routine, biochemical group, blood coagulation routine and other test results, as well as symptoms and medical history information. Samples with a feature loss rate greater than 0.8 were deleted from the original database. Data from 4723 cases were retained, 231 of which were positive for pulmonary embolism. 50 features were retained through the positive and negative statistical hypothesis testing which was used to build the predictive model. In order to avoid identification as majority-class samples caused by the imbalance of sample proportion, we used the method of Synthetic Minority Oversampling Technique (SMOTE) to increase the amount of information on minority samples. Five typical machine learning algorithms were used to model the screening of pulmonary embolism, including Support Vector Machines, Logistic Regression, Random Forest, XGBoost, and Back Propagation Neural Networks. To evaluate model performance, sensitivity, specificity and AUC curve were analyzed as the main evaluation indicators. Furthermore, a baseline model was established using the characteristics of the pulmonary embolism guidelines as a comparison model. Results: We found that XGBoost showed better performance compared to other models, with the highest sensitivity and specificity (0.99 and 0.99, respectively). Moreover, it showed significant improvement in performance compared to the baseline model (sensitivity and specificity were 0.76 and 0.76 respectively). More important, our model showed low missed diagnosis rate (0.46) and high AUC value (0.992). Finally, the calculation time of our model is only about 0.05 s to obtain the possibility of pulmonary embolism. Conclusions: In this study, five machine learning classification models were established to assess the likelihood of patients suffering from pulmonary embolism, and the XGBoost model most significantly improved the precision, sensitivity, and AUC for pulmonary embolism screening. Collectively, we have established an AI-based model to accurately predict pulmonary embolism at early stage. © 2023","2-s2.0-85183466094"
"Rivard S.","Rivard, Suzanne (7003383915)","7003383915","Unpacking the process of conceptual leaping in the conduct of literature reviews","2024","Journal of Strategic Information Systems","33","1","101822","","","","10.1016/j.jsis.2024.101822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185537507&doi=10.1016%2fj.jsis.2024.101822&partnerID=40&md5=c79ef09c14be9d2e9f316361770aa4ba","Literature reviews serve diverse purposes, including description, understanding, explanation, and testing. Traditionally – before online databases, full-text search availability, and AI-based search tools – identifying relevant sources might have been considered a valuable contribution. However, top-tier information systems (IS) journals now demand more than descriptive reviews; they require authors to move beyond summarizing existing knowledge toward proposing innovative research directions, important research questions, new concepts, and interesting linkages among concepts. Despite adhering to rigorous methodological guidelines, many authors struggle to make conceptual leaps, that is, to elevate their literature reviews beyond description, to achieve a profound understanding, to provide explanations, or to develop a model. Authors may mistakenly prioritize hard work – like thorough literature search, analysis, and organization – over hard thinking, which is crucial for advancing theoretical contributions. With this in mind, I adopt the view that the literature is indeed qualitative data. I suggest that approaches that help make conceptual leaps in qualitative research can benefit literature review authors searching for inconsistencies in the extant literature and developing new questions, concepts, and linkages. Drawing upon qualitative research (Klag, M., and Langley, A., 2013. Approaching the conceptual leap in qualitative research. International Journal of Management Reviews. 15 (2), 149–166.), I unpack the process of conceptual leaping in the conduct of literature reviews. This process involves navigating dialectic tensions between knowing and not knowing, engagement and detachment, deliberation and serendipity, and self-expression and social connection. Effectively managing these tensions can help authors increase the impact and innovativeness of their literature reviews. © 2024 The Author(s)","2-s2.0-85185537507"
"Panagoulias D.P.; Virvou M.; Tsihrintzis G.A.","Panagoulias, Dimitrios P. (57302923100); Virvou, Maria (7003569675); Tsihrintzis, George A. (7003361233)","57302923100; 7003569675; 7003361233","Augmenting Large Language Models with Rules for Enhanced Domain-Specific Interactions: The Case of Medical Diagnosis","2024","Electronics (Switzerland)","13","2","320","","","","10.3390/electronics13020320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183441231&doi=10.3390%2felectronics13020320&partnerID=40&md5=d6991e0ccf64c951809d74308cd320cb","In this paper, we present a novel Artificial Intelligence (AI) -empowered system that enhances large language models and other machine learning tools with rules to provide primary care diagnostic advice to patients. Specifically, we introduce a novel methodology, represented through a process diagram, which allows the definition of generative AI processes and functions with a focus on the rule-augmented approach. Our methodology separates various components of the generative AI process as blocks that can be used to generate an implementation data flow diagram. Building upon this framework, we utilize the concept of a dialogue process as a theoretical foundation. This is specifically applied to the interactions between a user and an AI-empowered software program, which is called “Med|Primary AI assistant” (Alpha Version at the time of writing), and provides symptom analysis and medical advice in the form of suggested diagnostics. By leveraging current advancements in natural language processing, a novel approach is proposed to define a blueprint of domain-specific knowledge and a context for instantiated advice generation. Our approach not only encompasses the interaction domain, but it also delves into specific content that is relevant to the user, offering a tailored and effective AI–user interaction experience within a medical context. Lastly, using an evaluation process based on rules, defined by context and dialogue theory, we outline an algorithmic approach to measure content and responses. © 2024 by the authors.","2-s2.0-85183441231"
"Ouared A.; Amrani M.; Schobbens P.-Y.","Ouared, Abdelkader (57191156064); Amrani, Moussa (55253499700); Schobbens, Pierre-Yves (6603466933)","57191156064; 55253499700; 6603466933","Explainable AI for DBA: Bridging the DBA's experience and machine learning in tuning database systems","2023","Concurrency and Computation: Practice and Experience","35","21","e7698","","","","10.1002/cpe.7698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152072289&doi=10.1002%2fcpe.7698&partnerID=40&md5=75f8c405f5d0643571d3a3b7e1fb4747","Recently artificial intelligence techniques in the database community have become a driver for many database applications. The proposed solution adopting AI in the core database shows that incorporating AI improves the query processing and the self-tuning of database systems. In traditional systems, self-tuning database systems are commonly addressed with heuristics to suggest the physical structures (e.g., creation of indexes and materialized views) that enable the fastest execution of queries. However, existing designer tools do not explain/justify how the system behaves and the reasoning behind tuning activities. Moreover, these tools do not keep the database administrator (DBA) in the loop of the optimization process to trust some of the automatic tuning decisions. To address this problem, we introduce a framework called Explain-Tun that enables to predict and explain self-tuning actions with transparent strategy from historical data using two explicit models, that is, decision tree and random forests. First, we propose AI-based DBMS to explain how to select physical structures and provide decision rules extracted by machine learning (ML) as a designed plug-gable component. Second, a goal-oriented model to keep DBA in the loop of the optimization process in order to manipulate ML models as CRUD entities. Finally, we evaluate our approach on three use cases, results show that bridging the DBA's experience and ML make sense in tuning database systems. © 2023 John Wiley & Sons, Ltd.","2-s2.0-85152072289"
"Singh P.","Singh, Prerna (57194829135)","57194829135","Systematic review of data-centric approaches in artificial intelligence and machine learning","2023","Data Science and Management","6","3","","144","157","13","10.1016/j.dsm.2023.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164330324&doi=10.1016%2fj.dsm.2023.06.001&partnerID=40&md5=eda8366178da6da97f63708058af7101","Artificial intelligence (AI) relies on data and algorithms. State-of-the-art (SOTA) AI smart algorithms have been developed to improve the performance of AI-oriented structures. However, model-centric approaches are limited by the absence of high-quality data. Data-centric AI is an emerging approach for solving machine learning (ML) problems. It is a collection of various data manipulation techniques that allow ML practitioners to systematically improve the quality of the data used in an ML pipeline. However, data-centric AI approaches are not well documented. Researchers have conducted various experiments without a clear set of guidelines. This survey highlights six major data-centric AI aspects that researchers are already using to intentionally or unintentionally improve the quality of AI systems. These include big data quality assessment, data preprocessing, transfer learning, semi-supervised learning, machine ​learning ​operations (MLOps), and the effect of adding more data. In addition, it highlights recent data-centric techniques adopted by ML practitioners. We addressed how adding data might harm datasets and how HoloClean can be used to restore and clean them. Finally, we discuss the causes of technical debt in AI. Technical debt builds up when software design and implementation decisions run into “or outright collide with” business goals and timelines. This survey lays the groundwork for future data-centric AI discussions by summarizing various data-centric approaches. © 2023 Xi'an Jiaotong University","2-s2.0-85164330324"
"De Donato L.; Dirnfeld R.; Somma A.; De Benedictis A.; Flammini F.; Marrone S.; Saman Azari M.; Vittorini V.","De Donato, Lorenzo (57386575200); Dirnfeld, Ruth (57221630132); Somma, Alessandra (57888463500); De Benedictis, Alessandra (57189080499); Flammini, Francesco (57515982400); Marrone, Stefano (57203106891); Saman Azari, Mehdi (57696652500); Vittorini, Valeria (6701381302)","57386575200; 57221630132; 57888463500; 57189080499; 57515982400; 57203106891; 57696652500; 6701381302","Towards AI-assisted digital twins for smart railways: preliminary guideline and reference architecture","2023","Journal of Reliable Intelligent Environments","9","3","","303","317","14","10.1007/s40860-023-00208-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161629381&doi=10.1007%2fs40860-023-00208-6&partnerID=40&md5=488047a776a9a48b09a411d13f6adf12","In the last years, there has been a growing interest in the emerging concept of digital twins (DTs) among software engineers and researchers. DTs not only represent a promising paradigm to improve product quality and optimize production processes, but they also may help enhance the predictability and resilience of cyber-physical systems operating in critical contexts. In this work, we investigate the adoption of DTs in the railway sector, focusing in particular on the role of artificial intelligence (AI) technologies as key enablers for building added-value services and applications related to smart decision-making. In this paper, in particular, we address predictive maintenance which represents one of the most promising services benefiting from the combination of DT and AI. To cope with the lack of mature DT development methodologies and standardized frameworks, we detail a workflow for DT design and development specifically tailored to a predictive maintenance scenario and propose a high-level architecture for AI-enabled DTs supporting such workflow. © 2023, The Author(s).","2-s2.0-85161629381"
"Ahmad K.; Abdelrazek M.; Arora C.; Agrahari Baniya A.; Bano M.; Grundy J.","Ahmad, Khlood (57419307200); Abdelrazek, Mohamed (56080446200); Arora, Chetan (55848706400); Agrahari Baniya, Arbind (57221245914); Bano, Muneera (36661996700); Grundy, John (7102156137)","57419307200; 56080446200; 55848706400; 57221245914; 36661996700; 7102156137","Requirements engineering framework for human-centered artificial intelligence software systems","2023","Applied Soft Computing","143","","110455","","","","10.1016/j.asoc.2023.110455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163544926&doi=10.1016%2fj.asoc.2023.110455&partnerID=40&md5=de91d4822852a3733b100d5ff3c485e6","Context: Artificial intelligence (AI) components used in building software solutions have substantially increased in recent years. However, many of these solutions focus on technical aspects and ignore critical human-centered aspects. Objective: Including human-centered aspects during requirements engineering (RE) when building AI-based software can help achieve more responsible, unbiased, and inclusive AI-based software solutions. Method: In this paper, we present a new framework developed based on human-centered AI guidelines and a user survey to aid in collecting requirements for human-centered AI-based software. We provide a catalog to elicit these requirements and a conceptual model to present them visually. Results: The framework is applied to a case study to elicit and model requirements for enhancing the quality of 360° videos intended for virtual reality (VR) users. Conclusion: We found that our proposed approach helped the project team fully understand the human-centered needs of the project to deliver. Furthermore, the framework helped to understand what requirements need to be captured at the initial stages against later stages in the engineering process of AI-based software. © 2023 The Author(s)","2-s2.0-85163544926"
"Turri V.; Dzombak R.","Turri, Violet (57607576100); Dzombak, Rachel (55959643200)","57607576100; 55959643200","Why We Need to Know More: Exploring the State of AI Incident Documentation Practices","2023","AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society","","","","576","583","7","10.1145/3600211.3604700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173620843&doi=10.1145%2f3600211.3604700&partnerID=40&md5=a855757a54cdb87b87aa0fb969acddc1","To enable the development and use of safe and equitable artificial intelligence (AI) systems, AI engineers must monitor deployed AI systems and learn from past AI incidents where failures have occurred. Around the world, public databases for cataloging AI systems and resulting harms are instrumental in promoting awareness of potential AI harms among policymakers, researchers, and the public. However, despite growing recognition of the potential of AI systems to produce harms, causes of AI systems failure remain elusive and AI incidents continue to occur. For example, incidents of AI bias are frequently reported and discussed, yet biased systems continue to be developed and deployed. This raises the question - how are we learning from documented incidents? What information do we need to analyze AI incidents and develop new AI engineering best practices? This paper examines reporting techniques from a variety of AI stakeholders and across different industries, identifies requirements towards the design of effective AI incident documentation, and proposes policy recommendations for augmenting current practice.  © 2023 Owner/Author.","2-s2.0-85173620843"
"Abdelwahab O.; Belzile F.; Torkamaneh D.","Abdelwahab, Omar (57885341000); Belzile, François (7003587293); Torkamaneh, Davoud (54409587200)","57885341000; 7003587293; 54409587200","Performance analysis of conventional and AI-based variant callers using short and long reads","2023","BMC Bioinformatics","24","1","472","","","","10.1186/s12859-023-05596-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179581544&doi=10.1186%2fs12859-023-05596-3&partnerID=40&md5=ff6e46d53b7524ff95656915dc7fd29a","Background: The accurate detection of variants is essential for genomics-based studies. Currently, there are various tools designed to detect genomic variants, however, it has always been a challenge to decide which tool to use, especially when various major genome projects have chosen to use different tools. Thus far, most of the existing tools were mainly developed to work on short-read data (i.e., Illumina); however, other sequencing technologies (e.g. PacBio, and Oxford Nanopore) have recently shown that they can also be used for variant calling. In addition, with the emergence of artificial intelligence (AI)-based variant calling tools, there is a pressing need to compare these tools in terms of efficiency, accuracy, computational power, and ease of use. Results: In this study, we evaluated five of the most widely used conventional and AI-based variant calling tools (BCFTools, GATK4, Platypus, DNAscope, and DeepVariant) in terms of accuracy and computational cost using both short-read and long-read data derived from three different sequencing technologies (Illumina, PacBio HiFi, and ONT) for the same set of samples from the Genome In A Bottle project. The analysis showed that AI-based variant calling tools supersede conventional ones for calling SNVs and INDELs using both long and short reads in most aspects. In addition, we demonstrate the advantages and drawbacks of each tool while ranking them in each aspect of these comparisons. Conclusion: This study provides best practices for variant calling using AI-based and conventional variant callers with different types of sequencing data. © 2023, The Author(s).","2-s2.0-85179581544"
"Planas E.; Martínez S.; Brambilla M.; Cabot J.","Planas, Elena (34771955200); Martínez, Salvador (57197244754); Brambilla, Marco (57226223274); Cabot, Jordi (8963493600)","34771955200; 57197244754; 57226223274; 8963493600","Modeling and enforcing access control policies in conversational user interfaces","2023","Software and Systems Modeling","22","6","","1925","1944","19","10.1007/s10270-023-01131-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177599009&doi=10.1007%2fs10270-023-01131-3&partnerID=40&md5=831ce323005406610590ef1849883e8b","Conversational user interfaces (CUIs), such as chatbots, are becoming a common component of many software systems. Although they are evolving in many directions (such as advanced language processing features, thanks to new AI-based developments), less attention has been paid to access control and other security concerns associated with CUIs, which may pose a clear risk to the systems they interface with. In this paper, we apply model-driven techniques to model and enforce access-control policies in CUIs. In particular, we present a fully fledged framework to integrate the role-based access-control (RBAC) protocol into CUIs by: (1) modeling a set of access-control rules to specify permissions over the bot resources using a domain-specific language that tailors core RBAC concepts to the CUI domain; and (2) describing a mechanism to show the feasibility of automatically generating the infrastructure to evaluate and enforce the modeled access control policies at runtime. © 2023, The Author(s).","2-s2.0-85177599009"
"Cazzato G.; Capuzzolo M.; Parente P.; Arezzo F.; Loizzi V.; Macorano E.; Marzullo A.; Cormio G.; Ingravallo G.","Cazzato, Gerardo (57216892499); Capuzzolo, Marialessandra (58184319000); Parente, Paola (36907728000); Arezzo, Francesca (57216589749); Loizzi, Vera (6603759718); Macorano, Enrica (57813676800); Marzullo, Andrea (58722880500); Cormio, Gennaro (7005847975); Ingravallo, Giuseppe (57194474667)","57216892499; 58184319000; 36907728000; 57216589749; 6603759718; 57813676800; 58722880500; 7005847975; 57194474667","Chat GPT in Diagnostic Human Pathology: Will It Be Useful to Pathologists? A Preliminary Review with ‘Query Session’ and Future Perspectives","2023","AI (Switzerland)","4","4","","1010","1022","12","10.3390/ai4040051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179844098&doi=10.3390%2fai4040051&partnerID=40&md5=fb23936aab0f430fc77042e50e99eb27","The advent of Artificial Intelligence (AI) has in just a few years supplied multiple areas of knowledge, including in the medical and scientific fields. An increasing number of AI-based applications have been developed, among which conversational AI has emerged. Regarding the latter, ChatGPT has risen to the headlines, scientific and otherwise, for its distinct propensity to simulate a ‘real’ discussion with its interlocutor, based on appropriate prompts. Although several clinical studies using ChatGPT have already been published in the literature, very little has yet been written about its potential application in human pathology. We conduct a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, using PubMed, Scopus and the Web of Science (WoS) as databases, with the following keywords: ChatGPT OR Chat GPT, in combination with each of the following: pathology, diagnostic pathology, anatomic pathology, before 31 July 2023. A total of 103 records were initially identified in the literature search, of which 19 were duplicates. After screening for eligibility and inclusion criteria, only five publications were ultimately included. The majority of publications were original articles (n = 2), followed by a case report (n = 1), letter to the editor (n = 1) and review (n = 1). Furthermore, we performed a ‘query session’ with ChatGPT regarding pathologies such as pigmented skin lesions, malignant melanoma and variants, Gleason’s score of prostate adenocarcinoma, differential diagnosis between germ cell tumors and high grade serous carcinoma of the ovary, pleural mesothelioma and pediatric diffuse midline glioma. Although the premises are exciting and ChatGPT is able to co-advise the pathologist in providing large amounts of scientific data for use in routine microscopic diagnostic practice, there are many limitations (such as data of training, amount of data available, ‘hallucination’ phenomena) that need to be addressed and resolved, with the caveat that an AI-driven system should always provide support and never a decision-making motive during the histopathological diagnostic process. © 2023 by the authors.","2-s2.0-85179844098"
"Bereska J.I.; Marquering H.; Besselink M.; Stoker J.; Verpalen I.","Bereska, Jacqueline Isabel (58669821500); Marquering, Henk (57217239823); Besselink, Marc (57214401117); Stoker, Jaap (7102180889); Verpalen, Inez (57203304107)","58669821500; 57217239823; 57214401117; 7102180889; 57203304107","Improving the Reliability of Medical Diagnostic Models through Rule-Based Decision Deferral","2023","Proceedings of the Inaugural 2023 Summer Symposium Series 2023","","","","122","126","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175402102&partnerID=40&md5=93a29e19db3aae5676c47497447aeb10","Pancreatic ductal adenocarcinoma (PDAC) is a highly lethal cancer, and accurate assessment of tumor resectability is crucial for determining appropriate treatment. AI-based models have shown promise in classifying tumor resectability, but reliability concerns have impeded clinical implementation. We propose extending the AI-based VasQNet model for classifying tumor resectability on AI-generated segmentations of computed tomography scans (CTs) to improve the models’ reliability. This extension allows VasQNet to defer decisions when the AI-generated segmentations violate pre-established rules on vascular anatomy, tumor location, and tumor size. We conducted experiments using CTs of (borderline) resectable and non-resectable PDAC patients. We evaluated the performance of the baseline VasQNet and the extended VasQNet with rule-based decision deferral (RBDD) by comparing their classifications to a ground-truth provided by a radiologist, employing agreement as a metric. Our results demonstrate that the extended VasQNet achieved a significantly higher agreement (90%) with the radiologist’s classification than the baseline VasQNet (67%). Notably, 17/31 (54%) deferred decisions would have been incorrect had they not been deferred. Our study demonstrates the effectiveness of RBDD in improving the reliability of clinical diagnostic models through the exemplification of VasQNet. In conclusion, RBDD can enhance the reliability of clinical diagnostics models, facilitating integration into clinical practice. The documented code is available on GitHub (https://github.com/PHAIR-Consortium/Vessel- Involvement-Quantifier). © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85175402102"
"El-Sappagh S.; Alonso-Moral J.M.; Abuhmed T.; Ali F.; Bugarín-Diz A.","El-Sappagh, Shaker (55233800700); Alonso-Moral, Jose M. (58258461100); Abuhmed, Tamer (27067512200); Ali, Farman (56645835400); Bugarín-Diz, Alberto (55910844200)","55233800700; 58258461100; 27067512200; 56645835400; 55910844200","Trustworthy artificial intelligence in Alzheimer’s disease: state of the art, opportunities, and challenges","2023","Artificial Intelligence Review","56","10","","11149","11296","147","10.1007/s10462-023-10415-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150219301&doi=10.1007%2fs10462-023-10415-5&partnerID=40&md5=f65fd5339a5260ebe0bc847bfeb3ac9d","Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017–2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer’s Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85150219301"
"Dutta N.; Dhar D.","Dutta, Neelarnab (57226311426); Dhar, Debayan (55437793800)","57226311426; 55437793800","Investigating Usability of Conversational User Interfaces for Integrated System-Physical Interactions: A Medical Device Perspective","2024","International Journal of Human-Computer Interaction","","","","","","","10.1080/10447318.2023.2298534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181454811&doi=10.1080%2f10447318.2023.2298534&partnerID=40&md5=13607dd7068a881d1628448228929385","The use of Conversational User Interfaces (CUIs) as human-machine interfaces in AI-infused systems has become increasingly popular. However, the existing design guidelines for CUIs are inadequate for meeting the complex interaction requirements of applications involving integrated System-Physical Interaction. In this study, the real-life context of using CUIs as the front-end of AI-enabled medical devices is examined, investigating interaction and usability issues in clinical task operations. Voice- and text-based CUIs were tested with 40 participants to perform clinical tasks. Based on user testing results, a team of seven experts identified 116 unique usability issues and synthesized 16 heuristics using a multilevel thematic coding process. These heuristics were compared to past guidelines to assess their alignment and novelty. Further, 12 usability experts evaluated the heuristics across various clinical systems. The study established that the proposed 16 heuristics provide comprehensive guidance for designing and evaluating CUIs, addressing a wide range of usability requirements. © 2024 Taylor & Francis Group, LLC.","2-s2.0-85181454811"
"Saenz A.D.; Harned Z.; Banerjee O.; Abràmoff M.D.; Rajpurkar P.","Saenz, Agustina D. (56722391100); Harned, Zach (57935048200); Banerjee, Oishi (57222081001); Abràmoff, Michael D. (6602158360); Rajpurkar, Pranav (57056352800)","56722391100; 57935048200; 57222081001; 6602158360; 57056352800","Autonomous AI systems in the face of liability, regulations and costs","2023","npj Digital Medicine","6","1","185","","","","10.1038/s41746-023-00929-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173624008&doi=10.1038%2fs41746-023-00929-1&partnerID=40&md5=7148726154031625bc673b18cf97cd4b","Autonomous AI systems in medicine promise improved outcomes but raise concerns about liability, regulation, and costs. With the advent of large-language models, which can understand and generate medical text, the urgency for addressing these concerns increases as they create opportunities for more sophisticated autonomous AI systems. This perspective explores the liability implications for physicians, hospitals, and creators of AI technology, as well as the evolving regulatory landscape and payment models. Physicians may be favored in malpractice cases if they follow rigorously validated AI recommendations. However, AI developers may face liability for failing to adhere to industry-standard best practices during development and implementation. The evolving regulatory landscape, led by the FDA, seeks to ensure transparency, evaluation, and real-world monitoring of AI systems, while payment models such as MPFS, NTAP, and commercial payers adapt to accommodate them. The widespread adoption of autonomous AI systems can potentially streamline workflows and allow doctors to concentrate on the human aspects of healthcare. © 2023, Springer Nature Limited.","2-s2.0-85173624008"
"Coppock H.; Nicholson G.; Kiskin I.; Koutra V.; Baker K.; Budd J.; Payne R.; Karoune E.; Hurley D.; Titcomb A.; Egglestone S.; Tendero Cañadas A.; Butler L.; Jersakova R.; Mellor J.; Patel S.; Thornley T.; Diggle P.; Richardson S.; Packham J.; Schuller B.W.; Pigoli D.; Gilmour S.; Roberts S.; Holmes C.","Coppock, Harry (57222152484); Nicholson, George (57202125264); Kiskin, Ivan (57203321835); Koutra, Vasiliki (57219479544); Baker, Kieran (58031642000); Budd, Jobie (57207206009); Payne, Richard (58031138300); Karoune, Emma (57539832600); Hurley, David (58031642100); Titcomb, Alexander (58030623900); Egglestone, Sabrina (58030969800); Tendero Cañadas, Ana (58031138400); Butler, Lorraine (58030969700); Jersakova, Radka (57219786061); Mellor, Jonathon (58030969900); Patel, Selina (57220739328); Thornley, Tracey (11940624500); Diggle, Peter (58870520100); Richardson, Sylvia (58657009900); Packham, Josef (58030799200); Schuller, Björn W. (6603767415); Pigoli, Davide (54895983300); Gilmour, Steven (58870313200); Roberts, Stephen (58870111300); Holmes, Chris (7202410721)","57222152484; 57202125264; 57203321835; 57219479544; 58031642000; 57207206009; 58031138300; 57539832600; 58031642100; 58030623900; 58030969800; 58031138400; 58030969700; 57219786061; 58030969900; 57220739328; 11940624500; 58870520100; 58657009900; 58030799200; 6603767415; 54895983300; 58870313200; 58870111300; 7202410721","Audio-based AI classifiers show no evidence of improved COVID-19 screening over simple symptoms checkers","2024","Nature Machine Intelligence","6","2","","229","242","13","10.1038/s42256-023-00773-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184421962&doi=10.1038%2fs42256-023-00773-8&partnerID=40&md5=85a8431a3ff2ac654ea06f17480aaa36","Recent work has reported that respiratory audio-trained AI classifiers can accurately predict SARS-CoV-2 infection status. However, it has not yet been determined whether such model performance is driven by latent audio biomarkers with true causal links to SARS-CoV-2 infection or by confounding effects, such as recruitment bias, present in observational studies. Here we undertake a large-scale study of audio-based AI classifiers as part of the UK government’s pandemic response. We collect a dataset of audio recordings from 67,842 individuals, with linked metadata, of whom 23,514 had positive polymerase chain reaction tests for SARS-CoV-2. In an unadjusted analysis, similar to that in previous works, AI classifiers predict SARS-CoV-2 infection status with high accuracy (ROC–AUC = 0.846 [0.838–0.854]). However, after matching on measured confounders, such as self-reported symptoms, performance is much weaker (ROC–AUC = 0.619 [0.594–0.644]). Upon quantifying the utility of audio-based classifiers in practical settings, we find them to be outperformed by predictions on the basis of user-reported symptoms. We make best-practice recommendations for handling recruitment bias, and for assessing audio-based classifiers by their utility in relevant practical settings. Our work provides insights into the value of AI audio analysis and the importance of study design and treatment of confounders in AI-enabled diagnostics. © The Author(s) 2024.","2-s2.0-85184421962"
"Li S.; Liu H.; Bian Z.; Fang J.; Huang H.; Liu Y.; Wang B.; You Y.","Li, Shenggui (57847262000); Liu, Hongxin (57928857500); Bian, Zhengda (57224928421); Fang, Jiarui (56670316100); Huang, Haichen (57928722300); Liu, Yuliang (58396300200); Wang, Boxiang (57224937433); You, Yang (57665946100)","57847262000; 57928857500; 57224928421; 56670316100; 57928722300; 58396300200; 57224937433; 57665946100","Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training","2023","ACM International Conference Proceeding Series","","","","766","775","9","10.1145/3605573.3605613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174793354&doi=10.1145%2f3605573.3605613&partnerID=40&md5=91c59630c9a3fd282073a67950e5fbfd","The success of Transformer models has pushed the deep learning model scale to billions of parameters, but the memory limitation of a single GPU has led to an urgent need for training on multi-GPU clusters. However, the best practice for choosing the optimal parallel strategy is still lacking, as it requires domain expertise in both deep learning and parallel computing. The Colossal-AI system addressed the above challenge by introducing a unified interface to scale your sequential code of model training to distributed environments. It supports parallel training methods such as data, pipeline, tensor, and sequence parallelism and is integrated with heterogeneous training and zero redundancy optimizer. Compared to the baseline system, Colossal-AI can achieve up to 2.76 times training speedup on large-scale models. © 2023 Association for Computing Machinery. All rights reserved.","2-s2.0-85174793354"
"Beerends S.; Aydin C.","Beerends, Siri (57347775300); Aydin, Ciano (26631603900)","57347775300; 26631603900","Negotiating the authenticity of AI: how the discourse on AI rejects human indeterminacy","2024","AI and Society","","","","","","","10.1007/s00146-024-01884-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185939821&doi=10.1007%2fs00146-024-01884-5&partnerID=40&md5=3cc22f4bd8b38b197fd195966712c1c0","In this paper, we demonstrate how the language and reasonings that academics, developers, consumers, marketers, and journalists deploy to accept or reject AI as authentic intelligence has far-reaching bearing on how we understand our human intelligence and condition. The discourse on AI is part of what we call the “authenticity negotiation process” through which AI’s “intelligence” is given a particular meaning and value. This has implications for scientific theory, research directions, ethical guidelines, design principles, funding, media attention, and the way people relate to and act upon AI. It also has great impact on humanity’s self-image and the way we negotiate what it means to be human, existentially, culturally, politically, and legally. We use a discourse analysis of academic papers, AI education programs, and online discussions to demonstrate how AI itself, as well as the products, services, and decisions delivered by AI systems are negotiated as authentic or inauthentic intelligence. In this negotiation process, AI stakeholders indirectly define and essentialize what being human(like) means. The main argument we will develop is that this process of indirectly defining and essentializing humans results in an elimination of the space for humans to be indeterminate. By eliminating this space and, hence, denying indeterminacy, the existential condition of the human being is jeopardized. Rather than re-creating humanity in AI, the AI discourse is re-defining what it means to be human and how humanity is valued and should be treated. © The Author(s) 2024.","2-s2.0-85185939821"
"Schütze D.; Holtz S.; Neff M.C.; Köhler S.M.; Schaaf J.; Frischen L.S.; Sedlmayr B.; Müller B.S.","Schütze, Dania (57221382749); Holtz, Svea (57282782800); Neff, Michaela C. (57226286644); Köhler, Susanne M. (57197025666); Schaaf, Jannik (57193580502); Frischen, Lena S. (58512685000); Sedlmayr, Brita (55807934600); Müller, Beate S. (55435743500)","57221382749; 57282782800; 57226286644; 57197025666; 57193580502; 58512685000; 55807934600; 55435743500","Requirements analysis for an AI-based clinical decision support system for general practitioners: a user-centered design process","2023","BMC Medical Informatics and Decision Making","23","1","144","","","","10.1186/s12911-023-02245-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166251260&doi=10.1186%2fs12911-023-02245-w&partnerID=40&md5=cd506b978208f94423f1caf1602309de","Background: As the first point of contact for patients with health issues, general practitioners (GPs) are frequently confronted with patients presenting with non-specific symptoms of unclear origin. This can result in delayed, prolonged or false diagnoses. To accelerate and improve the diagnosis of diseases, clinical decision support systems would appear to be an appropriate tool. The objective of the project ‘Smart physician portal for patients with unclear disease’ (SATURN) is to employ a user-centered design process based on the requirements analysis presented in this paper to develop an artificial Intelligence (AI)-based diagnosis support system that specifically addresses the needs of German GPs. Methods: Requirements analysis for a GP-specific diagnosis support system was conducted in an iterative process with five GPs. First, interviews were conducted to analyze current workflows and the use of digital applications in cases of diagnostic uncertainty (as-is situation). Second, we focused on collecting and prioritizing tasks to be performed by an ideal smart physician portal (to-be situation) in a workshop. We then developed a task model with corresponding user requirements. Results: Numerous GP-specific user requirements were identified concerning the tasks and subtasks: performing data entry (open system, enter patient data), reviewing results (receiving and evaluating results), discussing results (with patients and colleagues), scheduling further diagnostic procedures, referring to specialists (select, contact, make appointments), and case closure. Suggested features particularly concerned the process of screening and assessing results: e.g., the system should focus more on atypical patterns of common diseases than on rare diseases only, display probabilities of differential diagnoses, ensure sources and results are transparent, and mark diagnoses that have already been ruled out. Moreover, establishing a means of using the platform to communicate with colleagues and transferring patient data directly from electronic patient records to the system was strongly recommended. Conclusions: Essential user requirements to be considered in the development and design of a diagnosis system for primary care could be derived from the analysis. They form the basis for mockup-development and system engineering. © 2023, The Author(s).","2-s2.0-85166251260"
"Kotlyar I.; Sharifi T.; Fiksenbaum L.","Kotlyar, Igor (14035796000); Sharifi, Tina (57976348000); Fiksenbaum, Lisa (6602274167)","14035796000; 57976348000; 6602274167","Assessing Teamwork Skills: Can a Computer Algorithm Match Human Experts?","2023","International Journal of Artificial Intelligence in Education","33","4","","955","991","36","10.1007/s40593-022-00318-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142440852&doi=10.1007%2fs40593-022-00318-x&partnerID=40&md5=175e8d8d7fa421f6b981d5266c1bbd56","Teamwork skills are commonly evaluated by human assessors, which can be logistically challenging and resource intensive. Technological advancements provide an opportunity for a new assessment method – virtual behavioural simulations with self-scoring algorithms. This study explores whether a rule-based algorithm can match human assessors at evaluating teamwork skills. 206 undergraduate students completed a virtual simulation assessment, where they interacted with “teammates” (represented by chatbots) using natural language. In this study, students’ teamwork skills were assessed independently by a computer algorithm and two human experts based on the transcripts of their conversations with “teammates” (chatbots). The relative accuracy of these assessments was evaluated against peer- and self-evaluations of teamwork. The assessment scores generated by the algorithm and human experts were highly correlated with each other and were comparable in their ability to predict teamwork. The scores generated by the algorithm were slightly more correlated with peer-evaluations than those generated by human experts (r =.25 and r =.17, respectively; p =.21). The results indicate that AI-based techniques offer a promising method of skill assessment to support learning and acquisition teamwork skills. © 2022, International Artificial Intelligence in Education Society.","2-s2.0-85142440852"
"Ponzoni I.; Páez Prosper J.A.; Campillo N.E.","Ponzoni, Ignacio (6506279296); Páez Prosper, Juan Antonio (58507904200); Campillo, Nuria E. (7003271773)","6506279296; 58507904200; 7003271773","Explainable artificial intelligence: A taxonomy and guidelines for its application to drug discovery","2023","Wiley Interdisciplinary Reviews: Computational Molecular Science","13","6","e1681","","","","10.1002/wcms.1681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165911091&doi=10.1002%2fwcms.1681&partnerID=40&md5=6e57415c85ef14329ee6087c71b6ac6e","Artificial intelligence (AI) is having a growing impact in many areas related to drug discovery. However, it is still critical for their adoption by the medicinal chemistry community to achieve models that, in addition to achieving high performance in their predictions, can be trusty explained to the end users in terms of their knowledge and background. Therefore, the investigation and development of explainable artificial intelligence (XAI) methods have become a key topic to address this challenge. For this reason, a comprehensive literature review about explanation methodologies for AI based models, focused in the field of drug discovery, is provided. In particular, an intuitive overview about each family of XAI approaches, such as those based on feature attribution, graph topologies, or counterfactual reasoning, oriented to a wide audience without a strong background in the AI discipline is introduced. As the main contribution, we propose a new taxonomy of the current XAI methods, which take into account specific issues related with the typical representations and computational problems study in the design of molecules. Additionally, we also present the main visualization strategies designed for supporting XAI approaches in the chemical domain. We conclude with key ideas about each method category, thoroughly providing insightful analysis about the guidelines and potential benefits of their adoption in medical chemistry. This article is categorized under: Data Science > Artificial Intelligence/Machine Learning. © 2023 Wiley Periodicals LLC.","2-s2.0-85165911091"
"Panagoulias D.P.; Virvou M.; Tsihrintzis G.A.","Panagoulias, Dimitrios P. (57302923100); Virvou, Maria (7003569675); Tsihrintzis, George A. (7003361233)","57302923100; 7003569675; 7003361233","A novel framework for artificial intelligence explainability via the Technology Acceptance Model and Rapid Estimate of Adult Literacy in Medicine using machine learning","2024","Expert Systems with Applications","248","","123375","","","","10.1016/j.eswa.2024.123375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184472514&doi=10.1016%2fj.eswa.2024.123375&partnerID=40&md5=e84b05548bd9b294583cbe19c3cf97a2","The significant proliferation of AI-empowered systems and machine learning (ML) across various examined domains underscores the vital necessity for comprehensive and customised explainability frameworks to lead to usable and trustworthy systems. Especially in the medical domain, where validation of methodologies and outcomes is as important as the adoption rate of such systems, the requirements of the depth and the level of abstraction of the explainability are particularly important and necessitate a systemic approach to ensure a proper definition. Explainability and interpretability are important usability and trustworthiness properties of AI-empowered systems and, as such, constitute important factors for technology acceptance. In this paper, we propose a novel framework for explainability requirements in AI-empowered systems using the Technology Acceptance Model (TAM). This framework employs targeted ML (hierarchical clustering, k-means or other) to acquire a user model for personalised, multi-layered explainability. Our novel framework integrates a rule-based system, which guides the degree of trustworthiness to be achieved based on user perception and AI literacy level. We test this methodology in the case of AI-empowered medical systems to (1) assess and quantify the doctors’ abilities and familiarisation with technology and AI, (2) generate layers of personalised explainability based on user ability and user needs in terms of trustworthiness and (3) provide the necessary environment for transparency and validation. To assess and quantify the doctors’ abilities we have considered Rapid Estimate of Adult Literacy in Medicine (REALM) a tool commonly used in the medical domain to bridge the communication gap between patients and doctors. © 2024 Elsevier Ltd","2-s2.0-85184472514"
"Geijs D.J.; Dooper S.; Aswolinskiy W.; Hillen L.M.; Amir A.L.; Litjens G.","Geijs, Daan J. (57190395967); Dooper, Stephan (58479336400); Aswolinskiy, Witali (56593194200); Hillen, Lisa M. (57126190900); Amir, Avital L. (23048788000); Litjens, Geert (36622356600)","57190395967; 58479336400; 56593194200; 57126190900; 23048788000; 36622356600","Detection and subtyping of basal cell carcinoma in whole-slide histopathology using weakly-supervised learning","2024","Medical Image Analysis","93","","103063","","","","10.1016/j.media.2023.103063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182405222&doi=10.1016%2fj.media.2023.103063&partnerID=40&md5=bdd45d07f120efccb080eab7f5722f32","The frequency of basal cell carcinoma (BCC) cases is putting an increasing strain on dermatopathologists. BCC is the most common type of skin cancer, and its incidence is increasing rapidly worldwide. AI can play a significant role in reducing the time and effort required for BCC diagnostics and thus improve the overall efficiency of the process. To train such an AI system in a fully-supervised fashion however, would require a large amount of pixel-level annotation by already strained dermatopathologists. Therefore, in this study, our primary objective was to develop a weakly-supervised for the identification of basal cell carcinoma (BCC) and the stratification of BCC into low-risk and high-risk categories within histopathology whole-slide images (WSI). We compared Clustering-constrained Attention Multiple instance learning (CLAM) with StreamingCLAM and hypothesized that the latter would be the superior approach. A total of 5147 images were used to train and validate the models, which were subsequently tested on an internal set of 949 images and an external set of 183 images. The labels for training were automatically extracted from free-text pathology reports using a rule-based approach. All data has been made available through the COBRA dataset. The results showed that both the CLAM and StreamingCLAM models achieved high performance for the detection of BCC, with an area under the ROC curve (AUC) of 0.994 and 0.997, respectively, on the internal test set and 0.983 and 0.993 on the external dataset. Furthermore, the models performed well on risk stratification, with AUC values of 0.912 and 0.931, respectively, on the internal set, and 0.851 and 0.883 on the external set. In every single metric the StreamingCLAM model outperformed the CLAM model or is on par. The performance of both models was comparable to that of two pathologists who scored 240 BCC positive slides. Additionally, in the public test set, StreamingCLAM demonstrated a comparable AUC of 0.958, markedly superior to CLAM's 0.803. This difference was statistically significant and emphasized the strength and better adaptability of the StreamingCLAM approach. © 2023","2-s2.0-85182405222"
"Scannapieco S.; Tomazzoli C.","Scannapieco, Simone (36657754900); Tomazzoli, Claudio (56340126700)","36657754900; 56340126700","Cnosso, a novel method for business document automation based on open information extraction","2024","Expert Systems with Applications","245","","123038","","","","10.1016/j.eswa.2023.123038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181832527&doi=10.1016%2fj.eswa.2023.123038&partnerID=40&md5=f0b5bd2910e77049dccb8fbe476993ac","The state-of-the-art in automated processing of unstructured business documents has evolved from manual labor to advanced AI systems in the span of mere decades. Such systems involve learning techniques, rule or clause sets, neural models – either used alone or in combination – for the extraction to work. As an example, rule-based processes operate on a perceived layout or positioning of the information, whereas model-based frameworks adopt a semantic, and often uninspectable, approach. Verb-Based Semantic Role Labeling (VBSRL) is a novel system presented in a former paper that uses a hybrid foundation to inform the extraction phase via a set of rules modeling natural language. We propose a new VBSRL-based document processing method, aided by valuable and innovative architectural choices, which has been implemented for the Italian language and experimented upon with promising results. Even in its infancy, in fact, the first implementation of this system shows better results than comparable IE solutions, obtaining an aggregate, average F-measure of nearly 79%. © 2023 Elsevier Ltd","2-s2.0-85181832527"
"Kolivand M.; Al-jumeily D.","Kolivand, Mahyar (57205327555); Al-jumeily, Diyah (58783560400)","57205327555; 58783560400","Pre-planning for Plastic Surgery Using Machine Learning: A Proof of Concept","2024","Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","538 LNICST","","","44","57","13","10.1007/978-3-031-50215-6_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180794354&doi=10.1007%2f978-3-031-50215-6_4&partnerID=40&md5=968c23b22e62f6ce776b6c42438ea97e","This paper presents a proof-of-concept study on AI-based pre-surgery planning in plastic surgery. The study addresses the challenge of technique selection by developing an AI-driven system that utilises machine learning algorithms to analyse patient-specific data and historical outcomes. By comparing and evaluating diverse inputs, the system generates detailed results for each technique, providing surgeons with valuable insights into expected outcomes. This enhances decision-making during pre-surgery planning and improves surgical precision. The system’s development involved addressing challenges related to data availability, algorithm selection, and interpretability. Preoperative images will be processed using advanced computer vision algorithms to extract relevant features. A Convolutional Neural Network (CNN) architecture predicted technique-specific outcomes based on the extracted features. The validation included comparing predictions against ground truth data and expert evaluations. Feedback from plastic surgery practitioners will be collected to assess usability and practicality. Ethical guidelines will be strictly followed to ensure patient data protection and address potential biases. The successful implementation of the proof of concept demonstrates the potential of AI integration in pre-surgery planning for plastic surgery. By empowering surgeons with technique-specific insights, the system enhances decision-making, ultimately improving patient care and treatment outcomes. Future work involves expanding the dataset, considering additional variables, and conducting prospective clinical trials to validate the system’s real-world impact. © 2024, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","2-s2.0-85180794354"
"Zowghi D.; Bano M.; Borg M.","Zowghi, Didar (6602925723); Bano, Muneera (36661996700); Borg, Markus (37103431600)","6602925723; 36661996700; 37103431600","What's Missing in Requirements Engineering for Responsible AI?","2023","IEEE Software","40","6","","11","15","4","10.1109/MS.2023.3302934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179007786&doi=10.1109%2fMS.2023.3302934&partnerID=40&md5=ff881d3a109a4fe42bffcc4b42d3ccf5","The rapid evolution of artificial intelligence (AI) has catalyzed a multifaceted discourse in the software engineering (SE) community. The crux of this dialogue is to pinpoint the distinct attributes of AI systems that necessitate tailored SE methodologies. While classical SE techniques have proved effective across a spectrum of systems, there's an emerging consensus: AI introduces distinct challenges, compelling us to rethink some foundational principles of traditional SE.1 Central to AI systems is the imperative to design models, curate training datasets, govern system autonomy, and embed ethical guidelines. Two salient features of AI operations include continuous learning from evolving datasets and human feedback while dealing with the increased uncertainties and risks due to system autonomy.  © 1984-2012 IEEE.","2-s2.0-85179007786"
"Carroll M.; Chan A.; Ashton H.; Krueger D.","Carroll, Micah (57218718591); Chan, Alan (57222059630); Ashton, Henry (57221252268); Krueger, David (57194869490)","57218718591; 57222059630; 57221252268; 57194869490","Characterizing Manipulation from AI Systems","2023","ACM International Conference Proceeding Series","","","6","","","","10.1145/3617694.3623226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177860828&doi=10.1145%2f3617694.3623226&partnerID=40&md5=8e1433d690582791c2aa66d63ddbebb0","Manipulation is a concern in many domains, such as social media, advertising, and chatbots. As AI systems mediate more of our digital interactions, it is important to understand the degree to which AI systems might manipulate humans without the intent of the system designers. Our work clarifies challenges in defining and measuring this kind of manipulation from AI systems. Firstly, we build upon prior literature on manipulation and characterize the space of possible notions of manipulation, which we find to depend upon the concepts of incentives, intent, covertness, and harm. We review proposals on how to operationalize each concept and we outline challenges in including each concept in a definition of manipulation. Second, we discuss the connections between manipulation and related concepts, such as deception and coercion. We then analyze how our characterization of manipulation applies to recommender systems and language models, and give a brief overview of the regulation of manipulation in other domains. While some progress has been made in defining and measuring manipulation from AI systems, many gaps remain. In the absence of a consensus definition and reliable tools for measurement, we cannot rule out the possibility that AI systems learn to manipulate humans without the intent of the system designers. Manipulation could pose a significant threat to human autonomy and precautionary actions to mitigate it are likely warranted. © 2023 Owner/Author.","2-s2.0-85177860828"
"Bratu D.-V.; Zolya M.-A.; Moraru S.-A.","Bratu, Dragoș-Vasile (57216355951); Zolya, Maria-Alexandra (57275054600); Moraru, Sorin-Aurel (22433787000)","57216355951; 57275054600; 22433787000","RoboCoV Cleaner: An Indoor Autonomous UV-C Disinfection Robot with Advanced Dual-Safety Systems","2024","Sensors","24","3","974","","","","10.3390/s24030974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184655505&doi=10.3390%2fs24030974&partnerID=40&md5=c740c6a61d5973dac1c0e4dff049be56","In the face of today’s ever-evolving global health landscape and ambient assisted living (AAL), marked by the persistent emergence of novel viruses and diseases that impact vulnerable categories and individual safety, the need for innovative disinfection solutions has surged to unprecedented levels. In pursuit of advancing the field of autonomous UV-C disinfection robotics, we conducted two comprehensive state-of-the-art analyses: the first one in the literature and the second one in existing commercial disinfection robots to identify current challenges. Of all of the challenges, we consider the most outstanding ones to be safeguarding humans and animals and understanding the surroundings while operating the disinfection process challenges that we will address in this article. While UV-C lamps have demonstrated their effectiveness in sterilizing air and surfaces, the field of autonomous UV-C disinfection robotics represents a critical domain that requires advancement, particularly in safeguarding the wellbeing of humans and animals during operation. Operating UV-C disinfection robots in close proximity to humans or animals introduces inherent risks, and existing disinfection robots often fall short in incorporating advanced safety systems. In response to these challenges, we propose the RoboCoV Cleaner—an indoor autonomous UV-C disinfection robot equipped with an advanced dual and redundant safety system. This novel approach incorporates multiple passive infrared (PIR) sensors and AI object detection on a 360-degree camera. Under our test, the dual-redundant system reached more than 90% when detecting humans with high accuracy using the AI system 99% up to 30 m away in a university hallway (different light conditions) combined with the PIR system (with lower accuracy). The PIR system was proved to be a redundant system for uninterrupted operation during communication challenges, ensuring continuous sensor information collection with a swift response time of 50 ms (image processing within 200 ms). It empowers the robot to detect and react to human presence, even under challenging conditions, such as when individuals wear masks, in complete darkness, under UV light, or in environments with blurred visual conditions. In our test, the detection system performed outstandingly well with up to 99% detection rate of humans. Beyond safety features, the RoboCoV Cleaner can identify objects in its surroundings. This capability empowers the robot to discern objects affected by UV-C light, enabling it to apply specialized rules for targeted disinfection. The proposed system exhibits a wide range of capabilities beyond its core purpose of disinfection, making it suitable for healthcare facilities, universities, conference venues, and hospitals. Its implementation has the ability to improve significantly human safety and protect people. By showcasing the RoboCoV Cleaner’s safety-first approach and adaptability, we aim to set a new benchmark for UV-C disinfection robots, promoting clean and secure environments while protecting vulnerable people, even in challenging scenarios. © 2024 by the authors.","2-s2.0-85184655505"
"Nogaroli R.; Faleiros Júnior J.L.M.","Nogaroli, Rafaella (57260610400); Faleiros Júnior, José Luiz de Moura (58782415100)","57260610400; 58782415100","Ethical Challenges of Artificial Intelligence in Medicine and the Triple Semantic Dimensions of Algorithmic Opacity with Its Repercussions to Patient Consent and Medical Liability","2024","Law, Governance and Technology Series","58","","","229","248","19","10.1007/978-3-031-41264-6_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180707621&doi=10.1007%2f978-3-031-41264-6_12&partnerID=40&md5=08a8217b1f83a5291bf11f8a5a60ea47","Artificial intelligence algorithms have the potential to diagnose some types of skin cancer or to identify specific heart-rhythm abnormalities as well as (or even better) than board-certified dermatologists and cardiologists. However, one of the biggest fears in the healthcare sector in the Era of AI in Medicine is the so-called black box medicine, given the obscurity in the way information is processed by algorithms. More broadly, it is observed that there are three different semantic dimensions of algorithmic opacity relevant to Medicine: (1) epistemic opacity for the insufficient physicians understanding of the rules an AI system is applying to make predictions and decisions; (2) opacity for the lack of medical disclosure about the AI systems to support clinical decisions and patient’s unawareness that automated decision-making are being carried out with their personal data; (3) explanatory opacity for the unsatisfactory explanation to patients about the technology used to support professional decision-making. Therefore, the aim of this study is to analyze each type of opacity, considering hypothetical scenarios and its repercussions in terms of medical malpractice and patient’s informed consent. From this, it will be defined ethical challenges of using AI in the healthcare sector and the importance of medical education. © 2024, The Author(s).","2-s2.0-85180707621"
"Wang Z.; Ren M.; Gao D.; Li Z.","Wang, Zhenhua (57222010756); Ren, Ming (35753530300); Gao, Dong (35753006900); Li, Zhuang (57732886000)","57222010756; 35753530300; 35753006900; 57732886000","A Zipf's law-based text generation approach for addressing imbalance in entity extraction","2023","Journal of Informetrics","17","4","101453","","","","10.1016/j.joi.2023.101453","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169071768&doi=10.1016%2fj.joi.2023.101453&partnerID=40&md5=848c639ef9ebdc43e1fda925fb82d967","Entity extraction is critical in the intelligent advancement across diverse domains. Nevertheless, a challenge to its effectiveness arises from the data imbalance, where certain entities are common while others are scarce. To address this issue, this study proposes a novel text generation approach that harnesses Zipf's law, which is a powerful tool from informetrics for studying human language. By employing characteristics of Zipf's law, words within the documents are classified as common and rare ones. Subsequently, sentences are classified into common and rare ones, and are further processed by text generation models accordingly. Rare entities within the generated sentences are then labeled using human-designed rules, serving as a supplement to the raw dataset, thereby mitigating the imbalance problem. The study presents a case of extracting entities from technical documents, and the extensive experimental results on two datasets prove the effectiveness of the proposed method. Furthermore, the significance and potential of Zipf's law in driving the progress of artificial intelligence (AI) is discussed, broadening the scope and coverage of informetrics. By incorporating the foundational principles of informetrics into text generation, this study showcases the pivotal role of informetrics in shaping the design and developmental of AI systems. © 2023","2-s2.0-85169071768"
"Wang Y.; Zhang R.; Zhang S.; Guo L.; Zhou Q.; Zhao B.; Mo X.; Yang Q.; Huang Y.; Li K.; Fan Y.; Huang L.; Zhou F.","Wang, Yan (56431257100); Zhang, Ruochi (57196041167); Zhang, Shengde (58416363200); Guo, Liming (58414064800); Zhou, Qiong (58414828900); Zhao, Bowen (58590641000); Mo, Xiaotong (58415597300); Yang, Qian (58597380800); Huang, Yajuan (58414829000); Li, Kewei (57899757100); Fan, Yusi (57221785295); Huang, Lan (55770288600); Zhou, Fengfeng (55634210800)","56431257100; 57196041167; 58416363200; 58414064800; 58414828900; 58590641000; 58415597300; 58597380800; 58414829000; 57899757100; 57221785295; 55770288600; 55634210800","OCMR: A comprehensive framework for optical chemical molecular recognition","2023","Computers in Biology and Medicine","163","","107187","","","","10.1016/j.compbiomed.2023.107187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163775204&doi=10.1016%2fj.compbiomed.2023.107187&partnerID=40&md5=5ad386da5157b66f2e58b106dc491000","Artificial intelligence (AI) has achieved significant progress in the field of drug discovery. AI-based tools have been used in all aspects of drug discovery, including chemical structure recognition. We propose a chemical structure recognition framework, Optical Chemical Molecular Recognition (OCMR), to improve the data extraction capability in practical scenarios compared with the rule-based and end-to-end deep learning models. The proposed OCMR framework enhances the recognition performances via the integration of local information in the topology of molecular graphs. OCMR handles complex tasks like non-canonical drawing and atomic group abbreviation and substantially improves the current state-of-the-art results on multiple public benchmark datasets and one internally curated dataset. © 2023 Elsevier Ltd","2-s2.0-85163775204"
"Palmerini E.","Palmerini, Erica (56020482600)","56020482600","AI systems and the issue of liability in the European and national regulatory strategies","2023","Tort Liability and Autonomous Systems Accidents: Common and Civil Law Perspectives","","","","63","96","33","10.4337/9781802203844.00007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178988939&doi=10.4337%2f9781802203844.00007&partnerID=40&md5=705c1928ab181707af5261ccfe7ce406","This chapter focuses on the regulatory strategies undertaken at the European and national level with regard to the issue of liability for damages caused by cyber-physical systems. Attention will be devoted to the most recent attempts of identifying the appropriate target for regulation. This target seems to have shifted from the narrower field of robotics to the wider domain of AI. In the most recent documents the regulatory effort addresses the design and architecture of autonomous systems based on AI. An overview of the legislative endeavour in this field aims at evaluating its main policy goals, along with analysing the operational rules suggested by these policy goals to address the problem of liability. These are examined against the backdrop of the flaws within current liability regimes which are challenged by the special nature of autonomous systems, and questions the actual need for introducing new regulatory schemes. © Edward Elgar Publishing 2023.","2-s2.0-85178988939"
"Papadakis T.; Christou I.T.; Ipektsidis C.; Soldatos J.; Amicone A.","Papadakis, Thanasis (58654013500); Christou, Ioannis T. (6602111061); Ipektsidis, Charalampos (57188802176); Soldatos, John (8662280800); Amicone, Alessandro (58653579000)","58654013500; 6602111061; 57188802176; 8662280800; 58653579000","Explainable and transparent artificial intelligence for public policymaking","2024","Data and Policy","6","","e10","","","","10.1017/dap.2024.3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185783515&doi=10.1017%2fdap.2024.3&partnerID=40&md5=a3f781ba0df1aff50603a2e1f6c98190","Nowadays public policymakers are offered with opportunities to take data-driven evidence-based decisions by analyzing the very large volumes of policy-related data that are generated through different channels (e.g., e-services, mobile apps, social media). Machine learning (ML) and artificial intelligence (AI) tehcnologies ease and automate the analysis of large policy-related datasets, which helps policymakers to realize a shift toward data-driven decisions. Nevertheless, the deployment and use of AI tools for public policy development is also associated with significant technical, political, and operation challenges. For instance, AI-based policy development solutions must be transparent and explainable to policymakers, while at the same time adhering to the mandates of emerging regulations such as the AI Act of the European Union. This paper introduces some of the main technical, operational, regulatory compliance challenges of AI-based policymaking. Accordingly, it introduces technological solutions for overcoming them, including: (i) a reference architecture for AI-based policy development, (ii) a virtualized cloud-based tool for the specification and implementation of ML-based data-driven policies, (iii) a ML framework that enables the development of transparent and explainable ML models for policymaking, and (iv) a set of guidelines for using the introduced technical solutions to achieve regulatory compliance. The paper ends up illustrating the validation and use of the introduced solutions in real-life public policymaking cases for various local governments.  © 2024 The Author(s). Published by Cambridge University Press.","2-s2.0-85185783515"
"Hua D.; Petrina N.; Young N.; Cho J.-G.; Poon S.K.","Hua, David (58145423100); Petrina, Neysa (58412925500); Young, Noel (7402413046); Cho, Jin-Gun (39061078100); Poon, Simon K. (16301806100)","58145423100; 58412925500; 7402413046; 39061078100; 16301806100","Understanding the factors influencing acceptability of AI in medical imaging domains among healthcare professionals: A scoping review","2024","Artificial Intelligence in Medicine","147","","102698","","","","10.1016/j.artmed.2023.102698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180484311&doi=10.1016%2fj.artmed.2023.102698&partnerID=40&md5=392af1a0f780794b2bf9d351a18c6830","Background: Artificial intelligence (AI) technology has the potential to transform medical practice within the medical imaging industry and materially improve productivity and patient outcomes. However, low acceptability of AI as a digital healthcare intervention among medical professionals threatens to undermine user uptake levels, hinder meaningful and optimal value-added engagement, and ultimately prevent these promising benefits from being realised. Understanding the factors underpinning AI acceptability will be vital for medical institutions to pinpoint areas of deficiency and improvement within their AI implementation strategies. This scoping review aims to survey the literature to provide a comprehensive summary of the key factors influencing AI acceptability among healthcare professionals in medical imaging domains and the different approaches which have been taken to investigate them. Methods: A systematic literature search was performed across five academic databases including Medline, Cochrane Library, Web of Science, Compendex, and Scopus from January 2013 to September 2023. This was done in adherence to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines. Overall, 31 articles were deemed appropriate for inclusion in the scoping review. Results: The literature has converged towards three overarching categories of factors underpinning AI acceptability including: user factors involving trust, system understanding, AI literacy, and technology receptiveness; system usage factors entailing value proposition, self-efficacy, burden, and workflow integration; and socio-organisational-cultural factors encompassing social influence, organisational readiness, ethicality, and perceived threat to professional identity. Yet, numerous studies have overlooked a meaningful subset of these factors that are integral to the use of medical AI systems such as the impact on clinical workflow practices, trust based on perceived risk and safety, and compatibility with the norms of medical professions. This is attributable to reliance on theoretical frameworks or ad-hoc approaches which do not explicitly account for healthcare-specific factors, the novelties of AI as software as a medical device (SaMD), and the nuances of human-AI interaction from the perspective of medical professionals rather than lay consumer or business end users. Conclusion: This is the first scoping review to survey the health informatics literature around the key factors influencing the acceptability of AI as a digital healthcare intervention in medical imaging contexts. The factors identified in this review suggest that existing theoretical frameworks used to study AI acceptability need to be modified to better capture the nuances of AI deployment in healthcare contexts where the user is a healthcare professional influenced by expert knowledge and disciplinary norms. Increasing AI acceptability among medical professionals will critically require designing human-centred AI systems which go beyond high algorithmic performance to consider accessibility to users with varying degrees of AI literacy, clinical workflow practices, the institutional and deployment context, and the cultural, ethical, and safety norms of healthcare professions. As investment into AI for healthcare increases, it would be valuable to conduct a systematic review and meta-analysis of the causal contribution of these factors to achieving high levels of AI acceptability among medical professionals. © 2023 The Author(s)","2-s2.0-85180484311"
"De Bruyne J.; Dheu O.; Ducuing C.","De Bruyne, Jan (57225315207); Dheu, Orian (57222085293); Ducuing, Charlotte (57210732830)","57225315207; 57222085293; 57210732830","The European Commission's approach to extra-contractual liability and AI – An evaluation of the AI liability directive and the revised product liability directive","2023","Computer Law and Security Review","51","","105894","","","","10.1016/j.clsr.2023.105894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174727865&doi=10.1016%2fj.clsr.2023.105894&partnerID=40&md5=589ed715d347f8784673f06fc7579b51","The European Commission published two proposals that aim to adapt (tort) liability rules to the digital age, the circular economy and the impact of the global value chain. The ‘AI Liability Directive’ contains rules on the disclosure of information and the alleviation of the burden of proof in relation to damage caused by AI systems. The ‘revised Product Liability Directive’ substantially modifies the current product liability regime by broadening the scope, integrating new circumstances to assess the product's defectiveness and introducing provisions regarding presumptions of defectiveness and causation. In this article, we evaluate how both proposals provide some answers to major technological developments – in particular AI – in view of the issues they raise as identified in the legal literature. To do so, we also provide a clear understanding of the major provisions in both proposals, supported by visuals. Although we welcome both proposals for several reasons outlined in the article, different unclarities and inconsistencies need to be resolved. These inter alia relate to the unclarity of terms, the position of claimants, the uncertain interaction with other supranational initiatives and the many interpretation issues with regard to the fault-based liability regime. A more fundamental objection relates to the choice of the revised Product Liability Directive to capture all liability issues with AI systems, which comes at the cost of losing the connection to ‘product’ as a grounding concept. Our findings can be used by policymakers in further adapting and refining both proposals to the digital reality. © 2023 Elsevier Ltd","2-s2.0-85174727865"
"Deepak A.; William P.; Dubey R.; Sachdeva S.; Vinotha C.; Masand S.; Shrivastava A.","Deepak, A. (57210350224); William, P. (57433493200); Dubey, Rajat (58824154400); Sachdeva, Shilpa (58755612600); Vinotha, C. (57979503600); Masand, Sunny (58756457200); Shrivastava, Anurag (58035982500)","57210350224; 57433493200; 58824154400; 58755612600; 57979503600; 58756457200; 58035982500","Impact of Artificial Intelligence and Cyber Security as Advanced Technologies on Bitcoin Industries","2024","International Journal of Intelligent Systems and Applications in Engineering","12","3","","131","140","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179304329&partnerID=40&md5=d25b16b012bfa74fae68b55f176a3f74","This review article investigates the relationship between Bitcoin and artificial intelligence (AI), as well as any potential consequences on the Bitcoin market. Also included are any implications for the future of the cryptocurrency. The literature review focuses on the existing research on the relationships between artificial intelligence technology and Bitcoin, and it provides an overview of both of these businesses. This research investigates the potential impacts that AI might have on the Bitcoin industry, including improved user experiences, better levels of transactional security, and enhanced operational efficiencies. The paper also analyses the challenges that occur from applying AI to the Bitcoin industry in terms of the rules and regulations, data security and privacy, and trust that exist in the sector. In recent years, cryptocurrencies have emerged as a dominant form of digital money, and the financial system itself has evolved into an increasingly important component in this space. In order to reduce the amount of risk that is associated with investing, certain approaches that are based on artificial intelligence are required to predict price and trend, as well as to design portfolios and identify fraudulent activity. Along with recent research on AI-based strategies for cryptocurrencies, the most well-known cryptocurrency, Bitcoin, is explored in this article. The articles that were determined to be the most relevant were assessed, and this page addresses the bulk of those publications. This contains research on Bitcoin and other cryptocurrencies, as well as techniques of machine learning such as SVM, ANN, LSTM, and GRU. © 2024, Ismail Saritas. All rights reserved.","2-s2.0-85179304329"
"Adão T.; Oliveira J.; Shahrabadi S.; Jesus H.; Fernandes M.; Costa Â.; Ferreira V.; Gonçalves M.F.; Lopéz M.A.G.; Peres E.; Magalhães L.G.","Adão, Telmo (53363165700); Oliveira, João (35519965200); Shahrabadi, Somayeh (55839647600); Jesus, Hugo (58735653100); Fernandes, Marco (58735653200); Costa, Ângelo (58515186000); Ferreira, Vânia (58515409100); Gonçalves, Martinho Fradeira (53363332700); Lopéz, Miguel A. Guevara (36999281000); Peres, Emanuel (36437418800); Magalhães, Luís Gonzaga (58010199300)","53363165700; 35519965200; 55839647600; 58735653100; 58735653200; 58515186000; 58515409100; 53363332700; 36999281000; 36437418800; 58010199300","Empowering Deaf-Hearing Communication: Exploring Synergies between Predictive and Generative AI-Based Strategies towards (Portuguese) Sign Language Interpretation","2023","Journal of Imaging","9","11","235","","","","10.3390/jimaging9110235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178285214&doi=10.3390%2fjimaging9110235&partnerID=40&md5=5a4df4570bbda9ab330026683f7b8cd8","Communication between Deaf and hearing individuals remains a persistent challenge requiring attention to foster inclusivity. Despite notable efforts in the development of digital solutions for sign language recognition (SLR), several issues persist, such as cross-platform interoperability and strategies for tokenizing signs to enable continuous conversations and coherent sentence construction. To address such issues, this paper proposes a non-invasive Portuguese Sign Language (Língua Gestual Portuguesa or LGP) interpretation system-as-a-service, leveraging skeletal posture sequence inference powered by long-short term memory (LSTM) architectures. To address the scarcity of examples during machine learning (ML) model training, dataset augmentation strategies are explored. Additionally, a buffer-based interaction technique is introduced to facilitate LGP terms tokenization. This technique provides real-time feedback to users, allowing them to gauge the time remaining to complete a sign, which aids in the construction of grammatically coherent sentences based on inferred terms/words. To support human-like conditioning rules for interpretation, a large language model (LLM) service is integrated. Experiments reveal that LSTM-based neural networks, trained with 50 LGP terms and subjected to data augmentation, achieved accuracy levels ranging from 80% to 95.6%. Users unanimously reported a high level of intuition when using the buffer-based interaction strategy for terms/words tokenization. Furthermore, tests with an LLM—specifically ChatGPT—demonstrated promising semantic correlation rates in generated sentences, comparable to expected sentences. © 2023 by the authors.","2-s2.0-85178285214"
"Sarker I.H.; Janicke H.; Ferrag M.A.; Abuadbba A.","Sarker, Iqbal H. (56997358700); Janicke, Helge (14028408400); Ferrag, Mohamed Amine (56115001200); Abuadbba, Alsharif (56401899800)","56997358700; 14028408400; 56115001200; 56401899800","Multi-aspect rule-based AI: Methods, taxonomy, challenges and directions towards automation, intelligence and transparent cybersecurity modeling for critical infrastructures","2024","Internet of Things (Netherlands)","25","","101110","","","","10.1016/j.iot.2024.101110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184885846&doi=10.1016%2fj.iot.2024.101110&partnerID=40&md5=ea7113a711abc4f7cb8529c55ab757e4","Critical infrastructure (CI) typically refers to the essential physical and virtual systems, assets, and services that are vital for the functioning and well-being of a society, economy, or nation. However, the rapid proliferation and dynamism of today's cyber threats in digital environments may disrupt CI functionalities, which would have a debilitating impact on public safety, economic stability, and national security. This has led to much interest in effective cybersecurity solutions regarding automation and intelligent decision-making, where AI-based modeling is potentially significant. In this paper, we take into account “Rule-based AI” rather than other black-box solutions since model transparency, i.e., human interpretation, explainability, and trustworthiness in decision-making, is an essential factor, particularly in cybersecurity application areas. This article provides an in-depth study on multi-aspect rule based AI modeling considering human interpretable decisions as well as security automation and intelligence for CI. We also provide a taxonomy of rule generation methods by taking into account not only knowledge-driven approaches based on human expertise but also data-driven approaches, i.e., extracting insights or useful knowledge from data, and their hybridization. This understanding can help security analysts and professionals comprehend how systems work, identify potential threats and anomalies, and make better decisions in various real-world application areas. We also cover how these techniques can address diverse cybersecurity concerns such as threat detection, mitigation, prediction, diagnosis for root cause findings, and so on in different CI sectors, such as energy, defence, transport, health, water, agriculture, etc. We conclude this paper with a list of identified issues and opportunities for future research, as well as their potential solution directions for how researchers and professionals might tackle future generation cybersecurity modeling in this emerging area of study. © 2024 The Author(s)","2-s2.0-85184885846"
"Al-Hawawreh M.; Moustafa N.","Al-Hawawreh, Muna (57193866778); Moustafa, Nour (56816761200)","57193866778; 56816761200","Explainable deep learning for attack intelligence and combating cyber–physical attacks","2024","Ad Hoc Networks","153","","103329","","","","10.1016/j.adhoc.2023.103329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175734930&doi=10.1016%2fj.adhoc.2023.103329&partnerID=40&md5=05f73de12ea6ef5bf043576cc6e39f0b","Cyber–physical control loops comprising sensors, actuators and controllers pose the most valued and critical part of the industrial Internet of Things (IIoT) as it regulates the state of the physical process, such as water treatment or gas flow. Thus, any malicious activities could lead to physical damage, affecting human safety. Cyber–physical attacks against the physical process are difficult to detect using existing threats and attack intelligence due to the (1) lack of such intelligence for the physical process and operational technology systems and (2) such attacks affect the process parameters and states. Artificial Intelligence (AI)-based attack intelligence is required. This study proposes an attack intelligence framework for identifying cyber–physical attacks and extracting attack intelligence. We propose an attribution module for attack identification using various machine and deep learning algorithms. We also utilize Explainable AI (XAI) to improve the explainability of the attack attribution module and extract attack intelligence. Our proposed framework is evaluated and tested using a gas pipeline dataset as a use case. We demonstrate that the proposed framework improves the understanding of attacks and provides attack rules, assisting security analysts in securing critical physical processes. © 2023 The Author(s)","2-s2.0-85175734930"
"Gaiardelli S.; Lora M.; Spellini S.; Fummi F.","Gaiardelli, Sebastiano (57328867400); Lora, Michele (56495027000); Spellini, Stefano (57204980174); Fummi, Franco (7003817152)","57328867400; 56495027000; 57204980174; 7003817152","RRPDG: A Graph Model to Enable AI-Based Production Reconfiguration and Optimization","2024","IEEE Transactions on Industrial Informatics","","","","1","11","10","10.1109/TII.2024.3352645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184010229&doi=10.1109%2fTII.2024.3352645&partnerID=40&md5=22f8f35cde24ecb3d7df3b14ed572c4e","This article introduces the regionalized resource process dependence graphs (RRPDGs): a manufacturing processes representation inspired by the regionalized value state dependence graphs traditionally used in software compilers. An RRPDG is an ordered sequence of nodes, each characterized by stereotyped input and output parameters, encapsulating a transformation of the process state (<italic/>e.g.<italic/>, a manufacturing operation). RRPDG allow defining complex transformations by composing a set of nodes (<italic/>i.e.<italic/>, regions), hiding the internal details. Then, RRPDGs are used to automatically reasoning over dynamic reconfiguration and process optimization: an instance of the A-star search algorithm is used to search for possible transformations while pursuing an optimization function. The rules defined in this article over RRPDG models enforce the transformations&#x0027; correctness. We use RRPDGs to model a real production system while the transformation rules are applied to optimize the system&#x0027;s processes. The proposed representation reduced the search complexity in each experiment, allowing to reach an optimal solution also in the case for which classical approaches were unable to complete before reaching the timeout. In all the experiments, the cost of the solution produced by using the regionalized representation is minor than the the solution produced by using the classical representation. Authors","2-s2.0-85184010229"
"Li T.; Vorvoreanu M.; Debellis D.; Amershi S.","Li, Tianyi (57208707667); Vorvoreanu, Mihaela (15053834400); Debellis, Derek (58690688900); Amershi, Saleema (23007675700)","57208707667; 15053834400; 58690688900; 23007675700","Assessing Human-AI Interaction Early through Factorial Surveys: A Study on the Guidelines for Human-AI Interaction","2023","ACM Transactions on Computer-Human Interaction","30","5","69","","","","10.1145/3511605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176472685&doi=10.1145%2f3511605&partnerID=40&md5=21e49185c2530a77bb88b09a1467eafa","This work contributes a research protocol for evaluating human-AI interaction in the context of specific AI products. The research protocol enables UX and HCI researchers to assess different human-AI interaction solutions and validate design decisions before investing in engineering. We present a detailed account of the research protocol and demonstrate its use by employing it to study an existing set of human-AI interaction guidelines. We used factorial surveys with a 2 × 2 mixed design to compare user perceptions when a guideline is applied versus violated, under conditions of optimal versus sub-optimal AI performance. The results provided both qualitative and quantitative insights into the UX impact of each guideline. These insights can support creators of user-facing AI systems in their nuanced prioritization and application of the guidelines. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2-s2.0-85176472685"
"Alberti E.; Alvarez-Napagao S.; Anaya V.; Barroso M.; Barrué C.; Beecks C.; Bergamasco L.; Chala S.A.; Gimenez-Abalos V.; Graß A.; Hinjos D.; Holtkemper M.; Jakubiak N.; Nizamis A.; Pristeri E.; Sànchez-Marrè M.; Schlake G.; Scholz J.; Scivoletto G.; Walter S.","Alberti, Enrico (58899749200); Alvarez-Napagao, Sergio (26638728200); Anaya, Victor (14630001700); Barroso, Marta (57213935097); Barrué, Cristian (23391695100); Beecks, Christian (24723639300); Bergamasco, Letizia (57521066200); Chala, Sisay Adugna (57190403887); Gimenez-Abalos, Victor (57216865182); Graß, Alexander (57204901249); Hinjos, Daniel (58548560100); Holtkemper, Maike (58876533000); Jakubiak, Natalia (57473978300); Nizamis, Alexandros (57203766332); Pristeri, Edoardo (57209302624); Sànchez-Marrè, Miquel (6601998870); Schlake, Georg (57223133751); Scholz, Jona (58899232500); Scivoletto, Gabriele (57360469300); Walter, Stefan (57322375600)","58899749200; 26638728200; 14630001700; 57213935097; 23391695100; 24723639300; 57521066200; 57190403887; 57216865182; 57204901249; 58548560100; 58876533000; 57473978300; 57203766332; 57209302624; 6601998870; 57223133751; 58899232500; 57360469300; 57322375600","AI Lifecycle Zero-Touch Orchestration within the Edge-to-Cloud Continuum for Industry 5.0","2024","Systems","12","2","48","","","","10.3390/systems12020048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185656119&doi=10.3390%2fsystems12020048&partnerID=40&md5=3c653421cbbf18359e5273a3e833d13e","The advancements in human-centered artificial intelligence (HCAI) systems for Industry 5.0 is a new phase of industrialization that places the worker at the center of the production process and uses new technologies to increase prosperity beyond jobs and growth. HCAI presents new objectives that were unreachable by either humans or machines alone, but this also comes with a new set of challenges. Our proposed method accomplishes this through the knowlEdge architecture, which enables human operators to implement AI solutions using a zero-touch framework. It relies on containerized AI model training and execution, supported by a robust data pipeline and rounded off with human feedback and evaluation interfaces. The result is a platform built from a number of components, spanning all major areas of the AI lifecycle. We outline both the architectural concepts and implementation guidelines and explain how they advance HCAI systems and Industry 5.0. In this article, we address the problems we encountered while implementing the ideas within the edge-to-cloud continuum. Further improvements to our approach may enhance the use of AI in Industry 5.0 and strengthen trust in AI systems. © 2024 by the authors.","2-s2.0-85185656119"
"Laaber C.; Yue T.; Ali S.; Schwitalla T.; Nygård J.","Laaber, Christoph (57194171758); Yue, Tao (25651096400); Ali, Shaukat (56962801700); Schwitalla, Thomas (57193757105); Nygård, Jan (7003875061)","57194171758; 25651096400; 56962801700; 57193757105; 7003875061","Automated Test Generation for Medical Rules Web Services: A Case Study at the Cancer Registry of Norway","2023","ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering","","","","1937","1948","11","10.1145/3611643.3613882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172431647&doi=10.1145%2f3611643.3613882&partnerID=40&md5=3ca247bd1bfb5730356b1ded32efd778","The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN's practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN's software system. In particular, we focus on GURI, CRN's medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster's black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI's code. Concerning domain-specific coverage, EvoMaster's black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster's black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context. © 2023 ACM.","2-s2.0-85172431647"
"Rismani S.; Moon A.","Rismani, Shalaleh (56541640700); Moon, AJung (54969168600)","56541640700; 54969168600","What does it mean to be a responsible AI practitioner: An ontology of roles and skills","2023","AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society","","","","584","595","11","10.1145/3600211.3604702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173620022&doi=10.1145%2f3600211.3604702&partnerID=40&md5=319594add49e98d8543d8966cf38ddad","With the growing need to regulate AI systems across a wide variety of application domains, a new set of occupations has emerged in the industry. The so-called responsible Artificial Intelligence (AI) practitioners or AI ethicists are generally tasked with interpreting and operationalizing best practices for ethical and safe design of AI systems. Due to the nascent nature of these roles, however, it is unclear to future employers and aspiring AI ethicists what specific function these roles serve and what skills are necessary to serve the functions. Without clarity on these, we cannot train future AI ethicists with meaningful learning objectives. In this work, we examine what responsible AI practitioners do in the industry and what skills they employ on the job. We propose an ontology of existing roles alongside skills and competencies that serve each role. We created this ontology by examining the job postings for such roles over a two-year period (2020-2022) and conducting expert interviews with fourteen individuals who currently hold such a role in the industry. Our ontology contributes to business leaders looking to build responsible AI teams and provides educators with a set of competencies that an AI ethics curriculum can prioritize.  © 2023 Owner/Author.","2-s2.0-85173620022"
"Palmiotto F.; González N.M.","Palmiotto, Francesca (58525697600); González, Natalia Menéndez (58524591500)","58525697600; 58524591500","Facial recognition technology, democracy and human rights","2023","Computer Law and Security Review","50","","105857","","","","10.1016/j.clsr.2023.105857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166909919&doi=10.1016%2fj.clsr.2023.105857&partnerID=40&md5=06481e31c0b4692310383afab35f39ef","On 4 July 2023, the Third Section of the European Court of Human Rights (ECtHR) delivered the first judgment on the compatibility of facial recognition technology with human rights in Glukhin v. Russia. The case concerned the use of facial recognition technology (FRT) against Mr Glukhin following his solo demonstration in the Moscow underground. The Court unanimously found a violation of Article 8 (right to respect for private life) and Article 10 (freedom of expression) of the European Convention of Human Rights (ECHR). Regarding FRT, the Court concluded that the use of highly intrusive technology is incompatible with the ideals and values of a democratic society governed by the rule of law. This case note analyses the judgment and shows its relevance in the current regulatory debate on Artificial Intelligence (AI) systems in Europe. Notwithstanding the importance of this decision, we argue that the Court has left crucial questions unanswered. © 2023 Francesca Palmiotto and Natalia Menéndez González","2-s2.0-85166909919"
"Aldoseri A.; Al-Khalifa K.N.; Hamouda A.M.","Aldoseri, Abdulaziz (57514216400); Al-Khalifa, Khalifa N. (24536663600); Hamouda, Abdel Magid (7005464521)","57514216400; 24536663600; 7005464521","Methodological Approach to Assessing the Current State of Organizations for AI-Based Digital Transformation","2024","Applied System Innovation","7","1","14","","","","10.3390/asi7010014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185951492&doi=10.3390%2fasi7010014&partnerID=40&md5=70679baed7312facf77bcc857ea3680e","In an era defined by technological disruption, the integration of artificial intelligence (AI) into business processes is both strategic and challenging. As AI continues to disrupt and reshape industries and revolutionize business processes, organizations must take proactive steps to assess their readiness and capabilities to effectively leverage AI technologies. This research focuses on the assessment elements required to evaluate an organization’s current state in preparation for AI-based digital transformation. This research is based on a literature review and practical insights derived from extensive experience in industrial system engineering. This paper outlines the key assessment elements that organizations should consider to ensure successful and sustainable AI-based digital transformation. This emphasizes the need for a comprehensive approach to assess the organization’s data infrastructure, governance practices, and existing AI capabilities. Furthermore, the research work focuses on the evaluation of AI talent and skills within the organization, considering the significance of fostering an innovative culture and addressing change management challenges. The results of this study provide organizations with elements to assess their current state for AI-based digital transformation. By adopting and implementing the proposed guidelines, organizations can gain a holistic perspective of their current standing, identify strategic opportunities for AI integration, mitigate potential risks, and strategize a successful path forwards in the evolving landscape of AI-driven digital transformation. © 2024 by the authors.","2-s2.0-85185951492"
"Danilevskyi M.; Perez Tellez F.","Danilevskyi, Mykhailo (58847730900); Perez Tellez, Fernando (35090542400)","58847730900; 35090542400","On the compliance with ethical principles in AI","2023","ACM International Conference Proceeding Series","","","","50","","","10.1145/3633083.3633223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183314043&doi=10.1145%2f3633083.3633223&partnerID=40&md5=1f01099002a983eaf5877eb73873d5a7","In recent years, there has been a lot of discussion around ethics in IT and AI. Researchers and organizations have proposed guidelines to address privacy, fairness, and explainability challenges for creating trustworthy AI. In this work, we outline the importance of compliance with the above-mentioned ethical principles and their influence on the quality of AI systems. We map the relationship between available approaches for compliance with privacy, fairness, explainability principles and the accuracy of AI system decisions. Additionally, we introduce the difference between ensuring fairness for phenomena presented with tabular data and text. Tabular data may contain protected attributes such as gender, age, or race as well as the decision made historically in relation to the people concerned. Data presented in text is not structured and requires sense perception by AI systems to detect bias or unfairness. In the poster, we compare available approaches and present experiments for measuring bias in text data.  © 2023 Owner/Author.","2-s2.0-85183314043"
"Michel-Villarreal R.; Vilalta-Perdomo E.; Salinas-Navarro D.E.; Thierry-Aguilera R.; Gerardou F.S.","Michel-Villarreal, Rosario (57196017810); Vilalta-Perdomo, Eliseo (55931930600); Salinas-Navarro, David Ernesto (57208908312); Thierry-Aguilera, Ricardo (16069538900); Gerardou, Flor Silvestre (58247298800)","57196017810; 55931930600; 57208908312; 16069538900; 58247298800","Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT","2023","Education Sciences","13","9","856","","","","10.3390/educsci13090856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172136998&doi=10.3390%2feducsci13090856&partnerID=40&md5=82a953bf7de1d553a8f76abaf201a5eb","ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT’s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes. © 2023 by the authors.","2-s2.0-85172136998"
"Fernandez-Basso C.; Gutiérrez-Batista K.; Gómez-Romero J.; Ruiz M.D.; Martin-Bautista M.J.","Fernandez-Basso, Carlos (57204458107); Gutiérrez-Batista, Karel (57191544839); Gómez-Romero, Juan (8875878400); Ruiz, M. Dolores (24554420800); Martin-Bautista, Maria J. (6601983953)","57204458107; 57191544839; 8875878400; 24554420800; 6601983953","An AI knowledge-based system for police assistance in crime investigation","2024","Expert Systems","","","","","","","10.1111/exsy.13524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181704485&doi=10.1111%2fexsy.13524&partnerID=40&md5=51ab6cc2dfd6196054e2e7770de3b23d","The fight against crime is often an arduous task overall when huge amounts of data have to be inspected, as is currently the case when it comes for example in the detection of criminal activity on the dark web. This work presents and describes an artificial intelligence (AI) based system that combines various tools to assist police or law enforcement agencies during their investigations, or at least mitigate the hard process of data collection, processing and analysis. The system is an early warning/early action system for crime investigation that supports law enforcement with different processes to collect and process data as well as having knowledge extraction tools. It helps to extract information during the investigation of a criminal case or even to detect possible criminal hotspots that may lead to further investigation or analysis of a criminal case Abu Al-Haija et al. (2022, Electronics, 11, 556). The functionality of the proposed system is illustrated through several examples using data collected from the dark web, which includes advertisements offering firearms-related products. © 2024 The Authors. Expert Systems published by John Wiley & Sons Ltd.","2-s2.0-85181704485"
"Stasevych M.; Zvarych V.","Stasevych, Maryna (8636372500); Zvarych, Viktor (56040708100)","8636372500; 56040708100","Innovative Robotic Technologies and Artificial Intelligence in Pharmacy and Medicine: Paving the Way for the Future of Health Care—A Review","2023","Big Data and Cognitive Computing","7","3","147","","","","10.3390/bdcc7030147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172168908&doi=10.3390%2fbdcc7030147&partnerID=40&md5=3161726af6895f16cb9214581ce7bb9e","The future of innovative robotic technologies and artificial intelligence (AI) in pharmacy and medicine is promising, with the potential to revolutionize various aspects of health care. These advances aim to increase efficiency, improve patient outcomes, and reduce costs while addressing pressing challenges such as personalized medicine and the need for more effective therapies. This review examines the major advances in robotics and AI in the pharmaceutical and medical fields, analyzing the advantages, obstacles, and potential implications for future health care. In addition, prominent organizations and research institutions leading the way in these technological advancements are highlighted, showcasing their pioneering efforts in creating and utilizing state-of-the-art robotic solutions in pharmacy and medicine. By thoroughly analyzing the current state of robotic technologies in health care and exploring the possibilities for further progress, this work aims to provide readers with a comprehensive understanding of the transformative power of robotics and AI in the evolution of the healthcare sector. Striking a balance between embracing technology and preserving the human touch, investing in R&D, and establishing regulatory frameworks within ethical guidelines will shape a future for robotics and AI systems. The future of pharmacy and medicine is in the seamless integration of robotics and AI systems to benefit patients and healthcare providers. © 2023 by the authors.","2-s2.0-85172168908"
"Feffer M.; Skirpan M.; Lipton Z.; Heidari H.","Feffer, Michael (57471426900); Skirpan, Michael (56872837800); Lipton, Zachary (56358302800); Heidari, Hoda (56394228400)","57471426900; 56872837800; 56358302800; 56394228400","From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research","2023","AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society","","","","38","48","10","10.1145/3600211.3604661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173613572&doi=10.1145%2f3600211.3604661&partnerID=40&md5=dbf0b5af51d55e24155582778673a2a9","The AI Ethics community faces an imperative to empower stakeholders and impacted community members so that they can scrutinize and influence the design, development, and use of AI systems in high-stakes domains. While a growing chorus of recent papers has kindled interest in so-called ""participatory ML""methods, precisely what form participation ought to take and how to operationalize these ambitions are seldom addressed. Our survey of the relevant literature shows that in many papers, participation is reduced to highly structured, computational mechanisms designed to elicit mathematically tractable approximations of narrowly-defined moral values. Of papers that actually engage with real people, these engagements typically consist of one-time interactions with individuals that are often unrepresentative of the relevant stakeholders. Motivated by these clear limitations, we introduce a consolidated set of axes to evaluate and improve participatory approaches. We use these axes to analyze contemporary work in this space and outline future AI research directions that could meaningfully contribute to operationalizing the ideal of participation.  © 2023 Owner/Author.","2-s2.0-85173613572"
"Lin Y.; Li J.; Xiao H.; Zheng L.; Xiao Y.; Song H.; Fan J.; Xiao D.; Ai D.; Fu T.; Wang F.; Lv H.; Yang J.","Lin, Yucong (57212110354); Li, Jia (57441037000); Xiao, Huan (58345623700); Zheng, Lujie (58680782900); Xiao, Ying (58680917900); Song, Hong (7404037613); Fan, Jingfan (56028732500); Xiao, Deqiang (57212001182); Ai, Danni (56173394200); Fu, Tianyu (56365895900); Wang, Feifei (57190750487); Lv, Han (55977922500); Yang, Jian (57091071100)","57212110354; 57441037000; 58345623700; 58680782900; 58680917900; 7404037613; 56028732500; 57212001182; 56173394200; 56365895900; 57190750487; 55977922500; 57091071100","Automatic literature screening using the PAJO deep-learning model for clinical practice guidelines","2023","BMC Medical Informatics and Decision Making","23","1","247","","","","10.1186/s12911-023-02328-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175729816&doi=10.1186%2fs12911-023-02328-8&partnerID=40&md5=fe34ef835a5713a30bb6cf957977c352","Background: Clinical practice guidelines (CPGs) are designed to assist doctors in clinical decision making. High-quality research articles are important for the development of good CPGs. Commonly used manual screening processes are time-consuming and labor-intensive. Artificial intelligence (AI)-based techniques have been widely used to analyze unstructured data, including texts and images. Currently, there are no effective/efficient AI-based systems for screening literature. Therefore, developing an effective method for automatic literature screening can provide significant advantages. Methods: Using advanced AI techniques, we propose the Paper title, Abstract, and Journal (PAJO) model, which treats article screening as a classification problem. For training, articles appearing in the current CPGs are treated as positive samples. The others are treated as negative samples. Then, the features of the texts (e.g., titles and abstracts) and journal characteristics are fully utilized by the PAJO model using the pretrained bidirectional-encoder-representations-from-transformers (BERT) model. The resulting text and journal encoders, along with the attention mechanism, are integrated in the PAJO model to complete the task. Results: We collected 89,940 articles from PubMed to construct a dataset related to neck pain. Extensive experiments show that the PAJO model surpasses the state-of-the-art baseline by 1.91% (F1 score) and 2.25% (area under the receiver operating characteristic curve). Its prediction performance was also evaluated with respect to subject-matter experts, proving that PAJO can successfully screen high-quality articles. Conclusions: The PAJO model provides an effective solution for automatic literature screening. It can screen high-quality articles on neck pain and significantly improve the efficiency of CPG development. The methodology of PAJO can also be easily extended to other diseases for literature screening. © 2023, The Author(s).","2-s2.0-85175729816"
"Khunte A.; Sangha V.; Oikonomou E.K.; Dhingra L.S.; Aminorroaya A.; Mortazavi B.J.; Coppi A.; Brandt C.A.; Krumholz H.M.; Khera R.","Khunte, Akshay (57219020562); Sangha, Veer (57223591923); Oikonomou, Evangelos K. (57848941400); Dhingra, Lovedeep S. (57205440989); Aminorroaya, Arya (57567919700); Mortazavi, Bobak J. (42761875000); Coppi, Andreas (6602341479); Brandt, Cynthia A. (35513998400); Krumholz, Harlan M. (55152053200); Khera, Rohan (55974983700)","57219020562; 57223591923; 57848941400; 57205440989; 57567919700; 42761875000; 6602341479; 35513998400; 55152053200; 55974983700","Detection of left ventricular systolic dysfunction from single-lead electrocardiography adapted for portable and wearable devices","2023","npj Digital Medicine","6","1","124","","","","10.1038/s41746-023-00869-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165144614&doi=10.1038%2fs41746-023-00869-w&partnerID=40&md5=e701899fb4b2c8a0377da2bcdbb721e2","Artificial intelligence (AI) can detect left ventricular systolic dysfunction (LVSD) from electrocardiograms (ECGs). Wearable devices could allow for broad AI-based screening but frequently obtain noisy ECGs. We report a novel strategy that automates the detection of hidden cardiovascular diseases, such as LVSD, adapted for noisy single-lead ECGs obtained on wearable and portable devices. We use 385,601 ECGs for development of a standard and noise-adapted model. For the noise-adapted model, ECGs are augmented during training with random gaussian noise within four distinct frequency ranges, each emulating real-world noise sources. Both models perform comparably on standard ECGs with an AUROC of 0.90. The noise-adapted model performs significantly better on the same test set augmented with four distinct real-world noise recordings at multiple signal-to-noise ratios (SNRs), including noise isolated from a portable device ECG. The standard and noise-adapted models have an AUROC of 0.72 and 0.87, respectively, when evaluated on ECGs augmented with portable ECG device noise at an SNR of 0.5. This approach represents a novel strategy for the development of wearable-adapted tools from clinical ECG repositories. © 2023, The Author(s).","2-s2.0-85165144614"
"Qin J.; Qin J.; Qiu J.; Liu Q.; Li M.; Ma Q.","Qin, Jianmin (58699853900); Qin, Jiahu (35792326900); Qiu, Jiaxin (58699696500); Liu, Qingchen (56949199300); Li, Man (57206279095); Ma, Qichao (56383302700)","58699853900; 35792326900; 58699696500; 56949199300; 57206279095; 56383302700","SRL-ORCA: A Socially Aware Multi-Agent Mapless Navigation Algorithm in Complex Dynamic Scenes","2024","IEEE Robotics and Automation Letters","9","1","","143","150","7","10.1109/LRA.2023.3331621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177051842&doi=10.1109%2fLRA.2023.3331621&partnerID=40&md5=2b1c1b664cef4204a3de4b1ade03cc9c","For real-world navigation, it is important to endow robots with the capabilities to navigate safely and efficiently in a complex environment with both dynamic and static obstacles. However, achieving path-finding in non-convex complex environments without maps as well as enabling multiple robots to follow social rules for obstacle avoidance remain challenging problems. In this letter, we propose a socially aware mapless navigation algorithm, namely Safe Reinforcement Learning-Optimal Reciprocal Collision Avoidance (SRL-ORCA). This is a multi-Agent safe reinforcement learning algorithm by using ORCA as external knowledge to provide safety guarantees. This algorithm further introduces traffic norms of human society to improve social comfort and achieve cooperative avoidance by following human social customs. The result of experiments shows that SRL-ORCA learns strategies to obey specific traffic rules. Compared to RL, SRL-ORCA shows a significant improvement in navigation success rate in different complex scenarios. SRL-ORCA is able to cope with non-convex obstacle environments without falling into local minima and has a 14.5% improvement in average time to goal compared to ORCA.  © 2016 IEEE.","2-s2.0-85177051842"
"Turel O.; Kalhan S.","Turel, Ofir (12760214400); Kalhan, Shivam (57203318637)","12760214400; 57203318637","Prejudiced against the Machine? Implicit Associations and the Transience of Algorithm Aversion","2023","MIS Quarterly: Management Information Systems","47","7","","1369","1394","25","10.25300/MISQ/2022/17961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185252925&doi=10.25300%2fMISQ%2f2022%2f17961&partnerID=40&md5=9410fdcd27bffb03cd069d533b9649f3","Algorithm aversion is an important and persistent issue that prevents harvesting the benefits of advancements in artificial intelligence. The literature thus far has provided explanations that primarily focus on conscious reflective processes. Here, we supplement this view by taking an unconscious perspective that can be highly informative. Building on theories of implicit prejudice, in a preregistered study, we suggest that people develop an implicit bias (i.e., prejudice) against artificial intelligence (AI) systems, as a different and threatening “species,” the behavior of which is unknown. Like in other contexts of prejudice, we expected people to be guided by this implicit bias but try to override it. This leads to some willingness to rely on algorithmic advice (appreciation), which is reduced as a function of people’s implicit prejudice against the machine. Next, building on the somatic marker hypothesis and the accessibility-diagnosticity perspective, we provide an explanation as to why aversion is ephemeral. As people learn about the performance of an algorithm, they depend less on primal implicit biases when deciding whether to rely on the AI’s advice. Two studies (n1 = 675, n2 = 317) that use the implicit association test consistently support this view. Two additional studies (n3 = 255, n4 = 332) rule out alternative explanations and provide stronger support for our assertions. The findings ultimately suggest that moving the needle between aversion and appreciation depends initially on one’s general unconscious bias against AI because there is insufficient information to override it. They further suggest that in later use stages, this shift depends on accessibility to diagnostic information about the AI’s performance, which reduces the weight given to unconscious prejudice. © 2023 University of Minnesota. All rights reserved.","2-s2.0-85185252925"
"Khan A.A.; Akbar M.A.; Fahmideh M.; Liang P.; Waseem M.; Ahmad A.; Niazi M.; Abrahamsson P.","Khan, Arif Ali (26434399300); Akbar, Muhammad Azeem (57200183503); Fahmideh, Mahdi (43061009500); Liang, Peng (24923262400); Waseem, Muhammad (57189504629); Ahmad, Aakash (36760479100); Niazi, Mahmood (14045585000); Abrahamsson, Pekka (7006011356)","26434399300; 57200183503; 43061009500; 24923262400; 57189504629; 36760479100; 14045585000; 7006011356","AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers","2023","IEEE Transactions on Computational Social Systems","10","6","","2971","2984","13","10.1109/TCSS.2023.3251729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149866419&doi=10.1109%2fTCSS.2023.3251729&partnerID=40&md5=38cf09134048ffea3ffc4c07e337cf4c","Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems' development and quality assessment.  © 2014 IEEE.","2-s2.0-85149866419"
"Wardat Y.; Tashtoush M.A.; AlAli R.; Saleh S.","Wardat, Yousef (57213193372); Tashtoush, Mohammad A. (57227505600); AlAli, Rommel (56653438900); Saleh, Shoeb (57941891400)","57213193372; 57227505600; 56653438900; 57941891400","Artificial Intelligence in Education: Mathematics Teachers’ Perspectives, Practices and Challenges","2024","Iraqi Journal for Computer Science and Mathematics","5","1","","60","77","17","10.52866/ijcsm.2024.05.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180991973&doi=10.52866%2fijcsm.2024.05.01.004&partnerID=40&md5=85870ec90eaaa382341e5615e55770cf","Efforts have been made to include artificial intelligence (AI) in teaching and learning; nevertheless, the successful deployment of new instructional technology depends on the attitudes of the teachers who conduct the lesson. Few scholars have researched teachers' perspectives on AI use due to a general lack of expertise on how it can be used in the classroom, as well as a lack of specific knowledge about what AI-adopted tools would be like. This study investigated mathematics teachers’ perceptions of implemented AI systems and applications in Abu Dhabi Emirate schools. The sample study consists of 580 male and female math teachers from public and private schools across three educational regions in Abu Dhabi selected based on several qualifications and experiences. The research followed the descriptive analytical approach due to its suitability to the study’s context. The results revealed that AI could be used as an educational tool to facilitate teaching and develop students’ performance by including AI systems and applications in the curricula. They increased motivation for learning, encouraging challenge, competition, and suspense among students and considering their differences. The results also showed the most critical challenges that math teachers face in applying AI systems and applications, the most prominent of which are the need to exert more effort than the traditional method when using different AI systems and applications and the pressures placed on them, which prevent them from using AI in teaching. Additionally, the findings revealed no statistically significant differences in mathematics teachers’ perspectives regarding the importance of using systems and applications of AI in teaching; however, statistically significant differences were found in the math teachers’ challenges when applying AI systems and applications in teaching according to the educational qualifications, especially among math teachers who have masters’ degrees. These results can be used as a foundation for creating guidelines for the future integration of AI education in schools since they report teachers’ experiences utilizing the system and various considerations regarding its implementation. © 2024 College of Education, Al-Iraqia University. All rights reserved.","2-s2.0-85180991973"
"Duffourc M.N.; Gerke S.","Duffourc, Mindy Nunez (57193032783); Gerke, Sara (57199176578)","57193032783; 57199176578","The proposed EU Directives for AI liability leave worrying gaps likely to impact medical AI","2023","npj Digital Medicine","6","1","77","","","","10.1038/s41746-023-00823-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156129320&doi=10.1038%2fs41746-023-00823-w&partnerID=40&md5=77b356f13f790bb6b0524a28f5437b1c","Two newly proposed Directives impact liability for artificial intelligence in the EU: a Product Liability Directive (PLD) and an AI Liability Directive (AILD). While these proposed Directives provide some uniform liability rules for AI-caused harm, they fail to fully accomplish the EU’s goal of providing clarity and uniformity for liability for injuries caused by AI-driven goods and services. Instead, the Directives leave potential liability gaps for injuries caused by some black-box medical AI systems, which use opaque and complex reasoning to provide medical decisions and/or recommendations. Patients may not be able to successfully sue manufacturers or healthcare providers for some injuries caused by these black-box medical AI systems under either EU Member States’ strict or fault-based liability laws. Since the proposed Directives fail to address these potential liability gaps, manufacturers and healthcare providers may have difficulty predicting liability risks associated with creating and/or using some potentially beneficial black-box medical AI systems. © 2023, The Author(s).","2-s2.0-85156129320"
"Ji I.; Jeon S.; Seo J.T.","Ji, Ilhwan (58781877300); Jeon, Seungho (57214781958); Seo, Jung Taek (57211702744)","58781877300; 57214781958; 57211702744","AE-LSTM Based Anomaly Detection System for Communication Over DNP 3.0","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14402 LNCS","","","91","104","13","10.1007/978-981-99-8024-6_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182608850&doi=10.1007%2f978-981-99-8024-6_8&partnerID=40&md5=55a1738db1ff69473ffb7b42ff3d27bb","Energy Management System (EMS) communicates with power plants and substations to maintain the reliability and efficiency of power supplies. EMS collects and monitors data from these sources and controls power flow through commands to ensure uninterrupted power supply, frequency and voltage maintenance, and power recovery in the event of a power outage. EMS works in a Distributed Network Protocol (DNP) 3.0-based network environment that is considered secure due to its unique security features and communication methods. However, cyberattacks exploiting the vulnerability of the DNP 3.0 protocol can manipulate the power generation output, resulting in serious consequences such as facility malfunction and power outages. To address this issue, this paper identifies security threats in power system networks, including DNP 3.0, and proposes an AI-based anomaly detection system based on DNP 3.0 network traffic. Existing network traffic target rule-based detection methods and signature-based detection methods have defects. We propose an AI-based anomaly detection system to compensate for defects in existing anomaly detection methods and perform efficient anomaly detection. To evaluate the performance of the AI-based anomaly detection system proposed in this paper, we used a dataset containing normal network traffic and nine types of attack network traffic obtained from the DNP 3.0 communication testbed, and experiments showed 99% accuracy, 98% TPR, and 1.6% FPR, resulting in 99% F-1 score. By implementing these security measures, power system network environments, including EMS, can be better protected against cyber threats. © 2024, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85182608850"
"Novelli C.; Governatori G.; Rotolo A.","Novelli, Claudio (57218340049); Governatori, Guido (6602545579); Rotolo, Antonino (36888902800)","57218340049; 6602545579; 36888902800","Automating Business Process Compliance for the EU AI Act","2023","Frontiers in Artificial Intelligence and Applications","379","","","125","130","5","10.3233/FAIA230955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181168136&doi=10.3233%2fFAIA230955&partnerID=40&md5=b8eaf4f73404fed4ce794e9ba0dbc162","The EU AI Act is the first step toward a comprehensive legal framework for AI. It introduces provisions for AI systems based on their risk levels in relation to fundamental rights. Providers of AI systems must conduct Conformity Assessments before market placement. Recent amendments added Fundamental Rights Impact Assessments for high-risk AI system users, focusing on compliance with EU and national laws, fundamental rights, and potential impacts on EU values. The paper suggests that automating business process compliance can help standardize these assessments and outlines some methodological guidelines.  © 2023 The Authors.","2-s2.0-85181168136"
"Farhat S.; Abdelkader M.; Meddeb-Makhlouf A.; Zarai F.","Farhat, Saida (57218587938); Abdelkader, Manel (25654598100); Meddeb-Makhlouf, Amel (22734863100); Zarai, Faouzi (14120594100)","57218587938; 25654598100; 22734863100; 14120594100","CADS-ML/DL: efficient cloud-based multi-attack detection system","2023","International Journal of Information Security","22","6","","1989","2013","24","10.1007/s10207-023-00729-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164738630&doi=10.1007%2fs10207-023-00729-4&partnerID=40&md5=163fe71ffb18934e6a631250d6a0518b","With the increasing adoption of cloud computing, securing cloud-based systems and applications has become a critical concern for almost every organization. Traditional security approaches such as signature-based and rule-based have limited detection capabilities toward new and sophisticated attacks. To address this issue, there has been an increasing focus on implementing Artificial Intelligence (AI) in cloud security measures. In this research article, we present CADS-ML/DL, an efficient cloud-based multi-attack detection system. We investigate the effectiveness of Machine Learning (ML) and Deep Learning (DL) techniques for detecting cloud attacks. Our approach leverages a realistic dataset consisting of both benign and fourteen common attack network flows that meet real-world criteria on the AWS cloud platform. We evaluate eight Intrusion Detection Systems (IDSs) based on ML and DL algorithms, including Decision Tree (DT), Random Forest (RF), Extreme Gradient Boosting (XGBoost), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), Stacked LSTM, and Bidirectional LSTM (Bi-LSTM) models. Experimental results demonstrate that the CADS-ML/DL system, specifically the XGBoost model, outperforms the other models, exhibiting an accuracy of 0.9770 and a false error rate of 0.0230. Furthermore, we validate the effectiveness of our proposed XGBoost model on the AWS benchmark CSE-CICIDS2018 dataset, attaining a remarkable accuracy score of 0.9999 and an exceptionally low false error rate of 0.0001. Our findings suggest that AI-based approaches have the potential to detect cloud attacks effectively and contribute to the development of reliable and efficient IDSs for cloud security. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH, DE.","2-s2.0-85164738630"
"Fabris G.; Scalera L.; Gasparetto A.","Fabris, Giuliano (58706168300); Scalera, Lorenzo (57191853169); Gasparetto, Alessandro (7005379319)","58706168300; 57191853169; 7005379319","Playing Checkers with an Intelligent and Collaborative Robotic System †","2024","Robotics","13","1","4","","","","10.3390/robotics13010004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183411785&doi=10.3390%2frobotics13010004&partnerID=40&md5=4baebf0d17c98d723c11a1f5ccfcdfe1","Collaborative robotics represents a modern and efficient framework in which machines can safely interact with humans. Coupled with artificial intelligence (AI) systems, collaborative robots can solve problems that require a certain degree of intelligence not only in industry but also in the entertainment and educational fields. Board games like chess or checkers are a good example. When playing these games, a robotic system has to recognize the board and pieces and estimate their position in the robot reference frame, decide autonomously which is the best move to make (respecting the game rules), and physically execute it. In this paper, an intelligent and collaborative robotic system is presented to play Italian checkers. The system is able to acquire the game state using a camera, select the best move among all the possible ones through a decision-making algorithm, and physically manipulate the game pieces on the board, performing pick-and-place operations. Minimum-time trajectories are optimized online for each pick-and-place operation of the robot so as to make the game more fluent and interactive while meeting the kinematic constraints of the manipulator. The developed system is tested in a real-world setup using a Franka Emika arm with seven degrees of freedom. The experimental results demonstrate the feasibility and performance of the proposed approach. © 2023 by the authors.","2-s2.0-85183411785"
"Raftopoulos M.","Raftopoulos, Marigo (56781435700)","56781435700","Augmented Humans: Provocations for collaborative AI system design","2023","ACM International Conference Proceeding Series","","","","294","297","3","10.1145/3616961.3616969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180013386&doi=10.1145%2f3616961.3616969&partnerID=40&md5=f8ae58630c60b6cbf4f353d98000364e","This workshop is designed to facilitate an exploration of collaborative methodologies from both academia and industry practice to advance insight into the emergent problem space of designing AI-enabled information systems. The recent developments and implementations of AI-enabled technologies have seen a parallel proliferation of practical approaches to ensure human-centred and ethical design principles are imbedded into AI development which has largely been in response to widespread industry criticism of unethical practices and unintended negative consequences of black box' algorithmic decision making. Our prototype design cards and collaborative design process are targeted at current problems and limitations with intelligent human-machine systems that can be averted with more inclusive collaboration with users as stakeholders in system design. Our intention is to refine our AI design methodology and design cards over several international workshops and to provide them to the public as a free open-source tool for AI researchers and practitioners.  © 2023 Owner/Author.","2-s2.0-85180013386"
"Dzhusupova R.; Banotra R.; Bosch J.; Olsson H.H.","Dzhusupova, Rimma (57781802400); Banotra, Richa (57818771000); Bosch, Jan (56675290800); Olsson, Helena Holmström (24335916300)","57781802400; 57818771000; 56675290800; 24335916300","Using artificial intelligence to find design errors in the engineering drawings","2023","Journal of Software: Evolution and Process","35","12","e2543","","","","10.1002/smr.2543","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148338919&doi=10.1002%2fsmr.2543&partnerID=40&md5=f404ff59894622d614f5bd5ce6909cfb","Artificial intelligence is increasingly becoming important to businesses because many companies have realized the benefits of applying machine learning (ML) and deep learning (DL) in their operations. ML and DL have become attractive technologies for organizations looking to automate repetitive tasks to reduce manual work and free up resources for innovation. Unlike rule-based automation, typically used for standardized and predictable processes, machine learning, especially deep learning, can handle more complex tasks and learn over time, leading to greater accuracy and efficiency improvements. One of such promising applications is to use AI to reduce manual engineering work. This paper discusses a particular case within McDermott where the research team developed a DL model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI-based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&IDs). We also present a cost-benefit analysis and potential scale-up of the developed software. Our goal is to share the successful experience of AI-based product development that can substantially reduce the engineering hours and, therefore, reduce the project's overall costs. The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry. It also could motivate practitioners and researchers to create similar products for the various fields within engineering industry. © 2023 The Authors. Journal of Software: Evolution and Process published by John Wiley & Sons Ltd.","2-s2.0-85148338919"
"Vetter M.A.; Lucia B.; Jiang J.; Othman M.","Vetter, Matthew A. (57202046940); Lucia, Brent (57482475700); Jiang, Jialei (57214591723); Othman, Mahmoud (58863008700)","57202046940; 57482475700; 57214591723; 58863008700","Towards a framework for local interrogation of AI ethics: A case study on text generators, academic integrity, and composing with ChatGPT","2024","Computers and Composition","71","","102831","","","","10.1016/j.compcom.2024.102831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183969586&doi=10.1016%2fj.compcom.2024.102831&partnerID=40&md5=1fa83249f46aa5739059c37bf8945cb1","Ethical frameworks for text generators (TGs) in education are generally concerned with personalized instruction, a dependency on data, biases in training data, academic integrity, and lack of creativity from students. While broad-level, institutional guidelines provide value in understanding the ethical dimensions of artificial intelligence (AI) for the classroom, there is a need for a more ecological understanding of how AI ethics might be constructed locally, one that takes into account the negotiation of AI between teacher and student. This article investigates how an educational ethical framework for AI use emerges through a qualitative case study of one composition student's interaction with and understanding of using ChatGPT as a type of writing partner. Analysis of interview data and student logs uncover what we term an emergent “local ethic” – a framework that is capable of exploring unique ethical considerations, values, and norms that develop at the most foundational unit of higher education – the individual classroom. Our framework is meant to provide a heuristic for other writing teacher-scholars as they interrogate issues related to pedagogy, student criticality, agency, reliability, and access within the context of powerful AI systems. © 2024 Elsevier Inc.","2-s2.0-85183969586"
"Tchuente D.; Lonlac J.; Kamsu-Foguem B.","Tchuente, Dieudonné (25925535100); Lonlac, Jerry (55321339000); Kamsu-Foguem, Bernard (8046606700)","25925535100; 55321339000; 8046606700","A methodological and theoretical framework for implementing explainable artificial intelligence (XAI) in business applications","2024","Computers in Industry","155","","104044","","","","10.1016/j.compind.2023.104044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177220628&doi=10.1016%2fj.compind.2023.104044&partnerID=40&md5=cd24649935ab3176f26396031f4f52ef","Artificial Intelligence (AI) is becoming fundamental in almost all activity sectors in our society. However, most of the modern AI techniques (e.g., Machine Learning – ML) have a black box nature, which hinder their adoption by practitioners in many application fields. This issue raises a recent emergence of a new research area in AI called Explainable artificial intelligence (XAI), aiming at providing AI-based decision-making processes and outcomes to be easily understood, interpreted, and justified by humans. Since 2018, there has been an exponential growth of research studies on XAI, which has justified some review studies. However, these reviews currently focus on proposing taxonomies of XAI methods. Yet, XAI is by nature a highly applicative research field, and beyond XAI methods, it is also very important to investigate how XAI is concretely used in industries, and consequently derive the best practices to follow for better implementations and adoptions. There is a lack of studies on this latter point. To fill this research gap, we first propose a holistic review of business applications of XAI, by following the Theory, Context, Characteristics, and Methodology (TCCM) protocol. Based on the findings of this review, we secondly propose a methodological and theoretical framework in six steps that can be followed by all practitioners or stakeholders for improving the implementation and adoption of XAI in their business applications. We particularly highlight the need to rely on domain field and analytical theories to explain the whole analytical process, from the relevance of the business question to the robustness checking and the validation of explanations provided by XAI methods. Finally, we propose seven important future research avenues. © 2023 Elsevier B.V.","2-s2.0-85177220628"
"Zhang S.; Yang L.T.; Zhang Y.; Lu Z.; Yu J.; Cui Z.","Zhang, Shunli (57208395081); Yang, Laurence T. (57203323020); Zhang, Yue (57216883508); Lu, Zhixing (57216882216); Yu, Jing (56589203600); Cui, Zongmin (55866427000)","57208395081; 57203323020; 57216883508; 57216882216; 56589203600; 55866427000","Tensor-Based Baum-Welch Algorithms in Coupled Hidden Markov Model for Responsible Activity Prediction","2023","IEEE Transactions on Computational Social Systems","10","6","","2924","2937","13","10.1109/TCSS.2022.3227458","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153392752&doi=10.1109%2fTCSS.2022.3227458&partnerID=40&md5=f164d2b2e9d5cc94775ac61b37761455","The development and applications of artificial intelligence (AI) have brought unprecedented opportunities to humans, but also brought many challenges and concerns such as unfairness, immorality, distrust, illegality, and discrimination. Responsible AI provides a new solution to effectively address these AI potential threats by integrating social/physical rules into AI systems. However, these rules are high-level regulations and ethical principles, which are difficult to be formalized. To this end, we attempt to use the data generated in various AI systems such as cyber-physical-social systems (CPSS) to discover and reflect these rules to provide more responsible services for humans. In this article, we first propose a data-driven responsible CPSS framework. Its core idea is to mine valuable rules through perception, fusion, processing, and analysis of CPSS data, and then use these rules to adaptively optimize CPSS. Based on this framework, three tensor-based couple hidden Markov models (T-CHMMs) are constructed to integrate three responsible features (i.e., timing, periodicity, and correlation) for mining potential and valuable rules. Then, the corresponding tensor-based Baum-Welch (TBW) algorithms are designed to solve their learning problems. Finally, the predictive accuracy and computational efficiency of the proposed models and algorithms are verified on three open datasets. The experimental results show that proposed methods have the best performances for various scenarios, which reflects that our methods are more promising and responsible than existing methods.  © 2014 IEEE.","2-s2.0-85153392752"
"Zhong Z.; Song J.; Feng Z.; Liu T.; Jia L.; Yao S.; Hou T.; Song M.","Zhong, Zipeng (57565333800); Song, Jie (57343425200); Feng, Zunlei (57192555083); Liu, Tiantao (57565333900); Jia, Lingxiang (57566709600); Yao, Shaolun (57566709700); Hou, Tingjun (7103185497); Song, Mingli (9333722700)","57565333800; 57343425200; 57192555083; 57565333900; 57566709600; 57566709700; 7103185497; 9333722700","Recent advances in deep learning for retrosynthesis","2024","Wiley Interdisciplinary Reviews: Computational Molecular Science","14","1","e1694","","","","10.1002/wcms.1694","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174484461&doi=10.1002%2fwcms.1694&partnerID=40&md5=2b859bb1674dc143868a7f81552d3300","Retrosynthesis is the cornerstone of organic chemistry, providing chemists in material and drug manufacturing access to poorly available and brand-new molecules. Conventional rule-based or expert-based computer-aided synthesis has obvious limitations, such as high labor costs and limited search space. In recent years, dramatic breakthroughs driven by deep learning have revolutionized retrosynthesis. Here we aim to present a comprehensive review of recent advances in AI-based retrosynthesis. For single-step and multi-step retrosynthesis both, we first introduce their goal and provide a thorough taxonomy of existing methods. Afterwards, we analyze these methods in terms of their mechanism and performance, and introduce popular evaluation metrics for them, in which we also provide a detailed comparison among representative methods on several public datasets. In the next part, we introduce popular databases and established platforms for retrosynthesis. Finally, this review concludes with a discussion about promising research directions in this field. This article is categorized under: Data Science > Artificial Intelligence/Machine Learning Data Science > Computer Algorithms and Programming Data Science > Chemoinformatics. © 2023 Wiley Periodicals LLC.","2-s2.0-85174484461"
"Pierson C.M.; Hildt E.","Pierson, Cameron M. (57209210920); Hildt, Elisabeth (24479649800)","57209210920; 24479649800","From Principles to Practice: Comparative Analysis of European and United States Ethical AI Frameworks for Assessment and Methodological Application","2023","Proceedings of the Association for Information Science and Technology","60","1","","327","337","10","10.1002/pra2.792","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174587544&doi=10.1002%2fpra2.792&partnerID=40&md5=54cec82019459dc1f45a5dc2a51e8295","The Z-Inspection® Process is a form of applied research for the ethical assessment of AI systems. It is quickly establishing itself as a robust method to ethically assess AI in Europe. The process is predicated on the European Union's Ethics Guidelines for Trustworthy AI, outlining ethical principles intended to guide European AI development. In contrast, the United States has only recently released its holistic version of such guidelines, the Blueprint for an AI Bill of Rights. The aim of this paper is to assess the suitability of the Blueprint for an AI Bill of Rights as an ethical framework underpinning the use of the Z-Inspection® Process in the United States. This paper provides preliminary findings of comparative analysis of European and United States ethical frameworks for responsible AI development. Findings outline primary ethical concepts that are shared between respective frameworks. Findings suggest the US Blueprint is suitable as an ethical framework for the Z-Inspection® Process. There are notable omissions within the US framework which would require further development for Z-Inspection® use. Discussion will consider opportunities for adapting Z-Inspection® to the United States context, including contributions from the information professions and research.  Annual Meeting of the Association for Information Science & Technology | Oct. 27 – 31, 2023 | London, United Kingdom. Author(s) retain copyright, but ASIS&T receives an exclusive publication license.","2-s2.0-85174587544"
"Dhanasekaran P.; Sakthivel V.; Jayashri N.; Hemawathi M.S.; Kaliappan V.K.","Dhanasekaran, P. (58771321700); Sakthivel, V. (57222611519); Jayashri, N. (56884875800); Hemawathi, M.S. (58730717300); Kaliappan, Vishnu Kumar (24829297500)","58771321700; 57222611519; 56884875800; 58730717300; 24829297500","Artificial Intelligence Enabled Network Intrusion Detection Model (AI-NIDM) for Smart Grid Cyber-Physical Systems","2024","International Journal of Intelligent Systems and Applications in Engineering","12","2s","","388","396","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178190923&partnerID=40&md5=47a8aac581780fd8f06fa1f02867bb58","The increasing complexity and interconnectivity of Smart Grid Cyber-Physical Systems (SG-CPS) have raised significant concerns regarding the security and integrity of these systems. Network Intrusion Detection Model (NIDM) is an essential component of SG-CPS security infrastructure. However, the conventional rule-based and signature-based NIDM are becoming less effective in detecting advanced and sophisticated cyber-attacks. Artificial Intelligence (AI) technologies, named machine learning, deep learning, and neural networks, have shown great potential in enhancing the accuracy and efficiency of NIDM. This paper proposes an AI-Enabled Network Intrusion Detection Model (AI-NIDM) called GWA-ANN for SG-CPS, which integrates AI techniques with traditional NIDS for improved detection and response to cyber-attacks. The proposed system is evaluated on a public SG-CPS dataset, and the results establish that AI-NIDM can effectively detect and classify various types of cyber-attacks with high accuracy and low false-positive rates. The proposed AI-NIDM can significantly improve the security and resilience of SG-CPS against emerging cyber threats. © 2024, Ismail Saritas. All rights reserved.","2-s2.0-85178190923"
"Huang Y.; Tsao C.-T.; Lee H.-H.","Huang, Yuan (58605464300); Tsao, Cheng-Tien (58550228500); Lee, Hee-Hyol (58811824300)","58605464300; 58550228500; 58811824300","Efficiency Improvement to Neural-Network-Driven Optimal Path Planning via Region and Guideline Prediction","2024","IEEE Robotics and Automation Letters","9","2","","1851","1858","7","10.1109/LRA.2024.3350979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182384296&doi=10.1109%2fLRA.2024.3350979&partnerID=40&md5=eba8566447177646fa9bd6316e2eb84e","Traditional sampling-based algorithms rely on random samples to explore a whole configuration space of robots for optimal path planning, while a uniform sampler impedes the exploration with randomly generated samples, leading to a long calculation time, especially in complex environments. Recently, neural-network-driven methods have attracted wide interest in developing non-uniform sampling to improve the sampling efficiency and reduce the calculation time. A region that contains an optimal path is predicted by neural networks and employed subsequently to biasedly generate samples. This work aims at enhancing the sampling efficiency and reducing the calculation time of the optimal path planning by a novel region and guideline prediction (denoted as RGP) model. We innovatively propose the RGP model with a guideline prediction module to estimate the guideline distributions, which are characterized by the central line of the predicted region. The predicted region and guideline are integrated into a sampling-based algorithm, namely RGP-RRT*, with an adaptively biased sampling strategy to select a proper domain for sampling. Simulations demonstrate the RGP model outperforms other region prediction models in accuracy and robustness. Besides, the RGP-RRT∗ reliably achieves a 7.2-80.1% reduction in calculation time and a 2.0-58.1% reduction in sample number compared with other neural-network-driven methods.  © 2016 IEEE.","2-s2.0-85182384296"
"Maguluri L.P.; Arularasan A.N.; Boopathi S.","Maguluri, Lakshmana Phaneendra (57199852329); Arularasan, A.N. (57118243800); Boopathi, S. (57312510800)","57199852329; 57118243800; 57312510800","Assessing security concerns for ai-based drones in smart cities","2023","Effective AI, Blockchain, and E-Governance Applications for Knowledge Discovery and Management","","","","27","47","20","10.4018/978-1-6684-9151-5.ch002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175384239&doi=10.4018%2f978-1-6684-9151-5.ch002&partnerID=40&md5=67553ea9575cd90e172c82432a9e0835","This chapter investigates security concerns involving AI-powered drones in smart cities, emphasising the importance of secure deployment. It discusses topics like data privacy, cybersecurity risks, physical security, and ethical repercussions. Security precautions such encrypted communication channels, intrusion detection systems, collision avoidance systems, and observance of moral and legal norms are discussed. The chapter offers case studies of successful AI-based drone deployments as well as recommendations for best practises for upcoming operations. The chapter addresses challenges and embraces ethical concerns in an effort to support the moral integration of AI-based drones in smart city scenarios. © 2023, IGI Global. All rights reserved.","2-s2.0-85175384239"
"Lu Y.; Li W.; Li W.","Lu, Yunlong (57219797167); Li, Wenxin (55718665400); Li, Wenlong (58288658700)","57219797167; 55718665400; 58288658700","Official International Mahjong: A New Playground for AI Research","2023","Algorithms","16","5","235","","","","10.3390/a16050235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160211188&doi=10.3390%2fa16050235&partnerID=40&md5=055700652d118643aae5295ae83ddb9c","Games have long been benchmarks and testbeds for AI research. In recent years, with the development of new algorithms and the boost in computational power, many popular games played by humans have been solved by AI systems. Mahjong is one of the most popular games played in China and has been spread worldwide, which presents challenges for AI research due to its multi-agent nature, rich hidden information, and complex scoring rules, but it has been somehow overlooked in the community of game AI research. In 2020 and 2022, we held two AI competitions of Official International Mahjong, the standard variant of Mahjong rules, in conjunction with a top-tier AI conference called IJCAI. We are the first to adopt the duplicate format in evaluating Mahjong AI agents to mitigate the high variance in this game. By comparing the algorithms and performance of AI agents in the competitions, we conclude that supervised learning and reinforcement learning are the current state-of-the-art methods in this game and perform much better than heuristic methods based on human knowledge. We also held a human-versus-AI competition and found that the top AI agent still could not beat professional human players. We claim that this game can be a new benchmark for AI research due to its complexity and popularity among people. © 2023 by the authors.","2-s2.0-85160211188"
"Bhupathi P.; Prabu S.; Goh A.P.I.","Bhupathi, Priyadharshini (57214792414); Prabu, S. (55755787400); Goh, Alexis P.I. (57219053411)","57214792414; 55755787400; 57219053411","ARTIFICIAL INTELLIGENCE-ENABLED KNOWLEDGE MANAGEMENT USING A MULTIDIMENSIONAL ANALYTICAL FRAMEWORK OF VISUALIZATIONS","2023","International Journal of Cognitive Computing in Engineering","4","","","240","247","7","10.1016/j.ijcce.2023.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164706311&doi=10.1016%2fj.ijcce.2023.06.003&partnerID=40&md5=aa18142e0ff2cdf2ba22a83f57006956","To better manage human resources (HR), companies are increasingly incorporating artificial intelligence (AI) and other AI-based tools into their HR management (HRM) strategies, at a universal scale. Companies on a global scale, highlight the employment prospects and use of resources, business judgment, and make predictions using machine learning approaches. This work aims at the situation that the human resource department faces high employee turnover in the company especially some experienced employees leave. The termination of an employee is predicted by using an enhanced ID3 decision tree with ABC rule miner. The best-classifying attributes are chosen by ID3 and association rules are mined to generate an enhanced decision tree to perform classification. It is then passed to the regressor model to make prediction. Gradient descent optimizer is used for optimizing the proposed machine learning model. Predictive analysis is done in HR dataset v-14 by visualizing and analyzing and exploiting the behavioral relationship among the attributes. The variables of employee termination are predicted by a data-driven predictive analysis from the performance measure metrics. © 2023","2-s2.0-85164706311"
"Lee Y.; Kim T.S.; Kim S.; Yun Y.; Kim J.","Lee, Yoonjoo (57224003420); Kim, Tae Soo (57324085500); Kim, Sungdong (57218925368); Yun, Yohan (58285479800); Kim, Juho (39361826000)","57224003420; 57324085500; 57218925368; 58285479800; 39361826000","DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children's Why and How Questions","2023","Conference on Human Factors in Computing Systems - Proceedings","","","450","","","","10.1145/3544548.3581369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160019854&doi=10.1145%2f3544548.3581369&partnerID=40&md5=f8dd6be05ce59108e4df0493b0a84d9f","Children acquire an understanding of the world by asking ""why""and ""how""questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children's questions as they are more readily available than parents or teachers. However, CAs' answers to ""why""and ""how""questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children's engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children's questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence. © 2023 ACM.","2-s2.0-85160019854"
"Heyn H.-M.; Knauss E.; Pelliccione P.","Heyn, Hans-Martin (57216546553); Knauss, Eric (24829443700); Pelliccione, Patrizio (8852257900)","57216546553; 24829443700; 8852257900","A compositional approach to creating architecture frameworks with an application to distributed AI systems","2023","Journal of Systems and Software","198","","111604","","","","10.1016/j.jss.2022.111604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146698508&doi=10.1016%2fj.jss.2022.111604&partnerID=40&md5=fc81e8b936ec5952daa6c023a2b499fd","Artificial intelligence (AI) in its various forms finds more and more its way into complex distributed systems. For instance, it is used locally, as part of a sensor system, on the edge for low-latency high-performance inference, or in the cloud, e.g. for data mining. Modern complex systems, such as connected vehicles, are often part of an Internet of Things (IoT). This poses additional architectural challenges. To manage complexity, architectures are described with architecture frameworks, which are composed of a number of architectural views connected through correspondence rules. Despite some attempts, the definition of a mathematical foundation for architecture frameworks that are suitable for the development of distributed AI systems still requires investigation and study. In this paper, we propose to extend the state of the art on architecture framework by providing a mathematical model for system architectures, which is scalable and supports co-evolution of different aspects for example of an AI system. Based on Design Science Research, this study starts by identifying the challenges with architectural frameworks in a use case of distributed AI systems. Then, we derive from the identified challenges four rules, and we formulate them by exploiting concepts from category theory. We show how compositional thinking can provide rules for the creation and management of architectural frameworks for complex systems, for example distributed systems with AI. The aim of the paper is not to provide viewpoints or architecture models specific to AI systems, but instead to provide guidelines based on a mathematical formulation on how a consistent framework can be built up with existing, or newly created, viewpoints. To put in practice and test the approach, the identified and formulated rules are applied to derive an architectural framework for the EU Horizon 2020 project “Very efficient deep learning in the IoT” (VEDLIoT) in the form of a case study. © 2022 The Author(s)","2-s2.0-85146698508"
"Nguyen K.T.P.; Medjaher K.; Tran D.T.","Nguyen, Khanh T. P. (56890401400); Medjaher, Kamal (8293548200); Tran, Do T. (57197785548)","56890401400; 8293548200; 57197785548","A review of artificial intelligence methods for engineering prognostics and health management with implementation guidelines","2023","Artificial Intelligence Review","56","4","","3659","3709","50","10.1007/s10462-022-10260-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137841434&doi=10.1007%2fs10462-022-10260-y&partnerID=40&md5=d40ecb44f61acfcb4ca7147a300662ab","The past decade has witnessed the adoption of artificial intelligence (AI) in various applications. It is of no exception in the area of prognostics and health management (PHM) where the capacity of AI has been highlighted through numerous studies. In this paper, we present a comprehensive review of AI-based solutions in engineering PHM. This review serves as a guideline for researchers and practitioners with varying levels of experience seeking to broaden their know-how about AI-based PHM. Specifically, we provide both a broad quantitative analysis and a comprehensive qualitative examination of the roles of AI in PHM. The quantitative analysis offers an insight into the research community’s interest in AI-based approaches, focusing on the evolution of research trends and their developments in different PHM application areas. The qualitative survey gives a complete picture on the employment of AI in each stage of the PHM process, from data preparation to decision support. Based on the strengths and weaknesses of existing methods, we derive a general guideline for choosing proper techniques for each specific PHM task, aiming to level up maintenance practitioners’ efficiency in implementing PHM solutions. Finally, the review discusses challenges and future research directions in the development of autonomous intelligent PHM solutions. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85137841434"
"Rahman M.M.; Rivolta M.W.; Badilini F.; Sassi R.","Rahman, Md Moklesur (57212184733); Rivolta, Massimo Walter (55193762300); Badilini, Fabio (57203006991); Sassi, Roberto (56258832600)","57212184733; 55193762300; 57203006991; 56258832600","A Systematic Survey of Data Augmentation of ECG Signals for AI Applications","2023","Sensors","23","11","5237","","","","10.3390/s23115237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161479084&doi=10.3390%2fs23115237&partnerID=40&md5=3d12f869ac23a61084f4715fdb4e8e9c","AI techniques have recently been put under the spotlight for analyzing electrocardiograms (ECGs). However, the performance of AI-based models relies on the accumulation of large-scale labeled datasets, which is challenging. To increase the performance of AI-based models, data augmentation (DA) strategies have been developed recently. The study presented a comprehensive systematic literature review of DA for ECG signals. We conducted a systematic search and categorized the selected documents by AI application, number of leads involved, DA method, classifier, performance improvements after DA, and datasets employed. With such information, this study provided a better understanding of the potential of ECG augmentation in enhancing the performance of AI-based ECG applications. This study adhered to the rigorous PRISMA guidelines for systematic reviews. To ensure comprehensive coverage, publications between 2013 and 2023 were searched across multiple databases, including IEEE Explore, PubMed, and Web of Science. The records were meticulously reviewed to determine their relevance to the study’s objective, and those that met the inclusion criteria were selected for further analysis. Consequently, 119 papers were deemed relevant for further review. Overall, this study shed light on the potential of DA to advance the field of ECG diagnosis and monitoring. © 2023 by the authors.","2-s2.0-85161479084"
"Butt M.A.; Qayyum A.; Ali H.; Al-Fuqaha A.; Qadir J.","Butt, Muhammad Atif (57222118033); Qayyum, Adnan (57202908543); Ali, Hassan (57211394542); Al-Fuqaha, Ala (57220421072); Qadir, Junaid (15058218600)","57222118033; 57202908543; 57211394542; 57220421072; 15058218600","Towards secure private and trustworthy human-centric embedded machine learning: An emotion-aware facial recognition case study","2023","Computers and Security","125","","103058","","","","10.1016/j.cose.2022.103058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144401760&doi=10.1016%2fj.cose.2022.103058&partnerID=40&md5=ed1e6d693180b9b22f7f8cafe262dd88","The use of artificial intelligence (AI) at the edge is transforming every aspect of the lives of human beings from scheduling daily activities to personalized shopping recommendations. Since the success of AI is to be measured ultimately in terms of how it benefits human beings, and that the data driving the deep learning-based edge AI algorithms are intricately and intimately tied to humans, it is important to look at these AI technologies through a human-centric lens. However, despite the significant impact of AI design on human interests, the security and trustworthiness of edge AI applications are not foolproof and ethicalneither foolproof nor ethical; Moreover, social norms are often ignored duringin the design, implementation, and deployment of edge AI systems. In this paper, we make the following two contributions: Firstly, we analyze the application of edge AI through a human-centric perspective. More specifically, we present a pipeline to develop human-centric embedded machine learning (HC-EML) applications leveraging a generic human-centric AI (HCAI) framework. Alongside, we also analyzediscuss the privacy, trustworthiness, robustness, and security aspects of HC-EML applications with an insider look at their challenges and possible solutions along the way. Secondly, to illustrate the gravity of these issues, we present a case study on the task of human facial emotion recognition (FER) based on AffectNet dataset, where we analyze the effects of widely used input quantization on the security, robustness, fairness, and trustworthiness of an EML model. We find that input quantization partially degrades the efficacy of adversarial and backdoor attacks at the cost of a slight decrease in accuracy over clean inputs. By analyzing the explanations generated by SHAP, we identify that the decision of a FER model is largely influenced by features such as eyes, alar crease, lips, and jaws. Additionally, we note that input quantization is notably biased against the dark skin faces, and hypothesize that low-contrast features of dark skin faces may be responsible for the observed trends. We conclude with precautionary remarks and guidelines for future researchers. © 2022 The Author(s)","2-s2.0-85144401760"
"Olson T.; Forbus K.D.","Olson, Taylor (57431902800); Forbus, Kenneth D. (7003585370)","57431902800; 7003585370","Mitigating Adversarial Norm Training with Moral Axioms","2023","Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023","37","","","11882","11889","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168243505&partnerID=40&md5=3ce951128d31afcd388706099289c6eb","This paper addresses the issue of adversarial attacks on ethical AI systems. We investigate using moral axioms and rules of deontic logic in a norm learning framework to mitigate adversarial norm training. This model of moral intuition and construction provides AI systems with moral guard rails yet still allows for learning conventions. We evaluate our approach by drawing inspiration from a study commonly used in moral development research. This questionnaire aims to test an agent's ability to reason to moral conclusions despite opposed testimony. Our findings suggest that our model can still correctly evaluate moral situations and learn conventions in an adversarial training environment. We conclude that adding axiomatic moral prohibitions and deontic inference rules to a norm learning model makes it less vulnerable to adversarial attacks. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85168243505"
"Russell D.; Liao Q.V.; Kulkarni C.; Glassman E.L.; Martelaro N.","Russell, Daniel (7403669974); Liao, Q. Vera (36095944800); Kulkarni, Chinmay (36651262600); Glassman, Elena L. (23975987900); Martelaro, Nikolas (56144702700)","7403669974; 36095944800; 36651262600; 23975987900; 56144702700","Human-Computer Interaction and AI: What practitioners need to know to design and build effective AI system from a human perspective","2023","Conference on Human Factors in Computing Systems - Proceedings","","","545","","","","10.1145/3544549.3574170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158153387&doi=10.1145%2f3544549.3574170&partnerID=40&md5=25a3ee6302a933852f8ac3b57e6ba56f","AI and ML are now essential parts of many systems that are currently being built. What should CHI practitioners know about the possibilities and potential drawbacks of building AI systems? Understanding the human side of AI/ML based systems requires understanding both how the system-side AI works, but also how people think about, understand, and use AI tools and systems. This course will cover what AI components and systems currently exist, how to design and build usable systems with AI components, along with how the mental models of AI/ML tools operate. These models lead to user expectations of how AI systems function, and ultimately, to design guidelines that avoid disappointing end-users by accidentally creating unintelligible AI tools. We'll also cover the ethics of AI, including data collection, algorithmic and data fairness considerations, along with other risks of AI. © 2023 Owner/Author.","2-s2.0-85158153387"
"Ottun A.-R.; Asadi M.; Boerger M.; Tcholtchev N.; Goncalves J.; Borovcanin D.; Siniarsk B.; Flores H.","Ottun, Abdul-Rasheed (57958937100); Asadi, Mehrdad (58022777100); Boerger, Michell (57947415500); Tcholtchev, Nikolay (35231572100); Goncalves, Joao (58886439900); Borovcanin, Dusan (58886325900); Siniarsk, Bartlomiej (58886368700); Flores, Huber (54790934900)","57958937100; 58022777100; 57947415500; 35231572100; 58886439900; 58886325900; 58886368700; 54790934900","One to Rule them All: A Study on Requirement Management Tools for the Development of Modern AI-based Software","2023","Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023","","","","3556","3565","9","10.1109/BigData59044.2023.10386926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184985030&doi=10.1109%2fBigData59044.2023.10386926&partnerID=40&md5=bcec1d300b1368f4d445dbb8ba0391c9","Modern system architectures are rapidly adopting AI-based functionality. As a result, new requirements about software trustworthiness must be considered during the entire software development life cycle of applications. While several requirement management tools are available to track and monitor requirements over time, it is still unknown to what extent these tools can cope with these new demands imposed by AI. In this paper, we contribute by performing a qualitative and quantitative analysis of different requirement management tools and their performance in managing AI-related requirements effectively. Through a rigorous analysis performed by a consortium formed by different industry and academic partners, we evaluate the suitability of five different requirement management tools. Our results indicate that while several tools are available for managing requirements, it is currently challenging to find a tool that can manage AI requirements mainly because tools do not comply with the required aspects imposed by regulatory entities. Lastly, we also shared our lessons learned and experiences from selecting requirement tools that can be used in team-based consortium projects.  © 2023 IEEE.","2-s2.0-85184985030"
"Huang C.; Zhang Z.; Mao B.; Yao X.","Huang, Changwu (57837914500); Zhang, Zeqi (57224447618); Mao, Bifei (57224452995); Yao, Xin (57222996723)","57837914500; 57224447618; 57224452995; 57222996723","An Overview of Artificial Intelligence Ethics","2023","IEEE Transactions on Artificial Intelligence","4","4","","799","819","20","10.1109/TAI.2022.3194503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135738347&doi=10.1109%2fTAI.2022.3194503&partnerID=40&md5=1cd7b4f6b292f38169faff2dd6243a69","Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.  © 2020 IEEE.","2-s2.0-85135738347"
"Ronanki K.; Cabrero-Daniel B.; Horkoff J.; Berger C.","Ronanki, Krishna (58483395600); Cabrero-Daniel, Beatriz (57219337738); Horkoff, Jennifer (9042245700); Berger, Christian (16067915300)","58483395600; 57219337738; 9042245700; 16067915300","RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems","2023","ACM International Conference Proceeding Series","","","1","","","","10.1145/3597512.3599697","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167962950&doi=10.1145%2f3597512.3599697&partnerID=40&md5=3aef716e68beacc898aa78ce453d9608","Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address these concerns, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.  © 2023 Owner/Author.","2-s2.0-85167962950"
"van Bekkum M.; Zuiderveen Borgesius F.","van Bekkum, Marvin (57225126167); Zuiderveen Borgesius, Frederik (55581911400)","57225126167; 55581911400","Using sensitive data to prevent discrimination by artificial intelligence: Does the GDPR need a new exception?","2023","Computer Law and Security Review","48","","105770","","","","10.1016/j.clsr.2022.105770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142768621&doi=10.1016%2fj.clsr.2022.105770&partnerID=40&md5=965a6166c8c30fed51161c8f155cef1d","Organisations can use artificial intelligence to make decisions about people for a variety of reasons, for instance, to select the best candidates from many job applications. However, AI systems can have discriminatory effects when used for decision-making. To illustrate, an AI system could reject applications of people with a certain ethnicity, while the organisation did not plan such ethnicity discrimination. But in Europe, an organisation runs into a problem when it wants to assess whether its AI system accidentally discriminates based on ethnicity: the organisation may not know the applicants’ ethnicity. In principle, the GDPR bans the use of certain ‘special categories of data’ (sometimes called ‘sensitive data’), which include data on ethnicity, religion, and sexual preference. The proposal for an AI Act of the European Commission includes a provision that would enable organisations to use special categories of data for auditing their AI systems. This paper asks whether the GDPR's rules on special categories of personal data hinder the prevention of AI-driven discrimination. We argue that the GDPR does prohibit such use of special category data in many circumstances. We also map out the arguments for and against creating an exception to the GDPR's ban on using special categories of personal data, to enable preventing discrimination by AI systems. The paper discusses European law, but the paper can be relevant outside Europe too, as many policymakers in the world grapple with the tension between privacy and non-discrimination policy. © 2022","2-s2.0-85142768621"
"Padovan P.H.; Martins C.M.; Reed C.","Padovan, Paulo Henrique (57419405100); Martins, Clarice Marinho (57419223800); Reed, Chris (35337487200)","57419405100; 57419223800; 35337487200","Black is the new orange: how to determine AI liability","2023","Artificial Intelligence and Law","31","1","","133","167","34","10.1007/s10506-022-09308-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123174512&doi=10.1007%2fs10506-022-09308-9&partnerID=40&md5=a1c71521765ba91b55f19b702042fb61","Autonomous artificial intelligence (AI) systems can lead to unpredictable behavior causing loss or damage to individuals. Intricate questions must be resolved to establish how courts determine liability. Until recently, understanding the inner workings of “black boxes” has been exceedingly difficult; however, the use of Explainable Artificial Intelligence (XAI) would help simplify the complex problems that can occur with autonomous AI systems. In this context, this article seeks to provide technical explanations that can be given by XAI, and to show how suitable explanations for liability can be reached in court. It provides an analysis of whether existing liability frameworks, in both civil and common law tort systems, with the support of XAI, can address legal concerns related to AI. Lastly, it claims their further development and adoption should allow AI liability cases to be decided under current legal and regulatory rules until new liability regimes for AI are enacted. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85123174512"
"Meske C.; Bunde E.","Meske, Christian (55806873000); Bunde, Enrico (57218312382)","55806873000; 57218312382","Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection","2023","Information Systems Frontiers","25","2","","743","773","30","10.1007/s10796-021-10234-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125542214&doi=10.1007%2fs10796-021-10234-5&partnerID=40&md5=4dc9da137e577e709de78dd30c17c5a0","Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high. © 2022, The Author(s).","2-s2.0-85125542214"
"Viedienina Y.; Sakun L.; Mazharenko K.; Kovalenko M.","Viedienina, Yulia (57217826896); Sakun, Lesia (58886560900); Mazharenko, Kateryna (58886499100); Kovalenko, Maksym (58089376100)","57217826896; 58886560900; 58886499100; 58089376100","Management of Information Support and Automation of Energy Systems based on Artificial Intelligence","2023","Proceedings of the 5th International Conference on Modern Electrical and Energy System, MEES 2023","","","","","","","10.1109/MEES61502.2023.10402493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185004948&doi=10.1109%2fMEES61502.2023.10402493&partnerID=40&md5=35a1066e6c2197465f7423a8336860d1","This article investigates the impact of artificial intelligence (AI) on information support and automation in energy systems. It adopts a multi-method approach, combining literature review, case studies, and data analysis to explore various AI techniques and their applications in the energy sector. The findings show that AI-based tools can enhance the prediction, optimization, extraction, analysis, and recommendation of energy-related data, leading to improved efficiency, reliability, and sustainability of energy systems. The article also discusses AI technologies such as deep learning, reinforcement learning, and Internet of Things (IoT) integration, which offer novel opportunities for information support and automation in the energy sector. The article provides practical recommendations on the implementation of AI tools in energy systems, highlighting best practices and key considerations. © 2023 IEEE.","2-s2.0-85185004948"
"Chari S.; Acharya P.; Gruen D.M.; Zhang O.; Eyigoz E.K.; Ghalwash M.; Seneviratne O.; Saiz F.S.; Meyer P.; Chakraborty P.; McGuinness D.L.","Chari, Shruthi (57204180513); Acharya, Prasant (58097933000); Gruen, Daniel M. (8521973800); Zhang, Olivia (58097933100); Eyigoz, Elif K. (57216304694); Ghalwash, Mohamed (54415736300); Seneviratne, Oshani (36697042800); Saiz, Fernando Suarez (57221708398); Meyer, Pablo (17135725500); Chakraborty, Prithwish (57213522203); McGuinness, Deborah L. (7006256751)","57204180513; 58097933000; 8521973800; 58097933100; 57216304694; 54415736300; 36697042800; 57221708398; 17135725500; 57213522203; 7006256751","Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes","2023","Artificial Intelligence in Medicine","137","","102498","","","","10.1016/j.artmed.2023.102498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147794628&doi=10.1016%2fj.artmed.2023.102498&partnerID=40&md5=6c5cc1b57f4fd01e972d0ca1c16ae219","Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by ‘contextual explanations’ that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients’ clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) - a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians’ usage of AI models. © 2023","2-s2.0-85147794628"
"Kaur R.; Ginige J.A.; Obst O.","Kaur, Rajvir (57213732834); Ginige, Jeewani Anupama (25930945900); Obst, Oliver (56431373600)","57213732834; 25930945900; 56431373600","AI-based ICD coding and classification approaches using discharge summaries: A systematic literature review","2023","Expert Systems with Applications","213","","118997","","","","10.1016/j.eswa.2022.118997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140340911&doi=10.1016%2fj.eswa.2022.118997&partnerID=40&md5=6b9c0fd05c9a9392e9fdad009e1f2c46","The assignment of codes to free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning clinical codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related machine learning and deep learning methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. The main objective of this systematic literature review is to provide a comprehensive overview of automated clinical coding systems that utilise appropriate NLP, machine learning and deep learning methods and techniques to assign the International Classification of Diseases (ICD) codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2021 in four high quality academic databases: PubMed, ScienceDirect, Association for Computing Machinery (ACM) Digital Library, and the Association for Computational Linguistics (ACL) Anthology. We reviewed 6128 publications; 42 met the inclusion criteria. This review identified: 6 datasets having discharge summaries (2 publicly available, 4 acquired from hospitals); 14 NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. The review also shows that there is a significant increase in the use of deep learning models compared to machine learning. To measure the performance of classification methods, different evaluation metrics are used. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers. © 2022 Elsevier Ltd","2-s2.0-85140340911"
"Kernan Freire S.","Kernan Freire, Samuel (57914193800)","57914193800","The Human Factors of AI-Empowered Knowledge Sharing","2023","Conference on Human Factors in Computing Systems - Proceedings","","","502","","","","10.1145/3544549.3577044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158111237&doi=10.1145%2f3544549.3577044&partnerID=40&md5=f5fa0530175b8d188eca1e15f68dd0e0","Many industries are facing the challenge of how to capture workers' knowledge such that it can be shared, in particular tacit knowledge. The operation of complex systems such as a manufacturing line is knowledge-intensive, especially if the operator must frequently reconfigure it for different products. Considering the breadth and dynamic nature of this knowledge, existing solutions for sharing knowledge (e.g., word-of-mouth, issue reports, document creation, and decision support systems) are inefficient and/or resource-intensive. Conversational user interfaces are an efficient way to convey information that mimics the way humans share knowledge; however, we know little about how to design them specifically for this purpose, especially regarding tacit knowledge. In this work, my main goal is to investigate how a cognitive assistant can be designed to facilitate (tacit) knowledge transfer between users of dynamic complex systems. I aim to achieve this by outlining the design requirements, challenges, and opportunities in factories; by collaboratively designing, implementing, and evaluating a cognitive assistant for sharing knowledge; studying the effects of design characteristics on aspects such as user experience; and finally, creating a set of design guidelines. © 2023 Owner/Author.","2-s2.0-85158111237"
"Jatti V.S.; Jatti A.V.; Mishra A.; Dhabale R.D.; Sefene E.M.","Jatti, Vijaykumar S. (55792700800); Jatti, Ashwini V. (57212246377); Mishra, Akshansh (57216633068); Dhabale, Rahul D. (55906601500); Sefene, Eyob Messele (57216271008)","55792700800; 57212246377; 57216633068; 55906601500; 57216271008","Optimizing flexural strength of fused deposition modelling using supervised machine learning algorithms","2023","International Journal of Information Technology (Singapore)","15","5","","2759","2766","7","10.1007/s41870-023-01329-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161462801&doi=10.1007%2fs41870-023-01329-0&partnerID=40&md5=e7a09b056dcdfc594094b9d8592a7cfd","Due to its distinct production paradigm, additive manufacturing (AM) is positioned to bring about a revolution. It presents the possibility of on-demand, decentralized, and mass-customizable manufacturing. However, several issues related to design principles, standardization, and quality control arise from not only the complexity of production systems but also the need for increasingly complicated and high-quality goods. Artificial Intelligence (AI)-based algorithms, which can effectively monitor quality, optimize processes, model complex systems, and manage energy, is essential in addressing the difficulties. In the present work, we have used three supervised machine learning regression-based algorithms, i.e., XG Boost, Random Forest, and Decision Trees, to determine the Flexural Strength of the Fused Deposition Modeling specimen. The results showed that the XG Boost algorithm resulted in the highest coefficient of determination value of 0.77. Supervised machine learning classification-based algorithms such as the Stochastic Gradient Descent (SGD) algorithm, Decision Tree, and Random Forest algorithm is used to determine good and bad flexural strength specimens. The result showed that the SGD algorithm achieved the highest F1 score of 0.85. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.","2-s2.0-85161462801"
"Ramanayake R.; Wicke P.; Nallur V.","Ramanayake, Rajitha (57226329306); Wicke, Philipp (57204726099); Nallur, Vivek (35311284300)","57226329306; 57204726099; 35311284300","Immune moral models? Pro-social rule breaking as a moral enhancement approach for ethical AI","2023","AI and Society","38","2","","801","813","12","10.1007/s00146-022-01478-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130510136&doi=10.1007%2fs00146-022-01478-z&partnerID=40&md5=0f38bfb94cfad75c4e456038e1eeec85","We are moving towards a future where Artificial Intelligence (AI) based agents make many decisions on behalf of humans. From healthcare decision-making to social media censoring, these agents face problems, and make decisions with ethical and societal implications. Ethical behaviour is a critical characteristic that we would like in a human-centric AI. A common observation in human-centric industries, like the service industry and healthcare, is that their professionals tend to break rules, if necessary, for pro-social reasons. This behaviour among humans is defined as pro-social rule breaking. To make AI agents more human-centric, we argue that there is a need for a mechanism that helps AI agents identify when to break rules set by their designers. To understand when AI agents need to break rules, we examine the conditions under which humans break rules for pro-social reasons. In this paper, we present a study that introduces a ‘vaccination strategy dilemma’ to human participants and analyzes their response. In this dilemma, one needs to decide whether they would distribute COVID-19 vaccines only to members of a high-risk group (follow the enforced rule) or, in selected cases, administer the vaccine to a few social influencers (break the rule), which might yield an overall greater benefit to society. The results of the empirical study suggest a relationship between stakeholder utilities and pro-social rule breaking (PSRB), which neither deontological nor utilitarian ethics completely explain. Finally, the paper discusses the design characteristics of an ethical agent capable of PSRB and the future research directions on PSRB in the AI realm. We hope that this will inform the design of future AI agents, and their decision-making behaviour. © 2022, The Author(s).","2-s2.0-85130510136"
"Dixit S.; Bohre K.; Singh Y.; Himeur Y.; Mansoor W.; Atalla S.; Srinivasan K.","Dixit, Shriniket (57482011400); Bohre, Khitij (58125018700); Singh, Yashbir (57214304083); Himeur, Yassine (55636199800); Mansoor, Wathiq (6506544762); Atalla, Shadi (36611295600); Srinivasan, Kathiravan (57192191217)","57482011400; 58125018700; 57214304083; 55636199800; 6506544762; 36611295600; 57192191217","A Comprehensive Review on AI-Enabled Models for Parkinson’s Disease Diagnosis","2023","Electronics (Switzerland)","12","4","783","","","","10.3390/electronics12040783","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149247102&doi=10.3390%2felectronics12040783&partnerID=40&md5=10eb6e0ac577df744809551b8388f085","Parkinson’s disease (PD) is a devastating neurological disease that cannot be identified with traditional plasma experiments, necessitating the development of a faster, less expensive diagnostic instrument. Due to the difficulty of quantifying PD in the past, doctors have tended to focus on some signs while ignoring others, primarily relying on an intuitive assessment scale because of the disease’s characteristics, which include loss of motor control and speech that can be utilized to detect and diagnose this disease. It is an illness that impacts both motion and non-motion functions. It takes years to develop and has a wide range of clinical symptoms and prognoses. Parkinson’s patients commonly display non-motor symptoms such as sleep problems, neurocognitive ailments, and cognitive impairment long before the diagnosis, even though scientists have been working to develop designs for diagnosing and categorizing the disease, only noticeable defects such as movement patterns, speech, or writing skills are offered in this paper. This article provides a thorough analysis of several AI-based ML and DL techniques used to diagnose PD and their influence on developing additional research directions. It follows the guidelines of Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR). This review also examines the current state of PD diagnosis and the potential applications of data-driven AI technology. It ends with a discussion of future developments, which aids in filling critical gaps in the current Parkinson’s study. © 2023 by the authors.","2-s2.0-85149247102"
"Raz N.R.; Akbarzadeh M.-R.T.; Setayeshi S.","Raz, Nasibeh Rady (56127014200); Akbarzadeh, Mohammad-R. T. (56241971800); Setayeshi, Saeed (56962768400)","56127014200; 56241971800; 56962768400","Influence-Based Nano Fuzzy Swarm Oxygen Deficiency Detection and Therapy","2023","IEEE Transactions on Systems, Man, and Cybernetics: Systems","53","8","","4994","5005","11","10.1109/TSMC.2023.3252899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153341617&doi=10.1109%2fTSMC.2023.3252899&partnerID=40&md5=3897c1a00b7c9cee9be5039c231520ce","Oxygen deficiency is a serious health problem that may occur as a result of many diseases. In this article, we present an influence-based nano fuzzy swarm (INFS) for oxygen deficiency detection and therapy using a swarm of oxygen carrier nanomachines operating in three cognitive fields of control, influence, and interest. In particular, we propose a long short-term memory (LSTM) deep neural network for detecting apnea by analyzing the irregular peripheral oxygen saturation (SpO2) signal. Using the proposed sleep-in-the-loop strategy and the desaturated blood biomarkers, including oxygen and hydrogen ion concentrations, an in-silico multithreshold nano fuzzy swarm noninvasive therapeutic method is then performed. We also analytically prove the stability of the INFS using swarm control theory. We apply our strategy to sleep apnea, as one of the most common instances of oxygen deficiency. Furthermore, we compare the accuracy of INSF by using LSTM, bidirectional LSTM (BiLSTM), multilayer perceptron (MLP), convolutional neural network (CNN), and support vector machines (SVM). The detection and therapy results are then compared with other apnea detection methods. The input variables and structure of INSF, i.e., the number of rules and width of membership functions, are studied in terms of robustness to noise. As the results show, the proposed artificial intelligence (AI)-based noninvasive nano detection and therapy method could outperform the competing approaches in treating oxygen deficiency emergencies such as apnea.  © 2022 IEEE.","2-s2.0-85153341617"
"Satpathy S.; Misra N.K.; Goyal V.; Das S.; Sharma V.; Ali S.","Satpathy, Sambit (57191034397); Misra, Neeraj Kumar (56405207500); Goyal, Vishal (57196964308); Das, Sanchali (57209974963); Sharma, Vishnu (58659035900); Ali, Shabir (55783020100)","57191034397; 56405207500; 57196964308; 57209974963; 58659035900; 55783020100","An AI-Based Newly Developed Analytical Formulation for Discharging Behavior of Supercapacitors with the Integration of a Review of Supercapacitor Challenges and Advancement Using Quantum Dots","2023","Symmetry","15","4","844","","","","10.3390/sym15040844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156164959&doi=10.3390%2fsym15040844&partnerID=40&md5=9798c5b278dde48f486372c32e84a25b","A supercapacitor is a type of electrical component that has larger capacitance, due to asymmetric behavior with better power density, and lower ESR (effective series resistance) than conventional energy-storage components. Supercapacitors can be used with battery technology to create an effective energy storage system due to their qualities and precise characterization. Studies have shown that the use of quantum dots as electrodes in supercapacitors can significantly increase their effectiveness. In this research article, we have used a Drude model based on free electrons (asymmetric nature) to describe the supercapacitor’s discharging characteristics. Commercially available Nippon DLA and Green-cap supercapacitors were used to verify the Drude model by discharging them through a constant current source using a simple current mirror circuit. The parameters of both the fractional-order models and our suggested method were estimated using the least-squares regression fitting approach. An intriguing finding from the Drude model is the current-dependent behavior of the leakage-parallel resistance in the constant current discharge process. Instead of using the traditional exponential rule, supercapacitors discharge according to a power law. This work reflects the strong symmetry of different aspects of designing a hybrid supercapacitor with high efficiency and reliability. © 2023 by the authors.","2-s2.0-85156164959"
"Berns F.; Zimmermann G.; Borgelt C.; Heilig N.; Kirchhoff J.; Stumpe F.","Berns, Fabian (57207617567); Zimmermann, Georg (57143766400); Borgelt, Christian (58886375500); Heilig, Niclas (57678507700); Kirchhoff, Jan (57678813800); Stumpe, Florian (57678507800)","57207617567; 57143766400; 58886375500; 57678507700; 57678813800; 57678507800","Trustworthy Medical Operational AI: Marrying AI and Regulatory Requirements","2023","Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023","","","","2700","2704","4","10.1109/BigData59044.2023.10386683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184979848&doi=10.1109%2fBigData59044.2023.10386683&partnerID=40&md5=a720d1bf7217ac74d71972dc32e8116c","Despite recent advancements in AI and Data Science, the vast Big Data sources available to medical and health care providers are far from living up to their potential. Addressing the underlying transparency and data protection concerns helps to unleash these advancements in the medical domain and thus benefits research and patient care. Subsequently, we propose a system for trustworthy medical operational AI in this paper. We present our vision to align medical operational AI with regulatory demands of the medical domain. We propose guiding principles to marry data-driven diagnostic recommendations with legal frameworks, clinical protocols, and expert-driven reasoning. Through this research, we aim for AI systems in medicine that not only provide accurate predictions but also empower users to comprehend and trust the underlying decision-making processes.  © 2023 IEEE.","2-s2.0-85184979848"
"Buiten M.; de Streel A.; Peitz M.","Buiten, Miriam (57195264037); de Streel, Alexandre (8715351500); Peitz, Martin (6701667179)","57195264037; 8715351500; 6701667179","The law and economics of AI liability","2023","Computer Law and Security Review","48","","105794","","","","10.1016/j.clsr.2023.105794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148320776&doi=10.1016%2fj.clsr.2023.105794&partnerID=40&md5=449f5f74a370c52dccee8d4373bf66bb","The employment of AI systems presents challenges for liability rules. This paper identifies these challenges and evaluates how liability rules should be adapted in response. The paper discusses the gaps in liability that arise when AI systems are unpredictable or act (semi)-autonomously. It considers the problems in proving fault and causality when errors in AI systems are difficult to foresee for producers, and monitoring duties of users are difficult to define. From an economic perspective, the paper considers what liability rules would minimise costs of harm related to AI. Based on the analysis of risks and optimal liability rules, the paper evaluates the recently published EU proposals for a Product Liability Directive and for an AI Liability Directive. © 2023","2-s2.0-85148320776"
"Foster M.E.; Candelaria P.; Hudson S.; Lindsay A.; Pacquing M.; Petrick R.P.A.; Stinson J.; Zeller F.; Dwyer L.J.; Nishat F.; Ramírez-Duque A.A.; Ali S.","Foster, Mary Ellen (23091020100); Candelaria, Patricia (58148214900); Hudson, Summer (58148494300); Lindsay, Alan (56160096700); Pacquing, Mykelle (58148494400); Petrick, Ronald P. A. (36447706600); Stinson, Jennifer (7006660533); Zeller, Frauke (57099059200); Dwyer, Lauren J. (58148782200); Nishat, Fareha (57201408646); Ramírez-Duque, Andrès Alberto (57204657767); Ali, Samina (55366878700)","23091020100; 58148214900; 58148494300; 56160096700; 58148494400; 36447706600; 7006660533; 57099059200; 58148782200; 57201408646; 57204657767; 55366878700","Co-design of a Social Robot for Distraction in the Paediatric Emergency Department","2023","ACM/IEEE International Conference on Human-Robot Interaction","","","","461","465","4","10.1145/3568294.3580127","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150460905&doi=10.1145%2f3568294.3580127&partnerID=40&md5=db5aaacc8b3a1599dc39b053edeb7701","We are developing a social robot to help children cope with painful and distressing medical procedures in the hospital emergency department. This is a domain where a range of interventions have proven effective at reducing pain and distress, including social robots; however, until now, the robots have been designed with limited stakeholder involvement and have shown limited autonomy. For our system, we have defined and validated the necessary robot behaviour together with children, parents/caregivers, and healthcare professionals, taking into account the ethical and social implications of robotics and AI in the paediatric healthcare context. The result of the co-design process has been captured in a flowchart, which has been converted into a set of concrete design guidelines for the AI-based autonomous robot system. © 2023 IEEE Computer Society. All rights reserved.","2-s2.0-85150460905"
"Occhipinti C.; Carnevale A.; Briguglio L.; Iannone A.; Bisconti P.","Occhipinti, Carmela (57215420933); Carnevale, Antonio (56511501200); Briguglio, Luigi (55822782900); Iannone, Andrea (57221109083); Bisconti, Piercosma (57205669543)","57215420933; 56511501200; 55822782900; 57221109083; 57205669543","SAT: a methodology to assess the social acceptance of innovative AI-based technologies","2023","Journal of Information, Communication and Ethics in Society","21","1","","94","111","17","10.1108/JICES-09-2021-0095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141993879&doi=10.1108%2fJICES-09-2021-0095&partnerID=40&md5=0bf26961dd2bde939850592ff9bbde44","Purpose: The purpose of this paper is to present the conceptual model of an innovative methodology (SAT) to assess the social acceptance of technology, especially focusing on artificial intelligence (AI)-based technology. Design/methodology/approach: After a review of the literature, this paper presents the main lines by which SAT stands out from current methods, namely, a four-bubble approach and a mix of qualitative and quantitative techniques that offer assessments that look at technology as a socio-technical system. Each bubble determines the social variability of a cluster of values: User-Experience Acceptance, Social Disruptiveness, Value Impact and Trust. Findings: The methodology is still in development, requiring further developments, specifications and validation. Accordingly, the findings of this paper refer to the realm of the research discussion, that is, highlighting the importance of preventively assessing and forecasting the acceptance of technology and building the best design strategies to boost sustainable and ethical technology adoption. Social implications: Once SAT method will be validated, it could constitute a useful tool, with societal implications, for helping users, markets and institutions to appraise and determine the co-implications of technology and socio-cultural contexts. Originality/value: New AI applications flood today’s users and markets, often without a clear understanding of risks and impacts. In the European context, regulations (EU AI Act) and rules (EU Ethics Guidelines for Trustworthy) try to fill this normative gap. The SAT method seeks to integrate the risk-based assessment of AI with an assessment of the perceptive-psychological and socio-behavioural aspects of its social acceptability. © 2022, Emerald Publishing Limited.","2-s2.0-85141993879"
"Ehsan U.; Wintersberger P.; Watkins E.A.; Manger C.; Ramos G.; Weisz J.D.; Daumé H., II; Riener A.; Riedl M.O.","Ehsan, Upol (57195223484); Wintersberger, Philipp (55485458100); Watkins, Elizabeth A. (57193833255); Manger, Carina (57223025938); Ramos, Gonzalo (55993680200); Weisz, Justin D. (14036587800); Daumé, Hal (57210198346); Riener, Andreas (23012938100); Riedl, Mark O. (7004421643)","57195223484; 55485458100; 57193833255; 57223025938; 55993680200; 14036587800; 57210198346; 23012938100; 7004421643","Human-Centered Explainable AI (HCXAI): Coming of Age","2023","Conference on Human Factors in Computing Systems - Proceedings","","","353","","","","10.1145/3544549.3573832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158123516&doi=10.1145%2f3544549.3573832&partnerID=40&md5=f45781f736c33aca8cdccddc3e641b64","Explainability is an essential pillar of Responsible AI that calls for equitable and ethical Human-AI interaction. Explanations are essential to hold AI systems and their producers accountable, and can serve as a means to ensure humans' right to understand and contest AI decisions. Human-centered XAI (HCXAI) argues that there is more to making AI explainable than algorithmic transparency. Explainability of AI is more than just ""opening""the black box - who opens it matters just as much, if not more, as the ways of opening it. In this third CHI workshop on Human-centered XAI (HCXAI), we build on the maturation through the first two installments to craft the coming-of-age story of HCXAI, which embodies a deeper discourse around operationalizing human-centered perspectives in XAI. We aim towards actionable interventions that recognize both affordances and potential pitfalls of XAI. The goal of the third installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we emphasize ""operationalizing.""Within our research agenda for XAI, we seek actionable analysis frameworks, concrete design guidelines, transferable evaluation methods, and principles for accountability. © 2023 Owner/Author.","2-s2.0-85158123516"
"Yavich R.; Malev S.; Volinsky I.; Rotkin V.","Yavich, Roman (55960217000); Malev, Sergey (15750889700); Volinsky, Irina (56069519200); Rotkin, Vladimir (58488148800)","55960217000; 15750889700; 56069519200; 58488148800","Configurable Intelligent Design Based on Hierarchical Imitation Models","2023","Applied Sciences (Switzerland)","13","13","7602","","","","10.3390/app13137602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164793973&doi=10.3390%2fapp13137602&partnerID=40&md5=5fc3880c859800e4d2e0b56c74a38510","The deterministic AI system under review is an alternative to neural-network-based machine learning. In its application fields, which are science, technology, engineering, and business, the implementation of rule-based AI systems leads to benefits such as accuracy and correctness of design, and personalization of the process itself and the results. An algorithmic AI suite is based on design and logical imitation models alone, without creating and/or using Big Data and knowledge bases. Excessive complexity of configuration and high design resource capacity, which are inherent in deterministic systems, are balanced by a special methodology. A hierarchical modeling approach gives a quasi-dynamic network effect, symmetric to the analogous effect in neural networks. System performance is improved by deterministic reference training capable of modifying imitation models in online interaction with users. Such training, which serves as an alternative to neural machine learning, can be implemented by means of experimental partially empirical algorithms and system–user dialogues to build reference model libraries (portfolios). Partially empirical algorithms based on experimental design methods and system user dialogues are used to create reference model libraries (portfolios) that form a deterministic training system, which can be an alternative to neural machine learning. Estimated resources can be saved by using modified optimization techniques and by controlling the computational complexity of the algorithms. Since the proposed system in the considered layout has no analogues, and the relevant research and practical knowledge are extremely limited, special methods are required to implement this project. A gradual, phased implementation process involves the step-by-step formation of sets of algorithms with verification tests at each stage. Each test is performed using an iteration method, and each test includes test, tweak, and modification cycles. Final testing should lead to the development of an AI algorithm package, including related methodological and working papers. © 2023 by the authors.","2-s2.0-85164793973"
"Villmow J.; Campos V.; Petry J.; Abbad-Andaloussi A.; Ulges A.; Weber B.","Villmow, Johannes (57203089862); Campos, Viola (57668301600); Petry, Jean (58821330300); Abbad-Andaloussi, Amine (57202494427); Ulges, Adrian (8231074700); Weber, Barbara (7401435414)","57203089862; 57668301600; 58821330300; 57202494427; 8231074700; 7401435414","How Well Can Masked Language Models Spot Identifiers That Violate Naming Guidelines?","2023","Proceedings - 2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation, SCAM 2023","","","","131","142","11","10.1109/SCAM59687.2023.00023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182729792&doi=10.1109%2fSCAM59687.2023.00023&partnerID=40&md5=9125f59f0749b5e1653cddcddbcee223","Using meaningful identifiers in source code reduces the risk of errors, the cognitive load of developers, and speeds up the development process. Therefore, recent research has looked into an AI-based analysis of identifiers, for which large-scale language models appear to offer great potential. Based on tokens' probabilities, such models can suggest identifiers that are likely to appear in a given context. While current research has used language models to predict the most likely identifier names, studies on assessing the quality of given identifiers are scarce. To this end, we explore adherence to identifier naming guidelines as a proxy for identifier quality and propose and evaluate two unsupervised approaches for spotting violations: First, a generative approach, which uses the probability distribution of the language model directly without fine-tuning. Second, a discriminative method, which fine-tunes the model's encoder to discriminate between original identifiers and similar drop-in replacements suggested by a weak AI. We demonstrate that the proposed approaches can successfully detect violations of common guidelines for identifier naming. To do so, we have developed a dataset built on widely accepted identifier naming guidelines. The manually annotated dataset contains more than 6000 dense annotations of identifiers for 28 common guidelines. Using the data, we show that the generative approach achieves the best results, but that the particular masking strategy and scoring method matter substantially. Also, we demonstrate our approach to outperform other recent code transformers. In a per-guideline analysis, we highlight the potential and limitations of language models, and provide a blue-print for training and evaluating their ability to identify bad identifier names in source code. We make our dataset and models' implementation publicly available to encourage future research on AI-based identifier quality assessment.  © 2023 IEEE.","2-s2.0-85182729792"
"Karinshak E.; Liu S.X.; Park J.S.; Hancock J.T.","Karinshak, Elise (58203826600); Liu, Sunny Xun (57202048903); Park, Joon Sung (57222403758); Hancock, Jeffrey T. (7202389095)","58203826600; 57202048903; 57222403758; 7202389095","Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages","2023","Proceedings of the ACM on Human-Computer Interaction","7","CSCW1","116","","","","10.1145/3579592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153940405&doi=10.1145%2f3579592&partnerID=40&md5=4f68a46fded29bd7882d1ba0f1850f0d","Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.  © 2023 ACM.","2-s2.0-85153940405"
"Schedl M.; Gómez E.; Lex E.","Schedl, Markus (8684865900); Gómez, Emilia (14015483200); Lex, Elisabeth (25928014700)","8684865900; 14015483200; 25928014700","Trustworthy Algorithmic Ranking Systems","2023","WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining","","","","1240","1243","3","10.1145/3539597.3572723","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149664260&doi=10.1145%2f3539597.3572723&partnerID=40&md5=b163e003a18202a646be0005f81abaa4","This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency as relevant dimensions of trustworthy AI systems, tailored to algorithmic ranking systems such as search engines and recommender systems. We will equip the mostly technical audience of WSDM with the necessary understanding of the social and ethical implications of their research and development on the one hand, and of recent ethical guidelines and regulatory frameworks addressing the aforementioned dimensions on the other hand. While the tutorial foremost takes a European perspective, starting from the concept of trustworthy AI and discussing EU regulation in this area currently in the implementation stages, we also consider related initiatives worldwide. Since ensuring non-discrimination, diversity, and transparency in retrieval and recommendation systems is an endeavor in which academic institutions and companies in different parts of the world should collaborate, this tutorial is relevant for researchers and practitioners interested in the ethical, social, and legal impact of their work. The tutorial, therefore, targets both academic scholars and practitioners around the globe, by reviewing recent research and providing practical examples addressing these particular trustworthiness aspects, and showcasing how new regulations affect the audience's daily work. © 2023 Owner/Author.","2-s2.0-85149664260"
"Paik S.; Bonna S.; Novozhilova E.; Gao G.; Kim J.; Wijaya D.; Betke M.","Paik, Sejin (57455734000); Bonna, Sarah (58876424000); Novozhilova, Ekaterina (58827074100); Gao, Ge (57455117400); Kim, Jongin (58770008000); Wijaya, Derry (23391324000); Betke, Margrit (7004214113)","57455734000; 58876424000; 58827074100; 57455117400; 58770008000; 23391324000; 7004214113","The Affective Nature of AI-Generated News Images: Impact on Visual Journalism","2023","2023 11th International Conference on Affective Computing and Intelligent Interaction, ACII 2023","","","","","","","10.1109/ACII59096.2023.10388166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665586&doi=10.1109%2fACII59096.2023.10388166&partnerID=40&md5=5669ec54ce51d084fd7184b68c295be2","This study explores the affective responses and newsworthiness perceptions of generative AI for visual journalism. While generative AI offers advantages for newsrooms in terms of producing unique images and cutting costs, the potential misuse of AI-generated news images is a cause for concern. For our study, we designed a 3-part news image codebook for affect-labeling news images based on journalism ethics and photography guidelines. We collected 200 news headlines and images retrieved from a variety of U.S. news sources on the topics of gun violence and climate change, generated corresponding news images from DALL-E 2 and asked annotators their emotional responses to the human-selected and AI-generated news images following the codebook. We also examined the impact of modality on emotions by measuring the effects of visual and textual modalities on emotional responses. The findings of this study provide insights into the quality and emotional impact of generative news images produced by humans and AI. Further, results of this work can be useful in developing technical guidelines as well as policy measures for the ethical use of generative AI systems in journalistic production. The codebook, images and annotations are made publicly available to facilitate future research in affective computing, specifically tailored to civic and public-interest journalism.  © 2023 IEEE.","2-s2.0-85184665586"
"Zhang R.","Zhang, Rong (57490337600)","57490337600","Using Artificial Intelligence Assistant Technology to Develop Animation Games on IoT","2023","Computer Science and Information Systems","20","2","","765","792","27","10.2298/CSIS220719021Z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158946526&doi=10.2298%2fCSIS220719021Z&partnerID=40&md5=22332e58953898c82cf1e11704d9fb0e","This research proposes an XNA animation game system with AI technology for action animation games in mobile devices, based on an object-oriented modular concept. The animation game function with AI technology is encapsulated into independent objects, through the combination of objects to build repetition. It adds AI technology to the finite state machine, fuzzy state machine and neural network and attempts to combine the traditional rule-base system and learning adaptation system to increase the learning ability of traditional AI roles. The main contributions are compared with traditional methods and the AI animation game system is shown to have more reusability, design flexibility and expansibility of its AI system through the object composition approach. It adds AI technology to combine the traditional rule-base system and learning adaptation system to increase the learning ability of traditional AI roles. Therefore, AI animation game producers can accelerate their processes of developing animation games and reducing costs. © 2023, ComSIS Consortium. All rights reserved.","2-s2.0-85158946526"
"Park J.H.; Oh S.W.; Na M.G.","Park, Ji Hun (57222125593); Oh, Sang Won (57256272900); Na, Man Gyun (7006636997)","57222125593; 57256272900; 7006636997","Application of Rule Extraction for Explainability of Artificial Intelligence in Nuclear Power Plants","2023","Proceedings of 13th Nuclear Plant Instrumentation, Control and Human-Machine Interface Technologies, NPIC and HMIT 2023","","","","1540","1549","9","10.13182/NPICHMIT23-41016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183315454&doi=10.13182%2fNPICHMIT23-41016&partnerID=40&md5=a245d9df92060ae18c09be7087a58253","In order to improve the safety of nuclear power plants (NPPs), studies on artificial intelligence (AI)based operator support systems to reduce human errors of operators are being actively conducted. However, the black-box characteristic of AI interrupts its application in NPPs due to the lack of transparency, explainability, and reliability of AI. In this paper, a rule extraction method was used to secure transparency, explainability, and reliability of the operator support system to support operators in abnormal situations of NPPs. In NPPs, many abnormal operating procedures are prepared to mitigate abnormal situations, but a decision-making process is involved in selecting an appropriate procedure among them. The system in this paper was developed using the deep neural network (DNN) method as a procedure recommendation system to support such a decision-making process, and data required for developing the DNN model was collected by simulating abnormal situations in NPPs using the compact nuclear simulator. The optimization of the DNN model was achieved using a combination of grid search and early stopping methods. The efficient clause-wise rule extraction method was applied to extract the rules of the DNN model, and the extracted rules are used to construct a rule-based system comprising a set of single rules in the form of “IF…THEN”. The rule-based system helps understand the prediction method of the model by extracting understandable rules and decision criteria. The accuracy and fidelity are used as evaluation metrics to measure the ability of the extracted rule-based system to describe the DNN model. As a result, the application of the rule extraction method can provide additional insights into the decision-making process of AI-based operator support systems in NPPs. © 2023 American Nuclear Society, Incorporated.","2-s2.0-85183315454"
"Luo F.; Yang Z.; Zhang Z.; Wang Z.; Wang B.; Wu M.","Luo, Feng (57207053450); Yang, Zhenyu (57218377717); Zhang, Zhaojing (57288805400); Wang, Zitong (57573362800); Wang, Bowen (57224476976); Wu, Mingzhi (57482056700)","57207053450; 57218377717; 57288805400; 57573362800; 57224476976; 57482056700","A Multi-Layer Intrusion Detection System for SOME/IP-Based In-Vehicle Network","2023","Sensors","23","9","4376","","","","10.3390/s23094376","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159166938&doi=10.3390%2fs23094376&partnerID=40&md5=42ff730cc1c51ef172b80b55750d9252","The automotive Ethernet is gradually replacing the traditional controller area network (CAN) as the backbone network of the vehicle. As an essential protocol to solve service-based communication, Scalable service-Oriented MiddlewarE over IP (SOME/IP) is expected to be applied to an in-vehicle network (IVN). The increasing number of external attack interfaces and the protocol’s vulnerability makes SOME/IP in-vehicle networks vulnerable to intrusion. This paper proposes a multi-layer intrusion detection system (IDS) architecture, including rule-based and artificial intelligence (AI)-based modules. The rule-based module is used to detect the SOME/IP header, SOME/IP-SD message, message interval, and communication process. The AI-based module acts on the payload. We propose a SOME/IP dataset establishment method to evaluate the performance of the proposed multi-layer IDS. Experiments are carried out on a Jetson Xavier NX, showing that the accuracy of AI-based detection reached 99.7761% and that of rule-based detection was 100%. The average detection time per packet is 0.3958 ms with graphics processing unit (GPU) acceleration and 0.6669 ms with only a central processing unit (CPU). After vehicle-level real-time analyses, the proposed IDS can be deployed for distributed or select critical advanced driving assistance system (ADAS) traffic for detection in a centralized layout. © 2023 by the authors.","2-s2.0-85159166938"
"Williams R.; Ali S.; Devasia N.; DiPaola D.; Hong J.; Kaputsos S.P.; Jordan B.; Breazeal C.","Williams, Randi (57195219936); Ali, Safinah (57207448534); Devasia, Nisha (57220066687); DiPaola, Daniella (57208863454); Hong, Jenna (57224002868); Kaputsos, Stephen P. (57215312351); Jordan, Brian (57687176100); Breazeal, Cynthia (7003691791)","57195219936; 57207448534; 57220066687; 57208863454; 57224002868; 57215312351; 57687176100; 7003691791","AI + Ethics Curricula for Middle School Youth: Lessons Learned from Three Project-Based Curricula","2023","International Journal of Artificial Intelligence in Education","33","2","","325","383","58","10.1007/s40593-022-00298-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135260266&doi=10.1007%2fs40593-022-00298-y&partnerID=40&md5=b97a72bdfb611dc20a48437ae49abd09","Artificial Intelligence (AI) is revolutionizing many industries and becoming increasingly ubiquitous in everyday life. To empower children growing up with AI to navigate society’s evolving sociotechnical context, we developed three middle school AI literacy curricula: Creative AI, Dancing with AI, and How to Train Your Robot. In this paper we discuss how we leveraged three design principles—active learning, embedded ethics, and low barriers to access – to effectively engage students in learning to create and critique AI artifacts. During the summer of 2020, we recruited and trained in-service, middle school teachers from across the United States to co-instruct online workshops with students from their schools. In the workshops, a combination of hands-on unplugged and programming activities facilitated students’ understanding of AI. As students explored technical concepts in tandem with ethical ones, they developed a critical lens to better grasp how AI systems work and how they impact society. We sought to meet the specified needs of students from a range of backgrounds by minimizing the prerequisite knowledge and technology resources students needed to participate. Finally, we conclude with lessons learned and design recommendations for future AI curricula, especially for K-12 in-person and virtual learning. © 2022, The Author(s).","2-s2.0-85135260266"
"Agbese M.; Mohanani R.; Khan A.; Abrahamsson P.","Agbese, Mamia (57322330600); Mohanani, Rahul (57063218100); Khan, Arif (26434399300); Abrahamsson, Pekka (7006011356)","57322330600; 57063218100; 26434399300; 7006011356","Implementing AI Ethics: Making Sense of the Ethical Requirements","2023","ACM International Conference Proceeding Series","","","","62","71","9","10.1145/3593434.3593453","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162223727&doi=10.1145%2f3593434.3593453&partnerID=40&md5=bfca1694fb0b3d253b70ded36161b6fd","Society's increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.  © 2023 Owner/Author.","2-s2.0-85162223727"
"Balasubramaniam N.; Kauppinen M.; Rannisto A.; Hiekkanen K.; Kujala S.","Balasubramaniam, Nagadivya (57201946113); Kauppinen, Marjo (9044243800); Rannisto, Antti (57890514200); Hiekkanen, Kari (37017103300); Kujala, Sari (55377510200)","57201946113; 9044243800; 57890514200; 37017103300; 55377510200","Transparency and explainability of AI systems: From ethical guidelines to requirements","2023","Information and Software Technology","159","","107197","","","","10.1016/j.infsof.2023.107197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150888173&doi=10.1016%2fj.infsof.2023.107197&partnerID=40&md5=bfa0b5e96df1162eca52e7b8906f4baf","Context and Motivation: Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. Objective: This study consisted of two phases. The first goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems and then we investigated how explainability requirements can be defined in practice. Methods: In the first phase, we analyzed the ethical guidelines in 16 organizations representing different industries and public sector. Then, we conducted an empirical study to evaluate the results of the first phase with practitioners. Results: The analysis of the ethical guidelines revealed that the importance of transparency is highlighted by almost all of the organizations and explainability is considered as an integral part of transparency. To support the definition of explainability requirements, we propose a model of explainability components for identifying explainability needs and a template for representing explainability requirements. The paper also describes the lessons we learned from applying the model and the template in practice. Contribution: For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a systematic and structured way to define explainability requirements of AI systems. Furthermore, the results emphasize a set of good practices that help to define the explainability of AI systems. © 2023","2-s2.0-85150888173"
"Martinez J.; Eguia A.; Urretavizcaya I.; Amparan E.; Negro López P.","Martinez, Jabier (55376565900); Eguia, Alexander (58850349300); Urretavizcaya, Imanol (57211159138); Amparan, Estibaliz (57195635358); Negro López, Pablo (58850657800)","55376565900; 58850349300; 57211159138; 57195635358; 58850657800","Fault Tree Analysis and Failure Modes and Effects Analysis for Systems with Artificial Intelligence: A Mapping Study","2023","2023 7th International Conference on System Reliability and Safety, ICSRS 2023","","","","464","473","9","10.1109/ICSRS59833.2023.10381456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183473600&doi=10.1109%2fICSRS59833.2023.10381456&partnerID=40&md5=090510ddac7703ca68c93042075ad314","Reliability engineering has well-established analysis techniques to design critical systems that will be safe to operate. Two already field-proven techniques are the FTA (Fault Tree Analysis) and the FMECA (Failure Modes, Effects, and Criticality Analysis). These techniques, recommended or required by several supervisory authorities or independent assessments, will continue to be the main assets for the analysis of potential failures and faults. This mapping study revisits FMECA and FTA from the perspective of how they are used when dealing with systems with Artificial Intelligence (AI) components. After the literature database search and selection, 24 primary sources were leveraged to map them regarding their context, scope, considerations, and maturity. The diversity of safety-critical application domains and functions, and the need of more evidences from the evaluations of the proposed approaches, suggest that this field requires a pressing attention. The extracted considerations can be relevant elements of industrial guidelines.  © 2023 IEEE.","2-s2.0-85183473600"
"Shimizu A.; Wakabayashi K.; Matsubara M.; Ito H.; Morishima A.","Shimizu, Ayame (57407417800); Wakabayashi, Kei (23399137900); Matsubara, Masaki (55608696000); Ito, Hiroyoshi (57192271188); Morishima, Atsuyuki (36829985300)","57407417800; 23399137900; 55608696000; 57192271188; 36829985300","Hybrid Crowd-AI Learning for Human-Interpretable Symbolic Rules in Image Classification","2023","Proceedings - 2023 14th IIAI International Congress on Advanced Applied Informatics, IIAI-AAI 2023","","","","263","270","7","10.1109/IIAI-AAI59060.2023.00060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183465394&doi=10.1109%2fIIAI-AAI59060.2023.00060&partnerID=40&md5=72289775e1dce9daf5e645dc11c465db","Explainable AI is an indispensable goal for an AI-based society with trust, and deriving human-interpretable symbolic rules is one of the promising ways to verify whether the decision is appropriate. This paper explores a hybrid crowd-AI approach to develop white-box ML models associated with human-interpretable symbolic rules. The key idea of the proposed method is to discover human-interpretable latent features from trained neural networks by leveraging human abductive reasoning. The proposed method automatically generates crowdsourcing tasks that display subsets of images corresponding to each latent feature and ask crowd workers to provide the semantics of the features in natural language. The obtained semantics allow us to use the latent features as human-interpretable predicates that form symbolic rules to define target classes. We provide experimental results showing that the proposed approach can obtain interpretable symbolic rules and explanations.  © 2023 IEEE.","2-s2.0-85183465394"
"Siamnik-Krijestorac N.; Camelo M.; Chang C.-Y.; Soto P.; Cominardi L.; De Vleeschauwer D.; Latre S.; Marquez-Barja J.M.","Siamnik-Krijestorac, Nina (58685795700); Camelo, Miguel (36699296900); Chang, Chia-Yu (57190347041); Soto, Paola (57220360548); Cominardi, Luca (36634005000); De Vleeschauwer, Danny (55906562400); Latre, Steven (24470054300); Marquez-Barja, Johann M. (36185955700)","58685795700; 36699296900; 57190347041; 57220360548; 36634005000; 55906562400; 24470054300; 36185955700","AI-Empowered Management and Orchestration of Vehicular Systems in the Beyond 5G Era","2023","IEEE Network","37","4","","305","313","8","10.1109/MNET.008.2300024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176101047&doi=10.1109%2fMNET.008.2300024&partnerID=40&md5=92328bfd0b8321ed3d5905e9fde88429","The complexity of orchestrating Beyond 5G services, such as vehicular, demands novel approaches to remove limitations of existing techniques, as these might cause a large delay in orchestration operations, and thus, negatively impact the service performance. For instance, the human-in-the-loop approach is slow and prone to errors, and closed loop control using rule-based algorithms is difficult to design, as an abundant number of parameters need to be configured. Applying Artificial Intelligence (Al)/Machine Learning (ML), in combination with Network Function Virtualization (NFV) and Software Defined Networking (SDN), seems a promising solution for enabling automation and intelligence that will optimize orchestration operations. In this article, we study the challenges in current ETSI NFV orchestration solutions for B5G C-V2X edge services; propose an Al/ML-based closed-loop orchestration framework; propose how and which Al/ML techniques can alleviate the identified challenges and what are the implications resulting from applying certain Al/ML techniques; and discuss A//ML-based system enablers for B5G C-V2X services.  © 1986-2012 IEEE.","2-s2.0-85176101047"
"Van Zoelen E.; Mioch T.; Tajaddini M.; Fleiner C.; Tsaneva S.; Camin P.; Gouvêa T.S.; Baraka K.; De Boer M.H.T.; Neerincx M.A.","Van Zoelen, Emma (57211354974); Mioch, Tina (26422455500); Tajaddini, Mani (58590464300); Fleiner, Christian (57263212300); Tsaneva, Stefani (57940278400); Camin, Pietro (57969932800); Gouvêa, Thiago S. (23008537400); Baraka, Kim (55844333800); De Boer, Maaike H. T. (56021703700); Neerincx, Mark A. (9133405200)","57211354974; 26422455500; 58590464300; 57263212300; 57940278400; 57969932800; 23008537400; 55844333800; 56021703700; 9133405200","Developing Team Design Patterns for Hybrid Intelligence Systems","2023","Frontiers in Artificial Intelligence and Applications","368","","","3","16","13","10.3233/FAIA230071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170360346&doi=10.3233%2fFAIA230071&partnerID=40&md5=9fc705438622c521d751a1cb149fcd15","With artificial intelligence (AI) systems entering our working and leisure environments with increasing adaptation and learning capabilities, new opportunities arise for developing hybrid (human-AI) intelligence (HI) systems, comprising new ways of collaboration. However, there is not yet a structured way of specifying design solutions of collaboration for hybrid intelligence (HI) systems and there is a lack of best practices shared across application domains. We address this gap by investigating the generalization of specific design solutions into design patterns that can be shared and applied in different contexts. We present a human-centered bottom-up approach for the specification of design solutions and their abstraction into team design patterns. We apply the proposed approach for 4 concrete HI use cases and show the successful extraction of team design patterns that are generalizable, providing re-usable design components across various domains. This work advances previous research on team design patterns and designing applications of HI systems. © 2023 The Authors.","2-s2.0-85170360346"
"Yang Y.; Fu H.; Zhong X.; Zhang T.","Yang, Yulong (58876720600); Fu, Hongguang (56198538800); Zhong, Xiuqin (15120193700); Zhang, Tianming (58876404100)","58876720600; 56198538800; 15120193700; 58876404100","SUFFI-GPSC: Sufficient Geometry Problem Solution Checking with Symbolic Computation and Logical Reasoning","2023","2023 20th International Computer Conference on Wavelet Active Media Technology and Information Processing, ICCWAMTIP 2023","","","","","","","10.1109/ICCWAMTIP60502.2023.10387025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184655376&doi=10.1109%2fICCWAMTIP60502.2023.10387025&partnerID=40&md5=ff0ca5ec0d49bc3554dfdb216ec8f3b8","Logical reasoning and computational solving skill play a vital role in geometry problem solving (GPS). The development of large-scale language models has facilitated the progress of artificial intelligence (AI) systems capable of solving math word problems and proving theorems. These models have achieved remarkable results across various geometry problem datasets, attracting significant attention in natural language processing community. However, it remains a challenge to effectively evaluate the logical correctness in the process of solution steps answered by the model due to the diversity of solution approaches. Therefore, we propose a powerful approach that can check the logical sufficiency of the solving process of given geometry problems step by step with symbolic computation and logical reasoning, called Sufficient Geometry problem solution checking (Suffi-GPSC). Suffi-GPSC divides the tasks into two categories, one focuses on equation expressions and checks whether the target equations are true with symbolic computation under the preconditions that contain a large number of equations. The other focuses on geometric relationships and checks whether the goal relation can be deduced within limited steps with logical reasoning by considering known facts as conditions and axiomatic knowledge as conditional rules. Inspired by the mainstream, a theorem predictor based on transfer text-to-text transformer(T5) has been designed to generate the theorem sequences for a more efficient and rational reasoning process. Extensive experiments on the Geometry3K dataset demonstrate that Suffi-GPSC achieves remarkable improvements.  © 2023 IEEE.","2-s2.0-85184655376"
"Järvelä S.; Nguyen A.; Vuorenmaa E.; Malmberg J.; Järvenoja H.","Järvelä, Sanna (6603585406); Nguyen, Andy (57203165579); Vuorenmaa, Eija (57938933700); Malmberg, Jonna (35764884800); Järvenoja, Hanna (8966602300)","6603585406; 57203165579; 57938933700; 35764884800; 8966602300","Predicting regulatory activities for socially shared regulation to optimize collaborative learning","2023","Computers in Human Behavior","144","","107737","","","","10.1016/j.chb.2023.107737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150394250&doi=10.1016%2fj.chb.2023.107737&partnerID=40&md5=0c7b6ef3bbad19e6e2448dbd5d3a26ca","This study utilized multimodal learning analytics and AI-based methods to examine the patterns of the socially shared regulation of collaborative learning (CL). The study involved multimodal data involving video and electrodermal activities (EDA) data collected from ninety-four secondary school students (N = 94) during five science lessons to reveal trigger events in CL. A novel concept of trigger events is introduced, which are challenging events and/or situations that may inhibit collaboration and will, therefore, require strategic adaptation in the regulation of cognition, motivation, and emotion within the group. The ANOVA results for the Skin Conductance Responses (SCRs) analysis indicated the disparity of physiological behavior activated in relation to different types of interactions for regulation. Process analysis and episode-rule mining were applied to reveal regulatory patterns in CL, while an AI approach with long short-term memory (LSTM) deep-learning networks were designed for pattern prediction. LSTM has emerged as the most widely applied artificial recurrent neural network (RNN) architecture for sequential data analysis and classification. The proposed AI network holds the potential for designing solutions for similar signal-processing problems in studying learning regulation. This study contributes to developing AI-enabled real-time support for regulation in collaborative learning. © 2023 The Authors","2-s2.0-85150394250"
"Mosaiyebzadeh F.; Pouriyeh S.; Parizi R.M.; Sheng Q.Z.; Han M.; Zhao L.; Sannino G.; Ranieri C.M.; Ueyama J.ó.; Batista D.M.","Mosaiyebzadeh, Fatemeh (57440757600); Pouriyeh, Seyedamin (57195966015); Parizi, Reza M. (24478984000); Sheng, Quan Z. (57208669610); Han, Meng (55872233600); Zhao, Liang (56278541200); Sannino, Giovanna (36239105500); Ranieri, Caetano Mazzoni (55662436600); Ueyama, J.ó. (6701846104); Batista, Daniel Macêdo (22733809600)","57440757600; 57195966015; 24478984000; 57208669610; 55872233600; 56278541200; 36239105500; 55662436600; 6701846104; 22733809600","Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey","2023","Electronics (Switzerland)","12","12","2703","","","","10.3390/electronics12122703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163893152&doi=10.3390%2felectronics12122703&partnerID=40&md5=63c51aa760f87d9acc970b23e2cfc4fc","Advancements in wearable medical devices using the IoT technology are shaping the modern healthcare system. With the emergence of the Internet of Healthcare Things (IoHT), efficient healthcare services can be provided to patients. Healthcare professionals have effectively used AI-based models to analyze the data collected from IoHT devices to treat various diseases. Data must be processed and analyzed while avoiding privacy breaches, in compliance with legal rules and regulations, such as the HIPAA and GDPR. Federated learning (FL) is a machine learning-based approach allowing multiple entities to train an ML model collaboratively without sharing their data. It is particularly beneficial in healthcare, where data privacy and security are substantial concerns. Even though FL addresses some privacy concerns, there is still no formal proof of privacy guarantees for IoHT data. Privacy-enhancing technologies (PETs) are tools and techniques designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users’ personal information and sensitive data from unauthorized access and tracking. This paper comprehensively reviews PETs concerning FL in the IoHT scenario and identifies several key challenges for future research. © 2023 by the authors.","2-s2.0-85163893152"
"Boesl D.B.O.; Achtenberg T.; Bergler L.","Boesl, Dominik B.O. (57192434246); Achtenberg, Teresa (58136065600); Bergler, Lisa (58886696000)","57192434246; 58136065600; 58886696000","Foundations of an AI-based, cross-plattform companion app for lifelong learning optimization","2023","2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering, TALE 2023 - Conference Proceedings","","","","","","","10.1109/TALE56641.2023.10398394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184996246&doi=10.1109%2fTALE56641.2023.10398394&partnerID=40&md5=545ed3957facff28c1d1afaadbb17e28","Artificial Intelligence (AI) has revolutionized various domains, including education. It has the potential to transform traditional educational models and provide personalized learning experiences. Lifelong learning and continuing education have become essentials pillars for expanding personal growth and skill profiles in the professional world. This paper outlines the basis of lifelong learning and continuing education and presents assumptions, analyses, and a framework for the development of an Ai-based, cross-Platform cOmpanion-App [for] Lifelong Learning Optimization (acronym: APOLLO) as part of a 36-month funding project kindly supported by the German Federal Ministry of Education and Research (BMBF) and supervised by the German Federal Institute for Vocational Education and Training (BIBB) as part of the funding guideline of the innovation competition INVITE. It outlines the project idea, describes the motivation and the problem in the field of education.  © 2023 IEEE.","2-s2.0-85184996246"
"Pan X.; Zhao F.; Zhang Y.; Wang X.; Xiao X.; Zhang J.Z.H.; Ji C.","Pan, Xiaolin (57222585989); Zhao, Fanyu (58164969300); Zhang, Yueqing (57658956400); Wang, Xingyu (36814890100); Xiao, Xudong (57225874058); Zhang, John Z. H. (35235961100); Ji, Changge (27567812000)","57222585989; 58164969300; 57658956400; 36814890100; 57225874058; 35235961100; 27567812000","MolTaut: A Tool for the Rapid Generation of Favorable Tautomer in Aqueous Solution","2023","Journal of Chemical Information and Modeling","63","7","","1833","1840","7","10.1021/acs.jcim.2c01393","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151268926&doi=10.1021%2facs.jcim.2c01393&partnerID=40&md5=dd7fe73cc67758e9fdde7eb82f11690a","Fast and proper treatment of the tautomeric states for drug-like molecules is critical in computer-aided drug discovery since the major tautomer of a molecule determines its pharmacophore features and physical properties. We present MolTaut, a tool for the rapid generation of favorable states of drug-like molecules in water. MolTaut works by enumerating possible tautomeric states with tautomeric transformation rules, ranking tautomers with their relative internal energies and solvation energies calculated by AI-based models, and generating preferred ionization states according to predicted microscopic pKa. Our test shows that the ranking ability of the AI-based tautomer scoring approach is comparable to the DFT method (wB97X/6-31G*//M062X/6-31G*/SMD) from which the AI models try to learn. We find that the substitution effect on tautomeric equilibrium is well predicted by MolTaut, which is helpful in computer-aided ligand design. The source code of MolTaut is freely available to researchers and can be accessed at https://github.com/xundrug/moltaut. To facilitate the usage of MolTaut by medicinal chemists, we made a free web server, which is available at http://moltaut.xundrug.cn. MolTaut is a handy tool for investigating the tautomerization issue in drug discovery. © 2023 American Chemical Society","2-s2.0-85151268926"
"Kramcsák P.T.","Kramcsák, Pablo Trigo (57215617013)","57215617013","Can legitimate interest be an appropriate lawful basis for processing Artificial Intelligence training datasets?","2023","Computer Law and Security Review","48","","105765","","","","10.1016/j.clsr.2022.105765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142770735&doi=10.1016%2fj.clsr.2022.105765&partnerID=40&md5=4aa170b9e70a6f4d0531507f3e4c4b88","Precision and effectiveness of Artificial Intelligence (AI) models are highly dependent on the availability of genuine, relevant, and representative training data. AI systems tested and validated on poor-quality datasets can produce inaccurate, erroneous, skewed, or harmful outcomes (actions, behaviors, or decisions), with far-reaching effects on individuals' rights and freedoms. Appropriate data governance for AI development poses manifold regulatory challenges, especially regarding personal data protection. An area of concern is compliance with rules for lawful collection and processing of personal data, which implies, inter alia, that using databases for AI design and development should be based on a clear and precise legal ground: the prior consent of the data subject or another specific valid legal basis. Faced with this challenge, the European Union's personal data protection legal framework does not provide a preferred, one-size-fits-all answer, and the best option will depend on the circumstances of each case. Although there is no hierarchy among the different legal bases for data processing, in doubtful cases, consent is generally understood by data controllers as a preferred or default choice for lawful data processing. Notwithstanding this perception, obtaining data subjects' consent is not without drawbacks for AI developers or AI-data controllers, as they must meet (and demonstrate) various requirements for the validity of consent. As a result, data subjects' consent could not be a suitable and realistic option to serve AI development purposes. In view of this, it is necessary to explore the possibility of basing this type of personal data processing on lawful grounds other than the data subject's consent, specifically, the legitimate interest of the data controller or third parties. Given its features, legitimate interests could help to meet the challenge of quality, quantity, and relevance of data curation for AI training. The aim of this article is to provide an initial conceptual approach to support the debate about data governance for AI development in the European Union (EU), as well as in non-EU jurisdictions with European-like data protection laws. Based on the rules set by the EU General Data Protection Regulation (GDPR), this paper starts by referring to the relevance of adequate data curation and processing for designing trustworthy AI systems, followed by a legal analysis and conceptualization of some difficulties data controllers face for lawful processing of personal data. After reflecting on the legal standards for obtaining data subject's valid consent, the paper argues that legitimate interests (if certain criteria are met) may better match the purpose of building AI training datasets. © 2022 Pablo Trigo Kramcsák","2-s2.0-85142770735"
"Daole M.; Schiavo A.; Corcuera Bárcena J.L.; Ducange P.; Marcelloni F.; Renda A.","Daole, Mattia (57224506581); Schiavo, Alessio (57984481800); Corcuera Bárcena, José Luis (57887157800); Ducange, Pietro (16425459700); Marcelloni, Francesco (7003309696); Renda, Alessandro (57203896405)","57224506581; 57984481800; 57887157800; 16425459700; 7003309696; 57203896405","OpenFL-XAI: Federated learning of explainable artificial intelligence models in Python","2023","SoftwareX","23","","101505","","","","10.1016/j.softx.2023.101505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169915657&doi=10.1016%2fj.softx.2023.101505&partnerID=40&md5=cadb47342c26fc3baddcd052c12aafbe","Artificial Intelligence (AI) systems play a significant role in manifold decision-making processes in our daily lives, making trustworthiness of AI more and more crucial for its widespread acceptance. Among others, privacy and explainability are considered key requirements for enabling trust in AI. Building on these needs, we propose a software for Federated Learning (FL) of Rule-Based Systems (RBSs): on one hand FL prioritizes user data privacy during collaborative model training. On the other hand, RBSs are deemed as interpretable-by-design models and ensure high transparency in the decision-making process. The proposed software, developed as an extension to the Intel® OpenFL open-source framework, offers a viable solution for developing AI applications balancing accuracy, privacy, and interpretability. © 2023 The Author(s)","2-s2.0-85169915657"
"Baskar S.; Muthu S.; Chellamuthu G.; Misbah I.; Sekar A.; Ashraf M.","Baskar, S. (56396373800); Muthu, Sathish (57217850874); Chellamuthu, Girinivasan (57216951661); Misbah, Iffath (58654687500); Sekar, Aadithiyan (58909537600); Ashraf, Munis (57193627237)","56396373800; 57217850874; 57216951661; 58654687500; 58909537600; 57193627237","Artificial Intelligence Assisted Convolutional Neural Network for Detection of Distal Radius Fracture","2023","2023 Annual International Conference on Emerging Research Areas: International Conference on Intelligent Systems, AICERA/ICIS 2023","","","","","","","10.1109/AICERA/ICIS59538.2023.10420228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186139419&doi=10.1109%2fAICERA%2fICIS59538.2023.10420228&partnerID=40&md5=e66dea1ffb7b1e78c8b7e87246a0bd10","Artificial intelligence (AI) has demonstrated promising results in improving the reliability and effectiveness of fracture detection using X-rays. Deep learning, a branch of AI systems, requires enormous labeled image databases to correctly detect Distal Radius Fractures (DRF). High-reliability AI for DRF detection is challenging to achieve in part because it requires training on a large dataset of at least a thousand images. Detection of DRF needs to be considered in the small dataset images to diagnose and classify images by deep learning methods. The Artificial intelligence-assisted convolutional neural network (AI-CNN) model examines the odds of various events using new sets of comparable data by deducing patterns and rules from massive volumes of data. The collection of X-ray images is followed by an adaptable factor diffusion function for reducing distortion in the collected images. PCA (Principal Component Analysis) extracts the necessary variables from a large dataset. The extracted image is segmented by Kernel-based C-means clustering by categorizing related objects that are visually similar into a single segment. CNN with the two separate output layers detects the features in standard X-ray images. Training and diagnostic evaluations are performed using anteroposterior and lateral plain X-ray pictures of DRF. The Classification is based on the presence or absence of DRF. CNN classifies and identifies the DRF from the training set. The connection of Union tests the practicality of the object identification method. The network's diagnostic performance is calculated under receiver operating characteristics (ROC) and accuracy by measuring the values of Area Under Curve (AUC), Structural Similarity Index and sensitivity.  © 2023 IEEE.","2-s2.0-85186139419"
"Charef N.; Ben Mnaouer A.; Aloqaily M.; Bouachir O.; Guizani M.","Charef, Nadia (57425908900); Ben Mnaouer, Adel (56028760500); Aloqaily, Moayad (35226211500); Bouachir, Ouns (56027475000); Guizani, Mohsen (7004750176)","57425908900; 56028760500; 35226211500; 56027475000; 7004750176","Artificial intelligence implication on energy sustainability in Internet of Things: A survey","2023","Information Processing and Management","60","2","103212","","","","10.1016/j.ipm.2022.103212","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144031989&doi=10.1016%2fj.ipm.2022.103212&partnerID=40&md5=bd8073b16d1ba8e79f000a4047906cd7","The massive number of Internet of Things (IoT) devices connected to the Internet is continuously increasing. The operations of these devices rely on consuming huge amounts of energy. Power limitation is a major issue hindering the operation of IoT applications and services. To improve operational visibility, Low-power devices which constitute IoT networks, drive the need for sustainable sources of energy to carry out their tasks for a prolonged period of time. Moreover, the means to ensure energy sustainability and QoS must consider the stochastic nature of the energy supplies and dynamic IoT environments. Artificial Intelligence (AI) enhanced protocols and algorithms are capable of predicting and forecasting demand as well as providing leverage at different stages of energy use to supply. AI will improve the efficiency of energy infrastructure and decrease waste in distributed energy systems, ensuring their long-term viability. In this paper, we conduct a survey to explore enhanced AI-based solutions to achieve energy sustainability in IoT applications. AI is relevant through the integration of various Machine Learning (ML) and Swarm Intelligence (SI) techniques in the design of existing protocols. ML mechanisms used in the literature include variously supervised and unsupervised learning methods as well as reinforcement learning (RL) solutions. The survey constitutes a complete guideline for readers who wish to get acquainted with recent development and research advances in AI-based energy sustainability in IoT Networks. The survey also explores the different open issues and challenges. © 2022 Elsevier Ltd","2-s2.0-85144031989"
"Azafrani R.; Gupta A.","Azafrani, Rachel (57218391051); Gupta, Abhishek (57219761653)","57218391051; 57219761653","Bridging the civilian-military divide in responsible AI principles and practices","2023","Ethics and Information Technology","25","2","27","","","","10.1007/s10676-023-09693-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153272538&doi=10.1007%2fs10676-023-09693-y&partnerID=40&md5=2577d06c7921d9d1060501149517a77a","Advances in AI research have brought increasingly sophisticated capabilities to AI systems and heightened the societal consequences of their use. Researchers and industry professionals have responded by contemplating responsible principles and practices for AI system design. At the same time, defense institutions are contemplating ethical guidelines and requirements for the development and use of AI for warfare. However, varying ethical and procedural approaches to technological development, research emphasis on offensive uses of AI, and lack of appropriate venues for multistakeholder dialogue have led to differing operationalization of responsible AI principles and practices among civilian and defense entities. We argue that the disconnect between civilian and defense responsible development and use practices leads to underutilization of responsible AI research and hinders the implementation of responsible AI principles in both communities. We propose a research roadmap and recommendations for dialogue to increase exchange of responsible AI development and use practices for AI systems between civilian and defense communities. We argue that generating more opportunities for exchange will stimulate global progress in the implementation of responsible AI principles. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85153272538"
"Holstein K.; De-Arteaga M.; Tumati L.; Cheng Y.","Holstein, Kenneth (57190763027); De-Arteaga, Maria (56500677600); Tumati, Lakshmi (57832439900); Cheng, Yanghuidi (57604409800)","57190763027; 56500677600; 57832439900; 57604409800","Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables","2023","Proceedings of the ACM on Human-Computer Interaction","7","CSCW1","152","","","","10.1145/3579628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153756520&doi=10.1145%2f3579628&partnerID=40&md5=2173898003516343209266b8f83fd983","In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.  © 2023 Owner/Author.","2-s2.0-85153756520"
"Petti U.; Nyrup R.; Skopek J.M.; Korhonen A.","Petti, Ulla (57219630815); Nyrup, Rune (57024139100); Skopek, Jeffrey M. (36926353900); Korhonen, Anna (23987049200)","57219630815; 57024139100; 36926353900; 23987049200","Ethical considerations in the early detection of Alzheimer's disease using speech and AI","2023","ACM International Conference Proceeding Series","","","","1062","1075","13","10.1145/3593013.3594063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163646789&doi=10.1145%2f3593013.3594063&partnerID=40&md5=96579fbf227a1b1d81a746c4a1797abb","While recent studies indicate that AI could play an important role in detecting early signs of Alzheimer's disease in speech, this use of data from individuals with cognitive decline raises numerous ethical concerns. In this paper, we identify and explain concerns related to autonomy (including consent, depersonalization and disclosure), privacy and data protection (including the handling of personal content and medical information), welfare (including distress, discrimination and reliability), transparency (including the interpretability of language features and AI-based decision-making for developers and clinicians), and fairness (including bias and the distribution of benefits). Our aim is to not only raise awareness of the ethical concerns posed by the use of AI in speech-based Alzheimer's detection, but also identify ways in which these concerns might be addressed. To this end, we conclude with a list of suggestions that could be incorporated into ethical guidelines for researchers and clinicians working in this area. © 2023 Owner/Author.","2-s2.0-85163646789"
"Lim L.; Bannert M.; van der Graaf J.; Singh S.; Fan Y.; Surendrannair S.; Rakovic M.; Molenaar I.; Moore J.; Gašević D.","Lim, Lyn (57218403632); Bannert, Maria (6603100059); van der Graaf, Joep (56496687300); Singh, Shaveen (56010295900); Fan, Yizhou (57193777414); Surendrannair, Surya (57485084000); Rakovic, Mladen (57190194054); Molenaar, Inge (24577798700); Moore, Johanna (7405248281); Gašević, Dragan (8549413500)","57218403632; 6603100059; 56496687300; 56010295900; 57193777414; 57485084000; 57190194054; 24577798700; 7405248281; 8549413500","Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning","2023","Computers in Human Behavior","139","","107547","","","","10.1016/j.chb.2022.107547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140890206&doi=10.1016%2fj.chb.2022.107547&partnerID=40&md5=c42d533204ea72f5a4815659a3049f83","Self-Regulated Learning (SRL) is related to increased learning performance. Scaffolding learners in their SRL activities in a computer-based learning environment can help to improve learning outcomes, because students do not always regulate their learning spontaneously. Based on theoretical assumptions, scaffolds should be continuously adaptive and personalized to students' ongoing learning progress in order to promote SRL. The present study aimed to investigate the effects of analytics-based personalized scaffolds, facilitated by a rule-based artificial intelligence (AI) system, on students' learning process and outcomes by real-time measurement and support of SRL using trace data. Using a pre-post experimental design, students received personalized scaffolds (n = 36), generalized scaffolds (n = 32), or no scaffolds (n = 30) during learning. Findings indicated that personalized scaffolds induced more SRL activities, but no effects were found on learning outcomes. Process models indicated large similarities in the temporal structure of learning activities between groups which may explain why no group differences in learning performance were observed. In conclusion, analytics-based personalized scaffolds informed by students’ real-time SRL measured and supported with AI are a first step towards adaptive SRL supports incorporating artificial intelligence that has to be further developed in future research. © 2022 The Authors","2-s2.0-85140890206"
"Tomic B.; Kijevcanin A.; Sevarac Z.; Jovanovic J.M.","Tomic, Bojan (13907506400); Kijevcanin, Anisja (58017056000); Sevarac, Zoran (16230970600); Jovanovic, Jelena M. (7005027313)","13907506400; 58017056000; 16230970600; 7005027313","An AI-based Approach for Grading Students' Collaboration","2023","IEEE Transactions on Learning Technologies","16","3","","292","305","13","10.1109/TLT.2022.3225432","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144045464&doi=10.1109%2fTLT.2022.3225432&partnerID=40&md5=eb7049b0f3e6b07b56e0d510e62c05d9","Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made - something that proved to be very important to teachers.  © 2008-2011 IEEE.","2-s2.0-85144045464"
"Yildirim N.; Pushkarna M.; Goyal N.; Wattenberg M.; Viégas F.","Yildirim, Nur (57218706672); Pushkarna, Mahima (57212020272); Goyal, Nitesh (55258680900); Wattenberg, Martin (6602173002); Viégas, Fernanda (6602426326)","57218706672; 57212020272; 55258680900; 6602173002; 6602426326","Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook","2023","Conference on Human Factors in Computing Systems - Proceedings","","","356","","","","10.1145/3544548.3580900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160013788&doi=10.1145%2f3544548.3580900&partnerID=40&md5=64ad0c723325ae05e5fc6f5e28dff664","Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI's design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products. © 2023 Owner/Author.","2-s2.0-85160013788"
"Arya V.; Saha D.; Hans S.; Rajasekharan A.; Tang T.","Arya, Vijay (56227701100); Saha, Diptikalyan (57162370400); Hans, Sandeep (35078595000); Rajasekharan, Amaresh (56407121200); Tang, Tony (58061643700)","56227701100; 57162370400; 35078595000; 56407121200; 58061643700","Global Explanations for Multivariate time series models","2023","ACM International Conference Proceeding Series","","","","149","157","8","10.1145/3570991.3570998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146146741&doi=10.1145%2f3570991.3570998&partnerID=40&md5=dab0e6195633d9bbd0ff091cdd9088b1","Several explainable AI algorithms have been proposed to help make machine learning models more interpretable and trustworthy. However in spite of numerous methodological advancements, there is still a persistent gap between what researchers develop and what business users seek. In this work, we aim to bridge this gap for an AI system that predicts the remaining useful life of an aircraft's engine using time series data collected from multiple sensors. We propose a novel approach to compute easily understandable explanations by fusing two explainers in sequence wherein explanations of the first explainer are explained by the second. We use this approach to build a global post-hoc model-agnostic explainer for AI models that ingest multivariate time series data. Our approach fuses a local explainer that yields feature importance weights, with a directly interpretable model that outputs global rules. Our experimental results based on the C-MAPSS open-source dataset demonstrate that the proposed two-stage explainer computes global explanations that are amenable to business users and sheds light on how the behavior of an individual and a group of sensors impacts the remaining useful life of an aircraft's engine.  © 2023 ACM.","2-s2.0-85146146741"
"Corrado M.; Giliberti V.; Gozzi M.; Lanzolla V.; Vetere G.; Zurlo D.","Corrado, Mario (58593098300); Giliberti, Vincenzo (57751827800); Gozzi, Manuel (58590873700); Lanzolla, Vincenzo (58589984700); Vetere, Guido (22434365100); Zurlo, Domenico (58593098400)","58593098300; 57751827800; 58590873700; 58589984700; 22434365100; 58593098400","VO.I.C.E. FIRST: Supporting Human Assistants with Real-Time Voice Understanding","2023","2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering, MetroXRAINE 2023 - Proceedings","","","","1104","1109","5","10.1109/MetroXRAINE58569.2023.10405568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185786400&doi=10.1109%2fMetroXRAINE58569.2023.10405568&partnerID=40&md5=b40a412ee779a0c25e352dcfc2d2eb90","While AI and automation have made significant strides in customer support, there are still situations where human intervention via voice channels is necessary to provide the best possible customer experience. In fact, although AI and chatbots have become increasingly sophisticated, they may not always be able to handle complex or nuanced customer issues. Human agents can better understand and respond to these situations, providing tailored solutions. At the same time, solving non-trivial customer problems often requires access to knowledge bases and contextual customer information, for which AI is particularly well suited. Hence the idea of integrating human and artificial intelligence in a hybrid solution. We developed an AI system to help human assistants in the process of handling conversations. This system can be viewed as a collaborative bot (cobot). The cobot captures the audio stream of the conversation, converts it to text and analyzes it in real time. The extracted tokens are classified and sent to a reasoning system based on a knowledge graph, that provides information and action suggestions to the human assistant. Assistants are also capable of providing information to the reasoning system, utilizing their human understanding of the client's circumstances as they unfold. While designing a prototypical solution for utility services, we have faced the problem of real-time use of computationally complex procedures, including spontaneous speech understanding and knowledge-based heuristic rules. Moreover, we adopted a standards-based approach and experimented with open source reasoners and publicly available language models. The paper outlines the system architecture and design, and discusses the results of the first experiments. © 2023 IEEE.","2-s2.0-85185786400"
"Pfeifer-Chomiczewska K.","Pfeifer-Chomiczewska, Katarzyna (57694604300)","57694604300","Intelligent service robots for elderly or disabled people and human dignity: legal point of view","2023","AI and Society","38","2","","789","800","11","10.1007/s00146-022-01477-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130190875&doi=10.1007%2fs00146-022-01477-0&partnerID=40&md5=fc1d8b5193587a726c8f613faca5340e","This article aims to present the problem of the impact of artificial intelligence on respect for human dignity in the sphere of care for people who, for various reasons, are described as particularly vulnerable, especially seniors and people with various disabilities. In recent years, various initiatives and works have been undertaken on the European scene to define the directions in which the development and use of artificial intelligence should go. According to the human-centric approach, artificial intelligence should be developed, used and monitored with people in mind, their needs and rights. It is artificial intelligence that should adapt to the rules set by people, not the other way around. The source of all human rights and freedoms is respect for human dignity. This is evidenced by numerous European, international, national regulations and documents. Respecting this value is also one of the works on the AI development. One of the areas of our life into which AI enters more and more boldly and which in the near future, due to demographic reasons and aging population, may be almost dominated by modern technologies, is the medical and care system. The usefulness of industrial co-robots made us think about the possibility of using similar devices in the non-industrial sphere, including in the sphere of care, nursing and therapy. Actually, despite the impressive development of technology and AI, intelligent robots/devices used for care, nursing or therapy (so-called care/nursing or therapy robots) perform rather simple activities. They provide information, navigate, bring something and give it (e.g. medicines, food), help to get up. They are an important support for medical staff in this respect. Performing tasks that are more complex in terms of technology and movement, such as feeding, washing, intimate hygiene, dressing or undressing, is still beyond the reach of the currently used robots. The question we must ask ourselves is whether, in the future, care robots will be able to perform such tasks, and should they do so? Will this lead to the replacement of human medical personnel in the performance of the above-mentioned activities with such robots. Would anyone want to be ""looked after"" by a soulless machine? Should potential wards/patients, in other words all of us in fact, have the right to object to being taken into the care of an intelligent robot? There is no doubt that intelligent robots have great potential, especially when it comes to ensuring or maintaining the independence or mobility of people with various health limitations. However, we must not forget about the risks and dangers they may generate. Even a simple robot generates serious legal and ethical problems. Who should be liable for damage caused in connection with improper care performed with the participation of a robot? Robots based on AI systems are able to collect a significant amount of sensitive data, for example through the face and speech recognition function. There is considerable scope for abuse in this area, not only in terms of personal data protection but also in terms of informational self-determination, privacy and dignity. Bearing in mind the above risks, the creation of a new right to object to being looked after by a robot should be considered. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85130190875"
"Lucaj L.; Van Der Smagt P.; Benbouzid D.","Lucaj, Laura (57832472900); Van Der Smagt, Patrick (6601929804); Benbouzid, Djalel (55177310500)","57832472900; 6601929804; 55177310500","AI Regulation Is (not) All You Need","2023","ACM International Conference Proceeding Series","","","","1267","1279","12","10.1145/3593013.3594079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163658648&doi=10.1145%2f3593013.3594079&partnerID=40&md5=5177df0c341a920bb3ff1872e7eb7eb3","The development of processes and tools for ethical, trustworthy, and legal AI is only beginning. At the same time, legal requirements are emerging in various jurisdictions, following a deluge of ethical guidelines. It is therefore key to explore the necessary practices that must be adopted to ensure the quality of AI systems, mitigate their potential risks and enable legal compliance. Ensuring that the potential negative impacts of AI on individuals, society, and the environment are mitigated will depend on many factors, including the capacity to properly regulate its deployment and to mandate necessary internal best practices along lifecycles. Regulatory frameworks must evolve from abstract requirements to providing concrete operational mandates that enable better oversight mechanisms in the way AI systems operate, how they are developed, and how they are deployed. In view of the above, this paper explores the necessary practices that can be adopted throughout a comprehensive lifecycle audit as a key practice to ensure the quality of AI systems and enable the development of compliance mechanisms. It also discusses novel governance tools that enable bridging the current operational gaps. Such gaps were identified by interviewing experts, analysing adaptable tools and methodologies from the software engineering domain, and by exploring the state of the art of auditing. The results present recommendations for novel tools and oversight mechanisms for governing AI systems. © 2023 ACM.","2-s2.0-85163658648"
"Mendoza I.G.; Sabol V.; Hoffer J.G.","Mendoza, Inti Gabriel (58834064900); Sabol, Vedran (14632237600); Hoffer, Johannes Georg (57297990800)","58834064900; 14632237600; 57297990800","On the Importance of User Role-Tailored Explanations in Industry 5.0","2023","Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications","2","","","243","250","7","10.5220/0011748300003417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182944069&doi=10.5220%2f0011748300003417&partnerID=40&md5=c85f277ffee6bf231528bac1391fd159","Advanced Machine Learning models now see usage in sensitive fields where incorrect predictions have serious consequences. Unfortunately, as models increase in accuracy and complexity, humans cannot verify or validate their predictions. This ineffability foments distrust and reduces model usage. eXplainable AI (XAI) provides insights into AI models’ predictions. Nevertheless, scholar opinion on XAI range from ”absolutely necessary” to ”useless, use white box models instead”. In modern Industry 5.0 environments, AI sees usage in production process engineering and optimisation. However, XAI currently targets the needs of AI experts, not the needs of domain experts or process operators. Our Position is: XAI tailored to user roles and following social science’s guidelines on explanations is crucial in AI-supported production scenarios and for employee acceptance and trust. Our industry partners allow us to analyse user requirements for three identified user archetypes-the Machine Operator, Field Expert, and AI Expert-and experiment with actual use cases. We designed an (X)AI-based visual UI through multiple review cycles with industry partners to test our Position. Looking ahead, we can test and evaluate the impact of personalised XAI in Industry 5.0 scenarios, quantify its benefits, and identify research opportunities. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.","2-s2.0-85182944069"
"Nouri A.; Berger C.; Torner F.","Nouri, Ali (58095730700); Berger, Christian (16067915300); Torner, Fredrik (15063276700)","58095730700; 16067915300; 15063276700","On STPA for Distributed Development of Safe Autonomous Driving: An Interview Study","2023","Proceedings - 2023 49th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2023","","","","5","12","7","10.1109/SEAA60479.2023.00011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183325020&doi=10.1109%2fSEAA60479.2023.00011&partnerID=40&md5=47176f8bf1830476541da28305e137d8","Safety analysis is used to identify hazards and build knowledge during the design phase of safety-relevant functions. This is especially true for complex AI-enabled and software intensive systems such as Autonomous Drive (AD). System-Theoretic Process Analysis (STPA) is a novel method applied in safety-related fields like defense and aerospace, which is also becoming popular in the automotive industry. However, STPA assumes prerequisites that are not fully valid in the automotive system engineering with distributed system development and multi-abstraction design levels. This would inhibit software developers from using STPA to analyze their software as part of a bigger system, resulting in a lack of traceability. This can be seen as a maintainability challenge in continuous development and deployment (DevOps). In this paper, STPA's different guidelines for the automotive industry, e.g. J31887/ISO21448/STPA handbook, are firstly compared to assess their applicability to the distributed development of complex AI-enabled systems like AD. Further, an approach to overcome the challenges of using STPA in a multilevel design context is proposed. By conducting an interview study with automotive industry experts for the development of AD, the challenges are validated and the effectiveness of the proposed approach is evaluated.  © 2023 IEEE.","2-s2.0-85183325020"
"Pattathil N.; Zhao J.Z.L.; Sam-Oyerinde O.; Felfeli T.","Pattathil, Niveditha (57224464026); Zhao, Jonathan Z L (58289997600); Sam-Oyerinde, Olapeju (57297410900); Felfeli, Tina (57192924702)","57224464026; 58289997600; 57297410900; 57192924702","Adherence of randomised controlled trials using artificial intelligence in ophthalmology to CONSORT-AI guidelines: a systematic review and critical appraisal","2023","BMJ Health and Care Informatics","30","1","100757","","","","10.1136/bmjhci-2023-100757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165517452&doi=10.1136%2fbmjhci-2023-100757&partnerID=40&md5=f438d654ad95cadfd7c492ac05f10d9a","Purpose Many efforts have been made to explore the potential of deep learning and artificial intelligence (AI) in disciplines such as medicine, including ophthalmology. This systematic review aims to evaluate the reporting quality of randomised controlled trials (RCTs) that evaluate AI technologies applied to ophthalmology. Methods A comprehensive search of three relevant databases (EMBASE, Medline, Cochrane) from 1 January 2010 to 5 February 2022 was conducted. The reporting quality of these papers was scored using the Consolidated Standards of Reporting Trials-Artificial Intelligence (CONSORT-AI) checklist and further risk of bias was assessed using the RoB-2 tool. Results The initial search yielded 2973 citations from which 5 articles satisfied the inclusion/exclusion criteria. These articles featured AI technologies applied to diabetic retinopathy screening, ophthalmologic education, fungal keratitis detection and paediatric cataract diagnosis. None of the articles reported all items in the CONSORT-AI checklist. The overall mean CONSORT-AI score of the included RCTs was 53% (range 37%-78%). The individual scores of the articles were 37% (19/51), 39% (20), 49% (25), 61% (31) and 78% (40). All articles were scored as being moderate risk, or 'some concerns present', regarding potential risk of bias according to the RoB-2 tool. Conclusion A small number of RCTs have been published to date on the applications of AI in ophthalmology and vision science. Adherence to the 2020 CONSORT-AI reporting guidelines is suboptimal with notable reporting items often missed. Greater adherence will help facilitate reproducibility of AI research which can be a stimulus for more AI-based RCTs and clinical applications in ophthalmology.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","2-s2.0-85165517452"
"Gebreegziabher S.A.; Zhang Z.; Tang X.; Meng Y.; Glassman E.L.; Li T.J.-J.","Gebreegziabher, Simret Araya (58285478400); Zhang, Zheng (57462149300); Tang, Xiaohang (57869091100); Meng, Yihao (58285478500); Glassman, Elena L. (23975987900); Li, Toby Jia-Jun (57193573228)","58285478400; 57462149300; 57869091100; 58285478500; 23975987900; 57193573228","PaTAT: Human-AI Collaborative Qualitative Coding with Explainable Interactive Rule Synthesis","2023","Conference on Human Factors in Computing Systems - Proceedings","","","362","","","","10.1145/3544548.3581352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159891593&doi=10.1145%2f3544548.3581352&partnerID=40&md5=c5744fdef718143965801759406cf61b","Over the years, the task of AI-assisted data annotation has seen remarkable advancements. However, a specific type of annotation task, the qualitative coding performed during thematic analysis, has characteristics that make effective human-AI collaboration difficult. Informed by a formative study, we designed PaTAT, a new AI-enabled tool that uses an interactive program synthesis approach to learn flexible and expressive patterns over user-annotated codes in real-time as users annotate data. To accommodate the ambiguous, uncertain, and iterative nature of thematic analysis, the use of user-interpretable patterns allows users to understand and validate what the system has learned, make direct fixes, and easily revise, split, or merge previously annotated codes. This new approach also helps human users to learn data characteristics and form new theories in addition to facilitating the ""learning""of the AI model. PaTAT's usefulness and effectiveness were evaluated in a lab user study. © 2023 ACM.","2-s2.0-85159891593"
"Tang X.; Wang Z.; Zhang X.","Tang, Xiong (58293681500); Wang, Zichi (57103186000); Zhang, Xinpeng (57218701409)","58293681500; 57103186000; 57218701409","Steganalysis of Neural Networks Based on Symmetric Histogram Distribution","2023","Symmetry","15","5","1079","","","","10.3390/sym15051079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160517950&doi=10.3390%2fsym15051079&partnerID=40&md5=74af12a9c8c723fb223474e528f8ece4","Deep neural networks have achieved remarkable success in various fields of artificial intelligence. However, these models, which contain a large number of parameters, are widely distributed and disseminated by researchers, engineers, and even unauthorized users. Except for intelligent tasks, typically overparameterized deep neural networks have become new digital covers for data hiding, which may pose significant security challenges to AI systems. To address this issue, this paper proposes a symmetric steganalysis scheme specifically designed for neural networks trained for image classification tasks. The proposed method focuses on detecting the presence of additional data without access to the internal structure or parameters of the host network. It employs a well-designed method based on histogram distribution to find the optimal decision threshold, with a symmetric determining rule where the original networks and stego networks undergo two highly symmetrical flows to generate the classification labels; the method has been shown to be practical and effective. SVM and ensemble classifiers were chosen as the binary classifier for their applicability to feature vectors output from neural networks based on different datasets and network structures. This scheme is the first of its kind, focusing on steganalysis for neural networks based on the distribution of network output, compared to conventional digital media such as images, audio, and video. Overall, the proposed scheme offers a promising approach to enhancing the security of deep neural networks against data hiding attacks. © 2023 by the authors.","2-s2.0-85160517950"
"Pawlicka A.; Pawlicki M.; Kozik R.; Choras M.","Pawlicka, Aleksandra (57216816969); Pawlicki, Marek (57204352435); Kozik, Rafal (26654240400); Choras, Michal (55890809000)","57216816969; 57204352435; 26654240400; 55890809000","The Need for Practical Legal and Ethical Guidelines for Explainable AI-based Network Intrusion Detection Systems","2023","IEEE International Conference on Data Mining Workshops, ICDMW","","","","253","261","8","10.1109/ICDMW60847.2023.00038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186138613&doi=10.1109%2fICDMW60847.2023.00038&partnerID=40&md5=c53d98f451343bafa9f84a62c30a2dc1","When applied in network intrusion detection, xAI techniques contribute to better detection and mitigation of cyberthreats. However, the use of explainability techniques raises legal and ethical implications. Yet, no guidelines have been proposed concerning specifically the use of xAI techniques in intrusion detection. This paper fills this gap and explores the potential legal and ethical issues associated with xAI in network intrusion detection systems and emphasizes the need for responsible deployment and establishing relevant guidelines. Thus, a set of recommendations and guidelines are proposed, considering different stakeholders' perspectives and needs, which could serve as a starting point when designing regulatory frameworks and foster the dialogue between stakeholders and users. The article concludes by discussing future research directions. © 2023 IEEE.","2-s2.0-85186138613"
"Piñeiro-Martín A.; García-Mateo C.; Docío-Fernández L.; López-Pérez M.D.C.","Piñeiro-Martín, Andrés (57782838100); García-Mateo, Carmen (6701505646); Docío-Fernández, Laura (7801514037); López-Pérez, María del Carmen (58668760300)","57782838100; 6701505646; 7801514037; 58668760300","Ethical Challenges in the Development of Virtual Assistants Powered by Large Language Models †","2023","Electronics (Switzerland)","12","14","3170","","","","10.3390/electronics12143170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174218131&doi=10.3390%2felectronics12143170&partnerID=40&md5=88ba777ed44deb6210844de4d29082b7","Virtual assistants (VAs) have gained widespread popularity across a wide range of applications, and the integration of Large Language Models (LLMs), such as ChatGPT, has opened up new possibilities for developing even more sophisticated VAs. However, this integration poses new ethical issues and challenges that must be carefully considered, particularly as these systems are increasingly used in public services: transfer of personal data, decision-making transparency, potential biases, and privacy risks. This paper, an extension of the work presented at IberSPEECH 2022, analyzes the current regulatory framework for AI-based VAs in Europe and delves into ethical issues in depth, examining potential benefits and drawbacks of integrating LLMs with VAs. Based on the analysis, this paper argues that the development and use of VAs powered by LLMs should be guided by a set of ethical principles that prioritize transparency, fairness, and harm prevention. The paper presents specific guidelines for the ethical use and development of this technology, including recommendations for data privacy, bias mitigation, and user control. By implementing these guidelines, the potential benefits of VAs powered by LLMs can be fully realized while minimizing the risks of harm and ensuring that ethical considerations are at the forefront of the development process. © 2023 by the authors.","2-s2.0-85174218131"
"Farseev A.","Farseev, Aleksandr (57188707687)","57188707687","Under the Hood of Social Media Advertising: How Do We use AI Responsibly for Advertising Targeting and Creative Evaluation","2023","WSDM 2023 - Proceedings of the 16th ACM International Conference on Web Search and Data Mining","","","","1281","1282","1","10.1145/3539597.3575791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149688189&doi=10.1145%2f3539597.3575791&partnerID=40&md5=b7d81f1be0e22c0a7ef2475951bebf21","Digital Advertising is historically one of the most developed areas where Machine Learning and AI have been applied since its origination. From smart bidding to creative content generation and DCO, AI is well-demanded in the modern digital marketing industry and partially serves as a backbone of most of the state-of-the-art computational advertising systems, making them impossible for the AI tech and the programmatic systems to exist apart from one another. At the same time, given the drastic growth of the available AI technology nowadays, the issue of responsible AI utilization as well as the balance between the opportunity of deploying AI systems and the possible borderline etic and privacy-related consequences are still yet to be discussed comprehensively in both business and research communities. Particularly, an important issue of automatic User Profiling use in modern Programmatic systems like Meta Ads as well as the need for responsible application of the creative assessment models to fit into the business etic guidelines is yet to be described well. Therefore, in this talk, we are going to discuss the technology behind modern programmatic bidding and content scoring systems and the responsible application of AI by SoMin.ai to manage the Advertising targeting and Creative Validation process. © 2023 Owner/Author.","2-s2.0-85149688189"
"Nandutu I.; Atemkeng M.; Okouma P.","Nandutu, Irene (57219590670); Atemkeng, Marcellin (39960943100); Okouma, Patrice (24588275400)","57219590670; 39960943100; 24588275400","Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda","2023","AI and Society","38","1","","245","257","12","10.1007/s00146-021-01285-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115618097&doi=10.1007%2fs00146-021-01285-y&partnerID=40&md5=ff40dbf3c60b56599e12e1af92ba88cf","With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85115618097"
"Chen Y.-H.","Chen, Yen-Hung (56034163900)","56034163900","An adaptive heuristic algorithm to solve the network slicing resource management problem","2023","International Journal of Communication Systems","36","8","e5463","","","","10.1002/dac.5463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149262047&doi=10.1002%2fdac.5463&partnerID=40&md5=1ac26d4edb29e889b1ae1b2b5a0f192c","Artificial intelligence-based (AI-based) network slicing bandwidth allocation enables the 5G/6G service providers to create multiple virtual networks atop a shared physical infrastructure while fulfilling varying end-user demands. Some researchers argue that AI-enable network may run the danger of having private information compromised. We still need a backup rule-based methodology to allocate bandwidth resource to each slice, if the AI-based method suddenly encounters security issues. To design such a rule-based methodology, this study attempts to answer two questions: (1) Is the network slicing bandwidth allocation problem the nondeterministic polynomial-time completeness (NP-completeness)? (2) Is there a heuristic methodology without any training process, which has equivalent performance compared to the AI-based methodology? This study first proves the classical network slicing bandwidth allocation problems is NP-completeness. This shows that the designed heuristic method is inescapably suboptimal to the network slicing bandwidth allocation problem. Secondly, this study proposes the Adaptive Hungarian Algorithm (AHA), which outperforms previous AI-empowered method and does not need any training process. The experiments demonstrate that AHA reached 93%–97% of the maximal system throughput by brute-and-force algorithm, compared to other methodologies only having at most 93% of the maximal system throughput. This also indicates that AHA is capable to solve the network slicing bandwidth allocation problem, if the telecommunication operators do not have sufficient sample complexity to train an AI model. © 2023 John Wiley & Sons Ltd.","2-s2.0-85149262047"
"Kharchenko V.; Grekhov A.; Kondratiuk V.","Kharchenko, Volodymyr (7201365396); Grekhov, Andrii (55885405500); Kondratiuk, Vasyl (58291762000)","7201365396; 55885405500; 58291762000","Packet Losses in SAGIN with Artificial Intelligence","2023","International Journal of Wireless Information Networks","30","2","","164","172","8","10.1007/s10776-022-00579-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140977137&doi=10.1007%2fs10776-022-00579-2&partnerID=40&md5=9c10c087c4a5ad16c3f1b3e2a1fd1390","Modern solutions based on Artificial Intelligence (AI) play an important role in the management of drone’s resources in Space-Air-Ground-Integrated-Network (SAGIN). AI can use information collected by drone sensors to develop routing protocols, optimize communication networks, improve energy efficiency, and predict user behavior. In this regard, the analysis of data loss in SAGIN with AI is relevant. This work is devoted to the calculation of packet losses in SAGIN, containing additional hardware of AI system. Based on the original model containing a Base Station (BS), a stratospheric Remotely Piloted Air System (RPAS) with an AI system, a low-orbit satellite, a low-altitude RPAS and a user of a terrestrial cellular network, data traffic was simulated using NetCracker Professional 4.1 software. The AI system was simulated by a cloud structure with the ability to change the delay and the probability of packet losses. Quantitative characteristics of traffic in SAGIN channels with such a model of the AI hardware system are obtained. The dependences of packets losses on the size of messages and the data transfer rate are calculated. The dependences of BS uplink Average Load and the packets travel time on the TS, as well as the dependences of the Bit Error Rate (BER) on the Average Load, are obtained. The results are valuable in terms of practical guidelines for choosing data transfer modes and the necessary hardware parameters for an AI system. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2-s2.0-85140977137"
"Weerasekara D.H.N.R.; Wella Arachchi W.A.P.K.; Wellala S.R.G.; Rodrigo A.S.","Weerasekara, D.H.N.R. (58869918600); Wella Arachchi, W.A.P.K. (58869775400); Wellala, S.R.G. (58869858200); Rodrigo, Asanka S. (35748851300)","58869918600; 58869775400; 58869858200; 35748851300","Development of AI-Based Optimum Energy Resource Management System for Prosumers with Solar Rooftops","2023","Moratuwa Engineering Research Conference, MERCon","","","","7","12","5","10.1109/mERCon60487.2023.10355519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184360936&doi=10.1109%2fmERCon60487.2023.10355519&partnerID=40&md5=dd9d3d94f66d452e3a7f8e9288aac4ba","Solar installations are becoming popular around the world and have emerged as a promising solution to address the increased energy needs while reducing carbon emissions. To harness the full potential of solar photovoltaic (PV) systems, efficient resource management systems play a vital role. This research paper proposes an efficient solar PV energy resource management system to optimize performance and increase the profits of the prosumers. Utility providers have introduced several tariff systems for the financial motivation of customers. In the proposed method, the load demand and Solar PV generation are forecasted for the next 48 hours using the Long Short-Term Memory (LSTM) model. Then, the cost function is optimized using the Sequential Least Squares Programming (SLSQP) algorithm, and an energy dispatch schedule is provided for the customer: The results of the study show that the electricity cost is reduced for the prosumer by the proposed method than the conventional rule-based energy management systems. © 2023 IEEE.","2-s2.0-85184360936"
"Papagiannidis E.; Enholm I.M.; Dremel C.; Mikalef P.; Krogstie J.","Papagiannidis, Emmanouil (57229759600); Enholm, Ida Merete (57230931000); Dremel, Chirstian (57194428268); Mikalef, Patrick (42761793700); Krogstie, John (6602196721)","57229759600; 57230931000; 57194428268; 42761793700; 6602196721","Toward AI Governance: Identifying Best Practices and Potential Barriers and Outcomes","2023","Information Systems Frontiers","25","1","","123","141","18","10.1007/s10796-022-10251-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128394475&doi=10.1007%2fs10796-022-10251-y&partnerID=40&md5=fda9454550454d26f58879896d04304c","In recent years artificial intelligence (AI) has been seen as a technology with tremendous potential for enabling companies to gain an operational and competitive advantage. However, despite the use of AI, businesses continue to face challenges and are unable to immediately realize performance gains. Furthermore, firms need to introduce robust AI systems and mitigate AI risks, which emphasizes the importance of creating suitable AI governance practices. This study, explores how AI governance is applied to promote the development of robust AI applications that do not introduce negative effects, based on a comparative case analysis of three firms in the energy sector. The study illustrates which practices are placed to produce knowledge that assists with decision making while at the same time overcoming barriers with recommended actions leading to desired outcomes. The study contributes by exploring the main dimensions relevant to AI’s governance in organizations and by uncovering the practices that underpin them. © 2022, The Author(s).","2-s2.0-85128394475"
"Oommen B.J.; Omslandseter R.O.; Jiao L.","Oommen, B. John (55664159200); Omslandseter, Rebekka Olsson (57208478385); Jiao, Lei (35868065100)","55664159200; 57208478385; 35868065100","The object migration automata: its field, scope, applications, and future research challenges","2023","Pattern Analysis and Applications","26","3","","917","928","11","10.1007/s10044-023-01163-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152396799&doi=10.1007%2fs10044-023-01163-x&partnerID=40&md5=a90ebcddbecbc70f03f9225321b56b0f","Partitioning, in and of itself, is an NP-hard problem. Prior to the Artificial Intelligence (AI)-based solutions, it was solved in the 1970s by optimization-based strategies. However, AI-based solutions appeared in the 1980s in a pioneering way, by using a Learning Automaton (LA)-motivated strategy known as the so-called Object Migrating Automaton (OMA). Although the OMA and its derivatives have been used in numerous applications since then, the basic kernel has remained the same. Because the number of possible partitions in a partitioning problem can be combinatorially exponential and the underlying tasks are NP-hard, the most advanced OMA algorithms could, until recently, only solve issues involving equally sized groups. Due to our recent innovations cited in the body of this paper, the enhanced OMA now also handles non-equally sized groups. Earlier, we had presented in Omslandseter (Pattern Anal Appl, 2023), a comprehensive survey of the state-of-the-art enhancements of the best-known OMA. We believe that these results will be the benchmark for a few decades and that it will be very hard to beat these results. This is a companion paper, intended to augment the contents of Omslandseter (Pattern Anal Appl, 2023). In this paper, we first discuss the OMA’s prior applications, its historical and current innovations, and the OMA-based algorithms’ relevance to societal needs. We also provide well-specified guidelines for future researchers so that they can use them for unresolved tasks, and also develop further advancements. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85152396799"
"Wijekoon A.; Wiratunga N.; Palihawadana C.; Nkisi-Orji I.; Corsar D.; Martin K.","Wijekoon, Anjana (57204202475); Wiratunga, Nirmalie (13405064600); Palihawadana, Chamath (57208652699); Nkisi-Orji, Ikeckukwu (57195720655); Corsar, David (14059866600); Martin, Kyle (57200230178)","57204202475; 13405064600; 57208652699; 57195720655; 14059866600; 57200230178","iSee: Intelligent Sharing of Explanation Experience by Users for Users","2023","International Conference on Intelligent User Interfaces, Proceedings IUI","","","","79","82","3","10.1145/3581754.3584137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152021532&doi=10.1145%2f3581754.3584137&partnerID=40&md5=fe0221b98612f983c26325371934dfcf","The right to obtain an explanation of the decision reached by an Artificial Intelligence (AI) model is now an EU regulation. Different stakeholders of an AI system (e.g. managers, developers, auditors, etc.) may have different background knowledge, competencies and goals, thus requiring different kinds of interpretations and explanations. Fortunately, there is a growing armoury of tools to interpret ML models and explain their predictions, recommendations and diagnoses which we will refer to collectively as explanation strategies. As these explanation strategies mature, practitioners will gain experience that helps them know which strategies to deploy in different circumstances. What is lacking, and is addressed by iSee, is capturing, sharing and re-using explanation strategies based on past positive experiences. The goal of the iSee platform is to improve every user's experience of AI, by harnessing experiences and best practices in Explainable AI.  © 2023 Owner/Author.","2-s2.0-85152021532"
"Kiani M.; Andreu-Perez J.; Hagras H.","Kiani, Mehrin (57195927735); Andreu-Perez, Javier (55653526300); Hagras, Hani (6701586037)","57195927735; 55653526300; 6701586037","A Temporal Type-2 Fuzzy System for Time-Dependent Explainable Artificial Intelligence","2023","IEEE Transactions on Artificial Intelligence","4","3","","573","586","13","10.1109/TAI.2022.3210895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139437865&doi=10.1109%2fTAI.2022.3210895&partnerID=40&md5=a39be0001b94e5b84ac03f18ecf179bb","Explainable artificial intelligence (XAI) focuses on transparent AI models and decisions, which are easy to understand, analyze, and augment by a nontechnical audience. Fuzzy logic systems (FLS)-based XAI provides an explainable framework while also modeling uncertainties in real-world environments. However, most real-life processes are not characterized by high uncertainty alone; they are also inherently time dependent, i.e., the processes are time variant. In this work, we present a novel temporal type-2 FLS-based approach for time-dependent XAI (TXAI) systems, which can account for the likelihood of a sample occurrence in the time domain by its the frequency. In the proposed temporal type-2 fuzzy sets (TT2FSs), a 4-D time-dependent membership function integrates the universe of discourse, its membership, and its frequency of occurrence across time. The TXAI system manifested better classification prowess in cross-validation tests, with a mean recall of 95.40% than a standard XAI system (based on nontemporal general type-2 fuzzy sets) that had a mean recall of 87.04%. TXAI also performed significantly better than most nonexplainable AI systems, with between 3.95% and 19.04% improvement gain in mean recall. In addition, TXAI can also outline the most likely time-dependent trajectories using the frequency and time dimensions embedded in the TXAI model; viz. given a rule at a determined time interval, what will be the next most likely rule at a subsequent time interval. In this regard, the proposed TXAI system can have profound implications for delineating the evolution of real-life time-dependent processes, such as behavioral or biological processes.  © 2020 IEEE.","2-s2.0-85139437865"
"Panagoulias D.P.; Palamidas F.A.; Virvou M.; Tsihrintzis G.A.","Panagoulias, Dimitrios P. (57302923100); Palamidas, Filippos A. (58806563800); Virvou, Maria (7003569675); Tsihrintzis, George A. (7003361233)","57302923100; 58806563800; 7003569675; 7003361233","Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models","2023","Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","","","","70","77","7","10.1109/ICTAI59109.2023.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182402175&doi=10.1109%2fICTAI59109.2023.00018&partnerID=40&md5=2d68bb6456caf810ba3537c55ec5b058","In this paper, we investigate the enhancement of Artificial Intelligence (AI) technologies in healthcare and the better understanding of medical literature with the use of Large Language Models (LLMs) and Natural Language Processing (NLP). Specifically, we introduce a rule-augmented AI-empowered system which incorporates a rule-based decision system, the ChatGPT application programming interface (API), and other external machine learning and analytical APIs to offer diagnostic suggestions to patients. The complexities of patient healthcare experiences, including doctor-patient interactions, understanding levels, treatment procedures, and preventive care, are considered. We illustrate how a diagnostic process typically integrates various strategies depending on various factors. To digitize the greatest portion of the process, we propose and illustrate the use of LLMs for humanizing the communication process and investigating ways to reduce burdens and costs in primary healthcare. We also outline a theoretical decision model for evaluating the use of technological components from external sources versus building them from scratch. The paper is structured into sections detailing background theories and context, our proposed and implemented rule-augmented AI-empowered system, as well as a system test in a corresponding use case. Finally, the paper key findings are presented, which contribute valuable insights for future work in this field. © 2023 IEEE.","2-s2.0-85182402175"
"Rajakumari K.; Hamsagsayathri P.; Shanmugapriya S.","Rajakumari, K. (57195275731); Hamsagsayathri, P. (58302605400); Shanmugapriya, S. (58302605500)","57195275731; 58302605400; 58302605500","Features, key challenges, and applications of open-source data fabric platforms: Is open-source tools for data fabric - dawn or dusk?","2023","Data Fabric Architectures: Web-Driven Applications","","","","115","126","11","10.1515/9783111000886-006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160981956&doi=10.1515%2f9783111000886-006&partnerID=40&md5=0ebb28c553bafab725c4f632a58f2a0b","In recent years, ""Data Fabric"" has become new analytic buzzword in Data Management agility where it has become a high priority in booming industries where they have an environment that is more complicated, scattered, and diversified. Data analytics experts began exploring beyond conventional data management techniques and shifted toward contemporary solutions like AI-enabled data integration in order to decrease human errors and total costs. Data fabric is a weave where it stretches spanning a wide area that connects numerous sites, various data source kinds, and accessing techniques. As it progresses through the various stages of the data fabric, the data collected from the source can be handled, processed, and stored. For a wide range of applications, the data can also be accessible by or shared with both internal and external apps. Data fabric applications' main objectives are to optimize supply chains for end-to-end products, complywith data rules, and enhance consumer engagement through more sophisticated mobile apps and interactions. Always Companies can gain a competitive edge with data, but to meet customer demands, they must supply data rapidly. Most of the enterprises implemented cloud migration and IoT, with increased cost-effective data storage and processing. Because of this data is no longer tied to local centers, and most of the data are located in different places and it is very difficult to manage [1]. A Data Fabric is a strategic solution to the enterprise to incur storage operations and leverages the best version of cloud migration. This architecture can support centrally managed, public and private clouds, IoT and other devices. This reduces management tasks through automation, accelerates the development and deployment process, and protects assets without interruption. It enables changes to be made quickly, resolving problems, managing risk, reducing IT operations and complying with regulations. In this chapter, the best open source data fabric tools that meet the enterprise requirements are listed and highlighted with its benefits and challenges. The greatest data fabric tools are profiled in one location, which makes it easy for researchers to choose the tool throughout their search. Data categorization and discovery, data quality and profiling, data lineage and governance, and data exploration and integration are the four main functions offered by the data fabric technologies. These data collaboration platforms combine data integration with business applications. Atlan, Cinchy, Data.world, Denodo, IBM, K2 View are few open source tools that are used by enterprise to manage their data and its integration. There are wide ranges of Open Source Data fabric tools that are quick to list its benefits. Instead of using proprietary systems, the majority of firms are interested in open source solutions due to lower costs. The capacity to modify and offer creative solutions on the code to satisfy business objectives is another crucial advantage of working with open source proponents. However, in this chapter we discuss about the Key features, benefits and technical challenges of different open source data integration tools in detail. The primary challenges in the utilizing open source data tool in enterprise is they lack in community support. In general The IT departments of many businesses rely on vendor support to enhance their internal capabilities [2]. Having open source tools, make the enterprise to face and resolve the issues by their own, which is very hard. When developing a data management environment, technology teams frequently underestimate the amount of time and expertise required to properly employ open source software. Most of the organizations they frequently underestimate the amount of work necessary to integrate open source with other subsystems and, as a result, incorrectly evaluate the total cost of ownership of employing open source systems. Most businesses meet few significant obstacles when working on open source pilot projects, but they may run into problems when attempting to manage and maintain those deployments on a wide scale. © 2023 Walter de Gruyter GmbH, Berlin/Boston. All rights reserved.","2-s2.0-85160981956"
"Vladimirov N.; Perlman O.","Vladimirov, Nikita (57779119100); Perlman, Or (55546748800)","57779119100; 55546748800","Molecular MRI-Based Monitoring of Cancer Immunotherapy Treatment Response","2023","International Journal of Molecular Sciences","24","4","3151","","","","10.3390/ijms24043151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149053615&doi=10.3390%2fijms24043151&partnerID=40&md5=30d7281eb71ad4ba576eda616bb0aec0","Immunotherapy constitutes a paradigm shift in cancer treatment. Its FDA approval for several indications has yielded improved prognosis for cases where traditional therapy has shown limited efficiency. However, many patients still fail to benefit from this treatment modality, and the exact mechanisms responsible for tumor response are unknown. Noninvasive treatment monitoring is crucial for longitudinal tumor characterization and the early detection of non-responders. While various medical imaging techniques can provide a morphological picture of the lesion and its surrounding tissue, a molecular-oriented imaging approach holds the key to unraveling biological effects that occur much earlier in the immunotherapy timeline. Magnetic resonance imaging (MRI) is a highly versatile imaging modality, where the image contrast can be tailored to emphasize a particular biophysical property of interest using advanced engineering of the imaging pipeline. In this review, recent advances in molecular-MRI based cancer immunotherapy monitoring are described. Next, the presentation of the underlying physics, computational, and biological features are complemented by a critical analysis of the results obtained in preclinical and clinical studies. Finally, emerging artificial intelligence (AI)-based strategies to further distill, quantify, and interpret the image-based molecular MRI information are discussed in terms of perspectives for the future. © 2023 by the authors.","2-s2.0-85149053615"
"Burgess E.R.; Jankovic I.; Austin M.; Cai N.; Kapuścińska A.; Currie S.; Overhage J.M.; Poole E.S.; Kaye J.","Burgess, Eleanor R. (57197897716); Jankovic, Ivana (57218621183); Austin, Melissa (58285518200); Cai, Nancy (58285258800); Kapuścińska, Adela (57221863203); Currie, Suzanne (58285518300); Overhage, J. Marc (57204207499); Poole, Erika S. (58351556400); Kaye, Jofish (8454333500)","57197897716; 57218621183; 58285518200; 58285258800; 57221863203; 58285518300; 57204207499; 58351556400; 8454333500","Healthcare AI Treatment Decision Support: Design Principles to Enhance Clinician Adoption and Trust","2023","Conference on Human Factors in Computing Systems - Proceedings","","","15","","","","10.1145/3544548.3581251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160002202&doi=10.1145%2f3544548.3581251&partnerID=40&md5=96dc596f09afe5708658d0590bf0875c","Artificial intelligence (AI) supported clinical decision support (CDS) technologies can parse vast quantities of patient data into meaningful insights for healthcare providers. Much work is underway to determine the technical feasibility and the accuracy of AI-driven insights. Much less is known about what insights are considered useful and actionable by healthcare providers, their trust in the insights, and clinical workflow integration challenges. Our research team used a conceptual prototype based on AI-generated treatment insights for type 2 diabetes medications to elicit feedback from 41 U.S.-based clinicians, including primary care and internal medicine physicians, endocrinologists, nurse practitioners, physician assistants, and pharmacists. We contribute to the human-computer interaction (HCI) community by describing decision optimization and design objective tensions between population-level and personalized insights, and patterns of use and trust of AI systems. We also contribute a set of 6 design principles for AI-supported CDS. © 2023 Owner/Author.","2-s2.0-85160002202"
"Gan L.; Liu B.; Meng A.; Zhang F.; Qu G.","Gan, Lige (58909377400); Liu, Bo (55659663700); Meng, Andrew (58909599600); Zhang, Feng (57154782700); Qu, Guangzhi (7102342930)","58909377400; 55659663700; 58909599600; 57154782700; 7102342930","SATTree: A SHAP-Augmented Threshold Tree for Clustering Explanation","2023","IEEE International Conference on Data Mining Workshops, ICDMW","","","","931","938","7","10.1109/ICDMW60847.2023.00124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186142046&doi=10.1109%2fICDMW60847.2023.00124&partnerID=40&md5=e6669a30755bc2a234804817021ff221","With the blooming of Artificial Intelligence (AI), Machine Learning (ML) and Neural Networks are widely applied in various areas. Nevertheless, industrial applications take advantage of AI-based systems, and the users are more curious about how and why the decisions are being made by these approaches. Explainable AI (XAI), on the other hand, provides a transparent view, aiming at delivering interpretations according to the obtained information. In order to apply these methods in real-world applications, domain experts need to understand the reasoning behind the applications to support their decision-making. A majority of Explainable AI (XAI) models focus on supervised machine learning, yet the need for unsupervised machine learning explainability is still strong. Since the outcome of conventional unsupervised learning methods lacks the details of domain knowledge, it is difficult to be applied by industries. Moreover, the popular and classic explanation techniques, such as LIME and SHAP, cannot be directly utilized for unsupervised learning interpretation due to the absence of explicit labels or guidance in the datasets. In this work, we introduce an innovative clustering method, SATTree (SHAP-Augmented Threshold Tree), which leverages SHAP to gain a comprehensive understanding of global feature contributions, enhancing our knowledge in the clustering process, then builds up a hierarchical decision tree based on the knowledge of contribution ranking. The proposed approach can depict the properties of clusters with certain decision rule sets collected from the threshold tree. The outcomes of this method are anticipated to surpass expectations in facilitating improvements in real-world applications. © 2023 IEEE.","2-s2.0-85186142046"
"Maas J.","Maas, Jonne (57467556700)","57467556700","Machine learning and power relations","2023","AI and Society","38","4","","1493","1500","7","10.1007/s00146-022-01400-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125251069&doi=10.1007%2fs00146-022-01400-7&partnerID=40&md5=b17546bf9d0efa84b7af18549b82c36b","There has been an increased focus within the AI ethics literature on questions of power, reflected in the ideal of accountability supported by many Responsible AI guidelines. While this recent debate points towards the power asymmetry between those who shape AI systems and those affected by them, the literature lacks normative grounding and misses conceptual clarity on how these power dynamics take shape. In this paper, I develop a workable conceptualization of said power dynamics according to Cristiano Castelfranchi’s conceptual framework of power and argue that end-users depend on a system’s developers and users, because end-users rely on these systems to satisfy their goals, constituting a power asymmetry between developers, users and end-users. I ground my analysis in the neo-republican moral wrong of domination, drawing attention to legitimacy concerns of the power-dependence relation following from the current lack of accountability mechanisms. I illustrate my claims on the basis of a risk-prediction machine learning system, and propose institutional (external auditing) and project-specific solutions (increase contestability through design-for-values approaches) to mitigate domination. © 2022, The Author(s).","2-s2.0-85125251069"
"Alex S.A.; Parkavi A.; Sangeetha V.","Alex, Sini Anna (57205767953); Parkavi, A. (56040990300); Sangeetha, V. (57189683778)","57205767953; 56040990300; 57189683778","Data-driven mathematical modeling for AI-based security applications","2023","Handbook of Research on Data-Driven Mathematical Modeling in Smart Cities","","","","175","191","16","10.4018/978-1-6684-6408-3.ch010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151882407&doi=10.4018%2f978-1-6684-6408-3.ch010&partnerID=40&md5=085c89899fb8be0f6047e98e7785c067","Artificial intelligence (A.I.) is defined as the ability of a machine to perform cognitive functions that we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem solving, decision-making, and even demonstrating creativity. This field of artificial intelligence finds itself indispensable across various domains like shopping, fraud prevention, personalized learning, autonomous vehicles, voice assistants, etc. It is widely used in the field of cyber security. There are numerous AI based security models to delay security threats. Such algorithms could be classified under three heads - rule-based, shallow machine learning and deep learning algorithms. Fuzzy logic and fuzzy neural networks fall under rule-based algorithm. support vector machine (SVM), naïve bayes, decision tree, random forest, k-nearest neighbour and ensemble learning are some shallow ML algorithms that could be employed for cyber security. © 2023, IGI Global.","2-s2.0-85151882407"
"Myung J.; Ko Y.; Kwon T.; Lee J.; Kim K.; Song J.","Myung, Joonwoo (57749403800); Ko, Youngmin (58835743200); Kwon, Taewoong (57204022995); Lee, Jun (57188659911); Kim, Kyuil (56412219800); Song, Jungsuk (7404787465)","57749403800; 58835743200; 57204022995; 57188659911; 56412219800; 7404787465","Intrusion Detection Systems Based on Machine Learning Using Feature Expansion Methods","2023","Proceedings - 2023 18th Asia Joint Conference on Information Security, AsiaJCIS 2023","","","","32","38","6","10.1109/AsiaJCIS60284.2023.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182952657&doi=10.1109%2fAsiaJCIS60284.2023.00016&partnerID=40&md5=bbd5cd0b12af368acace22e154828b6d","With the development of computer networks, the amount of network traffic is explosively increasing. In addition, the importance of cyber security is being highlighted as cyber threats increase accordingly. In general, rule-based detection approaches have been used to detect cyber threats. The detection rules used in these are broadly set up to reliably detect cyber threats, resulting in too many unnecessary events. This leads to unanalyzed events, which can lead to severe security incidents. To solve this problem, recently, researches on AI-based cyber threat detection system that learns network traffic information and automatically generates detection rules are being conducted. Most of them have used complex model with sophisticated structures or feature engineering techniques so that AI models can learn as much information as possible. But, these are difficult to use in real-world security monitoring environment where quick decisions need to be made in real time, and are not suitable for that environments because they have been trained and verified through only open datasets. In this paper, we propose an AI-based cyber threat detection system that efficiently learns security event characteristics without any complicated process using tree-based model which efficient to learning tabular data. The proposed system detects cyber threats by learning security event characteristics using only information provided from security devices without complicated feature extraction process. In addition, rather than using the used information as a simple value, the value is transformed through a simple process so that the model can learn the event characteristics more effectively. Using the simplicity of the proposed method, it is expected that it can be applied to the real-world environments, and the possibility of this is demonstrated through real-world data.  © 2023 IEEE.","2-s2.0-85182952657"
"Levshun D.; Kotenko I.","Levshun, Diana (58114512500); Kotenko, Igor (15925268000)","58114512500; 15925268000","A survey on artificial intelligence techniques for security event correlation: models, challenges, and opportunities","2023","Artificial Intelligence Review","56","8","","8547","8590","43","10.1007/s10462-022-10381-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145836297&doi=10.1007%2fs10462-022-10381-4&partnerID=40&md5=7a9968254cca2713726da7fac44e18b8","Information systems need to process a large amount of event monitoring data. The process of finding the relationships between events is called correlation, which creates a context between independent events and previously collected information in real time and normalizes it for subsequent processing. In cybersecurity, events can determine the steps of attackers and can be analyzed as part of a specific attack strategy. In this survey, we present the systematization of security event correlation models in terms of their representation in AI-based monitoring systems as: rule-based, semantic, graphical and machine learning based-models. We define the main directions of current research in the field of AI-based security event correlation and the methods used for the correlation of both single events and their sequences in attack scenarios. We also describe the prospects for the development of hybrid correlation models. In conclusion, we identify the existing problems in the field and possible ways to overcome them. © 2023, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85145836297"
"Ahmad K.; Abdelrazek M.; Arora C.; Bano M.; Grundy J.","Ahmad, Khlood (57419307200); Abdelrazek, Mohamed (56080446200); Arora, Chetan (55848706400); Bano, Muneera (36661996700); Grundy, John (7102156137)","57419307200; 56080446200; 55848706400; 36661996700; 7102156137","Requirements practices and gaps when engineering human-centered Artificial Intelligence systems","2023","Applied Soft Computing","143","","110421","","","","10.1016/j.asoc.2023.110421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160513131&doi=10.1016%2fj.asoc.2023.110421&partnerID=40&md5=465e7c0ad209d62cdeaf7145fdebd78d","Context: Engineering Artificial Intelligence (AI) software is a relatively new area with many challenges, unknowns, and limited proven best practices. Big companies such as Google, Microsoft, and Apple have provided a suite of recent guidelines to assist engineering teams in building human-centered AI systems. Objective: The practices currently adopted by practitioners for developing such systems, especially during Requirements Engineering (RE), are little studied and reported to date. Method: This paper presents the results of a survey conducted to understand current industry practices in RE for AI (RE4AI) and to determine which key human-centered AI guidelines should be followed. Our survey is based on mapping existing industrial guidelines, best practices, and efforts in the literature. Results: We surveyed 29 professionals and found most participants agreed that all the human-centered aspects we mapped should be addressed in RE. Further, we found that most participants were using UML or Microsoft Office to present requirements. Conclusion: We identify that most of the tools currently used are not equipped to manage AI-based software, and the use of UML and Office may pose issues with the quality of requirements captured for AI. Also, all human-centered practices mapped from the guidelines should be included in RE. © 2023 The Author(s)","2-s2.0-85160513131"
"Hasan M.Z.; Hussain M.Z.; Javeed F.; Saeed M.; Nosheen S.; Qureshi A.M.; Siddiqui A.A.","Hasan, Muhammad Zulkifl (57208178055); Hussain, Muhammad Zunnurain (57202836473); Javeed, Farwa (58909500500); Saeed, Muaaz (58909500600); Nosheen, Summaira (58478157900); Qureshi, Ali Moiz (58137079600); Siddiqui, Adeel Ahmed (58138198900)","57208178055; 57202836473; 58909500500; 58909500600; 58478157900; 58137079600; 58138198900","Overcoming the Challenges of Data Sharing in Artificial Intelligence Systems: A Comprehensive Review of Techniques and Best Practices","2023","2023 Computer Applications and Technological Solutions, CATS 2023","","","","","","","10.1109/CATS58046.2023.10424361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186139964&doi=10.1109%2fCATS58046.2023.10424361&partnerID=40&md5=e6dae651fa36eba004ecb3cdb35d8d21","Artificial Intelligence (AI) systems rely heavily on data sharing to develop more accurate and effective algorithms. However, data sharing presents several challenges, including privacy concerns, security risks, and ownership issues. To address these challenges, organizations must implement effective data sharing strategies that maintain data privacy and security while leveraging the strengths and expertise of other organizations. This paper provides a comprehensive review of techniques and best practices for overcoming the challenges of data sharing in AI systems. The research concludes that there is no such dataprivacy technique one-size-fits-all solution. The choice of technique will depend on several factors, such as the sensitivity of the data being shared, the regulatory environment, and the desired level of data privacy.  © 2023 IEEE.","2-s2.0-85186139964"
"Zhang L.; Wang Z.; Dong X.; Feng Y.; Pang X.; Zhang Z.; Ren K.","Zhang, Lei (58436060300); Wang, Zhibo (24537844500); Dong, Xiaowei (57226122493); Feng, Yunhe (57195902826); Pang, Xiaoyi (57203225064); Zhang, Zhifei (57203212159); Ren, Kui (8396435500)","58436060300; 24537844500; 57226122493; 57195902826; 57203225064; 57203212159; 8396435500","Towards Fairness-aware Adversarial Network Pruning","2023","Proceedings of the IEEE International Conference on Computer Vision","","","","5145","5154","9","10.1109/ICCV51070.2023.00477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185871893&doi=10.1109%2fICCV51070.2023.00477&partnerID=40&md5=4a0b537d868e18a194f646546dc0c6dc","Network pruning aims to compress models while minimizing loss in accuracy. With the increasing focus on bias in AI systems, the bias inheriting or even magnification nature of traditional network pruning methods has raised a new perspective towards fairness-aware network pruning. Straightforward pruning plus debias methods and recent designs for monitoring disparities of demographic attributes during pruning have endeavored to enhance fairness in pruning. However, neither simple assembling of two tasks nor specifically designed pruning strategies could achieve the optimal trade-off among pruning ratio, accuracy, and fairness. This paper proposes an end-to-end learnable framework for fairness-aware network pruning, which optimizes both pruning and debias tasks jointly by adversarial training against those final evaluation metrics like accuracy for pruning, and disparate impact (DI) and equalized odds (DEO) for fairness. In other words, our fairness-aware adversarial pruning method would learn to prune without any handcraft rules. Therefore, our approach could flexibly adapt to variate network structures. Exhaustive experimentation demonstrates the generalization capacity of our approach, as well as superior performance on pruning and debias simultaneously. To highlight, the proposed method could preserve the SOTA pruning performance while significantly improving fairness by around 50% as compared to traditional pruning methods. © 2023 IEEE.","2-s2.0-85185871893"
"Borsci S.; Lehtola V.V.; Nex F.; Yang M.Y.; Augustijn E.-W.; Bagheriye L.; Brune C.; Kounadi O.; Li J.; Moreira J.; Van Der Nagel J.; Veldkamp B.; Le D.V.; Wang M.; Wijnhoven F.; Wolterink J.M.; Zurita-Milla R.","Borsci, Simone (26656618800); Lehtola, Ville V. (22980381100); Nex, Francesco (35234314600); Yang, Michael Ying (36015861500); Augustijn, Ellen-Wien (55503202600); Bagheriye, Leila (55912166900); Brune, Christoph (7006181855); Kounadi, Ourania (55756293800); Li, Jamy (56006505600); Moreira, Joao (56970579400); Van Der Nagel, Joanne (57427141900); Veldkamp, Bernard (6602896542); Le, Duc V. (55584901800); Wang, Mingshu (56342596800); Wijnhoven, Fons (6603180438); Wolterink, Jelmer M. (56198388700); Zurita-Milla, Raul (14419019600)","26656618800; 22980381100; 35234314600; 36015861500; 55503202600; 55912166900; 7006181855; 55756293800; 56006505600; 56970579400; 57427141900; 6602896542; 55584901800; 56342596800; 6603180438; 56198388700; 14419019600","Embedding artificial intelligence in society: looking beyond the EU AI master plan using the culture cycle","2023","AI and Society","38","4","","1465","1484","19","10.1007/s00146-021-01383-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123490849&doi=10.1007%2fs00146-021-01383-x&partnerID=40&md5=7961cc72f8f4580360077d88dea18bda","The European Union (EU) Commission’s whitepaper on Artificial Intelligence (AI) proposes shaping the emerging AI market so that it better reflects common European values. It is a master plan that builds upon the EU AI High-Level Expert Group guidelines. This article reviews the masterplan, from a culture cycle perspective, to reflect on its potential clashes with current societal, technical, and methodological constraints. We identify two main obstacles in the implementation of this plan: (i) the lack of a coherent EU vision to drive future decision-making processes at state and local levels and (ii) the lack of methods to support a sustainable diffusion of AI in our society. The lack of a coherent vision stems from not considering societal differences across the EU member states. We suggest that these differences may lead to a fractured market and an AI crisis in which different members of the EU will adopt nation-centric strategies to exploit AI, thus preventing the development of a frictionless market as envisaged by the EU. Moreover, the Commission aims at changing the AI development culture proposing a human-centred and safety-first perspective that is not supported by methodological advancements, thus taking the risks of unforeseen social and societal impacts of AI. We discuss potential societal, technical, and methodological gaps that should be filled to avoid the risks of developing AI systems at the expense of society. Our analysis results in the recommendation that the EU regulators and policymakers consider how to complement the EC programme with rules and compensatory mechanisms to avoid market fragmentation due to local and global ambitions. Moreover, regulators should go beyond the human-centred approach establishing a research agenda seeking answers to the technical and methodological open questions regarding the development and assessment of human-AI co-action aiming for a sustainable AI diffusion in the society. © 2022, The Author(s).","2-s2.0-85123490849"
"Alharbi A.; Petrunin I.; Panagiotakopoulos D.","Alharbi, Abdulrahman (57221016518); Petrunin, Ivan (7003772885); Panagiotakopoulos, Dimitrios (6603031837)","57221016518; 7003772885; 6603031837","Assuring Safe and Efficient Operation of UAV Using Explainable Machine Learning","2023","Drones","7","5","327","","","","10.3390/drones7050327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160249932&doi=10.3390%2fdrones7050327&partnerID=40&md5=496b5645badd91c84add47f108c90334","The accurate estimation of airspace capacity in unmanned traffic management (UTM) operations is critical for a safe, efficient, and equitable allocation of airspace system resources. While conventional approaches for assessing airspace complexity certainly exist, these methods fail to capture true airspace capacity, since they fail to address several important variables (such as weather). Meanwhile, existing AI-based decision-support systems evince opacity and inexplicability, and this restricts their practical application. With these challenges in mind, the authors propose a tailored solution to the needs of demand and capacity management (DCM) services. This solution, by deploying a synthesized fuzzy rule-based model and deep learning will address the trade-off between explicability and performance. In doing so, it will generate an intelligent system that will be explicable and reasonably comprehensible. The results show that this advisory system will be able to indicate the most appropriate regions for unmanned aerial vehicle (UAVs) operation, and it will also increase UTM airspace availability by more than 23%. Moreover, the proposed system demonstrates a maximum capacity gain of 65% and a minimum safety gain of 35%, while possessing an explainability attribute of 70%. This will assist UTM authorities through more effective airspace capacity estimation and the formulation of new operational regulations and performance requirements. © 2023 by the authors.","2-s2.0-85160249932"
"Graille M.; Sacquin-Mora S.; Taly A.","Graille, Marc (6701690013); Sacquin-Mora, Sophie (13105422700); Taly, Antoine (57188781909)","6701690013; 13105422700; 57188781909","Best Practices of Using AI-Based Models in Crystallography and Their Impact in Structural Biology","2023","Journal of Chemical Information and Modeling","63","12","","3637","3646","9","10.1021/acs.jcim.3c00381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164045056&doi=10.1021%2facs.jcim.3c00381&partnerID=40&md5=39c106b8e198748f948f682208e5f5c6","The recent breakthrough made in the field of three-dimensional (3D) structure prediction by artificial intelligence softwares, such as initially AlphaFold2 (AF2) and RosettaFold (RF) and more recently large Language Models (LLM), has revolutionized the field of structural biology in particular and also biology as a whole. These models have clearly generated great enthusiasm within the scientific community, and different applications of these 3D predictions are regularly described in scientific articles, demonstrating the impact of these high-quality models. Despite the acknowledged high accuracy of these models in general, it seems important to make users of these models aware of the wealth of information they offer and to encourage them to make the best use of them. Here, we focus on the impact of these models in a specific application by structural biologists using X-ray crystallography. We propose guidelines to prepare models to be used for molecular replacement trials to solve the phase problem. We also encourage colleagues to share as much detail as possible about how they use these models in their research, where the models did not yield correct molecular replacement solutions, and how these predictions fit with their experimental 3D structure. We feel this is important to improve the pipelines using these models and also to get feedback on their overall quality. © 2023 American Chemical Society.","2-s2.0-85164045056"
"Masood A.; Dao N.-N.; Kim H.; Son Y.; Lee H.T.; Paek J.; Cho S.","Masood, Arooj (57204741501); Dao, Nhu-Ngoc (56810883300); Kim, Hyosu (56403545200); Son, Yongseok (55838113000); Lee, Hyung Tae (55276259200); Paek, Jeongyeup (12789639400); Cho, Sungrae (55542045700)","57204741501; 56810883300; 56403545200; 55838113000; 55276259200; 12789639400; 55542045700","A Review on AI-Enabled Congestion Control Schemes for Content Centric Networks","2023","International Conference on ICT Convergence","","","","659","662","3","10.1109/ICTC58733.2023.10393556","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184608149&doi=10.1109%2fICTC58733.2023.10393556&partnerID=40&md5=e7d2d656aeea1a998dfc4daa1bf5c823","Content centric networks (CCN) offer more advantages over conventional TCP/IP networks in areas like content distribution. However, congestion control functionalities in CCN present challenges such as detecting congestion, over-reducing windows for non-congested paths, and addressing fairness issues. Most existing studies employed congestion control mechanisms similar to those in TCP. In addition, the existing mechanisms were based on conventional optimization rules to adjust the rate at which Interest packets are sent to request data from downstream nodes. However, such existing mechanisms do not consider the changes in network status and caching strategy due to multi-path and multi-source transmission. Moreover, they are based on assumptions about link bandwidth. In this paper, we study the problem of congestion control in CCN and discuss its challenges. In addition, we review the existing congestion control schemes in CCN based on machine learning. Finally, we highlight the open research issues to spur further investigations. © 2023 IEEE.","2-s2.0-85184608149"
"Kalahasty R.","Kalahasty, Rohan (57572755500)","57572755500","Neuro-Inspired Plasticity for Biologically Realistic Self-Adaptation of Neural Network Weights","2023","2023 IEEE International Conference on Development and Learning, ICDL 2023","","","","113","120","7","10.1109/ICDL55364.2023.10364505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182947507&doi=10.1109%2fICDL55364.2023.10364505&partnerID=40&md5=871d17983e5b086924bfcf25be6b1d8d","The Prefrontal Cortex is the core of higher level learning and memory. It currently operates much like an AI system, in the sense that its actions are guided via a dopamine based reward function, however there is one critical difference, the PFC has the ability to rewire itself - plasticity. Here, we look to biological studies to find the governing rules of plasticity - competitiveness, memory, and correlation - to create a biologically plausible implementation of plasticity called Hybrid Plasticity. We implement it in continuous time recurrent neural networks (CTRNNS) completing simple working memory tasks. We show that the implementation of plasticity increases the adaptability of the working memory process within networks, while also resulting in a significant decrease in active neurons within the network indicating higher efficiency. We further demonstrate that plasticity results in an increased small world index, indicating high levels of efficiency, parallel processing, and cognitive integration as proposed by Global Workspace Theory. Plasticity CTRNNs are also shown to self organize into brain-like connectivity patterns including inhibitory clusters, excitatory clusters, and inhibitory autapses during their forward pass. Hence, Hybrid Plasticity represents a proof-of-concept solution for bringing forth biologically realistic phenomena within neural networks resulting in increased efficiency and generalizability.  © 2023 IEEE.","2-s2.0-85182947507"
"Murtaza M.; Cheng C.-T.; Fard M.; Zeleznikow J.","Murtaza, Mohsin (57660474800); Cheng, Chi-Tsun (57188720201); Fard, Mohammad (6603666498); Zeleznikow, John (6701828144)","57660474800; 57188720201; 6603666498; 6701828144","The importance of transparency in naming conventions, designs, and operations of safety features: from modern ADAS to fully autonomous driving functions","2023","AI and Society","38","2","","983","993","10","10.1007/s00146-022-01442-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129305253&doi=10.1007%2fs00146-022-01442-x&partnerID=40&md5=49858842c03650c51b46284cb1f60582","This paper investigates the importance of standardising and maintaining the transparency of advanced driver-assistance systems (ADAS) functions nomenclature, designs, and operations in all categories up until fully autonomous vehicles. The aim of this paper is to reveal the discrepancies in ADAS functions across automakers and discuss the underlying issues and potential solutions. In this pilot study, user manuals of various brands are reviewed systematically and critical analyses of common ADAS functions are conducted. The result shows that terminologies used to describe ADAS functions vary widely across manufacturers and sometimes do not reflect their fundamental functions intuitively. Operational conditions and control procedures also vary across the selected models under this study. Due to this lack of consensus across the industry, drivers are not aware or well informed about ADAS functions in their vehicles, leading to a very low utilization rate and may lead to misuse of those functions. This paper provides insightful suggestions for the transport industry, Artificial Intelligence (AI) experts, and regulators to design frameworks and guidelines in governing the naming convention, operating conditions, control procedures, and information disclosure of ADAS. Such guidelines can be the foundations for regulating future AI-based self-driving functions. © 2022, The Author(s).","2-s2.0-85129305253"
"Vorvoreanu M.","Vorvoreanu, Mihaela (15053834400)","15053834400","Create Effective and Responsible AI User Experiences with The Human-AI Experience (HAX) Toolkit","2023","Conference on Human Factors in Computing Systems - Proceedings","","","534","","","","10.1145/3544549.3574191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158134951&doi=10.1145%2f3544549.3574191&partnerID=40&md5=a06e360d510159e92bcda16788f84780","The HAX Toolkit (https://aka.ms/haxtoolkit) is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. The Toolkit is grounded in a set of Guidelines for Human-AI Interaction [1] that prescribe how AI systems should behave when interacting with people. Course attendees will explore the nuances of each guideline and learn how to use the AI patterns and examples in the HAX Design Library to apply the Guidelines. Course attendees will also learn how to guide cross-disciplinary teams in planning user-facing AI systems by using the HAX Workbook. For NLP systems, course attendees will learn to use the HAX Playbook [2] to anticipate and design for failures. The HAX Toolkit is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. Course attendees will learn the nuances of the Guidelines for Human-AI Interaction, how to lead cross-disciplinary teams in planning human-AI interaction using the HAX Workbook, and how to use the HAX Workbook to plan for failures of NLP systems. © 2023 Owner/Author.","2-s2.0-85158134951"
"Diab I.","Diab, Isam (57807469000)","57807469000","Towards An Artificial Intelligence (AI)-based Framework to Automatically Adapt Short Stories in Spanish into Easier and Accessible Versions","2023","CEUR Workshop Proceedings","3625","","","10","18","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184807249&partnerID=40&md5=2618ba790123c1cde6757a20900099c0","The Easy-to-Read (E2R) Methodology was created with the aim of presenting clear and easily understood documents to improve the daily life of people who present reading comprehension difficulties, such as persons with cognitive disabilities. To do that, the methodology provides a set of guidelines regarding both writing and layout aspects. However, the E2R guidelines are applied manually to create easy-to-read text materials, which demands considerable resources and effort. To help in such a manual process, and considering that cultural materials, in general, and literary materials, in particular, should be accessible for all, our research objective is to develop (a) a technological framework for (semi)-automatically adapting short stories in Spanish into easier and accessible versions close to the E2R principles, and (b) an evaluation framework to ensure that the easier versions of the short stories provided by the technological framework preserve the content and semantics of the original versions. In this regard, the developed technological framework should be useful to help (a) different target groups who present comprehension difficulties (e.g. people with cognitive disabilities, low literacy skills or nonnative speakers) and (b) E2R professionals in terms of streamlining the task of text adaptation. © 2021 Copyright for this paper by its authors.","2-s2.0-85184807249"
"Deric E.; Frank D.; Tomic Z.","Deric, Elena (58903466700); Frank, Domagoj (56083217500); Tomic, Zoran (36893079500)","58903466700; 56083217500; 36893079500","Factors Influencing Perceived Switching Cost and User Switching Behavior Towards AI-Based Solutions and Technologies-A Systematic Review","2023","SISY 2023 - IEEE 21st International Symposium on Intelligent Systems and Informatics, Proceedings","","","","415","420","5","10.1109/SISY60376.2023.10417867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185843099&doi=10.1109%2fSISY60376.2023.10417867&partnerID=40&md5=6622a3053b639a778b07ac71b0c280be","The swift progress of artificial intelligence (AI), deep learning, and natural language processing brought massive changes across diverse domains. A substantial body of research underscored the advantages of AI technologies for consumers and identified motivational factors for their adoption. Current systematic literature reviews usually examined the traditional Technology Acceptance Model (TAM), Unified Theory of Acceptance and Use of Technology (UTAUT), and AI Device Use Acceptance (AIDUA), focused on a single solution or technology. On the other hand, the importance of perceived switching cost and measurement of switching behavior is an essential part of well-established and widely used theories (Push-Pull-Mooring (PPM) framework, Status Quo Bias theory, Lazy User Theory, etc.). By following the PRISMA 2020 guidelines, this literature review highlights studies that observe switching costs and switching behavior towards AI-based solutions. $\mathrm{N} = 2,739$ articles were initially identified in prominent databases (IEEE Xplore, Scopus, Web of Science, and EBSCO Host). After screening, $n = 7$ articles were deemed suitable for inclusion, and most of them relied on the Dual-factor framework and PPM framework. In many cases, these frameworks were integrated with theories and models such as the Status Quo Bias theory, UTAUT, TAM, and TAM3 to provide an understanding of underlying factors affecting user behavior and decision-making. Positive factors influencing switching behavior towards AI adoption include recognizing human limitations, while simultaneously perceiving advantages of AI technology, such as ease of use, efficiency, and personalized experiences. Negative factors, which hinder AI acceptance, encompass privacy risks, inertia, uncertainty, regret avoidance, and cognitive biases.  © 2023 IEEE.","2-s2.0-85185843099"
"Papadouli V.","Papadouli, Vasiliki (58652283200)","58652283200","The Role of the Autonomous Machines at the Conclusion of a Contract: Contractual Responsibility According to Current Rules of Private Law and Prospects","2023","Law, Governance and Technology Series","59","","","65","84","19","10.1007/978-3-031-41081-9_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178872158&doi=10.1007%2f978-3-031-41081-9_5&partnerID=40&md5=41ff83c1e70c8f4898ee7c9225a39a32","Nowadays, one of the most important applications of autonomous AI systems is the conclusion of contracts. Nonetheless, concerns are raised about the validity of the contracts concluded by autonomous machines and, subsequently, about the contractual responsibility in case of non-performance. Various theories have already been expounded in legal doctrine, with the view to tackling thereon. Some of them suggest that autonomous AI systems are mere communication tools or agents that render their user liable, whilst other legal scholars suggest that autonomous AI systems themselves—not their user—should be held liable. After presenting the arguments of these theories, the chapter concludes that the legal community should absolutely accept the validity of the contracts concluded by intelligent agents, considering their users legally bound to their performance. Users’ liability could be based on the theory of de facto contracts (faktische Verträge) or, alternatively, on the doctrine of reliance liability (Vertrauenshaftung). In both cases, users’ right to invalidate the contract in case of mistake must be guaranteed and the mistake shall be assigned to the intelligent agent. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","2-s2.0-85178872158"
"Arulprakash E.; Martin A.","Arulprakash, Enoch (57254980800); Martin, A. (57217456575)","57254980800; 57217456575","An object-oriented neural representation and its implication towards explainable AI","2023","International Journal of Information Technology (Singapore)","","","","","","","10.1007/s41870-023-01432-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170845839&doi=10.1007%2fs41870-023-01432-2&partnerID=40&md5=eaa72e016bb202f525a5281d48acedbb","Rapid dissemination of Artificial Intelligence (AI) and machine learning in real-world problems has raised a concern about the reliability aspects of the model. A separate sub-branch of AI solicitudes on reliability is known as Explainable AI (XAI). XAI analyses the cause and impact of the decision made by AI systems. The neural network plays a significant part in AI's ability to upgrade with more recent data. However, the learning capability left the model obscure for most of its decisions. Breaking the black-box nature of the neural network model and giving understanding and insight into the functionality of the model will mitigate the uncertainty. Here, in this research, we have designed Object oriented neural representation to devise a “Feature importance” technique from the correlation between Loss and Weight distribution devised method is effective in interpreting the decision to the end user and AI practitioners with optimal time complexity (TC = (L-1) × (E × C)). The proposed neural representation also extended to incorporate domain/business rules from which we introduced a new Loss, known as business loss. From getting the impact of business loss, we obtained an earlier decline in the overall Loss and improved performance from the ablation study. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.","2-s2.0-85170845839"
"Safaeisisakht M.; Hsu C.-H.; Hsu P.-Y.; Chen M.-Y.","Safaeisisakht, Maryam (57216808782); Hsu, Ching-Hsien (7404945944); Hsu, Po-Yen (58307502500); Chen, Mu-Yen (57211856395)","57216808782; 7404945944; 58307502500; 57211856395","An Intelligent Two-Phase Automated Architecture for Securing SDN-Based IoT Infrastructure","2023","2023 IEEE 3rd International Conference on Electronic Communications, Internet of Things and Big Data, ICEIB 2023","","","","12","16","4","10.1109/ICEIB57887.2023.10170386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166376773&doi=10.1109%2fICEIB57887.2023.10170386&partnerID=40&md5=792422f8b27adc0f8e27c0309862ba5a","The Internet of Things (IoT) will bring many opportunities in the next years. However, IoT devices have processing and power limitation. Thus, security remains one of the main challenges. Software-defined networking (SDN) helps traditional IoT infrastructure become manageable and flexible in a centralized fashion. The SDN-IoT architecture tackles the security issue of IoT networks. The proposed architecture adds a new security engine to the controller. The security engine consists of the monitoring, intelligent sub-layer, analyzing/detection engine, reaction, and config engine to automatically monitor, analyze, classify, detect, and generate a proper reaction to the possible threads in two phases. The config engine automatically rearranges the security rules and applies the set of rules as a new configuration to the devices (switches) in the data layer. The intelligent sub-layer uses AI-based feature selection (Bat Algorithm) and classification (Random Forest) algorithms to reveal the possible threats and forward its output to the analyzing/detecting engine to examine it and make the alerts. The cooperation of the intelligent sub-layer and analyzing/detection engine in the two mentioned steps help the system improve the overall system performance and false positive alerts. The proposed architecture follows new security rules based on the network status such as bandwidth minimization and traffic. All the process automatically makes by the security engine and protects the entire network from different threats and attacks.  © 2023 IEEE.","2-s2.0-85166376773"
"Kang H.-C.; Kang K.-B.; Kim D.-H.; Jwa M.-C.; Ko T.-S.; Jwa J.-W.","Kang, Hoon-Chul (58556713400); Kang, Ki-Beom (57204888932); Kim, Dong-Hyun (58556713500); Jwa, Myeong-Cheol (58040508000); Ko, Tae-Seung (58040893800); Jwa, Jeong-Woo (6506052251)","58556713400; 57204888932; 58556713500; 58040508000; 58040893800; 6506052251","Smart tourism chatbot system using Multi-domain Tourism Information DST","2023","International Conference on Ubiquitous and Future Networks, ICUFN","2023-July","","","608","612","4","10.1109/ICUFN57995.2023.10200288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169297620&doi=10.1109%2fICUFN57995.2023.10200288&partnerID=40&md5=43703f88da9b02afffb4994c8e68b9df","The smart tourism service provides tourists with travel planner services and tour guide services for easy and convenient travel throughout the entire travel process. In this paper, we develop the AI-based chatbot service using a pretrained language model (PLM) and provide tourism information so that tourists can make their travel plans. The proposed chatbot system consists of the DST server, the Neo4J graph DB and MySQL DB servers, and the natural language generation (NLG) server. The dialogue state tracking (DST) server understands the intention of tourists' questions to overcome the shortcomings of the previous rule-based chatbot system [7]. We define the domains and slots of the tourism information DST model with the 4W1H method and develop the dataset [12] for transfer learning of the SOM DST model [14]. The Neo4J and MySQL web servers search tourism information from the tourism information knowledgebase and the smart tourism information system, respectively. The NLG server provides the searched tourism information to the smart tourism app.  © 2023 IEEE.","2-s2.0-85169297620"
"Neghawi E.; Wang Z.; Huang J.; Liu Y.","Neghawi, Elie (56705544400); Wang, Zerui (57920891900); Huang, Jun (57920908800); Liu, Yan (55885279500)","56705544400; 57920891900; 57920908800; 55885279500","Linking Team-level and Organization-level Governance in Machine Learning Operations through Explainable AI and Responsible AI Connector","2023","Proceedings - International Computer Software and Applications Conference","2023-June","","","1223","1230","7","10.1109/COMPSAC57700.2023.00185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168909129&doi=10.1109%2fCOMPSAC57700.2023.00185&partnerID=40&md5=1cc5314d4d84f6fc1e0496018167de2b","The adoption of AI systems has been widely used across multiple industry domains at an alerting rate without focusing on its ethical concerns. In order to address those concerns, an increasing number of AI ethics frameworks have been suggested recently, which focus on the algorithmic level rather than the systems level. Nonetheless, some system-level approaches mostly cover a single-level governance pattern of the system components in the entire software design life cycle. However, the need to go beyond the single-level system design AI ethics frameworks to allow not only a better responsible-AI-by-design but also a trustworthy process pattern that abstracts and links the underlying layers of responsible AI on every level. This paper illustrates a principal-to-practice guide of the multi-level governance within organizations across the globe for AI ethics frameworks. We outline the main gap areas in organizations for AI ethics frameworks. Consecutively, we propose a multi-level governance pattern for responsible AI systems within organizations which is participatory, iterative, flexible and operable that targets those main gap areas. Finally, to assist practitioners in applying the multi-level governance AI in organizations and its impact on the industry level, we will translate it into effective and responsible AI practices using a case study. © 2023 IEEE.","2-s2.0-85168909129"
"Bala Kishore M.; Srinivasa Reddy I.; Sujihelen L.; Sivasangari A.; Christy A.","Bala Kishore, M. (58421195600); Srinivasa Reddy, I. (58419176300); Sujihelen, L. (56100365300); Sivasangari, A. (58143077500); Christy, A. (57215380965)","58421195600; 58419176300; 56100365300; 58143077500; 57215380965","Artificial Intelligence (AI) based Detection of Traffic Violations by Two-Wheeler Vehicles","2023","Proceedings of the 7th International Conference on Intelligent Computing and Control Systems, ICICCS 2023","","","","1788","1792","4","10.1109/ICICCS56967.2023.10142605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163885058&doi=10.1109%2fICICCS56967.2023.10142605&partnerID=40&md5=27349f3dd5db671a8041ae63c910b276","Increasing commuters, bad traffic signal management, and rider mentality are some of the factors contributing to traffic violations in India. Monitoring large traffic volumes physically and tracking violations at the same time is clearly insufficient with only physical traffic police. The result has been that many violators have gone undetected. By violating the traffic laws, the violators cause more serious mishaps on the road, thereby putting both themselves and others in danger. To avoid manual intervention in detecting and catching violators, Artificial Intelligence (AI)-based techniques should be incorporated. This research study demonstrates a novel technique to discover multiple offences on Indian roads electronically, which include helmet detection, using a smartphone while driving, tri cruising, wheeling, and parking illegally, and ultimately model the issuing of tickets by monitoring the infractions and affiliated car number together in record. Through all the automated AI-based traffic offense and booking system, the software will be extremely beneficial in determining diverse safety-related guidelines, facilitating in the imposing of harsher traffic restrictions, and fostering the development of such a green technology atmosphere. © 2023 IEEE.","2-s2.0-85163885058"
"Nikolinakos N.T.","Nikolinakos, Nikos Th. (58486605000)","58486605000","A European Approach to Excellence and Trust: The 2020 White Paper on Artificial Intelligence","2023","Law, Governance and Technology Series","53","","","211","280","69","10.1007/978-3-031-27953-9_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164712323&doi=10.1007%2f978-3-031-27953-9_5&partnerID=40&md5=c83c44f1e96e44c687fdfc98828eb03b","This chapter demonstrates that, although a soft-law approach was initially adopted with the publication of the non-binding 2019 Ethics Guidelines, the EU decided to shift towards a legislative approach and called for the adoption of a new EU regulatory framework on artificial intelligence. It underlines that the ethical guidelines and the existing laws which are applicable to AI systems were not considered by the Commission to be sufficient to address the risks posed by the development and deployment of AI. Therefore, the legislative framework should be improved by adjusting or clarifying existing legislation. Alongside the possible adjustments to and clarifications of existing legislation, the Commission considered that a new legislation specifically on artificial intelligence was needed to make the EU legal framework fit for the current and forthcoming technological and commercial developments. The White Paper on AI reaffirmed that “AI should work for people and be a force for good in society”, set out the Commission’s vision of advancing as well as regulating AI, confirmed that a new regulatory framework on AI will be adopted, and offered specific insights about the core elements of the forthcoming new AI regime. The guiding principles of the White Paper are the creation of ecosystems of excellence (“the Policy Framework”) and of trust (“the Regulatory Framework”). Although the White Paper on AI did not set out a concrete framework for new AI legislation, it did set out the Commission’s key priorities in that regard. A new regulatory framework specifically for AI (“effective” and “not excessively prescriptive”) was considered to be necessary, following a risk-based approach, ensuring that the regulatory intervention is proportionate and sufficiently flexible to accommodate technological progress while also precise enough to provide legal certainty. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85164712323"
"Arcilla A.O., Jr.; Espallardo A.K.V.; Gomez C.A.J.; Viado E.M.P.; Ladion V.J.T.; Naanep R.A.T.; Pascual A.R.L.; Artificio E.B.; Tubola O.D.","Arcilla, Angelis O. (58771719200); Espallardo, Adrian Kim V. (58771544100); Gomez, Clio Andrei J. (58710568900); Viado, Edrian Miles P. (58771683300); Ladion, Vince Jeremy T. (58771470700); Naanep, Ruben Andrei T. (58771610300); Pascual, Aaron Raphael L. (58771610400); Artificio, Edcel B. (58771470800); Tubola, Orland D. (57991569500)","58771719200; 58771544100; 58710568900; 58771683300; 58771470700; 58771610300; 58771610400; 58771470800; 57991569500","Ethics in AI Governance: Comparative Analysis, Implication, and Policy Recommendations for the Philippines","2023","27th International Computer Science and Engineering Conference 2023, ICSEC 2023","","","","319","326","7","10.1109/ICSEC59635.2023.10329756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180154518&doi=10.1109%2fICSEC59635.2023.10329756&partnerID=40&md5=cdc64a32704198d58e9c760202c396b2","This study provides a comparative analysis of Artificial Intelligence (AI) ethical guidelines by looking at six different sources from the USA, European Union, India, Philippines, UNESCO, and CAIDP. The researchers extracted key terms from these guidelines and categorized them based on their frequency across the six sources to get a deeper understanding of their content and identify central themes and topics across each guideline. In doing so, the paper was able to identify ethical considerations and challenges of implementing AI in the Philippine context, including data collection, use and sharing, and AI development. The insights from the literature and document reviews and the analysis of the extracted key terms were used to craft considerations in formulating AI policy for the Philippines. These include (1) defining ethical principles and values in developing and implementing AI, (2) establishing mechanisms for ensuring fairness and preventing bias, (3) implementing mechanisms to ensure security and mitigating risks in AI systems, and (4) assessing potential impacts on AI technologies. Overall, the study uncovered that existing guidelines and legal frameworks on AI ethics seem to have put less emphasis on ethics and fairness. This underpins the need for the PH to ensure that its localized AI ethics policy is clear about its definition of what is ethical and fair use of AI across sectors, industries., demographics, and contexts.  © 2023 IEEE.","2-s2.0-85180154518"
"Donoso-Guzmá I.","Donoso-Guzmá, Ivania (58745643700)","58745643700","Designing an evaluation framework for eXplainable AI in the Healthcare domain","2023","CEUR Workshop Proceedings","3554","","","201","208","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178607051&partnerID=40&md5=c75c5b5847eebee17c12aea25c60a718","The rapid adoption of Artificial Intelligence (AI) has brought automation and problem-solving capabilities in various fields, including healthcare. However, a significant challenge lies in the lack of explanation for AI predictions, particularly in healthcare, where transparency is crucial. This issue has led to eXplainable AI (XAI) development, focusing on constructing explanations for AI systems. However, the evaluation of these explanations lacks a standardized user-centric approach. This research proposes an evaluation framework for XAI methods to address this gap. The project involves four stages: conducting a systematic review of current evaluation methods, assessing the appropriateness of automatic evaluation of explanations, and conducting user studies to gauge the framework's effectiveness in capturing the user experience complexity. The desired outcome is a user-centric evaluation framework and guidelines, enhancing the scalability of XAI research and fostering confidence in adopting AI systems in the healthcare domain. © 2023 CEUR-WS. All rights reserved.","2-s2.0-85178607051"
"Agarwal L.; Jain N.; Singh N.; Kumar S.","Agarwal, Lakshay (58784783100); Jain, Naman (58835096700); Singh, Niharika (57207341267); Kumar, Saurabh (58738972200)","58784783100; 58835096700; 57207341267; 58738972200","AI-Based Planning of Business Management","2023","AI-Based Data Analytics: Applications for Business Management","","","","156","170","14","10.1201/9781032614083-10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180856320&doi=10.1201%2f9781032614083-10&partnerID=40&md5=9dcd7b38e947654bfd03429eacda917f","Artificial intelligence (AI)-based planning is a powerful tool for enhancing business management, offering accurate insights and informed decision-making. However, challenges like data privacy, bias, and job impact must be addressed. Best practices, human oversight, and ethical policies are crucial for responsible implementation. Understanding objectives, selecting appropriate tools, and ensuring technical readiness are key to successful integration. AI-based planning has transformative potential, but a critical and responsible approach is essential for sustainable systems. © 2024 selection and editorial matter, Kiran Chaudhary and Mansaf Alam; individual chapters, the contributors.","2-s2.0-85180856320"
"Larasati R.","Larasati, Retno (57197729397)","57197729397","AI in Healthcare: Impacts, Risks and Regulation to Mitigate Adverse Impacts","2023","CEUR Workshop Proceedings","3593","","","27","32","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180796691&partnerID=40&md5=9267b0c8fe81b330b06fd8f83ece842b","The rapid advancements in artificial intelligence (AI) have revolutionised various industries, including healthcare. AI systems in healthcare hold immense potential for improving patient outcomes, accelerating diagnosis, and enhancing overall healthcare delivery. However, the introduction of AI in healthcare also brings forth significant ethical, legal, and societal implications that necessitate a robust regulatory framework. This position paper aims to discuss the use and the risk of AI in healthcare, and also how the regulations or guidelines aiming to mitigate their potential adverse impact on individuals and societies corresponds to it. © 2023 CEUR-WS. All rights reserved.","2-s2.0-85180796691"
"Haigh K.Z.; Nguyen T.","Haigh, Karen Zita (58743202900); Nguyen, Trung (58833519300)","58743202900; 58833519300","Challenges of Testing Cognitive EW Systems","2023","AUTOTESTCON (Proceedings)","","","","","","","10.1109/AUTOTESTCON47464.2023.10296319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178518202&doi=10.1109%2fAUTOTESTCON47464.2023.10296319&partnerID=40&md5=782973486bb2583ee16fdd72d546a48c","This paper describes some of the test infrastructure requirements for testing the performance of artificial intelligence (AI) systems that can learn from novel experiences in the field. As a test community, we must validate the learning process, rather than validating the learned model. Cognitive capabilities will force multiple paradigm shifts from legacy test and evaluation (T&E) approaches. Notably, the system may never be the same twice. Testing must therefore become a continuous process, rather than a final exam, where we develop tests to understand system limitations and range of effectiveness. These paradigm shifts highlight some of the improvements needed in the current test infrastructure. The paper describes some of the requirements that should be placed on cognitive systems for data collection, transparency, and rules for how to interact with legacy systems. We use Cognitive Electronic Warfare (CogEW) as the motivating scenario, where AI enables EW systems to respond more quickly and effectively to real-world conditions with complex and novel emitters.  © 2023 IEEE.","2-s2.0-85178518202"
"Sanca V.; Ailamaki A.","Sanca, Viktor (57780338300); Ailamaki, Anastasia (56216343500)","57780338300; 56216343500","Analytical Engines With Context-Rich Processing: Towards Efficient Next-Generation Analytics","2023","Proceedings - International Conference on Data Engineering","2023-April","","","3699","3707","8","10.1109/ICDE55515.2023.00298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167714500&doi=10.1109%2fICDE55515.2023.00298&partnerID=40&md5=4e4702c09a5aa58821cf1de3fba0a767","As modern data pipelines continue to collect, produce, and store a variety of data formats, extracting and combining value from traditional and context-rich sources such as strings, text, video, audio, and logs becomes a manual process where such formats are unsuitable for RDBMS. To tap into the dark data, domain experts analyze and extract insights and integrate them into the data repositories. This process can involve out-of-DBMS, ad-hoc analysis, and processing resulting in ETL, engineering effort, and suboptimal performance. While AI systems based on ML models can automate the analysis process, they often further generate context-rich answers. Using multiple sources of truth, for either training the models or in the form of knowledge bases, further exacerbates the problem of consolidating the data of interest.We envision an analytical engine co-optimized with components that enable context-rich analysis. Firstly, as the data from different sources or resulting from model answering cannot be cleaned ahead of time, we propose using online data integration via model-assisted similarity operations. Secondly, we aim for a holistic pipeline cost- and rule-based optimization across relational and model-based operators. Thirdly, with increasingly heterogeneous hardware and equally heterogeneous workloads ranging from traditional relational analytics to generative model inference, we envision a system that just-in-time adapts to the complex analytical query requirements. To solve increasingly complex analytical problems, ML offers attractive solutions that must be combined with traditional analytical processing and benefit from decades of database community research to achieve scalability and performance effortless for the end user.  © 2023 IEEE.","2-s2.0-85167714500"
"Hedin B.; Curtis S.","Hedin, Bruce (58417795800); Curtis, Samuel (58835542000)","58417795800; 58835542000","Strengthening the AI Operating Environment","2023","CEUR Workshop Proceedings","3423","","","90","99","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163808361&partnerID=40&md5=e3d030111cffc9d940d2047039b8d3d2","In the rapidly evolving discourse on artificial intelligence (AI), the familiar refrain of “maximizing potential while mitigating risks” has become somewhat of a ubiquitous mantra, emphasizing the need for an effective risk mitigation framework. This paper briefly examines the current state of AI-enabled applications and discusses the various risk containment strategies being implemented. Initial efforts focused on establishing high-level principles for responsible AI use. More recent strategies have sought to operationalize these principles through normative instruments, such as industry best practices and legal statutes, that govern AI applications and their creators. While valuable, such a top-down approach is not sufficiently effective; a complementary, bottom-up approach focused on strengthening the environment in which AI is deployed is also necessary. The paper analyzes two specific initiatives aimed at enhancing the human component of AI deployment (creating a better-informed public through AI benchmarks, creating a better-equipped public with resources for local validation) and offers insights on how this environment-focused track can contribute to risk containment. Furthermore, we suggest additional steps for leveraging this approach in tandem with top-down strategies to cultivate a more robust risk mitigation framework. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85163808361"
"Singh V.; Osen O.L.; Bye R.T.","Singh, Vijander (57191532025); Osen, Ottar L. (55056393700); Bye, Robin T. (7006015517)","57191532025; 55056393700; 7006015517","Explainable Artificial Intelligence for Autonomous Surface Vessels by Fuzzy-Based Collision Avoidance System","2023","Lecture Notes in Networks and Systems","650 LNNS","","","145","163","18","10.1007/978-981-99-0838-7_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164724139&doi=10.1007%2f978-981-99-0838-7_12&partnerID=40&md5=e814e545062f3d456a98668b7ffa5c62","Autonomy at sea relies on algorithms (often local) to make the decisions. One approach to create these algorithms are through the use of artificial intelligence. Numerous black-box machine learning-based algorithms are proposed for autonomous surface vessels (ASV) to make decisions like changing the speed or changing the route in order to reach the operational goal in an optimal way with respect to cost (fuel, time, etc.) and safety (avoid collisions or dangerous situations). Hence, the algorithms must take into account many constraints and are influenced by several varying factors such as other vessels, weather, etc. The objective of this paper is to propose a model that provides the reason behind the ASV’s decision when it is on a predefined path and changes speed or route. Fuzzy logic is used to record the expert knowledge based on COLREGs to steer the vessel and take the decision during the collision course. Data has been captured based on expert knowledge and used to train an explainable model. The explainable model predicts the reason behind the decision. The focus of the paper is on local explainability instead of global decisions. The structured abstracts of the paper are (1) Background: Several AI-enabled algorithms have been proposed for implementing autonomy to avoid the collision. These black-box techniques provide good predictions at the same time, they fail to explain the reason behind the decision, which makes the model less trustworthy; (2) Methods: Expert knowledge (COLREGs) has been captured using fuzzy rules and applied when ASV progresses, the decision has been recorded. (3) Results: The explainable model provides the reason behind the action taken by the collision avoidance system; (4) Conclusion: A model has been proposed that explains the collision avoidance system to make it transparent and trustworthy. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85164724139"
"Kutz J.; Neuhüttler J.; Bienzeisler B.; Spilski J.; Lachmann T.","Kutz, Janika (58177280000); Neuhüttler, Jens (57194696327); Bienzeisler, Bernd (55641097800); Spilski, Jan (56340280900); Lachmann, Thomas (55971139300)","58177280000; 57194696327; 55641097800; 56340280900; 55971139300","Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14050 LNAI","","","115","130","15","10.1007/978-3-031-35891-3_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171429081&doi=10.1007%2f978-3-031-35891-3_8&partnerID=40&md5=a158c4c193f9266ca5cce6a36990f066","AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85171429081"
"Podder I.; Bub U.","Podder, Itilekha (57433062800); Bub, Udo (7801660909)","57433062800; 7801660909","A Design Science Research Approach Towards Knowledge Discovery and Predictive Maintenance of MEMS Inertial Sensors Using Machine Learning","2023","Communications in Computer and Information Science","1864 CCIS","","","313","325","12","10.1007/978-3-031-41774-0_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174718277&doi=10.1007%2f978-3-031-41774-0_25&partnerID=40&md5=064ac8b7bfd8bb7d19f268973ea679a1","Knowledge discovery is the process of extracting relevant and practical information from a collection of structured or unstructured data. In numerous applications, such as marketing, fraud detection, telecommunication, and manufacturing, it is an unavoidable step. The complexity of the discovery process has risen along with the volume of data during the past few decades. In this situation, artificial intelligence (AI)-based solutions have emerged as the most advantageous. However, there is a lack of a rigorous strategy in the knowledge extraction and reuse processes. A qualitative research paradigm known as Design Science Research (DSR), provides systematic recommendations for the generalization and transferability of newly produced knowledge utilizing artifacts. In this research, we present an artifact for the early prediction of impacted micro-electromechanical systems (MEMS)-based inertial sensors. MEMS-based inertial sensor manufacturing is complex and time-consuming. Moreover, there is a persistent need for more precise products, streamlined production stages, and quicker solutions. One way of achieving this is through optimized manufacturing processes using AI-based solutions. However, many difficulties are encountered, including problems with data collection, data analysis, computational power availability, platform compatibility, etc. Thorough and systemic guidelines can ensure the avoidance of all these issues. The proposed artifact is created using a DSR approach utilizing various machine learning algorithms for predictive maintenance of MEMS-based inertial sensors along with providing optimal feature selection methods. A thorough demonstration of the artifact designing and evaluation process is provided using a real use case. The manufacturing process has been improved by further investigation of the results to help with knowledge discovery and re-usability. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","2-s2.0-85174718277"
"Vishal M.; Vishalakshi Prabhu H.","Vishal, M. (57478316100); Vishalakshi Prabhu, H. (58178678400)","57478316100; 58178678400","A Comprehensive Review of Conversational AI-Based Chatbots: Types, Applications, and Future Trends","2023","Lecture Notes in Networks and Systems","616 LNNS","","","293","303","10","10.1007/978-981-19-9719-8_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171975240&doi=10.1007%2f978-981-19-9719-8_24&partnerID=40&md5=fcdc9099d045bc55bbe0ed292bb9bfba","It is an evident fact that almost every application area in the present-day world is driven by technology and a core reason for this disruption is Artificial Intelligence (AI) and Machine learning (ML). Among them, chatbot research is one of the core areas that is driven by AI. The shift from simple rule-based chatbots to AI-based conversational agents was all possible because of advancements in conversational AI research. This paper provides an in-depth review of the evolution of chatbot technology on an AI front, its applications in real-world scenarios, and hence the future trends associated with it. Additionally, a critical comparison of state-of-the-art conversational AI frameworks is also incorporated into the study. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85171975240"
"Zhang W.; Zhang W.; Struber D.; Hebig R.","Zhang, Wenli (58811780900); Zhang, Weixing (57748327600); Struber, Daniel (56503681700); Hebig, Regina (35147919400)","58811780900; 57748327600; 56503681700; 35147919400","Manual Abstraction in the Wild: A Multiple-Case Study on OSS Systems' Class Diagrams and Implementations","2023","Proceedings - ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems, MODELS 2023","","","","36","45","9","10.1109/MODELS58315.2023.00017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182331824&doi=10.1109%2fMODELS58315.2023.00017&partnerID=40&md5=bec3f5a8159e515a20cdb6a32e1d55d8","Models are a useful tool for software design, analysis, and to support the onboarding of new maintainers. However, these benefits are often lost over time, as the system implementation evolves and the original models are not updated. Reverse engineering methods and tools could help to keep models and implementation code in sync; however, automatically reverse-engineered models are typically not abstract and contain extensive information that prevents understanding. Recent advances in AI-based content generation make it likely that we will soon see reverse engineering tools with support for human-grade abstraction. To inform the design and validation of such tools, we need a principled understanding of what manual abstraction is, a question that has received little attention in the literature so far.Towards this goal, in this paper, we present a multiple-case study of model-To-code differences, investigating five substantial open-source software projects retrieved via repository mining. To explore characteristics of model-To-code differences, we, all in all, manually matched 466 classes, 1352 attributes, and 2634 operations from source code to 338 model elements (classes, attributes, operations, and relationships). These mappings precisely capture the differences between a provided class diagram design and implementation codebase. Studying all differences in detail allowed us to derive a taxonomy of difference types and to provide a sorted list of cases corresponding to the identified types of differences. As we discuss, our contributions pave the way for improved reverse engineering methods and tools, new mapping rules for model-To-code consistency checks, and guidelines for avoiding over-Abstraction and over-specification during design.  © 2023 IEEE.","2-s2.0-85182331824"
"Atasoy G.; Aydmdogan G.; Arslan S.","Atasoy, Gizem (58706307500); Aydmdogan, Glines (58705574300); Arslan, Secil (57191279489)","58706307500; 58705574300; 57191279489","AI-Augmented Early Warning Models for Commercial and SME Segments: Leveraging Unstructured Data and Time-Series Analytics","2023","UBMK 2023 - Proceedings: 8th International Conference on Computer Science and Engineering","","","","91","96","5","10.1109/UBMK59864.2023.10286634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177579515&doi=10.1109%2fUBMK59864.2023.10286634&partnerID=40&md5=3007adf5e6c221ce4a201a1e47894d95","The Early Warning System is a critical application that uses advanced AI algorithms to monitor large amounts of data to detect potential payment difficulties f or c lients. In this paper, we present a novel approach to generate time-series indicators from new data sources such as Trade Registry Gazette announcements and records of the number of days of delinquency. Our method leverages machine learning algorithms such as Extreme Gradient Boosting (XGBoost) to identify hidden patterns and trends in these data sources, thus overcoming the problems with the traditional rule-based models. By analyzing this data, we can identify time-series anomalies and predict the likelihood of 10 days of delinquency 6 months ahead for the clients in the SME (Small and medium-sized enterprises) and Commercial segments. Our analysis demonstrates that our approach can achieve high accuracy in delinquency prediction, enabling financial i nstitutions t o t ake p roactive m easures to prevent potential losses. Our proposed method can enrich credit monitoring systems and enhance the ability of financial institutions to mitigate financial risk. © 2023 IEEE.","2-s2.0-85177579515"
"Poghosyan A.; Harutyunyan A.; Grigoryan N.; Pang C.","Poghosyan, Arnak (55946421800); Harutyunyan, Ashot (57200866782); Grigoryan, Naira (35147909400); Pang, Clement (57222141212)","55946421800; 57200866782; 35147909400; 57222141212","Distributed Tracing for Troubleshooting of Native Cloud Applications via Rule-Induction Systems","2023","Journal of Universal Computer Science","29","11","","1274","1297","23","10.3897/jucs.112513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181214026&doi=10.3897%2fjucs.112513&partnerID=40&md5=d112d3c353fea40c7a1f92314f2c3158","Diagnosing IT issues is a challenging problem for large-scale distributed cloud environments due to complex and non-deterministic interrelations between the system components. Modern monitoring tools rely on AI-empowered data analytics for detection, root cause analysis, and rapid resolution of performance degradation. However, the successful adoption of AI solutions is anchored on trust. System administrators will not unthinkingly follow the recommendations without sufficient interpretability of solutions. Explainable AI is gaining popularity by enabling improved confidence and trust in intelligent solutions. For many industrial applications, explainable models with moderate accuracy are preferable to highly precise black-box ones. This paper shows the benefits of rule-induction classification methods, particularly RIPPER, for the root cause analysis of performance degradations. RIPPER reveals the causes of problems in a set of rules system administrators can use in remediation processes. Native cloud applications are based on the microservices architecture to consume the benefits of distributed computing. Monitoring such applications can be accomplished via distributed tracing, which inspects the passage of requests through different microservices. We discuss the application of rule-learning approaches to trace traffic passing through a malfunctioning microservice for the explanations of the problem. Experiments performed on datasets from cloud environments proved the applicability of such approaches and unveiled the benefits. © 2023, IICM. All rights reserved.","2-s2.0-85181214026"
"Ehrlinger L.; Werth B.; Wöß W.","Ehrlinger, Lisa (57063205600); Werth, Bernhard (57195298565); Wöß, Wolfram (6603077033)","57063205600; 57195298565; 6603077033","Automating Data Quality Monitoring with Reference Data Profiles","2023","Communications in Computer and Information Science","1860 CCIS","","","24","44","20","10.1007/978-3-031-37890-4_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172682110&doi=10.1007%2f978-3-031-37890-4_2&partnerID=40&md5=f7549feed2f213ee9e855f4ef630e44f","Data quality is of central importance for the qualitative evaluation of decisions taken by AI-based applications. In practice, data from several heterogeneous data sources is integrated, but complete, global domain knowledge is often not available. In such heterogeneous scenarios, it is particularly difficult to monitor data quality (e.g., completeness, accuracy, timeliness) over time. In this paper, we formally introduce a new data-centric method for automated data quality monitoring, which is based on reference data profiles. A reference data profile is a set of data profiling statistics that is learned automatically to model the target quality of the data. In contrast to most existing data quality approaches that require domain experts to define rules, our method can be fully automated from initialization to continuous monitoring. This data-centric method has been implemented in our data quality tool DQ-MeeRKat and evaluated with six real-world telematic device data streams. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85172682110"
"Chandre P.R.; Vanarote V.; Patil R.; Mahalle P.N.; Shinde G.R.; Nimbalkar M.; Barot J.","Chandre, Pankaj R. (57188728117); Vanarote, Viresh (58573891000); Patil, Rajkumar (57219564634); Mahalle, Parikshit N. (35170655700); Shinde, Gitanjali R. (57201552548); Nimbalkar, Madhukar (58659779300); Barot, Janki (58602802100)","57188728117; 58573891000; 57219564634; 35170655700; 57201552548; 58659779300; 58602802100","Explainable AI for Intrusion Prevention: A Review of Techniques and Applications","2023","Lecture Notes in Networks and Systems","719 LNNS","","","339","350","11","10.1007/978-981-99-3758-5_31","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174737359&doi=10.1007%2f978-981-99-3758-5_31&partnerID=40&md5=e966811b46c0bc712741cba704bfb4ec","Intrusion prevention has become a critical concern in today's increasingly complex and interconnected digital systems. Traditional intrusion prevention methods often rely on rule-based approaches that can be inflexible and prone to false positives and false negatives. The emergence of explainable artificial intelligence (AI) techniques has the potential to provide more accurate and interpretable solutions for intrusion prevention. This review paper surveys the current state of the art in explainable AI techniques for intrusion prevention, including their strengths and limitations. We begin by providing an overview of intrusion prevention and the challenges faced by traditional methods. We then explore the different types of explainable AI techniques, such as Local Interpretable Model-Agnostic Explanations (LIME), Shapley Additive Explanations (SHAP), and Integrated Gradients, and their application to intrusion prevention. We also discuss the different types of datasets and evaluation metrics used in explainable AI-based intrusion prevention, including public datasets such as NSL-KDD and UNSW-NB15. Finally, we highlight the future research directions in explainable AI-based intrusion prevention, including the need for larger and more diverse datasets, better evaluation metrics, and more comprehensive explainable AI models. Overall, this review paper provides a comprehensive overview of the state of the art in explainable AI for intrusion prevention, and serves as a valuable resource for researchers and practitioners in the field. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.","2-s2.0-85174737359"
"Freeland S.; Martin A.-S.","Freeland, Steven (23975378900); Martin, Anne-Sophie (57193772505)","23975378900; 57193772505","Harnessing Artificial Intelligence Technologies for Sustainable Space Missions: Legal Perspectives","2023","Artificial Intelligence for Space: AI4SPACE: Trends, Applications, and Perspectives","","","","273","300","27","10.1201/9781003366386-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180042690&doi=10.1201%2f9781003366386-8&partnerID=40&md5=ff4c0670af11fdd8c08fcdd7b26e13c8","Artificial Intelligence (AI) represents an opportunity, but also a challenge, for the future of space activities and its legal framework. Expanding connectivity and symbiotic interaction between humans and intelligent machines raises significant questions for the rule of law, including the liability regime in case of damage arising from actions undertaken through the utilization of increasingly advanced AI in space missions. Artificial Intelligence technologies also encompass a series of possibilities for space sustainability. We describe the legal issues brought by this technology, and then focus specifically on AI systems for space operations, which entail questions about how these interact with existing legal concepts and technical standards. We address the role of AI for space sustainability, especially in relation to how it can support the implementation of the 2019 UNCOPUOS Guidelines for the Long-term Sustainability of Space Activities. We also discuss how space law is relevant and applicable to AI use in the context of sustainable space operations, including autonomous action to avoid collisions in orbit and space traffic management to limit orbital congestion. © 2024 selection and editorial matter, Matteo Madi and Olga Sokolova; individual chapters, the contributors.","2-s2.0-85180042690"
"Yadav A.; Chhabra S.","Yadav, Ashutosh (58785306100); Chhabra, Shilpi (58785655600)","58785306100; 58785655600","Sentiment Analysis of Social Media with AI","2023","AI-Based Data Analytics: Applications for Business Management","","","","14","30","16","10.1201/9781032614083-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180878860&doi=10.1201%2f9781032614083-2&partnerID=40&md5=5599370e953e0caba9b8a00c5f769a41","Sentiment analysis, a crucial aspect of social media analysis, plays a significant role in understanding public opinions and attitudes towards products, services, and events. This chapter provides an overview of the use of artificial intelligence (AI) to conduct sentiment analysis for social media platforms. Various approaches to sentiment analysis, including rule-based, automated, and hybrid methods, are discussed, highlighting their respective strengths and limitations. The chapter further explores different types of sentiment analysis, such as fine-grained sentiment analysis, emotion detection, intent-based sentiment analysis, and aspect-based sentiment analysis, each serving specific analytical purposes. The advantages and disadvantages of employing AI-based sentiment analysis for social media are examined, emphasising its potential for providing valuable insights for businesses, economics, and finance. The chapter outlines popular software tools utilised for conducting sentiment analysis on social media data using AI techniques. It also addresses the cautionary measures, limitations, and challenges associated with sentiment analysis, including issues related to accuracy, context, language nuances, and bias. Overall, this chapter serves as a comprehensive guide to the application of sentiment analysis for social media analysis using AI, offering researchers, practitioners, and decision-makers valuable insights into harnessing the power of public sentiment for informed decision-making. © 2024 selection and editorial matter, Kiran Chaudhary and Mansaf Alam; individual chapters, the contributors.","2-s2.0-85180878860"
"Kareem A.; Sulaiman R.B.; Vaseem Akram S.; Maurya M.; Chakrapani I.S.; Sasikala P.","Kareem, Amer (57226162198); Sulaiman, Rejwan Bin (57225905781); Vaseem Akram, Shaik (57222495187); Maurya, M. (57216222226); Chakrapani, I.S. (57210182774); Sasikala, P. (58549911000)","57226162198; 57225905781; 57222495187; 57216222226; 57210182774; 58549911000","Artificial Intelligence Based Early Diagnosis of Sepsis","2023","2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2023","","","","1557","1562","5","10.1109/ICACITE57410.2023.10182599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178312839&doi=10.1109%2fICACITE57410.2023.10182599&partnerID=40&md5=6069cef90504837e78c89de1676e9784","Sepsis is a major killer of those who are already in a serious condition. The morbidity and death rates in this field remain high, despite the fact that medical technology has been advancing steadily over the last several years. This is due mostly to people not beginning therapy quickly enough and doctors not following best practices. Medical decision support solutions have advanced greatly with the help of artificial intelligence (AI), a rapidly developing sector in the medical industry. Great promise has been shown in its ability to anticipate patients' clinical conditions and aid clinical decision-making. Early prediction, prognosis evaluation, mortality prediction, and optimum treatment are just few of the areas where algorithms developed using artificial intelligence may be put to use. This article summarizes the most recent research on AI based clinical decision support in sepsis as well as explains how this cutting-edge technology might aid in sepsis prediction, identification, sub phenotyping, prognostic evaluation, and clinical treatment. We also spoke about the difficulties of using this non-conventional approach in clinical practice.  © 2023 IEEE.","2-s2.0-85178312839"
"Esposito R.; Polato M.; Aldinucci M.","Esposito, Roberto (35753188100); Polato, Mirko (56401862500); Aldinucci, Marco (8844070100)","35753188100; 56401862500; 8844070100","Boosting Methods for Federated Learning","2023","CEUR Workshop Proceedings","3478","","","439","448","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173481719&partnerID=40&md5=2158a627b773cbb40468f322eeffc870","Federated Learning (FL) has been proposed to develop better AI systems without compromising the privacy of final users and the legitimate interests of private companies. Initially deployed by Google to predict text input on mobile devices, FL has been deployed in many other industries. Since its introduction, Federated Learning mainly exploited the inner working of neural networks and other gradient descent-based algorithms by either exchanging the weights of the model or the gradients computed during learning. While this approach has been very successful, it rules out applying FL in contexts where other models are preferred, e.g., easier to interpret or known to work better. This paper proposes to leverage distributed versions of the AdaBoost algorithm to acquire strong federated models. In contrast with previous approaches, our proposal does not put any constraint on the client-side learning models and does not rely on inner workings of the learning algorithms used in the clients. We perform a large set of experiments on ten UCI datasets, comparing the algorithms in six non-iidness settings. Results show that the approach is effective, in the case of an IID setting, results are often near to the theoretical optimum (i.e., the performances of AdaBoost on the complete dataset). In case of non-IID settings, results very much depend on the severity of the non-IIDness. © 2023 CEUR-WS. All rights reserved.","2-s2.0-85173481719"
"Christou I.T.; Soldatos J.; Papadakis T.; Gutierrez-Rojas D.; Nardelli P.","Christou, Ioannis T. (6602111061); Soldatos, John (8662280800); Papadakis, Thanassis (58654013500); Gutierrez-Rojas, Daniel (57219741491); Nardelli, Pedro (24781106100)","6602111061; 8662280800; 58654013500; 57219741491; 24781106100","Feature Selection via Minimal Covering Sets for Industrial Internet of Things Applications","2023","Proceedings - 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things, DCOSS-IoT 2023","","","","562","567","5","10.1109/DCOSS-IoT58021.2023.00092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174403487&doi=10.1109%2fDCOSS-IoT58021.2023.00092&partnerID=40&md5=3b8da5564fa00d7db9322dd27d7930ad","High stakes decision making requires that any decision support systems must be able to come up with plausible explanations about the decisions they propose to the user. Several popular approaches to explaining black-box AI systems, such as neural networks, focus either on highlighting the features that matter the most in one particular decision as in the SHAP models, or on developing a local to the particular instance data model that is explainable by nature, such as a decision tree. ML systems that are by default explainable and/or interpretable, such as decision trees, or rule-based systems do not require such third-party approaches, as they are themselves explainable. Nevertheless, presenting a consistent (small) set of features to the users as explanations for any given proposed decision can increase the confidence of the users towards the reliability of the system. For this reason, we have developed a system that given a set of rules that hold on a training dataset, finds a minimal cardinality set of features that are used in a set of rules that together cover the entire training dataset. We develop a parallel heuristic algorithm for finding such a minimal variables set, and we show it outperforms all state-of-the-art optimization solvers for finding the solution to a MIP formulation of the problem. Experiments with data from use cases applying AI in public policy decision making as well as in medical use cases show that the proposed small set of features is sufficient to explain all the cases in the test dataset via rules containing only variables from the proposed set of features.  © 2023 IEEE.","2-s2.0-85174403487"
"Adamyk O.; Benson V.; Adamyk B.; Al-Khateeb H.; Chinnaswamy A.","Adamyk, Oksana (57202445942); Benson, Vladlena (14051714200); Adamyk, Bogdan (57202445866); Al-Khateeb, Haider (55339456900); Chinnaswamy, Anitha (56891526800)","57202445942; 14051714200; 57202445866; 55339456900; 56891526800","Does Artificial Intelligence Help Reduce Audit Risks?","2023","Proceedings - International Conference on Advanced Computer Information Technologies, ACIT","","","","294","298","4","10.1109/ACIT58437.2023.10275661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175575982&doi=10.1109%2fACIT58437.2023.10275661&partnerID=40&md5=c71accc16c6eff067350958c15328166","This article aims to discover how AI-powered systems facilitate auditing, what risks emerge for AI-assisted audits and how to deal with these new risks. The paper studies the impact of cognitive computing on audit risk. AI-powered software is capable of self-learn so that it can identify patterns in data and codify them in predictions, rules and decisions. This self-learning ability can become both a benefit and, at the same time, insecurity. Although AI-self-learning helps make the process more efficient and calculations more accurate by improving the algorithm, eliminating errors and reducing risks, it creates new previously unknown threats. We discovered inherent limitations of cognitive-based technologies and risks for the audit process associated with using AI systems. We also proposed a complex security model that can reduce the uncertainty of AI-enabled audit and provides insight into future research opportunities. © 2023 IEEE.","2-s2.0-85175575982"
"Gallese C.; Scantamburlo T.; Manzoni L.; Nobile M.S.","Gallese, Chiara (57222726276); Scantamburlo, Teresa (56009500200); Manzoni, Luca (36440034300); Nobile, Marco S. (55154974000)","57222726276; 56009500200; 36440034300; 55154974000","Investigating Semi-Automatic Assessment of Data Sets Fairness by Means of Fuzzy Logic","2023","CIBCB 2023 - 20th IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology","","","","","","","10.1109/CIBCB56990.2023.10264913","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174930182&doi=10.1109%2fCIBCB56990.2023.10264913&partnerID=40&md5=447928a52988b268a7015dfb23785b11","Research has shown how data sets convey social bias in AI systems, especially those based on machine learning. A biased data set is not representative of reality and might contribute to perpetuate societal biases within the model. To tackle this problem, it is important to understand how to avoid biases, errors, and unethical practices while creating the data sets. In this work we offer a preliminary framework for the semi-Automated evaluation of fairness in data sets, by combining statistical information about data with qualitative consideration. We address the issue of how much (un)fairness can be included in a data set used for machine learning research, focusing on classification issues. In order to provide guidance for the use of data sets in contexts of critical decision-making, such as health decisions, we identify six fundamental features (balance, numerosity, unevenness, compliance, quality, incompleteness) that could affect model fairness. We developed a rule-based approach based on fuzzy logic that combines these characteristics into a single score and enables a semi-Automatic evaluation of a data set in algorithmic fairness research.  © 2023 IEEE.","2-s2.0-85174930182"
"Adamyk O.; Chereshnyuk O.; Adamyk B.; Rylieiev S.","Adamyk, Oksana (57202445942); Chereshnyuk, Oksana (57200180939); Adamyk, Bogdan (57202445866); Rylieiev, Serhii (58677852100)","57202445942; 57200180939; 57202445866; 58677852100","Trustworthy AI: A Fuzzy-Multiple Method for Evaluating Ethical Principles in AI Regulations","2023","Proceedings - International Conference on Advanced Computer Information Technologies, ACIT","","","","608","613","5","10.1109/ACIT58437.2023.10275505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175573204&doi=10.1109%2fACIT58437.2023.10275505&partnerID=40&md5=aadec390c11c3feadb7771b4f390afca","In this study, we investigated the ethical principles of trustworthy AI and differentiated five prime factors essential for developing trust in AI and most widely presented in regulatory guidelines worldwide. By utilizing Fuzzy Logic Toolbox in MATLAB 9.4, we evaluated the impact of primary ethical principles on trustworthy AI systems in a systematic and structured manner. We discovered that the principle of Fairness and Non-discrimination is the most influential for the development of trustworthy AI, as it is the most represented in the regulatory guidelines. The proposed model offers two main benefits for developers and deployers of AI systems, including predicting the potential public trust in AI systems and assessment compliance with the regulatory frameworks. To ensure the continued trustworthiness of AI systems, the model should be used at all stages of the software life circle, including during development, before placing the system on the market, and at the stage of use to monitor compliance with the safeguards declared to users. © 2023 IEEE.","2-s2.0-85175573204"
"Sonntag M.; Mehmann; Teuteberg F.","Sonntag, Martin (57563262700); Mehmann, Jens (56491292600); Teuteberg, Frank (9038835200)","57563262700; 56491292600; 9038835200","DERIVING TRUST-SUPPORTING DESIGN KNOWLEDGE FOR AI-BASED CHATBOTS IN CUSTOMER SERVICE: A USE CASE FROM THE AUTOMOTIVE INDUSTRY","2023","Journal of Organizational Computing and Electronic Commerce","33","3-4","","178","210","32","10.1080/10919392.2023.2276631","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176389429&doi=10.1080%2f10919392.2023.2276631&partnerID=40&md5=f5aec9c8d60ebec07f812a07c7e4a04a","In the automotive industry, companies are increasingly implementing Artificial Intelligence (AI)-based chatbots to support various processes, especially in the context of customer service. However, there currently is a lack of knowledge, especially systematically derived design knowledge, regarding customer trust in interacting with AI-based chatbots. In this context, a lack of security and transparency, limited social features, and the communication style and quality-related issues of AI-based chatbots are just a few aspects that inhibit customer trust in interacting with this innovative technology, thereby hindering the adoption of chatbots. To address this knowledge gap, we adopted a design theory-based approach and developed a design concept for trust-supporting design knowledge regarding customer interaction with an AI-based chatbot. Design science provides a structured development and evaluation process to support, for example, the adoption of AI-based chatbots. Drawing on trust-based literature, a use case in customer service in the automotive industry, and seven semi-structured expert interviews, we propose 10 meta/user requirements and four design principles for trust-supporting design elements as (e.g. social) signals (stimuli) regarding the interaction with AI-based chatbots. We developed two click prototypes over two evaluation cycles. Each evaluation included an online survey with 180 participants. The findings that were obtained make a valuable contribution to solving the described lack of design knowledge by developing and evaluating different design approaches in the form of prototypical user interfaces. Moreover, the results show that visible design elements such as transparent and factual security signals (stimuli) and trust seals have a significant impact on customer trust. © 2023 Taylor & Francis Group, LLC.","2-s2.0-85176389429"
"Yu J.; Ma Z.; Zhu L.","Yu, Jun (55682171900); Ma, Zhengcong (57219966020); Zhu, Lin (57758799500)","55682171900; 57219966020; 57758799500","The configurational effects of artificial intelligence-based hiring decisions on applicants' justice perception and organisational commitment","2023","Information Technology and People","","","","","","","10.1108/ITP-04-2022-0271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175612938&doi=10.1108%2fITP-04-2022-0271&partnerID=40&md5=7d2fe1a2d478ed1e319ca9e77649a6e7","Purpose: This study aims to investigate the configurational effects of five rules – artificial intelligence (AI)-based hiring decision transparency, consistency, voice, explainability and human involvement – on applicants' procedural justice perception (APJP) and applicants' interactional justice perception (AIJP). In addition, this study examines whether the identified configurations could further enhance applicants' organisational commitment (OC). Design/methodology/approach: Drawing on the justice model of applicants' reactions, the authors conducted a longitudinal survey of 254 newly recruited employees from 36 Chinese companies that utilise AI in their hiring. The authors employed fuzzy-set qualitative comparative analysis (fsQCA) to determine which configurations could improve APJP and AIJP, and the authors used propensity score matching (PSM) to analyse the effects of these configurations on OC. Findings: The fsQCA generates three patterns involving five configurations that could improve APJP and AIJP. For pattern 1, when AI-based recruitment with high interpersonal rule (AI human involvement) aims for applicants' justice perception (AJP) through the combination of high informational rule (AI explainability) and high procedural rule (AI voice), there must be high levels of AI consistency and AI voice to complement AI explainability, and only this pattern of configurations can further enhance OC. In pattern 2, for the combination of high informational rule (AI explainability) and low procedural rule (absent AI voice), AI recruitment with high interpersonal rule (AI human involvement) should focus on AI transparency and AI explainability rather than the implementation of AI voice. In pattern 3, a mere combination of procedural rules could sufficiently improve AIJP. Originality/value: This study, which involved real applicants, is one of the few empirical studies to explore the mechanisms behind the impact of AI hiring decisions on AJP and OC, and the findings may inform researchers and managers on how to best utilise AI to make hiring decisions. © 2023, Emerald Publishing Limited.","2-s2.0-85175612938"
"Ema A.; Suyama T.","Ema, Arisa (36056198700); Suyama, Takashi (58547842900)","36056198700; 58547842900","Factors Influencing Trust and Use of Recommendation AI: A Case Study of Diet Improvement AI in Japan","2023","International Library of Ethics, Law and Technology","40","","","187","201","14","10.1007/978-3-031-34804-4_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168677246&doi=10.1007%2f978-3-031-34804-4_10&partnerID=40&md5=a1420475468df123ab3f1ca3d5bc2fff","To use AI systems that are trustworthy, it is necessary to consider not only AI technologies, but also a model that takes into account factors such as guidelines, assurance through audits and standards and user interface design. In this paper, we conducted a questionnaire survey focusing on (1) AI intervention, (2) data management, and (3) purpose of use. The survey was conducted on a case study of an AI service for dietary habit improvement recommendations among Japanese people. The results suggest that how the form of communication between humans and AI is designed may affect whether users trust and use AI. © 2023, The Author(s).","2-s2.0-85168677246"
"Bose S.; Kolekar M.H.; Nawale S.; Khut D.","Bose, Samprit (58278718500); Kolekar, Maheshkumar H. (6505856435); Nawale, Sahil (58628671200); Khut, Dhruv (58629075800)","58278718500; 6505856435; 58628671200; 58629075800","LoLTV: A Low Light Two-Wheeler Violation Dataset With Anomaly Detection Technique","2023","IEEE Access","11","","","124951","124961","10","10.1109/ACCESS.2023.3329737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177223786&doi=10.1109%2fACCESS.2023.3329737&partnerID=40&md5=45b76b25414d363c989048b142ffd5a2","Detecting traffic violations is essential for improving road safety, ensuring rule compliance, and maintaining smooth traffic flow. It also aids in holding violators accountable and supports data-driven decision-making for infrastructure enhancements. To address these challenges, the integration of AI-based methods for automated violation detection is increasingly vital, reducing the need for manual oversight. Low-light conditions pose additional difficulties, as violations become harder to detect. In this study, we created a novel dataset containing 1032 images with 1475 two-wheeler violations under low-light conditions. We propose a real-time deep learning system using YOLO-v8 for two-wheeler violation detection. Our system addresses the challenge of low-light conditions by incorporating a real-time low-light video enhancement module. Through comprehensive evaluations, our system has achieved an average precision of 98.2%, recall of 97.5%, and an accuracy of 97.05% when tested on our custom dataset. Notably, it successfully detected 172 out of 188 violations in the test dataset and exhibited 60% faster processing compared to other state-of-the-art methods. This suggests that our system not only outperforms existing methods on public datasets but also excels in terms of performance and accuracy when applied to the specifically constructed low-light traffic dataset. Furthermore, our system's practical scalability is evident through its integration with multiple devices and CCTV systems.  © 2013 IEEE.","2-s2.0-85177223786"
"Schreiberhuber K.; Sabou M.; Ekaputra F.J.; Knees P.; Aryan P.R.; Einfalt A.; Mosshammer R.","Schreiberhuber, Katrin (58528976300); Sabou, Marta (14042331100); Ekaputra, Fajar J. (55626029300); Knees, Peter (8219023200); Aryan, Peb Ruswono (53263097600); Einfalt, Alfred (56028664800); Mosshammer, Ralf (57213900250)","58528976300; 14042331100; 55626029300; 8219023200; 53263097600; 56028664800; 57213900250","Causality Prediction with Neural-Symbolic Systems: A Case Study in Smart Grids","2023","CEUR Workshop Proceedings","3432","","","336","347","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167395516&partnerID=40&md5=d7270167d645918c5784de58fc3397ae","In complex systems, such as smart grids, explanations of system events benefit both system operators and users. Deriving causality knowledge as a basis for explanations has been addressed with rule-based, symbolic AI systems. However, these systems are limited in their scope to discovering causalities that can be inferred by their rule base. To address this gap, we propose a neural-symbolic architecture that augments symbolic approaches with sub-symbolic components, in order to broaden the scope of the identified causalities. Concretely, we use Knowledge Graph Embeddings (KGE) to solve causality knowledge derivation as a link prediction problem. Experimental results show that the neural-symbolic approach can predict causality knowledge with a good performance and has the potential to predict causalities that were not present in the symbolic system, thus broadening the causality knowledge scope of symbolic approaches. © 2023 Copyright for this paper by its authors.","2-s2.0-85167395516"
"Nikolinakos N.T.","Nikolinakos, Nikos Th. (58486605000)","58486605000","The Proposed Artificial Intelligence Act and Subsequent ‘Compromise’ Proposals: Commission, Council, Parliament","2023","Law, Governance and Technology Series","53","","","327","741","414","10.1007/978-3-031-27953-9_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164711530&doi=10.1007%2f978-3-031-27953-9_8&partnerID=40&md5=2b2fecd5a83171cd55461f71d5f3ff66","This chapter provides a thorough and systematic analysis of the Commission’s proposed AI Act which set harmonised rules for the development, placement on the market and use of AI systems in the EU following a proportionate risk-based approach. The proposed AI Act must be reviewed and adopted by the European Parliament and Member States before it comes into effect and, to this end, the Commission’s proposed AI Act is being discussed by the co-legislators (the main decision-making bodies of the EU), i.e., the European Parliament (“the Parliament”) and the Council of the European Union (“the Council”). This chapter compares the Commission’s proposed AI Act with the Council’s numerous “compromise” proposals (from November 2021 to December 2022) which attempted to find a common position between Member States. The Council’s AI Act final version (general approach) of 11 November 2022 received unanimous approval from the Committee of Permanent Representatives on 18 November 2022, and its formal adoption by EU ministers took place at the Telecom Council meeting on 6 December 2022. This chapter also takes into account the European Parliament’s views on all major and controversial issues, revealing the position the European Parliament is likely to adopt in the forthcoming negotiations with the Commission and the Council on the text of the AI Act. It covers the process of preparing the Parliament’s compromise proposal, taking account of the comments/amendments which were submitted by political groups represented in the European Parliament and which set the tone for future discussions and political negotiations in order to reach a majority via compromises. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85164711530"
"Alonistioti N.; Tsichrintzi E.A.; Chrysafiadi K.; Alepis E.","Alonistioti, Nancy (6506638291); Tsichrintzi, Evangelia Aikaterini (57303055000); Chrysafiadi, Konstantina (16229548500); Alepis, Efthimios (57211584454)","6506638291; 57303055000; 16229548500; 57211584454","Requirements for Fuzzy Logic in Personalisation of Fire Emergency Alerts","2023","14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023","","","","","","","10.1109/IISA59645.2023.10345861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182028247&doi=10.1109%2fIISA59645.2023.10345861&partnerID=40&md5=a710958d84d44994fba24fc9f9367f8f","During major natural disasters like extreme weather events and wildfires, it is very important to notify citizens when the danger level exceeds certain thresholds. However, defining these thresholds in an entirely discrete manner is challenging, despite their major importance. Conversely, triggering an alarm without sufficient justification can be costly for the state and unnecessarily disrupt the lives of citizens. In this regard, employing a more flexible approach, such as fuzzy logic, in the context of artificial intelligence empowerment of the whole process, can provide rules to mitigate the discreteness of alarm thresholds. Failing to raise an alarm, when necessary, can result in significant human and property losses. In this article, we present a new approach that utilises fuzzy logic to classify danger thresholds in a smoother and more effective manner for the civil protection. The paper offers valuable insights into the practical implementation of Fuzzy Logic and the entire life cycle of the proposed Fuzzy logic-based approach. This approach is designed to be iterative, involving key stakeholders to ensure the validity and reliability of the results. © 2023 IEEE.","2-s2.0-85182028247"
"Eilermann S.; Wehmeier L.; Niggemann O.; Deuter A.","Eilermann, Sebastian (58574983000); Wehmeier, Leon (58575916000); Niggemann, Oliver (15835261800); Deuter, Andreas (8385797900)","58574983000; 58575916000; 15835261800; 8385797900","KIAAA: An AI Assistant for Teaching Programming in the Field of Automation","2023","IEEE International Conference on Industrial Informatics (INDIN)","2023-July","","","","","","10.1109/INDIN51400.2023.10218157","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171157934&doi=10.1109%2fINDIN51400.2023.10218157&partnerID=40&md5=544af0c9c889d0d3b067f3b4a2688de5","Especially in highly interdisciplinary fields such as automation engineering, contemporary programming education with tailored assignments and individual feedback is a major challenge for educational institutions due to the increasing number of students per teacher and the ever-increasing demand for computer science professionals. To address this gap, we present 'KIAAA' an AI Assistant for Automation Engineering Teaching, a work-in-progress approach for an integrated, customized, and AI-based learning support system for automation and programming courses based on instructor-defined course objectives. Thereby in the KIAAA system, the individual knowledge level of the students is determined and individually tailored virtual learning scenarios are generated based on the knowledge and learning profile of the students. These are iteratively adapted based on the answers given. To achieve this, KIAAA uses several AI components, a hybrid rule-based scenario generation component, a Help-DKT-based cognitive model, and a solution assessor that uses a combination of traditional code analysis methods and AI-based analyses methods for automated programming task assessment. These components are the main parts of KIAAA to generate customized programming scenarios as well as visualization and simulation based on a modern game and physics engine. © 2023 IEEE.","2-s2.0-85171157934"
"Cepeda Zapata K.A.; Patil R.; Ward T.; Loughran R.; McCaffery F.","Cepeda Zapata, Karla A. (58139678000); Patil, Ritesh (58602164700); Ward, Tomás (7402100229); Loughran, Róisín (24825132300); McCaffery, Fergal (57206225576)","58139678000; 58602164700; 7402100229; 24825132300; 57206225576","Analysis of the Classification of Medical Device Software in the AI Act Proposal","2023","CEUR Workshop Proceedings","3456","","","19","34","15","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171153182&partnerID=40&md5=dea20f85403209b1c6d49d2d0741338c","The Artificial Intelligence Act (AIA) proposal by the European Commission (EC) is considered the first legal attempt to harmonize rules for AI systems. The proposal is designed to regulate AI systems in different European economic sectors, including Medical Devices (MD). This paper aims to examine the classification of AI systems in the AIA and their alignment with the Medical Device Regulation (MDR). The analysis focuses on Software as a Medical Device (SaMD) and Software in a Medical Device (SiMD), excluding general-purpose AI systems and machinery products (i.e., driven systems and safety components), as investigation in the Machinery Directive legislation is required. The strategy is to identify the classification conditions for AI systems by mapping key terms and definitions related to Article 6 in the AIA. Then, these conditions are translated into propositions suitable for the MD domain and presented in a flow chart for discussion. The primary source of information for the analysis is the MDR and the AIA, considering the latest revisited version of the proposal (Presidency compromise text, document 11124/22). We conclude this paper by discussing the classification pathway for SaMD and SiMD according to the AIA and additional discussion on terminology-related concerns and suggestions. © 2023 Copyright for this paper by its authors.","2-s2.0-85171153182"
"Schuett J.","Schuett, Jonas (57219496511)","57219496511","Three lines of defense against risks from AI","2023","AI and Society","","","","","","","10.1007/s00146-023-01811-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178330147&doi=10.1007%2fs00146-023-01811-0&partnerID=40&md5=2c78f97ab97831df809397d1a7eb55fa","Organizations that develop and deploy artificial intelligence (AI) systems need to manage the associated risks—for economic, legal, and ethical reasons. However, it is not always clear who is responsible for AI risk management. The three lines of defense (3LoD) model, which is considered best practice in many industries, might offer a solution. It is a risk management framework that helps organizations to assign and coordinate risk management roles and responsibilities. In this article, I suggest ways in which AI companies could implement the model. I also discuss how the model could help reduce risks from AI: it could identify and close gaps in risk coverage, increase the effectiveness of risk management practices, and enable the board of directors to oversee management more effectively. The article is intended to inform decision-makers at leading AI companies, regulators, and standard-setting bodies. © 2023, The Author(s).","2-s2.0-85178330147"
"Sciolla J.C.; Paseri L.","Sciolla, Jacopo Ciani (57989006900); Paseri, Ludovica (57212571883)","57989006900; 57212571883","Anonymisation of Judicial Rulings for Legal Analytics Purposes: Ethics, Law, and Compliance","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14116 LNAI","","","105","117","12","10.1007/978-3-031-49011-8_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180622444&doi=10.1007%2f978-3-031-49011-8_9&partnerID=40&md5=4bbb645c7ad34da3e09650540b732ca9","Legal Analytics (LA) techniques are a useful tool in the process of digitisation of judicial systems. However, they may imply processing of personal data contained in judicial rulings. This requires an assessment of the impact generated on the rights and freedoms of individuals. What happens if personal data are processed, with LA and AI systems, for research purposes, such as prediction? Should be taken additional technical and organisational measures for the protection of individuals, such as anonymisation or pseudonymisation? The EU legal framework does not interfere with data processing of courts acting in their judicial capacity, in order to safeguard the independence of the judiciary. Therefore, the decision to anonymise judgments is normally taken by the Court’s rules or procedures. The paper provides an overview of the different policies adopted by the different EU countries, investigating whether they should apply to researchers performing LA of judicial rulings. The paper also illustrates how such issues have been dealt within the Legal Analytics for Italian LAw (LAILA) project, funded by the Italian Ministry of Education and Research within the “PRIN programme”. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85180622444"
"Wang L.; Zhang Z.; Wang D.; Cao W.; Zhou X.; Zhang P.; Liu J.; Fan X.; Tian F.","Wang, Liuping (57203515967); Zhang, Zhan (55619663000); Wang, Dakuo (57013823000); Cao, Weidan (55910961000); Zhou, Xiaomu (35301492800); Zhang, Ping (55491528800); Liu, Jianxing (58315572300); Fan, Xiangmin (57202047305); Tian, Feng (57202049684)","57203515967; 55619663000; 57013823000; 55910961000; 35301492800; 55491528800; 58315572300; 57202047305; 57202049684","Human-centered design and evaluation of AI-empowered clinical decision support systems: a systematic review","2023","Frontiers in Computer Science","5","","1187299","","","","10.3389/fcomp.2023.1187299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162059297&doi=10.3389%2ffcomp.2023.1187299&partnerID=40&md5=ddfd7c0dc87e003efa5ae2d009464bab","Introduction: Artificial intelligence (AI) technologies are increasingly applied to empower clinical decision support systems (CDSS), providing patient-specific recommendations to improve clinical work. Equally important to technical advancement is human, social, and contextual factors that impact the successful implementation and user adoption of AI-empowered CDSS (AI-CDSS). With the growing interest in human-centered design and evaluation of such tools, it is critical to synthesize the knowledge and experiences reported in prior work and shed light on future work. Methods: Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we conducted a systematic review to gain an in-depth understanding of how AI-empowered CDSS was used, designed, and evaluated, and how clinician users perceived such systems. We performed literature search in five databases for articles published between the years 2011 and 2022. A total of 19874 articles were retrieved and screened, with 20 articles included for in-depth analysis. Results: The reviewed studies assessed different aspects of AI-CDSS, including effectiveness (e.g., improved patient evaluation and work efficiency), user needs (e.g., informational and technological needs), user experience (e.g., satisfaction, trust, usability, workload, and understandability), and other dimensions (e.g., the impact of AI-CDSS on workflow and patient-provider relationship). Despite the promising nature of AI-CDSS, our findings highlighted six major challenges of implementing such systems, including technical limitation, workflow misalignment, attitudinal barriers, informational barriers, usability issues, and environmental barriers. These sociotechnical challenges prevent the effective use of AI-based CDSS interventions in clinical settings. Discussion: Our study highlights the paucity of studies examining the user needs, perceptions, and experiences of AI-CDSS. Based on the findings, we discuss design implications and future research directions. Copyright © 2023 Wang, Zhang, Wang, Cao, Zhou, Zhang, Liu, Fan and Tian.","2-s2.0-85162059297"
"Shahriar S.; Allana S.; Hazratifard S.M.; Dara R.","Shahriar, Sakib (57216440105); Allana, Sonal (57218691334); Hazratifard, Seyed Mehdi (58402352100); Dara, Rozita (35726812900)","57216440105; 57218691334; 58402352100; 35726812900","A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle","2023","IEEE Access","11","","","61829","61854","25","10.1109/ACCESS.2023.3287195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162824442&doi=10.1109%2fACCESS.2023.3287195&partnerID=40&md5=65ed7be60ded51a61db04f8006a17661","Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual's privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.  © 2013 IEEE.","2-s2.0-85162824442"
"Swamy D.P.; Berghoff C.; Danos V.; Langer F.; Markert T.; Schneider G.; von Twickel A.; Woitschek F.","Swamy, Devi Padmavathialagar (58689871900); Berghoff, Christian (57219591092); Danos, Vasilios (57926303500); Langer, Fabian (57925845300); Markert, Thora (57926303400); Schneider, Georg (57231984600); von Twickel, Arndt (8935046700); Woitschek, Fabian (57330098000)","58689871900; 57219591092; 57926303500; 57925845300; 57926303400; 57231984600; 8935046700; 57330098000","Towards Audit Requirements for AI-Based Systems in Mobility Applications","2023","International Conference on Information Systems Security and Privacy","","","","339","348","9","10.5220/0011619500003405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176347974&doi=10.5220%2f0011619500003405&partnerID=40&md5=d412b112f678cefd003f5d6492db627a","Various mobility applications like advanced driver assistance systems increasingly utilize artificial intelligence (AI) based functionalities. Typically, deep neural networks (DNNs) are used as these provide the best performance on the challenging perception, prediction or planning tasks that occur in real driving environments. However, current regulations like UNECE R 155 or ISO 26262 do not consider AI-related aspects and are only applied to traditional algorithm-based systems. The non-existence of AI-specific standards or norms prevents the practical application and can harm the trust level of users. Hence, it is important to extend existing standardization for security and safety to consider AI-specific challenges and requirements. To take a step towards a suitable regulation we propose 50 technical requirements or best practices that extend existing regulations and address the concrete needs for DNN-based systems. We show the applicability, usefulness and meaningfulness of the p roposed requirements by performing an exemplary audit of a DNN-based traffic sign recognition system using three of the proposed requirements. © 2023 by SCITEPRESS – Science and Technology Publications, Lda.","2-s2.0-85176347974"
"Yeganejou M.; Keshmiri M.; Dick S.","Yeganejou, Mojtaba (57195928906); Keshmiri, Mohammad (58745732700); Dick, Scott (7007080725)","57195928906; 58745732700; 7007080725","Accurate and Explainable Retinal Disease Recognition via DCNFIS","2023","Lecture Notes in Networks and Systems","751 LNNS","","","1","12","11","10.1007/978-3-031-46778-3_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178646845&doi=10.1007%2f978-3-031-46778-3_1&partnerID=40&md5=7776e6a9c10cc273cf3031fedffe778b","The accuracy-interpretability tradeoff is a significant challenge for Explainable AI systems; if too much accuracy is lost, an explainable system might be of no actual value. We report on the ongoing development of the Deep Convolutional Neuro-Fuzzy Inference System, an XAI algorithm that has to this point demonstrated accuracy on par with existing convolutional neural networks. Our system is evaluated on the Retinal OCT dataset, in which it achieves state-of-the-art performance. Explanations for the system’s classifications based on saliency analysis of medoid elements from the fuzzy rules in the classifier component are analyzed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85178646845"
"Huallpa J.J.; Flores Arocutipa J.P.; Panduro W.D.; Huete L.C.; Flores Limo F.A.; Herrera E.E.; Alba Callacna R.A.; Ariza Flores V.A.; Medina Romero M.Á.; Quispe I.M.; Hernández Hernández F.A.","Huallpa, Jorge Jinchuña (57221699160); Flores Arocutipa, Javier Pedro (57217225291); Panduro, Walker Diaz (57645031300); Huete, Luis Chauca (58657670900); Flores Limo, Fernando Antonio (58657141700); Herrera, Edward Espinoza (57934757600); Alba Callacna, Rafael Arturo (57216183211); Ariza Flores, Victor Andre (58317741900); Medina Romero, Miguel Ángel (58658195100); Quispe, Isaac Merino (58362701400); Hernández Hernández, Fredy Alberto (58349530900)","57221699160; 57217225291; 57645031300; 58657670900; 58657141700; 57934757600; 57216183211; 58317741900; 58658195100; 58362701400; 58349530900","Exploring the ethical considerations of using Chat GPT in university education","2023","Periodicals of Engineering and Natural Sciences","11","4","","105","115","10","10.21533/pen.v11i4.3770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172990878&doi=10.21533%2fpen.v11i4.3770&partnerID=40&md5=d257b7a9f07ce86bf5112b47d7986733","This study investigates the moral dilemmas that arise with incorporating Chat GPT into higher education, with a focus on the situation in Latinoamerican institutions of higher learning. The study surveyed 220 people via online questionnaire to learn more about their experiences with and motivations for using AI-powered conversational agents. An overview of the demographics of the participants was provided through descriptive statistics. This investigation of the subject at hand lays the groundwork for further research. It also reveals the hidden meanings of the observed phenomena, and it suggests possible solutions to the problems that have been uncovered. This research looks at how AI systems and chatbots can supplement human knowledge and judgment, as well as their potential drawbacks. The results showed that participants thought Chat GPT integration was moderately accessible and had moderately positive social attitudes. They understood the value and responsibility of Chat GPT in creating individualized educational opportunities. Participants stressed the necessity for explicit institutional standards regarding privacy and data security. Gender, age, sense of accessibility, social attitude, opinions, and personal experience, privacy and data security, institutional guidelines, and individualized learning were also found to affect participants' reliance on AI through regression analysis. The findings shed light on how the integration of Chat GPT into Latinoamerican higher education is complicated by factors such as individual beliefs, cultural norms, and ethical problems. The busy schedules of students may be accommodated and the resources they need to succeed can be made available thanks to this adaptability. In addition, natural language processing models can offer students instantaneous help via text chat, voice, or video. To fully grasp the ethical consequences and lead the creation of responsible implementation techniques, the research proposes that additional qualitative investigations, longitudinal studies, and comparative research across diverse contexts is required. Closing these knowledge gaps will help move the conversational AI field forward in ways that are ethical and beneficial to the classroom. © The Author 2023. This work is licensed under a Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/) that allows others to share and adapt the material for any purpose (even commercially), in any medium with an acknowledgement of the work's authorship and initial publication in this journal. All Rights Reserved.","2-s2.0-85172990878"
"Usmani U.A.; Happonen A.; Watada J.","Usmani, Usman Ahmad (57226748630); Happonen, Ari (35585858000); Watada, Junzo (57189052014)","57226748630; 35585858000; 57189052014","Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations","2023","HORA 2023 - 2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings","","","","","","","10.1109/HORA58378.2023.10156761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165722411&doi=10.1109%2fHORA58378.2023.10156761&partnerID=40&md5=c31651bc59351c71450551ed0d05fc62","Human-Centered Artificial Intelligence (AI) focuses on AI systems prioritizing user empowerment and ethical considerations. We explore the importance of usercentric design principles and ethical guidelines in creating AI technologies that enhance user experiences and align with human values. It emphasizes user empowerment through personalized experiences and explainable AI, fostering trust and user agency. Ethical considerations, including fairness, transparency, accountability, and privacy protection, are addressed to ensure AI systems respect human rights and avoid biases. Effective human AI collaboration is emphasized, promoting shared decision-making and user control. By involving interdisciplinary collaboration, this research contributes to advancing human-centered AI, providing practical recommendations for designing AI systems that enhance user experiences, promote user empowerment, and adhere to ethical standards. It emphasizes the harmonious coexistence between humans and AI, enhancing well-being and autonomy and creating a future where AI technologies benefit humanity. Overall, this research highlights the significance of human-centered AI in creating a positive impact. By centering on users' needs and values, AI systems can be designed to empower individuals and enhance their experiences. Ethical considerations are crucial to ensure fairness and transparency. With effective collaboration between humans and AI, we can harness the potential of AI to create a future that aligns with human aspirations and promotes societal well-being. © 2023 IEEE.","2-s2.0-85165722411"
"Ramya P.; Gowtham C.P.; Kumar S.K.; Silpica T.P.; Renugadevi P.","Ramya, P. (57216605283); Gowtham, C.P. (58573949500); Kumar, S. Kishore (58594809400); Silpica, T.P. (58573900100); Renugadevi, P. (58573977100)","57216605283; 58573949500; 58594809400; 58573900100; 58573977100","A Customisable AI Deck for Pitch Reports and Automated III Umpire Decision Review System DRS","2023","Proceedings of the 2nd International Conference on Edge Computing and Applications, ICECAA 2023","","","","952","957","5","10.1109/ICECAA58104.2023.10212245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170820189&doi=10.1109%2fICECAA58104.2023.10212245&partnerID=40&md5=5b9cc1443b0162d6a7657b3ee2465631","Nowadays giving fair verdict is a quite challenging task because of certain contentious aspects in modern cricket. So, in order to avoid making wrong decisions, we develop an automated AI-based solution. This project focus on a technology that helps both the main umpire and third umpire to makes critical determination for Leg Before the Wicket (LBW) regarding whether the batsman is out or not-out and also minimizes the waiting time for players until the third umpire go through the trajectory of the ball to make a correct decision. The main purpose of our AI-DRS is to remove the umpires call which plays a vital role in giving third umpires decision because whether any one of the cases shows umpires call the decision will be stick with on-field umpires call whether it may be out or not-out. The pitch report and comprehensive cricket laws are also included for the sake of the game. The pitch report will be examined with several key wicket characteristics, such as kind of soil, cracks, amount of grass cover, and wetness, etc. using drone we capture the video of the match day pitch. To determine the field crack, canny edge detection is performed and soil moisture sensor is used to determine the moisture content of the soil. This information help cricket team to make a decision about whether to bat or field after winning the toss and helps to choose the strongest 11 players through which can win the match on that pitch on that day. Utilizing support vector machine (SVM) and histograms of gradients (HOG), objects are classified and recognized. In order to monitor and forecast the velocity of the ball, linear regression and quadratic regression are applied. Finally, Tkinter is used for GUI development, imutils and OpenCV are used as implementation tools. Due to the controversy of rare wicket calls, boundary and penalty runs, we bring a voice recognized AI system which gave fans to easily understand why this decision is made by the umpire and sometime umpires found difficulty to remember some rules which is rarely used in cricket it will also give assist to on-field umpires to give a very clear idea why he made the decision, the on-field umpires can easily access the laws through voice recognition which use Alan-AI. The Voice recognition web app was developed using react-js.  © 2023 IEEE.","2-s2.0-85170820189"
"Tavolato-Wötzl C.; Tavolato P.","Tavolato-Wötzl, Christina (57208408787); Tavolato, Paul (6505913713)","57208408787; 6505913713","Enhancing Trust in Machine Learning Systems by Formal Methods: With an Application to a Meteorological Problem","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14065 LNCS","","","170","187","17","10.1007/978-3-031-40837-3_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172212262&doi=10.1007%2f978-3-031-40837-3_11&partnerID=40&md5=fe5f95993336d2ee2bfb751bad1a4f90","With the deployment of applications based on machine learning techniques the need for understandable explanations of these systems’ results becomes evident. This paper clarifies the concept of an “explanation”: the main goal of an explanation is to build trust in the recipient of the explanation. This can only be achieved by creating an understanding of the results of the AI systems in terms of the users’ domain knowledge. In contrast to most of the approaches found in the literature, which base the explanation of the AI system’s results on the model provided by the machine learning algorithm, this paper tries to find an explanation in the specific expert knowledge of the system’s users. The domain knowledge is defined as a formal model derived from a set of if-then-rules provided by experts. The result from the AI system is represented as a proposition in a temporal logic. Now we attempt to formally prove this proposition within the domain model. We use model checking algorithms and tools for this purpose. If the proof is successful, the result of the AI system is consistent with the model of the domain knowledge. The model contains the rules it is based on and hence the path representing the proof can be translated back to the rules: this explains, why the proposition is consistent with the domain knowledge. The paper describes the application of this approach to a real world example from meteorology, the short-term forecasting of cloud coverage for particular locations. © 2023, IFIP International Federation for Information Processing.","2-s2.0-85172212262"
"Nikolinakos N.T.","Nikolinakos, Nikos Th. (58486605000)","58486605000","Ethical Principles for Trustworthy AI","2023","Law, Governance and Technology Series","53","","","101","166","65","10.1007/978-3-031-27953-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164669119&doi=10.1007%2f978-3-031-27953-9_3&partnerID=40&md5=f38e3576f495c34813b648735ff3acd3","This chapter covers the guiding ethical principles which should be based on the EU’s ‘human-centric’ approach to AI that is respectful of European values and principles. The chapter discusses five ethical principles (“ethical imperatives”) and their correlated values that must be respected in the development, deployment and use of AI systems. These ethical principles are: (i) respect for human autonomy; (ii) prevention of harm (non-maleficence); (iii) fairness/justice; (iv) explicability; (v) the principle of beneficence (‘do only good’), i.e., the principle of creating AI technology that is beneficial to humanity. It is explained that EU policy-makers have chosen to remain faithful to the EU’s cultural preferences and higher standard of protection against the risks posed by AI, building on the existing regulatory framework and ensuring that European values are at the heart of creating the right environment of trust for the successful development and use of AI. The overall aim of the ethics guidelines is—apart from establishing an ethical level playing field across all Member States as well as offering guidance on how to foster and secure the development of ethical AI systems—to bring a European ethical approach to the global stage, i.e. to stimulate discussion of ethical frameworks for AI “at a global level” and, therefore, to build an international consensus on AI ethics guidelines. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85164669119"
"Herrmann T.","Herrmann, Thomas (12791089500)","12791089500","Collaborative Appropriation of AI in the Context of Interacting with AI","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14051 LNAI","","","249","260","11","10.1007/978-3-031-35894-4_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173001278&doi=10.1007%2f978-3-031-35894-4_18&partnerID=40&md5=6dc8fd2ff014071fef3aee0ad503e12a","In the context of maintaining technical equipment, AI is used to detect possible problems. Human specialists check whether a real problem is addressed, and, in this case, try to solve it. Furthermore, they go on trying to translate the problem notification into an improvement of other software components into which the AI system is embedded. Thus, every AI result is not only the cause of immediate action but is also a trigger within the process of continuous appropriation of the technical infrastructure that includes AI. The whole socio-technical system is a subject of AI-related improvement as a collaborative task that requires continuous advancement of human competences and skills. This has to be supported by a type of explainable AI by which the process of understanding the reasons driving AI output is not a task for a single end-user but rather the result of combining different specialists’ viewpoints and competences. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85173001278"
"Camilleri M.A.","Camilleri, Mark Anthony (55916086300)","55916086300","Artificial intelligence governance: Ethical considerations and implications for social responsibility","2023","Expert Systems","","","","","","","10.1111/exsy.13406","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165344366&doi=10.1111%2fexsy.13406&partnerID=40&md5=2a92c11a1cc42f69194760675ee49ff9","A number of articles are increasingly raising awareness on the different uses of artificial intelligence (AI) technologies for customers and businesses. Many authors discuss about their benefits and possible challenges. However, for the time being, there is still limited research focused on AI principles and regulatory guidelines for the developers of expert systems like machine learning (ML) and/or deep learning (DL) technologies. This research addresses this knowledge gap in the academic literature. The objectives of this contribution are threefold: (i) It describes AI governance frameworks that were put forward by technology conglomerates, policy makers and by intergovernmental organizations, (ii) It sheds light on the extant literature on ‘AI governance’ as well as on the intersection of ‘AI’ and ‘corporate social responsibility’ (CSR), (iii) It identifies key dimensions of AI governance, and elaborates about the promotion of accountability and transparency; explainability, interpretability and reproducibility; fairness and inclusiveness; privacy and safety of end users, as well as on the prevention of risks and of cyber security issues from AI systems. This research implies that all those who are involved in the research, development and maintenance of AI systems, have social and ethical responsibilities to bear toward their consumers as well as to other stakeholders in society. © 2023 The Author. Expert Systems published by John Wiley & Sons Ltd.","2-s2.0-85165344366"
"Heck P.; Schouten G.","Heck, Petra (36741406800); Schouten, Gerard (57219468050)","36741406800; 57219468050","Defining Quality Requirements for a Trustworthy AI Wildflower Monitoring Platform","2023","Proceedings - 2023 IEEE/ACM 2nd International Conference on AI Engineering - Software Engineering for AI, CAIN 2023","","","","119","126","7","10.1109/CAIN58948.2023.00029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165217536&doi=10.1109%2fCAIN58948.2023.00029&partnerID=40&md5=99f70ba6c49775b015aae0eaa7bf91c1","For an AI solution to evolve from a trained machine learning model into a production-ready AI system, many more things need to be considered than just the performance of the machine learning model. A production-ready AI system needs to be trustworthy, i.e. of high quality. But how to determine this in practice. For traditional software, ISO25000 and its predecessors have since long time been used to define and measure quality characteristics. Recently, quality models for AI systems, based on ISO25000, have been introduced. This paper applies one such quality model to a real-life case study: a deep learning platform for monitoring wildflowers. The paper presents three realistic scenarios sketching what it means to respectively use, extend and incrementally improve the deep learning platform for wildflower identification and counting. Next, it is shown how the quality model can be used as a structured dictionary to define quality requirements for data, model and software. Future work remains to extend the quality model with metrics, tools and best practices to aid AI engineering practitioners in implementing trustworthy AI systems. © 2023 IEEE.","2-s2.0-85165217536"
"Kemell K.-K.; Vakkuri V.; Sohrab F.","Kemell, Kai-Kristian (57203633786); Vakkuri, Ville (57203640458); Sohrab, Fahad (57188863577)","57203633786; 57203640458; 57188863577","How Do AI Ethics Principles Work? From Process to Product Point of View","2023","CEUR Workshop Proceedings","3582","","","24","38","14","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180009332&partnerID=40&md5=3a84c9eca64dd2de6a8bed6601361976","Discussing the potential negative impacts of AI systems and how to address them has been the core idea of AI ethics more recently. Based on this discussion, various principles summarizing and categorizing ethical issues have been proposed. To bring these principles into practice, it has been common to repackage them into guidelines for AI ethics. The impact of these guidelines seems to remain small, however, and is considered to be a result of a lack of interest in them. To remedy this issue, other ways of implementing these principles have also been proposed. In this paper, we wish to motivate more discussion on the role of the product in AI ethics. While the lack of adoption of these guidelines and their principles is an issue, we argue that there are also issues with the principles themselves. The principles overlap and conflict and commonly include discussion on issues that seem distant from practice. Given the lack of empirical studies in AI ethics, we wish to motivate further empirical studies by highlighting current gaps in the research area. © 2023 Copyright for this paper by its authors.","2-s2.0-85180009332"
"Mishra A.R.; Rai A.; Dayem Ansari M.; Pratap Singh R.","Mishra, Asha Rani (57216459604); Rai, Amrita (36873234500); Dayem Ansari, Mohd (58769674300); Pratap Singh, Ritesh (57207365421)","57216459604; 36873234500; 58769674300; 57207365421","Technical Trends in Public Healthcare and Medical Engineering","2023","Privacy Preservation of Genomic and Medical Data","","","","45","71","26","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180064078&partnerID=40&md5=1890cbca0786a0203fb9ccacdb7ea558","Healthcare is a sizable sector of the economy with outdated systems, which can result in inefficiencies. For healthcare and associated purposes, use computing platforms, networking, software, and sensors as digital health technologies. When new technologies develop and rules change as a result of pooled expertise, this has led to a significant movement in the areas of interest within the field of digital health. Technology can help with trainings, supervision, and the delivery of healthcare in remote areas through telemedicine, m-health, and digital platforms or apps. For unbreakable and infinite connection between medical personnel and patients, present hospitals require online healthcare management and control using different types of sensors, and recent tools and technology that can be used in the medical domain. This chapter discusses health system-related difficulties and looks for appropriate solutions using technologies from the Internet of Things (IoT), clouds, sensors, and soft computing. It also elaborates how several AI-based technologies are creating effective decision assistance for medical applications. © 2024 Scrivener Publishing LLC.","2-s2.0-85180064078"
"Dillenhöfer F.; Doksanbir A.; Kraske J.L.; Künne B.","Dillenhöfer, Fabian (57972355400); Doksanbir, Abdullah (58802547400); Kraske, Jan Lennart (58802385300); Künne, Bernd (6507389325)","57972355400; 58802547400; 58802385300; 6507389325","Automatic Generation of Training Data for AI Object Detection in Terms of Technical Drawings in Engineering","2023","Lecture Notes in Networks and Systems","763 LNNS","","","643","651","8","10.1007/978-3-031-42467-0_60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181804633&doi=10.1007%2f978-3-031-42467-0_60&partnerID=40&md5=5d21ed167d4e8623bc953cfcf24ccd1b","This paper deals with the development of a program code which is able to produce a huge synthetic data training set automatically and quickly. Since technical drawings vary a lot depending on the application, it is difficult to gather a large amount of high quality data for AI-based image classification. To overcome this problem, firstly, engineering standard design proceedings and rules including calculations are collected, and the important objects to classify are defined. This information is then implemented into an algorithm that generates the training data. Finally, a parameter analysis is performed evaluating both the influences of the input into the program to generate training data, and the input of the training data on the object detection quality. The approach will be standardized so that it is scalable for other applications. In addition, an outlook on how this methodology could be integrated into teaching practice is given for a particular example. The easy and fast production of large training data sets for object detection puts forward the use of AI especially in engineering education. This concept is an ex-ample for teachers and researchers to reproduce for their own purpose. In this manner, they are capable of using AI for new challenges. Moreover, the paper investigates the impact of the parameters of the training data program and the significance on the object detection of YOLOv4. The influence of the resizing of the image resolution on the object detection quality is analyzed. Some limitations imposed will be discussed as well. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85181804633"
"Maneria S.; Paikaray D.","Maneria, Sumitra (58136427200); Paikaray, Divya (57219291562)","58136427200; 57219291562","Artificial Intelligence & AGILE Based Business Development Review","2023","2023 3rd International Conference on Advance Computing and Innovative Technologies in Engineering, ICACITE 2023","","","","2091","2095","4","10.1109/ICACITE57410.2023.10182756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178255825&doi=10.1109%2fICACITE57410.2023.10182756&partnerID=40&md5=af6ea2e7fdc671c0386d3d3340dc0cc1","In this essay, I want to look at how to provide products to customers as rapidly as possible without sacrificing product quality. We will examine how the six consistent design principles may assist us in ensuring that the finished product has the highest attainable quality in the shortest amount of time imaginable throughout the improvement interaction. Giving wonderful items quickly for what it's worth to accomplish as such successfully is equally important. There are several strategies we may employ to achieve this, such availability techniques, which enable us to retain the highest level of quality we are capable of as a software development team. Along with a few strategies for expediting product delivery and including a better driver software architecture in the driver software, he explains these strategies. A sizable portion of India's economy is focused on the food industry. The great majority of individuals in this area rely mostly on agricultural produce for their income, which benefits the whole community. The development of food, which is fundamental for human food, is heavily influenced by ranchers. The sales reps are attempting to decide the right selling cost for the offers they are giving. The misfortunes of this organization outperform its benefits. As indicated by the financial exchange hypothesis referenced above, ranchers are allowed to sell their wares at the most elevated offer cost. Ranchers that sign up in this manner will approach different administrations, including assessments, distributer correspondence, market warnings, and different elements and benefits of a comparable kind. Predictive analytics may be used in many other industries, such as expert device manufacture (which might include voice recognition and artificial vision), judicial assessment, and a number of others. Precision agriculture, automated weapons systems (such as drones), and judicial precedent analysis are a few examples. The adoption of artificial intelligence agricultural methods will help alleviate the challenge of the rising global food demand. Artificial intelligence would make it simple to identify and target weeds, and decisions on the use of pesticides and the appropriate buffer zone could be made quickly. It was chosen to include certain artificial intelligence (AI) components in this paper. © 2023 IEEE.","2-s2.0-85178255825"
"Le M.K.; Chia J.Z.J.; Peskes D.","Le, Minh Khai (58522799600); Chia, Jason Zi Jie (58522716900); Peskes, Dennis (58522880600)","58522799600; 58522716900; 58522880600","AI-Based Localization and Classification of Visual Anomalies on Semiconductor Devices","2023","IEEE International Conference on Electro Information Technology","2023-May","","","122","126","4","10.1109/eIT57321.2023.10187356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166739070&doi=10.1109%2feIT57321.2023.10187356&partnerID=40&md5=28352170f426369a6da29f108f73c7fb","This paper presents an AI-based system for automated visual inspection of semiconductor components, aimed at improving the Zero-Defect strategy in their manufacturing process. The system leverages unsupervised learning using Variational Autoencoder to learn and compare images of undamaged components to identify anomalies. An anomaly score is devised to enable detection of even minor flaws on the edges of components and decision rules are evaluated using appropriate metrics. The proposed system surpasses the current tape machine in detecting anomalies, hence contributing to achieving the Zero-Defect strategy in semiconductor manufacturing.  © 2023 IEEE.","2-s2.0-85166739070"
"Yu M.; Gu Y.; Guo X.; Feng Y.; Zhu X.; Greenspan M.; Campbell M.; Gan C.","Yu, Mo (35174012000); Gu, Yi (57814227900); Guo, Xiaoxiao (58729603000); Feng, Yufei (57208922784); Zhu, Xiaodan (55696698900); Greenspan, Michael (56238043800); Campbell, Murray (7403371273); Gan, Chuang (57141834200)","35174012000; 57814227900; 58729603000; 57208922784; 55696698900; 56238043800; 7403371273; 57141834200","JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions","2023","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","11226","11238","12","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175463587&partnerID=40&md5=3c451622a0a2093dabdcb84ed10a620b","Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an essential cornerstone in building general AI systems. We propose a new commonsense reasoning dataset based on human's Interactive Fiction (IF) gameplay walkthroughs as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset provides a natural mixture of various reasoning types and requires multi-hop reasoning. Moreover, the IF game-based construction procedure requires much less human interventions than previous ones. Different from existing benchmarks, our dataset focuses on the assessment of functional commonsense knowledge rules rather than factual knowledge. Hence, in order to achieve higher performance on our tasks, models need to effectively utilize such functional knowledge to infer the outcomes of actions, rather than relying solely on memorizing facts. Experiments show that the introduced dataset is challenging to previous machine reading models as well as the new large language models with a significant 20% performance gap compared to human experts. © 2023 Association for Computational Linguistics.","2-s2.0-85175463587"
"Hazra-Ganju A.; Dlima S.D.; Menezes S.R.; Ganju A.; Mer A.","Hazra-Ganju, Aditi (57218502294); Dlima, Schenelle Dayna (57282457800); Menezes, Sonia Rebecca (57218499835); Ganju, Aakash (50361188100); Mer, Anjali (58567841300)","57218502294; 57282457800; 57218499835; 50361188100; 58567841300","An omni-channel, outcomes-focused approach to scale digital health interventions in resource-limited populations: a case study","2023","Frontiers in Digital Health","5","","1007687","","","","10.3389/fdgth.2023.1007687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170208425&doi=10.3389%2ffdgth.2023.1007687&partnerID=40&md5=cd5cb742aec90d62529929895992054a","Populations in resource-limited communities have low health awareness, low financial literacy levels, and inadequate access to primary healthcare, leading to low adoption of preventive health behaviours, low healthcare-seeking behaviours, and poor health outcomes. Healthcare providers have limited reach and insights, limiting their ability to design relevant products for resource limited settings. Our primary preventive health intervention, called the Saathealth family health interventions, is a scaled digital offering that aims to improve knowledge levels on various health topics, nudge positive behaviour changes, and drive improved health outcomes. This case study presents our learnings and best practices in scaling these digital health interventions in resource-limited settings and maximising their impact. We scaled the Saathealth interventions to cumulatively reach >10 million users across India using a multi-pronged approach: (1) ensuring localization and cultural relevance of the health content delivered through user research; (2) disseminating content using omni-channel approaches, which involved using diverse content types and multiple digital platforms; (3) using iterative product features such as gamification and artificial intelligence-based (AI-based) predictive models; (4) using real-time analytics to adapt the user's digital experience by using interactive content to drive them towards products and services and (5) experiments with sustainability models to yield some early successes. The Saathealth family health mobile app had >25,000 downloads and the intervention reached >873,000 users in India every month through the mobile app, Facebook, and Instagram combined, from the time period of February 2022 to January 2023. We repeatedly observed videos and quizzes to be the most popular content types across all digital channels being used. Our AI-based predictive models helped improve user retention and content consumption, contributing to the sustainability of the mobile apps. In addition to reaching a high number of users across India, our scaling strategies contributed to deepened engagement and improved health-seeking behaviour. We hope these strategies help guide the sustainable and impactful scaling of mobile health interventions in other resource-limited settings. 2023 Hazra-Ganju, Dlima, Menezes, Ganju and Mer.","2-s2.0-85170208425"
"Ronanki K.","Ronanki, Krishna (58483395600)","58483395600","Towards an AI-centric Requirements Engineering Framework for Trustworthy AI","2023","Proceedings - International Conference on Software Engineering","","","","278","280","2","10.1109/ICSE-Companion58688.2023.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171855123&doi=10.1109%2fICSE-Companion58688.2023.00075&partnerID=40&md5=ffa5efeeab1b6e5dcda2acccf871dcae","Ethical guidelines are an asset for artificial intel-ligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level. © 2023 IEEE.","2-s2.0-85171855123"
"Heuer M.; Lewandowski T.; Weglewski J.; Mayer T.; Kubicek M.; Lembke P.; Ortgiese S.; Böhmann T.","Heuer, Marvin (58177483800); Lewandowski, Tom (58177277900); Weglewski, Joffrey (58591857000); Mayer, Tom (58591857100); Kubicek, Max (58590965500); Lembke, Patrick (58593186600); Ortgiese, Simon (58593186700); Böhmann, Tilo (22939846600)","58177483800; 58177277900; 58591857000; 58591857100; 58590965500; 58593186600; 58593186700; 22939846600","Rethinking Interaction with Conversational Agents: How to Create a Positive User Experience Utilizing Dialog Patterns","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14033 LNCS","","","283","301","18","10.1007/978-3-031-35708-4_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171485601&doi=10.1007%2f978-3-031-35708-4_22&partnerID=40&md5=0b9cd2116a053b6fa043f95affcedab5","Conversational agents (CAs) are increasingly used as an additional convenient and innovative customer service channel to relieve service employees, as in the studied organization. In the process of analyzing and maintaining the present AI-based agent, however, user satisfaction is low as the CA lacks understanding and offers unsatisfactory solutions to users. Nonetheless, solving the requests and providing a positive user experience is crucial to relieve the service employees’ workload permanently. For CAs’ improvement, this study followed action design research (ADR) and used design thinking. We identified the central interaction problems (findability, welcome message, dialog control and fallback issues) with a monitoring process and analysis. Afterward, we interviewed users about their expectations and requirements and addressed these problems by creating user-centric mock-ups. Through a quantitative survey, the most popular solutions were implemented in a prototype. Finally, the resulting CA prototype was evaluated, showing a significantly improved user experience afterward, and design guidelines were discovered. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85171485601"
"Farhi F.; Jeljeli R.; Aburezeq I.; Dweikat F.F.; Al-shami S.A.; Slamene R.","Farhi, Faycal (57216876673); Jeljeli, Riadh (57202027520); Aburezeq, Ibtehal (56798650000); Dweikat, Fawzi Fayez (58500500100); Al-shami, Samer Ali (58110130000); Slamene, Radouane (58297665300)","57216876673; 57202027520; 56798650000; 58500500100; 58110130000; 58297665300","Analyzing the students' views, concerns, and perceived ethics about chat GPT usage","2023","Computers and Education: Artificial Intelligence","5","","100180","","","","10.1016/j.caeai.2023.100180","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176221584&doi=10.1016%2fj.caeai.2023.100180&partnerID=40&md5=ddb4c58b8772d6fcebe421e6b1095d39","Artificial Intelligence has greatly revolutionized education in many aspects. Today, AI-enabled language models, such as ChatGPT, are gaining popularity due to their characteristics and benefits. However, users also consider them a threat to educational integrity and purposes. This research examined ChatGPT usage among students in the United Arab Emirates (UAE), their views, concerns, and perceived ethics. The data was gathered from 388 students from two universities in Al Ain city using Yamane's formula. Findings showed that students consider ChatGPT a revolutionary technology that helps students in many ways. The gathered data showed that the effect of ChatGPT Usage remained significant on students' views. The path analysis also supported the second hypothesis, proposing the significant effect of ChatGPT on Students' Concerns. Finally, the findings also indicated the validation of the final hypothesis, showing the significant effect of ChatGPT Usage on the Perceived Ethics among the students in the UAE. Therefore, this study concluded that using ChatGPT in education has useful and concerning effects on educational integrity. However, implementing practical guidelines can assist in making informed decisions and shaping policies within educational institutions. Recognizing the complexities and importance of ChatGPT usage, teachers and policymakers can keep a balance by leveraging Artificial Intelligence technology to improve education while upholding ethical practices that promote critical thinking, originality, and integrity among students. © 2023 The Authors","2-s2.0-85176221584"
"Fareedi A.A.; Ismail M.; Ghazawneh A.; Bergquist M.; Ortiz-Rodriguez F.","Fareedi, Abid Ali (50161218200); Ismail, Muhammad (58554770000); Ghazawneh, Ahmad (36006505700); Bergquist, Magnus (26424554300); Ortiz-Rodriguez, Fernando (15043035600)","50161218200; 58554770000; 36006505700; 26424554300; 15043035600","The Utilization of Artificial Intelligence for Developing Autonomous Social Robots within Health Information Systems","2023","CEUR Workshop Proceedings","3447","","","34","50","16","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169129710&partnerID=40&md5=82cdf6babd14d257e66963014db9c49e","This study focuses on using AI systems, specifically conversational agents (CAs), to improve information flow during peak hours in healthcare emergency departments (EDs). We customized a Cross Industry Standard Process for Data Mining CRISP-DM approach to a CRISP-Knowledge graph (CRISP-KG) for overall design research. We use a knowledge graph approach to create an intelligent knowledge base (KBs) for CAs, which can enhance their reasoning, knowledge management, and context awareness abilities. We employ a collaborative methodology and ontology design patterns to develop a formal ontological model. Our goal is to build intelligent KBs for CAs that can interact with end-users and improve care quality in EDs, using Semantic Web Rule Language (SWRL) for inference. The KG approach can assist healthcare practitioners and patients in managing information flow more efficiently in EDs, ultimately improving care outcomes. © 2023 CEUR-WS. All rights reserved.","2-s2.0-85169129710"
"Sulaiman M.; Håkansson A.; Karlsen R.","Sulaiman, Muhammad (22434244300); Håkansson, Anne (15055825600); Karlsen, Randi (7006442939)","22434244300; 15055825600; 7006442939","A Proof-of-Concept Implementation Based on the Framework of AI-Enabled Proactive mHealth: Health Promotion with Motivation","2023","Communications in Computer and Information Science","1814 CCIS","","","256","287","31","10.1007/978-3-031-38854-5_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172213344&doi=10.1007%2f978-3-031-38854-5_14&partnerID=40&md5=17cb0cc00c259263800b519d67e61754","Digital health with mHealth contributes to health promotion by empowering the user with a holistic view of their health. Proactive mHealth is to predict and prevent a situation beforehand, promptly. Most health decisions are taken by the user pervasively. They have a short or long-term impact. Being proactive requires support as ubiquitous decision-making is prone to sudden changes. Changes in users’ internal and contextual states require adaptive systems with timeliness. Personalized health information needs analysis to support user-level decision-making. The goal is to automate processes and augment healthy behaviour. Data from wearables, together with the context, requires automated decision-making with AI modelling, for predicting intervention values. Prediction and prevention mechanism in implementation requires timely interventions, triggered with a supportive action. The health information (wearables + context) can provide information about the states (current, future, and goal). AI-enabled proactive mHealth framework accentuates abstraction by presenting modules with rules of user-level decision-making, tools for automated decision-making, design with P5 principles, and the architecture of Just-in-time adaptive interventions. In this paper, a proof-of-concept (POC) for health promotion with physical activity is implemented based on the framework. The goal is to promote health with motivation. The paper also categorizes intervention with type, properties, and principles. Components of intervention and behaviour change are also listed. POC includes parameters of context and user profile. The paper provides a step-by-step approach to implementing the system on the framework, from input/output mapping to modelling. The outcome is a POC that alters and augments behaviour change for health promotion with physical activity. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85172213344"
"Brehar R.; Groza A.; Damian I.; Muntean G.; Nicoara S.D.","Brehar, Raluca (36674570400); Groza, Adrian (23389267600); Damian, Ioana (57194702031); Muntean, George (57202511576); Nicoara, Simona Delia (7003830224)","36674570400; 23389267600; 57194702031; 57202511576; 7003830224","Age-Related Macular Degeneration Biomarker Segmentation from OCT images","2023","Proceedings - 2023 24th International Conference on Control Systems and Computer Science, CSCS 2023","","","","444","451","7","10.1109/CSCS59211.2023.00076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170221067&doi=10.1109%2fCSCS59211.2023.00076&partnerID=40&md5=0f4d28b95cd9bafe07e020e3f716828c","The image classification task is considered solved from the technical perspective: given enough data - in terms of quantity, quality and distribution - machine learning technology is able to classify various medical conditions with high performance metrics. Yet, one disadvantage is that the large majority of approaches directly target to signal the disease without considering at all the running protocols or medical guidelines used by clinicians. We address here the gap between running clinical protocols and solutions provided by computer scientists. Instead of directly target the disease, we aim the identify only the biomarkers that the physicians are looking for. We apply this approach to the age-related macular degeneration (AMD). The task is to identify biomarkers for the AMD condition by segmenting retinal optical coherence tomography (OCT) images. One relevant question regards the choice between feature based techniques versus deep learning methods. We address this question by providing a hybrid original solution that combines deep learning based retinal layer segmentation with feature based image classification used to distinguish between a particular fluid area and its neighbouring retinal areas. In this context we perform a comparative analysis of various semantic segmentation techniques which provide noticeable results for retinal layer segmentation. On the other hand, due to the low representation of some fluids in the considered benchmark dataset, we address and enhance their recognition by texture based region of interest classification. The proposed approach is a step towards developing AI systems in line with running medical protocols. © 2023 IEEE.","2-s2.0-85170221067"
"Mittal P.; Gupta A.; Panigrahi B.S.; Begum R.; Sen S.K.","Mittal, Poonam (54397365000); Gupta, Ashlesha (55547705300); Panigrahi, Bhawani Sankar (57777583600); Begum, Ruqqaiya (58065116500); Sen, Sanjay Kumar (58414965800)","54397365000; 55547705300; 57777583600; 58065116500; 58414965800","Face Mask Detection: An Application of Artificial Intelligence","2023","Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","471 LNICST","","","193","201","8","10.1007/978-3-031-35081-8_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169674950&doi=10.1007%2f978-3-031-35081-8_16&partnerID=40&md5=470f4bdc045152d97905be676ee0dbdb","COVID-19 has been announced as a new pandemic which has affected almost all the countries of the world. Millions of people have become sick and thousands have died due to the respiratory illness caused by the virus. The virus is known to spread when small droplets from nose or mouth of an infected person gets dissolved in air when he or she coughs or exhales or when a person touches a surface infected with virus. The governments all over the world are working on ways to curb the spread of this virus. Multidisciplinary researchers are working to find the best solutions in their own way. Out of the many solutions wearing surgical facemasks is being one of the best preventive measures to limit the spread of corona virus. These masks support filtration of air and adequate breathability. But the problem is that few people don’t use the masks regularly or occasionally due to various reasons like negligence and discomfort etc. This is one of the main causes of high spread of COVID. So, there is a strong need to detect people without mask at public places and to aware them. There are so many initiatives taken by government in this direction, but all have their limitation in one or the other way. So, there is a strong need of a digital solution to ensure that people comply with the government rules of wearing masks in public place sand to recognize unmasked faces on existing monitoring systems to maintain safety and security. Facial recognition systems were being used to identify faces using technology that includes hardware like video cameras. These systems work by combining AI based pattern recognition system along with biometrics to map facial features from an image and compare it with a database of known faces. This research content is also an initiative in this direction to optimize the results. © 2023, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","2-s2.0-85169674950"
"Zeller M.; Rothfelder M.; Klein C.","Zeller, Marc (7101842885); Rothfelder, Martin (8308380400); Klein, Cornel (24722763000)","7101842885; 8308380400; 24722763000","Safe.trAIn - Engineering and Assurance of a Driverless Regional Train","2023","Proceedings - 2023 IEEE/ACM 2nd International Conference on AI Engineering - Software Engineering for AI, CAIN 2023","","","","197","","","10.1109/CAIN58948.2023.00036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165180845&doi=10.1109%2fCAIN58948.2023.00036&partnerID=40&md5=c501a4efc167e2214d0e93ed974a1efa","Traditional automation technologies alone are not sufficient to enable the fully automated operation of trains. However, Artificial Intelligence (AI) and Machine Learning (ML) offers great potential to realize the mandatory novel functions to replace the tasks of a human train driver, such as obstacle detection on the tracks. The problem, which still remains unresolved, is to find a practical way to link AI/ML techniques with the requirements and approval processes that are applied in the railway domain. The safe.trAIn project aims to lay the foundation for the safe use of AI/ML to achieve the driverless operation of rail vehicles and thus addresses this key technological challenge hindering the adoption of unmanned rail transport. The project goals are to develop guidelines and methods for the reliable engineering and safety assurance of ML in the railway domain. Therefore, the project investigates methods to reliable design ML models and to prove the trustworthiness of AI-based functions taking robustness, uncertainty, and transparency aspects of the AI/ML model into account. © 2023 IEEE.","2-s2.0-85165180845"
"SureshKumar M.; Raviraaj S.I.V.; Sukhresswarun R.","SureshKumar, M. (57195360699); Raviraaj, S.I. Vishwa (58797040900); Sukhresswarun, R. (58797067400)","57195360699; 58797040900; 58797067400","Inclusion of XAI in artificial intelligence and deep learning technologies","2023","Explainable Artificial Intelligence (XAI): Concepts, enabling tools, technologies and applications","","","","51","64","13","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181628434&partnerID=40&md5=d31c8c4f185f6fac2550f99655a9a372","As technology has advanced over the past few decades, the complexity of artificial intelligence (AI) systems has increased rapidly. While these systems can provide impressive results, they can also be difficult to understand, even for experts in the field. Explainable AI (XAI) is an emerging field of research focused on making AI systems more transparent and interpretable. In this article, we will explore what XAI is, why it matters, and how it works. XAI is an emerging field of research that aims to make AI systems more transparent, interpretable, and accountable. In recent years, AI has made significant advances in fields such as natural language processing, image recognition, and game playing. However, as AI systems become more complex and ubiquitous, it becomes increasingly important to ensure that they are used ethically and responsibly. One of the main challenges with AI is that it can be difficult for humans to understand how the system arrived at a particular decision. For example, a deep learning algorithm might be able to identify objects in an image with incredible accuracy, but it may not be clear how the system arrived at its conclusion. This can lead to a lack of trust in the system, particularly in high-stakes domains such as healthcare, finance, and criminal justice. Technically, XAI refers to a set of methods and techniques that enable AI systems to provide human-understandable explanations of their decisions, predictions, and actions. XAI utilizes various approaches such as rule-based systems, decision trees, and model-based techniques to produce explanations that can be interpreted and verified by humans. XAI aims to address the lack of transparency and accountability in traditional black-box AI systems referred in Figure 4.1, which can make it difficult for developers and users to understand and trust these systems. By providing interpretable explanations, XAI can increase the effectiveness, reliability, and trustworthiness of AI systems in a variety of applications. © The Institution of Engineering and Technology 2023.","2-s2.0-85181628434"
"Krauss C.; Streicher A.; Poxleitner E.; Altun D.; Mueller J.; An T.-S.; Mueller C.","Krauss, Christopher (55988607500); Streicher, Alexander (37162259500); Poxleitner, Eva (58478916000); Altun, Daniela (57226639605); Mueller, Joanna (58478916100); An, Truong-Sinh (57191329137); Mueller, Christoph (57768545700)","55988607500; 37162259500; 58478916000; 57226639605; 58478916100; 57191329137; 57768545700","Best-of-Breed: Service-Oriented Integration of Artificial Intelligence in Interoperable Educational Ecosystems","2023","Communications in Computer and Information Science","1830 CCIS","","","267","283","16","10.1007/978-3-031-34754-2_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164247368&doi=10.1007%2f978-3-031-34754-2_22&partnerID=40&md5=a2af18d74c6f7f1d42828f9b1722ba57","Artificial Intelligence (AI) offers great potential for optimizing learning processes, teaching methods, learning content, or organizational procedures. However, the success of AI components in educational environments is by no means guaranteed and depends on several conditions in their respective learning settings. In this article, we analyze requirements that are often addressed prior to introducing AI features. We address organizational, methodological, didactical, content-related, and technical challenges. The research question of this work is how AI features can best be incorporated into modern educational system landscapes to create sustainable system architectures that are accepted and perceived as added value by users. Thereby, the article discusses two approaches to software architecture: Best-of-Suite (for monolithic architectures) and Best-of-Breed (for service-oriented architectures). Monolithic systems offer a wide range of functions, can be offered by a single provider but can become difficult to manage and create dependencies. Specialized and service-oriented systems, in turn, consist of modular functions handled by specialized services, are more flexible and scalable, and can be integrated with a wide range of tools and services, but require more effort to set up and manage. We explain why the Best-of-Breed strategy is a sensible approach to the use of AI components, how this can be implemented sustainably with the help of a middleware component, and we report on the user experiences from a field test. While in this work we evaluate the implemented system with a cybersecurity training as an on-the-job course, the middleware has been successfully used in other educational contexts, as well. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85164247368"
"Bunde E.; Eisenhardt D.; Sonntag D.; Profitlich H.-J.; Meske C.","Bunde, Enrico (57218312382); Eisenhardt, Daniel (58304928500); Sonntag, Daniel (12241487800); Profitlich, Hans-Jürgen (6506157925); Meske, Christian (55806873000)","57218312382; 58304928500; 12241487800; 6506157925; 55806873000","Giving DIAnA More TIME – Guidance for the Design of XAI-Based Medical Decision Support Systems","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13873 LNCS","","","107","122","15","10.1007/978-3-031-32808-4_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161153089&doi=10.1007%2f978-3-031-32808-4_7&partnerID=40&md5=05876ce90d402f71972f3a7e34216add","Future healthcare ecosystems integrating human-centered artificial intelligence (AI) will be indispensable. AI-based healthcare technologies can support diagnosis processes and make healthcare more accessible globally. In this context, we conducted a design science research project intending to introduce design principles for user interfaces (UIs) of explainable AI-based (XAI) medical decision support systems (XAI-based MDSS). We used an archaeological approach to analyze the UI of an existing web-based system in the context of skin lesion classification called DIAnA (Dermatological Images – Analysis and Archiving). One of DIAnA’s unique characteristics is that it should be usable for the stakeholder groups of physicians and patients. We conducted the in-situ analysis with these stakeholders using the think-aloud method and semi-structured interviews. We anchored our interview guide in concepts of the Theory of Interactive Media Effects (TIME), which formulates UI features as causes and user psychology as effects. Based on the results, we derived 20 design requirements and developed nine design principles grounded in TIME for this class of XAI-based MDSS, either associated with the needs of physicians, patients, or both. Regarding evaluation, we first conducted semi-structured interviews with software developers to assess the reusability of our design principles. Afterward, we conducted a survey with user experience/interface designers. The evaluation uncovered that 77% of the participants would adopt the design principles, and 82% would recommend them to colleagues for a suitable project. The findings prove the reusability of the design principles and highlight a positive perception by potential implementers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85161153089"
"Chrobak R.; Galán S.G.; Expósito E.M.; Ibanez M.V.; Marciniak T.; Marchewka A.","Chrobak, Rafal (58778136300); Galán, Sebastián García (57218862439); Expósito, Enrique Munoz (57218863288); Ibanez, Manuel Valverde (57452044800); Marciniak, Tomasz (57197973686); Marchewka, Adam (50461746200)","58778136300; 57218862439; 57218863288; 57452044800; 57197973686; 50461746200","Color Tracking Application Using AI-Based Docker Container Scheduling in Fog Computing","2023","Lecture Notes in Networks and Systems","766","","","169","183","14","10.1007/978-3-031-41630-9_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180539956&doi=10.1007%2f978-3-031-41630-9_17&partnerID=40&md5=0f62b171c2ce1093a0f74b04ccec40f8","This paper presents the real implementation of a fog computing environment for the execution of color tracking applications by using FogBus2 framework and an artificial intelligence based docker container scheduling. To be precise, an edge computing network has been developed by using a personal computer and several small computing devices such as Raspberry Pi and Nvidia Jetson Nano. Related to the scheduling policy, besides the existing policies in Fogbus2 framework, another one based on fuzzy rules-based system has been designed. Results demonstrate the proposed policy outperforms classical approaches, even when using, pavin the way to the use of knowledge acquisition techniques in order to improve the scheduling performance in terms of makespan and flowtime. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85180539956"
"Nikolinakos N.T.","Nikolinakos, Nikos Th. (58486605000)","58486605000","The European Parliament’s 2020 Resolution: Proposal for a Regulation on Ethical Principles for the Development, Deployment and Use of Artificial Intelligence, Robotics and Related Technologies","2023","Law, Governance and Technology Series","53","","","281","306","25","10.1007/978-3-031-27953-9_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164736983&doi=10.1007%2f978-3-031-27953-9_6&partnerID=40&md5=c7266c5a9991f66f14bae8b956bffd41","This chapter examines the European Parliaments’ 2020 Resolution on a framework of ethical principles and legal obligations for the development, deployment and use of artificial intelligence, robotics and related technologies. With this legislative initiative, the Parliament urged the Commission to present a new legal framework (the AI Regulation/Act) outlining the ethical principles and legal obligations to be followed when developing, deploying and using artificial intelligence, robotics and related technologies in the EU. In line with the White Paper on AI and the Ethics Guidelines for Trustworthy AI, the Parliament’s proposal for a Regulation on AI was premised on several guiding principles and obligations to be imposed in relation to “high-risk” sectors and high-risk uses and purposes that entail a risk of breach of fundamental rights and safety rules. Those guiding principles and obligations included a human-centric, human-made and human-controlled AI (guaranteeing full human oversight); an impartial, regulated and external ex-ante risk assessment based on concrete and pre-defined criteria; features to ensure safety, transparency and accountability; safeguards against bias and discrimination; the right to challenge the introduction or ongoing use of a AI system and to seek remedies for a violation of rights; social responsibility and environmental sustainability; respect for privacy and fundamental rights. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85164736983"
"Clariso R.; Cabot J.","Clariso, Robert (8948086100); Cabot, Jordi (8963493600)","8948086100; 8963493600","Model-Driven Prompt Engineering","2023","Proceedings - ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems, MODELS 2023","","","","47","54","7","10.1109/MODELS58315.2023.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182339047&doi=10.1109%2fMODELS58315.2023.00020&partnerID=40&md5=d312907ae4ff6d7b6199849d1b6aa28b","Generative artificial intelligence (AI) systems are capable of synthesizing complex content such as text, source code or images according to the instructions described in a natural language prompt. The quality of the output depends on crafting a suitable prompt. This has given rise to prompt engineering, the process of designing natural language prompts to best take advantage of the capabilities of generative AI systems.Through experimentation, the creative and research communities have created guidelines and strategies for creating good prompts. However, even for the same task, these best practices vary depending on the particular system receiving the prompt. Moreover, some systems offer additional features using a custom platform-specific syntax, e.g., assigning a degree of relevance to specific concepts within the prompt.In this paper, we propose applying model-driven engineering to support the prompt engineering process. Using a domain-specific language (DSL), we define platform-independent prompts that can later be adapted to provide good quality outputs in a target AI system. The DSL also facilitates managing prompts by providing mechanisms for prompt versioning and prompt chaining. Tool support is available thanks to a Langium-based Visual Studio Code plugin.  © 2023 IEEE.","2-s2.0-85182339047"
"Sanabria-Z J.; Alfaro-Ponce B.; Argüelles-Cruz A.; Ramírez-Montoya M.S.","Sanabria-Z, Jorge (58663027800); Alfaro-Ponce, Berenice (57218391289); Argüelles-Cruz, Amadeo (23395973700); Ramírez-Montoya, Maria Soledad (54911980200)","58663027800; 57218391289; 23395973700; 54911980200","AI-Based Platform Design for Complex Thinking Assessment: A Case Study of an Ideathon Using the Transition Design Approach","2023","Computers in the Schools","40","4","","391","411","20","10.1080/07380569.2023.2256711","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174811612&doi=10.1080%2f07380569.2023.2256711&partnerID=40&md5=215fc1b4eadfcc363d61df9e0844bdea","Emerging Artificial Intelligence-enhanced technology platforms in education warrant attention to exploring new learning strategies and dynamics. Keeping up with the accelerating momentum to bring classic traditional learning activities to Artificial Intelligence-supported platforms may unbalance the interest in developing the participants’ higher-order thinking. This article presents case study research of an Artificial Intelligence-based technological platform to measure complex thinking traits of higher education participants in an Ideathon learning scenario. The didactical strategy was grounded in the Transition Design approach, with Sharing Economy as the challenge. An overview of the process for developing Artificial Intelligence-supported activities, the challenges and risks identified in the development, and a classification model and enhancements for future implementation in a subsequent pilot are presented. The findings set a guideline for balancing Artificial Intelligence-powered educational activities and the development of the participants’ complex thinking. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","2-s2.0-85174811612"
"Hossain S.S.; Ebrahimi M.R.; Padmanabhan B.; El Naqa I.; Kuo P.C.; Beard A.; Merkel S.","Hossain, Shafayet Shariar (58547898800); Ebrahimi, Mohammadreza Reza (56208183900); Padmanabhan, Balaji (56512553400); El Naqa, Issam (35472734900); Kuo, Paul C. (58199844100); Beard, Abigail (57917554400); Merkel, Sarah (58547399100)","58547898800; 56208183900; 56512553400; 35472734900; 58199844100; 57917554400; 58547399100","Robust AI-enabled Simulation of Treatment Paths with Markov Decision Process for Breast Cancer Patients","2023","Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023","","","","105","108","3","10.1109/CAI54212.2023.00053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168665500&doi=10.1109%2fCAI54212.2023.00053&partnerID=40&md5=98c00ba8d0f08a9ea5541f8ad9ec8c49","Development in AI/ML-based methodologies has facilitated improvement in clinical decision making at various stages of treatment in breast cancer care. While this addresses patient needs at specific stages of treatment, the overall treatment path of a patient from a holistic standpoint has remained understudied due to challenges in accessing the relevant data. In this study, we propose to develop an AI-enabled treatment path simulation for breast cancer patients while characterizing the treatment paths as a Markov decision process (MDP). In order to avoid the limitations of healthcare records, which are often incomplete and subject to misinformation, we have leveraged clinical practice guidelines and expertise from physicians at Moffitt Cancer Center to develop the MDP. Our study of developing such an MDP, leveraging domain knowledge, contributes to improving research on treatment path simulation for breast cancer patients.  © 2023 IEEE.","2-s2.0-85168665500"
"Lakshmi Narayanan K.; Karthik Ganesh R.; Bharathi S.T.; Srinivasan A.; Santhana Krishnan R.; Sundararajan S.","Lakshmi Narayanan, K. (55808540200); Karthik Ganesh, R. (39861677700); Bharathi, S.T. (58579484000); Srinivasan, A. (56727516100); Santhana Krishnan, R. (57868354800); Sundararajan, S. (57371180800)","55808540200; 39861677700; 58579484000; 56727516100; 57868354800; 57371180800","AI Enabled IoT based Intelligent Waste Water Management System for Municipal Waste Water Treatment Plant","2023","6th International Conference on Inventive Computation Technologies, ICICT 2023 - Proceedings","","","","361","365","4","10.1109/ICICT57646.2023.10134075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163510179&doi=10.1109%2fICICT57646.2023.10134075&partnerID=40&md5=73f9b671a46a0145f17f8b3651726c0c","Water is considered to be an essential part of human life, it is our individual responsibility to utilize the water with utmost care. Agriculture is considered to be an important factor in the growth of the economy which also depends upon the availability of water. Rainfall in today's scenario is unpredictable and uncertain as the monsoon rainfalls are irregular in recent days, this causes serious water scarcity and agriculture failure in most places. To overcome these problems, various technologies are adopted in the field of agriculture to make the irrigation system more effective. This research study adopts a novel Artificial Intelligence (AI) based system to properly manage the usage of water in Municipal Wastewater Treatment Plants with the help of the Internet of Things (IoT). This system runs on a central Atmega 328p Microcontroller connected with an ESP 8266 Wi-Fi on the chip. Various parameters of the water such as pH, conductivity, color, smell, and temperature are recorded in the cloud server, which is analyzed with an AI-based system to decide whether the water can be reused or it can be passed to the garden for irrigation. © 2023 IEEE.","2-s2.0-85163510179"
"Hofeditz L.; Mirbabaie M.; Ortmann M.","Hofeditz, Lennart (57217043574); Mirbabaie, Milad (56440203400); Ortmann, Mara (58768191500)","57217043574; 56440203400; 58768191500","Ethical Challenges for Human–Agent Interaction in Virtual Collaboration at Work","2023","International Journal of Human-Computer Interaction","","","","","","","10.1080/10447318.2023.2279400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179968888&doi=10.1080%2f10447318.2023.2279400&partnerID=40&md5=917f7b34e4eda10fecd9a29e0ba84223","In virtual collaboration at the workplace, a growing number of teams apply supportive conversational agents (CAs). They take on different work-related tasks for teams and single users such as scheduling meetings or stimulating creativity. Previous research merely focused on these positive aspects of introducing CAs at the workplace, omitting ethical challenges faced by teams using these often artificial intelligence (AI)-enabled technologies. Thus, on the one hand, CAs can present themselves as benevolent teammates, but on the other hand, they can collect user data, reduce worker autonomy, or foster social isolation by their service. In this work, we conducted 15 expert interviews with senior researchers from the fields of ethics, collaboration, and computer science in order to derive ethical guidelines for introducing CAs in virtual team collaboration. We derived 14 guidelines and seven research questions to pave the way for future research on the dark sides of human–agent interaction in organizations. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","2-s2.0-85179968888"
"Syrowatka A.; Bates D.W.","Syrowatka, Ania (37082071600); Bates, David W. (57113031900)","37082071600; 57113031900","Artificial intelligence in adverse drug events","2023","Artificial Intelligence in Clinical Practice: How AI Technologies Impact Medical Research and Clinics","","","","383","387","4","10.1016/B978-0-443-15688-5.00014-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176865220&doi=10.1016%2fB978-0-443-15688-5.00014-0&partnerID=40&md5=99592abc3484026c86034de519424338","The Institute of Medicine defined adverse drug events as injuries “resulting from medical intervention related to a drug”. These events are common in healthcare and there is substantial opportunity for improvement. This chapter describes artificial intelligence (AI)-based algorithms and tools that can be used to inform clinical decision-making for the prevention or mitigation of adverse drug events at the point of care. It covers three types of AI: rule-based models that are currently in use, and the next generation of more complex, modern machine learning and natural language processing-based tools that are under development and in testing. The application of modern AI is an emerging area and has the potential to substantially improve medication-related decision-making compared with rule-based tools. There are several challenges to address before widespread use and impact in real-world clinical settings can be realized. © 2024 Elsevier Inc. All rights reserved.","2-s2.0-85176865220"
"Yaman S.G.; Burholt C.; Jones M.; Calinescu R.; Cavalcanti A.","Yaman, Sinem Getir (58309013200); Burholt, Charlie (58308580800); Jones, Maddie (58308580900); Calinescu, Radu (6507842838); Cavalcanti, Ana (56265113000)","58309013200; 58308580800; 58308580900; 6507842838; 56265113000","Specification and Validation of Normative Rules for Autonomous Agents","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13991 LNCS","","","241","248","7","10.1007/978-3-031-30826-0_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161375694&doi=10.1007%2f978-3-031-30826-0_13&partnerID=40&md5=07c267c330bb0a2c82595a05fdd45855","A growing range of applications use autonomous agents such as AI and robotic systems to perform tasks deemed dangerous, tedious or costly for humans. To truly succeed with these tasks, the autonomous agents must perform them without violating the social, legal, ethical, empathetic, and cultural (SLEEC) norms of their users and operators. We introduce SLEECVAL, a tool for specification and validation of rules that reflect these SLEEC norms. Our tool supports the specification of SLEEC rules in a DSL [1] we co-defined with the help of ethicists, lawyers and stakeholders from health and social care, and uses the CSP refinement checker FDR4 to identify redundant and conflicting rules in a SLEEC specification. We illustrate the use of SLEECVAL for two case studies: an assistive dressing robot, and a firefighting drone. © 2023, The Author(s).","2-s2.0-85161375694"
"Laarhoven T.; Ponukumati A.","Laarhoven, Thijs (55293763300); Ponukumati, Aditya (58298112600)","55293763300; 58298112600","Towards Transparent Cheat Detection in Online Chess: An Application of Human and Computer Decision-Making Preferences","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13865 LNCS","","","163","180","17","10.1007/978-3-031-34017-8_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163378777&doi=10.1007%2f978-3-031-34017-8_14&partnerID=40&md5=115a03ac59e7321e03ecb81fbe17c813","Online game providers face the challenge of preventing malicious users (cheaters) from breaking the rules and winning games through illegal means. This issue in particular plagues the online chess scene, where the strongest algorithms have long surpassed the world’s best players [4] – any cheater can beat the best human players through computer assistance. Moreover, recent developments in AI-based chess engines have opened the door to even more human-like engines [33], which are increasingly able to mimic legitimate human players. Unfortunately, because major chess websites do not discuss their cheat detection mechanisms publicly, there is limited scientific literature on how to tackle the pervasive problem of cheating in online chess. Certainly, there is no way to validate whether these mechanisms actually work. We take a first step towards formalizing a proper cheat detection framework for online chess by leveraging a large-scale statistical examination of human and computer decision-making tendencies over millions of chess games played online. Although cheaters are not engines (computer players) but centaurs (computer-assisted human players), the insights into computer play serve as a useful guideline for finding the strongest indicators of cheating. We then demonstrate how these findings may distinguish legitimate human players from cheaters in an automated, rules-based manner. Additionally, we argue that the status quo of hiding cheat detection mechanisms from the public eye is dangerous to the integrity of the game, and that cheat detection is foremost a service to society instead of a competitive advantage for chess websites to attract more users. Consistent with Kerckhoffs’ paradigm [24], we believe that the benefits of an open discussion on cheat detection far outweigh the potential drawbacks of cheaters learning about these methods. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85163378777"
"Piro L.","Piro, Ludovica (57226114854)","57226114854","Conversational AI for Web Inclusivity: Technologies, Design Patterns and Development Toolkits","2023","CEUR Workshop Proceedings","3481","","","29","35","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172870199&partnerID=40&md5=503b0ef4f132cdddd5f9817468dd6fd1","Digital services can represent an important channel for granting access to knowledge, education, and work. Expecially to the citizens living with disabilities. However, as of now, the Web is conceived essentially for visual fruition and is inadequate for all those users living with permanent or situational impairments. Conversational AI is emerging as a technology apt for the development of inclusive and accessible applications, but there is still a lack of guidance specific to the design of inclusive Conversational AI systems. This research proposes to identify guidelines, interaction patterns, and enabling technology for a new paradigm for accessible conversational web browsing. © 2023 Copyright for this paper by its authors.","2-s2.0-85172870199"
"Lee J.; Myeong I.-S.; Kim Y.","Lee, Jonghyun (57250557900); Myeong, In-Soo (55958985400); Kim, Yun (57192988290)","57250557900; 55958985400; 57192988290","The Drug-Like Molecule Pre-Training Strategy for Drug Discovery","2023","IEEE Access","11","","","61680","61687","7","10.1109/ACCESS.2023.3285811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162644701&doi=10.1109%2fACCESS.2023.3285811&partnerID=40&md5=5cd53ca242692b6c3de8698273ab37dc","Recent advances in artificial intelligence (AI) have led to the development of transformer-based models that have shown success in identifying potential drug molecules for therapeutic purposes. However, for a molecule to be considered a viable drug candidate, it must exhibit certain desirable properties such as low toxicity, high druggability, and synthesizability. To address this, we propose an approach that incorporates prior knowledge about these properties during the model training process. In this study, we utilized the PubChem database, which contains 100 million molecules, to filter drug-like molecules based on the quantity of drug-likeliness (QED) score and the Pfizer rule. We then used this filtered dataset of drug-like molecules to train both molecular representation (ChemBERTa) and molecular generation models (MolGPT). To assess the performance of the molecular representation model, we fine-tuned the results on the MoleculeNet benchmark datasets. Meanwhile, we evaluated the performance of the molecular generation model based on the generated samples comprising 10,000 molecules. Despite the limited diversity of the pre-training dataset, the models for molecular representation were able to retain at least 90% of their original performance on benchmark datasets, with an additional improvement of 6% in predicting clinical toxicology. In the domain of molecular generation, the model pre-trained on drug-like molecules exhibited a high rate of desirable molecule properties in the unconditionally generated outputs. Additionally, the diversity of generated structures demonstrated notable performance compared to the conditional generation approach. Moreover, the drug-like molecule pre-training strategy is not limited to a specific model or training method, making it a flexible approach that can be easily modified based on the research interests and criteria of interest.  © 2013 IEEE.","2-s2.0-85162644701"
"Desai S.Y.; Kore S.L.","Desai, Sharada Y. (58623925700); Kore, Sharada L. (36069273500)","58623925700; 36069273500","The Current State of Art-Indian Unleavened Flat Bread Cooking","2023","Lecture Notes in Networks and Systems","720 LNNS","","","1","9","8","10.1007/978-981-99-3761-5_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172720480&doi=10.1007%2f978-981-99-3761-5_1&partnerID=40&md5=53f0f6ea79a66bfee39ee33f72c3917d","New methods of food production and technical food processing are now possible. Thanks to contemporary advancements in the food sector. Studies on the standardization of conditions for making dough with wheat flour, wheat flour size of particle, and wheat flour variations were conducted with the goal of producing a consistent procedure for baking the unleavened flat bread known as chapati, a traditional Indian dish. Water needed to make chapati dough, dough thickness, rolling qualities, chapati thickness, baking time and temperature, and chapati puffing conditions were all factors taken into account. This paper summarizes current research on the aforementioned chapati making parameters. It provides guidelines for future work on computer vision and AI based chapati production. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85172720480"
"Schwarz B.; Schrills T.; Franke T.","Schwarz, Benjamin (58745949600); Schrills, Tim (57218269411); Franke, Thomas (56652374700)","58745949600; 57218269411; 56652374700","Experiencing Ethics and Values in the Design Process of AI-Enabled Medical Devices and Software","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14059 LNCS","","","232","250","18","10.1007/978-3-031-48057-7_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178645423&doi=10.1007%2f978-3-031-48057-7_15&partnerID=40&md5=770e821c283bd6a6e02733f108c9c8c2","The interaction design of medical devices has to engage and cater to the needs of a wide range of stakeholders, from patients to physicians. The present paper aims to show by example the methodological integration of critical reflection on ethics and values during the design process of AI-enabled tools. The question of how to promote awareness of ethical responsibilities in the context of AI in medical devices is raised, and the use of core frameworks for ethical and value-based design as well as reflexive practice are being evaluated. To this end we conducted multiple empirical studies based on multiple university research projects, including joint research with healthcare industry partners, connecting the fields of medicine, engineering psychology, media informatics, and design research. We present a questionnaire-based self-reflection tool—VaPeMeT—designed to encourage ethical reflection and use of frameworks across project phases and team members. Our studies combine qualitative and quantitative research in order to 1) connect reported participant actions with theoretical considerations from value-based design and 2) evaluate the completeness and usefulness of the VaPeMeT questionnaire. By conceptualizing process design implications and suggesting a questionnaire-based self-reflection tool, our research aims to contribute to integrated, actionable and responsible transdisciplinary cooperation in this sensitive context. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85178645423"
"Bhati D.; Guercio A.; Rossano V.; Francese R.","Bhati, Deepshikha (57552724000); Guercio, Angela (6603877464); Rossano, Veronica (12753684700); Francese, Rita (6602289285)","57552724000; 6603877464; 12753684700; 6602289285","BookMate: Leveraging Deep Learning to Empower Caregivers of People with ASD in Generation of Social Stories","2023","Proceedings of the International Conference on Information Visualisation","","","","403","408","5","10.1109/IV60283.2023.00074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178516521&doi=10.1109%2fIV60283.2023.00074&partnerID=40&md5=b7d3664aa10a146bd4cfb75b3a30c9cd","People with Autism Spectrum Disorder (ASD) have difficulties in social communication and interaction. Their caregivers help them in overcoming these challenges. Social stories are tools largely adopted to improve the interaction and communication capabilities of people with ASD. The creation of a social story is not an easy task. Several guidelines have been defined to build them. In this paper, we propose an interactive mobile application aimed at empowering caregivers of people with ASD in generating social stories. The application integrates AI processing and AI-based audio transcription for story generation, effective audio data extraction, and data processing. The stories are presented in a slide-show format to the learner in different modalities according to the learner's capabilities. A preliminary usability study of the application has been performed and the first results are encouraging. © 2023 IEEE.","2-s2.0-85178516521"
"Vietas J.","Vietas, Jay (58308312900)","58308312900","Artificial intelligence and global health","2023","Artificial Intelligence in Clinical Practice: How AI Technologies Impact Medical Research and Clinics","","","","395","399","4","10.1016/B978-0-443-15688-5.00034-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176848878&doi=10.1016%2fB978-0-443-15688-5.00034-6&partnerID=40&md5=99531c5ce3915d297cd1b90d69316e75","The use of modern machine learning and natural language processing is an emerging area in the prevention and detection of adverse drug events at the point of care, which has the potential to substantially improve medication-related decision-making compared with rule-based tools. This chapter focuses on AI-based algorithms and tools that can be used to inform clinical decision-making for prevention or early detection of adverse drug events at the point of care. This overview addresses three types of AI: rule-based models which are currently used in practice; the next generation of more complex, modern machine learning; and natural language processing-based tools that are under development and in testing. Examples are given of the current rules-based systems that are widely used to support medication-related decision-making are summarized; these use clinical guidelines, patient-specific information such as comorbidities or genomic profiles, and known contraindications from pharmacological databases. The next generation of AI tools that use Machine Learning and Natural Language Processing (NLP) to inform medication-related decision-making are reviewed and there is a brief introduction of the currently limited scope of NLP being applied to extract information from free-text clinical notes in the electronic health record. The current challenges that are limiting the implementation of AI within this field are identified and suggestions for the future direction of AI that will affect clinical decision-making and patient outcomes are given. © 2024 Elsevier Inc. All rights reserved.","2-s2.0-85176848878"
"Virvou M.","Virvou, Maria (7003569675)","7003569675","Artificial Intelligence and User Experience in reciprocity: Contributions and state of the art","2023","Intelligent Decision Technologies","17","1","","73","125","52","10.3233/IDT-230092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161272994&doi=10.3233%2fIDT-230092&partnerID=40&md5=6d04ce74f3266b823c2a6e7a7f91efc6","Among the primary aims of Artificial Intelligence (AI) is the enhancement of User Experience (UX) by providing deep understanding, profound empathy, tailored assistance, useful recommendations, and natural communication with human interactants while they are achieving their goals through computer use. To this end, AI is used in varying techniques to automate sophisticated functions in UX and thereby changing what UX is apprehended by the users. This is achieved through the development of intelligent interactive systems such as virtual assistants, recommender systems, and intelligent tutoring systems. The changes are well received, as technological achievements but create new challenges of trust, explainability and usability to humans, which in turn need to be amended by further advancements of AI in reciprocity. AI can be utilised to enhance the UX of a system while the quality of the UX can influence the effectiveness of AI. The state of the art in AI for UX is constantly evolving, with a growing focus on designing transparent, explainable, and fair AI systems that prioritise user control and autonomy, protect user data privacy and security, and promote diversity and inclusivity in the design process. Staying up to date with the latest advancements and best practices in this field is crucial. This paper conducts a critical analysis of published academic works and research studies related to AI and UX, exploring their interrelationship and the cause-effect cycle between the two. Ultimately, best practices for achieving a successful interrelationship of AI in UX are identified and listed based on established methods or techniques that have been proven to be effective in previous research reviewed.  © 2023 - The authors. Published by IOS Press.","2-s2.0-85161272994"
"Dikopoulou Z.; Lavasa E.; Perez-Castanos S.; Monzo D.; Moustakidis S.","Dikopoulou, Zoumpolia (55967851400); Lavasa, Eleni (57225080551); Perez-Castanos, Sergi (57224136376); Monzo, David (58787315100); Moustakidis, Serafeim (23969428400)","55967851400; 57225080551; 57224136376; 58787315100; 23969428400","Towards Explainable AI Validation in Industry 4.0: A Fuzzy Cognitive Map-based Evaluation Framework for Assessing Business Value","2023","Proceedings of the 29th International Conference on Engineering, Technology, and Innovation: Shaping the Future, ICE 2023","","","","","","","10.1109/ICE/ITMC58018.2023.10332301","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181130067&doi=10.1109%2fICE%2fITMC58018.2023.10332301&partnerID=40&md5=5981cdb9fba42ab0e57140302c947b9b","The development of Artificial Intelligence (AI) systems in Industry 4.0 has gained momentum due to their potential for increasing efficiency and productivity. However, AI systems can be just as complex and opaque, leading to concerns about their reliability, trustworthiness, and accountability. To address these issues, this paper proposes a validation framework for Explainable AI (XAI) in Industry 4.0 based on Fuzzy Cognitive Maps (FCMs). The proposed framework aims to evaluate Key Performance Indicators (KPIs) based on a set of AI metrics and XAI metrics. The FCM-based approach enables the representation of causal-effect relationships between the different concepts of the system using expert knowledge. The presented validation framework provides a theoretical background for evaluating and optimizing the business values of AI systems based on multiple criteria in the manufacturing industry, demonstrating its effectiveness. The main contributions of this paper are: i) the development of an FCM-based validation framework for XAI in Industry 4.0; ii) the identification of relevant AI and XAI metrics for the evaluation of the KPIs of the theoretical graph model; and iii) the demonstration of the effectiveness of the proposed framework through a case study. The results of this study provide valuable insights into the importance of considering not only accuracy but also efficiency and transparency when developing AI pipelines that generate higher business value. Overall, this paper offers a theoretical foundation and practical insights for organizations seeking to evaluate the business values of their AI systems in Industry 4.0. It emphasizes the importance of explainability and the integration of AI and XAI metrics in achieving transparent and accountable AI solutions that deliver optimal results for the manufacturing industry and beyond.  © 2023 IEEE.","2-s2.0-85181130067"
"Kautonen H.; Gasparini A.","Kautonen, Heli (55811137100); Gasparini, Andrea (55484484900)","55811137100; 55484484900","Research Libraries Approaching Trustworthy Artificial Intelligence","2023","CEUR Workshop Proceedings","3582","","","104","113","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180006338&partnerID=40&md5=0e747a793ca5e2ad22e0f8fc61d0b8b6","Recent advances in artificial intelligence (AI) applications have raised concerns about the consequences of the uncontrolled development of AI technology for society and humans. Information and knowledge professionals working in research libraries are in professions that have long existed and have globally applied ethical codes that serve as self-regulatory ethical norms. New AI technologies that penetrate throughout libraries’ operations cause confusion among librarians and challenge the existing ethics. In this paper, we examine these challenges and present a qualitative study that reveals the ethical considerations that research librarians face when they approach new AI technologies. As there are no established AI ethics norms for research librarians, we compared the international code of conduct for libraries against the European AI guidelines to identify relevant themes for our study. We analyzed the data from two Scandinavian workshops for librarians. Our findings highlight the central role of research libraries in making AI-powered research ethical. Our study also indicates a need to update international codes of conduct for libraries for the AI age by including aspects of AI agency and the interests of future generations. This helps librarians better orient themselves and their patrons towards a trustworthy and existentially sustainable future with AI systems. © 2023 Copyright for this paper by its authors.","2-s2.0-85180006338"
"Godoy B. de Oliveira C.; de Paula Albuquerque O.; Liene Belotti E.; Ferreira Lopes I.; Brandão de A. Silva R.; Arbix G.","Godoy B. de Oliveira, Cristina (58682980100); de Paula Albuquerque, Otávio (57212554105); Liene Belotti, Emily (58682295300); Ferreira Lopes, Isabella (58682521600); Brandão de A. Silva, Rodrigo (58682748500); Arbix, Glauco (7801423118)","58682980100; 57212554105; 58682295300; 58682521600; 58682748500; 7801423118","Regulation and Ethics of Facial Recognition Systems: An Analysis of Cases in the Court of Appeal in the State of São Paulo","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14195 LNAI","","","18","32","14","10.1007/978-3-031-45368-7_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175789467&doi=10.1007%2f978-3-031-45368-7_2&partnerID=40&md5=2289f48cb2e44cda3e19b0e7504f3895","Context: The use of Artificial Intelligence (AI) in various sectors of the economy is already a reality in Brazil. Consequently, since 2019, the number of cases in the Judiciary involving AI has increased. Cases involving facial recognition systems (FRS) for contracting bank credit are increasing annually, so it is necessary to analyze how the Judiciary handles the issues. Problem: Why is the São Paulo Court of Appeal ruling in favor of banks in all cases involving taking out credit through facial recognition technology? Methodology and Methods: Data were collected and processed using automated computer programs. The qualitative analysis used the analytical, comparative and monographic methods. Results: The Court of Appeal of São Paulo considers it difficult to deceive an AI system, therefore, the burden of proof is on the author, even if there is a consumer relationship. That is, the decisions are contrary to the general rule of the Code of Consumer Protection in Brazil, which consists of reversing the burden of proof in consumer relations when one of the parties is underprivileged. Contributions and Solutions: The research points to the path of jurisprudence in cases involving the contracting of credit through FRS, and the Judiciary is deciding against the bank’s customers, dispensing with the production of evidence by the banking sector. Therefore, it is necessary to alert the National Council of Justice and the Central Bank regarding this situation so that it is disciplined adequately since the FRS is fallible and does not guarantee the absence of fraud. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","2-s2.0-85175789467"
"Gezici G.; Mannari C.; Orlandi L.","Gezici, Gizem (36166866400); Mannari, Chiara (57906960700); Orlandi, Lorenzo (57203802519)","36166866400; 57906960700; 57203802519","The Ethical Impact Assessment of Selling Life Insurance to Titanic Passengers","2023","CEUR Workshop Proceedings","3456","","","35","50","15","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171160340&partnerID=40&md5=f2a165d4d28f27a970bee140d582e36b","The Artificial Intelligence Act (AIA) is a uniform legal framework to ensure that AI systems within the European Union (EU) are safe and comply with existing law on fundamental rights and constitutional values. The AIA adopts a risk-based approach with the aim of intending to regulate AI systems, especially categorised as high-risk, which have significant harmful impacts on the health, safety and fundamental rights of persons in the Union. The AIA is founded on the Ethics Guidelines of the High-Level Expert Group for Trustworthy AI, which are grounded in fundamental rights and reflect four ethical imperatives in order to ensure ethical and robust AI. While we acknowledge that ethics is not law, we advocate that the analysis of ethical risks can assist us in complying with laws, thereby facilitating the implementation of the AIA requirements. Thus, we first design an AI-driven Decision Support System for individual risk prediction in the insurance domain (categorised as high-risk by the AIA) based on the Titanic case, which is a popular benchmark dataset in machine learning. We then fulfill an ethical impact assessment of the Titanic case study, relying on the four ethical imperatives of respect for human autonomy, prevention of harm, fairness, and explicability, declared by the High-Level Expert Group for Trustworthy AI. In the context of this ethical impact assessment, we also refer to the questions in the ALTAI checklist. Our discussions regarding the ethical impact assessment in the insurance domain demonstrate that ethical principles can intersect but also create tensions (intriguingly, only in this particular context), for which there is no definitive solution. When tensions arise, which may result in unavoidable trade-offs, these trade-offs should be addressed in a rational and methodical manner, paying special attention to the context of the current case study being evaluated. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85171160340"
"Razzhigaev A.; Salnikov M.; Malykh V.; Braslavski P.; Panchenko A.","Razzhigaev, Anton (57219788402); Salnikov, Mikhail (57219694535); Malykh, Valentin (57190971630); Braslavski, Pavel (16548847400); Panchenko, Alexander (55632785700)","57219788402; 57219694535; 57190971630; 16548847400; 55632785700","A System for answering simple questions in multiple languages","2023","Proceedings of the Annual Meeting of the Association for Computational Linguistics","3","","","524","537","13","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173528312&partnerID=40&md5=2ace2d7f648be3faff80eaec92b4b521","Our research focuses on the most prevalent type of queries-simple questions-exemplified by questions like ""What is the capital of France-"". These questions reference an entity such as ""France"", which is directly connected (one hop) to the answer entity ""Paris"" in the underlying knowledge graph (KG). We propose a multilingual Knowledge Graph Question Answering (KGQA) technique that orders potential responses based on the distance between the question s text embeddings and the answer s graph embeddings. A system incorporating this novel method is also described in our work. Through comprehensive experimentation using various English and multilingual datasets and two KGs-Freebase andWikidata-we illustrate the comparative advantage of the proposed method across diverse KG embeddings and languages. This edge is apparent even against robust baseline systems, including seq2seq QA models, search-based solutions and intricate rule-based pipelines. Interestingly, our research underscores that even advanced AI systems like ChatGPT encounter difficulties when tasked with answering simple questions. This finding emphasizes the relevance and effectiveness of our approach, which consistently outperforms such systems. We are making the source code and trained models from our study publicly accessible to promote further advancements in multilingual KGQA. © ACL-DEMO 2023. All rights reserved.","2-s2.0-85173528312"
"Alshehhi K.; Cheaitou A.; Rashid H.","Alshehhi, Khalid (58786017900); Cheaitou, Ali (25026693900); Rashid, Hamad (57189290489)","58786017900; 25026693900; 57189290489","Fuzzy Failure Modes Effect and Criticality Analysis of the Procurement Process of Artificial Intelligent Systems/Services","2023","International Journal of Advanced Computer Science and Applications","14","10","","562","570","8","10.14569/IJACSA.2023.0141060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180974967&doi=10.14569%2fIJACSA.2023.0141060&partnerID=40&md5=ebddc5450b106d05e2b9082d758c7b98","This study focuses on the ranking of risks associated with the procurement of Artificial Intelligent (AI) systems/services for UAE public Sectors. Considering the involvement of human-based reasoning, this study proposes to use Fuzzy Failure Mode Effect and Criticality Analysis (FMECA). The risks were identified from the literature and subsequently, using 40 interviews with practitioners, the final list is developed on the basis of the presence of risks in the AI procurement process. For Fuzzy FMECA, the input data is collected from fifteen experts. The values of Severity (S), and Detection (D) for each risk element are averaged to use as input. If-Then rule-based fuzzy inference system is employed to obtain the Fuzzy Risk Priority Numbers of risk elements. The traditional RPN and Fuzzy RPN numbers are compared and it is found that fuzzy RPN gives a realistic picture of the ranking of risks. Privacy and security risks, Integration Risks, Risk of Malfunction of systems/services, and Ethical risks are found to be high priorities. This study provides valuable insight to policymakers to develop strategies to mitigate these risks for smooth procurement and implementation of AI-related Projects. © (2023), (Science and Information Organization). All Rights Reserved.","2-s2.0-85180974967"
"Giordano G.; Annunziata G.; De Lucia A.; Palomba F.","Giordano, Giammaria (57843134600); Annunziata, Giusy (58627077000); De Lucia, Andrea (7003641564); Palomba, Fabio (55321369000)","57843134600; 58627077000; 7003641564; 55321369000","Understanding developer practices and code smells diffusion in ai-enabled software: A preliminary study","2023","CEUR Workshop Proceedings","3543","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177040669&partnerID=40&md5=7eca06300ad083258f32aa3843fad742","To deal with continuous change requests and the strict time-To-market, practitioners and big companies constantly update their software systems to meet users requirements. This practice force developers to release immature products, neglecting best practices to reduce delivery times. As a possible result, technical debt can arise, i.e., potential design issues that can negatively impact software maintenance and evolution and, in turn, increase both the time-To-market and costs. Code smells-sub-optimal design decisions identifiable by computing software metrics and providing a general overview of code quality-Are common symptoms of technical debt. While previous research focused on code smells primarily considering them in the context of Java, the growing popularity of Python, particularly for developing artificial intelligence (AI)-Enabled systems, calls for additional investigations. This preliminary analysis addresses this gap by exploring the diffusion of Python-specific code smells, and the activities performed by developers that induce the introduction of code smells in their systems. To perform our preliminary investigation, we selected 200 AI-Enabled systems available in the Niche dataset; We extracted 10,611 information on the releases using PyDriller, and PySmell to extract information about code smells. The results reveal several insights: 1) Code smells related to object-oriented principles are rarely detected in Python; 2) Complex List Comprehension is the most prevalent and the most long-Alive smell; 3) The main activities that can induce code smells are evolutionary. This study fills a critical gap in the literature by providing empirical evidence on the evolution of code smells in Python-based AI-enabled systems. © 2021 Copyright for this paper by its authors.","2-s2.0-85177040669"
"Xu Y.; Collenette J.; Dennis L.; Dixon C.","Xu, Yifan (58606650500); Collenette, Joe (57190131122); Dennis, Louise (7005190026); Dixon, Clare (7101860491)","58606650500; 57190131122; 7005190026; 7101860491","Dialogue Explanations for Rule-Based AI Systems","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14127 LNAI","","","59","77","18","10.1007/978-3-031-40878-6_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172226429&doi=10.1007%2f978-3-031-40878-6_4&partnerID=40&md5=323a3bed489535d65b884f39b2ad2c35","The need for AI systems to explain themselves is increasingly recognised as a priority, particularly in domains where incorrect decisions can result in harm and, in the worst cases, death. Explainable Artificial Intelligence (XAI) tries to produce human-understandable explanations for AI decisions. However, most XAI systems prioritize factors such as technical complexities and research-oriented goals over end-user needs, risking information overload. This research attempts to bridge a gap in current understanding and provide insights for assisting users in comprehending the rule-based system’s reasoning through dialogue. The hypothesis is that employing dialogue as a mechanism can be effective in constructing explanations. A dialogue framework for rule-based AI systems is presented, allowing the system to explain its decisions by engaging in “Why?” and “Why not?” questions and answers. We establish formal properties of this framework and present a small user study with encouraging results that compares dialogue-based explanations with proof trees produced by the AI System. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85172226429"
"Sabarish G.; Maria N.A.; Shanthini M.K.; Mayurappriyan P.S.; Ganesh C.; Shanmugasundaram R.","Sabarish, G. (58792725800); Maria, Nivetha A (58547368900); Shanthini, M.K. (58537977800); Mayurappriyan, P.S. (25929373100); Ganesh, C. (56503518500); Shanmugasundaram, R. (56464912500)","58792725800; 58547368900; 58537977800; 25929373100; 56503518500; 56464912500","An Energy Management Strategy in Hybrid Electric Vehicles: The Present and The Future Scenario","2023","2nd International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation, ICAECA 2023","","","","","","","10.1109/ICAECA56562.2023.10200140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168656898&doi=10.1109%2fICAECA56562.2023.10200140&partnerID=40&md5=276c13bea57c7d687adec1752e7128d7","There has been a significant increase in interest towards ""The electrification of transportation""in the past decade. The environmental crisis caused due to global warming and the depletion of oil supplies are factors that have made the automobile sector adopt strategies to produce eco-friendly, sustainable vehicles instead of their commercial fuel propelled vehicles. Most governments have expressed their interest in alleviating the environmental impact caused due to vehicle pollution by introducing various policies that eventually help people switch to Electric Vehicles (EV). Though there has been a surge of interest among people to adopt environmentally friendly, economically affordable electric vehicles, the major concern is the state of charge and range offered by these EVs. The global automobile sector has started to invest in research dedicated to the energy management system in EVs to overcome these issues. The emergence of artificial intelligence (AI) and the advancement of control systems are clear signs for developing smart-energy management systems in EV. This paper reviews the methods of energy storage and usage in EV following the various Energy Management Systems (EMS) present in EV such as Rule-based EMS and Optimization-based EMS and its types. Also, it gives an insight into the emergence of futuristic AI-based chips that would revolutionize the energy-management system in E-vehicles. © 2023 IEEE.","2-s2.0-85168656898"
"Morais F.L.D.; Garcia A.C.B.; Dos Santos P.S.M.; Ribeiro L.A.P.A.","Morais, Fábio Luiz D. (58486450600); Garcia, Ana Cristina B. (25723096500); Dos Santos, Paulo Sérgio M. (24328396100); Ribeiro, Luiz Alberto P. A. (57224526423)","58486450600; 25723096500; 24328396100; 57224526423","Do Explainable AI techniques effectively explain their rationale? A case study from the domain expert's perspective","2023","Proceedings of the 2023 26th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2023","","","","1569","1574","5","10.1109/CSCWD57460.2023.10152722","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164676219&doi=10.1109%2fCSCWD57460.2023.10152722&partnerID=40&md5=cd1c95c2b4dad94d1e0aeebf71d54bd6","Artificial Intelligence (AI) systems are technologies impacting our lives. The systems learn from existing datasets that record past human decisions. Their performance is measured in terms of accuracy, precision, and recall for reproducing already-known results. Understanding the system's rationale is crucial to check for bias and accept such technology. Explainable AI (XAI) is the area devoted to opening the AI black box, and designing guidelines to build explainable AI systems. Nevertheless, it is important to understand the user's needs for these explanations. This paper presents an investigation of the usefulness of XAI systems in the field of cancer diagnosis from the domain expert's (oncologist) perspective. The main findings suggest domain experts (1) understood the outcomes of the XAI systems; (2) considered XAI outcomes as informative, rather than explanatory; (3) would like to go beyond the fixed presented perspective; and (4) missed the causal relation that would reveal the system's rationale.  © 2023 IEEE.","2-s2.0-85164676219"
"Oberste L.; Rüffer F.; Aydingül O.; Rink J.; Heinzl A.","Oberste, Luis (57224832897); Rüffer, Florian (58304924700); Aydingül, Okan (57191158028); Rink, Johann (57222315500); Heinzl, Armin (6603170209)","57224832897; 58304924700; 57191158028; 57222315500; 6603170209","Designing User-Centric Explanations for Medical Imaging with Informed Machine Learning","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13873 LNCS","","","470","484","14","10.1007/978-3-031-32808-4_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161230356&doi=10.1007%2f978-3-031-32808-4_29&partnerID=40&md5=002adf140563fc1e96e36e0c72dc2d9d","A flawed algorithm released in clinical practice can cause unintended harm to patient health. Risks, regulation, responsibility, and ethics shape the demand of clinical users to understand and rely on the outputs made by artificial intelligence. Explainable artificial intelligence (XAI) offers methods to render a model’s behavior understandable from different perspectives. Extant XAI, however, is mainly data-driven and designed to meet developers’ demands to correct models rather than clinical users’ expectations to reflect clinically relevant information. To this end, informed machine learning (IML) utilizes prior knowledge jointly with data to generate predictions, a promising paradigm to enrich XAI with medical knowledge. To explore how IML can be used to generate explanations that are congruent to clinical users’ demands and useful to medical decision-making, we conduct Action Design Research (ADR) in collaboration with a team of radiologists. We propose an IML-based XAI system for clinically relevant explanations of diagnostic imaging predictions. With the help of ADR, we reduce the gap between implementation and user evaluation and demonstrate the effectiveness of the system in a real-world application with clinicians. While we develop design principles of using IML for user-centric XAI in diagnostic imaging, the study demonstrates that an IML-based design adequately reflects clinicians’ conceptions. In this way, IML inspires greater understandability and trustworthiness of AI-enabled diagnostic imaging. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85161230356"
"Sawilla I.; Weber C.; Schmidt B.; Ulrich M.","Sawilla, Ingo (57893509000); Weber, Christian (57893992000); Schmidt, Benedikt (35068523300); Ulrich, Marco (37073527000)","57893509000; 57893992000; 35068523300; 37073527000","Industrielle herausforderungen für KI systems engineering Entwicklungen hin zu autonomen Systemen in der Industrie; [Industrial challenges for AI systems engineering Towards autonomous industrial systems]","2022","At-Automatisierungstechnik","70","9","","805","814","9","10.1515/auto-2022-0015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138171250&doi=10.1515%2fauto-2022-0015&partnerID=40&md5=637d36cdd7c0b1a6b740e4318ea8eac7","Integration of Artificial Intelligence (AI) methods into industrial systems engineering processes is challenging. Despite an increasing body of knowledge on AI techniques and impressive state-of-the-art reports, the application of AI in industrial contexts is only at an early stage. This paper summarizes challenges for AI Systems Engineering. Two examples of AI systems engineering are provided: the TRUMPF Sorting Guide and ABB BatchInsight. Summaries of the projects give insights into the project executions and related challenges. The learnings from these projects also show that increased maturity of AI systems engineering can be expected from increased method competence and adjusted project setups. Here guidelines and best practices for AI systems engineering can support.  © 2022 Walter de Gruyter GmbH, Berlin/Boston.","2-s2.0-85138171250"
"Steinke G.; Labrie R.; Sarkar S.","Steinke, Gerhard (7004045062); Labrie, Ryan (56110774200); Sarkar, Satadipa (57827962200)","7004045062; 56110774200; 57827962200","Recommendation for Continuous Ethical Analysis of AI Algorithms","2022","ACM International Conference Proceeding Series","","","","104","106","2","10.1145/3528580.3532996","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135312739&doi=10.1145%2f3528580.3532996&partnerID=40&md5=d63c8763d25e7128bdaa97a5add280ca","Artificial Intelligence (AI) algorithms and applications have become more prevalent in our information society. Organizations that build AI applications incorporate various ethical evaluation frameworks, policies, and guidelines-and yet the outcome of many AI systems are producing questionable, biased, unfair, opaque, unjustified, and/or unexplained results. In this research project we determine the necessity for not just an initial ethical review of such algorithms, but suggest the ongoing ethical evaluation of AI algorithms as applications are updated and enhanced-a Continuous Ethical Analysis process.  © 2022 Owner/Author.","2-s2.0-85135312739"
"Loh H.W.; Ooi C.P.; Seoni S.; Barua P.D.; Molinari F.; Acharya U.R.","Loh, Hui Wen (57220933535); Ooi, Chui Ping (55663773200); Seoni, Silvia (57213608081); Barua, Prabal Datta (36993665100); Molinari, Filippo (7004289592); Acharya, U Rajendra (7004510847)","57220933535; 55663773200; 57213608081; 36993665100; 7004289592; 7004510847","Application of explainable artificial intelligence for healthcare: A systematic review of the last decade (2011–2022)","2022","Computer Methods and Programs in Biomedicine","226","","107161","","","","10.1016/j.cmpb.2022.107161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139596030&doi=10.1016%2fj.cmpb.2022.107161&partnerID=40&md5=b58be41e5d7b4209828ff3915e5921e6","Background and objectives: Artificial intelligence (AI) has branched out to various applications in healthcare, such as health services management, predictive medicine, clinical decision-making, and patient data and diagnostics. Although AI models have achieved human-like performance, their use is still limited because they are seen as a black box. This lack of trust remains the main reason for their low use in practice, especially in healthcare. Hence, explainable artificial intelligence (XAI) has been introduced as a technique that can provide confidence in the model's prediction by explaining how the prediction is derived, thereby encouraging the use of AI systems in healthcare. The primary goal of this review is to provide areas of healthcare that require more attention from the XAI research community. Methods: Multiple journal databases were thoroughly searched using PRISMA guidelines 2020. Studies that do not appear in Q1 journals, which are highly credible, were excluded. Results: In this review, we surveyed 99 Q1 articles covering the following XAI techniques: SHAP, LIME, GradCAM, LRP, Fuzzy classifier, EBM, CBR, rule-based systems, and others. Conclusion: We discovered that detecting abnormalities in 1D biosignals and identifying key text in clinical notes are areas that require more attention from the XAI research community. We hope this is review will encourage the development of a holistic cloud system for a smart city. © 2022 Elsevier B.V.","2-s2.0-85139596030"
"Islam C.; Babar M.A.; Croft R.; Janicke H.","Islam, Chadni (57208753315); Babar, M. Ali (6602842620); Croft, Roland (57219534056); Janicke, Helge (14028408400)","57208753315; 6602842620; 57219534056; 14028408400","SmartValidator: A framework for automatic identification and classification of cyber threat data","2022","Journal of Network and Computer Applications","202","","103370","","","","10.1016/j.jnca.2022.103370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127644255&doi=10.1016%2fj.jnca.2022.103370&partnerID=40&md5=cfcad9b93e73bce41ca34d4b0cb697ad","A wide variety of Cyber Threat Information (CTI) is used by Security Operation Centres (SOCs) to perform validation of security incidents and alerts. Security experts manually define different types of rules and scripts based on CTI to perform validation tasks. These rules and scripts need to be updated continuously due to evolving threats, changing SOCs’ requirements and dynamic nature of CTI. The manual process of updating rules and scripts delays the response to attacks. To reduce the burden of human experts and accelerate response, we propose a novel Artificial Intelligence (AI) based framework, SmartValidator. SmartValidator leverages Machine Learning (ML) techniques to enable automated validation of alerts. It consists of three layers to perform the tasks of data collection, model building and alert validation. It projects the validation task as a classification problem. Instead of building and saving models for all possible requirements, we propose to automatically construct the validation models based on SOC's requirements and CTI. We built a Proof of Concept (PoC) system with eight ML algorithms, two feature engineering techniques and 18 requirements to investigate the effectiveness and efficiency of SmartValidator. The evaluation results showed that when prediction models were built automatically for classifying cyber threat data, the F1-score of 75% of the models were above 0.8, which indicates adequate performance of the PoC for use in a real-world organization. The results further showed that dynamic construction of prediction models required 99% less models to be built than pre-building models for all possible requirements. Thus, SmartValidator is much more efficient to use when SOCs’ requirements and threat behaviour are constantly evolving. The framework can be followed by various industries to accelerate and automate the validation of alerts and incidents based on their CTI and SOC's preferences. © 2022 Elsevier Ltd","2-s2.0-85127644255"
"Deiva Ganesh A.; Kalpana P.","Deiva Ganesh, A. (57668493900); Kalpana, P. (57224479487)","57668493900; 57224479487","Supply chain risk identification: a real-time data-mining approach","2022","Industrial Management and Data Systems","122","5","","1333","1354","21","10.1108/IMDS-11-2021-0719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129501941&doi=10.1108%2fIMDS-11-2021-0719&partnerID=40&md5=e6feb57444008920ab7b8aa1a9c7aeb9","Purpose: The global pandemic COVID-19 unveils transforming the supply chain (SC) to be more resilient against unprecedented events. Identifying and assessing these risk factors is the most significant phase in supply chain risk management (SCRM). The earlier risk quantification methods make timely decision-making more complex due to their inability to provide early warning. The paper aims to propose a model for analyzing the social media data to understand the potential SC risk factors in real-time. Design/methodology/approach: In this paper, the potential of text-mining, one of the most popular Artificial Intelligence (AI)-based data analytics approaches for extracting information from social media is exploited. The model retrieves the information using Twitter streaming API from online SC forums. Findings: The potential risk factors that disrupt SC performance are obtained from the recent data by text-mining analyses. The outcomes carry valuable insights about some contemporary SC issues due to the pandemic during the year 2021. The most frequent risk factors using rule mining techniques are also analyzed. Originality/value: This study presents the significant role of Twitter in real-time risk identification from online SC platforms like “Supply Chain Dive”, “Supply Chain Brain” and “Supply Chain Digest”. The results indicate the significant role of data analytics in achieving accurate decision-making. Future research will extend to represent a digital twin for identifying potential risks through social media analytics, assessing risk propagation and obtaining mitigation strategies. © 2022, Emerald Publishing Limited.","2-s2.0-85129501941"
"Ibáñez J.C.; Olmeda M.V.","Ibáñez, Javier Camacho (57218222521); Olmeda, Mónica Villas (57240156400)","57218222521; 57240156400","Operationalising AI ethics: how are companies bridging the gap between practice and principles? An exploratory study","2022","AI and Society","37","4","","1663","1687","24","10.1007/s00146-021-01267-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113948828&doi=10.1007%2fs00146-021-01267-0&partnerID=40&md5=3b0181103ccfd3931591d8d20a7628bc","Despite the increase in the research field of ethics in artificial intelligence, most efforts have focused on the debate about principles and guidelines for responsible AI, but not enough attention has been given to the “how” of applied ethics. This paper aims to advance the research exploring the gap between practice and principles in AI ethics by identifying how companies are applying those guidelines and principles in practice. Through a qualitative methodology based on 22 semi-structured interviews and two focus groups, the goal of the current study is to understand how companies approach ethical issues related to AI systems. A structured analysis of the transcripts brought out many actual practices and findings, which are presented around the following main research topics: ethics and principles, privacy, explainability, and fairness. The interviewees also raised issues of accountability and governance. Finally, some recommendations are suggested such as developing specific sector regulations, fostering a data-driven organisational culture, considering the algorithm’s complete life cycle, developing and using a specific code of ethics, and providing specific training on ethical issues. Despite some obvious limitations, such as the type and number of companies interviewed, this work identifies real examples and direct priorities to advance the research exploring the gap between practice and principles in AI ethics, with a specific focus on Spanish companies. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85113948828"
"Wang N.; Luo Y.; Sato T.; Xu K.; Chen Q.A.","Wang, Ningfei (57219260741); Luo, Yunpeng (57552174800); Sato, Takami (57219686251); Xu, Kaidi (57205687721); Chen, Qi Alfred (56379253400)","57219260741; 57552174800; 57219686251; 57205687721; 56379253400","Poster: On the System-Level Effectiveness of Physical Object-Hiding Adversarial Attack in Autonomous Driving","2022","Proceedings of the ACM Conference on Computer and Communications Security","","","","3479","3481","2","10.1145/3548606.3563539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143049135&doi=10.1145%2f3548606.3563539&partnerID=40&md5=41d5ccb8a30e37c8af84f147057ea479","In Autonomous Driving (AD) systems, perception is both security and safety-critical. Among different attacks on AD perception, object-hiding adversarial attack is one of the most critical ones due to the direct impact on safety-critical driving decisions such as collision avoidance. However, all of the prior works on physical object-hiding adversarial attacks only study the security of the AI component alone rather than with the entire AD system pipeline with closed-loop control. This thus inevitably raises a critical research question: can these prior works actually achieve system-level effects (e.g., vehicle collisions, traffic rule violation) under real-world AD settings with closed-loop control? To answer this critical question, in this work we take the necessary first step by performing the first measurement study on whether and how effective the existing designs can lead to system-level effects. Our early results find that RP2 and FTE, as two representative examples of prior works, cannot achieve any system-level effect in a representative closed-loop AD setup in common STOP sign-controlled road speeds. In the future, we plan to 1) perform a more comprehensive measurement study using both simulated environments and a real vehicle-sized AD R&D chassis; and 2) analyze the measurement study results and explore new attack designs that can better achieve the system-level effect in AD systems. © 2022 Owner/Author.","2-s2.0-85143049135"
"Bailao Goncalves M.; Anastasiadou M.; Santos V.","Bailao Goncalves, Mariana (57908851000); Anastasiadou, Maria (57218491920); Santos, Vitor (49864419600)","57908851000; 57218491920; 49864419600","AI and public contests: a model to improve the evaluation and selection of public contest candidates in the Police Force","2022","Transforming Government: People, Process and Policy","16","4","","627","648","21","10.1108/TG-05-2022-0078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138863281&doi=10.1108%2fTG-05-2022-0078&partnerID=40&md5=f8505aa87242172bf87de6d76d548377","Purpose: The number of candidates applying to public contests (PC) is increasing compared to the number of human resources employees required for selecting them for the Police Force (PF). This work intends to perceive how those public institutions can evaluate and select their candidates efficiently during the different phases of the recruitment process. To achieve this purpose, artificial intelligence (AI) was studied. This paper aims to focus on analysing the AI technologies most used and appropriate to the PF as a complementary recruitment strategy of the National Criminal Investigation police agency of Portugal – Polícia Judiciária. Design/methodology/approach: Using design science research as a methodological approach, the authors suggest a theoretical framework in pair with the segmentation of the candidates and comprehend the most important facts facing public institutions regarding the usage of AI technologies to make decisions about evaluating and selecting candidates. Following the preferred reporting items for systematic reviews and meta-analyses methodology guidelines, a systematic literature review and meta-analyses method was adopted to identify how the usage and exploitation of transparent AI positively impact the recruitment process of a public institution, resulting in an analysis of 34 papers between 2017 and 2021. Findings: Results suggest that the conceptual pairing of evaluation and selection problems of candidates who apply to PC with applicable AI technology such as K-means, hierarchical clustering, artificial neural network and convolutional neural network algorithms can support the recruitment process and could help reduce the workload in the entire process while maintaining the standard of responsibility. The combination of AI and human decision-making is a fair, objective and unbiased process emphasising a decision-making process free of nepotism and favouritism when carefully developed. Innovative and modern as a category, group the statements that emphasise the innovative and contemporary nature of the process. Research limitations/implications: There are two main limitations in this study that should be considered. Firstly, the difficulty regarding the timetable, privacy and legal issues associated with public institutions. Secondly, a small group of experts served as the validation group for the new framework. Individual semi-structured interviews were conducted to alleviate this constraint. They provide additional insights into an interviewee’s opinions and beliefs. Social implications: Ensure that the system is fair, transparent and facilitates their application process. Originality/value: The main contribution is the AI-based theoretical framework, applicable within the analysis of literature papers, focusing on the problem of how the institutions can gain insights about their candidates while profiling them, how to obtain more accurate information from the interview phase and how to reach a more rigorous assessment of their emotional intelligence providing a better alignment of moral values. This work aims to improve the decision-making process of a PF institution recruiter by turning it into a more automated and evidence-based decision when recruiting an adequate candidate for the job vacancy. © 2022, Emerald Publishing Limited.","2-s2.0-85138863281"
"Naiseh M.; Al-Thani D.; Jiang N.; Ali R.","Naiseh, Mohammad (57217108046); Al-Thani, Dena (56444337800); Jiang, Nan (56038315600); Ali, Raian (56038311800)","57217108046; 56444337800; 56038315600; 56038311800","How the different explanation classes impact trust calibration: The case of clinical decision support systems","2023","International Journal of Human Computer Studies","169","","102941","","","","10.1016/j.ijhcs.2022.102941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139859152&doi=10.1016%2fj.ijhcs.2022.102941&partnerID=40&md5=87e55eeea60ef783e02b78186514493b","Machine learning has made rapid advances in safety-critical applications, such as traffic control, finance, and healthcare. With the criticality of decisions they support and the potential consequences of following their recommendations, it also became critical to provide users with explanations to interpret machine learning models in general, and black-box models in particular. However, despite the agreement on explainability as a necessity, there is little evidence on how recent advances in eXplainable Artificial Intelligence literature (XAI) can be applied in collaborative decision-making tasks, i.e., human decision-maker and an AI system working together, to contribute to the process of trust calibration effectively. This research conducts an empirical study to evaluate four XAI classes for their impact on trust calibration. We take clinical decision support systems as a case study and adopt a within-subject design followed by semi-structured interviews. We gave participants clinical scenarios and XAI interfaces as a basis for decision-making and rating tasks. Our study involved 41 medical practitioners who use clinical decision support systems frequently. We found that users perceive the contribution of explanations to trust calibration differently according to the XAI class and to whether XAI interface design fits their job constraints and scope. We revealed additional requirements on how explanations shall be instantiated and designed to help a better trust calibration. Finally, we build on our findings and present guidelines for designing XAI interfaces. © 2022","2-s2.0-85139859152"
"Vianello A.; Laine S.; Tuomi E.","Vianello, Andrea (58357680900); Laine, Sami (56421774500); Tuomi, Elsa (57797934900)","58357680900; 56421774500; 57797934900","Improving Trustworthiness of AI Solutions: A Qualitative Approach to Support Ethically-Grounded AI Design","2023","International Journal of Human-Computer Interaction","39","7","","1405","1422","17","10.1080/10447318.2022.2095478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134078500&doi=10.1080%2f10447318.2022.2095478&partnerID=40&md5=e79a00bf150c0f69084e0257b50f74b2","Despite recent efforts to make AI systems more transparent, a general lack of trust in such systems still discourages people and organizations from using or adopting them. In this article, we first present our approach for evaluating the trustworthiness of AI solutions from the perspectives of end-user explainability and normative ethics. Then, we illustrate its adoption through a case study involving an AI recommendation system used in a real business setting. The results show that our proposed approach allows for the identification of a wide range of practical issues related to AI systems and further supports the formulation of improvement opportunities and generalized design principles. By linking these identified opportunities to ethical considerations, the overall results show that our approach can support the design and development of trustworthy AI solutions and ethically-aligned business improvement. © 2022 The Author(s). Published with license by Taylor & Francis Group, LLC.","2-s2.0-85134078500"
"Vössing M.; Kühl N.; Lind M.; Satzger G.","Vössing, Michael (57191150803); Kühl, Niklas (57196220660); Lind, Matteo (57710237300); Satzger, Gerhard (25825625400)","57191150803; 57196220660; 57710237300; 25825625400","Designing Transparency for Effective Human-AI Collaboration","2022","Information Systems Frontiers","24","3","","877","895","18","10.1007/s10796-022-10284-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130737893&doi=10.1007%2fs10796-022-10284-3&partnerID=40&md5=df5769a0be3d27f5bd509d299f395ab0","The field of artificial intelligence (AI) is advancing quickly, and systems can increasingly perform a multitude of tasks that previously required human intelligence. Information systems can facilitate collaboration between humans and AI systems such that their individual capabilities complement each other. However, there is a lack of consolidated design guidelines for information systems facilitating the collaboration between humans and AI systems. This work examines how agent transparency affects trust and task outcomes in the context of human-AI collaboration. Drawing on the 3-Gap framework, we study agent transparency as a means to reduce the information asymmetry between humans and the AI. Following the Design Science Research paradigm, we formulate testable propositions, derive design requirements, and synthesize design principles. We instantiate two design principles as design features of an information system utilized in the hospitality industry. Further, we conduct two case studies to evaluate the effects of agent transparency: We find that trust increases when the AI system provides information on its reasoning, while trust decreases when the AI system provides information on sources of uncertainty. Additionally, we observe that agent transparency improves task outcomes as it enhances the accuracy of judgemental forecast adjustments. © 2022, The Author(s).","2-s2.0-85130737893"
"Davis S.E.; Walsh C.G.; Matheny M.E.","Davis, Sharon E. (56701529600); Walsh, Colin G. (7401952440); Matheny, Michael E. (57210774976)","56701529600; 7401952440; 57210774976","Open questions and research gaps for monitoring and updating AI-enabled tools in clinical settings","2022","Frontiers in Digital Health","4","","958284","","","","10.3389/fdgth.2022.958284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138156015&doi=10.3389%2ffdgth.2022.958284&partnerID=40&md5=c014d3e5f7731575adb9ae6ef66ec8e8","As the implementation of artificial intelligence (AI)-enabled tools is realized across diverse clinical environments, there is a growing understanding of the need for ongoing monitoring and updating of prediction models. Dataset shift—temporal changes in clinical practice, patient populations, and information systems—is now well-documented as a source of deteriorating model accuracy and a challenge to the sustainability of AI-enabled tools in clinical care. While best practices are well-established for training and validating new models, there has been limited work developing best practices for prospective validation and model maintenance. In this paper, we highlight the need for updating clinical prediction models and discuss open questions regarding this critical aspect of the AI modeling lifecycle in three focus areas: model maintenance policies, performance monitoring perspectives, and model updating strategies. With the increasing adoption of AI-enabled tools, the need for such best practices must be addressed and incorporated into new and existing implementations. This commentary aims to encourage conversation and motivate additional research across clinical and data science stakeholders. 2022 Davis, Walsh and Matheny.","2-s2.0-85138156015"
"Chourasia V.; Pandey S.; Kumar S.","Chourasia, Vishakha (56209206800); Pandey, Sudhakar (57220976603); Kumar, Sanjay (57224463562)","56209206800; 57220976603; 57224463562","Reliable data exchange in vehicular delay tolerant networks using AI-based hybrid trust management","2022","International Journal of Communication Systems","35","11","e5197","","","","10.1002/dac.5197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129450661&doi=10.1002%2fdac.5197&partnerID=40&md5=4c014a51ec9957f5b624756991fd0df9","Vehicular delay-tolerant networks (VDTNs) play prominent part in smart transportation and smart city paradigm to diminish the drivers' risk to meet accidents and offer many infotainment and entertainment services. All the operations are carried out by exchanging data among nodes. However, due to open communication nature of VDTN, the data broadcasted by mobile nodes are quiet susceptible to security attacks. Recently, a number of protocols are proposed for open communication. However, securing such communications and establishing trust value among vehicles are major addressable issues. This is because the existing fraudulent peers can lead to catastrophic circumstances on roads. Along with securing the data carriers, the authenticity and reliability of data is also equally important. In order to identify reliable nodes and maintaining the authenticity of data being communicated, a new artificial intelligence (AI)-based hybrid trust management framework is proposed in this article. The study particularly exploits the proximity-based k-nearest neighbour (kNN) classification model for selecting controlling nodes. Further, decision stump is employed to accomplish trust estimation rules, and backpropagation is used to self-train the mobile nodes, whenever anticipated trust value is not attained. The proposed scheme maintains the integrity of vehicular nodes and efficiently handles the specified. The trust framework uses a multifaceted direct and recommended trust estimation approach to calculate the global trust values. For comparison, the performance of the proposed method was compared with other trust management approaches. © 2022 John Wiley & Sons Ltd.","2-s2.0-85129450661"
"Wintersberger P.; Van Berkel N.; Fereydooni N.; Tag B.; Glassman E.L.; Buschek D.; Blandford A.; Michahelles F.","Wintersberger, Philipp (55485458100); Van Berkel, Niels (56032304300); Fereydooni, Nadia (57210430321); Tag, Benjamin (56747853900); Glassman, Elena L. (23975987900); Buschek, Daniel (55850134500); Blandford, Ann (7004087556); Michahelles, Florian (6507384553)","55485458100; 56032304300; 57210430321; 56747853900; 23975987900; 55850134500; 7004087556; 6507384553","Designing for Continuous Interaction with Artificial Intelligence Systems","2022","Conference on Human Factors in Computing Systems - Proceedings","","","170","","","","10.1145/3491101.3516409","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129740257&doi=10.1145%2f3491101.3516409&partnerID=40&md5=271836e5b6eb04bbe95defff729a17d1","The increasing capabilities of Artificial Intelligence enable the support of users in a continuously growing number of applications. Current systems typically dictate that interaction between user input and AI output unfolds in discrete steps, as is the case with, for example, conversational agents. Novel scenarios require AI systems to adapt and respond to continuous user input, e.g., image-guided surgery and AI-supported text entry. In and across these applications, AI systems need to support more varied and dynamic interactions in which users and AI interact continuously and in parallel. Current methods and guidelines are often inadequate and sometimes even detrimental to user needs when considering continuous usage scenarios. Realizing a continuous interaction between users and AI requires a substantial change in perspective when designing Human-AI systems. In this SIG, we support the exchange of cutting-edge research contributing to a better understanding and improved methods and tools to design continuous Human-AI interaction. © 2022 Owner/Author.","2-s2.0-85129740257"
"Nandi S.; Mishra M.; Majumder S.","Nandi, Swarup (57219559595); Mishra, Madhusudhan (56405112400); Majumder, Swanirbhar (26648786000)","57219559595; 56405112400; 26648786000","Usage of AI and wearable IoT Devices for healthcare data: A study","2022","Machine Learning Algorithms for Signal and Image Processing","","","","315","337","22","10.1002/9781119861850.ch18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148484178&doi=10.1002%2f9781119861850.ch18&partnerID=40&md5=67cc0f0414498f0e4953e80be81aacd7","In this present situation, the importance of drawing the efficient learning footsteps should be necessary for describing mortal performances with the help of wearable-internet of things (W-IoT) sensors for analyzing body parameters, such as average-accuracy analysis, tracking performance, work-offloading wage and possibility analysis, power-consumption analysis, and reliability-ratio analysis. In the healthcare department, data storing/collection are done by using artificial intelligence (AI) based cognitive factor tools use wearing sensors for control where cloud support internet of things (IoT) are introduced. In spite of the fact that several current set of rules with deep-learning patterns shows hopeful outcomes in sensor facts and statistics resolution for identification of mortal attitudes, appreciation of uncertainty in cognitive factor is yet harder and few common processes are more complicated. On account of the reserved computing ability, W-IoT devices want most effective use of network to handle the maintenance and improvement of physical- and mental-health information practically and effectively for feasible interpretation. Therefore, a modern ethical mobility determination is introduced that fully worked on improved Bayesian convolution network (IBCN), which permits to deliver everyone and every knowledgeable process to copy information via either basic telecommunications technique or lower ability back diffraction informing with cloud facilitation. IBCN consists of an adjustment of the pattern's dormant fickle is planned and the shape are uprooted using fold layers, the achievement of the W-IoT has been uplifted by assembling a volatile auto-encoder with a grade sound genuine classifier. In addition, the IBCN provides assistance to locate the privacy consignment where EDL is developed with a useful offloading AI technique. These explorative outcomes display the collection of information from the W-IoT sensors side is impressionable to various productions of doubtfulness, such as noise and reliability. In addition, lab-scale explorative solution on sick person's hygiene info grouping appropriateness has been displayed with the help of IBCN, which is a usual designed with the help of cognitive radio (CR) learning, DL-SAR and cloud-assisted agent-based smart environment (CASE). © 2023 The Institute of Electrical and Electronics Engineers, Inc.","2-s2.0-85148484178"
"Kousa P.; Niemi H.","Kousa, Päivi (57202532349); Niemi, Hannele (22939202000)","57202532349; 22939202000","AI ethics and learning: EdTech companies’ challenges and solutions","2023","Interactive Learning Environments","31","10","","6735","6746","11","10.1080/10494820.2022.2043908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126018975&doi=10.1080%2f10494820.2022.2043908&partnerID=40&md5=150439a1372bf7d49df66fb32296b9de","The aim of this study is to identify the ethical challenges, solutions and needs of educational technology (EdTech) companies. Qualitative data was collected in interviews with seven experts from four companies, and the data was analysed using inductive content analysis. The four main areas of challenges were ambiguous regulations, inequalities in human learning, ethical dilemmas in machine learning (ML) and lack of ability to assess consequences in society. According to the studied companies, AI regulations are difficult to understand and implement. There is also much to be done in terms of reliability, transparency, and safety. Consequently, companies suggested that AI-based products should be more preventive, safe, explicable, and equally accessible. Sufficient information, multi-professional support also within company, global collaboration, sharing best practices, and general discussion were emphasised. The results show that EdTech companies are aware of their ethical challenges, and their responsibility as disseminators of information. However, translating information into practice is challenging because it is often very fragmented and difficult to understand. Companies hoped that everyone: themselves, consumers, educational institutions, researchers, funders, and decision-makers would do more together to overcome the ethical challenges of AI. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2-s2.0-85126018975"
"Gianni R.; Lehtinen S.; Nieminen M.","Gianni, Robert (56642629100); Lehtinen, Santtu (57740004300); Nieminen, Mika (57225331891)","56642629100; 57740004300; 57225331891","Governance of Responsible AI: From Ethical Guidelines to Cooperative Policies","2022","Frontiers in Computer Science","4","","873437","","","","10.3389/fcomp.2022.873437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131854622&doi=10.3389%2ffcomp.2022.873437&partnerID=40&md5=00e6f6e82d33aa610e3099bcee604a07","The increasingly pervasive role of Artificial Intelligence (AI) in our societies is radically changing the way that social interaction takes place within all fields of knowledge. The obvious opportunities in terms of accuracy, speed and originality of research are accompanied by questions about the possible risks and the consequent responsibilities involved in such a disruptive technology. In recent years, this twofold aspect has led to an increase in analyses of the ethical and political implications of AI. As a result, there has been a proliferation of documents that seek to define the strategic objectives of AI together with the ethical precautions required for its acceptable development and deployment. Although the number of documents is certainly significant, doubts remain as to whether they can effectively play a role in safeguarding democratic decision-making processes. Indeed, a common feature of the national strategies and ethical guidelines published in recent years is that they only timidly address how to integrate civil society into the selection of AI objectives. Although scholars are increasingly advocating the necessity to include civil society, it remains unclear which modalities should be selected. If both national strategies and ethics guidelines appear to be neglecting the necessary role of a democratic scrutiny for identifying challenges, objectives, strategies and the appropriate regulatory measures that such a disruptive technology should undergo, the question is then, what measures can we advocate that are able to overcome such limitations? Considering the necessity to operate holistically with AI as a social object, what theoretical framework can we adopt in order to implement a model of governance? What conceptual methodology shall we develop that is able to offer fruitful insights to governance of AI? Drawing on the insights of classical pragmatist scholars, we propose a framework of democratic experimentation based on the method of social inquiry. In this article, we first summarize some of the main points of discussion around the potential societal, ethical and political issues of AI systems. We then identify the main answers and solutions by analyzing current national strategies and ethics guidelines. After showing the theoretical and practical limits of these approaches, we outline an alternative proposal that can help strengthening the active role of society in the discussion about the role and extent of AI systems. Copyright © 2022 Gianni, Lehtinen and Nieminen.","2-s2.0-85131854622"
"Kumar Y.; Gupta S.; Singla R.; Hu Y.-C.","Kumar, Yogesh (57225085312); Gupta, Surbhi (57226094578); Singla, Ruchi (57215433546); Hu, Yu-Chen (24449408900)","57225085312; 57226094578; 57215433546; 24449408900","A Systematic Review of Artificial Intelligence Techniques in Cancer Prediction and Diagnosis","2022","Archives of Computational Methods in Engineering","29","4","","2043","2070","27","10.1007/s11831-021-09648-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115797852&doi=10.1007%2fs11831-021-09648-w&partnerID=40&md5=d4bf36bf92c795afc06c1e027bf6a7c4","Artificial intelligence has aided in the advancement of healthcare research. The availability of open-source healthcare statistics has prompted researchers to create applications that aid cancer detection and prognosis. Deep learning and machine learning models provide a reliable, rapid, and effective solution to deal with such challenging diseases in these circumstances. PRISMA guidelines had been used to select the articles published on the web of science, EBSCO, and EMBASE between 2009 and 2021. In this study, we performed an efficient search and included the research articles that employed AI-based learning approaches for cancer prediction. A total of 185 papers are considered impactful for cancer prediction using conventional machine and deep learning-based classifications. In addition, the survey also deliberated the work done by the different researchers and highlighted the limitations of the existing literature, and performed the comparison using various parameters such as prediction rate, accuracy, sensitivity, specificity, dice score, detection rate, area undercover, precision, recall, and F1-score. Five investigations have been designed, and solutions to those were explored. Although multiple techniques recommended in the literature have achieved great prediction results, still cancer mortality has not been reduced. Thus, more extensive research to deal with the challenges in the area of cancer prediction is required. © 2021, CIMNE, Barcelona, Spain.","2-s2.0-85115797852"
"Kim Y.; Lee W.","Kim, Yaeran (58025300400); Lee, Woonghee (55987224100)","58025300400; 55987224100","Distributed Raman Spectrum Data Augmentation System Using Federated Learning with Deep Generative Models","2022","Sensors","22","24","9900","","","","10.3390/s22249900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144525478&doi=10.3390%2fs22249900&partnerID=40&md5=7bf37298123727cc8efb5d741a433fe7","Chemical agents are one of the major threats to soldiers in modern warfare, so it is so important to detect chemical agents rapidly and accurately on battlefields. Raman spectroscopy-based detectors are widely used but have many limitations. The Raman spectrum changes unpredictably due to various environmental factors, and it is hard for detectors to make appropriate judgments about new chemical substances without prior information. Thus, the existing detectors with inflexible techniques based on determined rules cannot deal with such problems flexibly and reactively. Artificial intelligence (AI)-based detection techniques can be good alternatives to the existing techniques for chemical agent detection. To build AI-based detection systems, sufficient amounts of data for training are required, but it is not easy to produce and handle fatal chemical agents, which causes difficulty in securing data in advance. To overcome the limitations, in this paper, we propose the distributed Raman spectrum data augmentation system that leverages federated learning (FL) with deep generative models, such as generative adversarial network (GAN) and autoencoder. Furthermore, the proposed system utilizes various additional techniques in combination to generate a large number of Raman spectrum data with reality along with diversity. We implemented the proposed system and conducted diverse experiments to evaluate the system. The evaluation results validated that the proposed system can train the models more quickly through cooperation among decentralized troops without exchanging raw data and generate realistic Raman spectrum data well. Moreover, we confirmed that the classification model on the proposed system performed learning much faster and outperformed the existing systems. © 2022 by the authors.","2-s2.0-85144525478"
"Mökander J.; Sheth M.; Gersbro-Sundler M.; Blomgren P.; Floridi L.","Mökander, Jakob (57222069643); Sheth, Margi (57979987700); Gersbro-Sundler, Mimmi (57979621100); Blomgren, Peder (57979987800); Floridi, Luciano (6603039594)","57222069643; 57979987700; 57979621100; 57979987800; 6603039594","Challenges and best practices in corporate AI governance: Lessons from the biopharmaceutical industry","2022","Frontiers in Computer Science","4","","1068361","","","","10.3389/fcomp.2022.1068361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142468176&doi=10.3389%2ffcomp.2022.1068361&partnerID=40&md5=074cacb88292ddc7babd4ecc19b7fe42","While the use of artificial intelligence (AI) systems promises to bring significant economic and social benefits, it is also coupled with ethical, legal, and technical challenges. Business leaders thus face the question of how to best reap the benefits of automation whilst managing the associated risks. As a first step, many companies have committed themselves to various sets of ethics principles aimed at guiding the design and use of AI systems. So far so good. But how can well-intentioned ethical principles be translated into effective practice? And what challenges await companies that attempt to operationalize AI governance? In this article, we address these questions by drawing on our first-hand experience of shaping and driving the roll-out of AI governance within AstraZeneca, a biopharmaceutical company. The examples we discuss highlight challenges that any organization attempting to operationalize AI governance will have to face. These include questions concerning how to define the material scope of AI governance, how to harmonize standards across decentralized organizations, and how to measure the impact of specific AI governance initiatives. By showcasing how AstraZeneca managed these operational questions, we hope to provide project managers, CIOs, AI practitioners, and data privacy officers responsible for designing and implementing AI governance frameworks within other organizations with generalizable best practices. In essence, companies seeking to operationalize AI governance are encouraged to build on existing policies and governance structures, use pragmatic and action-oriented terminology, focus on risk management in development and procurement, and empower employees through continuous education and change management. Copyright © 2022 Mökander, Sheth, Gersbro-Sundler, Blomgren and Floridi.","2-s2.0-85142468176"
"Li F.; Lu Y.","Li, Fan (57310320800); Lu, Yuan (55378447100)","57310320800; 55378447100","Human-AI interaction and ethics of AI: how well are we following the guidelines","2022","ACM International Conference Proceeding Series","","","","96","104","8","10.1145/3565698.3565773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185391384&doi=10.1145%2f3565698.3565773&partnerID=40&md5=532866cc374721bc26c6001c5796309c","Despite the benefits of AI-enabled solutions in different industrial sectors, their technology acceptance remains challenging. The acceptance of AI technologies depends on both the Human-AI (HAI) interaction and the ethics of AI. HAI interaction significantly affects the acceptance of AI-enabled solutions. Many guidelines have been developed to support HAI interaction design, including Microsoft's Guidelines for HAI interaction. On the other hand, many ethics by design guidelines were developed, such as the Ethics Guidelines for Trustworthy AI (EGTAI) developed by European Commission. However, there is less discussion about the possible relations between these two sets of guidelines for developing AI-enabled solutions. This study aims to analyze how current AI-enabled solutions comply with these two guidelines using a case study approach. To realize this aim, we conducted a co-evaluation workshop investigating how two existing AI-enabled apps, Strava and CoronaMelder, comply with these two guidelines. In this workshop, four participants with prior knowledge of designing with AI were asked to analyze the two cases by identifying whether these guidelines were met. The workshop results implied that when HAI interactions are designed according to the HAI interaction guidelines, they do not necessarily align with the EGTAI guidelines and vice versa.  © 2022 Owner/Author.","2-s2.0-85185391384"
"Giannotti F.; Naretto F.; Bodria F.","Giannotti, Fosca (7004495132); Naretto, Francesca (57219593665); Bodria, Francesco (57218956980)","7004495132; 57219593665; 57218956980","Explainable for Trustworthy AI","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13500 LNAI","","","175","195","20","10.1007/978-3-031-24349-3_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152569751&doi=10.1007%2f978-3-031-24349-3_10&partnerID=40&md5=83741453a472ce530160839747badda2","Black-box Artificial Intelligence (AI) systems for automated decision making are often based on over (big) human data, map a user’s features into a class or a score without exposing why. This is problematic for the lack of transparency and possible biases inherited by the algorithms from human prejudices and collection artefacts hidden in the training data, leading to unfair or wrong decisions. The future of AI lies in enabling people to collaborate with machines to solve complex problems. This requires good communication, trust, clarity, and understanding, like any efficient collaboration. Explainable AI (XAI) addresses such challenges, and for years different AI communities have studied such topics, leading to different definitions, evaluation protocols, motivations, and results. This chapter provides a reasoned introduction to the work of Explainable AI to date and surveys the literature focusing on symbolic AI-related approaches. We motivate the needs of XAI in real-world and large-scale applications while presenting state-of-the-art techniques and best practices and discussing the many open challenges. © 2023, Springer Nature Switzerland AG.","2-s2.0-85152569751"
"Kraetzer C.; Siegel D.; Seidlitz S.; Dittmann J.","Kraetzer, Christian (15033995900); Siegel, Dennis (57218093460); Seidlitz, Stefan (57222523152); Dittmann, Jana (25821612000)","15033995900; 57218093460; 57222523152; 25821612000","Process-Driven Modelling of Media Forensic Investigations-Considerations on the Example of DeepFake Detection","2022","Sensors","22","9","3137","","","","10.3390/s22093137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128423412&doi=10.3390%2fs22093137&partnerID=40&md5=dba1488d9706c708e8f8fe4ad6700f9f","Academic research in media forensics mainly focuses on methods for the detection of the traces or artefacts left by media manipulations in media objects. While the resulting detectors often achieve quite impressive detection performances, when tested under lab conditions, hardly any of those have yet come close to the ultimate benchmark for any forensic method, which would be courtroom readiness. This paper tries first to facilitate the different stakeholder perspectives in this field and then to partly address the apparent gap between the academic research community and the requirements imposed onto forensic practitioners. The intention is to facilitate the mutual understanding of these two classes of stakeholders and assist with first steps intended at closing this gap. To do so, first a concept for modelling media forensic investigation pipelines is derived from established guidelines. Then, the applicability of such modelling is illustrated on the example of a fusion-based media forensic investigation pipeline aimed at the detection of DeepFake videos using five exemplary detectors (hand-crafted, in one case neural network supported) and testing two different fusion operators. At the end of the paper, the benefits of such a planned realisation of AI-based investigation methods are discussed and generalising effects are mapped out. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85128423412"
"de Hond A.A.H.; Leeuwenberg A.M.; Hooft L.; Kant I.M.J.; Nijman S.W.J.; van Os H.J.A.; Aardoom J.J.; Debray T.P.A.; Schuit E.; van Smeden M.; Reitsma J.B.; Steyerberg E.W.; Chavannes N.H.; Moons K.G.M.","de Hond, Anne A. H. (57205398709); Leeuwenberg, Artuur M. (56736513400); Hooft, Lotty (57202068648); Kant, Ilse M. J. (57195222927); Nijman, Steven W. J. (57219920778); van Os, Hendrikus J. A. (57190048785); Aardoom, Jiska J. (55446701500); Debray, Thomas P. A. (54879335700); Schuit, Ewoud (45161772100); van Smeden, Maarten (55580255200); Reitsma, Johannes B. (7004204084); Steyerberg, Ewout W. (7006417148); Chavannes, Niels H. (6604023299); Moons, Karel G. M. (56354581300)","57205398709; 56736513400; 57202068648; 57195222927; 57219920778; 57190048785; 55446701500; 54879335700; 45161772100; 55580255200; 7004204084; 7006417148; 6604023299; 56354581300","Guidelines and quality criteria for artificial intelligence-based prediction models in healthcare: a scoping review","2022","npj Digital Medicine","5","1","2","","","","10.1038/s41746-021-00549-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122738619&doi=10.1038%2fs41746-021-00549-7&partnerID=40&md5=0d7d18844b4bdc7089ecaf87c2457fb6","While the opportunities of ML and AI in healthcare are promising, the growth of complex data-driven prediction models requires careful quality and applicability assessment before they are applied and disseminated in daily practice. This scoping review aimed to identify actionable guidance for those closely involved in AI-based prediction model (AIPM) development, evaluation and implementation including software engineers, data scientists, and healthcare professionals and to identify potential gaps in this guidance. We performed a scoping review of the relevant literature providing guidance or quality criteria regarding the development, evaluation, and implementation of AIPMs using a comprehensive multi-stage screening strategy. PubMed, Web of Science, and the ACM Digital Library were searched, and AI experts were consulted. Topics were extracted from the identified literature and summarized across the six phases at the core of this review: (1) data preparation, (2) AIPM development, (3) AIPM validation, (4) software development, (5) AIPM impact assessment, and (6) AIPM implementation into daily healthcare practice. From 2683 unique hits, 72 relevant guidance documents were identified. Substantial guidance was found for data preparation, AIPM development and AIPM validation (phases 1–3), while later phases clearly have received less attention (software development, impact assessment and implementation) in the scientific literature. The six phases of the AIPM development, evaluation and implementation cycle provide a framework for responsible introduction of AI-based prediction models in healthcare. Additional domain and technology specific research may be necessary and more practical experience with implementing AIPMs is needed to support further guidance. © 2022, The Author(s).","2-s2.0-85122738619"
"Agarwal A.; Gupta S.; Bonagiri V.; Gaur M.; Reagle J.; Kumaraguru P.","Agarwal, Anmol (57337359200); Gupta, Shrey (57213338772); Bonagiri, Vamshi (57574511300); Gaur, Manas (57204944466); Reagle, Joseph (15132588300); Kumaraguru, Ponnurangam (14042000100)","57337359200; 57213338772; 57574511300; 57204944466; 15132588300; 14042000100","Towards Effective Paraphrasing for Information Disguise","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13981 LNCS","","","331","340","9","10.1007/978-3-031-28238-6_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150980550&doi=10.1007%2f978-3-031-28238-6_22&partnerID=40&md5=8247d286bd24846e1ce5aba0aeffa40a","Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors’ posts on the Internet. Research on ID becomes important when authors’ written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author’s post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit “r/AmItheAsshole” as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach. (https://github.com/idecir/idecir-Towards-Effective-Paraphrasing-for-Information-Disguise ) © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85150980550"
"AlZaabi A.; AlMaskari S.; AalAbdulsalam A.","AlZaabi, Adhari (57890842300); AlMaskari, Saleh (58085584200); AalAbdulsalam, Abdulrahman (58085100000)","57890842300; 58085584200; 58085100000","Are physicians and medical students ready for artificial intelligence applications in healthcare?","2023","Digital Health","9","","","","","","10.1177/20552076231152167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147168720&doi=10.1177%2f20552076231152167&partnerID=40&md5=baada435fd666870d9d868ccc392e624","Background: Artificial intelligence (AI) Healthcare applications are listed in the national visions of some Gulf Cooperation Council countries. A successful use of AI depends on the attitude and perception of medical experts of its applications. Objective: To evaluate physicians and medical students’ attitude and perception on AI applications in healthcare. Method: A web-based survey was disseminated by email to physicians and medical students. Results: A total of 293 (82 physicians and 211 medical students) individuals have participated (response rate is 27%). Seven participants (9%) reported knowing nothing about AI, while 208 (69%) were aware that it is an emerging field and would like to learn about it. Concerns about AI impact on physicians’ employability were not prominent. Instead, the majority (n=159) agreed that new positions will be created and the job market for those who embrace AI will increase. They reported willingness to adapt AI in practice if it was incorporated in international guidelines (30.5%), published in respected scientific journals (17.1%), or included in formal training (12.2%). Almost two of the three participants agreed that dedicated courses will help them to implement AI. The most commonly reported problem of AI is its inability to provide opinions in unexpected scenarios. Half of the participants think that both the manufacturer and physicians should be legally liable for medical errors occur due to AI-based decision support tools while more than one-third (36.77%) think that physicians who make the final decision should be legally liable. Senior physicians were found to be less familiar with AI and more concerned about physicians’ legal liability in case of a medical error. Conclusion: Physicians and medical students showed positive attitudes and willingness to learn about AI applications in healthcare. Introducing AI learning objectives or short courses in medical curriculum would help to equip physicians with the needed skills for AI-augmented healthcare system. © The Author(s) 2023.","2-s2.0-85147168720"
"Cachat-Rosset G.; Klarsfeld A.","Cachat-Rosset, Gaelle (57212757304); Klarsfeld, Alain (7003544827)","57212757304; 7003544827","Diversity, Equity, and Inclusion in Artificial Intelligence: An Evaluation of Guidelines","2023","Applied Artificial Intelligence","37","1","2176618","","","","10.1080/08839514.2023.2176618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148634636&doi=10.1080%2f08839514.2023.2176618&partnerID=40&md5=21a4531c420dd39a6b2f981904f5308a","Artificial intelligence (AI) is present everywhere in the lives of individuals. Unfortunately, several cases of discrimination by AI systems have already been reported. Scholars have warned on risks of AI reproducing existing inequalities or even amplifying them. To tackle these risks and promote responsible AI, many ethics guidelines for AI have emerged recently, including diversity, equity, and inclusion (DEI) principles and practices. However, little is known about the DEI content of these guidelines, and to what extent they meet the most relevant accumulated knowledge from DEI literature. We performed a semi-systematic literature review of the AI guidelines regarding DEI stakes and analyzed 46 guidelines published from 2015 to today. We fleshed out the 14 DEI principles and the 18 DEI practices recommended underlying these 46 guidelines. We found that the guidelines mostly encourage one of the DEI management paradigms, namely fairness, justice, and nondiscrimination, in a limited compliance approach. We found that narrow technical practices are favored over holistic ones. Finally, we conclude that recommended practices for implementing DEI principles in AI should include actions aimed at directly influencing AI actors’ behaviors and awareness of DEI risks, rather than just stating intentions and programs. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","2-s2.0-85148634636"
"Buhalis D.; Moldavska I.","Buhalis, Dimitrios (6603014980); Moldavska, Iuliia (57386476600)","6603014980; 57386476600","Voice assistants in hospitality: using artificial intelligence for customer service","2022","Journal of Hospitality and Tourism Technology","13","3","","386","403","17","10.1108/JHTT-03-2021-0104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121805894&doi=10.1108%2fJHTT-03-2021-0104&partnerID=40&md5=f3fe0c7e2467289ec12fefd337dc1f75","Purpose: Voice assistants (VAs) empower human–computer interactions by recognising human speech and implementing commands pronounced by users. This paper aims to investigate VA-enabled interactions between hotels and guests in the hospitality context. The research positions VAs within the artificial intelligence (AI)-enabled Internet of Things (IoT) context, disrupting old practices and processes. Smart hospitality uses VAs to support effortless value cocreation for guests cost-effectively. The research examines consumer perceptions and expectations of hospitality VAs and explores VA capabilities through expert technology providers. Design/methodology/approach: This empirical paper investigates the current use and future implications of VAs for hotel environments. It uses qualitative, semi-structured in-depth interviews with 7 expert hospitality VA technology providers and 21 hotel guests who have VA experience. The research adopts a demand and supply approach, addressing the VAs in hospitality holistically. Findings: The findings illustrate the requirements from both end-users’ sides, hotels and guests, exploring VA advantages and challenges. The analysis demonstrates that VAs increasingly become digital assistants. VA technology helps hotels to improve customer service, expand operational capability and reduce costs. Although in its infancy, VA technology has made progress towards optimising hotel operations and upgrading customer service. The study proposes a speech-enabled interactions model. Research limitations/implications: This research stimulates the transformation of hospitality services by using VAs and the development of smart hospitality and tourism ecosystems. The study can benefit from further research with hotel managers, to reflect hoteliers’ points of view and investigate their perception of VAs. Further research can also explore different aspects of consumer–VA interaction in different contexts. Practical implications: The paper makes a significant contribution to hospitality management and human–computer interaction best practices. It supports technology providers to reconsider how to develop suitable technology solutions towards improving their strategic competitiveness. It also explains how to use VAs cost-effectively and profitably while adding value to travellers’ experience. Originality/value: VA studies are often focussed on the technology in private households, rather than in commercial or hotel spaces. This paper contributes to the emerging literature on AI and IoT in smart hospitality and explores the acceptance and operationalisation of VAs. The research contributes to the conceptualisation of VA-enabled hotel services and explores positive and negative features, as well as future prospects. © 2021, Emerald Publishing Limited.","2-s2.0-85121805894"
"Cachel K.; Rundensteiner E.","Cachel, Kathleen (57818614900); Rundensteiner, Elke (7005195084)","57818614900; 7005195084","FINS auditing framework: Group fairness for subset selections","2022","AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","","","","144","155","11","10.1145/3514094.3534160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137161090&doi=10.1145%2f3514094.3534160&partnerID=40&md5=e5a92ef24117d9b154f6aa473d366a7a","Subset selection is an integral component of AI systems that is increasingly affecting people's livelihoods in applications ranging from hiring, healthcare, education, to financial decisions. Subset selections powered by AI-based methods include top-k analytics, data summarization, clustering, and multi-winner voting. While group fairness auditing tools have been proposed for classification systems, these state-of-The-Art tools are not directly applicable to measuring and conceptualizing fairness in selected subsets. In this work, we introduce the first comprehensive auditing framework, FINS, to support stakeholders in interpretably quantifying group fairness across a diverse range of subset-specific fairness concerns. FINS offers a family of novel measures that provide a flexible means to audit group fairness for fairness goals ranging from item-based, score-based, and a combination thereof. FINS provides one unified easy-To-understand interpretation across these different fairness problems. Further, we develop guidelines through the FINS Fair Subset Chart, that supports auditors in determining which measures are relevant to their problem context and fairness objectives. We provide a comprehensive mapping between each fairness measure and the belief system (i.e., worldview) that is encoded within its measurement of fairness. Lastly, we demonstrate the interpretability and efficacy of FINS in supporting the identification of real bias with case studies using AirBnB listings and voter records.  © 2022 ACM.","2-s2.0-85137161090"
"Lee H.; Lee S.H.; Quek T.Q.S.","Lee, Hoon (56337886700); Lee, Sang Hyun (57188647435); Quek, Tony Q. S. (55362784200)","56337886700; 57188647435; 55362784200","MOSAIC: Multiobjective Optimization Strategy for AI-Aided Internet of Things Communications","2022","IEEE Internet of Things Journal","9","17","","15657","15673","16","10.1109/JIOT.2022.3150747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124711596&doi=10.1109%2fJIOT.2022.3150747&partnerID=40&md5=1451136b75b9cb2e54380d371082c413","Future Internet of Things (IoT) communication trends toward heterogeneous services and diverse quality-of-service requirements pose fundamental challenges for network management strategies. In particular, multiobjective optimization (MOO) is necessary in resolving the competition among different nodes sharing limited wireless network resources. A unified coordination mechanism is essential such that individual nodes conduct the opportunistic maximization of heterogeneous local objectives for efficient distributed resource allocation. To such a problem, this article proposes an artificial intelligence (AI)-based framework, which is termed as MOO strategy for AI-aided IoT communications (MOSAIC). This framework enables to tackle numerous MOO tasks in IoT network management with simple reconfiguration of learning rules. In this strategy, a component unit associated with an individual network node includes a pair of deep neural networks (DNNs) to learn optimal local functions responsible for calculation and distributed coordination, respectively. The resultant AI module swarm called DNN tiles realizes the node cooperation that collectively seeks distributed MOO calculation rules. The advantage of MOSAIC is characterized by Pareto tradeoffs among conflicting performance metrics in diverse wireless networking configurations subject to severe interference and distinct criteria for multiple targets.  © 2022 IEEE.","2-s2.0-85124711596"
"Hassan A.H.; Sulaiman R.B.; Abdulgabber M.A.; Kahtan H.","Hassan, Ali H. (58709942100); Sulaiman, Riza bin (6602275590); Abdulgabber, Mansoor A. (57210572137); Kahtan, Hasan (55600272800)","58709942100; 6602275590; 57210572137; 55600272800","Balancing Technological Advances with User Needs: User-centered Principles for AI-Driven Smart City Healthcare Monitoring","2023","International Journal of Advanced Computer Science and Applications","14","3","","365","376","11","10.14569/IJACSA.2023.0140341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151783180&doi=10.14569%2fIJACSA.2023.0140341&partnerID=40&md5=a3f64462c4d269187e625754c877e61a","In recent years, the integration of artificial intelligence (AI) technologies has greatly benefited smart city healthcare, meeting the growing demand for affordable, efficient, and real-time healthcare services. Patient monitoring is one area where artificial intelligence has shown great promise. Improved health outcomes have been made possible by the advancement of AI-based monitoring systems, which enable more personalized and continuous patient monitoring. However, to fully maximize the benefits of these systems, a user-centered approach is essential, which prioritizes patients' needs and experiences while ensuring their privacy and autonomy are respected. This study focuses on the application of user-centered design principles in the development and deployment of AI-driven monitoring systems in smart city healthcare. Addressing the challenges and opportunities of AI-driven monitoring systems, the article considers issues such as privacy and security concerns, data accuracy, and user acceptance. Finally, some possible future directions to the challenges are suggested. A user-centered approach to AI monitoring systems is recommended for healthcare providers to enhance patient experience in smart city healthcare. © 2022,International Journal of Advanced Computer Science and Applications. All Rights Reserved.","2-s2.0-85151783180"
"Chen X.; Zeng Y.; Kang S.; Jin R.","Chen, Xiaoyu (57192992965); Zeng, Yingyan (57222602643); Kang, Sungku (57190302435); Jin, Ran (23389079600)","57192992965; 57222602643; 57190302435; 23389079600","INN: An Interpretable Neural Network for AI Incubation in Manufacturing","2022","ACM Transactions on Intelligent Systems and Technology","13","5","85","","","","10.1145/3519313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147941195&doi=10.1145%2f3519313&partnerID=40&md5=b488f28582c0168e12bea93e65067890","Both artificial intelligence (AI) and domain knowledge from human experts play an important role in manufacturing decision making. Smart manufacturing emphasizes a fully automated data-driven decision-making; however, the AI incubation process involves human experts to enhance AI systems by integrating domain knowledge for modeling, data collection and annotation, and feature extraction. Such an AI incubation process not only enhances the domain knowledge discovery but also improves the interpretability and trustworthiness of AI methods. In this article, we focus on the knowledge transfer from human experts to a supervised learning problem by learning domain knowledge as interpretable features and rules, which can be used to construct rule-based systems to support manufacturing decision making, such as process modeling and quality inspection. Although many advanced statistical and machine learning methods have shown promising modeling accuracy and efficiency, rule-based systems are still highly preferred and widely adopted due to their interpretability for human experts to comprehend. However, most of the existing rule-based systems are constructed based on deterministic human-crafted rules, whose parameters, such as thresholds of decision rules, are suboptimal. Yet the machine learning methods, such as tree models or neural networks, can learn a decision rule based structure without much interpretation or agreement with domain knowledge. Therefore, the traditional machine learning models and human experts' domain knowledge cannot be directly improved by learning from data. In this research, we propose an interpretable neural network (INN) model with a center-adjustable sigmoid activation function to efficiently optimize the rule-based systems. Using the rule-based system from domain knowledge to regulate the INN architecture not only improves the prediction accuracy with optimized parameters but also ensures the interpretability by adopting the interpretable rule-based systems from domain knowledge. The proposed INN will be effective for supervised learning problems when rule-based systems are available. The merits of the INN model are demonstrated via a simulation study and a real case study in the quality modeling of a semiconductor manufacturing process. © 2022 Association for Computing Machinery.","2-s2.0-85147941195"
"Lu Y.; Zhang C.; Zhang I.; Li T.J.-J.","Lu, Yuwen (57673347000); Zhang, Chengzhi (57674163300); Zhang, Iris (57673347100); Li, Toby Jia-Jun (57193573228)","57673347000; 57674163300; 57673347100; 57193573228","Bridging the Gap Between UX Practitioners' Work Practices and AI-Enabled Design Support Tools","2022","Conference on Human Factors in Computing Systems - Proceedings","","","268","","","","10.1145/3491101.3519809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129752843&doi=10.1145%2f3491101.3519809&partnerID=40&md5=222c789beebf23cdf43a05ceb3496fc4","User interface (UI) and user experience (UX) design have become an indispensable part of today's tech industry. Recently, much progress has been made in machine-learning-enabled design support tools for UX designers. However, few of these tools have been adopted by practitioners. To learn the underlying reasons and understand user needs for bridging this gap, we conducted a retrospective analysis with 8 UX professionals to understand their practice and identify opportunities for future research. We found that the current AI-enabled systems to support UX work mainly work on graphical interface elements, while design activities that involve more ""design thinking""such as user interviews and user testings are more helpful for designers. Many current systems were also designed for overly-simplistic and generic use scenarios. We identified 4 areas in the UX workflow that can benefit from additional AI-enabled assistance: design inspiration search, design alternative exploration, design system customization, and design guideline violation check. © 2022 ACM.","2-s2.0-85129752843"
"Shumba A.-T.; Montanaro T.; Sergi I.; Fachechi L.; De Vittorio M.; Patrono L.","Shumba, Angela-Tafadzwa (57321584300); Montanaro, Teodoro (56285236200); Sergi, Ilaria (55512097200); Fachechi, Luca (57221681812); De Vittorio, Massimo (23501214900); Patrono, Luigi (6507173572)","57321584300; 56285236200; 55512097200; 57221681812; 23501214900; 6507173572","Leveraging IoT-Aware Technologies and AI Techniques for Real-Time Critical Healthcare Applications","2022","Sensors","22","19","7675","","","","10.3390/s22197675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140005157&doi=10.3390%2fs22197675&partnerID=40&md5=8c7932fdf70f36686c79a6b635ccea9e","Personalised healthcare has seen significant improvements due to the introduction of health monitoring technologies that allow wearable devices to unintrusively monitor physiological parameters such as heart health, blood pressure, sleep patterns, and blood glucose levels, among others. Additionally, utilising advanced sensing technologies based on flexible and innovative biocompatible materials in wearable devices allows high accuracy and precision measurement of biological signals. Furthermore, applying real-time Machine Learning algorithms to highly accurate physiological parameters allows precise identification of unusual patterns in the data to provide health event predictions and warnings for timely intervention. However, in the predominantly adopted architectures, health event predictions based on Machine Learning are typically obtained by leveraging Cloud infrastructures characterised by shortcomings such as delayed response times and privacy issues. Fortunately, recent works highlight that a new paradigm based on Edge Computing technologies and on-device Artificial Intelligence significantly improve the latency and privacy issues. Applying this new paradigm to personalised healthcare architectures can significantly improve their efficiency and efficacy. Therefore, this paper reviews existing IoT healthcare architectures that utilise wearable devices and subsequently presents a scalable and modular system architecture to leverage emerging technologies to solve identified shortcomings. The defined architecture includes ultrathin, skin-compatible, flexible, high precision piezoelectric sensors, low-cost communication technologies, on-device intelligence, Edge Intelligence, and Edge Computing technologies. To provide development guidelines and define a consistent reference architecture for improved scalable wearable IoT-based critical healthcare architectures, this manuscript outlines the essential functional and non-functional requirements based on deductions from existing architectures and emerging technology trends. The presented system architecture can be applied to many scenarios, including ambient assisted living, where continuous surveillance and issuance of timely warnings can afford independence to the elderly and chronically ill. We conclude that the distribution and modularity of architecture layers, local AI-based elaboration, and data packaging consistency are the more essential functional requirements for critical healthcare application use cases. We also identify fast response time, utility, comfort, and low cost as the essential non-functional requirements for the defined system architecture. © 2022 by the authors.","2-s2.0-85140005157"
"Sayed W.S.; Noeman A.M.; Abdellatif A.; Abdelrazek M.; Badawy M.G.; Hamed A.; El-Tantawy S.","Sayed, Wafaa S. (56902453700); Noeman, Ahmed M. (57773302900); Abdellatif, Abdelrahman (58708742200); Abdelrazek, Moemen (57215356676); Badawy, Mostafa G. (57773303000); Hamed, Ahmed (57772783100); El-Tantawy, Samah (35721806800)","56902453700; 57773302900; 58708742200; 57215356676; 57773303000; 57772783100; 35721806800","AI-based adaptive personalized content presentation and exercises navigation for an effective and engaging E-learning platform","2023","Multimedia Tools and Applications","82","3","","3303","3333","30","10.1007/s11042-022-13076-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133167384&doi=10.1007%2fs11042-022-13076-8&partnerID=40&md5=c8c9a0d1b337189ad59e68f5689b028f","Effective and engaging E-learning becomes necessary in unusual conditions such as COVID-19 pandemic, especially for the early stages of K-12 education. This paper proposes an adaptive personalized E-learning platform with a novel combination of Visual/Aural/Read, Write/Kinesthetic (VARK) presentation or gamification and exercises difficulty scaffolding through skipping/hiding/ reattempting. Cognitive, behavior and affective adaptation means are included in developing a dynamic learner model, which detects and corrects each student’s learning style and cognitive level. As adaptation targets, the platform provides adaptive content presentation in two groups (VARK and gamification), adaptive exercises navigation and adaptive feedback. To achieve its goal, the platform utilizes a Deep Q-Network Reinforcement Learning (DQN-RL) and an online rule-based decision making implementation. The platform interfaces front-end dedicated website and back-end adaptation algorithms. An improvement in learning effectiveness is achieved comparing the post-test to the pre-test in a pilot experiment for grade 3 mathematics curriculum. Both groups witnessed academic performance and satisfaction level improvements, most importantly, for the students who started the experiment with a relatively low performance. VARK group witnessed a slightly more improvement and higher satisfaction level, since interactive activities and games in the kinesthetic presentation can provide engagement, while keeping other presentation styles available, when needed. © 2022, The Author(s).","2-s2.0-85133167384"
"Nazir T.; Mushhood Ur Rehman M.; Asghar M.R.; Kalia J.S.","Nazir, Talha (57942875200); Mushhood Ur Rehman, Muhammad (57942236400); Asghar, Muhammad Roshan (57941359300); Kalia, Junaid S. (35435243400)","57942875200; 57942236400; 57941359300; 35435243400","Artificial intelligence assisted acute patient journey","2022","Frontiers in Artificial Intelligence","5","","962165","","","","10.3389/frai.2022.962165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140588037&doi=10.3389%2ffrai.2022.962165&partnerID=40&md5=e8fbabca87168e0eb2a0d23b9ef8c95a","Artificial intelligence is taking the world by storm and soon will be aiding patients in their journey at the hospital. The trials and tribulations of the healthcare system during the COVID-19 pandemic have set the stage for shifting healthcare from a physical to a cyber-physical space. A physician can now remotely monitor a patient, admitting them only if they meet certain thresholds, thereby reducing the total number of admissions at the hospital. Coordination, communication, and resource management have been core issues for any industry. However, it is most accurate in healthcare. Both systems and providers are exhausted under the burden of increasing data and complexity of care delivery, increasing costs, and financial burden. Simultaneously, there is a digital transformation of healthcare in the making. This transformation provides an opportunity to create systems of care that are artificial intelligence-enabled. Healthcare resources can be utilized more justly. The wastage of financial and intellectual resources in an overcrowded healthcare system can be avoided by implementing IoT, telehealth, and AI/ML-based algorithms. It is imperative to consider the design principles of the patient's journey while simultaneously prioritizing a better user experience to alleviate physician concerns. This paper discusses the entire blueprint of the AI/ML-assisted patient journey and its impact on healthcare provision. Copyright © 2022 Nazir, Mushhood Ur Rehman, Asghar and Kalia.","2-s2.0-85140588037"
"Dasgupta D.; Sen S.","Dasgupta, Dipankar (7103226630); Sen, Sajib (57203189507)","7103226630; 57203189507","An empirical study of algorithmic bias","2022","Handbook On Computer Learning And Intelligence","2-2","","","895","922","27","10.1142/9789811247323_0023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142915623&doi=10.1142%2f9789811247323_0023&partnerID=40&md5=25acf9c354162333ec4fa4dd328df0a7","In all goal-oriented selection activities, the existence of a certain level of bias is unavoidable and may be desired for efficient AI-based decision support systems. However, a fair, independent comparison of all eligible entities is essential to alleviate explicit biasness in a competitive marketplace. For example, searching online for a good or a service, it is expected that the underlying algorithm will provide fair results by searching all available entities in the search category mentioned. However, a biased search can make a narrow or collaborative query, ignoring competitive outcomes, resulting in it costing the customers more or getting lower-quality products or services for the resources (money) they spend. This chapter describes algorithmic biases in different contexts with real-life case studies, examples, and scenarios; it provides best practices to detect and remove algorithmic bias. © 2022 World Scientific Publishing Company.","2-s2.0-85142915623"
"Kumbhar M.; Vishwakarma V.; Jain R.","Kumbhar, Mrudgandh (58265514300); Vishwakarma, Vinay (58580210200); Jain, Reetu (58067163700)","58265514300; 58580210200; 58067163700","A Logical Agent Approach to Solving the Wumpus World Problem: An Analysis of Game Trees","2023","2023 9th International Conference on Advanced Computing and Communication Systems, ICACCS 2023","","","","1839","1844","5","10.1109/ICACCS57279.2023.10113041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159769934&doi=10.1109%2fICACCS57279.2023.10113041&partnerID=40&md5=35bac88c7d428e15a1c8075b60eb42b2","The Wumpus World problem is a classic AI challenge in which an agent must navigate a maze-like environment to find and retrieve gold while avoiding obstacles such as pits and a monster called the Wumpus. This project aims to implement a logical agent to solve the Wumpus World problem using a combination of first-order logic and the Minimax algorithm. The environment is represented as a set of logical propositions. The agent's knowledge base is expressed as a set of first-order logic rules describing the relationships between the propositions. The Minimax algorithm is used to generate a game tree and compute the minimax values of the nodes in the tree, allowing the agent to make informed decisions about which actions to take. The implementation demonstrates the versatility and expressiveness of logical agents for solving complex AI problems and highlights the potential benefits of using first-order logic in AI systems. © 2023 IEEE.","2-s2.0-85159769934"
"Samad S.; Ahmed F.; Naher S.; Kabir M.A.; Das A.; Amin S.; Islam S.M.S.","Samad, Sabiha (57830387600); Ahmed, Fahmida (57435041600); Naher, Samsun (57830576500); Kabir, Muhammad Ashad (36630601000); Das, Anik (57226374028); Amin, Sumaiya (57217255097); Islam, Sheikh Mohammed Shariful (56400111100)","57830387600; 57435041600; 57830576500; 36630601000; 57226374028; 57217255097; 56400111100","Smartphone apps for tracking food consumption and recommendations: Evaluating artificial intelligence-based functionalities, features and quality of current apps","2022","Intelligent Systems with Applications","15","","200103","","","","10.1016/j.iswa.2022.200103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135390556&doi=10.1016%2fj.iswa.2022.200103&partnerID=40&md5=a7f6ea69074108c7baf14b90cc20dba7","The advancement of artificial intelligence (AI) and the significant growth in the use of food consumption tracking and recommendation-related apps in the app stores have created a need for an evaluation system, as minimal information is available about the evidence-based quality and technological advancement of these apps. Electronic searches were conducted across three major app stores and the selected apps were evaluated by three independent raters. A total of 473 apps were found and 80 of them were selected for review based on inclusion and exclusion criteria. An app rating tool is devised to evaluate the selected apps. Our rating tool assesses the apps essential features, AI based advanced functionalities and software quality characteristics required for food consumption tracking and recommendations, as well as their usefulness to general users. The rating tool's internal consistency, as well as inter- and intra-rater reliability among raters, are also calculated. Users’ comments from the app stores are collected and evaluated to better understand their expectations and perspectives. Following an evaluation of the assessed applications, design considerations that emphasize automation-based approaches using artificial intelligence are proposed. According to our assessment, most mobile apps in the app stores do not satisfy the overall requirements for tracking food consumption and recommendations. “Foodvisor” is the only app that can automatically recognise food items, and compute the recommended volume and nutritional information of that food item. However, these features need to be improvised in the food consumption tracking and recommendation apps. This study provides both researchers and developers with an insight into current state-of-the-art apps and design guidelines with necessary information on essential features and software quality characteristics for designing and developing a better app. © 2022 The Author(s)","2-s2.0-85135390556"
"Dasgupta P.; Kliem J.","Dasgupta, Prithviraj (7201405936); Kliem, John (56154837000)","7201405936; 56154837000","Improved Reinforcement Learning in Asymmetric Real-time Strategy Games via Strategy Diversity","2023","International Journal of Serious Games","10","1","","19","38","19","10.17083/ijsg.v10i1.548","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153337074&doi=10.17083%2fijsg.v10i1.548&partnerID=40&md5=05ef8ec36e96ea3d5554cf40892a56c9","We investigate the use of artificial intelligence (AI)-based techniques in learning to play a 2-player, real-time strategy (RTS) game called Hunting-of-the-Plark. The game is challenging to play for both humans and AI-based techniques because players cannot observe each other’s moves while playing the game and one player is at a disadvantage due to the asymmetric nature of the game rules. We analyze the performance of different deep reinforcement learning algorithms to train software agents that can play the game. Existing reinforcement learning techniques for RTS games enable players to converge towards an equilibrium outcome of the game but usually do not facilitate further exploration of techniques to exploit and defeat the opponent. To address this shortcoming, we investigate techniques including self-play and strategy diversity that can be used by players to improve their performance beyond the equilibrium outcome. We observe that when players use self-play, their number of wins begins to cycle around an equilibrium value as each player quickly learns to outwit and defeat its opponent and vice-versa. Finally, we show that strategy diversity could be used as an effective means to alleviate the performance of the disadvantaged player caused by the asymmetric nature of the game. © 2023, Serious Games Society. All rights reserved.","2-s2.0-85153337074"
"Calegari R.; Sabbatini F.","Calegari, Roberta (23134796300); Sabbatini, Federico (57200964844)","23134796300; 57200964844","The PSyKE Technology for Trustworthy Artificial Intelligence","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13796 LNAI","","","3","16","13","10.1007/978-3-031-27181-6_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151061620&doi=10.1007%2f978-3-031-27181-6_1&partnerID=40&md5=3209b9df02b30e8d14d566b9267640dd","Transparency is one of the “Ethical Principles in the Context of AI Systems” as described in the Ethics Guidelines for Trustworthy Artificial Intelligence (TAI). It is closely linked to four other principles – respect for human autonomy, prevention of harm, traceability and explainability – and involves numerous ways in which opaqueness can have undesirable impacts, such as discrimination, inequality, segregation, marginalisation, and manipulation. The opaqueness of many AI tools and the inability to understand the underpinning black boxes contradicts these principles as well as prevents people from fully trusting them. In this paper we discuss the PSyKE technology, a platform providing general-purpose support to symbolic knowledge extraction from different sorts of black-box predictors via many extraction algorithms. The extracted knowledge results are easily injectable into existing AI assets making them meet the transparency TAI requirement. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85151061620"
"Narteni S.; Ferretti M.; Rampa V.; Mongelli M.","Narteni, Sara (57220574684); Ferretti, Melissa (57203499432); Rampa, Vittorio (6603275866); Mongelli, Maurizio (7005882346)","57220574684; 57203499432; 6603275866; 7005882346","Bag-of-Words Similarity in eXplainable AI","2023","Lecture Notes in Networks and Systems","543 LNNS","","","835","851","16","10.1007/978-3-031-16078-3_58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138318393&doi=10.1007%2f978-3-031-16078-3_58&partnerID=40&md5=04a20129753bfde80c25257c028a2625","eXplainable AI (XAI) does not only lie in the interpretation of the rules generated by AI systems, but also in the evaluation and selection, among many rules automatically generated by large datasets, of those that are more relevant and meaningful for domain experts. With this work, we propose a method for evaluation of similarity between rules, which identifies similar rules, or very different ones, by exploiting techniques developed for Natural Language Processing (NLP). We evaluate the similarity of if-then rules by interpreting them as sentences and generating a similarity matrix acting as an enabler for domain experts to analyse the generated rules and thus discover new knowledge. Rule similarity may be applied to rule analysis and manipulation in different scenarios: the first one deals with rule analysis and interpretation, while the second scenario refers to pruning unnecessary rules within a single ruleset. Rule similarity allows also the automatic comparison and evaluation of rulesets. Two different examples are provided to evaluate the effectiveness of the proposed method for rules analysis for knowledge extraction and rule pruning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85138318393"
"Zacharias J.; von Zahn M.; Chen J.; Hinz O.","Zacharias, Jan (57998933100); von Zahn, Moritz (57225204668); Chen, Johannes (57557485400); Hinz, Oliver (14033045500)","57998933100; 57225204668; 57557485400; 14033045500","Designing a feature selection method based on explainable artificial intelligence","2022","Electronic Markets","32","4","","2159","2184","25","10.1007/s12525-022-00608-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142888081&doi=10.1007%2fs12525-022-00608-1&partnerID=40&md5=e9bbf03e2a79c76946bb1b0125350c38","Nowadays, artificial intelligence (AI) systems make predictions in numerous high stakes domains, including credit-risk assessment and medical diagnostics. Consequently, AI systems increasingly affect humans, yet many state-of-the-art systems lack transparency and thus, deny the individual’s “right to explanation”. As a remedy, researchers and practitioners have developed explainable AI, which provides reasoning on how AI systems infer individual predictions. However, with recent legal initiatives demanding comprehensive explainability throughout the (development of an) AI system, we argue that the pre-processing stage has been unjustifiably neglected and should receive greater attention in current efforts to establish explainability. In this paper, we focus on introducing explainability to an integral part of the pre-processing stage: feature selection. Specifically, we build upon design science research to develop a design framework for explainable feature selection. We instantiate the design framework in a running software artifact and evaluate it in two focus group sessions. Our artifact helps organizations to persuasively justify feature selection to stakeholders and, thus, comply with upcoming AI legislation. We further provide researchers and practitioners with a design framework consisting of meta-requirements and design principles for explainable feature selection. © 2022, The Author(s).","2-s2.0-85142888081"
"Nazarian S.; Koo H.F.; Carrington E.; Darzi A.; Patel N.","Nazarian, S. (57221924320); Koo, H.F. (58112983900); Carrington, E. (58113448600); Darzi, A. (14633357600); Patel, N. (55891876300)","57221924320; 58112983900; 58113448600; 14633357600; 55891876300","The future of endoscopy–what are the thoughts on artificial intelligence?","2023","Journal of Experimental and Theoretical Artificial Intelligence","","","","","","","10.1080/0952813X.2023.2178516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148632742&doi=10.1080%2f0952813X.2023.2178516&partnerID=40&md5=83ef57c5f4c0b011a5954ec68cb202cc","There is an emerging role of artificial intelligence (AI) in endoscopy with studies on early systems showing promising results. However, various limitations inhibit widespread use. The aim of this study was to ascertain the sentiments of endoscopists and understand the benefits and barriers towards adoption of AI systems into healthcare. An anonymous online 18-question survey was disseminated to gastroenterology and surgical departments across UK. A total of 75 endoscopists completed the questionnaire. The majority felt that AI would increase adenoma detection rate (ADR) (72.8%) and aid lesion characterisation (78.6%). However, only a quarter of respondents were either moderately or very familiar with AI, and there was no consensus on necessity of AI in endoscopy. The key barriers identified were cost, accessibility and lack of guidelines. Endoscopists believe AI systems will have a positive impact on endoscopy; however, these systems must provide quality assurance through large clinical trials before adoption. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","2-s2.0-85148632742"
"Simhadri N.; Swamy T.N.V.R.","Simhadri, Naga (58249836600); Swamy, T.N.V.R. (56096145300)","58249836600; 56096145300","Awareness among teaching on AI and ML applications based on fuzzy in education sector at USA","2023","Soft Computing","","","","","","","10.1007/s00500-023-08329-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159275752&doi=10.1007%2fs00500-023-08329-z&partnerID=40&md5=70eacc5c6229b428e53fc39834567da0","This paper summarises the level of knowledge held by educators in the United States on the use of artificial intelligence and machine learning in the classroom. The education industry seems to have reaped little benefits from the AI & ML industry's growth thus far. In any event, the creation of new ML & AI-based systems is mostly aimed towards areas with higher societal needs, such as medical diagnostics and individual transportation, rather than institutions of higher education. With this analysis, we want to shed some light on the mysterious state of application development in the US education industry. The report was written using a triangulation of research approaches to achieve this objective. First, we surveyed the current state-of-the-art reports from other countries and reviewed the relevant literature on AI & ML applications in the field of education. In the second phase, we analysed, to the extent possible, official documents from the United States education sector that dealt with AI and ML based on fuzzy digitalization initiatives. Third, in order to corroborate and expand upon the impressions received from the relevant literature and the document analysis, 15 guideline-based expert interviews were undertaken. Based on this data, we provide a selection of the AI & ML systems in use in universities and colleges now, analyse the benefits and drawbacks of implementing them, and speculate on their potential future evolution. While it would be a stretch to say that this paper presents a comprehensive overview of the subject, it does provide light on key areas of application and potential future research directions for AI and ML. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","2-s2.0-85159275752"
"Xu Y.","Xu, Yifan (58606650500)","58606650500","Dialogue Explanation with Reasoning for AI","2022","AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","","","","918","","","10.1145/3514094.3539522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137160869&doi=10.1145%2f3514094.3539522&partnerID=40&md5=34f03f96941a3ae4d980df2d9792449e","Explainable Artificial Intelligence is increasingly gaining attention in domains, such as self-driving cars and medical treatment. One of the most prevalent issues with these explainable models is that they are difficult to comprehend and have not been tested in real-world scenarios. In this research, I propose a dialogue-based explanation with reasoning for a rule-based system with the intention of utilising it in the future with a Neuro Symbolic AI system, to give machines the capacity to explain their actions or decisions using logic. We hypothesize that when a system makes a deduction that was, in some way, unexpected by the user then locating the source of the disagreement or misunderstanding is best achieved through a collaborative dialogue process that allows the participants to gradually isolate the cause. I also conduct a user evaluation for this hypothesis.  © 2022 Owner/Author.","2-s2.0-85137160869"
"Niehaus S.; Hartwig M.; Rosen P.H.; Wischniewski S.","Niehaus, Susanne (57812356200); Hartwig, Matthias (55788688400); Rosen, Patricia H. (57195321627); Wischniewski, Sascha (16647985500)","57812356200; 55788688400; 57195321627; 16647985500","An Occupational Safety and Health Perspective on Human in Control and AI","2022","Frontiers in Artificial Intelligence","5","","868382","","","","10.3389/frai.2022.868382","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134575597&doi=10.3389%2ffrai.2022.868382&partnerID=40&md5=c6697f0673ad4d753fb93d1c488fab8b","The continuous and rapid development of AI-based systems comes along with an increase in automation of tasks and, therewith, a qualitative shift in opportunities and challenges for occupational safety and health. A fundamental aspect of humane working conditions is the ability to exert influence over different aspects of one's own work. Consequently, stakeholders contribute to the prospect of maintaining the workers' autonomy albeit increasing automation and summarize this aspiration with the human in control principle. Job control has been part of multiple theories and models within the field of occupational psychology. However, most of the models do not include specific technical considerations nor focus on task but rather on job level. That is, they are possibly not able to fully explain specific changes regarding the digitalization of tasks. According to the results of a large-scale study on German workers (DiWaBe), this seems to be the case to some extend: the influence of varying degrees of automation, moderated by perceived autonomy, on workers' wellbeing was not consistent. However, automation is a double-edged sword: on a high level, it can be reversely related to the workers' job control while highly autonomous and reliable systems can also create opportunities for more flexible, impactful and diverse working tasks. Consequently, automation can foster and decrease the factor of job control. Models about the optimal level of automation aim to give guidelines on how the former can be achieved. The results of the DiWaBe study indicate that automation in occupational practice does not always happen in line with these models. Instead, a substantial part of automation happens at the decision-making level, while executive actions remain with the human. From an occupational safety and health perspective, it is therefore crucial to closely monitor and anticipate the implementation of AI in working systems. Constellations where employees are too controlled by technology and are left with a high degree of demands and very limited resources should be avoided. Instead, it would be favorable to use AI as an assistance tool for the employees, helping them to gather and process information and assisting them in decision-making. Copyright © 2022 Niehaus, Hartwig, Rosen and Wischniewski.","2-s2.0-85134575597"
"Wu D.","Wu, Di (57225007897)","57225007897","Good for tech: Disability expertise and labor in China’s artificial intelligence sector","2023","First Monday","28","1","","","","","10.5210/fm.v28i1.12887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153350508&doi=10.5210%2ffm.v28i1.12887&partnerID=40&md5=69d5fdd565e0408815f9c9d4cc4988e6","People with disabilities are often perceived as being “given” the opportunity to work, rather than “providing” valuable labor. Centering on disabled data workers as experts involved in the quotidian construction of artificial intelligence (AI) systems in China, this article shows that disability expertise and labor can afford a technical edge to AI systems in a certain political economy. In the case examined, the work of consistently synchronizing interpretations of the ambiguous data and elusive rules of smart home systems prefers a stable annotation workforce with coordinated cognition and trained judgment. This technical demand has come to be met by a committed team of skilled disabled workers, who are pushed out from mainstream job market by systemic ableism, and pulled in by disability-informed expertise that reconfigures space, time, and political economy to meet non-normative bodyminds. Through this exceptional case run by a disabled people led organization, I draw attention to disabled people’s underexamined role as system-builders of information technologies as opposed to users, victims, or inspirations, and highlight the transformative potential of disability expertise © This paper is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License","2-s2.0-85153350508"
"Choi S.-W.; Lee E.-B.","Choi, So-Won (57226501136); Lee, Eul-Bum (7406967942)","57226501136; 7406967942","Contractor’s Risk Analysis of Engineering Procurement and Construction (EPC) Contracts Using Ontological Semantic Model and Bi-Long Short-Term Memory (LSTM) Technology","2022","Sustainability (Switzerland)","14","11","6938","","","","10.3390/su14116938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132049524&doi=10.3390%2fsu14116938&partnerID=40&md5=4d91f38ad73a0a4f3276b960e488ce29","The development of intelligent information technology in the era of the fourth industrial revolution requires the EPC (engineering, procurement, and construction) industry to increase productivity through a digital transformation. This study aims to automatically analyze the critical risk clauses in the invitation to bid (ITB) at the bidding stage to strengthen their competitiveness for the EPC contractors. To this end, we developed an automated analysis technology that effectively analyzes a large amount of ITB documents in a short time by applying natural language processing (NLP) and bi-directional long short-term memory (bi-LSTM) algorithms. This study proposes two models. First, the semantic analysis (SA) model is a rule-based approach that applies NLP to extract key risk clauses. Second, the risk level ranking (RLR) model is a train-based approach that ranks the risk impact for each clause by applying bi-LSTM. After developing and training an artificial intelligent (AI)-based ITB analysis model, its performance was evaluated through the actual project data. As a result of validation, the SA model showed an F1 score of 86.4 percent, and the RLR model showed an accuracy of 46.8 percent. The RLR model displayed relatively low performance because the ITB used in the evaluation test included the contract clauses that did not exist in the training dataset. Therefore, this study illustrated that the rule-based approach performed superior to the training-based method. The authors suggest that EPC contractors should apply both the SA and RLR modes in the ITB analysis, as one supplements the other. The two models were embedded in the Engineering Machine-learning Automation Platform (EMAP), a cloud-based platform developed by the authors. Rapid analysis through applying both the rule-based and AI-based automatic ITB analysis technology can contribute to securing timeliness for risk response and supplement possible human mistakes in the bidding stage. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85132049524"
"Deshpande A.; Sharp H.","Deshpande, Advait (55569540800); Sharp, Helen (7101843009)","55569540800; 7101843009","Responsible AI Systems: Who are the Stakeholders?","2022","AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","","","","227","236","9","10.1145/3514094.3534187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137153372&doi=10.1145%2f3514094.3534187&partnerID=40&md5=7e696a3c4694e0a18b327a2f3225b74d","As of 2021, there were more than 170 guidelines on AI ethics and responsible, trustworthy AI in circulation according to the AI Ethics Guidelines Global Inventory maintained by AlgorithmWatch, an organisation which tracks the effects of increased digitalisation on everyday lives. However, from the perspective of day-To-day work, for those engaged in designing, developing, and maintaining AI systems identifying relevant guidelines and translating them into practice presents a challenge. The aim of this paper is to help anyone engaged in building a responsible AI system by identifying an indicative long-list of potential stakeholders. This list of impacted stakeholders is intended to enable such AI system builders to decide which guidelines are most suited to their practice. The paper draws on a literature review of articles short-listed based on searches conducted in the ACM Digital Library and Google Scholar. The findings are based on content analysis of the short-listed literature guided by probes which draw on the ISO 26000:2010 Guidance on social responsibility. The paper identifies three levels of potentially relevant stakeholders when responsible AI systems are considered: individual stakeholders (including users, developers, and researchers), organisational stakeholders, and national / international stakeholders engaged in making laws, rules, and regulations. The main intended audience for this paper is software, requirements, and product engineers engaged in building AI systems. In addition, business executives, policy makers, legal/regulatory experts, AI researchers, public, private, and third sector organisations developing responsible AI guidelines, and anyone interested in seeing functional responsible AI systems are the other intended audience for this paper.  © 2022 ACM.","2-s2.0-85137153372"
"Hort M.; Moussa R.; Sarro F.","Hort, Max (57218601709); Moussa, Rebecca (57192194949); Sarro, Federica (36631133800)","57218601709; 57192194949; 36631133800","Multi-objective search for gender-fair and semantically correct word embeddings","2023","Applied Soft Computing","133","","109916","","","","10.1016/j.asoc.2022.109916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145659097&doi=10.1016%2fj.asoc.2022.109916&partnerID=40&md5=dfa9d08080c70386cd51747b9f49cab3","Fairness is a crucial non-functional requirement of modern software systems that rely on the use of Artificial Intelligence (AI) to make decisions regarding our daily lives in application domains such as justice, healthcare and education. In fact, these algorithms can exhibit unwanted discriminatory behaviours that create unfair outcomes when the software is used, such as giving privilege to one group of users over another (e.g., males vs. females). Mitigating algorithmic bias during the development life cycle of AI-enabled software is crucial given that any bias in these algorithms is inherited by the software systems using them. However, previous work has shown that mitigating bias can impact the performance of such systems. Therefore, we propose herein a novel use of soft computing for improving AI-enabled software fairness. Specifically, we exploit multi-objective search, as opposed to previous work optimising fairness only, to strike an optimal balance between reducing gender bias and improving semantic correctness of word embedding models, which are at the core of many AI-enabled systems. To assess the effectiveness of our proposal, we carry out a thorough empirical study based on the most recent best practice for the evaluation of search-based approaches and AI-enabled software. We explore seven different search-based approaches, and benchmark them against both baseline and state-of-the-art approaches applied to a popular and widely used word embedding model, namely WORD2VEC. Our results show that multi-objective search outperforms single-objective search, and generates word embeddings that are strictly better than the original ones in both objectives, bias and semantic correctness, for all investigated cases. Additionally, our approach generates word embeddings of higher semantic correctness than those generated by using state-of-the-art techniques in all cases, while also achieving a higher degree of fairness in 67% of the cases. These findings show the feasibility and effectiveness of multi-objective search as a tool for engineers to incorporate fair and accurate word embedding models in their AI-enabled systems. © 2022 The Author(s)","2-s2.0-85145659097"
"Costanza-Chock S.; Raji I.D.; Buolamwini J.","Costanza-Chock, Sasha (39963436200); Raji, Inioluwa Deborah (57206671199); Buolamwini, Joy (55855559500)","39963436200; 57206671199; 55855559500","Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem","2022","ACM International Conference Proceeding Series","","","","1571","1583","12","10.1145/3531146.3533213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133022250&doi=10.1145%2f3531146.3533213&partnerID=40&md5=1dbffc1736286e0c2b235dea2bdb8a42","Algorithmic audits (or g AI audits') are an increasingly popular mechanism for algorithmic accountability; however, they remain poorly defined. Without a clear understanding of audit practices, let alone widely used standards or regulatory guidance, claims that an AI product or system has been audited, whether by first-, second-, or third-party auditors, are difficult to verify and may potentially exacerbate, rather than mitigate, bias and harm. To address this knowledge gap, we provide the first comprehensive field scan of the AI audit ecosystem. We share a catalog of individuals (N=438) and organizations (N=189) who engage in algorithmic audits or whose work is directly relevant to algorithmic audits; conduct an anonymous survey of the group (N=152); and interview industry leaders (N=10). We identify emerging best practices as well as methods and tools that are becoming commonplace, and enumerate common barriers to leveraging algorithmic audits as effective accountability mechanisms. We outline policy recommendations to improve the quality and impact of these audits, and highlight proposals with wide support from algorithmic auditors as well as areas of debate. Our recommendations have implications for lawmakers, regulators, internal company policymakers, and standards-setting bodies, as well as for auditors. They are: 1) require the owners and operators of AI systems to engage in independent algorithmic audits against clearly defined standards; 2) notify individuals when they are subject to algorithmic decision-making systems; 3) mandate disclosure of key components of audit findings for peer review; 4) consider real-world harm in the audit process, including through standardized harm incident reporting and response mechanisms; 5) directly involve the stakeholders most likely to be harmed by AI systems in the algorithmic audit process; and 6) formalize evaluation and, potentially, accreditation of algorithmic auditors. © 2022 ACM.","2-s2.0-85133022250"
"Velmurugan K.J.; Srinivasan P.; Gayathri A.; Yuvarani S.","Velmurugan, K. Jayasakthi (58141896000); Srinivasan, P. (57225300804); Gayathri, A. (57610371900); Yuvarani, S. (57079085500)","58141896000; 57225300804; 57610371900; 57079085500","Melanoma Boundaries Detection Techniques using Artificial Intelligence","2023","Proceedings of the 3rd International Conference on Artificial Intelligence and Smart Energy, ICAIS 2023","","","","647","651","4","10.1109/ICAIS56108.2023.10073936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152381679&doi=10.1109%2fICAIS56108.2023.10073936&partnerID=40&md5=bcb6bdb45993e8663bca2c72c765dd6e","Melanoma is the 6th most successive disease in the United States, with more than 9000 individuals kicking the bucket every year. Fast acknowledgment of melanoma expands an individual's life expectancy, but further developed analytic advancements are as yet required. Skin injury limit anomaly, which addresses the ""B""includes in the ""ABCD rule"", is viewed as a critical clinical component for the early discovery of melanoma. What's more, blue-white line structure evacuation additionally further develops the identification proficiency. In this paper, an AI based location method for distinguishing skin injury limit inconsistencies is presented. The technique involves extricating the skin injury from the dermoscopic images, recognizing the skin sore line, estimating line inconsistency, and prepared famous directed learning models called SVM, RF, DT, and gathering move learning calculations to distinguish line anomaly naturally, bringing about a true choice on whether the skin sore boundary is customary or unpredictable. The method produces excellent results, with 92.6 percent accuracy, 91.3 percent sensitivity, 92.5 percent specificity, and 95.1 percent F-Score, respectively. © 2023 IEEE.","2-s2.0-85152381679"
"Shahrzad H.; Hodjat B.; Miikkulainen R.","Shahrzad, Hormoz (6504609025); Hodjat, Babak (6507712371); Miikkulainen, Risto (7003434895)","6504609025; 6507712371; 7003434895","Evolving explainable rule sets","2022","GECCO 2022 Companion - Proceedings of the 2022 Genetic and Evolutionary Computation Conference","","","","1779","1784","5","10.1145/3520304.3534023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136337765&doi=10.1145%2f3520304.3534023&partnerID=40&md5=cc8bea4795887808a2607f11afb13cab","Most AI systems work like black boxes tasked with generating reasonable outputs for given inputs. Many domains, however, have explainablity and trustworthiness requirements not fulfilled by these approaches. Various methods exist to analyze or interpret black-box models post training. When it comes down to sensitive domains in which there is a mandate for white-box models, a better choice would be to use transparent models. In this work, we present a method which evolves explainable rule-sets using inherently transparent ordinary logic to make models. We showcase some sample domains we tackled and discuss their major desirable properties like bias detection, knowledge discovery, and modifiablity, to name a few. © 2022 ACM.","2-s2.0-85136337765"
"Chu C.; Nyrup R.; Donato-Woodger S.; Leslie K.; Khan S.; Bernett C.; Grenier A.","Chu, Charlene (55496539800); Nyrup, Rune (57024139100); Donato-Woodger, Simon (57218317338); Leslie, Kathleen (56937989400); Khan, Shehroz (8693268700); Bernett, Corinne (57809764400); Grenier, Amanda (8334738000)","55496539800; 57024139100; 57218317338; 56937989400; 8693268700; 57809764400; 8334738000","Examining the technology-mediated cycles of injustice that contribute to digital ageism: Advancing the conceptualization of digital ageism: evidence and implications","2022","ACM International Conference Proceeding Series","","","","545","551","6","10.1145/3529190.3534765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134433542&doi=10.1145%2f3529190.3534765&partnerID=40&md5=3da5b3eed659bda345cc2cd7fa7feff7","Our work draws attention to digital ageism referring to the nexus of ageism (discrimination or bias related to age) that is mediated and perpetuated by artificial intelligent (AI) systems and technologies. Building on the World Health Organization's recently published policy brief entitled ""Ageism in AI for Health""and our previous work about digital ageism, this paper aims to advance our current understanding and conceptualization of digital ageism in technology and AI systems broadly and beyond health alone. To do this, we will 1) elaborate on our conceptual model and the ageist technology-mediated cycles of injustice that can produce and reinforce digital ageism; 2) present empirical evidence of our descriptive analysis of seven commonly used facial image datasets to highlight data disparities for older adults which will provide real-world evidence that substantiates one of the elements in our ageist cycles of injustice; and 3) summarize results from our grey literature search of various grey literature databases including the AI ethics guidelines Global Inventory to identify guidance documents that address ageism in AI in research or technology development. This paper uniquely contributes conceptual and empirical evidence of digital ageism which will advance knowledge in the field and deepen our understanding of how ageism in AI is fostered by broader ageist cycles of injustice. Lastly, we will briefly provide future considerations to address digital ageism.  © 2022 ACM.","2-s2.0-85134433542"
"Okazaki K.; Inoue K.","Okazaki, Kotaro (56542550400); Inoue, Katsumi (35748800500)","56542550400; 35748800500","Explainable Model Fusion for Customer Journey Mapping","2022","Frontiers in Artificial Intelligence","5","","824197","","","","10.3389/frai.2022.824197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130995699&doi=10.3389%2ffrai.2022.824197&partnerID=40&md5=eaedec5b0f3f349bb9d1d3f882fc1427","Due to advances in computing power and internet technology, various industrial sectors are adopting IT infrastructure and artificial intelligence (AI) technologies. Recently, data-driven predictions have attracted interest in high-stakes decision-making. Despite this, advanced AI methods are less often used for such tasks. This is because AI technology is a black box for the social systems it is meant to support; trustworthiness and fairness have not yet been established. Meanwhile in the field of marketing, strategic decision-making is a high-stakes problem that has a significant impact on business trends. For global marketing, with its diverse cultures and market environments, future decision-making is likely to focus on building consensus on the formulation of the problem itself rather than on solutions for achieving the goal. There are two important and conflicting facts: the fact that the core of domestic strategic decision-making comes down to the formulation of the problem itself, and the fact that it is difficult to realize AI technology that can achieve problem formulation. How can we resolve this difficulty with current technology? This is the main challenge for the realization of high-level human-AI systems in the marketing field. Thus, we propose customer journey mapping (CJM) automation through model-level data fusion, a process for the practical problem formulation known as explainable alignment. Using domain-specific requirements and observations as inputs, the system automatically outputs a CJM. Explainable alignment corresponds with both human and AI perspectives and in formulating the problem, thereby improving strategic decision-making in marketing. Following preprocessing to make latent variables and their dynamics transparent with latent Dirichlet allocation and a variational autoencoder, a post-hoc explanation is implemented in which a hidden Markov model and learning from an interpretation transition are combined with a long short-term memory architecture that learns sequential data between touchpoints for extracting attitude rules for CJM. Finally, we realize the application of human-AI systems to strategic decision-making in marketing with actual logs in over-the-top media services, in which the dynamic behavior of customers for CJM can be automatically extracted. Copyright © 2022 Okazaki and Inoue.","2-s2.0-85130995699"
"Kenthapadi K.; Lakkaraju H.; Natarajan P.; Sameki M.","Kenthapadi, Krishnaram (12239006400); Lakkaraju, Himabindu (37104369800); Natarajan, Pradeep (57221511785); Sameki, Mehrnoosh (55515620900)","12239006400; 37104369800; 57221511785; 55515620900","Model Monitoring in Practice: Lessons Learned and Open Challenges","2022","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","4800","4801","1","10.1145/3534678.3542617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137144890&doi=10.1145%2f3534678.3542617&partnerID=40&md5=52e9e71a36a997099747894171cba4d5","Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges. In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.  © 2022 Owner/Author.","2-s2.0-85137144890"
"Brauner P.; Hick A.; Philipsen R.; Ziefle M.","Brauner, Philipp (35228685600); Hick, Alexander (58175607200); Philipsen, Ralf (56244848800); Ziefle, Martina (6602475572)","35228685600; 58175607200; 56244848800; 6602475572","What does the public think about artificial intelligence?—A criticality map to understand bias in the public perception of AI","2023","Frontiers in Computer Science","5","","1113903","","","","10.3389/fcomp.2023.1113903","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151962980&doi=10.3389%2ffcomp.2023.1113903&partnerID=40&md5=d3d35cbd6fff1458d01d44baa2b11a04","Introduction: Artificial Intelligence (AI) has become ubiquitous in medicine, business, manufacturing and transportation, and is entering our personal lives. Public perceptions of AI are often shaped either by admiration for its benefits and possibilities, or by uncertainties, potential threats and fears about this opaque and perceived as mysterious technology. Understanding the public perception of AI, as well as its requirements and attributions, is essential for responsible research and innovation and enables aligning the development and governance of future AI systems with individual and societal needs. Methods: To contribute to this understanding, we asked 122 participants in Germany how they perceived 38 statements about artificial intelligence in different contexts (personal, economic, industrial, social, cultural, health). We assessed their personal evaluation and the perceived likelihood of these aspects becoming reality. Results: We visualized the responses in a criticality map that allows the identification of issues that require particular attention from research and policy-making. The results show that the perceived evaluation and the perceived expectations differ considerably between the domains. The aspect perceived as most critical is the fear of cybersecurity threats, which is seen as highly likely and least liked. Discussion: The diversity of users influenced the evaluation: People with lower trust rated the impact of AI as more positive but less likely. Compared to people with higher trust, they consider certain features and consequences of AI to be more desirable, but they think the impact of AI will be smaller. We conclude that AI is still a “black box” for many. Neither the opportunities nor the risks can yet be adequately assessed, which can lead to biased and irrational control beliefs in the public perception of AI. The article concludes with guidelines for promoting AI literacy to facilitate informed decision-making. Copyright © 2023 Brauner, Hick, Philipsen and Ziefle.","2-s2.0-85151962980"
"Radclyffe C.; Ribeiro M.; Wortham R.H.","Radclyffe, Charles (58154189600); Ribeiro, Mafalda (57216819946); Wortham, Robert H. (57194335737)","58154189600; 57216819946; 57194335737","The assessment list for trustworthy artificial intelligence: A review and recommendations","2023","Frontiers in Artificial Intelligence","6","","1020592","","","","10.3389/frai.2023.1020592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150727471&doi=10.3389%2ffrai.2023.1020592&partnerID=40&md5=fae41ca213bd3b3c292216d6a5d6b265","In July 2020, the European Commission's High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as Environmental Sustainability, Social Justice, and Corporate Governance (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry. Copyright © 2023 Radclyffe, Ribeiro and Wortham.","2-s2.0-85150727471"
"Liu Y.; Yang K.","Liu, Yusha (57199717193); Yang, Kun (57208327746)","57199717193; 57208327746","Communication, sensing, computing and energy harvesting in smart cities","2022","IET Smart Cities","4","4","","265","274","9","10.1049/smc2.12041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137826871&doi=10.1049%2fsmc2.12041&partnerID=40&md5=d17e6a9b019acbec8e081858b8dec393","A smart city provides diverse services based on real-time data obtained from different devices deployed in urban areas. These devices are largely battery-powered and widely placed. Therefore, providing continuous energy to these devices and ensuring their efficient sensing and communications are critical for the wide deployment of smart cities. To achieve frequent and effective data exchange, advanced enabling information and communication technology (ICT) infrastructure is in urgent demand. An ideal network in future smart cities should be capable of sensing the physical environment and intelligently mapping the digital world. Therefore, in this paper, we propose design guidelines on how to integrate communications with sensing, computing and/or energy harvesting in the context of smart cities, aiming to offer research insights on developing integrated communications, sensing, computing and energy harvesting (ICSCE) for promoting the development ICT infrastructure in smart cities. To put these four pillars of smart cities together and to take advantage of ever-increasing artificial intelligence (AI) technologies, the authors propose a promising AI-enabled ICSCE architecture by leveraging the digital twin network. The proposed architecture models the physical deep neural network-aided ICSCE system in a virtual space, where offline training is performed by using the collected real-time data from the environment and physical devices. © 2022 The Authors. IET Smart Cities published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","2-s2.0-85137826871"
"Pullagura L.; Kumari N.V.; Bhuyan H.K.; Ghantasala G.S.P.","Pullagura, Lokaiah (57218201112); Kumari, Nalli Vinaya (57218509194); Bhuyan, Hemanta Kumar (54957384400); Ghantasala, G.S. Pradeep (57208258862)","57218201112; 57218509194; 54957384400; 57208258862","Biomedical data analysis and processing using explainable artificial intelligence and responsive artificial intelligence","2022","Mobile Health: Advances in Research and Applications - Volume II","","","","127","156","29","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141409033&partnerID=40&md5=5e9ea877f8596b52247f3c1782c3e1ef","Medicine and biomedical sciences ensure developed data-intensive arenas, at the same time, allowing the application of data-driven methods and necessitating refined data processing and data analysis methods. Biomedical informatics affords an appropriate interdisciplinary circumstance to assimilate information and data when dispensation accessible information, with the intention of generous operative decision-making maintenance in translational and clinic research. Potential applications in the biomedical field comprise the instinctive identification of entrant biomarkers on behalf of a disease or analytic of a treatment reaction, and the edifice of prognostic or diagnostic rules manipulating these biomarkers. These procedures being generic, they could be pragmatic to numerous causes of data and biomedical/biological requests. Nowadays, in medical applications, the growth of procedures for explaining, visualizing, and interpreting deep learning replicas has freshly appealed to cumulative attention. Interpretable Machine Learning (IML) or Explainable Machine Learning (XAI) programs are intended to generate a complement of machine learning procedures that yield additional explainable models while upholding a high level of accurateness. It moreover empowers users to comprehend, applicably trust, and effectively achieve the evolving cohort of artificially intelligent associates. The XAI befits more and more decisive for deep learning-powered applications, exclusively for healthcare and medical studies. A pace elsewhere XAI is Responsive AI (RAI), which symbolizes a set of moralities to have happened when arranging AI-based classifications in practical circumstances: Fairmindedness, Human-Centric, Explainability Accountability, Privacy Awareness, Security and Safety. Owed to the flora of amenities and the liability of an enormous segment of patrons, the theme of accountable AI is necessary to convert the focus of prevalent learning and conversation. The main idea underlying the concept of Biomedical Data Analysis and Processing is extracting knowledge from the very large amount of medical data which is available in the form of signals and images, with a very large amount of variables. © 2022 Nova Science Publishers, Inc.","2-s2.0-85141409033"
"Tien P.W.; Wei S.; Darkwa J.; Wood C.; Calautit J.K.","Tien, Paige Wenbin (57207847056); Wei, Shuangyu (57209367453); Darkwa, Jo (55805429300); Wood, Christopher (56962756600); Calautit, John Kaiser (54787297700)","57207847056; 57209367453; 55805429300; 56962756600; 54787297700","Machine Learning and Deep Learning Methods for Enhancing Building Energy Efficiency and Indoor Environmental Quality – A Review","2022","Energy and AI","10","","100198","","","","10.1016/j.egyai.2022.100198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136150981&doi=10.1016%2fj.egyai.2022.100198&partnerID=40&md5=02e7abb51a0c192bd1bd44fcfc0ecebe","The built environment sector is responsible for almost one-third of the world's final energy consumption. Hence, seeking plausible solutions to minimise building energy demands and mitigate adverse environmental impacts is necessary. Artificial intelligence (AI) techniques such as machine and deep learning have been increasingly and successfully applied to develop solutions for the built environment. This review provided a critical summary of the existing literature on the machine and deep learning methods for the built environment over the past decade, with special reference to holistic approaches. Different AI-based techniques employed to resolve interconnected problems related to heating, ventilation and air conditioning (HVAC) systems and enhance building performances were reviewed, including energy forecasting and management, indoor air quality and occupancy comfort/satisfaction prediction, occupancy detection and recognition, and fault detection and diagnosis. The present study explored existing AI-based techniques focusing on the framework, methodology, and performance. The literature highlighted that selecting the most suitable machine learning and deep learning model for solving a problem could be challenging. The recent explosive growth experienced by the research area has led to hundreds of machine learning algorithms being applied to building performance-related studies. The literature showed that existing research studies considered a wide range of scope/scales (from an HVAC component to urban areas) and time scales (minute to year). This makes it difficult to find an optimal algorithm for a specific task or case. The studies also employed a wide range of evaluation metrics, adding to the challenge. Further developments and more specific guidelines are required for the built environment field to encourage best practices in evaluating and selecting models. The literature also showed that while machine and deep learning had been successfully applied in building energy efficiency research, most of the studies are still at the experimental or testing stage, and there are limited studies which implemented machine and deep learning strategies in actual buildings and conducted the post-occupancy evaluation. © 2022","2-s2.0-85136150981"
"Sadeghi D.; Shoeibi A.; Ghassemi N.; Moridian P.; Khadem A.; Alizadehsani R.; Teshnehlab M.; Gorriz J.M.; Khozeimeh F.; Zhang Y.-D.; Nahavandi S.; Acharya U.R.","Sadeghi, Delaram (57219763771); Shoeibi, Afshin (57193554372); Ghassemi, Navid (57211581674); Moridian, Parisa (57219761470); Khadem, Ali (57027659100); Alizadehsani, Roohallah (55328861400); Teshnehlab, Mohammad (23006417100); Gorriz, Juan M. (7004736801); Khozeimeh, Fahime (57191575180); Zhang, Yu-Dong (35786830100); Nahavandi, Saeid (55992860000); Acharya, U Rajendra (7004510847)","57219763771; 57193554372; 57211581674; 57219761470; 57027659100; 55328861400; 23006417100; 7004736801; 57191575180; 35786830100; 55992860000; 7004510847","An overview of artificial intelligence techniques for diagnosis of Schizophrenia based on magnetic resonance imaging modalities: Methods, challenges, and future works","2022","Computers in Biology and Medicine","146","","105554","","","","10.1016/j.compbiomed.2022.105554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130093735&doi=10.1016%2fj.compbiomed.2022.105554&partnerID=40&md5=c40435b916eaae706ad71c6c4efa1791","Schizophrenia (SZ) is a mental disorder that typically emerges in late adolescence or early adulthood. It reduces the life expectancy of patients by 15 years. Abnormal behavior, perception of emotions, social relationships, and reality perception are among its most significant symptoms. Past studies have revealed that SZ affects the temporal and anterior lobes of hippocampus regions of the brain. Also, increased volume of cerebrospinal fluid (CSF) and decreased volume of white and gray matter can be observed due to this disease. Magnetic resonance imaging (MRI) is the popular neuroimaging technique used to explore structural/functional brain abnormalities in SZ disorder, owing to its high spatial resolution. Various artificial intelligence (AI) techniques have been employed with advanced image/signal processing methods to accurately diagnose SZ. This paper presents a comprehensive overview of studies conducted on the automated diagnosis of SZ using MRI modalities. First, an AI-based computer aided-diagnosis system (CADS) for SZ diagnosis and its relevant sections are presented. Then, this section introduces the most important conventional machine learning (ML) and deep learning (DL) techniques in the diagnosis of diagnosing SZ. A comprehensive comparison is also made between ML and DL studies in the discussion section. In the following, the most important challenges in diagnosing SZ are addressed. Future works in diagnosing SZ using AI techniques and MRI modalities are recommended in another section. Results, conclusion, and research findings are also presented at the end. © 2022 Elsevier Ltd","2-s2.0-85130093735"
"Vakkuri V.; Kemell K.-K.; Tolvanen J.; Jantunen M.; Halme E.; Abrahamsson P.","Vakkuri, Ville (57203640458); Kemell, Kai-Kristian (57203633786); Tolvanen, Joel (57753617100); Jantunen, Marianna (57217089350); Halme, Erika (57222063097); Abrahamsson, Pekka (7006011356)","57203640458; 57203633786; 57753617100; 57217089350; 57222063097; 7006011356","How Do Software Companies Deal with Artificial Intelligence Ethics? A Gap Analysis","2022","ACM International Conference Proceeding Series","","","","100","109","9","10.1145/3530019.3530030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132379594&doi=10.1145%2f3530019.3530030&partnerID=40&md5=886987920452a5aa41c719c87e8969af","The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the ""The Ethics Guidelines for Trustworthy Artificial Intelligence"". The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies. © 2022 ACM.","2-s2.0-85132379594"
"Yu Z.; Yang X.; Sweeting G.L.; Ma Y.; Stolte S.E.; Fang R.; Wu Y.","Yu, Zehao (57226392302); Yang, Xi (57203172777); Sweeting, Gianna L. (57315752900); Ma, Yinghan (57220605484); Stolte, Skylar E. (57209971096); Fang, Ruogu (36720287600); Wu, Yonghui (55645924700)","57226392302; 57203172777; 57315752900; 57220605484; 57209971096; 36720287600; 55645924700","Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods","2022","BMC Medical Informatics and Decision Making","22","","255","","","","10.1186/s12911-022-01996-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138896942&doi=10.1186%2fs12911-022-01996-2&partnerID=40&md5=2c6f06b1403a20f2728762d4c6b28a62","Background: Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports. Methods: In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including ‘gold-standard’ setting—where gold-standard concepts were used–and end-to-end setting. Results: For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores. Conclusions: This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it’s necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better. © 2022, The Author(s).","2-s2.0-85138896942"
"Kuehnel K.; Au-Yong-oliveira M.","Kuehnel, Klaus (57671498400); Au-Yong-oliveira, Manuel (57218856174)","57671498400; 57218856174","The Development of an Information Technology Architecture for Automated, Agile and Versatile Companies with Ecological and Ethical Guidelines","2022","Informatics","9","2","37","","","","10.3390/informatics9020037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129611828&doi=10.3390%2finformatics9020037&partnerID=40&md5=13c879e3442cf3e31b405d2485a1d327","Based on many years of experience as a management consultant in different industries and corporate structures and cultures, the motivation to use digital transformation in connection with variable corporate goals—such as fluctuating workloads, agile response to customer inquiries, and ecological and economic sustainability—results in a process or a product to be developed that intelligently adapts to market requirements and requires forward-looking leadership. Using an AI-based methodical analysis and synthesis approach, the high consumption of economic and human resources is to be continuously monitored and optimization measures initiated at an early stage. The necessary information technology with its infrastructure and architecture is the starting point to accompany the agility and changeability of corporate goals. Researching the relevant documents begins with writing the panorama or the state of knowledge on the topic. This article is about the IT infrastructure based on the requirements for an architecture and behavior that a versatile, agile company needs to accompany the constantly changing framework conditions of the market. The technology used and the available resources, including the human resources, need to be adapted as early as possible. Data now represent the most valuable asset on Earth and future industrial manufacturing systems must maximize the opportunity of data usage. Low-level data must be transformed to make them useful in supporting intelligent decision-making, for example. Furthermore, future manufacturing systems must be highly productive, adaptable, absent of error, and kind to the environment and to local communities. The all-important design should minimize the waste of material, capital, energy, and media. Herein, we discuss the fulfilling of agile customer requirements involving adaptable and modulated production processes (related to the ‘agile manufacturing’ and ‘digital transformation’ perspectives). © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85129611828"
"Wang H.; Ren Z.; Yu Z.; Zhang Y.; Liu J.; Cui H.","Wang, Hui (56165776400); Ren, Zhuoli (57821984500); Yu, Zhiwen (16178409600); Zhang, Yao (57194837082); Liu, Jiaqi (56487280400); Cui, Heilei (57020559500)","56165776400; 57821984500; 16178409600; 57194837082; 56487280400; 57020559500","CoupHM: Task Scheduling Using Gradient Based Optimization for Human-Machine Computing Systems","2023","Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS","2023-January","","","859","866","7","10.1109/ICPADS56603.2022.00116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152905788&doi=10.1109%2fICPADS56603.2022.00116&partnerID=40&md5=d3f42fb606086cc42fa2c3eb8f9cbea7","We witnessed great advancement in Artificial Intelligence (AI) powered technologies in recent years, and yet, when applied to certain high-stake contexts, such as medical diagnosis, automatic driving and criminal justice, they are not qualified. This matter can be greatly settled by Human-Machine Computing (HMC), which is an effective computing paradigm that couples the expertise and demonstration abilities of humans with the high-performance computing power of machines. This work studies an optimal task scheduling problem for HMC systems, where various tasks are decomposed and dispatched to humans and AI-enabled machines to provide significantly better benefits compared to either type of computing resources in isolation. However, designing such optimal task scheduling is challenging because of the stochastic hybrid features of machines, as well as various human professional abilities. Considering the Quality of Service (QoS) and the heterogeneity of human-machine computing resources, we propose CoupHM, a feasible task scheduler using gradient based optimization for HMC systems. In particular, we firstly present the underlying architecture of HMC system and details of the task-driven workload model. On that basis, we then formulate the objective optimization problem to be solved and describe the composition of the CoupHM scheduler. Finally, the performance of our solution is evaluated by the simulation experiments, and the results indicate that the proposed scheduler has preferable performance both in balancing resources and guaranteeing QoS, which can serve as guidelines for future research on HMC systems. © 2023 IEEE.","2-s2.0-85152905788"
"Tapeh A.T.G.; Naser M.Z.","Tapeh, Arash Teymori Gharah (57814470500); Naser, M.Z. (35189338400)","57814470500; 35189338400","Artificial Intelligence, Machine Learning, and Deep Learning in Structural Engineering: A Scientometrics Review of Trends and Best Practices","2023","Archives of Computational Methods in Engineering","30","1","","115","159","44","10.1007/s11831-022-09793-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134657391&doi=10.1007%2fs11831-022-09793-w&partnerID=40&md5=adf72b00faf56b8ea478c0c0fa56cc1e","Artificial Intelligence (AI), machine learning (ML), and deep learning (DL) are emerging techniques capable of delivering elegant and affordable solutions which can surpass those obtained through traditional methods. Despite the recent and rapid advancements in developing next-gen AI-based techniques, we continue to lack a systemic understanding of how AI, ML, and DL can fundamentally be integrated into the structural engineering domain. To advocate for a smooth and expedite the adoption of AI techniques into our field, we present a state-of-the-art review that is specifically tailored to structural engineers. This review aims to serve three purposes: (1) introduce the art and science of AI, ML, and DL in terms of its commonly used algorithms and techniques with particular attention to those of high value to this domain, (2) map the current knowledge within this domain through a scientometrics analysis of more than 4000 scholarly works with a focus on those published in the last decade to identify best practices in terms of procedures, performance metrics, and dataset size etc., and (3) review past and recent efforts that applied AI derivatives into the various subfields within structural engineering. Special attention is given to the application of AI, ML, and DL in earthquake, wind, and fire engineering, as well as structural health monitoring, damage detection, and prediction of properties of structural materials as collected from over 200 sources. Finally, a discussion on trends, recommendations, best practices, and advanced topics towards the end of this review. © 2022, The Author(s) under exclusive licence to International Center for Numerical Methods in Engineering (CIMNE).","2-s2.0-85134657391"
"Nguyen T.-L.; Kavuri S.; Park S.-Y.; Lee M.","Nguyen, Tuan-Linh (57754841100); Kavuri, Swathi (34881754200); Park, Soo-Yeon (57612850100); Lee, Minho (57191730119)","57754841100; 34881754200; 57612850100; 57191730119","Attentive Hierarchical ANFIS with interpretability for cancer diagnostic","2022","Expert Systems with Applications","201","","117099","","","","10.1016/j.eswa.2022.117099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128737625&doi=10.1016%2fj.eswa.2022.117099&partnerID=40&md5=73988b7db218c859d39c16b53b8771fd","Prediction of clinical outcomes using the patient's medical data enhances clinical decision making and improves prognostic accuracy. Deep learning (DL) for medical decision support systems has particularly shown expert-level accuracy in predicting clinical outcomes. However, most of these machine learning and Artificial Intelligent (AI) models lack interpretability which causes major trust-related problems in healthcare. This necessitates the need for interpretable AI systems that can explain their decisions. This paper is designed to address the problem of how clinical decision support systems can be designed to be transparent, interpretable and therefore comprehensible for humans. In this view, this paper proposes an attentive hierarchical adaptive neuro-fuzzy inference system (AH-ANFIS), that combines fuzzy inference in a hierarchical architecture with attention for selecting the important rules. The proposed model benefits from the rule-based structure of ANFIS that enables the user to interpret the abstractions of hidden layers. The hierarchical structure in fuzzy modeling helps to overcome the rule explosion problem that arises with large medical data and improve interpretability. To ensure the improvement of interpretability with hierarchical architecture, an evolutionary algorithm (EA) is used to decompose the input space into an optimal permutation of input subsets which results in subsystems with independent meaning. The attention-based rule selector identifies the most activated rule to select important patient-specific features for predicting the clinical outcome. To verify the performance of the proposed AH-ANFIS and analyze the important features for classification, we perform experiments with two cancer diagnostic datasets. By pruning fuzzy if-then rules using recursive rule elimination (RRE), the complexity of the model is largely reduced while maintaining the performance of the system making it more interpretable. © 2022 Elsevier Ltd","2-s2.0-85128737625"
"Ao S.","Ao, Shuang (57226330806)","57226330806","Building Safe and Reliable AI Systems for Safety Critical Tasks with Vision-Language Processing","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13982 LNCS","","","423","428","5","10.1007/978-3-031-28241-6_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151049574&doi=10.1007%2f978-3-031-28241-6_47&partnerID=40&md5=f65db8297166370e9271a7e3b7d23a75","Although AI systems have been applied in various fields and achieved impressive performance, their safety and reliability are still a big concern. This is especially important for safety-critical tasks. One shared characteristic of these critical tasks is their risk sensitivity, where small mistakes can cause big consequences and even endanger life. There are several factors that could be guidelines for the successful deployment of AI systems in sensitive tasks: (i) failure detection and out-of-distribution (OOD) detection; (ii) overfitting identification; (iii) uncertainty quantification for predictions; (iv) robustness to data perturbations. These factors are also challenges of current AI systems, which are major blocks for building safe and reliable AI. Specifically, the current AI algorithms are unable to identify common causes for failure detection. Furthermore, additional techniques are required to quantify the quality of predictions. All these contribute to inaccurate uncertainty quantification, which lowers trust in predictions. Hence obtaining accurate model uncertainty quantification and its further improvement are challenging. To address these issues, many techniques have been proposed, such as regularization methods and learning strategies. As vision and language are the most typical data type and have many open source benchmark datasets, this thesis will focus on vision-language data processing for tasks like classification, image captioning, and vision question answering. In this thesis, we aim to build a safeguard by further developing current techniques to ensure the accurate model uncertainty for safety-critical tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85151049574"
"Usmani U.A.; Happonen A.; Watada J.","Usmani, Usman Ahmad (57226748630); Happonen, Ari (35585858000); Watada, Junzo (57189052014)","57226748630; 35585858000; 57189052014","Enhancing Artificial Intelligence Control Mechanisms: Current Practices, Real Life Applications and Future Views","2023","Lecture Notes in Networks and Systems","559 LNNS","","","287","306","19","10.1007/978-3-031-18461-1_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141727958&doi=10.1007%2f978-3-031-18461-1_19&partnerID=40&md5=b80865813b7aadc87a9aa520ee790cee","The popularity of Artificial Intelligence has grown lately with the potential it promises for revolutionizing a wide range of different sectors. To achieve the change, whole community must overcome the Machine Learning (ML) related explainability barrier, an inherent obstacle of current sub symbolism-based approaches, e.g. in Deep Neural Networks, which was not existing during the last AI hype time including some expert and rule-based systems. Due to lack of transparency, privacy, biased systems, lack of governance and accountability, our society demands toolsets to create responsible AI solutions for enabling of unbiased AI systems. These solutions will help business owners to create AI applications which are trust enhancing, open and transparent and also explainable. Properly made systems will enhance trust among employees, business leaders, customers and other stakeholders. The process of overseeing artificial intelligence usage and its influence on related stakeholders belongs to the context of AI Governance. Our work gives a detailed overview of a governance model for Responsible AI, emphasizing fairness, model explainability, and responsibility in large-scale AI technology deployment in real-world organizations. Our goal is to provide the model developers in an organization to understand the Responsible AI with a comprehensive governance framework that outlines the details of the different roles and the key responsibilities. The results work as reference for future research is aimed to encourage area experts from other disciplines towards embracement of AI in their own business sectors, without interpretability shortcoming biases. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85141727958"
"Kreminski M.; Dickinson M.; Wardrip-Fruin N.; Mateas M.","Kreminski, Max (57203113523); Dickinson, Melanie (57211160353); Wardrip-Fruin, Noah (6507322880); Mateas, Michael (57206356074)","57203113523; 57211160353; 6507322880; 57206356074","Loose Ends: A Mixed-Initiative Creative Interface for Playful Storytelling","2022","Proceedings - AAAI Artificial Intelligence and Interactive Digital Entertainment Conference, AIIDE","18","1","","120","128","8","10.1609/aiide.v18i1.21955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144285887&doi=10.1609%2faiide.v18i1.21955&partnerID=40&md5=8897bbcdb08780b587bbe9ee2267297f","We present Loose Ends, a mixed-initiative co-creative storytelling play experience in which a human player and an AI system work together to compose a story. Loose Ends specifically aims to provide computational support for managing multiple parallel plot threads and bringing these threads to satisfying conclusions—something that has proven difficult in past attempts to facilitate playful mixed-initiative storytelling. We describe the overall human-AI interaction loop in Loose Ends, including the implementation of the rules-based AI system that enables this interaction loop; discuss four examples of desirable mixed-initiative interactions that are possible in Loose Ends, but not in similar systems; and present results from a preliminary expert evaluation of Loose Ends. Altogether, we find that Loose Ends shows promise for creating a sense of coauthorship in the player while also mitigating the directionlessness reported by players of earlier systems. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85144285887"
"Goldstein J.; Weitzman D.; Lemerond M.; Jones A.","Goldstein, Juli (57736265500); Weitzman, Dena (58303854800); Lemerond, Meghan (58303145800); Jones, Andrew (58304025400)","57736265500; 58303854800; 58303145800; 58304025400","Determinants for scalable adoption of autonomous AI in the detection of diabetic eye disease in diverse practice types: key best practices learned through collection of real-world data","2023","Frontiers in Digital Health","5","","1004130","","","","10.3389/fdgth.2023.1004130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161033814&doi=10.3389%2ffdgth.2023.1004130&partnerID=40&md5=d0dab30c25507942d60bb57f3936791b","Autonomous Artificial Intelligence (AI) has the potential to reduce disparities, improve quality of care, and reduce cost by improving access to specialty diagnoses at the point-of-care. Diabetes and related complications represent a significant source of health disparities. Vision loss is a complication of diabetes, and there is extensive evidence supporting annual eye exams for prevention. Prior to the use of autonomous AI, store-and-forward imaging approaches using remote reading centers (asynchronous telemedicine) attempted to increase diabetes related eye exams with limited success. In 2018, after rigorous clinical validation, the first fully autonomous AI system [LumineticsCore™ (formerly IDx-DR), Digital Diagnostics Inc., Coralville, IA, United States] received U.S. Food and Drug Administration (FDA) De Novo authorization. The system diagnoses diabetic retinopathy (including macular edema) without specialist physician overread at the point-of-care. In addition to regulatory clearance, reimbursement, and quality measure updates, successful adoption requires local optimization of the clinical workflow. The general challenges of frontline care clinical workflow have been well documented in the literature. Because healthcare AI is so new, there remains a gap in the literature about challenges and opportunities to embed diagnostic AI into the clinical workflow. The goal of this review is to identify common workflow themes leading to successful adoption, measured as attainment number of exams per month using the autonomous AI system against targets set for each health center. We characterized the workflow in four different US health centers over a 12-month period. Health centers were geographically dispersed across the Midwest, Southwest, Northeast, and West Coast and varied distinctly in terms of size, staffing, resources, financing and demographics of patient populations. After 1 year, the aggregated number of diabetes-related exams per month increased from 89 after the first month of initial deployment to 174 across all sites. Across the diverse practice types, three primary determinants underscored sustainable adoption: (1) Inclusion of Executive and Clinical Champions; (2) Underlining Health Center Resources; and (3) Clinical workflows that contemplate patient identification (pre-visit), LumineticsCore Exam Capture and Provider Consult (patient visit), and Timely Referral Triage (post-visit). In addition to regulatory clearance, reimbursement and quality measures, our review shows that addressing the core determinants for workflow optimization is an essential part of large-scale adoption of innovation. These best practices can be generalizable to other autonomous AI systems in front-line care settings, thereby increasing patient access, improving quality of care, and addressing health disparities. 2023 Goldstein, Weitzman, Lemerond and Jones.","2-s2.0-85161033814"
"Hoda R.","Hoda, Rashina (26643938800)","26643938800","Socio-Technical Grounded Theory for Software Engineering","2022","IEEE Transactions on Software Engineering","48","10","","3808","3832","24","10.1109/TSE.2021.3106280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113342741&doi=10.1109%2fTSE.2021.3106280&partnerID=40&md5=549a29f87e7b42b5df682a53c8a13a88","Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence. © 1976-2012 IEEE.","2-s2.0-85113342741"
"Lee Y.; Lee E.; Lee T.","Lee, Yongsoo (57226770294); Lee, Eungyu (57226766304); Lee, Taejin (57223752078)","57226770294; 57226766304; 57223752078","Human-Centered Efficient Explanation on Intrusion Detection Prediction","2022","Electronics (Switzerland)","11","13","2082","","","","10.3390/electronics11132082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133125755&doi=10.3390%2felectronics11132082&partnerID=40&md5=d5624b4a9c6c6d248e182bb8884fbb90","The methodology for constructing intrusion detection systems and improving existing systems is being actively studied in order to detect harmful data within large-capacity network data. The most common approach is to use AI systems to adapt to unanticipated threats and improve system performance. However, most studies aim to improve performance, and performance-oriented systems tend to be composed of black box models, whose internal working is complex. In the field of security control, analysts strive for interpretation and response based on information from given data, system prediction results, and knowledge. Consequently, performance-oriented systems suffer from a lack of interpretability owing to the lack of system prediction results and internal process information. The recent social climate also demands a responsible system rather than a performance-focused one. This research aims to ensure understanding and interpretation by providing interpretability for AI systems in multiple classification environments that can detect various attacks. In particular, the better the performance, the more complex and less transparent the model and the more limited the area that the analyst can understand, the lower the processing efficiency accordingly. The approach provided in this research is an intrusion detection methodology that uses FOS based on SHAP values to evaluate if the prediction result is suspicious and selects the optimal rule from the transparent model to improve the explanation. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85133125755"
"Setiawan R.; Ganga R.R.; Velayutham P.; Thangavel K.; Sharma D.K.; Rajan R.; Krishnamoorthy S.; Sengan S.","Setiawan, Roy (57216745785); Ganga, Ramakoteswara Rao (56781559100); Velayutham, Priya (58021757500); Thangavel, Kumaravel (57222980522); Sharma, Dilip Kumar (57219005491); Rajan, Regin (57208682999); Krishnamoorthy, Sujatha (57209005934); Sengan, Sudhakar (55008255500)","57216745785; 56781559100; 58021757500; 57222980522; 57219005491; 57208682999; 57209005934; 55008255500","Encrypted Network Traffic Classification and Resource Allocation with Deep Learning in Software Defined Network","2022","Wireless Personal Communications","127","1","","749","765","16","10.1007/s11277-021-08403-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103390660&doi=10.1007%2fs11277-021-08403-5&partnerID=40&md5=8ef4a4402ce3817c5ee124540758d9af","The climate has changed absolutely in every area in just a few years as digitized, making high-speed internet service a significant need in the future. Future Internet is supposed to face exponential growth in traffic, and highly complicated infrastructure, threatening to make conventional NTC approaches unreliable and even counterproductive. In recent days, AI Stimulated state-of-the-art breakthroughs with the ability to tackle extensive and multifarious challenges, and the network community is initiated by considering the NTC prototype from legacy rule-based towards a novel AI-based. Design and execution are applied to interdisciplinary become more essential. A smart home network supports various applications and smart devices within the proposed work, including e-health devices, regular computing devices, and home automation devices. Many devices accessible through the Internet by Home GateWay for Congestion (HGC) in a smart home. Throughout this paper, a Software-Defined Network Home GateWay for Congestion (SDNHGC) architecture for improved management of remote smart home networks and protection of the significant network's SDN controller. It enables effective network capacity regulation, focused on real-time traffic analysis and core network resource allocation. It cannot control the Network in dispersed smart homes. Our innovative SDNHGC expands power across the connectivity network, a smart home network enabling improved end-to-end monitoring of networks. The planned SDNHGC directly will gain centralized device identification by classifying traffic through a smart home network. Several of the current traffic classifications approach, checking deep packets, cannot have this real-time device knowledge for encrypted data to solve this issue. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","2-s2.0-85103390660"
"Cole M.; Cant C.; Ustek Spilda F.; Graham M.","Cole, Matthew (57823787200); Cant, Callum (57215675339); Ustek Spilda, Funda (57208577115); Graham, Mark (55536168100)","57823787200; 57215675339; 57208577115; 55536168100","Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work","2022","Frontiers in Artificial Intelligence","5","","869114","","","","10.3389/frai.2022.869114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135191923&doi=10.3389%2ffrai.2022.869114&partnerID=40&md5=18279634b0c5c9903d7370e8cdf2e045","Calls for “ethical Artificial Intelligence” are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing “ethical AI” remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work. Copyright © 2022 Cole, Cant, Ustek Spilda and Graham.","2-s2.0-85135191923"
"Charran R.S.; Dubey R.K.","Charran, R. Shree (57807522700); Dubey, Rahul Kumar (57205667288)","57807522700; 57205667288","Two-Wheeler Vehicle Traffic Violations Detection and Automated Ticketing for Indian Road Scenario","2022","IEEE Transactions on Intelligent Transportation Systems","23","11","","22002","22007","5","10.1109/TITS.2022.3186679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134317512&doi=10.1109%2fTITS.2022.3186679&partnerID=40&md5=01427d38d7e8e4718b54a542295f09c1","Traffic violation monitoring and control is a major concern in India due to excess crowd, increasing commuters, bad traffic signal management, and rider mentality. It is obvious that physical traffic police-based monitoring alone is insufficient to monitor such large traffic volumes and simultaneously track violations. This has led to many violators going unnoticed. The violators, in turn, cause more serious mishaps on the road resulting in danger to their own life as well as to other's life. Thus, there is a need for incorporating Artificial Intelligence (AI)-based techniques to eliminate manual intervention for the detection and catching of violators. In this paper, we propose a system to automatically detect two-wheeler violations like not wearing a helmet, usage of a phone while riding, triple riding, wheeling, and illegal parking for Indian road scenarios and eventually automating the ticketing process by capturing the violations and corresponding vehicle number in a database. We propose using a custom trained Yolo-v4 + DeepSORT for violation detection and tracking and Yolo-v4 + Tesseract for number plate detection and extraction. This implementation obtained a mean average precision (mAP) of 98.09% for violation detection and an accuracy of 99.41% for number plate detection on the test data. Further, the system detected 77 out of 93 violations with zero false positives in real-life scenarios. Thus,showing that the traffic violation system developed can be used to automate traffic violation ticketing. The developed system would be particularly useful in deriving various safety-related policies and will help to enforce strong regulation of traffic rules and build towards a smart city ecosystem via the automated AI-based traffic violation and ticketing system. © 2000-2011 IEEE.","2-s2.0-85134317512"
"Mohammadi S.; Alinaghi S.A.S.; Heydari M.; Pashaei Z.; Mirzapour P.; Karimi A.; Afsahi A.M.; Mirghaderi P.; Mohammadi P.; Arjmand G.; Soleimani Y.; Azarnoush A.; Mojdeganlou H.; Dashti M.; Cheshmekabodi H.A.; Varshochi S.; Mehrtak M.; Shamsabadi A.; Mehraeen E.; Hackett D.","Mohammadi, Samaneh (58194056600); Alinaghi, Seyed Ahmad Seyed (26647754800); Heydari, Mohammad (57205595669); Pashaei, Zahra (57224442980); Mirzapour, Pegah (56731109400); Karimi, Amirali (57441434100); Afsahi, Amir Masoud (57219597081); Mirghaderi, Peyman (57226428360); Mohammadi, Parsa (57468581700); Arjmand, Ghazal (57755275800); Soleimani, Yasna (57194611159); Azarnoush, Ayein (57221415101); Mojdeganlou, Hengameh (57225092959); Dashti, Mohsen (57372394700); Cheshmekabodi, Hadiseh Azadi (58189961100); Varshochi, Sanaz (57855948400); Mehrtak, Mohammad (56561935500); Shamsabadi, Ahmadreza (57210437579); Mehraeen, Esmaeil (56770172400); Hackett, Daniel (55060990800)","58194056600; 26647754800; 57205595669; 57224442980; 56731109400; 57441434100; 57219597081; 57226428360; 57468581700; 57755275800; 57194611159; 57221415101; 57225092959; 57372394700; 58189961100; 57855948400; 56561935500; 57210437579; 56770172400; 55060990800","Artificial Intelligence in COVID-19 Management: A Systematic Review","2023","Journal of Computer Science","19","5","","554","568","14","10.3844/jcssp.2023.554.568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153380701&doi=10.3844%2fjcssp.2023.554.568&partnerID=40&md5=8c6506fdd9d4a28bc88f11633cb10dbb","With the development of modern technologies in the field of healthcare, the use of Artificial Intelligence (AI) in disease management is increasing. AI methods may assist healthcare providers in the COVID-19 era. The current study aimed to observe the efficacy and importance of AI for managing the COVID-19 pandemic. An organized search was conducted, utilizing PubMed, Web of Science, Scopus, Embase, and Cochrane up to September 2022. Studies were considered qualified for inclusion if they met the inclusion criterion. We conducted review according to the Preferred Reporting Items for Systematic reviews and Meta Analyses (PRISMA) guidelines. There were 52 documents that met the eligibility criteria to be included in the review. The most common item using AI during the COVID-19 era was predictive models to foretell pneumonia and mortality risks in people with COVID-19 based on medical and experimental parameters. COVID-19 mortality was related to being male and elderly based on the Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) logistic regression analysis of demographics, clinical data, and laboratory tests of hospitalized COVID-19 patients. AI can predict, diagnose and model COVID-19 by using techniques such as support vector machines, decision trees, and neural networks. It is suggested that future research should deal with the design and development of AI-based tools for the management of chronic diseases such as COVID-19. © 2023 Samaneh Mohammadi, SeyedAhmad SeyedAlinaghi, Mohammad Heydari, Zahra Pashaei, Pegah Mirzapour, Amirali Karimi, Amir Masoud Afsahi, Peyman Mirghaderi, Parsa Mohammadi, Ghazal Arjmand, Yasna Soleimani, Ayein Azarnoush, Hengameh Mojdeganlou, Mohsen Dashti, Hadiseh Azadi Cheshmekabodi, Sanaz Varshochi, Mohammad Mehrtak, Ahmadreza Shamsabadi, Esmaeil Mehraeen, and Daniel Hackett. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.","2-s2.0-85153380701"
"Devagiri J.S.; Paheding S.; Niyaz Q.; Yang X.; Smith S.","Devagiri, Jeevan S. (57795234800); Paheding, Sidike (56585990900); Niyaz, Quamar (55191240800); Yang, Xiaoli (35774975600); Smith, Samantha (57211412692)","57795234800; 56585990900; 55191240800; 35774975600; 57211412692","Augmented Reality and Artificial Intelligence in industry: Trends, tools, and future challenges","2022","Expert Systems with Applications","207","","118002","","","","10.1016/j.eswa.2022.118002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133939651&doi=10.1016%2fj.eswa.2022.118002&partnerID=40&md5=09822ad9b075050dd57e6e59de25fbc3","Augmented Reality (AR) is an augmented depiction of reality formed by overlaying digital information on an image of objects being seen through a device. Artificial Intelligence (AI) techniques have experienced unprecedented growth and are being applied in various industries. The combination of AR and AI is the next prominent direction in upcoming years with many industries and academia recognizing the importance of their adoption. With the advancements in the silicone industry that push the boundaries of Moore's law, processors will be less expensive, more efficient, and power-optimized in the forthcoming years. This is a tremendous support and necessity for an AR boom, and with the help of AI, there is an excellent potential for smart industries to increase the production speed and workforce training along with improved manufacturing, error handling, assembly, and packaging. In this work, we provide a systematic review of recent advances, tools, techniques, and platforms of AI-empowered AR along with the challenges of using AI in AR applications. This paper will serve as a guideline for future research in the domain of AI-assisted AR in industrial applications. © 2022 Elsevier Ltd","2-s2.0-85133939651"
"Purificato E.; Lorenzo F.; Fallucchi F.; De Luca E.W.","Purificato, Erasmo (57201425697); Lorenzo, Flavio (57736332300); Fallucchi, Francesca (23392345500); De Luca, Ernesto William (14026533600)","57201425697; 57736332300; 23392345500; 14026533600","The Use of Responsible Artificial Intelligence Techniques in the Context of Loan Approval Processes","2023","International Journal of Human-Computer Interaction","39","7","","1543","1562","19","10.1080/10447318.2022.2081284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131725653&doi=10.1080%2f10447318.2022.2081284&partnerID=40&md5=81d120c4e1892e0f28ca99895376e457","Despite the existing skepticism about the use of automatic systems in contexts where human knowledge and experience are considered indispensable (e.g., the granting of a mortgage, the prediction of stock prices, or the detection of cancers), our work aims to show how the use of explainability and fairness techniques can lead to the growth of a domain expert’s trust and reliance on an artificial intelligence (AI) system. This article presents a system, applied to the context of loan approval processes, focusing on the two aforementioned ethical principles out of the four defined by the High-Level Expert Group on AI in the document “Ethics Guidelines for Trustworthy AI,” published in April 2019, in which the key requirements that AI systems should meet to be considered trustworthy are identified. The presented case study is realized within a proprietary framework composed of several components for supporting the user throughout the management of the whole life cycle of a machine learning model. The main approaches, consisting of providing an interpretation of the model’s outputs and monitoring the model’s decisions to detect and react to unfair behaviors, are described in more detail to compare our system within state-of-the-art related frameworks. Finally, a novel Trust & Reliance Scale is proposed for evaluating the system, and a usability test is performed to measure the user satisfaction with the effectiveness of the developed user interface; results are obtained, respectively, by the submission of the mentioned novel scale to bank domain experts and the usability questionnaire to a heterogeneous group composed of loan officers, data scientists, and researchers. © 2022 Taylor & Francis Group, LLC.","2-s2.0-85131725653"
"Fantechi A.; Gnesi S.; Semini L.","Fantechi, Alessandro (6701442229); Gnesi, Stefania (6603718373); Semini, Laura (6505993305)","6701442229; 6603718373; 6505993305","Rule-based NLP vs ChatGPT in Ambiguity Detection, a Preliminary Study","2023","CEUR Workshop Proceedings","3378","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158943732&partnerID=40&md5=a7599c00eec4fda6d1c561d99f5d64be","With the rapid advances of AI-based tools, the question of whether to use such tools or conventional rule-based tools often arises in many application domains. In this paper, we address this question when considering the issue of ambiguity in requirements documents. For this purpose, we consider GPT-3 that is the third-generation of the Generative Pretrained Transformer language model, developed by OpenAI and we compare its ambiguity detection capability with that of a publicly available rule-based NLP tool on a few example requirements documents. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85158943732"
"Chennamaneni S.; Pradhan P.; Chebolu V.; Vejendla M.; Kannaiah S.K.; Aravinth S.S.","Chennamaneni, Suprith (58244858300); Pradhan, Phalguni (58245583900); Chebolu, Varsha (58245584000); Vejendla, Manjunadh (58245584100); Kannaiah, Sathish Kumar (57204745177); Aravinth, S.S. (56084992700)","58244858300; 58245583900; 58245584000; 58245584100; 57204745177; 56084992700","Designing Cybersecurity AI Based Awareness Games for Citizens: Best Practices and Future Directions","2023","2nd International Conference on Sustainable Computing and Data Communication Systems, ICSCDS 2023 - Proceedings","","","","407","412","5","10.1109/ICSCDS56580.2023.10104800","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159090071&doi=10.1109%2fICSCDS56580.2023.10104800&partnerID=40&md5=062ddad8d2ab74b9e87683066b971c7b","Cybercrimes are a hazard to both people and businesses. Knowing the best techniques for cyber security is essential for defending against these threats. Despite their ability to be useful, conventional learning techniques like reading articles or attending seminars lack interest. Because of this, employing serious games for education is growing in popularity. Serious games give players an involved learning experience while educating them on a subject, like cyber security. In order to give players a useful understanding to defend themselves, this study investigates the best approaches for embedding cyber security education into serious games. Learning about cyber security is made enjoyable and more relevant by using a game-based methodology. In order to evaluate how game design aspects might be utilized to effectively instruct players on cyber security, the paper examines a variety of game design elements, including game mechanics, narrative, and feedback mechanisms. Additionally, it goes into how different players, such as novice and experienced players, might be catered to in serious games. In general, playing serious games is a fun and effective approach to educate yourself about cyber security. Designers and teachers can produce games that are both enjoyable and instructional by adhering to the quality standards described in this paper.  © 2023 IEEE.","2-s2.0-85159090071"
"Squadrone L.; Croce D.; Basili R.","Squadrone, Luca (57205117429); Croce, Danilo (27567467600); Basili, Roberto (7004280182)","57205117429; 27567467600; 7004280182","Ethics by Design for Intelligent and Sustainable Adaptive Systems","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13796 LNAI","","","154","167","13","10.1007/978-3-031-27181-6_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151051693&doi=10.1007%2f978-3-031-27181-6_11&partnerID=40&md5=7e13f5349b42ff976b72144125d63aad","AI systems are increasingly dependent on the data and information sources they are developed with. In particular, learning machines are highly exposed to undesirable problems due to biased and incomplete coverage of training data. The autonomy exhibited by machines trained on low-quality data raises an ethical concern, as it may infringe on social rules and security constraints. In this paper, we extensively experiment with a learning framework, called Ethics by Design, which aims to ensure a supervised learning policy that can pursue both the satisfaction of ethical constraints and the optimization of task (i.e., business) accuracy. The results obtained on tasks and datasets confirm the positive impact of the method in ensuring ethical compliance. This paves the way for a large set of industrial applications, whose ethical dimension is critical to increasing the trustworthiness with respect to this technology. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85151051693"
"Werner B.D.; Schumeg B.J.; Mills T.M.; Velilla E.V.","Werner, Benjamin D. (55249835100); Schumeg, Benjamin J. (57911298600); Mills, Tiffany M. (58191739300); Velilla, Elizabeth V. (9240367600)","55249835100; 57911298600; 58191739300; 9240367600","An Assurance Case for the DoD Ethical Principles of Artificial Intelligence","2023","Proceedings - Annual Reliability and Maintainability Symposium","2023-January","","","","","","10.1109/RAMS51473.2023.10088273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153266309&doi=10.1109%2fRAMS51473.2023.10088273&partnerID=40&md5=6692193afde7c90e08cb5735f444b78e","The Ethical Principles of Artificial Intelligence (AI) [1] laid out by the Defense Innovation Board were one of the first publications from the Department of Defense to outline the expectations for AI enabled systems and technologies. This document served as the first guidance for developing agencies and was reviewed to understand the requirements for these new systems. As engineers, the desire is to view the Ethical Principles as evaluation criteria and identify the means by which a system can be qualified against the language laid out by the Defense Innovation Board.One of the first parallels that was identified with this document was the concept of an assurance case. The Ethical Principles do not explicitly lay out any requirements but are more so suggestions or guidelines so the question was how to demonstrate adherence or fulfillment. To this extent the Materiel Release process [2], the process the U.S. Army follows to deploy and field a system, was reviewed as a means to demonstrate fulfillment through the requirements and documentation dictated by that process.This paper demonstrates how the processes and procedures followed by the U.S. Army, in pursuit of mitigating risks for fielding, also in turn fulfill the intent of the Ethical Principles. Upon further review of the principles, it can be observed as design best practices to ensure the development of trusted and assured products. The Materiel Release process is proposed as an assurance case for the adherence to the Ethical Principles of AI. The MR process and associated feeder processes are here compared to the language embodied in the Ethical Principles to the extent that the application of the same rigorous processes done for traditional systems may be applied to AI enabled systems-and in some cases adapted-to ensure justified confidence in the delivered product. Systems that have gone through a Materiel Release review can thus also be said to have demonstrated, as a byproduct, adherence to the Ethical Principles of AI. © 2023 IEEE.","2-s2.0-85153266309"
"Antal L.; Aubard M.; Ábrahám E.; Madureira A.; Madureira L.; Costa M.; Pinto J.; Campos R.","Antal, László (58183888700); Aubard, Martin (58010109600); Ábrahám, Erika (57203555979); Madureira, Ana (8634629500); Madureira, Luís (23009390300); Costa, Maria (57201981265); Pinto, José (21733438800); Campos, Renato (57224123006)","58183888700; 58010109600; 57203555979; 8634629500; 23009390300; 57201981265; 21733438800; 57224123006","A Collision Avoidance Method for Autonomous Underwater Vehicles Based on Long Short-Term Memories","2023","Lecture Notes in Networks and Systems","649 LNNS","","","448","457","9","10.1007/978-3-031-27499-2_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152533322&doi=10.1007%2f978-3-031-27499-2_42&partnerID=40&md5=d77c40e220352efc100dc7720b830eec","Over the past decades, underwater robotics has enjoyed growing popularity and relevance. While performing a mission, one crucial task for Autonomous Underwater Vehicles (AUVs) is bottom tracking, which should keep a constant distance from the seabed. Since static obstacles like walls, rocks, or shipwrecks can lie on the sea bottom, bottom tracking needs to be extended with obstacle avoidance. As AUVs face a wide range of uncertainties, implementing these essential operations is still challenging. A simple rule-based control method has been proposed in [7] to realize obstacle avoidance. In this work, we propose an alternative AI-based control method using a Long Short-Term Memory network. We compare the performance of both methods using real-world data as well as via a simulator. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85152533322"
"Elfiky N.","Elfiky, Noha (55341383700)","55341383700","Application of Artificial Intelligence in the Food Industry: AI-Based Automatic Pruning of Dormant Apple Trees","2023","Studies in Computational Intelligence","1000","","","1","15","14","10.1007/978-3-031-13702-0_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141734135&doi=10.1007%2f978-3-031-13702-0_1&partnerID=40&md5=aa80844b5754ca641e8f9b1f64f37c92","Automatic pruning is one of the most essential as well as expensive and labor-intensive procedure in specialty crop production. During winter, expert pruners are employed to remove certain primary branches of dormant trees based on a set of predefined rules. The end goal of the automatic pruning applications is to reduce dependence on this huge labor and associated humongous costs by automating the pruning decisions, which in turn would facilitate easy interface with intelligent robotic pruners. In this chapter, we have developed a robust 3D reconstruction scheme that utilizes color information in addition to the time-of-flight depth data from Kinect2 sensor for accurately modeling the trunk and primary branches of a dormant apple tree. The motivation behind incorporating color in our framework is to acquire accurate 3D tree reconstruction even in absence of quality depth data. Quantitative and qualitative comparisons of our proposed approach with a depth based reconstruction technique depicts the usefulness of using color information in our automatic pruning system. On average, the proposed scheme provides a performance of 93.94% accuracy for correctly identifying the branches, and 71.13 and 89.26% for correctly estimating the diameters of the primary branches within error margins of 3 mm and 5 mm respectively. Moreover, the time complexity of our proposed algorithm shows an improvement in order of magnitude over the complexity of the baseline approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85141734135"
"Dong S.U.I.; Lei Z.H.A.N.G.; Fei Y.A.N.G.","Dong, S.U.I. (58141653800); Lei, Z.H.A.N.G. (58141942300); Fei, Y.A.N.G. (57218531594)","58141653800; 58141942300; 57218531594","Data-driven based four examinations in TCM: a survey","2022","Digital Chinese Medicine","5","4","","377","385","8","10.1016/j.dcmed.2022.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150049697&doi=10.1016%2fj.dcmed.2022.12.004&partnerID=40&md5=b5b478e4824b06016e66a89f5ca7fb35","Traditional Chinese medicine (TCM) diagnosis is a unique disease diagnosis method with thousands of years of TCM theory and effective experience. Its thinking mode in the process is different from that of modern medicine, which includes the essence of TCM theory. From the perspective of clinical application, the four diagnostic methods of TCM, including inspection, auscultation and olfaction, inquiry, and palpation, have been widely accepted by TCM practitioners worldwide. With the rise of artificial intelligence (AI) over the past decades, AI based TCM diagnosis has also grown rapidly, marked by the emerging of a large number of data-driven deep learning models. In this paper, our aim is to simply but systematically review the development of the data-driven technologies applied to the four diagnostic approaches, i.e. the four examinations, in TCM, including data sets, digital signal acquisition devices, and learning based computational algorithms, to better analyze the development of AI-based TCM diagnosis, and provide references for new research and its applications in TCM settings in the future. © 2023 Digital Chinese Medicine","2-s2.0-85150049697"
"Khan A.A.; Badshah S.; Liang P.; Waseem M.; Khan B.; Ahmad A.; Fahmideh M.; Niazi M.; Akbar M.A.","Khan, Arif Ali (26434399300); Badshah, Sher (57218940314); Liang, Peng (24923262400); Waseem, Muhammad (57189504629); Khan, Bilal (57216127356); Ahmad, Aakash (36760479100); Fahmideh, Mahdi (43061009500); Niazi, Mahmood (14045585000); Akbar, Muhammad Azeem (57200183503)","26434399300; 57218940314; 24923262400; 57189504629; 57216127356; 36760479100; 43061009500; 14045585000; 57200183503","Ethics of AI: A Systematic Literature Review of Principles and Challenges","2022","ACM International Conference Proceeding Series","","","","383","392","9","10.1145/3530019.3531329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132446173&doi=10.1145%2f3530019.3531329&partnerID=40&md5=75ef9c23dbb8180bffeb0311483eae5d","Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements. © 2022 ACM.","2-s2.0-85132446173"
"Nguyen T.-L.","Nguyen, Tuan-Linh (57754841100)","57754841100","Deep ANFIS for Understanding Emotions in Movie Clips","2023","Lecture Notes in Networks and Systems","602 LNNS","","","326","334","8","10.1007/978-3-031-22200-9_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145031644&doi=10.1007%2f978-3-031-22200-9_35&partnerID=40&md5=e6a894cfa4ff4b56c3b521e82817190f","Significant success of Deep learning (DL) in extracting features from big data which led to an explosion of Artificial Intelligence (AI) applications. However, most of those AI systems lack transparency and interpretability due to the black-box nature of DL architecture, which causes major trust-related problems in AI applications where validation is essential. This necessitates the need for interpretable AI systems that can explain their decisions. In this view, this paper proposes a deep adaptive neuro-fuzzy inference system (Deep ANFIS), that combines fuzzy inference with DL architecture to provide a more comprehensible explanation of the decision processes. Deep ANFIS uses ANFIS based convolution units in convolutional neural networks (CNNs) architecture that allows approximating the complex non-linear problems using fuzzy if-then rules. To verify the performance of the proposed Deep ANFIS and analyze the essential features for classification, we perform experiments with COGNIMUSE dataset for emotion recognition. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85145031644"
"Castelnovo A.; Cosentini A.; Malandri L.; Mercorio F.; Mezzanzanica M.","Castelnovo, Alessandro (57220179981); Cosentini, Andrea (57485965700); Malandri, Lorenzo (57204852435); Mercorio, Fabio (36056728000); Mezzanzanica, Mario (16444828900)","57220179981; 57485965700; 57204852435; 36056728000; 16444828900","FFTree: A flexible tree to handle multiple fairness criteria","2022","Information Processing and Management","59","6","103099","","","","10.1016/j.ipm.2022.103099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139298565&doi=10.1016%2fj.ipm.2022.103099&partnerID=40&md5=aac71bb1b55243f3ceebf48b5dc74e0a","The demand for transparency and fairness in AI-based decision-making systems is constantly growing. Organisations need to be assured that their applications, based on these technologies, behave fairly, without introducing negative social implications in relation to sensitive attributes such as gender or race. Since the notion of fairness is context dependent and not uniquely defined, studies in the literature have proposed various formalisation. In this work, we propose a novel, flexible, discrimination-aware decision-tree that allows the user to employ different fairness criteria depending on the application domain. Our approach enhances decision-tree classifiers to provide transparent and fair rules to final users. © 2022 Elsevier Ltd","2-s2.0-85139298565"
"Nguyen N.H.; Nguyen H.Q.; Nguyen N.T.; Nguyen T.V.; Pham H.H.; Nguyen T.N.-M.","Nguyen, Ngoc Huy (57218693099); Nguyen, Ha Quy (57219758824); Nguyen, Nghia Trung (57220988000); Nguyen, Thang Viet (57225934450); Pham, Hieu Huy (57201117744); Nguyen, Tuan Ngoc-Minh (56666402000)","57218693099; 57219758824; 57220988000; 57225934450; 57201117744; 56666402000","Deployment and validation of an AI system for detecting abnormal chest radiographs in clinical settings","2022","Frontiers in Digital Health","4","","890759","","","","10.3389/fdgth.2022.890759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135805426&doi=10.3389%2ffdgth.2022.890759&partnerID=40&md5=33b7a1f3def6de8962909b51f53d2824","Background: The purpose of this paper is to demonstrate a mechanism for deploying and validating an AI-based system for detecting abnormalities on chest X-ray scans at the Phu Tho General Hospital, Vietnam. We aim to investigate the performance of the system in real-world clinical settings and compare its effectiveness to the in-lab performance. Method: The AI system was directly integrated into the Hospital's Picture Archiving and Communication System (PACS) after being trained on a fixed annotated dataset from other sources. The system's performance was prospectively measured by matching and comparing the AI results with the radiology reports of 6,285 chest X-ray examinations extracted from the Hospital Information System (HIS) over the last 2 months of 2020. The normal/abnormal status of a radiology report was determined by a set of rules and served as the ground truth. Results: Our system achieves an F1 score—the harmonic average of the recall and the precision—of 0.653 (95% CI 0.635, 0.671) for detecting any abnormalities on chest X-rays. This corresponds to an accuracy of 79.6%, a sensitivity of 68.6%, and a specificity of 83.9%. Conclusions: Computer-Aided Diagnosis (CAD) systems for chest radiographs using artificial intelligence (AI) have recently shown great potential as a second opinion for radiologists. However, the performances of such systems were mostly evaluated on a fixed dataset in a retrospective manner and, thus, far from the real performances in clinical practice. Despite a significant drop from the in-lab performance, our result establishes a reasonable level of confidence in applying such a system in real-life situations. Copyright © 2022 Nguyen, Nguyen, Nguyen, Nguyen, Pham and Nguyen.","2-s2.0-85135805426"
"Andrikopoulou E.","Andrikopoulou, Efstathia (37067032100)","37067032100","The rise of AI in telehealth","2023","Emerging Practices in Telehealth: Best Practices in a Rapidly Changing Field","","","","183","207","24","10.1016/B978-0-443-15980-0.00011-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159468768&doi=10.1016%2fB978-0-443-15980-0.00011-9&partnerID=40&md5=d3f7cbd19c70f11af507299cfbd898bb","Since its introduction in 1955, artificial intelligence (AI) has continued its growth and expansion across all industries and societal sectors. It took the COVID-19 pandemic for AI and its subsets to take the center stage in medicine and health care. AI is a broad discipline and encompasses machine learning (ML), deep learning (DL), and other techniques. Advancements in AI enabled, facilitated, and accelerated the expansion of telehealth. Telehealth describes the wide array of digital information and communication technologies and systems that allow the delivery of health and health-related services. There are three distinct subtypes of telehealth: synchronous, asynchronous, and remote (tele) monitoring. The overarching goal of telehealth is to break down barriers in delivery of high value care by overcoming challenges resulting from time or location constraints. The end goal is not to replace in-person care, rather to commoditize and democratize high quality, high value care. On the other hand, there remain significant limitations and pitfalls, particularly regulatory and technological. Examples include best practice guidelines on the adaptation of standards regulating data exchange, expansion of reimbursement and importantly ethical challenges. The latter include critical issues such as data privacy, security, and governance, AI-introduced bias, the black box nature of some AI/ML algorithms and the impact of AI technologies/algorithms on health disparities and inequities. Disparities in access to and use of tele-health were already known but highlighted during the COVID-19 pandemic. Recognition of this hurdle led to the emerging and rapidly growing field of digital determinants of health, which comprise factors like digital literacy, access to AI/technology, and community infrastructure like access to WiFi/broadband internet. © 2023 Elsevier Inc. All rights reserved.","2-s2.0-85159468768"
"Sopauschke D.; Trostmann E.; Richter K.","Sopauschke, Daniel (57225179059); Trostmann, Erik (57212254172); Richter, Klaus (57022276100)","57225179059; 57212254172; 57022276100","Smart Process Observer for Crane Automation","2023","Lecture Notes in Networks and Systems","640 LNNS","","","177","190","13","10.1007/978-3-031-26655-3_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149668650&doi=10.1007%2f978-3-031-26655-3_16&partnerID=40&md5=223aa5227fe2c1f5b02107c2b27cbaa6","A method of automated, noncontact analysis is presented, which scans a process crane’s work area fully extrinsically with special 3D LiDAR sensors and analyzes its motion dynamics in real time. Rule- and AI-based algorithms that interpret high-quality point cloud scans have been developed, thus making it possible to evaluate a process crane’s specific handling operations reliably. Existing CAD models of the crane assemblies are automatically fitted into the point cloud for the central process of fused data analysis. The workflow starts with the localization of the loading beam’s cables to estimate its initial orientation and position. The CAD models of the lifting beam and all other lifting system components are successively fitted into the point cloud exactly with the aid of local registration. Swivel joint design constraints are factored into the assessment. The lifting operation is displayed in a VR model automatically receiving all component orientations and positions and the load every second. The crane operator can view the current situation from defined perspectives and additionally receives information on crane component position, spacing and the load, which is needed to control the crane. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85149668650"
"Giordano G.; Palomba F.; Ferrucci F.","Giordano, Giammaria (57843134600); Palomba, Fabio (55321369000); Ferrucci, Filomena (7003406181)","57843134600; 55321369000; 7003406181","On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review","2022","Journal of Systems and Software","193","","111475","","","","10.1016/j.jss.2022.111475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136467284&doi=10.1016%2fj.jss.2022.111475&partnerID=40&md5=9e3462d0a71d4fe859f0ab8331727169","The Internet of Things (IoT) refers to a network of Internet-enabled devices that can make different operations, like sensing, communicating, and reacting to changes arising in the surrounding environment. Nowadays, the number of IoT devices is already higher than the world population. These devices operate by exchanging data between them, sometimes through an intermediate cloud infrastructure, and may be used to enable a wide variety of novel services that can potentially improve the quality of life of billions of people. Nonetheless, all that glitters is not gold: the increasing adoption of IoT comes with several privacy concerns due to the lack or loss of control over the sensitive data exchanged by these devices. This represents a key challenge for software engineering researchers attempting to address those privacy concerns by proposing (semi-)automated solutions to identify sources of privacy leaks. In this respect, a notable trend is represented by the adoption of smart solutions, that is, the definition of techniques based on artificial intelligence (AI) algorithms. This paper proposes a systematic literature review of the research in smart detection of privacy concerns in IoT devices. Following well-established guidelines, we identify 152 primary studies that we analyze under three main perspectives: (1) What are the privacy concerns addressed with AI-enabled techniques; (2) What are the algorithms employed and how they have been configured/validated; and (3) Which are the domains targeted by these techniques. The key results of the study identified six main tasks targeted through the use of artificial intelligence, like Malware Detection or Network Analysis. Support Vector Machine is the technique most frequently used in literature, however in many cases researchers do not explicitly indicate the domain where to use artificial intelligence algorithms. We conclude the paper by distilling several lessons learned and implications for software engineering researchers. © 2022","2-s2.0-85136467284"
"Kim C.-Y.; Jeong J.-G.; Choi S.-W.; Lee E.-B.","Kim, Chae-Yeon (57346041900); Jeong, Jong-Gwan (57884864100); Choi, So-Won (57226501136); Lee, Eul-Bum (7406967942)","57346041900; 57884864100; 57226501136; 7406967942","An AI-Based Automatic Risks Detection Solution for Plant Owner’s Technical Requirements in Equipment Purchase Order","2022","Sustainability (Switzerland)","14","16","10010","","","","10.3390/su141610010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137682276&doi=10.3390%2fsu141610010&partnerID=40&md5=d329a8637b346dc2154bc58f972e33e9","Maintenance activities to replace, repair, and revamp equipment in the industrial plant sector are gradually needed for sustainability during the plant’s life cycle. In order to carry out these revamping activities, the plant owners exchange many purchase orders (POs) with equipment suppliers, including technical and specification documents and commercial procurement content. As POs are written in various formats with large volumes and complexities, it is often time-consuming for the owner’s engineer to review them and it may lead to errors and omissions. This study proposed the purchase order recognition and analysis system (PORAS), which automatically detects and compares risk clauses between plant owners’ and suppliers’ POs by utilizing artificial intelligence (AI). The PORAS is a comprehensive framework consisting of two independent modules and four model components that accurately reflect on the added value of the PORAS. The table recognition and comparison (TRC) module is utilized for risk clauses in POs written in tables with its two components, the table comparison (TRC-C) and table recognition (TRC-R) models. The critical terms in general conditions (CTGC) module analyzes the patterns of risk clauses in general texts, then extracts them with a rule-based algorithm and compares them through entity matching. In the TRC-C model using machine learning (Ditto model), a few errors occurred due to insufficient training data, resulting in an accuracy of 87.8%, whereas in the TRC-R model, a rule-based algorithm, errors occurred in only some exceptional cases; thus, its F1 score was evaluated to be 96.9%. The CTGC module’s F2 score for automatic extraction performance was evaluated as 79.1% due to some data’s bias. Overall, the validation study shows that while a human review of the risk clauses in a PO manually took hours, it took only an average of 10 min with the PORAS. Therefore, this time saving can significantly reduce the owner engineer’s PO workload. In essence, this study contributes to achieving sustainable engineering processes through the intelligence and automation of document and risk management in the plant industry. © 2022 by the authors.","2-s2.0-85137682276"
"Tsiakas K.; Murray-Rust D.","Tsiakas, Konstantinos (56236865600); Murray-Rust, Dave (14827312400)","56236865600; 14827312400","Using human-in-the-loop and explainable AI to envisage new future work practices","2022","ACM International Conference Proceeding Series","","","","588","594","6","10.1145/3529190.3534779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134432782&doi=10.1145%2f3529190.3534779&partnerID=40&md5=c056ac8d4cef4372b14eff87e3c189d3","In this paper, we discuss the trends and challenges of the integration of Artificial Intelligence (AI) methods in the workplace. An important aspect towards creating positive AI futures in the workplace is the design of fair, reliable and trustworthy AI systems which aim to augment human performance and perception, instead of replacing them by acting in an automatic and non-transparent way. Research in Human-AI Interaction has proposed frameworks and guidelines to design transparent and trustworthy human-AI interactions. Considering such frameworks, we discuss the potential benefits of applying human-in-the-loop (HITL) and explainable AI (XAI) methods to define a new design space for the future of work. We illustrate how such methods can create new interactions and dynamics between human users and AI in future work practices.  © 2022 Owner/Author.","2-s2.0-85134432782"
"Ou C.; Buschek D.; Mayer S.; Butz A.","Ou, Changkun (57211271298); Buschek, Daniel (55850134500); Mayer, Sven (57014349100); Butz, Andreas (55150450600)","57211271298; 55850134500; 57014349100; 55150450600","The Human in the Infinite Loop: A Case Study on Revealing and Explaining Human-AI Interaction Loop Failures","2022","ACM International Conference Proceeding Series","","","","158","168","10","10.1145/3543758.3543761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139174285&doi=10.1145%2f3543758.3543761&partnerID=40&md5=770184e3a141b4c4644503a0a318f2f5","Interactive AI systems increasingly employ a human-in-the-loop strategy. This creates new challenges for the HCI community when designing such systems. We reveal and investigate some of these challenges in a case study with an industry partner, and developed a prototype human-in-the-loop system for preference-guided 3D model processing. Two 3D artists used it in their daily work for 3 months. We found that the human-AI loop often did not converge towards a satisfactory result and designed a lab study (N=20) to investigate this further. We analyze interaction data and user feedback through the lens of theories of human judgment to explain the observed human-in-the-loop failures with two key insights: 1) optimization using preferential choices lacks mechanisms to deal with inconsistent and contradictory human judgments; 2) machine outcomes, in turn, influence future user inputs via heuristic biases and loss aversion. To mitigate these problems, we propose descriptive UI design guidelines. Our case study draws attention to challenging and practically relevant imperfections in human-AI loops that need to be considered when designing human-in-the-loop systems.  © 2022 ACM.","2-s2.0-85139174285"
"Žigienė G.; Rybakovas E.; Vaitkienė R.; Gaidelys V.","Žigienė, Gerda (18234429400); Rybakovas, Egidijus (56191860700); Vaitkienė, Rimgailė (57204418879); Gaidelys, Vaidas (37561174500)","18234429400; 56191860700; 57204418879; 37561174500","Setting the Grounds for the Transition from Business Analytics to Artificial Intelligence in Solving Supply Chain Risk","2022","Sustainability (Switzerland)","14","19","11827","","","","10.3390/su141911827","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140024666&doi=10.3390%2fsu141911827&partnerID=40&md5=0663f690c5b1cc88d551f078ee362d5e","As supply chains (SCs) become more complex globally, businesses are looking for efficient business analytics (BA), business intelligence (BI), and artificial intelligence (AI) tools for managing supply-chain risk. The tools and methodologies proposed by the supply-chain risk management (SCRM) literature are mostly based on experts’ judgments, their knowledge, and past data. The expert evaluation-based approach could be partly or fully replaced by AI solutions, increasing objectivity, impartiality, and impersonality, reducing sources of human mistakes, biases, and inefficiencies in SCRM. However, the transition from BA to AI in SCRM is not a self-contained process; though attractive as a vision, it is not straightforward as a management or implementation process. The purpose of this research is to explore and define the conceptual grounds for transitioning from BA to AI in SCRM. The conceptual SCRM structure, its AI suitability, and implementation terms are defined theoretically based on a literature review. A single, in-depth business case study is employed to explore the theoretically defined terms of AI-based SCRM implementation. The proposed conceptual AI-suitable SCRM structure is defined by five principal building blocks: risk events, risk-event indicators, data-processing rules and algorithms, analytical techniques, and risk event probability forecasts. The study concludes that the business environment meets AI-based SCRM-implementation terms of data existence and access. Since data on risk events and negative outcomes are limited for machine learning, experts’ experience and knowledge might be utilised to build initial rules and data-processing algorithms for AI. © 2022 by the authors.","2-s2.0-85140024666"
"Eszteri D.","Eszteri, Dániel (57193710010)","57193710010","BLOCKCHAIN AND ARTIFICIAL INTELLIGENCE: CONNECTING TWO DISTINCT TECHNOLOGIES TO COMPLY WITH GDPR’S DATA PROTECTION BY DESIGN PRINCIPLE","2022","Masaryk University Journal of Law and Technology","16","1","","59","87","28","10.5817/MUJLT2022-1-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134780260&doi=10.5817%2fMUJLT2022-1-3&partnerID=40&md5=d2d60c7450a614498b1a77d9e269e2f3","The aim of the paper is to present some of the general principles of data protection law that can be applied to automated decision-making applications embedded into blockchain technology in order to comply with the provision of the European Union’s General Data Protection Regulation (GDPR). The analysis focuses on the applicability of the ‘data protection by design’ principle during the development of such systems. Because blockchain-based networks are built on distributed data processing operations, therefore data controlling or processing of participating nodes should comply some abstract data protection patterns predetermined and collectively built-in during the system’s development phase. On the other hand, the imprint of AI’s automated data processing could be also observed and tracked back in the blockchain due to its historically retroactive nature. In the end, the study presents the human mind and its ‘uploading’ with conscious and unconscious contents as an analogy to blockchain-based AI systems. My goal is to highlight that the synergy of blockchain and machine learning-based AI can be hypothetically suitable to develop robust yet transparent automated decision-making systems. The compliance of these distributed AI systems with data protection law’s principles is a key issue regarding the high risks posed by them to data subjects rights and freedoms. © 2022 Masaryk University Journal of Law and Technology. All rights reserved.","2-s2.0-85134780260"
"Jin Z.; Levine S.; Gonzalez F.; Kamal O.; Sap M.; Sachan M.; Mihalcea R.; Tenenbaum J.; Schölkopf B.","Jin, Zhijing (57216691426); Levine, Sydney (57202333145); Gonzalez, Fernando (57937826600); Kamal, Ojasv (57222083806); Sap, Maarten (56419784900); Sachan, Mrinmaya (36094978300); Mihalcea, Rada (8619220500); Tenenbaum, Joshua (7006818404); Schölkopf, Bernhard (7004460308)","57216691426; 57202333145; 57937826600; 57222083806; 56419784900; 36094978300; 8619220500; 7006818404; 7004460308","When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment","2022","Advances in Neural Information Processing Systems","35","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150590503&partnerID=40&md5=d6813d069907440dd6091f48d2df95d8","AI systems are becoming increasingly intertwined with human life. In order to effectively collaborate with humans and ensure safety, AI systems need to be able to understand, interpret and predict human moral judgments and decisions. Human moral judgments are often guided by rules, but not always. A central challenge for AI safety is capturing the flexibility of the human moral mind - the ability to determine when a rule should be broken, especially in novel or unusual situations. In this paper, we present a novel challenge set consisting of moral exception question answering (MoralExceptQA) of cases that involve potentially permissible moral exceptions - inspired by recent moral psychology studies. Using a state-of-the-art large language model (LLM) as a basis, we propose a novel moral chain of thought (MORALCOT) prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments. MORALCOT outperforms seven existing LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to capture the flexibility of the human moral mind. We also conduct a detailed error analysis to suggest directions for future work to improve AI safety using MoralExceptQA. © 2022 Neural information processing systems foundation. All rights reserved.","2-s2.0-85150590503"
"He Y.; Peng D.","He, Yonghua (57876290600); Peng, Debin (57876486600)","57876290600; 57876486600","AI Tools for Media Data Governance in the Post-Truth Era: from Abnormal Data Recognition to Intelligent Opinion Monitoring Algorithm","2022","5th International Conference on Inventive Computation Technologies, ICICT 2022 - Proceedings","","","","1282","1286","4","10.1109/ICICT54344.2022.9850591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137333738&doi=10.1109%2fICICT54344.2022.9850591&partnerID=40&md5=f0965f3ed075ee5b0080094d44eb6009","AI tools for media data governance in the post-truth era from abnormal data recognition to intelligent opinion monitoring algorithm is studied in the paper. The decisions and rules made by artificial intelligence are not necessarily superior to human beings. In terms of fairness, machine learning identifies patterns from past data and makes new decisions based on these patterns. Therefore, AI systems may consolidate or amplify historical bias. In the analysis of network public opinion, the first thing is to then grab the network text, and analyze the behavior characteristics, classify different behavior characteristics, so as to detect network public opinion according to some different behavior types and with this inspiration. In our designed model, the data mining algorithm is designed for the modelling. Through the comparison analysis, the performance is then validated.  © 2022 IEEE.","2-s2.0-85137333738"
"Verne G.B.; Steinstø T.; Simonsen L.; Bratteteig T.","Verne, Guri B. (55347763900); Steinstø, Tina (57218717679); Simonsen, Linett (57218718545); Bratteteig, Tone (6507348626)","55347763900; 57218717679; 57218718545; 6507348626","How Can I Help You? A chatbot’s answers to citizens’ information needs","2022","Scandinavian Journal of Information Systems","34","2","7","232","280","48","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146252835&partnerID=40&md5=d9663356ea697e53563ccabd60334de8","AI-based chatbots are becoming an increasingly common part of the front-line of public services. Through natural language, users can write simple queries to a chatbot which answers with appropriate information. We have investigated how a public chatbot operates in actual practice and how it answers the citizens’ questions about the rules and regulations for welfare benefits. We use the concept of citizens’ information needs to determine the quality of the chatbot’s answers. Information needs are often not formulated from the start as answerable questions. We analyse logs from chat sessions between the chatbot and the citizens, and focus on problems that arise, e.g., that the chatbot gives irrelevant answers or omits important information. The paper shows how the inner workings of the chatbot shapes the answerable questions. We conclude that responsible use of AI (such as chatbots) is a matter of design of the overall service and includes acknowledging that the AI itself can never be responsible. © Scandinavian Journal of Information Systems.","2-s2.0-85146252835"
"Kline E.; Sengupta S.","Kline, Ed (58184996700); Sengupta, Srijan (57201825614)","58184996700; 57201825614","How AI can Help us Understand and Mitigate Error Propagation in Radiation Oncology","2022","Artificial Intelligence in Radiation Oncology","","","","305","334","29","10.1142/9789811263545_0014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152621753&doi=10.1142%2f9789811263545_0014&partnerID=40&md5=8bc3fe70bb302677f326530872a144bd","The treatment workflow in Radiation Oncology involves a long chain of clinical and technical steps involving numerous subsystems, multiple vendors, and a variety of medical professionals. This complex workflow must be further customized for individual patients whose tumor size and locations can change during treatment. Therefore, medical errors can occur, and, crucially, such errors can propagate to future steps unless detected and addressed immediately. Understanding this error propagation is key to proactive error management. This chapter aims to discuss these issues and to provide guidelines toward an artificial intelligence (AI)-based analytical framework to analyze structured and unstructured incident reports. Such an analytical framework can be used to model error propagation and proactively identify points of weakness in Radiation Oncology pathways. Incorporating statistical learning and AI tools in this model may preemptively identify errors or trends in errors and suggest actions to prevent their recurrence. © 2023 by World Scientific Publishing Co. Pte. Ltd.","2-s2.0-85152621753"
"Saranya V.S.; Ramachandran G.; Chakaravarthi S.","Saranya, V.S. (57496803000); Ramachandran, G. (57371224500); Chakaravarthi, S. (56048705100)","57496803000; 57371224500; 56048705100","Secured IoT Malware Detection Framework using AI based Fuzzy Logic Systems","2022","International Conference on Automation, Computing and Renewable Systems, ICACRS 2022 - Proceedings","","","","771","779","8","10.1109/ICACRS55517.2022.10029032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148320471&doi=10.1109%2fICACRS55517.2022.10029032&partnerID=40&md5=ae6c4a97157d2692ce34219bafd637ec","Internet of Things (IoT) system is emerged enormously today and it is utilized in all the applications of human lives. Security of IoT systems seem more challengeable in terms of malicious software's which are referred as malwares. IoT malwares are also evolved with the employment of advanced obfuscation and evading techniques. It is a very challengeable job for the security analysts as well as security providers. In this paper, an enhanced IoT malware detection framework is proposed by making use of AI based Fuzzy Logic Systems (AIFLS) by considering the shortcomings of existing recent detection methods. Fuzzy rules are generated automatically without any human intervention. Further, Fuzzy Pattern Trees (FPT) are generated and utilized for fastening classification of IoT malwares and enhancing detection accuracy. Experimentation results provide better results. © 2022 IEEE","2-s2.0-85148320471"
"Dwivedi U.K.; Wiwatcharakoses C.; Sekimoto Y.","Dwivedi, Uttam Kumar (58069227500); Wiwatcharakoses, Chayut (56039851900); Sekimoto, Yoshihide (53364561900)","58069227500; 56039851900; 53364561900","Realtime Safety Analysis System using Deep Learning for Fire Related Activities in Construction Sites","2022","International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2022","","","","","","","10.1109/ICECCME55909.2022.9987855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146432969&doi=10.1109%2fICECCME55909.2022.9987855&partnerID=40&md5=a918333488490ea660532464b4f33854","The era of digital transformation focuses on the integration of digital and AI based technology in construction industry for sustainable economic growth and high quality of life. This paper aims to provide a real-time detection and tracking of various construction activities and provide immediate practical safety guidelines and alert for probable accidental scenarios to ensure the safety of construction site and workers by using deep learning algorithms with vision-based edge devices and smartphone. Proposed paper develops a hybrid algorithm using scene classification first, and dependent object detection and tracking second to analyze vast category of fire related activities from video and images in real-time using computationally challenging devices. To cover the ever-changing construction location, easy to move smartphone-based applications were developed with AI as an API solution. The review of the results confirms superior real-time performance in successfully identifying and providing clear safety guidelines for indoor and outdoor fire related activities such as welding work and fire safety equipment and workers safety gear such as hardhat helmet. The study validated the practicality of IoT and deep learning-based solutions for construction jobsites with indoor and outdoor locations. © 2022 IEEE.","2-s2.0-85146432969"
"Ahmadi A.R.B.; Panahi M.S.; Ayati M.","Ahmadi, Amir Reza Baba (58103914500); Panahi, Masoud Shariat (6507953459); Ayati, Moosa (25027078800)","58103914500; 6507953459; 25027078800","Hybrid AI-based Control Strategy for a Full-Vehicle Semi-Active Suspension System Equipped with MR Dampers","2022","10th RSI International Conference on Robotics and Mechatronics, ICRoM 2022","","","","433","438","5","10.1109/ICRoM57054.2022.10025306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148087036&doi=10.1109%2fICRoM57054.2022.10025306&partnerID=40&md5=367158132b84f43feecb5ed05626e1d6","This paper's goal is to design a hybrid AI-based controller for a MR-damped semi-active suspension system using a seven-degree-of-freedom model to enhance ride comfort by mitigating the acceleration exerted on the passenger. A fuzzy-logic control strategy is employed to determine the desired force required to be applied to the vehicle body. Also, a recurrent neural network was developed to predict the input voltage of the damper required to generate its actual force. The fuzzy controller rules are designed based on minimizing the vehicle body acceleration. The neural network is trained using the synthetic data produced from the modified Bouc-Wen model. The performance of the proposed hybrid AI-based method was evaluated by applying it to a full suspension system model incorporating an MR damper model with 7-DOF riding on a bumpy road. Based on various simulations, the effectiveness of the proposed strategy is proved by calculating RMS values of the vertical body acceleration, angular acceleration, and the vertical displacement of body center mass. © 2022 IEEE.","2-s2.0-85148087036"
"Guo L.Y.; Xia L.; Huang X.Y.; Fu Y.X.; Li X.Y.; Zhou S.C.; Zhao C.; Yang B.X.","Guo, Long Yin (57271776600); Xia, Lin (57216613682); Huang, Xin Yi (58737368700); Fu, Yu Xin (57981365600); Li, Xin Yi (57327561800); Zhou, Si Chen (57704165700); Zhao, Chao (57981033800); Yang, Bing Xiang (57195756147)","57271776600; 57216613682; 58737368700; 57981365600; 57327561800; 57704165700; 57981033800; 57195756147","The Construction and Validation of an Automatic Crisis Balance Analysis Model","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13705 LNCS","","","177","188","11","10.1007/978-3-031-20627-6_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142650353&doi=10.1007%2f978-3-031-20627-6_17&partnerID=40&md5=12b8c078c054883fe308178bf5f1fe19","Background: With the development of Internet, many people with suicide risk tend to express their thoughts on social media platforms. AI-based model can early identify social media users with suicide risk and analyze their cognitive and interpersonal characteristics. Then we can do early intervention to help them. Objective: To build an automatic crisis balance analysis model based on artificial intelligence which can perform automatic early suicide identification, suicide risk classification and analyze cognitive distortion and interpersonal relationship of users. Then to validate the predictive efficiency of model. Method: Firstly, based on the suicide knowledge graph, free annotation data set was generated and then Bert-based model was built. Secondly, the data set was refined by psychology students and experts to build fine-tuning model and Psychology+ model. The Psychology+ model was used as final suicide risk assessment model. We enriched and quantified the variables of cognitive and interpersonal characteristics and built the cognitive distortion and interpersonal relationship analysis model. Using F1 score, precision, recall and accuracy to evaluate the model performance and the consistence of model results with expert judgment and scales results to evaluate the model prediction ability. Results: For the suicide risk assessment model, the F1 score, precision, recall rate and accuracy rate of the model are 77.98%, 80.75%, 75.41% and 78.68% respectively. For the cognitive distortion and interpersonal relationship analysis model, the F1 score, accuracy and recall rate of the model are 77.26%, 78.22% and 76.33% respectively. Comparing the results with the results of the scale by chi square test, there was no significant difference in cognitive distortion(P = 0.521) and interpersonal relationship(P = 0.189) aspect. Conclusion: The model showed good performance and can be used as a guideline and evaluation tool for intervention. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85142650353"
"Bode J.; Schemmer M.; Balyo T.","Bode, Jan (58613607500); Schemmer, Max (57226651200); Balyo, Tomáš (55668565600)","58613607500; 57226651200; 55668565600","Explainable AI for Constraint-Based Expert Systems","2022","17th International Conference on Wirtschaftsinformatik, WI 2022","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172024673&partnerID=40&md5=07b700a7fe359c847300bf87973a6d32","The need to derive explanations from machine learning (ML)-based AI systems has been addressed in recent research due to the opaqueness of their processing. However, a significant amount of productive AI systems are not based on ML but are expert systems including strong opaqueness. A resulting lack of understanding causes massive inefficiencies in business processes that involve opaque expert systems. This work uses recent research interest in explainable AI (XAI) to generate knowledge for the design of explanations in constraint-based expert systems. Following the Design Science Research paradigm, we develop design requirements and design principles. Subsequently, we design an artifact and evaluate the artifact in two experiments. We observe the following phenomena. First, global explanations in a textual format were well-received. Second, abstract local explanations improved comprehensibility. Third, contrastive explanations successfully assisted in the resolution of contradictions. Finally, a local tree-based explanation was perceived as challenging to understand. © 2022 17th International Conference on Wirtschaftsinformatik, WI 2022. All rights reserved.","2-s2.0-85172024673"
"Huang X.; Wu X.; Usmani A.","Huang, Xinyan (56008117600); Wu, Xiqiang (57216592869); Usmani, Asif (7006213305)","56008117600; 57216592869; 7006213305","Perspectives of Using Artificial Intelligence in Building Fire Safety","2022","Handbook of Cognitive and Autonomous Systems for Fire Resilient Infrastructures","","","","139","159","20","10.1007/978-3-030-98685-8_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161349141&doi=10.1007%2f978-3-030-98685-8_6&partnerID=40&md5=6cb9d8d80688082e5b1cb472305a4866","Over the past decade, big data and artificial intelligence (AI) enable new smart techniques in the building and construction area. The applications of AI in fire detection, risk assessment, and fire forecast are emerging. This chapter provides a roadmap for AI-based building fire safety engineering application by comparing it with the history of CFD fire modelling. Guidelines for constructing a reliable fire database with both experimental and numerical data are introduced. The AI algorithms having a great potential to detect and forecast fire scenarios are discussed, and the latest research on exploring and developing intelligent firefighting systems are reviewed. Finally, three new concepts of applying AI in building fire safety are proposed, (1) the AI-based fire engineering design to improve the structure fire safety, (2) the building fire Digital Twin to monitoring the fire risk and development in real time, and (3) the Super Real-time Forecast (SuRF) of the fire evolution. © Springer Nature Switzerland AG 2022.","2-s2.0-85161349141"
"Xiang J.; Tong L.; Zhou S.","Xiang, Jianmin (14069458500); Tong, Litao (57215882712); Zhou, Shengfa (57902934700)","14069458500; 57215882712; 57902934700","Design of AI System for National Fitness Sports Competition Action Based on Association Rules Algorithm","2022","Computational Intelligence and Neuroscience","2022","","1375009","","","","10.1155/2022/1375009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138656845&doi=10.1155%2f2022%2f1375009&partnerID=40&md5=6abf7f799a925fbceccc59f9446bf80c","In information system construction, online data migration is a very important link. At present, in different fields, people provide protection for online data migration through the way of project management to ensure the speed and efficiency of online migration. However, some problems may occur in the process of online data migration. In the development of contemporary sports, competitive sports, as the high-end stage of sports development, are constantly pursued by ordinary sports enthusiasts. Therefore, in the national fitness activities, how to combine the national fitness and competitive sports data to provide a more professional storage platform is a focus of research but also a problem to be solved in the process of online data migration. Because the data mining ID3 algorithm only supports querying and retrieving RowKey indexes, it does not support non-RowKey column indexing. Therefore, if you want to query non-RowKey indexes, the data mining ID3 algorithm will search the form in the overall scan, but the performance of this method is low. In order to improve the query speed of non-RowKey columns, this paper designs a secondary index function based on HBase. The sports competition action system can retrieve data from the secondary index of the query state, to avoid scanning the whole world and improve the search speed. In this paper, ID3 algorithm is used to combine national fitness and competitive sports data, which provides a guarantee for the migration of competitive sports data in the national fitness system. © 2022 Jianmin Xiang et al.","2-s2.0-85138656845"
"Qiu K.; Chang H.; Wang Y.; Yu X.; Zhu W.; Liu Y.; Ma J.; Li W.; Liu X.; Dai S.","Qiu, Kun (57297825700); Chang, Harry (57298428800); Wang, Ying (57826317700); Yu, Xiahui (57826657700); Zhu, Wenjun (57298632100); Liu, Yingqi (57825810400); Ma, Jianwei (57826317800); Li, Weigang (57193714080); Liu, Xiaobo (57825977300); Dai, Shuo (57825810500)","57297825700; 57298428800; 57826317700; 57826657700; 57298632100; 57825810400; 57826317800; 57193714080; 57825977300; 57825810500","Traffic Analytics Development Kits (TADK): Enable Real-Time AI Inference in Networking Apps","2022","International Conference on Ubiquitous and Future Networks, ICUFN","2022-July","","","392","398","6","10.1109/ICUFN55119.2022.9829628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135237223&doi=10.1109%2fICUFN55119.2022.9829628&partnerID=40&md5=8e5c0dd1c714c6d647b60f7b67bba0fc","Sophisticated traffic analytics, such as the encrypted traffic analytics and unknown malware detection, emphasizes the need for advanced methods to analyze the network traffic. Traditional methods of using fixed patterns, signature matching, and rules to detect known patterns in network traffic are being replaced with AI (Artificial Intelligence) driven algorithms. However, the absence of a high-performance AI networking-specific framework makes deploying real-time AI-based processing within networking workloads impossible. In this paper, we describe the design of Traffic Analytics Development Kits (TADK), an industry-standard framework specific for AI-based networking workloads processing. TADK can provide real-time AI-based networking workload processing in networking equipment from the data center out to the edge without the need for specialized hardware (e.g., GPUs, Neural Processing Unit, and so on). We have deployed TADK in commodity WAF and 5G UPF, and the evaluation result shows that TADK can achieve a throughput up to 35.3Gbps per core on traffic feature extraction, 6.5Gbps per core on traffic classification, and can decrease SQLi/XSS detection down to 4.5μs per request with higher accuracy than fixed pattern solution.  © 2022 IEEE.","2-s2.0-85135237223"
"Ali M.S.; Azam F.; Safdar A.; Anwar M.W.","Ali, Muhammad Shahroze (57223753208); Azam, Farooque (57195670768); Safdar, Aon (57961836300); Anwar, Muhammad Waseem (56677318200)","57223753208; 57195670768; 57961836300; 56677318200","Intelligent Agents in Educational Institutions: NEdBOT - NLP-based Chatbot for Administrative Support Using DialogFlow","2022","Proceedings - 2022 IEEE International Conference on Agents, ICA 2022","","","","30","35","5","10.1109/ICA55837.2022.00012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146496302&doi=10.1109%2fICA55837.2022.00012&partnerID=40&md5=72fcef86d1c7ca86735c60083782c79a","Artificial intelligence (AI)-based chatbot systems have seen increased adaption in the educational domain in recent years owing to increased sophistication in the AI domain. However, most of the communication between students and educational institutions is still performed physically and causes major administrative overhead, especially during the time of admission. Contemporary pattern-matching-based and generative-based chatbots underperform to queries outside a limited scope, grammatically and structurally ambiguous inputs, outliers to pre-defined rule-set, and longer response times for a huge knowledge base. We proposed a NEdBOT-An NLP-based Educational Bot, developed by Natural Language Processing models integrated within the DialogFlow platform utilizing a Retrieval-based approach. We evaluate the developed chatbot on a custom dataset generated for the admissions use case of a prominent university. We used an objective evaluation criterion with real-world users to achieve an intent classification accuracy of 76.8% at an average mean response time of 216.43ms per query and a user-friendliness score of 72% on the System Usability Scale (SUS). The results demonstrate the proposed approach's ability to create robust, reliable, responsive, and user-friendly web-based smart chatbots that are highly scalable with the capability to handle wider scopes and vague inputs with ease.  © 2022 IEEE.","2-s2.0-85146496302"
"Bhoi S.; Sourav S.","Bhoi, Suman (57190384663); Sourav, Suman (6506101779)","57190384663; 6506101779","Towards Understanding and Improving Handwriting with AI","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13639 LNCS","","","331","344","13","10.1007/978-3-031-21648-0_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144390655&doi=10.1007%2f978-3-031-21648-0_23&partnerID=40&md5=418d23ace5fad4bf383e95caa693262c","What makes a handwriting good? If the aesthetic judgment of handwriting follows implicit rules, can those rules be recovered by observing good and bad examples? To answer these questions, we apply explainability techniques to the classification of good and bad handwriting. We show that it is indeed possible to recover these inherent rules. We develop an AI system that uses a modified version of LIME Image Explainer and generates images containing suggestions for improvement. We use single-character and word-level datasets labelled with binary labels generated via accepted rules for handwriting classification. We discuss the possible improvements to the current system as well as where this research could be applied, such as user-specific auto-suggestions. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85144390655"
"Costa A.; Silva F.","Costa, Andre (58391343300); Silva, Firmino (56014653800)","58391343300; 56014653800","Interaction Design for AI Systems: An oriented state-of-the-art","2022","HORA 2022 - 4th International Congress on Human-Computer Interaction, Optimization and Robotic Applications, Proceedings","","","","","","","10.1109/HORA55278.2022.9800084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133977548&doi=10.1109%2fHORA55278.2022.9800084&partnerID=40&md5=80334c7030d4da3629c07a47f0b08aaf","In recent years, new web-based technologies have emerged, and mobile devices and applications access have become widespread, resulting in new paradigms in Human-Computer Interaction (HCI). These paradigms created several challenges in interaction design regarding customization, adaptability, and accessibility. Over the lifetime of a digital product, the user must adapt to updates, changes in the interface, and new functions, while having to provide attention to customization and configuration tasks in interfaces created for millions of individuals worldwide. Simultaneously, users' conditions change, and the system must adjust to new requirements, preferences, and needs in a fast-paced digital environment. And new functions, interfaces, and technologies that meet current market directions, such as Artificial Intelligence, Augmented Reality, Virtual Reality, and even Design without physical interfaces must be developed and implemented. This research work explores the importance of Interaction Design (IxD) in the present and future Artificial Intelligence (AI) systems, highlighting the prominent authors of User-Centered Design and usability principles, guidelines, and heuristics. Moreover, researching appropriate design principles for developing a positive, effective, and safe interaction between humans and computers. This study will also deepen and orient the study of the state-of-the-art to promote the exploration of HCI in a period of enormous challenges and opportunities in AI. As a result of this research work, a table summarizes, compares, and classifies the state of the art according to Usability & Design Principles. Outputting a matrix that aggregates the fundamental principles for designing interfaces in artificial intelligence systems, regardless of their interface. This matrix serves as a base for a framework to create a prototype, in future work, based on the guidelines suggested. © 2022 IEEE.","2-s2.0-85133977548"
"Cheng E.C.K.; Wang T.","Cheng, Eric C. K. (37123500500); Wang, Tianchong (55535720400)","37123500500; 55535720400","Institutional Strategies for Cybersecurity in Higher Education Institutions","2022","Information (Switzerland)","13","4","192","","","","10.3390/info13040192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129009461&doi=10.3390%2finfo13040192&partnerID=40&md5=3527274f71c18e3ceffe90b898016808","Cybersecurity threats have grown exponentially, posing a heavy burden on organisations. Higher Education Institutions (HEIs) are particularly vulnerable, and their cybersecurity issues are receiving greater attention. However, existing research on cybersecurity has limited referencing value for HEI leaders and policy-makers because they are usually technology-focused. Publications that showcase best practices often lack system-wide perspectives towards cybersecurity in HEIs. Our paper, therefore, aims to bridge this literature gap and generate institutional cybersecurity strategies for HEI leaders and policy-makers from a system perspective. We first review how the cybersecurity landscape has evolved over the last few decades and its latest trends and projections for the next decade. By analysing these historical developments and new changes, we further illuminate the importance of strengthening HEI cybersecurity capacities. As we explore why HEIs face severe challenges to tackle the ever-escalating cyberattacks, we propose a system-wide approach to safeguard HEI cybersecurity and highlight the necessity to reassess prioritised areas. By taking an extensive literature review and desk research of methods that could respond to the cybersecurity vulnerabilities of the next decade, we synthesise our findings with a set of institutional strategies, with takeaways designed to equip HEIs better to address cybersecurity threats into the future. The strategies include: (1) Strengthening Institutional Governance for Cybersecurity; (2) Revisiting Cybersecurity KPIs; (3) Explicating Cybersecurity Policies, Guidelines and Mechanisms; (4) Training and Cybersecurity Awareness Campaigns to Build Cybersecurity Culture; (5) Responding to AI-based Cyber-threats and Harnessing AI to Enhance Cybersecurity; (6) Introduction of New and More Sophisticated Security Measures; (7) Paying Attention to Mobile Devices Use, Using Encryption as a Daily Practice; and (8) Risk Management. We believe that cybersecurity can be safeguarded throughout the new decade when these strategies are considered thoroughly and with the concerted effort of relevant HEI stakeholders. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85129009461"
"Yang L.-H.; Ren T.-Y.; Ye F.-F.; Nicholl P.; Wang Y.-M.; Lu H.","Yang, Long-Hao (56159127900); Ren, Tian-Yu (57467251600); Ye, Fei-Fei (57205267471); Nicholl, Peter (6602918816); Wang, Ying-Ming (55966745100); Lu, Haitian (55519988000)","56159127900; 57467251600; 57205267471; 6602918816; 55966745100; 55519988000","An ensemble extended belief rule base decision model for imbalanced classification problems","2022","Knowledge-Based Systems","242","","108410","","","","10.1016/j.knosys.2022.108410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125239803&doi=10.1016%2fj.knosys.2022.108410&partnerID=40&md5=616fb214987d141e8ee26b80813aa6d0","Class imbalance is a common problem in real-world applications and usually poses a major challenge to artificial intelligent (AI)-based decision models. The present work introduces a novel ensemble decision model which utilizes an explainable and fast-growing rule-based system, called extended belief rule base (EBRB) decision model, to alleviate the impact of class imbalance, where the proposed ensemble EBRB model includes two core components: a diversity-based base EBRB construction scheme and a consistency-based ensemble EBRB inference scheme. Specifically, for the purpose of enhancing diversity in the construction scheme, various kinds of oversampling techniques are applied to construct diverse base EBRBs firstly, followed by the calculation of attribute weights based on information gain. As for the inference scheme, the proposed ensemble EBRB model aims to produce inferential outputs not only integrating the rules activated from all base EBRBs, but also taking into consideration the consistency of the activated rules. In experimental study, twenty-six imbalanced classification datasets are used to demonstrate the effectiveness of the proposed ensemble EBRB decision model. Results demonstrate that the proposed model outperforms conventional EBRB systems and other typical imbalanced classifiers. © 2022 Elsevier B.V.","2-s2.0-85125239803"
"Faritha Banu J.; Neelakandan S.; Geetha B.T.; Selvalakshmi V.; Umadevi A.; Martinson E.O.","Faritha Banu, J. (54959955500); Neelakandan, S. (57023847500); Geetha, B.T (55419528700); Selvalakshmi, V. (57207301031); Umadevi, A. (57476033700); Martinson, Eric Ofori (56494693800)","54959955500; 57023847500; 55419528700; 57207301031; 57476033700; 56494693800","Artificial Intelligence Based Customer Churn Prediction Model for Business Markets","2022","Computational Intelligence and Neuroscience","2022","","1703696","","","","10.1155/2022/1703696","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139729739&doi=10.1155%2f2022%2f1703696&partnerID=40&md5=59832a79ef2c88d1119ce46c4ebe4617","The introduction of artificial intelligence (AI) and machine learning (ML) technologies in recent years has resulted in improved company performance. Customer churn forecast is a difficult problem in many corporate sectors, particularly the telecommunications industry. Because customer churns have a direct impact on a company's total revenue, telecommunications firms have begun to develop 76 models to reduce churns at an earlier stage. Previous research has revealed that AI and ML models are effective CCP solutions. According to this viewpoint, this study proposes a unique AI-based CCP model for Telecommunication Business Markets (AICCP-TBM). The AICCP-TBM model's purpose is to control the existence of churners and non-churners in the telecom sector. The proposed AICCP-TBM model employs a Chaotic Salp Swarm Optimization-based Feature Selection (CSSO-FS) method for the best feature assortment. In addition, a Fuzzy Rule-based Classifier(FRC) is used to distinguish between client churners and non-churners. A technique known as Quantum Behaved Particle Swarm Optimization (QPSO) is used to pick the membership functions for the FRC model in order to improve the classification performance of the FRC model. The performance of the AICCP-TBM model is validated using a benchmark CCP dataset and the experimental results are reviewed from several angles. In relations of presentation, the imitation consequences demonstrated that the AICCP-TBM model surpassed the most recent state-of-the-art CPP models. The suggested AICCP-TBM method's comparative accuracy was thoroughly tested on the three datasets used. Using datasets 1-3, this technique obtained better levels of accuracy, with the maximum attainable values being 97.25 %, 97.5 % and 94.33 %. The simulation results for the AICCP-TBM model demonstrated improved prediction performance.  © 2022 J. Faritha Banu et al.","2-s2.0-85139729739"
"Liza F.F.","Liza, Farhana Ferdousi (24448712400)","24448712400","Challenges of Enforcing Regulations in Artificial Intelligence Act - Analyzing Quantity Requirement in Data and Data Governance","2022","CEUR Workshop Proceedings","3221","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139932182&partnerID=40&md5=7d17a9bd610a7d6a14ef696cfdb19d05","To make Artificial Intelligence (AI) systems and services accountable and regulated in the European Union market, in April 2021, the European Union Parliament published a proposal 'Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act)', widely known as Artificial Intelligence Act (AI Act). Since then, many concerns have been raised in terms of compliance and whether the regulations are enforceable. However, to the best of our knowledge, none of them provided an explicit technical analysis of the challenges in enforcing the regulation. Among 85 Articles in the AI Act, we emphasize on the Article 10, the central regulatory requirement for data and data governance. In this paper, we have analyzed a specific requirement, the data quantity, to show the challenges of enforcing this requirement in a principled way. In our analysis, we have used deep learning modeling and machine learning generalization theory. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)","2-s2.0-85139932182"
"Díaz-Rodríguez N.; Lamas A.; Sanchez J.; Franchi G.; Donadello I.; Tabik S.; Filliat D.; Cruz P.; Montes R.; Herrera F.","Díaz-Rodríguez, Natalia (55904010200); Lamas, Alberto (57206904461); Sanchez, Jules (57223910751); Franchi, Gianni (56462320300); Donadello, Ivan (56436667500); Tabik, Siham (55884151200); Filliat, David (55976331500); Cruz, Policarpo (37028231900); Montes, Rosana (7006522713); Herrera, Francisco (7102347190)","55904010200; 57206904461; 57223910751; 56462320300; 56436667500; 55884151200; 55976331500; 37028231900; 7006522713; 7102347190","EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case","2022","Information Fusion","79","","","58","83","25","10.1016/j.inffus.2021.09.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117377421&doi=10.1016%2fj.inffus.2021.09.022&partnerID=40&md5=5a2e55141681d547930d52f2a0ee42bf","The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols – such as knowledge graphs – are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: (1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and (2) SHAP-Backprop, an explainable AI-informed training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that with our approach, it is possible to improve explainability at the same time as performance. © 2021 The Authors","2-s2.0-85117377421"
"Polato M.; Esposito R.; Aldinucci M.","Polato, Mirko (56401862500); Esposito, Roberto (35753188100); Aldinucci, Marco (8844070100)","56401862500; 35753188100; 8844070100","Boosting the Federation: Cross-Silo Federated Learning without Gradient Descent","2022","Proceedings of the International Joint Conference on Neural Networks","2022-July","","","","","","10.1109/IJCNN55064.2022.9892284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140794272&doi=10.1109%2fIJCNN55064.2022.9892284&partnerID=40&md5=8b557ad26c52eba2d4efdf73388439ca","Federated Learning has been proposed to develop better AI systems without compromising the privacy of final users and the legitimate interests of private companies. Initially deployed by Google to predict text input on mobile devices, FL has been deployed in many other industries. Since its introduction, Federated Learning mainly exploited the inner working of neural networks and other gradient descent-based algorithms by either exchanging the weights of the model or the gradients computed during learning. While this approach has been very successful, it rules out applying FL in contexts where other models are preferred, e.g., easier to interpret or known to work better. This paper proposes FL algorithms that build federated models without relying on gradient descent-based methods. Specifically, we leverage distributed versions of the AdaBoost algorithm to acquire strong federated models. In contrast with previous approaches, our proposal does not put any constraint on the client-side learning models. We perform a large set of experiments on ten UCI datasets, comparing the algorithms in six non-iidness settings. © 2022 IEEE.","2-s2.0-85140794272"
"Kabudi T.; Pappas I.O.; Olsen D.H.","Kabudi, Tumaini (57220834021); Pappas, Ilias O. (55387371600); Olsen, Dag H. (7202416827)","57220834021; 55387371600; 7202416827","Deriving Design Principles for AI-Adaptive Learning Systems: Findings from Interviews with Experts","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13454 LNCS","","","82","94","12","10.1007/978-3-031-15342-6_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137999557&doi=10.1007%2f978-3-031-15342-6_7&partnerID=40&md5=ebbda3c32ffa3725246f76fc87d115ab","AI applications are increasing in the field of education, from laboratory set-ups to contemporary and complex learning systems. A great example of such systems is AI-enabled adaptive learning systems (AI-ALS) that promote adaptive learning. Despite its promised potential, there are challenges such as design issues, highly complex models, and lack of evidence-based guidelines and design principles that hinder the large-scale adoption and implementation of AI-ALS. The goal of this paper thus is to establish a set of empirically grounded design principles (DPs) of AI-ALS, that would serve well in a university context. 22 interviews were con-ducted with experts knowledgeable about the design and development of AI-ALS. Several rounds of coding and deep analysis of the expert interviews revealed features and functionalities of AI-ALS; purposes for designing and using AI-ALS; and recommended improvements for AI-ALS as requirements. These requirements were translated to 13 preliminary DPs. The findings of this study serve as a guide on how to better design AI-ALS, that will improve the learning experiences of students. © 2022, IFIP International Federation for Information Processing.","2-s2.0-85137999557"
"Maas J.","Maas, Jonne (57467556700)","57467556700","A Neo-Republican Critique of AI ethics","2022","Journal of Responsible Technology","9","","100022","","","","10.1016/j.jrt.2021.100022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125265404&doi=10.1016%2fj.jrt.2021.100022&partnerID=40&md5=50281bacb015b3fc05847019eca5fdb6","The AI Ethics literature, aimed to responsibly develop AI systems, widely agrees on the fact that society is in dire need for effective accountability mechanisms with regards to AI systems. Particularly, machine learning (ML) systems cause reason for concern due to their opaque and self-learning characteristics. Nevertheless, what such accountability mechanisms should look like remains either largely unspecified (e.g., ‘stakeholder input’) or ineffective (e.g., ‘ethical guidelines’). In this paper, I argue that the difficulty to formulate and develop effective accountability mechanisms lies partly in the predominant focus on Mill's harm's principle, rooted in the conception of freedom as non-interference. A strong focus on harm overcasts other moral wrongs, such as potentially problematic power dynamics between those who shape the system and those affected by it. I propose that the neo-republican conception of freedom as non-domination provides a suitable framework to inform responsible ML development. Domination, understood by neo-republicans, is a moral wrong as it undermines the potential for human flourishing. In order to mitigate domination, neo-republicans plead for accountability mechanisms that minimize arbitrary relations of power. Neo-republicanism should hence inform responsible ML development as it provides substantive and concrete grounds when accountability mechanisms are effective (i.e. when they are non-dominating). © 2021","2-s2.0-85125265404"
"Ehsan U.; Wintersberger P.; Liao Q.V.; Watkins E.A.; Manger C.; Daumé Iii H.; Riener A.; Riedl M.O.","Ehsan, Upol (57195223484); Wintersberger, Philipp (55485458100); Liao, Q. Vera (36095944800); Watkins, Elizabeth Anne (57193833255); Manger, Carina (57223025938); Daumé Iii, Hal (57210198346); Riener, Andreas (23012938100); Riedl, Mark O (7004421643)","57195223484; 55485458100; 36095944800; 57193833255; 57223025938; 57210198346; 23012938100; 7004421643","Human-Centered Explainable AI (HCXAI): Beyond Opening the Black-Box of AI","2022","Conference on Human Factors in Computing Systems - Proceedings","","","109","","","","10.1145/3491101.3503727","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129739238&doi=10.1145%2f3491101.3503727&partnerID=40&md5=a2bed4cc9e603d260b4fb3370e005626","Explainability of AI systems is crucial to hold them accountable because they are increasingly becoming consequential in our lives by powering high-stakes decisions in domains like healthcare and law. When it comes to Explainable AI (XAI), understanding who interacts with the black-box of AI is just as important as ""opening""it, if not more. Yet the discourse of XAI has been predominantly centered around the black-box, suffering from deficiencies in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. In this second CHI workshop on Human-centered XAI (HCXAI), we build on the success of the first installment from CHI 2021 to expand the conversation around XAI. We chart the domain and shape the HCXAI discourse with reflective discussions from diverse stakeholders. The goal of the second installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on ""operationalizing"", aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI. © 2022 Owner/Author.","2-s2.0-85129739238"
"Prasad S.K.; Mathur N.","Prasad, Sanjeev Kumar (57193997539); Mathur, Nidhi (58131878700)","57193997539; 58131878700","A Hybrid Approach of Web Based Heart Disease Diagnosis with Neural Networks","2022","2nd IEEE International Conference on Advanced Technologies in Intelligent Control, Environment, Computing and Communication Engineering, ICATIECE 2022","","","","","","","10.1109/ICATIECE56365.2022.10047363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149516982&doi=10.1109%2fICATIECE56365.2022.10047363&partnerID=40&md5=49f30ee5aa814d6ff340f04551a36b80","The prescient displaying approach for assessing cardiovascular gamble in medical services informatics is extremely challenging. Consequently, utilizing delicate figuring innovations to clinically assess clinical data sets and prescient displaying is viewed as a beneficial and practical decision for clinical specialists. Accordingly, delicate registering advances are essential in the present medical services applications since they can perform information examination and demonstrating and assist specialists with making ideal, precise clinical decisions. Information mining is the most common way of finding designs in a data set of wellbeing science factors that connect indicator factors. The displaying of convoluted, powerful frameworks is OK for existing information mining approaches. In this review, we propose a group model system for coordinating the prescient force of various classifiers' models for further developed expectation precision. To foresee and analyze the repeat of cardiovascular disease, this review utilizes group figuring out how to consolidate the demonstrating approaches of five classifiers, including support vector machines, fake neural networks, Credulous Bayesian, relapse examination, and arbitrary woods. Cleveland and Hungarian cardiovascular information records were taken from the UCI archive. The two most significant elements in myocardial localized necrosis determination are timing and exactness. Minor demonstrative slip-ups can essentially affect the length and cost of treatment as well as seriously jeopardized the patient. This study portrays a choice emotionally supportive network (DSS) for myocardial localized necrosis (MI) finding and the board, along with persistent pulse checking of the patient, based on neural networks and factual interaction control diagrams. In the whole world, heart disease is viewed as one of the main sources of death. Clinical experts find it challenging to foresee on the grounds that a complicated undertaking calls for experience and high level information. Presently, information mining and AI based clinical strong advances assume a huge part in the forecast of cardiovascular diseases. In this review, we propose a clever hybrid strategy for the expectation of cardiovascular disease utilizing an assortment of AI techniques, including Calculated Relapse (LR), Versatile Helping (AdaBoostM1), Multi-Objective Developmental Fluffy Classifier (MOEFC), Fluffy Unordered Rule Enlistment (FURIA), Hereditary Fluffy Framework LogitBoost (GFS-LB), and Fluffy Hybrid Hereditary Based AI. © 2022 IEEE.","2-s2.0-85149516982"
"Thamik H.; Wu J.","Thamik, Hanane (57547555200); Wu, Jiang (57153290000)","57547555200; 57153290000","The Impact of Artificial Intelligence on Sustainable Development in Electronic Markets","2022","Sustainability (Switzerland)","14","6","3568","","","","10.3390/su14063568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126923924&doi=10.3390%2fsu14063568&partnerID=40&md5=2f1159a4e0fedff32705cb98182fdf7e","With the emergence of artificial intelligence (AI), the technological revolution has transformed human lives and processes, empowering the products and services in today’s marketplaces. AI introduces new ways of doing jobs and business, and of exploring new global market opportuni-ties. However, on the other hand, it provides many challenges to comprehend. Therefore, our study’s main objective was to examine the behavioral, cultural, ethical, social, and economic challenges of AI-enabled products and services in consumer markets and discuss how businesses might shape their approaches to address AI-related ethical issues. AI offers numerous social, ethical, and behavioral difficulties for people, organizations, and societies that endanger the sustainable development of economies. These fundamental challenges due to AI technologies have raised serious questions for the sustainable development of electronic markets. Based on this, the current study presents a framework highlighting these issues. Systematic reviewing was our research method; we looked for explicit information and methods that indicate the credibility of research or reduce biases. This paper is of great importance, as it highlights several behavioral, societal, ethical, and cultural aspects in electronic markets which were not presented in previous studies. Some key issues are the security and privacy of consumers, AI biases, individual autonomy, wellbeing, and issues of unemployment. Therefore, companies that use AI systems need to be socially responsible and make AI systems as secure as possible to promote the sustainable development of countries. The results suggest that AI has undoubtedly transformed life and has both positive and negative effects. However, the main aim regarding AI should be to use it for the overall goals of humanity. Moreover, authorities operating in e-business environments need to create proper rules and regulations and make the systems as secure as possible for people. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85126923924"
"Moosbrugger J.; Ntoa S.","Moosbrugger, Jennifer (58023705000); Ntoa, Stavroula (22433405500)","58023705000; 22433405500","A Unified Framework to Collect and Document AI-Infused Project Exemplars","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13518 LNCS","","","407","420","13","10.1007/978-3-031-21707-4_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144446023&doi=10.1007%2f978-3-031-21707-4_29&partnerID=40&md5=7ab00f3cf79d4d0ee2f7c48e7d2c7b75","Advancements in AI and ML approaches are the reason for the current hype of this technology. A lot of products and services, either in consumer-facing solutions, as well as in the industrial context, embrace the advancement of smart algorithms. Designing such systems entails several challenges, including designing for black-box decision-making with a potentially infinite and unknown set of UI manifestations, delivering easy-to-understand explanations, involving end-users in requirements specification and product evaluation, and communication with software engineers and data scientists among others. Although designers are today equipped with several UX tools for capturing and presenting users’ experience with the products they are designing, the question that arises in the AI context is whether and how existing contemporary tools can adapt and scale to support the design of AI-enabled interactive systems. Therefore, AI and ML are perceived as a new design material. This work aims to assist researchers and practitioners involved in AI-infused projects by proposing a framework to collect and document these. The framework was designed following a workshop with representative stakeholders, through which different use cases were presented and elaborated. Evaluation of the framework highlighted that it is an easy to use and useful tool for documenting use cases and communicating them to a wide audience. © 2022, Springer Nature Switzerland AG.","2-s2.0-85144446023"
"Mueller C.; Mezhuyev V.","Mueller, Christoph (57918931900); Mezhuyev, Vitaliy (24468383200)","57918931900; 24468383200","AI Models and Methods in Automotive Manufacturing: A Systematic Literature Review","2022","Studies in Computational Intelligence","1061","","","1","25","24","10.1007/978-3-031-14748-7_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139436067&doi=10.1007%2f978-3-031-14748-7_1&partnerID=40&md5=b6c536322f597e8c641148be0225c62c","While artificial intelligence (AI) experienced an increasing interest in industry during the past decade, the true potential and applicability of AI for automotive original equipment manufacturers (OEMs) and suppliers in real-world scenarios have not been clearly understood. Most applications of AI focus on the development of connected and autonomous cars, rather than the optimisation of automotive operations and manufacturing processes. This work, therefore, bridged this gap and shed light on the topic of AI in the context of automotive manufacturing and Industry 4.0. It aimed to promote understanding and provide up-to-date insights on specific models and methods of AI, applications that have been achieved with best practices as well as the problems that were encountered, underpinned with possible future prospects. A systematic literature review approach was adopted to ensure broad and thorough coverage of current knowledge and the identification of relevant literature on the topic. The literature search was confined to papers that were published from 2015 onwards using the databases of IEEE and ScienceDirect as primary sources, with a three-keyword search phrase to narrow down the results and increase specificity. A total of 359 papers were identified and subsequently screened for eligibility, of which 84 papers were selected for quantitative and 79 papers for qualitative analysis. The results of the quantitative analysis confirmed that the topic has markedly increased in significance, with a mere 3 papers published in 2015 and 33 papers in 2021. The majority of papers dealt with solving problems in production (39.29%), quality (35.71%) and assembly (16.67%), whereas supply chain (5.95%) and business intelligence (2.38%) were inadequately represented. The results of the qualitative analysis revealed that machine learning methods dominate current research and automotive applications, with neural networks as the most used out of more than 70 identified models. The industrial applicability was confirmed by many use cases including quality inspection, robot assembly, human–robot collaboration, material demand prediction or AI-enabled manufacturing decision making. The problems of such applications were mainly attributed to data availability and quality, model development and gaps in simulation, system integration, the complexity of automotive processes, the physical conditions of the system environment and dynamic change. For industrial applications it is thus recommended to further optimise AI methods and models, enabling a wider system integration by harvesting the potential of big data and both edge and cloud computing. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85139436067"
"Księżak P.; Wojtczak S.","Księżak, Paweł (57219006550); Wojtczak, Sylwia (57215843893)","57219006550; 57215843893","A Human Being Must Obey the Commands of a Robot! CAVs, Asimov’s Second Law and the New Ground-Breaking Ethics","2022","Communications in Computer and Information Science","1676 CCIS","","","380","393","13","10.1007/978-3-031-20316-9_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144617736&doi=10.1007%2f978-3-031-20316-9_29&partnerID=40&md5=3af0e7a96197fec699d4d1bfc5c0144a","In 2020, the Independent Expert Group published the “Ethics of Connected and Automated Vehicles: recommendations on road safety, privacy, fairness, explainability and responsibility” report. This document represents a significant step towards systematizing the ongoing debate on ethical issues related to autonomic AI systems, especially Connected Automated Vehicles (CAVs). However, the report does not address the conflict between the values of human autonomy and safety, which becomes apparent when considering who should have control over CAVs, and who is responsible for the results of human autonomy. This problem and these questions have therefore become the subject of this paper. The analysis implied the following: either the human driver will be forbidden from driving, which is tantamount to admitting Asimov’s Second Law à rebours, i.e. a human being must obey the commands of a robot, or the human driver should be held fully responsible for overriding the decisions of the AI controlling the CAV. The choice between these two options must be made by the law maker according to the ethical rules within a culture. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85144617736"
"Kang B.; Kumar H.; Dash S.; Mukhopadhyay S.","Kang, Beomseok (57217433479); Kumar, Harshit (57212731702); Dash, Saurabh (57219110505); Mukhopadhyay, Saibal (8330116700)","57217433479; 57212731702; 57219110505; 8330116700","Unsupervised Hebbian Learning on Point Sets in StarCraft II","2022","Proceedings of the International Joint Conference on Neural Networks","2022-July","","","","","","10.1109/IJCNN55064.2022.9892259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140772794&doi=10.1109%2fIJCNN55064.2022.9892259&partnerID=40&md5=7188a35538544538a6afd15e0cf5d8b3","Learning the evolution of real-time strategy (RTS) game is a challenging problem in artificial intelligent (AI) system. In this paper, we present a novel Hebbian learning method to extract the global feature of a point set in StarCraft II game units, and its application to predict the movement of the points. Our model includes encoder, LSTM, and decoder, and we train the encoder with the unsupervised learning method. We introduce the concept of neuron activity aware learning combined with k-Winner-Takes-All. The optimal value of neuron activity is mathematically derived, and experiments support the effectiveness of the concept over the downstream task. Our Hebbian learning rule benefits the prediction with lower loss compared to self-supervised learning. Also, our model significantly saves the computational cost such as activations and FLOPs compared to a frame-based approach. © 2022 IEEE.","2-s2.0-85140772794"
"Morales S.; Clarisó R.; Cabot J.","Morales, Sergio (57983289600); Clarisó, Robert (8948086100); Cabot, Jordi (8963493600)","57983289600; 8948086100; 8963493600","Towards a DSL for AI Engineering Process Modeling","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13709 LNCS","","","53","60","7","10.1007/978-3-031-21388-5_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142678033&doi=10.1007%2f978-3-031-21388-5_4&partnerID=40&md5=9daf0cd119665d73aed58b454ee7ef14","Many modern software products embed AI components. As a result, their development requires multidisciplinary teams with diverse skill sets. Diversity may lead to communication issues or misapplication of best practices. Process models, which prescribe how software should be developed within an organization, can alleviate this problem. In this paper, we introduce a domain-specific language for modeling AI engineering processes. The DSL concepts stem from our analysis of scientific and gray literature that describes how teams are developing AI-based software. This DSL contributes a structured framework and a common ground for designing, enacting and automating AI engineering processes. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85142678033"
"Song F.; Yeung S.H.F.","Song, Fei (57195979484); Yeung, Shing Hay Felix (57983915800)","57195979484; 57983915800","A pluralist hybrid model for moral AIs","2022","AI and Society","","","","","","","10.1007/s00146-022-01601-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142667938&doi=10.1007%2fs00146-022-01601-0&partnerID=40&md5=544ac276b1bdde7ef4677f6a909630fb","With the increasing degrees AIs and machines, the need for implementing ethics in AIs is pressing. In this paper, we first survey current approaches to moral AIs and their inherent limitations. Then we propose the pluralist hybrid approach and show how these limitations of moral AIs can be partly alleviated by the pluralist hybrid approach. The core ethical decision-making capacity of an AI based on the pluralist hybrid approach consists of two systems. The first is a deterministic algorithm system that embraces different moral rules for making explicit moral decisions. The second is a machine learning system that accounts for calculating the value of the variables required by the application of moral principles. The pluralist hybrid system is better than the existing proposals as it better addresses the moral disagreement problem of the top-down approach by including distinct moral principles. Besides, the pluralist hybrid system reduces the opacity of ethical decision-making by implementing explicit moral principles for moral decision-making. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85142667938"
"Petersen P.; Stage H.; Langner J.; Ries L.; Rigoll P.; Philipp Hohl C.; Sax E.","Petersen, Patrick (57189845163); Stage, Hanno (58081002500); Langner, Jacob (57200193801); Ries, Lennart (57204704203); Rigoll, Philipp (57322131000); Philipp Hohl, Carl (58080280200); Sax, Eric (35243409200)","57189845163; 58081002500; 57200193801; 57204704203; 57322131000; 58080280200; 35243409200","Towards a Data Engineering Process in Data-Driven Systems Engineering","2022","ISSE 2022 - 2022 8th IEEE International Symposium on Systems Engineering, Conference Proceedings","","","","","","","10.1109/ISSE54508.2022.10005441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146916854&doi=10.1109%2fISSE54508.2022.10005441&partnerID=40&md5=1de6583a4edf76225507a1c116b743d3","Highly Automated Driving (HAD) has become one of the leading trends in the automotive industry. Mandatory tasks like environment perception and scene understanding challenge existing rule-based methods. Thus, data-driven technologies and Artificial Intelligence (AI) have been introduced to automotive software development. Utilizing data in the development process has become essential as these systems are no longer developed with classical systems engineering methods, but rather by deriving requirements from and training the algorithms with recorded real-world data. This entails the introduction of data-driven workflows and data-management as new aspects of Automotive Systems Engineering (ASE). Tasks related to the development of Artificial Intelligence (AI) software differ from their classical engineering and programming counterparts. Thus, engineers require new tools and methods for developing safe and accurate AI-based software and handling data efficiently during ASE. Another important aspect of data-driven development is ensuring data quality throughout the systems engineering process. Hence, this paper aims to take a step towards the introduction of a data engineering process in data-driven automotive systems engineering. Putting a spotlight on developing well-designed data sets as the central element for training and validating AI-based software. Besides determining the quality of data sets, we present steps towards improving data and data set quality.  © 2022 IEEE.","2-s2.0-85146916854"
"Liartis J.; Dervakos E.; Menis-Mastromichalakis O.; Chortaras A.; Stamou G.","Liartis, Jason (57347033300); Dervakos, Edmund (57223037573); Menis-Mastromichalakis, Orfeas (57219553208); Chortaras, Alexandros (13204472900); Stamou, Giorgos (7004137698)","57347033300; 57223037573; 57219553208; 13204472900; 7004137698","Searching for explanations of black-box classifiers in the space of semantic queries","2022","Semantic Web","1","","","1","42","41","10.3233/SW-233469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176397455&doi=10.3233%2fSW-233469&partnerID=40&md5=6336be8d4c8b196c0a7c9ba55eaf5d34","Deep learning models have achieved impressive performance in various tasks, but they are usually opaque with regards to their inner complex operation, obfuscating the reasons for which they make decisions. This opacity raises ethical and legal concerns regarding the real-life use of such models, especially in critical domains such as in medicine, and has led to the emergence of the eXplainable Artificial Intelligence (XAI) field of research, which aims to make the operation of opaque AI systems more comprehensible to humans. The problem of explaining a black-box classifier is often approached by feeding it data and observing its behaviour. In this work, we feed the classifier with data that are part of a knowledge graph, and describe the behaviour with rules that are expressed in the terminology of the knowledge graph, that is understandable by humans. We first theoretically investigate the problem to provide guarantees for the extracted rules and then we investigate the relation of “explanation rules for a specific class” with “semantic queries collecting from the knowledge graph the instances classified by the black-box classifier to this specific class”. Thus we approach the problem of extracting explanation rules as a semantic query reverse engineering problem. We develop algorithms for solving this inverse problem as a heuristic search in the space of semantic queries and we evaluate the proposed algorithms on four simulated use-cases and discuss the results. © 2023 – The authors.","2-s2.0-85176397455"
"Czere J.T.; Pentek M.","Czere, Janos Tibor (57960642400); Pentek, Marta (23111917300)","57960642400; 23111917300","Exploring the Feasibility of the Meta-Analysis of Randomized Controlled Trials on Artificial Intelligence Chatbots for Use in Healthcare Based on a Published Systematic Review","2022","SISY 2022 - IEEE 20th Jubilee International Symposium on Intelligent Systems and Informatics, Proceedings","","","","53","58","5","10.1109/SISY56759.2022.10036294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149105730&doi=10.1109%2fSISY56759.2022.10036294&partnerID=40&md5=b7e5a7814af4894ae31821507143ad33","Usage of artificial intelligence (AI) based chatbot systems has been increasing not only in many industrial fields but also in the health care system. The effectiveness of AI chatbot systems as therapeutic tools has to be confirmed by clinical trials. Meta-analysis, a statistical method that synthetizes results of multiple studies thus increases the power of the findings. In this paper, our focus is on randomized controlled trials (RCTs) for the purpose of studying the effectiveness of AI chatbots used for healthcare purposes and analyzing step by step their applicability for meta-analysis. This article is based on a systematic literature review that identified eight RCTs. Only two RCTs (in the field of mental health) were feasible for meta-analysis. Standardization of the RCTs, development of points to consider as guidelines for conducting clinical trials with AI chatbots in diverse clinical areas could efficiently increase the strength of the studies and enable meta-analyses.  © 2022 IEEE.","2-s2.0-85149105730"
"Szczekocka E.; Tarnec C.; Pieczerak J.","Szczekocka, Ewelina (55210906500); Tarnec, Christele (58100743400); Pieczerak, Janusz (56022553200)","55210906500; 58100743400; 56022553200","Standardization on Bias in Artificial Intelligence as Industry Support","2022","Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022","","","","5090","5099","9","10.1109/BigData55660.2022.10020735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147965424&doi=10.1109%2fBigData55660.2022.10020735&partnerID=40&md5=c6929cbea159a18d43e45d0d4fb91789","Industry strives for trustworthy Artificial Intelligence (AI) systems through recognizing and implementing Responsible AI principles. Solutions supporting that goal are of the utmost interest in that context. Standardization is an essential element here, as it provides a platform for industry to discuss and facilitate not only the development of practical rules and requirements but also ways to implement AI based systems. One of Responsible AI principles is fairness, and bias is a serious obstacle against it. First, we explain the concept of Responsible AI and highlight results of our analysis on bias and fairness in ongoing international standardization works and AI Act (AIA). We identified a gap between the principles defined by high-level studies, including the AIA, and their practical implementations, and differences within standardization and research works. Second, we draw a standardization map for AI works. Finally, we state how international standardization bodies may fill this gap? © 2022 IEEE.","2-s2.0-85147965424"
"Puri V.; Kataria A.; Solanki V.K.; Rani S.","Puri, Vikram (57189093819); Kataria, Aman (57208667528); Solanki, Vijender Kumar (55823149200); Rani, Sita (57248574400)","57189093819; 57208667528; 55823149200; 57248574400","AI-based botnet attack classification and detection in IoT devices","2022","Proceedings of the 2022 IEEE International Conference on Machine Learning and Applied Network Technologies, ICMLANT 2022","","","","","","","10.1109/ICMLANT56191.2022.9996464","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146734075&doi=10.1109%2fICMLANT56191.2022.9996464&partnerID=40&md5=29925cd121a4b5b61e8442317f73771c","End-user Internet of Things (IoT) devices, including security cameras, smart appliances, home monitors, and thermostats, are becoming more prevalent in households. Additionally, the proliferation of devices facilitates the propagation of security concerns like DoS and spoofing. However, it is difficult for conventional rule-based security systems to recognize IoT assaults due to the development of heterogenous devices in the IoT ecosystem. Artificial Intelligence (AI) techniques can be a solution which enables the creation of an effective security model based on actual data from each device. In this work, IoT botnets are detected and classified using machine learning (ML) and deep learning (DL) based algorithms. Six ML models and three DL models are used to assess the system's performance. The best-performing model is also implemented as an API.  © 2022 IEEE.","2-s2.0-85146734075"
"Ziegler D.M.; Nix S.; Chan L.; Bauman T.; Schmidt-Nielsen P.; Lin T.; Scherlis A.; Nabeshima N.; Weinstein-Raun B.; de Haas D.; Shlegeris B.; Thomas N.","Ziegler, Daniel M. (57219500281); Nix, Seraphina (57704700500); Chan, Lawrence (57208164126); Bauman, Tim (57704014000); Schmidt-Nielsen, Peter (35559829600); Lin, Tao (57703321200); Scherlis, Adam (56971479500); Nabeshima, Noa (57704922000); Weinstein-Raun, Ben (57704014100); de Haas, Daniel (57704238900); Shlegeris, Buck (57219632529); Thomas, Nate (57703779400)","57219500281; 57704700500; 57208164126; 57704014000; 35559829600; 57703321200; 56971479500; 57704922000; 57704014100; 57704238900; 57219632529; 57703779400","Adversarial training for high-stakes reliability","2022","Advances in Neural Information Processing Systems","35","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148749810&partnerID=40&md5=9be0c2ff5fe0eca08a463528b0fb586d","In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high-stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance. In this work, we used a safe language generation task (“avoid injuries”) as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques-including a tool that assists human adversaries-to find and eliminate failures in a classifier that filters text completions suggested by a generator. In our task, we determined that we can set very conservative classifier thresholds without significantly impacting the quality of the filtered outputs. We found that adversarial training increased robustness to the adversarial attacks that we trained on-doubling the time for our contractors to find adversarial examples both with our tool (from 13 to 26 minutes) and without (from 20 to 44 minutes)-without affecting in-distribution performance. We hope to see further work in the high-stakes reliability setting, including more powerful tools for enhancing human adversaries and better ways to measure high levels of reliability, until we can confidently rule out the possibility of catastrophic deployment-time failures of powerful models. © 2022 Neural information processing systems foundation. All rights reserved.","2-s2.0-85148749810"
"Zhang T.; Qiu H.; Mellia M.; Li Y.; Li H.; Xu K.","Zhang, Tianzhu (57194420747); Qiu, Han (56669200900); Mellia, Marco (6603904712); Li, Yuanjie (56368710500); Li, Hewu (8332351200); Xu, Ke (56878066700)","57194420747; 56669200900; 6603904712; 56368710500; 8332351200; 56878066700","Interpreting AI for Networking: Where We Are and Where We Are Going","2022","IEEE Communications Magazine","60","2","","25","31","6","10.1109/MCOM.001.2100736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126269961&doi=10.1109%2fMCOM.001.2100736&partnerID=40&md5=3b4aa5f151b7862d384bd81ab9092439","In recent years, artificial intelligence (AI) techniques have been increasingly adopted to tackle networking problems. Although AI algorithms can deliver high-quality solutions, most of them are inherently intricate and erratic for human cognition. This lack of interpretability tremendously hinders the commercial success of AI-based solutions in practice. To cope with this challenge, networking researchers are starting to explore explainable AI (XAI) techniques to make AI models interpretable, manageable, and trustworthy. In this article, we overview the application of AI in networking and discuss the necessity for interpretability. Next, we review the current research on interpreting AI-based networking solutions and systems. At last, we envision future challenges and directions. The ultimate goal of this article is to present a general guideline for AI and networking practitioners and motivate the continuous advancement of AI-based solutions in modern communication networks.  © 1979-2012 IEEE.","2-s2.0-85126269961"
"Man Li R.Y.; Crabbe M.J.C.","Man Li, Rita Yi (58304214900); Crabbe, M. James C. (56913081000)","58304214900; 56913081000","Artificial Intelligence Robot Safety: A Conceptual Framework and Research Agenda Based on New Institutional Economics and Social Media","2022","Current State of Art in Artificial Intelligence and Ubiquitous Cities","","","","41","61","20","10.1007/978-981-19-0737-1_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146218810&doi=10.1007%2f978-981-19-0737-1_3&partnerID=40&md5=71daea023756c681df520d7b85d25a21","According to “Huang’s law”, Artificial intelligence (AI)-related hardware increases in power 4–10 times per year. AI can benefit various stages of real estate development, from planning and construction to occupation and demolition. However, Hong Kong’s legal system is currently behind when it comes to technological abilities, while the field of AI safety in built environments is still in its infancy. Negligent design and production processes, irresponsible data management, questionable deployment, algorithm training, sensor design and/or manufacture, unforeseen consequences from multiple data inputs, and erroneous AI operation based on sensor or remote data can all lead to accidents. Yet, determining how legal rules should apply to liability for losses caused by AI systems takes time. Traditional product liability laws can apply for some systems, meaning that the manufacturer will bear responsibility for a malfunctioning part. That said, more complex cases will undoubtedly have to come before the courts to determine whether something unsafe should be the manufacturer’s fault or the individual’s fault, as well as who should receive the subsequent financial and/or non-financial compensation, etc. Since AI adoption has an inevitable relationship with safety concerns, this project intends to shed light on responsible AI development and usage, with a specific focus on AI safety laws, policies, and people’s perceptions. We will conduct a systematic literature review via the PRISMA approach to study the academic perspectives of AI safety policies and laws and data-mining publicly available content on social media platforms such as Twitter, YouTube, and Reddit to study societal concerns about AI safety in built environments. We will then research court cases and laws related to AI safety in 61 jurisdictions, in addition to policies that have been implemented globally. Two case studies on AI suppliers that sell AI hardware and software to users of built environment will also be included. Another two case studies will be conducted on built environment companies (a contractor and Hong Kong International Airport) that use AI safety tools. The results obtained from social media, court cases, legislation, and policies will be discussed with local and international experts via a workshop, then released to the public to provide the international community and Hong Kong with unique policy and legal orientations. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.","2-s2.0-85146218810"
"Thrun M.C.","Thrun, Michael C. (56450887700)","56450887700","Exploiting Distance-Based Structures in Data Using an Explainable AI for Stock Picking","2022","Information (Switzerland)","13","2","51","","","","10.3390/info13020051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123046635&doi=10.3390%2finfo13020051&partnerID=40&md5=383e035c1d0575dfd24a479bbae921f1","In principle, the fundamental data of companies may be used to select stocks with a high probability of either increasing or decreasing price. Many of the commonly known rules or used explanations for such a stock-picking process are too vague to be applied in concrete cases, and at the same time, it is challenging to analyze high-dimensional data with a low number of cases in order to derive data-driven and usable explanations. This work proposes an explainable AI (XAI) approach on the quarterly available fundamental data of companies traded on the German stock market. In the XAI, distance-based structures in data (DSD) that guide decision tree induction are identified. The leaves of the appropriately selected decision tree contain subsets of stocks and provide viable explanations that can be rated by a human. The prediction of the future price trends of specific stocks is made possible using the explanations and a rating. In each quarter, stock picking by DSD-XAI is based on understanding the explanations and has a higher success rate than arbitrary stock picking, a hybrid AI system, and a recent unsupervised decision tree called eUD3.5. © 2022 by the author. Licensee MDPI, Basel, Switzerland.","2-s2.0-85123046635"
"Shirvani-Hosseini S.; Samadi-Koucheksaraee A.; Ahmadianfar I.; Gharabaghi B.","Shirvani-Hosseini, Seyedehelham (57486304000); Samadi-Koucheksaraee, Arvin (57194609788); Ahmadianfar, Iman (57074098100); Gharabaghi, Bahram (6507404820)","57486304000; 57194609788; 57074098100; 6507404820","Data Mining Methods for Modeling in Water Science","2022","Studies in Computational Intelligence","1043","","","157","178","21","10.1007/978-981-19-2519-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134166681&doi=10.1007%2f978-981-19-2519-1_8&partnerID=40&md5=2a7b28fcb4f9a1a9c6b41a3522f7d174","One of the most useful research fields with many real-life applications, such as in water science, is the subject of data mining. Data mining (DM) is considered a process to extract valuable data from a wide range of information stored in various databases. The data is categorized into the form of patterns, associations, changes, anomalies and significant structures. In water recourses management and environmental engineering, predicting and modelling parameters play an integral role in decision making. The most critical freshwater water resource for millions of people worldwide are rivers with a dynamic nature (floods/droughts), in terms of available freshwater quantity and quality. With various basin characteristics, river flow and sediment regime may be influenced by natural processes such as erosion and sediment transport as well as anthropogenic factors such as urban stormwater runoff and semi-treated sanitary/industrial sewage discharge. Therefore, artificial intelligence (AI) techniques are used to decrease model development costs and improve prediction errors, achieving more efficient models. In this chapter, some well-known techniques and AI-based methods are introduced, and their applications are elaborated. The models are comprised of extreme learning machine (ELM), least square support vector machine (LSSVM), genetic programming (GP), adaptive neural-fuzzy inference system (ANFIS), and multivariate adaptive regression spline (MARS). Each technique, then, is illustrated with a brief literature review. Having being evaluated in terms of the basic concept, the methods are addressed based on a mathematical statement. In the last part, the pseudocode of the ways, an acceptable guideline for coding the methods, is pointed out. This chapter is collected for graduate students, researchers, educators, and practitioners interested in engineering optimization. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85134166681"
"Meschini S.; Tagliabue L.C.; Di Giuda G.M.","Meschini, Silvia (57191869544); Tagliabue, Lavinia C. (18042749100); Di Giuda, Giuseppe M. (56523362500)","57191869544; 18042749100; 56523362500","Leveraging Digital Twins to Enhance Green Public Procurement in AECO Industry","2022","CEUR Workshop Proceedings","3285","","","26","38","12","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143413486&partnerID=40&md5=42c0895d313b4b81ca4b927c5c2b7add","The digital transition of process management and Digital Twins (DTs) are promising to bridge the gap towards Product Lifecycle Management (PLM) and revolutionize decision-making processes in AECO (Architectural, Engineering, Construction and Operation) industry. Public procurement particularly suffers of poor digitalization with ineffective processes and low adoption of Green Public Procurement (GPP) mainly due to the lack of digital and automated data-driven tools for tender evaluation. Leveraging DTs as virtual Prototypes (DTPs) could help to overcome the current discrete project performances evaluation and enable a systemic one, exploitable for bids evaluation besides performance and sustainability optimization. The research adopts a PLM view to define a methodology aimed at developing DTPs starting from the bidding BIM models. The main objective is to integrate several DTPs and an Artificial Intelligence (AI) system in the aim automatizing MEAT (Most Economic Advantageous Tender) procedure and promote GPP adoption, providing an optimal and more objective data-driven awarding system and criteria weighting. Three crucial objectives should be accomplished: (i) the definition of a replicable methodology to develop the DTPs, (ii) the definition of their informative structure and (iii) the re-engineering of tender processes to bring full digitalization and automation. This could enable more effective decisions and performance optimization, bids objective evaluation, tendering procedure streamlining, transparency and sustainability enhancement. The awarded DTP, as a truthful “As-built” developed accordingly to defined information guidelines, must be exploited as the basis for valuable DTIs to manage the whole lifecycle, optimizing DTs development costs together with operational and maintenance costs. © 2022 Copyright for this paper by its authors.","2-s2.0-85143413486"
"Sundar A.S.; Heck L.","Sundar, Anirudh S. (57713771400); Heck, Larry (7005241213)","57713771400; 7005241213","Multimodal Conversational AI A Survey of Datasets and Approaches","2022","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","131","147","16","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136041619&partnerID=40&md5=f9672bc1550bc8f5563641b101d06ddd","As humans, we experience the world with all our senses or modalities (sound, sight, touch, smell, and taste). We use these modalities, particularly sight and touch, to convey and interpret specific meanings. Multimodal expressions are central to conversations; a rich set of modalities amplify and often compensate for each other. A multimodal conversational AI system answers questions, fulfills tasks, and emulates human conversations by understanding and expressing itself via multiple modalities. This paper motivates, defines, and mathematically formulates the multimodal conversational research objective. We provide a taxonomy of research required to solve the objective: multimodal representation, fusion, alignment, translation, and co-learning. We survey state-of-the-art datasets and approaches for each research area and highlight their limiting assumptions. Finally, we identify multimodal co-learning as a promising direction for multimodal conversational AI research. © 2022 Association for Computational Linguistics.","2-s2.0-85136041619"
"Kerrigan C.; Vercoe O.","Kerrigan, Charles (57879490100); Vercoe, Oliver (57878553700)","57879490100; 57878553700","EXPLAINABLE AI AND RESPONSIBLE AI","2022","Artificial Intelligence: Law and Regulation","","","","527","533","6","10.4337/9781800371729.00043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137439975&doi=10.4337%2f9781800371729.00043&partnerID=40&md5=1b0d682897b3073d76962e4a411f608c","Chapter 29 relating to Explainable AI and Responsible AI 'sets out' the 'black box'problem. This is so often discussed in the mainstream media now that it has become a cliché. The book, and this chapter in particular, unpicks the cliché. Part of this involves education on how AI systems operate, how XAI works, how rules and standards operate in the context of AI, and how to apply ethical considerations to AI. The chapter includes explanations of explainability (!) and points the way towards toolkits to be used in practice. © The Editor and Contributors Severally 2022. All rights reserved.","2-s2.0-85137439975"
"Whilde E.T.; Lane J.; Dickson C.; Mah-E-Fatima S.; Fatimah Q.A.; Hasnain A.","Whilde, Elaine Taylor (58765506100); Lane, Janine (57293435700); Dickson, Chris (58765506200); Mah-E-Fatima, Syeda (58765568400); Fatimah, Qurratal Ain (57215763080); Hasnain, Ali (25031022900)","58765506100; 57293435700; 58765506200; 58765568400; 57215763080; 25031022900","Woubot®: A personalized predictive AI system for hard to heal wounds","2022","CEUR Workshop Proceedings","3573","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179852203&partnerID=40&md5=2fc6fec23f86b4630ddfd37304de6966","Management of chronic wounds in healthcare disciplines is a huge financial burden on healthcare systems around the world. An estimated 1.5-2 million patients in Europe alone suffer from acute or chronic wounds at a given time. The mental and societal burden of living with a chronic wound is immense. Many studies have shown that treatment of these wounds conservatively (without surgery) is one of the major contributing factors to the cost, with wound dressings being a significant impactr. Data from the NHS shows that managing wounds properly such as choosing the appropriate dressing for the right wound and continuous appropriate treatment can significantly increase healing and reduce healthcare spending. Funded by the National Institute of Health Research and NHS England the AI in Health and Care Award Accelerated Access Collaborative (AAC) and NHS AI Lab supported AI technologies across the spectrum of development, from initial feasibility to evaluation within clinical pathways in the NHS and social care settings, to the point that they could be nationally commissioned. In this paper, the findings of a phase 1, project a feasibility study are introduced for discussion and shared learning about an artificial intelligence-based technology which aims in phase 2 to predict the development of hard to heal wounds and their rates of healing and produce recommendations for clinicians dealing with wound care. Woubot® will evaluate the risks of different wound treatments and predict and monitor the progression of wounds. Considering national guidelines on treatment as well as data available, improvements in practice will be recommended, and tailored treatment plans will be suggested for individual patients. Early analysis of patient data (combined electronic clinical records containing demographic, historical, laboratory tests, intervention details etc.) was completed over a 12-month period. The impact of biological factors affecting wound healing suggested that changes in clinical practice such as carrying out a blood test to detect for example vitamin B12 levels and other circulatory factors could significantly improve wound healing rates. The findings suggest that once detected either simple lifestyle changes (diet) or a clinical intervention e.g., B12 injections may result in improved healing. Initial assessments show the monetized benefits of using Woubot® have been predicted to be around £35 million over a period of 10 years, which is a substantial development in the future of wound management. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85179852203"
"Manodnya K.H.; Giri A.","Manodnya, K.H. (58066360300); Giri, Animesh (57193057558)","58066360300; 57193057558","GPT-K: A GPT-based model for generation of text in Kannada","2022","Proceedings of 4th International Conference on Cybernetics, Cognition and Machine Learning Applications, ICCCMLA 2022","","","","534","539","5","10.1109/ICCCMLA56841.2022.9989289","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146318240&doi=10.1109%2fICCCMLA56841.2022.9989289&partnerID=40&md5=ff2a287f0be6c192a3192a6398859ba5","Large AI-based language models are changing how we work with language. They are becoming increasingly popular because they allow us to create complex linguistic structures without requiring a lot of resources. A language model must have access to a large corpus of linguistic data (e.g., word frequencies) to learn and generate new words. GPT-2, a language model, can generate coherent paragraphs independently, without any input on what to write about or guidance on grammar rules. Although multiple pre-trained GPT-2 models exist for English and other high-resource languages, there are few to no such models for Indic languages like Kannada. In this study, we propose GPT-K, a GPT-2 based model for language modeling in Kannada. GPT-K has been trained on a large corpus of Kannada text and can effectively perform language modeling tasks in Kannada. The model generated syntactically correct text in most cases. © 2022 IEEE.","2-s2.0-85146318240"
"Guo J.; Wen C.; Jin S.; Li X.","Guo, Jiajia (56161255400); Wen, Chao-Kai (7201367144); Jin, Shi (55243233900); Li, Xiao (55637288300)","56161255400; 7201367144; 55243233900; 55637288300","AI for CSI Feedback Enhancement in 5G-Advanced","2022","IEEE Wireless Communications","","","","1","8","7","10.1109/MWC.010.2200304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144772592&doi=10.1109%2fMWC.010.2200304&partnerID=40&md5=b0c8044606379ea07ea9f2589f6fa522","The 3rd Generation Partnership Project started the study of Release 18 in 2021. Artificial intelligence (AI)-native air interface is one of the key features of Release 18, where AI for channel state information (CSI) feedback enhancement is selected as the representative use case. This article provides an overview of AI for CSI feedback enhancement in 5G-Advanced. Several representative non-AI and AI-enabled CSI feedback frameworks are first introduced and compared. Then, the standardization of AI for CSI feedback enhancement in 5G-advanced is presented in detail. First, the scope of the AI for CSI feedback enhancement in 5G-Advanced is presented and discussed. Then, the main challenges and open problems in the standardization of AI for CSI feedback enhancement, especially focusing on performance evaluation and the design of new protocols for AI-enabled CSI feedback, are identified and discussed. This article provides a guideline for the standardization study of AI-based CSI feedback enhancement. IEEE","2-s2.0-85144772592"
"Bravo-Rocca G.; Liu P.; Guitart J.; Dholakia A.; Ellison D.; Hodak M.","Bravo-Rocca, Gusseppe (57194494010); Liu, Peini (57221089689); Guitart, Jordi (9737380700); Dholakia, Ajay (57205738370); Ellison, David (57207566384); Hodak, Miroslav (57205741518)","57194494010; 57221089689; 9737380700; 57205738370; 57207566384; 57205741518","Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation","2022","Proceedings - 2022 IEEE 46th Annual Computers, Software, and Applications Conference, COMPSAC 2022","","","","32","37","5","10.1109/COMPSAC54236.2022.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136964552&doi=10.1109%2fCOMPSAC54236.2022.00014&partnerID=40&md5=719fc2698899b949f50f6fd1207c8fdd","Increasing a ML model accuracy is not enough, we must also increase its trustworthiness. This is an important step for building resilient AI systems for safety-critical applications such as automotive, finance, and healthcare. For that purpose, we propose a multi-agent system that combines both machine and human agents. In this system, a checker agent calculates a trust score of each instance (which penalizes overconfidence in predictions) using an agreement-based method and ranks it; then an improver agent filters the anomalous instances based on a human rule-based procedure (which is considered safe), gets the human labels, applies geometric data augmentation, and retrains with the augmented data using transfer learning. We evaluate the system on corrupted versions of the MNIST and FashionMNIST datasets. We get an improvement in accuracy and trust score with just few additional labels compared to a baseline approach. © 2022 IEEE.","2-s2.0-85136964552"
"Rendon L.G.","Rendon, L. Grisales (57795229100)","57795229100","An Introduction to the Principle of Transparency in Automated Decision-Making Systems","2022","2022 45th Jubilee International Convention on Information, Communication and Electronic Technology, MIPRO 2022 - Proceedings","","","","1245","1252","7","10.23919/MIPRO55190.2022.9803417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133896467&doi=10.23919%2fMIPRO55190.2022.9803417&partnerID=40&md5=16d3694f74e3a8dbef126a16f31dea83","Under current European data protection law and the approach of the European Commission regarding artificial intelligence (AI) development, the principle of transparency and explainability by design are essential to protect the data subject's rights and generate confidence in AI systems. However, a closer look reveals that the legal approach ignores limitations of the transparency principle in the practical application of automated-decision making systems. Current transparency rules also require a high standard of transparency in automated decisions due to its potential risks.This paper seeks to analyze the scope of the principle of transparency and its limitations in the practical field, suggesting a division of data subjects to provide automated decision-making explanations according to their level of expertise to reach the transparency principle's goal: user understanding. The paper will address the semantic discussion of whether this objective is achieved through interpretability, explainability, accountability or, transparency in the broad sense. It also maps out the analysis about guidance to address transparency through a certification mechanism, contestability by design, or supplementary post hoc explanations in AI systems. © 2022 Croatian Society MIPRO.","2-s2.0-85133896467"
"Pfeuffer N.","Pfeuffer, Nicolas (57210111932)","57210111932","Design Principles for (X)AI-based Patient Education Systems","2022","Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)","P-319","","","143","157","14","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136257097&partnerID=40&md5=50c49bb8e29bf6ebb52935f1211018c3","Recently, the management of chronic diseases has advanced to a prime topic for Information Systems (IS) research and practice. With increasing capability of Information Technology, patients are empowered to engage in self-management of chronic diseases connected to promises of health benefits for the individual as well as an unburdening of clinics and economic advantages for health care systems. Nevertheless, patients must be adequately educated about risks, screening and examination options to make patient self-management effective, sustainable and profitable. In this regard, Explainable Artificial Intelligence ((X)AI)-based Patient Education Systems (PES) may be an opportunity to provide patient education in an interactive, intelligible and intelligent manner. By establishing Design Principles (DP) for the engineering of effective (X)AIbased PES, instantiating them in a system prototype and evaluating the DP with the help of general practitioners, this paper contributes to the body of knowledge in designing health IS. © 2022 Gesellschaft fur Informatik (GI). All rights reserved.","2-s2.0-85136257097"
"Bobek S.; Kuk M.; Szelazek M.; Nalepa G.J.","Bobek, Szymon (49661044900); Kuk, Michal (57218769050); Szelazek, MacIej (57219785933); Nalepa, Grzegorz J. (55879229400)","49661044900; 57218769050; 57219785933; 55879229400","Enhancing Cluster Analysis With Explainable AI and Multidimensional Cluster Prototypes","2022","IEEE Access","10","","","101556","101574","18","10.1109/ACCESS.2022.3208957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139414159&doi=10.1109%2fACCESS.2022.3208957&partnerID=40&md5=626cd73eaaa852d758aadd74a82991e6","Explainable Artificial Intelligence (XAI) aims to introduce transparency and intelligibility into the decision-making process of AI systems. Most often, its application concentrates on supervised machine learning problems such as classification and regression. Nevertheless, in the case of unsupervised algorithms like clustering, XAI can also bring satisfactory results. In most cases, such application is based on the transformation of an unsupervised clustering task into a supervised one and providing generalised global explanations or local explanations based on cluster centroids. However, in many cases, the global explanations are too coarse, while the centroid-based local explanations lose information about cluster shape and distribution. In this paper, we present a novel approach called ClAMP (Cluster Analysis with Multidimensional Prototypes) that aids experts in cluster analysis with human-readable rule-based explanations. The developed state-of-the-art explanation mechanism is based on cluster prototypes represented by multidimensional bounding boxes. This allows representing of arbitrary shaped clusters and combines the strengths of local explanations with the generality of global ones. We demonstrate and evaluate the use of our approach in a real-life industrial case study from the domain of steel manufacturing as well as on the benchmark datasets. The explanations generated with ClAMP were more precise than either centroid-based or global ones.  © 2013 IEEE.","2-s2.0-85139414159"
"Chakraborty S.; Paul H.; Ghatak S.; Pandey S.K.; Kumar A.; Singh K.U.; Shah M.A.","Chakraborty, Sanjay (57169636900); Paul, Hrithik (58040112200); Ghatak, Sayani (58040208000); Pandey, Saroj Kumar (57202704001); Kumar, Ankit (57209569655); Singh, Kamred Udham (57211279213); Shah, Mohd Asif (58090397100)","57169636900; 58040112200; 58040208000; 57202704001; 57209569655; 57211279213; 58090397100","An AI-Based Medical Chatbot Model for Infectious Disease Prediction","2022","IEEE Access","10","","","128469","128483","14","10.1109/ACCESS.2022.3227208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145435300&doi=10.1109%2fACCESS.2022.3227208&partnerID=40&md5=703ab0781c2cbb85cc595f408d112bc3","The purpose of this paper is to show concisely how we can promote chatbots in the medical sector and cure infectious diseases. We can create awareness through the users and the users can get proper medical solutions to prevent disease. We created a preliminary training model and a study report to improve human interaction in databases in 2021. Through natural language processing, we describe the human behaviors and characteristics of the chatbot. In this paper, we propose an AI Chatbot interaction and prediction model using a deep feedforward multilayer perceptron. Our analysis discovered a gap in knowledge about theoretical guidelines and practical recommendations for creating AI chatbots for lifestyle improvement programs. A brief comparison of our proposed model concerning the time complexity and accuracy of testing is also discussed in this paper. In our work, the loss is a minimum of 0.1232 and the highest accuracy is 94.32%. This study describes the functionalities and possible applications of medical chatbots and explores the accompanying challenges posed by the use of these emerging technologies during such health crises mainly posed by pandemics. We believe that our findings will help researchers get a better understanding of the layout and applications of these revolutionary technologies, which will be required for continuous improvement in medical chatbot functionality and will be useful in avoiding COVID-19.  © 2013 IEEE.","2-s2.0-85145435300"
"Agarwal B.; Urlings C.; van Lankveld G.; Klemke R.","Agarwal, Bhoomika (57171753100); Urlings, Corrie (57211854329); van Lankveld, Giel (36134136600); Klemke, Roland (16230731700)","57171753100; 57211854329; 36134136600; 16230731700","Ethical FRAPPE - an adapted draft framework for ethical AIED","2022","CEUR Workshop Proceedings","3292","","","46","54","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143789685&partnerID=40&md5=b9f3ccf7702f48716477d9e94a41644a","Artificial Intelligence (AI) is pervading our lives in numerous ways today. It is important to apply ethical principles to guide the development and usage of AI systems to prevent harms or discrimination through AI algorithms. This has led to various ethical regulations and guidelines being formed at the corporate, national and supra-national level. The EU AI Act classifies the usage of AI in education as 'high-risk' as “such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination” [1, p. 26]. However, there has been little attention paid to ethics in AI in Education (AIED) in literature and there is only one existing framework to ethically guide AIED. AIED ethics is complex as it has to combine both general AI ethics and the ethics of educational technology. We aim to create a theoretical framework for AIED, comprising implementation guidelines for developers and organizational users of AI in education. In this paper, an existing draft framework by Holmes et al. is adapted by using insights from literature in the ethics of AI, ethics of educational technology and ethics of AIED. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85143789685"
"Kachuee M.; Nam J.; Ahuja S.; Won J.-M.; Lee S.","Kachuee, Mohammad (56943447900); Nam, Jinseok (56358265900); Ahuja, Sarthak (57669174100); Won, Jin-Myung (57667518700); Lee, Sungjin (57203128754)","56943447900; 56358265900; 57669174100; 57667518700; 57203128754","Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems","2022","NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Industry Papers","","","","1","8","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137728094&partnerID=40&md5=15e5d31f50bb1eb278d2dcea9a5a1b69","Skill routing is an important component in large-scale conversational systems. In contrast to traditional rule-based skill routing, state-of-the-art systems use a model-based approach to enable natural conversations. To provide supervision signal required to train such models, ideas such as human annotation, replication of a rule-based system, relabeling based on user paraphrases, and bandit-based learning were suggested. However, these approaches: (a) do not scale in terms of the number of skills and skill on-boarding, (b) require a very costly expert annotation/rule-design, (c) introduce risks in the user experience with each model update. In this paper, we present a scalable self-learning approach to explore routing alternatives without causing abrupt policy changes that break the user experience, learn from the user interaction, and incrementally improve the routing via frequent model refreshes. To enable such robust frequent model updates, we suggest a simple and effective approach that ensures controlled policy updates for individual domains, followed by an off-policy evaluation for making deployment decisions without any need for lengthy A/B experimentation. We conduct various offline and online A/B experiments on a commercial large-scale conversational system to demonstrate the effectiveness of the proposed method in real-world production settings. © 2022 Association for Computational Linguistics.","2-s2.0-85137728094"
"Woensel W.V.; Scioscia F.; Loseto G.; Seneviratne O.; Patton E.; Abidi S.; Kagal L.","Woensel, William Van (57290000900); Scioscia, Floriano (23036414100); Loseto, Giuseppe (36640050200); Seneviratne, Oshani (36697042800); Patton, Evan (36025753600); Abidi, Samina (22033756700); Kagal, Lalana (57211739566)","57290000900; 23036414100; 36640050200; 36697042800; 36025753600; 22033756700; 57211739566","Explainable Clinical Decision Support: Towards Patient-Facing Explanations for Education and Long-Term Behavior Change","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13263 LNAI","","","57","62","5","10.1007/978-3-031-09342-5_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135033332&doi=10.1007%2f978-3-031-09342-5_6&partnerID=40&md5=98ee71583f5ee52f7bc39399003eb07a","There is an increasing shift towards the self-management of long-term chronic illness by patients in a home setting, supported by personal health electronic equipment. Among others, self-management requires comprehensive education on the illness, i.e., understanding the effects of nutritional, fitness, and medication choices on personal health; and long-term health behavior change, i.e., modifying unhealthy lifestyles that contribute to chronic illness. Smart health recommendations, generated using AI-based Clinical Decision Support (CDS), can guide patients towards positive nutritional, fitness, and health behavioral choices. Moreover, we posit that explaining these recommendations to patients, using Explainable AI (XAI) techniques, will effect education and positive behavior change. We present our work towards an explanation framework for rule-based CDS, called EXPLAIN (EXPLanations of AI In N3), which aims to generate human-readable, patient-facing explanations. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85135033332"
"Bilquise G.; Shaalan K.","Bilquise, Ghazala (57211990676); Shaalan, Khaled (6507669702)","57211990676; 6507669702","AI-based Academic Advising Framework: A Knowledge Management Perspective","2022","International Journal of Advanced Computer Science and Applications","13","8","","193","203","10","10.14569/IJACSA.2022.0130823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137169435&doi=10.14569%2fIJACSA.2022.0130823&partnerID=40&md5=601b0e4a979fa03754a9ed4e93eac02c","Academic advising has become a critical factor of students’ success as universities offer a variety of programs and courses in their curriculum. It is a student-centered initiative that fosters a student’s involvement with the institution by supporting students in their academic progression and career goals. Managing the knowledge involved in the advising process is crucial to ensure that the knowledge is available to those who need it and that it is used effectively to make good advising decisions that impact student persistence and success. The use of AI-based tools strengthens the advising process by reducing the workload of advisors and providing better decision support tools to improve the advising practice. This study explores the challenges associated with the current advising system from a knowledge management perspective and proposes an integrated AI-based framework to tackle the main advising tasks. © 2022, International Journal of Advanced Computer Science and Applications. All rights reserved.","2-s2.0-85137169435"
"Kuberkar S.; Singhal T.K.; Singh S.","Kuberkar, Sachin (57217537389); Singhal, Tarun Kumar (57703677600); Singh, Shikha (58130574700)","57217537389; 57703677600; 58130574700","Fate of AI for Smart City Services in India: A Qualitative Study","2022","International Journal of Electronic Government Research","18","2","","","","","10.4018/IJEGR.298216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137661464&doi=10.4018%2fIJEGR.298216&partnerID=40&md5=5c22d1f5ff0380b9c4afee10c539bd88","With the rollout of the smart city initiative in India, this study explores potential risks and opportunities in adopting artificial intelligence (AI) for citizen services. The study deploys expert interview technique, and the data collected from various sources are analyzed using qualitative analysis. It was found that AI implementation needs a critical examination of various socio-technological factors to avoid any undesirable impacts on citizens. Fairness, accountability, transparency, and ethics (FATE) play an important role during the design and execution of AI-based systems. This study provides vital insights into AI implications to smart city managers, citizen groups, and policymakers while delivering promised smart city experience. The study has social implications in terms of ensuring that proper guidelines are developed for using AI technology for citizen services, thereby bridging the ever-critical trust gap between citizens and city administration.  Copyright © 2022, IGI Global.","2-s2.0-85137661464"
"Lozhnikov P.S.; Zhumazhanova S.S.","Lozhnikov, P.S. (55027255900); Zhumazhanova, S.S. (57190336068)","55027255900; 57190336068","Potential Information Security Risks in the Implementation of AI - Based Systems","2022","16th International Scientific and Technical Conference ""Dynamics of Systems, Mechanisms and Machines"", Dynamics 2022 - Proceedings","","","","","","","10.1109/Dynamics56256.2022.10014814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147705146&doi=10.1109%2fDynamics56256.2022.10014814&partnerID=40&md5=aff3f2e600686005b488b01e6d3528d8","At present, technological solutions based on artificial intelligence (AI) are being accelerated in various sectors of the economy and social relations in the world. Practice shows that fast-developing information technologies, as a rule, carry new, previously unidentified threats to information security (IS). It is quite obvious that identification of vulnerabilities, threats and risks of AI technologies requires consideration of each technology separately or in some aggregate in cases of their joint use in application solutions. Of the wide range of AI technologies, data preparation, DevOps, Machine Learning (ML) algorithms, cloud technologies, microprocessors and public services (including Marketplaces) have received the most attention. Due to the high importance and impact on most AI solutions, this paper will focus on the key AI assets, the attacks and risks that arise when implementing AI-based systems, and the issue of building secure AI.  © 2022 IEEE.","2-s2.0-85147705146"
"Hickok M.","Hickok, Merve (57924217100)","57924217100","Public procurement of artificial intelligence systems: new risks and future proofing","2022","AI and Society","","","","","","","10.1007/s00146-022-01572-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139714305&doi=10.1007%2fs00146-022-01572-2&partnerID=40&md5=79f4bcde3e95971b7b4e890873c722cc","Public entities around the world are increasingly deploying artificial intelligence (AI) and algorithmic decision-making systems to provide public services or to use their enforcement powers. The rationale for the public sector to use these systems is similar to private sector: increase efficiency and speed of transactions and lower the costs. However, public entities are first and foremost established to meet the needs of the members of society and protect the safety, fundamental rights, and wellbeing of those they serve. Currently AI systems are deployed by the public sector at various administrative levels without robust due diligence, monitoring, or transparency. This paper critically maps out the challenges in procurement of AI systems by public entities and the long-term implications necessitating AI-specific procurement guidelines and processes. This dual-prong exploration includes the new complexities and risks introduced by AI systems, and the institutional capabilities impacting the decision-making process. AI-specific public procurement guidelines are urgently needed to protect fundamental rights and due process. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85139714305"
"Lam N.","Lam, Nardi (57412867800)","57412867800","Explanations in AI as Claims of Tacit Knowledge","2022","Minds and Machines","32","1","","135","158","23","10.1007/s11023-021-09588-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122866928&doi=10.1007%2fs11023-021-09588-1&partnerID=40&md5=600eb8223014b861529cc3d93979ce47","As AI systems become increasingly complex it may become unclear, even to the designer of a system, why exactly a system does what it does. This leads to a lack of trust in AI systems. To solve this, the field of explainable AI has been working on ways to produce explanations of these systems’ behaviors. Many methods in explainable AI, such as LIME (Ribeiro et al. in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016), offer only a statistical argument for the validity of their explanations. However, some methods instead study the internal structure of the system and try to find components which can be assigned an interpretation. I believe that these methods provide more valuable explanations than those statistical in nature. I will try to identify which explanations can be considered internal to the system using the Chomskyan notion of tacit knowledge. I argue that each explanation expresses a rule, and through the localization of this rule in the system internals, we can take a system to have tacit knowledge of the rule. I conclude that the only methods which are able to sufficiently establish this tacit knowledge are those along the lines of Olah (Distill 2(11): 4901–4911, 2017), and therefore they provide explanations with unique strengths. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85122866928"
"Jalaja T.; Adilakshmi T.; Sharat Chandra M.S.; Imran Mirza M.; Kumar M.V.S.","Jalaja, Tattari (57219418258); Adilakshmi, T. (54419425200); Sharat Chandra, Manchi Sarapu (57984965000); Imran Mirza, Mohammed (57985318400); Kumar, M.V. Sashi (57826860100)","57219418258; 54419425200; 57984965000; 57985318400; 57826860100","A Behavioral Chatbot Using Encoder-Decoder Architecture : Humanizing conversations","2022","Proceedings - 2022 2nd International Conference on Interdisciplinary Cyber Physical Systems, ICPS 2022","","","","51","54","3","10.1109/ICPS55917.2022.00017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142770960&doi=10.1109%2fICPS55917.2022.00017&partnerID=40&md5=53914bf8a7452f72f1f81af092305650","Though there are so many ways of building conversational chatbots, they lack the human touch and sound very robotic. We don't have any chatbots that aim to imitate even a speck of a personality or human-like traits, while we very well possess everything that we need in terms of data and computation. This project aims to make both efficient and human-like chatbot using the modern encoder-decoder architecture. There are many frameworks and libraries available to develop AI-based chatbots including program-based, rule-based and interface-based. But they lack the flexibility in developing real dialogues and understanding humans. The popular chatbot models don't aim to hold conversations that imitate real human-like interactions. Current chatbots employ a rule-based approach, basic machine learning algorithms, or a retrieval-based strategy that does not provide humanized outputs, i.e., these chatbots are incapable of producing engaging dialogues. In this paper, we tried to develop a Behavioural chatbot, using modern deep learning techniques like Seq2Seq aiming to develop chatbots to understand humans and make some situation agnostic conversations that remind us of our desirable personalities. This chatbot model was trained on real human conversations extracted out of Hollywood movies, hence the dataset possesses around 2.3 lakh truly organic dialogues. The model was trained with ~4.2 million parameters, 250 epochs and attained an accuracy of 95%. This chatbot is capable of displaying subtle sarcasm and also tries to be funny at times, thanks to the dramatic Hollywood dialogue writers.  © 2022 IEEE.","2-s2.0-85142770960"
"Adler R.; Klaes M.","Adler, Rasmus (22733254900); Klaes, Michael (57219526939)","22733254900; 57219526939","Assurance Cases as Foundation Stone for Auditing AI-Enabled and Autonomous Systems: Workshop Results and Political Recommendations for Action from the ExamAI Project","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13520 LNCS","","","283","300","17","10.1007/978-3-031-18158-0_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142671124&doi=10.1007%2f978-3-031-18158-0_21&partnerID=40&md5=ad0a185b264e2ef45d59e4e78928896d","The European Machinery Directive and related harmonized standards do consider that software is used to generate safety-relevant behavior of the machinery but do not consider all kinds of software. In particular, software based on machine learning (ML) are not considered for the realization of safety-relevant behavior. This limits the introduction of suitable safety concepts for autonomous mobile robots and other autonomous machinery, which commonly depend on ML-based functions. We investigated this issue and the way safety standards define safety measures to be implemented against software faults. Functional safety standards use Safety Integrity Levels (SILs) to define which safety measures shall be implemented. They provide rules for determining the SIL and rules for selecting safety measures depending on the SIL. In this paper, we argue that this approach can hardly be adopted with respect to ML and other kinds of Artificial Intelligence (AI). Instead of simple rules for determining an SIL and applying related measures against faults, we propose the use of assurance cases to argue that the individually selected and applied measures are sufficient in the given case. To get a first rating regarding the feasibility and usefulness of our proposal, we presented and discussed it in a workshop with experts from industry, German statutory accident insurance companies, work safety and standardization commissions, and representatives from various national, European, and international working groups dealing with safety and AI. In this paper, we summarize the proposal and the workshop discussion. Moreover, we check to which extent our proposal is in line with the European AI Act proposal and current safety standardization initiatives addressing AI and Autonomous Systems. © 2022, Springer Nature Switzerland AG.","2-s2.0-85142671124"
"Suárez-Figueroa M.C.; Diab I.; Ruckhaus E.; Cano I.","Suárez-Figueroa, Mari Carmen (56005389600); Diab, Isam (57807469000); Ruckhaus, Edna (10242585700); Cano, Isabel (57219166665)","56005389600; 57807469000; 10242585700; 57219166665","First steps in the development of a support application for easy-to-read adaptation","2022","Universal Access in the Information Society","","","","","","","10.1007/s10209-022-00946-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142153361&doi=10.1007%2fs10209-022-00946-z&partnerID=40&md5=313be346a28ee147e31d8410288af34f","The application of the easy-to-read (E2R) methodology is one of the ways to achieve cognitive accessibility and specifically, it is a path that guarantees the right of access to information of people with reading comprehension difficulties and thus improves their daily life. This methodology includes a set of guidelines and recommendations whose goal is to present clear and easily understood documents. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. These processes are very time and human-resource consuming, due to the need of involving E2R experts as well as people with cognitive disabilities. In order to alleviate such manual processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to support the E2R adaptation of documents in a (semi)-automatic fashion. The main goal of this research is to help E2R experts in their daily tasks of (a) assessing a particular document with respect to the E2R guidelines and (b) transforming such a document according to the E2R methodology. In this paper we present our initial efforts toward the development of an AI-based application for supporting the E2R adaptation of documents. These efforts are the elicitation of E2R needs and informal requirements and the design of an application called FACILE. © 2022, The Author(s).","2-s2.0-85142153361"
"Lundberg H.; Mowla N.I.; Abedin S.F.; Thar K.; Mahmood A.; Gidlund M.; Raza S.","Lundberg, Hampus (57918676400); Mowla, Nishat I (56811703000); Abedin, Sarder Fakhrul (56811073900); Thar, Kyi (56811684000); Mahmood, Aamir (36024046600); Gidlund, Mikael (25641313800); Raza, Shahid (35307658300)","57918676400; 56811703000; 56811073900; 56811684000; 36024046600; 25641313800; 35307658300","Experimental Analysis of Trustworthy In-Vehicle Intrusion Detection System Using eXplainable Artificial Intelligence (XAI)","2022","IEEE Access","10","","","102831","102841","10","10.1109/ACCESS.2022.3208573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139441364&doi=10.1109%2fACCESS.2022.3208573&partnerID=40&md5=89f23ff7df7096eec7776c82399502b3","Anomaly-based In-Vehicle Intrusion Detection System (IV-IDS) is one of the protection mechanisms to detect cyber attacks on automotive vehicles. Using artificial intelligence (AI) for anomaly detection to thwart cyber attacks is promising but suffers from generating false alarms and making decisions that are hard to interpret. Consequently, this issue leads to uncertainty and distrust towards such IDS design unless it can explain its behavior, e.g., by using eXplainable AI (XAI). In this paper, we consider the XAI-powered design of such an IV-IDS using CAN bus data from a public dataset, named 'Survival'. Novel features are engineered, and a Deep Neural Network (DNN) is trained over the dataset. A visualization-based explanation, 'VisExp', is created to explain the behavior of the AI-based IV-IDS, which is evaluated by experts in a survey, in relation to a rule-based explanation. Our results show that experts' trust in the AI-based IV-IDS is significantly increased when they are provided with VisExp (more so than the rule-based explanation). These findings confirm the effect, and by extension the need, of explainability in automated systems, and VisExp, being a source of increased explainability, shows promise in helping involved parties gain trust in such systems.  © 2013 IEEE.","2-s2.0-85139441364"
"Cheng H.; Conway E.; Heggedahl T.; Morgan J.; Schlessman B.","Cheng, Huaining (57218977608); Conway, Emily (58073540400); Heggedahl, Timothy (58072291900); Morgan, Justin (58071797800); Schlessman, Bradley (22951825700)","57218977608; 58073540400; 58072291900; 58071797800; 22951825700","Explore AI and Machine Learning for Future ISR Collection Planning and Management","2022","Proceedings of SPIE - The International Society for Optical Engineering","12113","","1211313","","","","10.1117/12.2619117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146597282&doi=10.1117%2f12.2619117&partnerID=40&md5=8483299dd121fef7cdcf54e2b4349f85","The current airborne ISR (Intelligence, Surveillance, and Reconnaissance) collection planning and management is designed for the employment of a limited number of large ISR platforms with respect to a set of collection requirements created through an assembly line-like process. This process is often very cumbersome and mentally exhaustive for intelligence analysts when dealing with a large volume of dynamic all-source intelligence. Consequently, more human time and resources are spent on processing and digesting raw data, instead of strategizing and designing the most effective ISR collection plans. These problems could be amplified significantly in potential future conflicts with a near-peer adversary because the complexity, scale, and intensity of an airborne ISR operation could be several orders higher. This paper discusses our new research concepts and preliminary results in applying artificial intelligence (AI) and machine learning (ML) as proof-of-concepts for facilitating future ISR collection planning and management. We explored a dynamic knowledge graph to represent historical and current all-source intelligence data as well as the corresponding contextual relationships and temporal states. Such an accumulative knowledge base allows us to apply machine learning and other analytical methods to infer and visualize multi-layered intelligence on an adversary’s capabilities and operations. These analytical results could assist human ISR analysts in understanding adversary’s operational tactics, techniques, and procedures. We further look into AI-enabled virtual agents in assisting mission planners to best manage a group of ISR assets for fulfillment of collection requirements. Applying deep reinforcement learning to Intellection, a new cooperative multi-player ISR collection board game, we train the virtual agents into AI players who can follow the game rules and estimate the desirable flight paths for potentially maximizing successful collections over prioritized targets. Together, these explorations may potentially create decision advantages and relieve possible manpower bottlenecks in future fast-paced ISR collection planning and management. © 2022 SPIE.","2-s2.0-85146597282"
"Tang Y.; Zhang Y.; Yin Z.; Deng J.; Li F.; Cui Y.; Zhang X.","Tang, Yinan (57212614224); Zhang, Yabo (57874723500); Yin, Zhifeng (57874723600); Deng, Jianxi (57874723700); Li, Feng (58378513100); Cui, Yong (7402595894); Zhang, Xiaoxiao (58452636300)","57212614224; 57874723500; 57874723600; 57874723700; 58378513100; 7402595894; 58452636300","AI-enabled Multi-modal Network Anomaly Association: A Deep Self/Semi-Supervised Learning Approach","2022","IEEE International Conference on Communications","2022-May","","","4068","4073","5","10.1109/ICC45855.2022.9839022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137259916&doi=10.1109%2fICC45855.2022.9839022&partnerID=40&md5=aa901c6b3ccb903f75c9538126a4a5e1","In nowadays large-scale networks, it is challenging for network operation and maintenance systems to analyze the reported massive network anomaly information. To handle this problem, we proposed a deep multi-modal learning approach called multi-modal anomaly root cause analysis, which enables network operation and maintenance systems to automatically and effectively associate the related network anomalies that appear from different modalities or aspects, and then locate the root causes. As a self/semi-supervised approach, our proposal is capable of realizing self-learning, self-adapting, and does not rely on a large number of manual annotations. According to the experimental results in a real large-scale network, without any annotations, our approach achieves up to 14% accuracy improvement in terms of multi-modal network anomaly association and root cause locating compared to the classical association rule mining algorithm Apriori, while its performance turns even much better when a few of labeled training samples are provided. The experiment also well proves the versatility and self-adaptability of our approach, which means our learning-based approach is able to not only achieve fast convergence but also automatically adapt itself to network changes. © 2022 IEEE.","2-s2.0-85137259916"
"Roksandic S.; Protrka N.; Engelhart M.","Roksandic, Suncana (57419658500); Protrka, Nikola (57210315830); Engelhart, Marc (55888249100)","57419658500; 57210315830; 55888249100","Trustworthy Artificial Intelligence and its use by Law Enforcement Authorities: where do we stand?","2022","2022 45th Jubilee International Convention on Information, Communication and Electronic Technology, MIPRO 2022 - Proceedings","","","","1225","1232","7","10.23919/MIPRO55190.2022.9803606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133917063&doi=10.23919%2fMIPRO55190.2022.9803606&partnerID=40&md5=f4421335281b72f0bc85201a3b30400e","From all kinds of industry, communication, education, banking, government, service, manufacturing, medical, and more, Artificial Intelligence (hereinafter: AI) applications may be found in many sectors of our life. Public safety and criminal justice are gaining advantages thanks to artificial intelligence. For example, traffic safety systems detect infractions and alert authorities. AI is also assisting in the identification of criminals. As a public safety resource, AI is being researched in a number of ways. Face recognition is becoming increasingly popular as an AI application in both the public and private sectors. For law enforcement authorities, AI applications boost efficiency, promote data-driven processes, and extend capabilities. AI technology can help law enforcement agencies make judgments and complete tasks in general. They can strengthen data-driven procedures, increase efficiency, or extend capabilities for specific activities or choices. However, recognized human rights as adjudicated by European Convention of Human Rights are calling for caution in the development and usage of AI within the European Union. Fair Trials and 114 civil society organizations have launched a collective statement to call for an Artificial Intelligence Act which foregrounds fundamental rights in November 2021. This Act is under preparation in the EU. Ethics Guidelines for Trustworthy AI from 2019, by High Level Expert Group on Artificial intelligence set up by the European Commission, (hereinafter: Ethical Guidelines) are underlining how it is necessary to develop, deploy and use trustworthy AI systems in a way that adheres to the ethical principles of: respect for human autonomy, prevention of harm, fairness and explicability. European Parliament Resolution of 6 October 2021 on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (hereinafter: Resolution) underlines that AI, alongside benefits, possesses great risks for fundamental rights and democracies based on the rule of law. AI should not be seen as an end in itself, but as a tool for serving people, with the ultimate aim of increasing human well-being, human capabilities and safety. In this article the authors will analyse some of the concerns taking into accounts principles set in Ethical Guidelines and human rights concerns. As the Regulation on AI is underway in the EU, the authors will stress some of the concerns that should be addressed in its wording. © 2022 Croatian Society MIPRO.","2-s2.0-85133917063"
"Rajamäki J.; Lebre Rocha P.A.; Perenius M.; Gioulekas F.","Rajamäki, Jyri (6602563131); Lebre Rocha, Pedro Afonso (58099436300); Perenius, Mira (58099239200); Gioulekas, Fotios (8619879100)","6602563131; 58099436300; 58099239200; 8619879100","SHAPES Project Pilots' Self-assessment for Trustworthy AI","2022","Proceedings of the 2022 IEEE 12th International Conference on Dependable Systems, Services and Technologies, DESSERT 2022","","","","","","","10.1109/DESSERT58054.2022.10018790","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147846364&doi=10.1109%2fDESSERT58054.2022.10018790&partnerID=40&md5=0bdb2c56fbbfc17fcdbf2ab8b11f1b6b","The Assessment List for Trustworthy AI (ALTAI) was developed by the High-Level Expert Group on Artificial Intelligence (AI HLEG) set up by the European Commission to help assess whether the AI system that is being developed, deployed, procured, or used, complies with the seven requirements of Trustworthy AI, as specified in the AI HLEG's Ethics Guidelines for Trustworthy AI. This paper describes the self-evaluation process of the SHAPES pilot campaign and presents some individual case results applying the prototype of an interactive version of the Assessment List for Trustworthy AI. Finally, the available results of two individual cases are combined. The best results are obtained from the evaluation category 'transparency' and the worst from 'technical robustness and safety'. Future work will be combining the missing self-assessment results and developing mitigation recommendations for AI-based risk reduction recommendations for new SHAPES services.  © 2022 IEEE.","2-s2.0-85147846364"
"Kieseberg P.; Buttinger C.; Kaltenbrunner L.; Temper M.; Tjoa S.","Kieseberg, Peter (37761500500); Buttinger, Christina (57907756900); Kaltenbrunner, Laura (57906972500); Temper, Marlies (57193401969); Tjoa, Simon (19934750700)","37761500500; 57907756900; 57906972500; 57193401969; 19934750700","Security considerations for the procurement and acquisition of Artificial Intelligence (AI) systems","2022","IEEE International Conference on Fuzzy Systems","2022-July","","","","","","10.1109/FUZZ-IEEE55066.2022.9882675","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138817994&doi=10.1109%2fFUZZ-IEEE55066.2022.9882675&partnerID=40&md5=10f107243bacd6c6c0dda2200d211eea","Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.  © 2022 IEEE.","2-s2.0-85138817994"
"Puyol-Antón E.; Ruijsink B.; Sidhu B.S.; Gould J.; Porter B.; Elliott M.K.; Mehta V.; Gu H.; Rinaldi C.A.; cowie M.; Chowienczyk P.; Razavi R.; King A.P.","Puyol-Antón, Esther (57190216600); Ruijsink, Bram (57160365500); Sidhu, Baldeep S. (57200621668); Gould, Justin (57194686865); Porter, Bradley (57192436471); Elliott, Mark K. (57216709824); Mehta, Vishal (57216706211); Gu, Haotian (56828600600); Rinaldi, Christopher A. (57217533072); cowie, Martin (7006231575); Chowienczyk, Phil (7006409663); Razavi, Reza (13908270000); King, Andrew P. (24344292700)","57190216600; 57160365500; 57200621668; 57194686865; 57192436471; 57216709824; 57216706211; 56828600600; 57217533072; 7006231575; 7006409663; 13908270000; 24344292700","AI-Enabled Assessment of Cardiac Systolic and Diastolic Function from Echocardiography","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13565 LNCS","","","75","85","10","10.1007/978-3-031-16902-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138818721&doi=10.1007%2f978-3-031-16902-1_8&partnerID=40&md5=d1513899c831e6471ae2ccc8a78026e0","Left ventricular (LV) function is an important factor in terms of patient management, outcome, and long-term survival of patients with heart disease. The most recently published clinical guidelines for heart failure recognise that over reliance on only one measure of cardiac function (LV ejection fraction) as a diagnostic and treatment stratification biomarker is suboptimal. Recent advances in AI-based echocardiography analysis have shown excellent results on automated estimation of LV volumes and LV ejection fraction. However, from time-varying 2-D echocardiography acquisition, a richer description of cardiac function can be obtained by estimating functional biomarkers from the complete cardiac cycle. In this work we propose for the first time an AI approach for deriving advanced biomarkers of systolic and diastolic LV function from 2-D echocardiography based on segmentations of the full cardiac cycle. These biomarkers will allow clinicians to obtain a much richer picture of the heart in health and disease. The AI model is based on the ’nn-Unet’ framework and was trained and tested using four different databases. Results show excellent agreement between manual and automated analysis and showcase the potential of the advanced systolic and diastolic biomarkers for patient stratification. Finally, for a subset of 50 cases, we perform a correlation analysis between clinical biomarkers derived from echocardiography and cardiac magnetic resonance and we show a very strong relationship between the two modalities. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85138818721"
"Zhang T.; Wagner C.; Garibaldi J.M.","Zhang, Te (57195927262); Wagner, Christian (55652566500); Garibaldi, Jonathan. M. (56765542600)","57195927262; 55652566500; 56765542600","Counterfactual rule generation for fuzzy rule-based classification systems","2022","IEEE International Conference on Fuzzy Systems","2022-July","","","","","","10.1109/FUZZ-IEEE55066.2022.9882705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138784273&doi=10.1109%2fFUZZ-IEEE55066.2022.9882705&partnerID=40&md5=efae974abddf6dbd264f13d2bf517d4e","EXplainable Artificial Intelligence (XAI) is of in-creasing importance as researchers and practitioners seek better transparency and verifiability of AI systems. Mamdani fuzzy systems can provide explanations based on their linguistic rules, and thus a potential pathway to XAI. A factual rule based explanation generally refers to the given set of rules executed, or fired, for a given input. However, research has shown that human explanations are often counterfactual (CF), i.e. rather than explaining why a given output was reached, they show why other potential outputs were not. Although several machine learning-based CF explanation generation methods have been proposed in recent years, quasi none of them focus on fuzzy systems. Also, where they do, they focus on correlation, which limits the interpretive value of any CF explanations obtained as humans expect a causal relationship in rules, i.e. we are cause-effect thinkers. In this paper, we propose a new rule generation framework for Mamdani fuzzy classification systems, which we refer to as CF-MABLAR, building on the MARkov BLAnket Rules (MABLAR) framework. CF-MABLAR approximates the causal links between inputs and output(s) of fuzzy systems and generates CF rules by leveraging them. Uniquely, the CF rules obtained not only provide a basic CF explanation, but can also articulate how the given inputs would need to be changed to generate a different output, crucial for lay-user insight, verification and sensitivity-evaluation of XAI systems, for example in decision support around credit risk, cyber security and medical assistance.  © 2022 IEEE.","2-s2.0-85138784273"
"Afrizal S.H.; Hakiem N.; Erna Permanasari A.; Syaifullah Albab H.; Yoki Sanjaya G.; Lazuardi L.","Afrizal, Sandra Hakiem (57210473582); Hakiem, Nashrul (36548044900); Erna Permanasari, Adhistya (25825391000); Syaifullah Albab, Hadid (58091136900); Yoki Sanjaya, Guardian (55536508300); Lazuardi, Lutfan (6506658334)","57210473582; 36548044900; 25825391000; 58091136900; 55536508300; 6506658334","A User-Centered Design of Natural Language Processing for Maternal Monitoring Chatbot System","2022","Proceedings - 4th International Conference on Informatics, Multimedia, Cyber and Information System, ICIMCIS 2022","","","","244","248","4","10.1109/ICIMCIS56303.2022.10017517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147424416&doi=10.1109%2fICIMCIS56303.2022.10017517&partnerID=40&md5=5abc9571450b9650b0a5f96ff6422091","A self-monitoring device and remote counseling system for pregnant mothers using interactive chat is an effective method due to the reduction of maternal care visits caused during the pandemic. The employment of an artificial intelligence (AI) based system using natural language processing (NLP) for decision support has prospectively enhanced the conversational access of patient to improve health awareness and knowledge. This research was conducted to develop an AI-based system which focuses on education and monitoring with regard to danger signs during pregnancy using NLP. The Telegram chatbot was used to develop the system after investigating user needs based on the danger sign monitoring guideline from WHO and the Ministry of Health of the Republic of Indonesia. The inputs from users were recognized by NLP and forwarded to the testing data for decision system. Furthermore, the analysis result was sent to the user which provides educational information and a personalized monitoring result. System Usability Scale (SUS) was undertaken to assess the user ability to use the application. The SUS score average for the chatbot system was 62.3 which was classified as 'OK' for the adjective ratings. The implication of the maternal monitoring using a chatbot system is the improvement of maternal care with regard to early detection of danger signs and relevant suggestions using an effective and interactive system which could be very promising especially in a limited healthcare resource environment.  © 2022 IEEE.","2-s2.0-85147424416"
"Joshi D.; Sabharwal A.","Joshi, Deepa (57212644824); Sabharwal, Anikait (57980619900)","57212644824; 57980619900","Artificial intelligence in healthcare","2022","The Internet of Medical Things: Enabling technologies and emerging applications","","","","93","110","17","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142557463&partnerID=40&md5=dab0c47ab6ba742d1a299b1b8cf28a62","The ability of artificial intelligence (AI) to imitate human cognitive capabilities, coupled with the ease of accessibility of medical data and the expeditious advancement of analytical techniques, is bringing paramount difference to the healthcare industry. Former research demonstrates the remarkable accuracy of AI to aid physicians to settle on better clinical choices or supplant judgment made by human beings, in particular, technical and practical areas of medical care. Statistics indicate that the shortage of doctors in therapeutically under-resourced regions and the lack of availability of skilled physicians in highly engaged clinical settings tend to cause a rise in false detection rates. The excessive workload causes fatigue that could lead to poor recovery of diseases. AI is ever-evolving as it is making advancements at an exponential rate, especially in healthcare treatments, such as monitoring treatments, improving the planning, and analyzing data to provide better treatment plans. The procedure of data accumulation, data management, clustering, and tagging invites numerous governance and regulatory challenges that could take a long duration. The healthcare industry thrives in this unending battle as the complexity and intricacy of data, and strict guidelines take a major toll. A healthcare institute is subjected to ask for consent from an institutional review board’s work to attenuate a portion of these concerns, and researchers and scientists may measure, process, and anonymize DICOM information to strip away any patient’s medical information. The AI-enabled medical care employed in the institutes plays an imperative role as an informative assistant that provides aid to doctors in acquiring an understanding of meaningful patterns from data collection. This practice holds the potential to save a lot of time, cost, and effort while yielding consistent, unbiased, and prime diagnosis or treatment. AI and deep learning (DL) tools used in day-to-day medical decision-making have a grave impact on improving the patient’s treatment and overall cost incurred due to their employment efficiency and accuracy. AI and machine learning (ML) can prove to be of supreme importance and assistance in the early detection and thus the prevention of a plethora of diseases by reading and analyzing the patient’s vitals. The presented chapter is of 5-folds. First, the distinct data sources where the healthcare data is gathered from are discussed. Second, we talk about the moral and lawful difficulties of AI-driven medical care. Next, the structured and unstructured types of healthcare data have been analyzed followed by the AI techniques applied to these types of data, such as ML, natural language processing (NLP), and DL.We then analyze the crucial disease areas such as cardiology, radiology, neurology, and cancer, where the health issues can be alleviated by employing AI techniques. In conclusion, we further discuss the areas where AI-based techniques are applied in real life. © The Institution of Engineering and Technology 2022.","2-s2.0-85142557463"
"Takale S.A.; Thorat S.A.; Sajjan R.S.","Takale, Sheetal A. (57004811700); Thorat, Sandeep A. (25928097700); Sajjan, Rajani S. (57197757395)","57004811700; 25928097700; 57197757395","Legal Document Summarization Using Ripple Down Rules","2022","Proceedings of 2022 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering, WIECON-ECE 2022","","","","78","83","5","10.1109/WIECON-ECE57977.2022.10150974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164251817&doi=10.1109%2fWIECON-ECE57977.2022.10150974&partnerID=40&md5=aed57ed5273baff404697fee09e71736","This paper presents an approach for legal document summarization using Ripple Down Rules(RDR). RDR is an Artificial Intelligence(AI) based approach and an alternative technique to Machine Learning(ML) algorithms for incrementally building the knowledge base. In this implementation, we have used RDR to develop an improving and increasing knowledge base of classification rules for assigning rhetorical role labels to the sentences in a legal document. The RDR rules for classification are developed using a set of syntactic, semantic and statistical features at word, sentence and document level. For each sentence in the legal document we have assigned an rhetorical role with the help of Ripple Down Rule. We have generated the final summary using the identified thirteen rhetorical roles. The proposed system is evaluated using 50 legal documents from four different domains. Experiments demonstrate that the RDR based Legal Document summarization approach has advantages over supervised and unsupervised ML techniques such as, independence from the need of annotated dataset and continuous updation of classification rules for rhetorical role labeling with the help of expert knowledge. © 2022 IEEE.","2-s2.0-85164251817"
"Passalacqua M.; Pellerin R.; Doyon-Poulin P.; Del-Aguila L.; Boasen J.; Léger P.-M.","Passalacqua, Mario (57204581475); Pellerin, Robert (23486421800); Doyon-Poulin, Philippe (26429305100); Del-Aguila, Laurène (58024825400); Boasen, Jared (57202038252); Léger, Pierre-Majorique (57202616738)","57204581475; 23486421800; 26429305100; 58024825400; 57202038252; 57202616738","Human-Centred AI in the Age of Industry 5.0: A Systematic Review Protocol","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13518 LNCS","","","483","492","9","10.1007/978-3-031-21707-4_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144398445&doi=10.1007%2f978-3-031-21707-4_34&partnerID=40&md5=a4edc0063f7239990f0d3ab11cc198bd","Research within AI-based Industry 4.0 (I4.0) work systems has predominantly focused on technical and process performance, while human and psychosocial factors are rarely examined. These factors must be considered to design human-centred systems that cultivate sustainable human-AI interaction, i.e., human-AI interaction that promotes long-term well-being, engagement, and performance. The European Commission has brought forward a new vision of I4.0 called Industry 5.0, where well-being and technological advancement are jointly considered, thus overcoming the weaknesses of I4.0. To move forward with Industry 5.0, it is necessary to consolidate our knowledge of human-technology interaction within I4.0. This systematic review aims to uncover the antecedents and consequences of human and psychosocial factors within AI-based I4.0 systems, with an end goal of providing guidelines for the sustainable design, implementation, and use of these systems. This protocol presents the background and the methodology behind our review, as well as preliminary results and expected contributions. © 2022, Springer Nature Switzerland AG.","2-s2.0-85144398445"
"Badea C.; Artus G.","Badea, Cosmin (57222419936); Artus, Gregory (57222420751)","57222419936; 57222420751","Morality, Machines, and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13652 LNAI","","","124","137","13","10.1007/978-3-031-21441-7_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144815494&doi=10.1007%2f978-3-031-21441-7_9&partnerID=40&md5=a00bbcaa9d324526c689832706c371b1","We present what we call the Interpretation Problem, whereby any rule in symbolic form is open to infinite interpretation in ways that we might disapprove of and argue that any attempt to build morality into machines is subject to it. We show how the Interpretation Problem in Artificial Intelligence is an illustration of Wittgenstein’s general claim that no rule can contain the criteria for its own application, and that the risks created by this problem escalates in proportion to the degree to which a machine is causally connected to the world, in what we call the Law of Interpretative Exposure. Using games as an illustration, we attempt to define the structure of normative spaces and argue that any rule-following within a normative space is guided by values that are external to that space and which cannot themselves be represented as rules. In light of this, we categorise the types of mistakes an artificial moral agent could make into Mistakes of Intention and Instrumental Mistakes, and we propose ways of building morality into machines by getting them to interpret the rules we give in accordance with these external values, through explicit moral reasoning, the “Show, not Tell” paradigm, the adjustment of causal power and structure of the agent, and relational values, with the ultimate aim that the machine develop a virtuous character and that the impact of the Interpretation Problem is minimised. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85144815494"
"Neto A.V.S.; Camargo J.B.; Almeida J.R.; Cugnasca P.S.","Neto, Antonio V. Silva (57217627385); Camargo, Joao B. (25640686200); Almeida, Jorge R. (57868885000); Cugnasca, Paulo S. (6506073565)","57217627385; 25640686200; 57868885000; 6506073565","Safety Assurance of Artificial Intelligence-Based Systems: A Systematic Literature Review on the State of the Art and Guidelines for Future Work","2022","IEEE Access","10","","","130733","130770","37","10.1109/ACCESS.2022.3229233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144813199&doi=10.1109%2fACCESS.2022.3229233&partnerID=40&md5=2a3afc2cdc0fbecc33bd880258eb34f2","The objective of this research is to present the state of the art of the safety assurance of Artificial Intelligence (AI)-based systems and guidelines on future correlated work. For this purpose, a Systematic Literature Review comprising 5090 peer-reviewed references relating safety to AI has been carried out, with focus on a 329-reference subset in which the safety assurance of AI-based systems is directly conveyed. From 2016 onwards, the safety assurance of AI-based systems has experienced significant effervescence and leaned towards five main approaches: performing black-box testing, using safety envelopes, designing fail-safe AI, combining white-box analyses with explainable AI, and establishing a safety assurance process throughout systems' lifecycles. Each of these approaches has been discussed in this paper, along with their features, pros and cons. Finally, guidelines for future research topics have also been presented. They result from an analysis based on both the cross-fertilization among the reviewed references and the authors' experience with safety and AI. Among 15 research themes, these guidelines reinforce the need for deepening guidelines for the safety assurance of AI-based systems by, e.g., analyzing datasets from a safety perspective, designing explainable AI, setting and justifying AI hyperparameters, and assuring the safety of hardware-implemented AI-based systems.  © 2013 IEEE.","2-s2.0-85144813199"
"Mobius M.; Kallfass D.; Doll T.; Kunde D.","Mobius, Michael (58091083700); Kallfass, Daniel (55616209100); Doll, Thomas (58091305500); Kunde, Dietmar (55342695500)","58091083700; 55616209100; 58091305500; 55342695500","AI-Based Military Decision Support Using Natural Language","2022","Proceedings - Winter Simulation Conference","2022-December","","","2082","2093","11","10.1109/WSC57314.2022.10015234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147454662&doi=10.1109%2fWSC57314.2022.10015234&partnerID=40&md5=8ce8f6b39402d96380ce89fb03acccb0","To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.  © 2022 IEEE.","2-s2.0-85147454662"
"Nitta I.; Ohashi K.; Shiga S.; Onodera S.","Nitta, Izumi (24559235300); Ohashi, Kyoko (16023151400); Shiga, Satoko (35103460300); Onodera, Sachiko (57972144200)","24559235300; 16023151400; 35103460300; 57972144200","AI Ethics Impact Assessment based on Requirement Engineering","2022","Proceedings of the IEEE International Conference on Requirements Engineering","","","","152","161","9","10.1109/REW56159.2022.00037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142257709&doi=10.1109%2fREW56159.2022.00037&partnerID=40&md5=80f6844a15f10445baeb81b668b8a1fb","This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process. © 2022 IEEE.","2-s2.0-85142257709"
"Salama R.; Al-Turjman F.","Salama, Ramiz (57481159900); Al-Turjman, Fadi (20336944100)","57481159900; 20336944100","AI in Blockchain Towards Realizing Cyber Security","2022","Proceedings - 2022 International Conference on Artificial Intelligence in Everything, AIE 2022","","","","471","475","4","10.1109/AIE57029.2022.00096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140925136&doi=10.1109%2fAIE57029.2022.00096&partnerID=40&md5=818598bfb336a3d16dc8182ce53b6f06","Blockchain and artificial intelligence are two technologies that, when combined, have the ability to help each other realize their full potential. Blockchains can guarantee the accessibility and consistent admittance to integrity safeguarded big data indexes from numerous areas, allowing AI systems to learn more effectively and thoroughly. Similarly, artificial intelligence (AI) can be used to offer new consensus processes, and hence new methods of engaging with Blockchains. When it comes to sensitive data, such as corporate, healthcare, and financial data, various security and privacy problems arise that must be properly evaluated. Interaction with Blockchains is vulnerable to data credibility checks, transactional data leakages, data protection rules compliance, on-chain data privacy, and malicious smart contracts. To solve these issues, new security and privacy-preserving technologies are being developed. AI-based blockchain data processing, either based on AI or used to defend AI-based blockchain data processing, is emerging to simplify the integration of these two cutting-edge technologies.  © 2022 IEEE.","2-s2.0-85140925136"
"Al-Obeidi A.H.; Al-Mulla M.S.","Al-Obeidi, Ali Hadi (57226685678); Al-Mulla, Muaath Sulaiman (57737399600)","57226685678; 57737399600","The Legal Basis of the Right to Explanation for Artificial Intelligence Decisions in UAE Law","2022","Proceedings - 2022 23rd International Arab Conference on Information Technology, ACIT 2022","","","","","","","10.1109/ACIT57182.2022.9994088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146910942&doi=10.1109%2fACIT57182.2022.9994088&partnerID=40&md5=b5c32c7b9de1a67d8408b99d840864a0","Artificial intelligence (AI) systems have a major role in making decisions affecting humans in the present era, however, they still suffer from several shortcomings, the most important of which is the inability of the human element to understand the mechanism of action of these systems and the foundations upon the decision basis. Ambiguity also makes it impossible to assign responsibility and control potential AI biases. Thus, international and national standards were set to counteract the negative consequences, among the most important international standards are the recommendations set by UNESCO for the ethics of artificial intelligence. While on the United Arab Emirates Level, this study addresses the basis of this explanation right in its Constitution, in the Civil Procedures Law and Smart Dubai Department Law No. (1) of 2020, which was enacted in order to enhance the status of the Emirate of Dubai and support its efforts towards transformation into smart cities. The authors relied on an analytical and descriptive approach to the various legislative provisions related to the right to explain. The study concluded that there is no explicit legal provision at the UAE level that establishes the right of people to have AI decisions explained. However, this right has been recognized at the international level in the nonbinding UNESCO guidelines. The study reached a recommendation that lawmakers at the international and national levels should pay more attention to the right to explanation of AI decisions, and they should recognize this right with explicit and binding legal texts.  © 2022 IEEE.","2-s2.0-85146910942"
"Lewandowski T.; Heuer M.; Vogel P.; Böhmann T.","Lewandowski, Tom (58177277900); Heuer, Marvin (58177483800); Vogel, Pascal (57217049676); Böhmann, Tilo (22939846600)","58177277900; 58177483800; 57217049676; 22939846600","Design Knowledge for the Lifecycle Management of Conversational Agents","2022","17th International Conference on Wirtschaftsinformatik, WI 2022","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152138978&partnerID=40&md5=5590997debdca9dafb819e08021f9eb8","Organizations spend extensive resources on artificial intelligence (AI) solutions in customer service in order to remain customer-focused and competitive. A rising language-based application of AI emerges in the context of conversational agents (CAs), such as chatbots, which represent increasingly intelligent, autonomous, scalable, and cost-effective service platforms. However, AI-based CAs bring new organizational challenges. They are underrepresented in current research, leading to many unanswered questions and research potential regarding the management of their introduction, operation, and improvement. To address this issue, we provide design knowledge that considers the organizational perspective of CAs. Therefore, we conducted a systematic literature review (SLR) and qualitative interview study to reveal and analyze individual issues and challenges, develop meta-requirements, and finally, use them to create design principles. We contribute to the emerging field of CAs that has previously focused mainly on the individual, behavioral, interactional, or technical design. © 2022 17th International Conference on Wirtschaftsinformatik, WI 2022. All rights reserved.","2-s2.0-85152138978"
"Deshpande A.; Kumar S.; Junnarkar A.","Deshpande, Asmita (57959524500); Kumar, Sanjay (58644279000); Junnarkar, Aparna (57201977939)","57959524500; 58644279000; 57201977939","AEPRS-EF: Advanaced Eelectricity Plan Recommendation System utilizing Efficient Fuzzy Logic","2022","2022 2nd Asian Conference on Innovation in Technology, ASIANCON 2022","","","","","","","10.1109/ASIANCON55314.2022.9908936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141578920&doi=10.1109%2fASIANCON55314.2022.9908936&partnerID=40&md5=208e40af8779f3e5692bc17dd62bc0c8","this paper was to propose novel advanced electricity plan recommendation utilizing Efficient Fuzzy logic algorithms (AEPRS-EF). To solve the problems related to sparsity, recommendation accuracy, & computation efficiency. For sparsity, we introduced the advanced Efficient Fuzzy logic under which we applied the set of fuzzy rules to optimize the recommendation process. For the accuracy & computation efficiency, we propose the advanced relevance feedback approach which may automatically recommends the advanced electricity planes based on end user feedbacks on previous recommendation results for the same user. The main goal & objectives is to propose & evaluate a unique data mining-based advanced electricity plan extraction framework. This research investigates the use of an advanced recommender system as compare to existing method, an AI-based rapid creation technique, to the task regards recommending power plans for a single private customer. Five basic advanced measures, including Normalized Discontinued Cumulative Gain (NDCG), Precision, Recall, Area under Precision & Recall Curve (AUPR), & Average Recommendation Time, have been utilized to evaluate the performance regards method under this study (ART). We computed the following performance metrics for the top K suggestion outcomes. © 2022 IEEE.","2-s2.0-85141578920"
"Mohammed S.Q.; Ilyas M.","Mohammed, Sameer Qutaiba (58294290200); Ilyas, Muhammad (57203258353)","58294290200; 57203258353","Delay Root Cause Analysis and 3D Modeling of LTE Control Communication Using Machine Learning","2022","Proceedings - 2022 International Conference on Artificial Intelligence of Things, ICAIoT 2022","","","","","","","10.1109/ICAIoT57170.2022.10121830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160573907&doi=10.1109%2fICAIoT57170.2022.10121830&partnerID=40&md5=fc20ccf44e9a953232e2a72f3e5a80aa","This study investigates and evaluates delay root cause analysis and 3D modeling of LTE control communication utilizing sophisticated machine learning for network testing. The research studied LTE protocols for 5th-generation mobile telephony and provided guidelines for controlling LTE frequency for background knowledge, although it used an independent technique that did not employ LTE standards. 512 elements of input-output MIMO were employed for 100-GHz and 128 elements for mid-band sub-6-GHz. LOS is always 0.5. This paper is about LTE, not 3D modeling of LTE control path loss type communication using machine learning. This work's route loss depends on cross-pol beam LTE polarization (±45o). The receiver (Rx) operations and transmitter (Tx) activities in the estimated distance of 0.5 km at an approximate altitude of 15.25 m. Distance, handover authentication, rain, atmosphere, and sub-6GHz vs 100GHz weather conditions affect path loss. The methodology has enhanced the spatial variety by boosting transmitting power and transmitting efficiency. Authorizing and sanctioning ANN-based LTE frequency for both mid-band sub-6-GHz and 100-GHz is possible due to its planning and development using open-source material and strategy with high transmission power and rate under doubtful handover confirmation using MIMO input/yield receiving wires. This theory examines LTE innovation dimensioning as unbiased for various handover verification and allows input boundary alterations for various organization arrangement setups for LTE recurrent data transmission from 6 GHz to 100 GHz for three climate sorts. This cycle should be seen as an undeniable level way to examine LTE networks under various air conditions. Using signal handling tool compartment and explicit AI-based ANN calculation from AI toolkit in MATLAB R2019a, it is possible to create a result answer for three climate types in a dataset with an LTE communication level of exactness of downpour assimilation and abundance foliage miss fort. © 2022 IEEE.","2-s2.0-85160573907"
"Sheth A.; Gaur M.; Roy K.; Venkataraman R.; Khandelwal V.","Sheth, Amit (57200763252); Gaur, Manas (57204944466); Roy, Kaushik (57221320197); Venkataraman, Revathy (57220602660); Khandelwal, Vedant (57520317400)","57200763252; 57204944466; 57221320197; 57220602660; 57520317400","Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety","2022","IEEE Internet Computing","26","5","","76","84","8","10.1109/MIC.2022.3182349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139197559&doi=10.1109%2fMIC.2022.3182349&partnerID=40&md5=1c47f1ea43d14f938fd8d7a43d558ba7","AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.  © 1997-2012 IEEE.","2-s2.0-85139197559"
"Zhang Q.; Song Y.; Jiao P.; Hu Y.","Zhang, Qi (56520586200); Song, Yukai (58458711100); Jiao, Peng (25922230800); Hu, Yue (57193845091)","56520586200; 58458711100; 25922230800; 57193845091","A Hybrid and Hierarchical Approach for Spatial Exploration in Dynamic Environments","2022","Electronics (Switzerland)","11","4","574","","","","10.3390/electronics11040574","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124377650&doi=10.3390%2felectronics11040574&partnerID=40&md5=d9c4eb6ccb1d9c02979e15179dc3758a","Exploration in unknown dynamic environments is a challenging problem in an AI system, and current techniques tend to produce irrational exploratory behaviours and fail in obstacle avoidance. To this end, we present a three-tiered hierarchical and modular spatial exploration model that combines the intrinsic motivation integrated deep reinforcement learning (DRL) and rule-based real-time obstacle avoidance approach. We address the spatial exploration problem in two levels on the whole. On the higher level, a DRL based global module learns to determine a distant but easily reachable target that maximizes the current exploration progress. On the lower level, another two-level hierarchical movement controller is used to produce locally smooth and safe movements between targets based on the information of known areas and free space assumption. Experimental results on diverse and challenging 2D dynamic maps show that the proposed model achieves almost 90% coverage and generates smoother trajectories compared with a state-of-the-art IM based DRL and some other heuristic methods on the basis of avoiding obstacles in real time. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85124377650"
"Kim D.; Jo D.","Kim, Daehwan (57230781500); Jo, Dongsik (15022650700)","57230781500; 15022650700","Effects on Co-Presence of a Virtual Human: A Comparison of Display and Interaction Types","2022","Electronics (Switzerland)","11","3","367","","","","10.3390/electronics11030367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123344898&doi=10.3390%2felectronics11030367&partnerID=40&md5=04ed6ca6bd57bb34ca3814bd177b71ce","Recently, artificial intelligence (AI)-enabled virtual humans have been widely used in various fields in our everyday lives, such as for museum exhibitions and as information guides. Given the continued technological innovations in extended reality (XR), immersive display devices and interaction methods are evolving to provide a feeling of togetherness with a virtual human, termed co-presence. With regard to such technical developments, one main concern is how to improve the experience through the sense of co-presence as felt by participants. However, virtual human systems still have limited guidelines on effective methods, and there is a lack of research on how to visualize and interact with virtual humans. In this paper, we report a novel method to support a strong sense of co-presence with a virtual human, and we investigated the effects on co-presence with a comparison of display and interaction types. We conducted the experiment according to a specified scenario between the participant and the virtual human, and our experimental study showed that subjects who participated in an immersive 3D display with non-verbal interaction felt the greatest co-presence. Our results are expected to provide guidelines on how to focus on constructing AI-based interactive virtual humans. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85123344898"
"Gallese C.","Gallese, Chiara (57222726276)","57222726276","Suggestions for a Revision of the European Smart Robot Liability Regime","2022","4th European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2022","","","","29","35","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176323315&partnerID=40&md5=8d377b5136f8da60d5fbb8ebaea3ff69","In recent years, the need for regulation of robots and Artificial Intelligence, together with the urgency of reshaping the civil liability framework, has become apparent in Europe. Although the matter of civil liability has been the subject of many studies and resolutions, multiple attempts to harmonize EU tort law have been unsuccessful so far, and only the liability of producers for defective products has been harmonized so far. In 2021, by publishing the AI Act proposal, the European Commission reached the goal to regulate AI at the European level, classifying smart robots as”high-risk systems”. This new piece of legislation, albeit tackling important issues, does not focus on liability rules. However, regulating the responsibility of developers and manufacturers of robots and AI systems, in order to avoid a fragmented legal framework across the EU and an uneven application of liability rules in each Member State, is still an important issue that raises many concerns in the industry sector. In particular, deep learning techniques need to be carefully regulated, as they challenge the traditional liability paradigm: it is often not possible to know the reason behind the output given by those models, and neither the programmer nor the manufacturer is able to predict the AI behavior. For this reason, some authors have argued that we need to take liability away from producers and programmers when robots are capable of acting autonomously from their original design, while others have proposed a strict liability regime. This article explores liability issues about AI and robots with regards to users, producers, and programmers, especially when the use of machine learning techniques is involved, and suggests some regulatory solutions for European lawmakers. © 2022 Impact of Artificial Intelligence and Robotics, ECIAIR 2022","2-s2.0-85176323315"
"Xu W.; Zhao J.; Parvataneni K.; Zhang V.; Lin S.; Wang H.","Xu, William (57989735900); Zhao, Jiawen (57989056000); Parvataneni, Krishnaveni (57989594100); Zhang, Vincent (57989459300); Lin, Sophia (57989186900); Wang, Hongning (57985960900)","57989735900; 57989056000; 57989594100; 57989459300; 57989186900; 57985960900","Hybrid Al Framework for Remote Patient Heart Failure Risk Prediction","2022","2022 Global Reliability and Prognostics and Health Management Conference, PHM-Yantai 2022","","","","","","","10.1109/PHM-Yantai55411.2022.9941764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143176996&doi=10.1109%2fPHM-Yantai55411.2022.9941764&partnerID=40&md5=4a762dac5515a4e339b81959d2458dc4","Heart failure is a lethal disease with a high risk of death. Once it is diagnosed, it cannot be cured definitively. Continuous attention needs to be given to such patients in both hospital and home environment. Due to the lack of measurement and risk analysis at home, the chance of early intervention is dramatically reduced. This research aims to offer a hybrid AI-based approach for patients to monitor and assess their daily risk at home. Highly personalized AI models are trained with continuous data stream from wearable devices and demographic information. The personalized risk assessment is based on individual's benchmark of the daily routine and bio pattern. Also, the rule-based algorithms are developed based on clinical well-established thresholds. This hybrid approach yields 87.5% accuracy. Our approach can provide a cost-efficient method for at-home patients' heart failure prediction. © 2022 IEEE.","2-s2.0-85143176996"
"Biersmith L.; Laplante P.","Biersmith, Luke (57994443900); Laplante, Phil (7005498946)","57994443900; 7005498946","Introduction to AI Assurance for Policy Makers","2022","Proceedings - 2022 IEEE 29th Annual Software Technology Conference, STC 2022","","","","51","56","5","10.1109/STC55697.2022.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143401851&doi=10.1109%2fSTC55697.2022.00016&partnerID=40&md5=ea7c56515d745080a467919e91c5864c","The deployment of artificial intelligence (AI) applications has accelerated faster than most scientists, policymakers and business leaders could have predicted. AI enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risk either in the form of physical injury or unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective and requires oversight, therefore depending on experts opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations.While not comprehensive, this work provides an overview of AI legislation and directives at the international, U.S. state and federal levels. It also covers business standards, and technical society initiatives. This work can serve as a resource for policymakers and other key stakeholders and an entry point to their understanding of AI policy.  © 2022 IEEE.","2-s2.0-85143401851"
"Binza L.; Budree A.","Binza, Lungile (58036376600); Budree, Adheesh (57189874732)","58036376600; 57189874732","Towards a Balanced Natural Language Processing: A Systematic Literature Review for the Contact Centre: Balancing the AI Triple Challenge of Opportunity, Ethics, and Opportunity Cost!","2022","IFIP Advances in Information and Communication Technology","657 IFIP","","","397","420","23","10.1007/978-3-031-19429-0_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145221117&doi=10.1007%2f978-3-031-19429-0_24&partnerID=40&md5=eff65e9b22b074cdbf01eaffa61bdf21","Artificial Intelligence (AI), which is the design, development, and utilisation of iterative and complex algorithmic systems that complete tasks which normally required human intelligence, is rapidly gaining momentum throughout the world. Through Machine Learning these AI systems automatically learn and adapt themselves so that they can offer an even more accurate outcome than humans and this offers many exciting benefits to most businesses and economies. But their introduction has raised ethical questions after some unethical conduct on their part like racism, biasness against women, unemployment (through intelligent automation), and inequality. After these incidents of unethical behaviour by some AI technologies around the globe most public, private, and even non-profit organisations embarked on initiatives to address the unethical conduct of AI systems. They produced a range of ethical AI frameworks, guidelines, and principles, but a properly balanced AI, where opportunity, ethics, and opportunity costs intersect, is still to be achieved or realised. Most AI Practitioners are pressured by their shareholders to prioritise commercial interests over ethical considerations. The findings from this Systematic Literature Review study, which used meta-analyses for qualitative synthesis, demonstrate that a Balanced Natural Language Processing (NLP) is possible. © 2022, IFIP International Federation for Information Processing.","2-s2.0-85145221117"
"Marsh Runyon K.R.; D. Montilus K.; Nachman L.; Smith Herrick K.; Ferrara L.","Marsh Runyon, K. Rebecca (57845316900); D. Montilus, Kinta (57845055900); Nachman, Larisa (57844025800); Smith Herrick, Kristen (57844026000); Ferrara, Lisa (57845316600)","57845316900; 57845055900; 57844025800; 57844026000; 57845316600","ETS® AI Labs™ Ways of Working Tutorial: How to Build Evidence-Based, User-Obsessed, AI-Enabled Learning Solutions in an Agile Framework","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13356 LNCS","","","119","122","3","10.1007/978-3-031-11647-6_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135914749&doi=10.1007%2f978-3-031-11647-6_21&partnerID=40&md5=243f8739dc64c3076ff7a7dbb3c683b1","How do you advance the science and engineering of digital learning solutions at your institution, business, or organization? Bring your current ways of working to this tutorial and get ready to innovate them alongside your fellow researchers, practitioners, business owners, and policy makers. As we work together to share our knowledge and lived experiences, presenters will assist participants in co-creating action plans for how they can utilize best practices from user-centered design (UCD), Design thinking, and Agile to deliver user-obsessed, AI-enabled, efficacious learning solutions. © 2022, Springer Nature Switzerland AG.","2-s2.0-85135914749"
"Zerroug A.; Vaishnav M.; Colin J.; Musslick S.; Serre T.","Zerroug, Aimen (57219226079); Vaishnav, Mohit (57232966800); Colin, Julien (57375259700); Musslick, Sebastian (57195317708); Serre, Thomas (55880171800)","57219226079; 57232966800; 57375259700; 57195317708; 55880171800","A Benchmark for Compositional Visual Reasoning","2022","Advances in Neural Information Processing Systems","35","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147657710&partnerID=40&md5=f9f680644366e9ca47d3bed9d7455332","A fundamental component of human vision is our ability to parse complex visual scenes and judge the relations between their constituent objects. AI benchmarks for visual reasoning have driven rapid progress in recent years with state-of-the-art systems now reaching human accuracy on some of these benchmarks. Yet, there remains a major gap between humans and AI systems in terms of the sample efficiency with which they learn new visual reasoning tasks. Humans' remarkable efficiency at learning has been at least partially attributed to their ability to harness compositionality - allowing them to efficiently take advantage of previously gained knowledge when learning new tasks. Here, we introduce a novel visual reasoning benchmark, Compositional Visual Relations (CVR), to drive progress towards the development of more data-efficient learning algorithms. We take inspiration from fluid intelligence and non-verbal reasoning tests and describe a novel method for creating compositions of abstract rules and generating image datasets corresponding to these rules at scale. Our proposed benchmark includes measures of sample efficiency, generalization, compositionality, and transfer across task rules. We systematically evaluate modern neural architectures and find that convolutional architectures surpass transformer-based architectures across all performance measures in most data regimes. However, all computational models are much less data efficient than humans, even after learning informative visual representations using self-supervision. Overall, we hope our challenge will spur interest in developing neural architectures that can learn to harness compositionality for more efficient learning. © 2022 Neural information processing systems foundation. All rights reserved.","2-s2.0-85147657710"
"Yao J.; Ye X.; Xia Y.; Zhou J.; Shi Y.; Yan K.; Wang F.; Lin L.; Yu H.; Hua X.-S.; Lu L.; Jin D.; Zhang L.","Yao, Jiawen (58594503300); Ye, Xianghua (56904382900); Xia, Yingda (57203969828); Zhou, Jian (56949215200); Shi, Yu (57218086012); Yan, Ke (57211681344); Wang, Fang (58737478300); Lin, Lili (36617794000); Yu, Haogang (55986036600); Hua, Xian-Sheng (55441195100); Lu, Le (55474685200); Jin, Dakai (55823374900); Zhang, Ling (55971484200)","58594503300; 56904382900; 57203969828; 56949215200; 57218086012; 57211681344; 58737478300; 36617794000; 55986036600; 55441195100; 55474685200; 55823374900; 55971484200","Effective Opportunistic Esophageal Cancer Screening Using Noncontrast CT Imaging","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13433 LNCS","","","344","354","10","10.1007/978-3-031-16437-8_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139054911&doi=10.1007%2f978-3-031-16437-8_33&partnerID=40&md5=8b17d2444d57e991ce7107f1b2c39f0e","Esophageal cancer is the second most deadly cancer. Early detection of resectable/curable esophageal cancers has a great potential to reduce mortality, but no guideline-recommended screening test is available. Although some screening methods have been developed, they are expensive, might be difficult to apply to the general population, and often fail to achieve satisfactory sensitivity for identifying early-stage cancers. In this work, we investigate the feasibility of esophageal tumor detection and classification (cancer or benign) on the noncontrast CT scan, which could potentially be used for opportunistic cancer screening. To capture the global context, a novel position-sensitive self-attention is proposed to augment nnUNet with non-local interactions. Our model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients. In comparison, the mean sensitivity and specificity of four doctors are 75.0% and 83.8%, respectively. For the classification task, our model outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system, our method has comparable performance and is even more sensitive for early-stage cancer and benign tumor. Our proposed method is a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85139054911"
"Alnafrani R.; Wijesekera D.","Alnafrani, Rami (57803937800); Wijesekera, Duminda (6603774480)","57803937800; 6603774480","AIFIS: Artificial Intelligence (AI)-Based Forensic Investigative System","2022","10th International Symposium on Digital Forensics and Security, ISDFS 2022","","","","","","","10.1109/ISDFS55398.2022.9800801","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134268800&doi=10.1109%2fISDFS55398.2022.9800801&partnerID=40&md5=699a1f53113846ffe89ae4f6b32086a1","The scope of forensic investigations has recently expanded. Since most Internet of Things (IoT) devices are plug and play and do not have much memory or storage to pre-process data, it is a challenge for forensic investigators to identify and obtain relevant evidence to reconstruct attacks. As a solution, we propose using artificial intelligence (AI)-inspired techniques to automate the forensic analysis process by emulating attacks in the process of identifying and collecting forensic evidence. We used a differentiable inductive logic programming (∂ILP) system to obtain attack emulation information from different sources, such as device- and subsystem-level vulnerabilities gathered by assessing device components in an enterprise network, and to predict potential attacks from previous attacks on similar configurations. Our experimental results showed that the proposed methodology could successfully generate rules that can assist forensic examiners in identifying evidence to emulate attacks without execution.  © 2022 IEEE.","2-s2.0-85134268800"
"Partridge Z.; Thielscher M.","Partridge, Zachary (57819696200); Thielscher, Michael (6701317963)","57819696200; 6701317963","Hidden Information General Game Playing with Deep Learning and Search","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13631 LNCS","","","161","172","11","10.1007/978-3-031-20868-3_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142873359&doi=10.1007%2f978-3-031-20868-3_12&partnerID=40&md5=4d494c5a62cc1211acdc894f8a3f368f","General Game Playing agents are capable of learning to play games they have never seen before, merely by looking at a formal description of the rules of a game. Recent developments in deep learning have influenced the way state-of-the-art AI systems can learn to play games with perfect information like Chess and Go. This development is popularised by the success of AlphaZero and was subsequently generalised to arbitrary games describable in the general Game Description Language, GDL. Many real-world problems, however, are non-deterministic and involve actors with concealed information, or events with probabilistic outcomes. We describe a framework and system for General Game Playing with self-play reinforcement learning and search for hidden-information games, which can be applied to any game describable in the extended Game Description Language for imperfect-information games, GDL-II. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85142873359"
"Rahman M.S.; Khomh F.; Rivera E.; Gueheneuc Y.-G.; Lehnert B.","Rahman, Md Saidur (57212184180); Khomh, Foutse (24724747600); Rivera, Emilio (57821306800); Gueheneuc, Yann-Gael (13613429100); Lehnert, Bernd (57219584967)","57212184180; 24724747600; 57821306800; 13613429100; 57219584967","Challenges in Machine Learning Application Development: An Industrial Experience Report","2022","Proceedings - Workshop on Software Engineering for Responsible AI, SE4RAI 2022","","","","21","28","7","10.1145/3526073.3527593","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135006055&doi=10.1145%2f3526073.3527593&partnerID=40&md5=59c930355f820fdb244cbc896fedad91","SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers' feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours. CCS CONCEPTS • Software and its engineering → Programming teams.  © 2022 ACM.","2-s2.0-85135006055"
"Stokes K.; Castaldo R.; Federici C.; Pagliara S.; Maccaro A.; Cappuccio F.; Fico G.; Salvatore M.; Franzese M.; Pecchia L.","Stokes, Katy (57253034100); Castaldo, Rossana (56734351100); Federici, Carlo (57189296971); Pagliara, Silvio (14523356200); Maccaro, Alessia (57216878584); Cappuccio, Francesco (7006704793); Fico, Giuseppe (16174738100); Salvatore, Marco (7102652689); Franzese, Monica (57215069298); Pecchia, Leandro (35746897300)","57253034100; 56734351100; 57189296971; 14523356200; 57216878584; 7006704793; 16174738100; 7102652689; 57215069298; 35746897300","The use of artificial intelligence systems in diagnosis of pneumonia via signs and symptoms: A systematic review","2022","Biomedical Signal Processing and Control","72","","103325","","","","10.1016/j.bspc.2021.103325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118851096&doi=10.1016%2fj.bspc.2021.103325&partnerID=40&md5=7bc7c6347352632e8797443db6d1635a","Artificial Intelligence (AI) systems using symptoms/signs to detect respiratory diseases may improve diagnosis especially in limited resource settings. Heterogeneity in such AI systems creates an ongoing need to analyse performance to inform future research. This systematic literature review aimed to investigate performance and reporting of diagnostic AI systems using machine learning (ML) for pneumonia detection based on symptoms and signs, and to provide recommendations on best practices for designing and implementing predictive ML algorithms. This article was conducted following the PRISMA protocol, 876 articles were identified by searching PubMed, Scopus, and OvidSP databases (last search 5th May 2021). For inclusion, studies must have differentiated clinically diagnosed pneumonia from controls or other diseases using AI. Risk of Bias was evaluated using The STARD 2015 tool. Information was extracted from 16 included studies regarding study characteristics, ML-model features, reference tests, study population, accuracy measures and ethical aspects. All included studies were highly heterogenous concerning the study design, setting of diagnosis, study population and ML algorithm. Study reporting quality in methodology and results was low. Ethical issues surrounding design and implementation of the AI algorithms were not well explored. Although no single performance measure was used in all studies, most reported an accuracy measure over 90%. There is strong evidence to support further investigations of ML to automatically detect pneumonia based on easily recognisable symptoms and signs. To help improve the efficacy of future research, recommendations for designing and implementing AI tools based on the findings of this study are provided. © 2021","2-s2.0-85118851096"
"Treacy C.; Regan G.; Shahid A.; Maguire B.","Treacy, Ceara (57203847059); Regan, Gilbert (55250931100); Shahid, Arsalan (57193236007); Maguire, Brian (57221379161)","57203847059; 55250931100; 57193236007; 57221379161","Legal, Privacy, Social and Ethical Requirements and Impact Assessment for an Artificial Intelligence Based Medical Imaging Project","2022","Communications in Computer and Information Science","1646 CCIS","","","29","44","15","10.1007/978-3-031-15559-8_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137982552&doi=10.1007%2f978-3-031-15559-8_3&partnerID=40&md5=ba8f31ed65abc0f28e481762a2987ad3","The use of Artificial Intelligence (AI) systems in the health domain requires developers of these systems to consider a wider view of requirements beyond traditional data security requirements. Data controllers of these systems should also include requirements that consider legal, privacy, fundamental rights, social, and ethical values. However, harmonized guidelines around AI principles and requirements are not agreed and divergent. This requires a creative approach with the development of these requirements for AI projects. Furthermore, many of the guidelines fail to establish a link between principles and actionable requirements. In this paper we present the methodology used to develop the legal, privacy, social and ethical requirements for an AI based medical imaging project entitled Medical Imaging Ireland (Med-I). Furthermore, we provide an overview of an assessment of these requirements implementation within the Med-I project. © 2022, Springer Nature Switzerland AG.","2-s2.0-85137982552"
"Ahmad M.A.; Overman S.; Allen C.; Kumar V.; Teredesai A.; Eckert C.","Ahmad, Muhammad Aurangzeb (57670469700); Overman, Steve (57219118061); Allen, Christine (57259119900); Kumar, Vikas (57037615000); Teredesai, Ankur (6602892213); Eckert, Carly (56803339200)","57670469700; 57219118061; 57259119900; 57037615000; 6602892213; 56803339200","Software as a Medical Device: Regulating AI in Healthcare via Responsible AI","2021","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","4023","4024","1","10.1145/3447548.3470823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114920107&doi=10.1145%2f3447548.3470823&partnerID=40&md5=f86306856ae50d26b6172ce216587531","With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.  © 2021 Owner/Author.","2-s2.0-85114920107"
"Rietz T.; Maedche A.","Rietz, Tim (57212505427); Maedche, Alexander (6603610788)","57212505427; 6603610788","Cody: An ai-based system to semi-automate coding for qalitative research","2021","Conference on Human Factors in Computing Systems - Proceedings","","","","","","","10.1145/3411764.3445591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106707782&doi=10.1145%2f3411764.3445591&partnerID=40&md5=fd1c6f635f3030229809a074dc8a59a1","Qualitative research can produce a rich understanding of a phenomenon but requires an essential and strenuous data annotation process known as coding. Coding can be repetitive and timeconsuming, particularly for large datasets. Existing AI-based approaches for partially automating coding, like supervised machine learning (ML) or explicit knowledge represented in code rules, require high technical literacy and lack transparency. Further, little is known about the interaction of researchers with AI-based coding assistance. We introduce Cody, an AI-based system that semiautomates coding through code rules and supervised ML. Cody supports researchers with interactively (re)defning code rules and uses ML to extend coding to unseen data. In two studies with qualitative researchers, we found that (1) code rules provide structure and transparency, (2) explanations are commonly desired but rarely used, (3) suggestions beneft coding quality rather than coding speed, increasing the intercoder reliability, calculated with Krippendorf's Alpha, from 0.085 (MAXQDA) to 0.33 (Cody). © 2021 ACM.","2-s2.0-85106707782"
"Pei Y.; Li G.","Pei, Ying (57642163400); Li, Gang (57859682800)","57642163400; 57859682800","Massive AI based cloud environment for smart online education with data mining","2021","Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021","","","9432201","1115","1118","3","10.1109/ICICCS51141.2021.9432201","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107588586&doi=10.1109%2fICICCS51141.2021.9432201&partnerID=40&md5=962d33b508980631a1a855aebad743e3","Under the background of the deep integration of Internet technology and artificial intelligence technology with the field of education, the traditional teacher centered teaching mode is facing a historic change. How to guide students to learn and communicate actively, and explore and improve the new student-centered teaching mode, has become the key problem to be solved. In the mixed cloud environment, the data stream is disturbed, and the error of mining association data is large. Aiming at the problem of poor anti-interference of scattered point cloud adaptive compression mining algorithm, this paper analyzes the data mining technology in cloud environment. Firstly, the time series analysis model of big data information flow in hybrid cloud environment is constructed to analyze the data structure, and then the high-dimensional phase space of data information flow in hybrid cloud environment is reconstructed. In the reconstructed phase space, the association rules are extracted, and the extracted features are used as pheromones to guide data location mining, so as to improve the data mining algorithm.  © 2021 IEEE.","2-s2.0-85107588586"
"Rawat R.M.; Rana A.; Toppo A.J.; Beck A.","Rawat, Ram Murti (57218934290); Rana, Ashish (57224450630); Toppo, Ankit Jose (58400094200); Beck, Akshit (57224454964)","57218934290; 57224450630; 58400094200; 57224454964","AI based impact of COVID 19 on food industry and technological approach to mitigate","2021","Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021","","","9432152","1743","1748","5","10.1109/ICICCS51141.2021.9432152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107529764&doi=10.1109%2fICICCS51141.2021.9432152&partnerID=40&md5=2843ebe8212fca58e671a95ebb8e66f7","The food industry or the restaurant business has always been one of the most profitable and growing businesses. As technology is evolving day by day and to sustain itself in the food industry the restaurant needs to come up with new and innovative services which they can provide to the customers. Pandemic has made a major impact on the business of the restaurant industry in 2020. This paper will help to understand how technology can help in food ordering, while taking care of the COVID-19 pandemic guidelines. The purpose of this paper is to analyze the impact of COVID-19 in the food industry and suggest methods that would help restaurants to adapt to challenges that originate from COVID-19. One of the ways would be to automate the food ordering process. Our Project 'Contactless food ordering system' is a mobile application operated by a voice assistant. That the client (The Restaurant Customer) can use to scan through the restaurant menu and view various food categories and items like 'Starter' 'Drinks' etc. and place their order through the Application. They can modify and confirm their order, as well as make their payment. The aim of the study is to reduce the point of contact during COVID-19 and automate the ordering and billing process, simplifying the work. Thus, providing a totally computerized, automated, and scalable food ordering system that will assist the business by reducing their workload, provide better management and smooth operation. The restaurant can also use various other means to increase their presence as a business.  © 2021 IEEE.","2-s2.0-85107529764"
"Salahuddin Z.; Woodruff H.C.; Chatterjee A.; Lambin P.","Salahuddin, Zohaib (57221155895); Woodruff, Henry C. (8548234000); Chatterjee, Avishek (57209563820); Lambin, Philippe (57215029931)","57221155895; 8548234000; 57209563820; 57215029931","Transparency of deep neural networks for medical image analysis: A review of interpretability methods","2022","Computers in Biology and Medicine","140","","105111","","","","10.1016/j.compbiomed.2021.105111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120608641&doi=10.1016%2fj.compbiomed.2021.105111&partnerID=40&md5=c173e5ae0641008948e88b59ac596726","Artificial Intelligence (AI) has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown the same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. In order to conform to the principles of trustworthy AI, it is essential that the AI system be transparent, robust, fair, and ensure accountability. Current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision-making process. Therefore, there is a need to ensure the interpretability of deep neural networks before they can be incorporated into the routine clinical workflow. In this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. Furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. Finally, we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis. © 2021 The Authors","2-s2.0-85120608641"
"Letaief K.B.; Shi Y.; Lu J.; Lu J.","Letaief, Khaled B. (55666697100); Shi, Yuanming (55695283900); Lu, Jianmin (55701380700); Lu, Jianhua (7601561492)","55666697100; 55695283900; 55701380700; 7601561492","Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications","2022","IEEE Journal on Selected Areas in Communications","40","1","","5","36","31","10.1109/JSAC.2021.3126076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119402748&doi=10.1109%2fJSAC.2021.3126076&partnerID=40&md5=788834e2a9956cbf8a095a6f60bb5cf7","The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from 'connected things' to 'connected intelligence'. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.  © 1983-2012 IEEE.","2-s2.0-85119402748"
"Sarker I.H.; Furhad M.H.; Nowrozy R.","Sarker, Iqbal H. (56997358700); Furhad, Md Hasan (56092021900); Nowrozy, Raza (57219271902)","56997358700; 56092021900; 57219271902","AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions","2021","SN Computer Science","2","3","173","","","","10.1007/s42979-021-00557-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131828113&doi=10.1007%2fs42979-021-00557-0&partnerID=40&md5=1f5aca049ff12eef884696a5d9232cd8","Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or AI-based technical point of view. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","2-s2.0-85131828113"
"Santra D.; Goswami S.; Mandal J.K.; Basu S.K.","Santra, Debarpita (55547994100); Goswami, Subrata (55947825300); Mandal, Jyotsna Kumar (24605629500); Basu, Swapan Kumar (55455657400)","55547994100; 55947825300; 24605629500; 55455657400","Low back pain expert systems: Clinical resolution through probabilistic considerations and poset","2021","Artificial Intelligence in Medicine","120","","102163","","","","10.1016/j.artmed.2021.102163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114954635&doi=10.1016%2fj.artmed.2021.102163&partnerID=40&md5=ff2e48f2a7351bfdea1a56b6553d4306","Objective: Proper diagnosis of Low Back Pain (LBP) is quite challenging in especially the developing countries like India. Though some developed countries prepared guidelines for evaluation of LBP with tests to detect psychological overlay, implementation of the recommendations becomes quite difficult in regular clinical practice, and different specialties of medicine offer different modes of management. Aiming at offering an expert-level diagnosis for the patients having LBP, this paper uses Artificial Intelligence (AI) to derive a clinically justified and highly sensitive LBP resolution technique. Materials and methods: The paper considers exhaustive knowledge for different LBP disorders (classified based on different pain generators), which have been represented using lattice structures to ensure completeness, non-redundancy, and optimality in the design of knowledge base. Further the representational enhancement of the knowledge has been done through construction of a hierarchical network, called RuleNet, using the concept of partially-ordered set (poset) with respect to the subset equality (⊆) relation. With implicit incorporation of probability within the knowledge, the RuleNet is used to derive reliable resolution logic along with effective resolution of uncertainties during clinical decision making. Results: The proposed methodology has been validated with clinical records of seventy seven LBP patients accessed from the database of ESI Hospital Sealdah, India over a period of one year from 2018 to 2019. Achieving 83% sensitivity of the proposed technique, the pain experts at the hospital find the design clinically satisfactory. The inferred outcomes have also been found to be homogeneous with the actual or original diagnosis. Discussions: The proposed approach achieves the clinical and computational efficiency by limiting the shortcomings of the existing methodologies for AI-based LBP diagnosis. While computational efficiency (with respect to both time and space complexity) is ensured by inferring clinical decisions through optimal processing of the knowledge items using poset, the clinical acceptability has been ascertained reaching to the most-likely diagnostic outcomes through probabilistic resolution of clinical uncertainties. Conclusion: The derived resolution technique, when embedded in LBP medical expert systems, would provide a fast, reliable, and affordable healthcare solution for this ailment to a wider range of general population suffering from LBP. The proposed scheme would significantly reduce the controversies and confusion in LBP treatment, and cut down the cost of unnecessary or inappropriate treatment and referral. © 2021 Elsevier B.V.","2-s2.0-85114954635"
"Keller P.; Drake A.","Keller, Perry (36967519800); Drake, Archie (57215284894)","36967519800; 57215284894","Exclusivity and paternalism in the public governance of explainable AI","2021","Computer Law and Security Review","40","","105490","","","","10.1016/j.clsr.2020.105490","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095916201&doi=10.1016%2fj.clsr.2020.105490&partnerID=40&md5=1385173fbe66440e5dd5d37a5d62db7f","In this comment, we address the apparent exclusivity and paternalism of goal and standard setting for explainable AI and its implications for the public governance of AI. We argue that the widening use of AI decision-making, including the development of autonomous systems, not only poses widely-discussed risks for human autonomy in itself, but is also the subject of a standard-setting process that is remarkably closed to effective public contestation. The implications of this turn in governance for democratic decision-making in Britain have also yet to be fully appreciated. As the governance of AI gathers pace, one of the major tasks will be ensure not only that AI systems are technically ‘explainable’ but that, in a fuller sense, the relevant standards and rules are contestable and that governing institutions and processes are open to democratic contestability. © 2020 Perry Keller","2-s2.0-85095916201"
"Morley J.; Elhalal A.; Garcia F.; Kinsey L.; Mökander J.; Floridi L.","Morley, Jessica (57209294694); Elhalal, Anat (8219521000); Garcia, Francesca (57224823596); Kinsey, Libby (57201436846); Mökander, Jakob (57222069643); Floridi, Luciano (6603039594)","57209294694; 8219521000; 57224823596; 57201436846; 57222069643; 6603039594","Ethics as a Service: A Pragmatic Operationalisation of AI Ethics","2021","Minds and Machines","31","2","","239","256","17","10.1007/s11023-021-09563-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108377488&doi=10.1007%2fs11023-021-09563-w&partnerID=40&md5=39fcdcd33f27500c91d92d994d0a5967","As the range of potential uses for Artificial Intelligence (AI), in particular machine learning (ML), has increased, so has awareness of the associated ethical issues. This increased awareness has led to the realisation that existing legislation and regulation provides insufficient protection to individuals, groups, society, and the environment from AI harms. In response to this realisation, there has been a proliferation of principle-based ethics codes, guidelines and frameworks. However, it has become increasingly clear that a significant gap exists between the theory of AI ethics principles and the practical design of AI systems. In previous work, we analysed whether it is possible to close this gap between the ‘what’ and the ‘how’ of AI ethics through the use of tools and methods designed to help AI developers, engineers, and designers translate principles into practice. We concluded that this method of closure is currently ineffective as almost all existing translational tools and methods are either too flexible (and thus vulnerable to ethics washing) or too strict (unresponsive to context). This raised the question: if, even with technical guidance, AI ethics is challenging to embed in the process of algorithmic design, is the entire pro-ethical design endeavour rendered futile? And, if no, then how can AI ethics be made useful for AI practitioners? This is the question we seek to address here by exploring why principles and technical translational tools are still needed even if they are limited, and how these limitations can be potentially overcome by providing theoretical grounding of a concept that has been termed ‘Ethics as a Service.’ © 2021, The Author(s).","2-s2.0-85108377488"
"Yu J.; Park S.; Kwon S.-H.; Cho K.-H.; Lee H.","Yu, Jaehak (25227980300); Park, Sejin (57191670651); Kwon, Soon-Hyun (56115728600); Cho, Kang-Hee (57199155482); Lee, Hansung (13005677900)","25227980300; 57191670651; 56115728600; 57199155482; 13005677900","AI-Based Stroke Disease Prediction System Using ECG and PPG Bio-Signals","2022","IEEE Access","10","","","43623","43638","15","10.1109/ACCESS.2022.3169284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129184805&doi=10.1109%2fACCESS.2022.3169284&partnerID=40&md5=77d7abe3c5d3f03fb35841182125f48a","Since stroke disease often causes death or serious disability, active primary prevention and early detection of prognostic symptoms are very important. Stroke diseases can be divided into ischemic stroke and hemorrhagic stroke, and they should be minimized by emergency treatment such as thrombolytic or coagulant administration by type. First, it is essential to detect in real time the precursor symptoms of stroke, which occur differently for each individual, and to provide professional treatment by a medical institution within the proper treatment window. However, prior studies have focused on developing acute treatment or clinical treatment guidelines after the onset of stroke rather than detecting the prognostic symptoms of stroke. In particular, in recent studies, image analysis such as magnetic resonance imaging (MRI) or computed tomography (CT) has mostly been used to detect and predict prognostic symptoms in stroke patients. Not only are these methodologies difficult to diagnose early in real-time, but they also have limitations in terms of a long test time and a high cost of testing. In this paper, we propose a system that can predict and semantically interpret stroke prognostic symptoms based on machine learning using the multi-modal bio-signals of electrocardiogram (ECG) and photoplethysmography (PPG) measured in real-time for the elderly. To predict stroke disease in real-time while walking, we designed and implemented a stroke disease prediction system with an ensemble structure that combines CNN and LSTM. The proposed system considers the convenience of wearing the bio-signal sensors for the elderly, and the bio-signals were collected at a sampling rate of 1,000Hz per second from the three electrodes of the ECG and the index finger for PPG while walking. According to the experimental results, C4.5 decision tree showed a prediction accuracy of 91.56% while RandomForest showed a prediction accuracy of 97.51% during walking by the elderly. In addition, the CNN-LSTM model using raw data of ECG and PPG showed satisfactory prediction accuracy of 99.15%. As a result, the real-time prediction of the elderly stroke patients simultaneously showed high prediction accuracy and performance.  © 2013 IEEE.","2-s2.0-85129184805"
"Seth D.; Talwadker R.; Mukherjee T.; Chitapure U.; Adiga N.; Gupta A.","Seth, Deepanshi (57217015342); Talwadker, Rukma (55837241100); Mukherjee, Tridib (15060197100); Chitapure, Usama (57226481549); Adiga, Nagesh (57226469940); Gupta, Avantika (58264137100)","57217015342; 55837241100; 15060197100; 57226481549; 57226469940; 58264137100","AI Based Information Retrieval System for Identifying Harmful Online Gaming Patterns","2021","SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","3464921","2639","2640","1","10.1145/3404835.3464921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111620180&doi=10.1145%2f3404835.3464921&partnerID=40&md5=1b5b2108244f38e484700d88c72fefcb","Games of skill are an excellent source of recreation and relaxation. Games are also the safest and readily accessible constructs for social interaction and community affairs which potentially opens up new avenues for realising personal worth, social acceptance, respect and recognition. However, when these games are played with real money, ensuring game prudence, whereby users play real-money skill games only for entertainment purposes, and do so well within their resourceful means, becomes necessary. It becomes paramount for the wellness of players and also to ensure online gaming is only available for sheer entertainment. In this proposal, we present an automated, data driven, AI powered, Responsible Game Play (RGP) framework cum tool which has been integrated in our online skill gaming platform. RGP pipeline is a combination of: a) a couple of anomaly detection Rule Based Engines; b) a Deep Learning Pipeline which models the game play characteristics of healthy and engaged players to identify potentially risky players, and c) a ML based Local Expert which leverages users' longitudinal behavioral patterns and constructs new features using the adjacent AI OPS and Signal Processing Domains. We integrate the psychometric assessment to nudge and coarse correct at-risk players proactively, ahead of time  © 2021 Owner/Author.","2-s2.0-85111620180"
"Tanikawa C.; Kajiwara T.; Shimizu Y.; Yamashiro T.; Chu C.; Nagahara H.","Tanikawa, Chihiro (22837117000); Kajiwara, Tomoyuki (56903744700); Shimizu, Yuujin (57219510475); Yamashiro, Takashi (55416765600); Chu, Chenhui (57687731700); Nagahara, Hajime (7006675539)","22837117000; 56903744700; 57219510475; 55416765600; 57687731700; 7006675539","Machine/deep learning for performing orthodontic diagnoses and treatment planning","2021","Machine Learning in Dentistry","","","","69","78","9","10.1007/978-3-030-71881-7_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118531030&doi=10.1007%2f978-3-030-71881-7_6&partnerID=40&md5=dc36744d7df6a575a18faf5552e1ae78","As automated treatment planning is expected to reduce inter-planner variability and the planning time allocated for the optimization process in order to improve the plan quality, researchers have attempted to develop such systems. Artificial intelligence (AI) attempts to reflect advanced human intelligence in machines, and efforts to develop AI systems have been made since the advent of computers. In the 1980s, an expert system that expressed expert knowledge in a program produced useful results as AI technology. However, because it was a system in which rules were embedded in advance, it was limited by its difficulty in handling exceptions. Furthermore, making rules is time-consuming. The importance of machine learning that inductively learns general rules and laws based on various events (data) became recognized in the 1990s. Machine learning techniques can be said to be general-purpose techniques for detecting regularity and specificity in observational data. In this chapter, we will introduce several AI systems that have been used to derive orthodontic diagnoses and develop treatment plans in the past. We will then introduce a newly developed AI system that uses natural language processing to conduct various clinical text evaluations and develop accompanying treatment protocols. © Springer Nature Switzerland AG 2021. All rights reserved.","2-s2.0-85118531030"
"Rathod K.; Sonawane A.","Rathod, Kundan (57693971600); Sonawane, Aditi (57693860100)","57693971600; 57693860100","Application of Artificial Intelligence in Project Planning to Solve Late and Over-Budgeted Construction Projects","2022","International Conference on Sustainable Computing and Data Communication Systems, ICSCDS 2022 - Proceedings","","","","424","431","7","10.1109/ICSCDS53736.2022.9761027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130092685&doi=10.1109%2fICSCDS53736.2022.9761027&partnerID=40&md5=2cdd5ae3b2a55638a974ca55f00db9ad","Advance use of Artificial Intelligence (AI), has reduced the need of human intervention within several tasks that are repetitive and rule-based. AI can have a great impact on the workforce of a project within the construction industry. Use of Machine learning techniques within the project process can be beneficial for a project manager to manage financial aspects and time scheduling both. The major problem that construction project managers face is ineffective tracking process, cost management process. This is the main reason, the AI-based solution are needed within construction sites. The aim of this research is to identify the role of AI in time management as well as cost management of a construction project in India. Intelligence robotics is a major AI-based tool that is used within construction project for marinating cost. Some challenges are also found within construction project that might have a huge effect within its implementation process such as cultural barriers, high-cost of maintenance and unavailability of similar input parameters in all projects. As per the findings, ANN, SVM, Regression and many other AI-based are effective Ai-based machine learning tools that are used within construction project to replace various time consuming process by modern technologies. Construction delays are the major effective factor for cost overrun and time overrun within a project. As per this research article, it has been found that, use of AI, especially ANN model can reduce the tendency of delay in construction projects and mismanagement of costs.  © 2022 IEEE.","2-s2.0-85130092685"
"Hepworth A.J.; Baxter D.P.; Abbass H.A.","Hepworth, Adam J. (57221420762); Baxter, Daniel P. (57221417553); Abbass, Hussein A. (6701824380)","57221420762; 57221417553; 6701824380","Onto4MAT: A Swarm Shepherding Ontology for Generalized Multiagent Teaming","2022","IEEE Access","10","","","59843","59861","18","10.1109/ACCESS.2022.3180032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131723862&doi=10.1109%2fACCESS.2022.3180032&partnerID=40&md5=c5ec70643015968f001f987b188fe7d0","Research in multi-agent teaming has increased substantially over recent years. Underneath these attempts sits a suite of communication functions to enable effective teaming. The Artificial Intelligence (AI) systems supporting the teaming arrangement have primarily relied on knowledge-based systems, with rules triggered based on the mode of interaction. Enabling humans to join the team of AI agents effectively calls for both the humans and AI agents to share their understanding and representation of their shared worlds. Such shared understanding requires formal representations of concepts to support transparency during bi-directional communications between team members. Little research has been done in this space, especially when humans need to team with a swarm of agents. We present an ontology designed specifically for human-agent teaming to address this research gap. The ontology is general, but we then contextualise it into a particular swarm-shepherding scenario to illustrate its use in a particular context. The proposed Ontology for Generalised Multi-Agent Teaming Onto4MAT offers the underlying building blocks for effective communication and shared understanding between humans and multi-agent teams.  © 2013 IEEE.","2-s2.0-85131723862"
"Peng L.; Zeng H.","Peng, Li (57765583400); Zeng, Hongwu (57202730262)","57765583400; 57202730262","Research and development of the clinical thinking mining and discovery system based on artificial intelligence","2022","Proceedings of SPIE - The International Society for Optical Engineering","12260","","1226021","","","","10.1117/12.2637407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132935531&doi=10.1117%2f12.2637407&partnerID=40&md5=0ce5ddc8687d0fc92f1806470bdfc51b","An AI-based clinical thinking mining discovery system that can be used on PCs and mobile terminals (cell phones, pads, etc.). The system utilizes artificial intelligence technology to obtain massive medical case data and case discussions from the Internet for data extraction and organization, and intelligently classifies them by disease type and clinical presentation. Using natural language processing technology and intelligent mapping mechanism of medical terms, it mines the information of clinical features, tests, inspections, disposal measures and reasons (drugs, surgeries, etc.) of the extracted cases, abstracts and visualizes the diagnostic rules and clinical treatment channels of the cases. The medical case data processed on the Internet will be combined with the typical case data in the HIS system to form a clinical knowledge repository of diseases, guide junior doctors and students to conduct clinical thinking training and consolidate medical knowledge.  © The Authors.","2-s2.0-85132935531"
"Ryan M.; Stahl B.C.","Ryan, Mark (57211005946); Stahl, Bernd Carsten (10045088600)","57211005946; 10045088600","Artificial intelligence ethics guidelines for developers and users: clarifying their content and normative implications","2021","Journal of Information, Communication and Ethics in Society","19","1","","61","86","25","10.1108/JICES-12-2019-0138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086091728&doi=10.1108%2fJICES-12-2019-0138&partnerID=40&md5=47053a211fa92e106eba8b4b9431dc30","Purpose: The purpose of this paper is clearly illustrate this convergence and the prescriptive recommendations that such documents entail. There is a significant amount of research into the ethical consequences of artificial intelligence (AI). This is reflected by many outputs across academia, policy and the media. Many of these outputs aim to provide guidance to particular stakeholder groups. It has recently been shown that there is a large degree of convergence in terms of the principles upon which these guidance documents are based. Despite this convergence, it is not always clear how these principles are to be translated into practice. Design/methodology/approach: In this paper, the authors move beyond the high-level ethical principles that are common across the AI ethics guidance literature and provide a description of the normative content that is covered by these principles. The outcome is a comprehensive compilation of normative requirements arising from existing guidance documents. This is not only required for a deeper theoretical understanding of AI ethics discussions but also for the creation of practical and implementable guidance for developers and users of AI. Findings: In this paper, the authors therefore provide a detailed explanation of the normative implications of existing AI ethics guidelines but directed towards developers and organisational users of AI. The authors believe that the paper provides the most comprehensive account of ethical requirements in AI currently available, which is of interest not only to the research and policy communities engaged in the topic but also to the user communities that require guidance when developing or deploying AI systems. Originality/value: The authors believe that they have managed to compile the most comprehensive document collecting existing guidance which can guide practical action but will hopefully also support the consolidation of the guidelines landscape. The authors’ findings should also be of academic interest and inspire philosophical research on the consistency and justification of the various normative statements that can be found in the literature. © 2020, Mark Ryan and Bernd Carsten Stahl.","2-s2.0-85086091728"
"Han S.-H.; Choi H.-J.","Han, Seung-Ho (57193959163); Choi, Ho-Jin (35073646600)","57193959163; 35073646600","Checklist for Validating Trustworthy AI","2022","Proceedings - 2022 IEEE International Conference on Big Data and Smart Computing, BigComp 2022","","","","391","394","3","10.1109/BigComp54360.2022.00088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127568173&doi=10.1109%2fBigComp54360.2022.00088&partnerID=40&md5=e59326b91fca55c5a7c2174b7194883d","In the recent years AI technologies have been improved and utilized in the various real-world fields such as life, economy, finance, transportation, game, etc. Especially, the deep learning, one of the learning-based machine learning methods, has shown remarkable performance improvement in a broad variety of studies. As the widespread use of AI systems including the deep learning, however, the issue of reliability of AI-based systems has recently emerged. In the case of the many AI systems, they use a huge amount of data to train their models as well as the system is very complex for humans to comprehend. Hence, humans cannot be able to understand AI systems and have no confidence in the results they generate. Furthermore, it can cause various problems such as unexplained system error or uncontrollable system behavior when using AI systems in the real-world, and even can lead to very serious situations in sensitive services such as aviation, medical care, and security. In this paper, we examine a checklist to improve a reliability of AI system. Specifically, we introduce considerations with regard to the life cycle of an AI system.  © 2022 IEEE.","2-s2.0-85127568173"
"Lu Q.; Zhu L.; Xu X.; Whittle J.; Douglas D.; Sanderson C.","Lu, Qinghua (56431802100); Zhu, Liming (57191568259); Xu, Xiwei (55706225900); Whittle, Jon (23006933800); Douglas, David (57196901046); Sanderson, Conrad (55616049200)","56431802100; 57191568259; 55706225900; 23006933800; 57196901046; 55616049200","Software engineering for Responsible AI: An empirical study and operationalised patterns","2022","Proceedings - International Conference on Software Engineering","","","","241","242","1","10.1109/ICSE-SEIP55303.2022.9793864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132823818&doi=10.1109%2fICSE-SEIP55303.2022.9793864&partnerID=40&md5=08b040095394ccd2b2f8e2b2a1dc8a59","AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.  © 2022 IEEE.","2-s2.0-85132823818"
"Jiang Y.; Gu X.; Hua L.; Li K.; Tao Y.; Li B.","Jiang, Yizhang (55437846600); Gu, Xiaoqing (55639726400); Hua, Lei (57219713570); Li, Kang (57220546571); Tao, Yuwen (57222348052); Li, Bo (57226853686)","55437846600; 55639726400; 57219713570; 57220546571; 57222348052; 57226853686","Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted TSK Fuzzy System","2021","ACM Transactions on Internet Technology","22","3","64","","","","10.1145/3475870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137614940&doi=10.1145%2f3475870&partnerID=40&md5=7e56adf1cd0999be8c5506a05eeec81b","Artificial intelligence-(AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ϵ-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.  © 2021 Association for Computing Machinery.","2-s2.0-85137614940"
"Grua E.M.; de Sanctis M.; Malavolta I.; Hoogendoorn M.; Lago P.","Grua, Eoin Martino (57207728498); de Sanctis, Martina (56358489900); Malavolta, Ivano (25823118300); Hoogendoorn, Mark (10640498300); Lago, Patricia (56187491900)","57207728498; 56358489900; 25823118300; 10640498300; 56187491900","Social sustainability in the e-health domain via personalized and self-adaptive mobile apps","2021","Software Sustainability","","","","301","328","27","10.1007/978-3-030-69970-3_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124488061&doi=10.1007%2f978-3-030-69970-3_13&partnerID=40&md5=798c90e2f8a7402aa52f5b87ddf40d30","Within software engineering, social sustainability is the dimension of sustainability that focuses on the ""support of current and future generations to have the same or greater access to social resources by pursuing social equity."" An important domain that strives to achieve social sustainability is e-Health, and more recently e-Health mobile apps.A wealth of e-Health mobile apps is available for many purposes, such as lifestyle improvement and mental coaching. The interventions, prompts, and encouragements of e-Health apps sometimes take context into account (e.g., previous interactions or geographical location of the user), but they still tend to be rigid, e.g., apps use fixed sets of rules or they are not sufficiently tailored toward individuals' needs. Personalization to the different users' characteristics and run-time adaptation to their changing needs and context provide a great opportunity for getting users continuously engaged and active, eventually leading to better physical and mental conditions. This chapter presents a reference architecture for enabling AI-based personalization and self-adaptation of mobile apps for e-Health. The reference architecture makes use of a dedicated goal model and multiple MAPE loops operating at different levels of granularity and for different purposes. The proposed reference architecture is instantiated in the context of a fitness-based mobile application and exemplified through a series of typical usage scenarios extracted from our industrial collaborations. © Springer Nature Switzerland AG 2021. All rights reserved.","2-s2.0-85124488061"
"Montalbo F.J.P.","Montalbo, Francis Jesmar P. (57212309186)","57212309186","Diagnosing Covid-19 chest x-rays with a lightweight truncated DenseNet with partial layer freezing and feature fusion","2021","Biomedical Signal Processing and Control","68","","102583","","","","10.1016/j.bspc.2021.102583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103685033&doi=10.1016%2fj.bspc.2021.102583&partnerID=40&md5=1b497a79cade425c1222a46b7ca25e9e","Due to the unforeseen turn of events, our world has undergone another global pandemic from a highly contagious novel coronavirus named COVID-19. The novel virus inflames the lungs similarly to Pneumonia, making it challenging to diagnose. Currently, the common standard to diagnose the virus's presence from an individual is using a molecular real-time Reverse-Transcription Polymerase Chain Reaction (rRT-PCR) test from fluids acquired through nasal swabs. Such a test is difficult to acquire in most underdeveloped countries with a few experts that can perform the test. As a substitute, the widely available Chest X-Ray (CXR) became an alternative to rule out the virus. However, such a method does not come easy as the virus still possesses unknown characteristics that even experienced radiologists and other medical experts find difficult to diagnose through CXRs. Several studies have recently used computer-aided methods to automate and improve such diagnosis of CXRs through Artificial Intelligence (AI) based on computer vision and Deep Convolutional Neural Networks (DCNN), which some require heavy processing costs and other tedious methods to produce. Therefore, this work proposed the Fused-DenseNet-Tiny, a lightweight DCNN model based on a densely connected neural network (DenseNet) truncated and concatenated. The model trained to learn CXR features based on transfer learning, partial layer freezing, and feature fusion. Upon evaluation, the proposed model achieved a remarkable 97.99 % accuracy, with only 1.2 million parameters and a shorter end-to-end structure. It has also shown better performance than some existing studies and other massive state-of-the-art models that diagnosed COVID-19 from CXRs. © 2021 Elsevier Ltd","2-s2.0-85103685033"
"Bublin M.; Schefer-Wenzl S.; Miladinović I.","Bublin, Mugdim (57219588402); Schefer-Wenzl, Sigrid (55234970500); Miladinović, Igor (6602306899)","57219588402; 55234970500; 6602306899","Educating AI Software Engineers: Challenges and Opportunities","2022","Lecture Notes in Networks and Systems","390 LNNS","","","241","251","10","10.1007/978-3-030-93907-6_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124767420&doi=10.1007%2f978-3-030-93907-6_26&partnerID=40&md5=0b44ae9d51ed6da5e6e3c22acf30149b","To properly develop, test und use Artificial Intelligence (AI) applications, students and professionals need a well-defined AI software engineering (AISE) process and the appropriate tools. However, AISE, which is today mainly based on the use of deep learning (DL) neural networks, is still under development. This makes the education of AI software engineers particularly challenging, since there are no well-established methodologies, tools and practices, like in traditional Software Engineering (SE) education drawing on decades of experience and methods in all phases of software development, from requirements analysis over design and implementation to integration and testing. We analyze the main differences between traditional SE and AISE education and address challenges in AISE education. Our methodology is based on literature survey, analysis of own industry experience and statistical analysis of students works on AI applications. Our goal is to provide guidelines for an AISE process and propose a curriculum path for AISE education, which can be used to update a traditional SE curriculum. According to results of our analysis, the main challenges for the students are: Dealing with data and taking into account that algorithms change (learn) by data, selection and re-use of AI algorithms, model test, maintenance and automatizing the AISE process. We propose to address these challenges in SE curricula by teaching more statistical thinking with connections to software development, developing re-engineering capabilities, teaching a model-based AI approach and combining AI with virtual reality simulations. In the whole process, we consider an optimal division of work between humans and AI systems by explicitly including humans in the AISE loop. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85124767420"
"Rausch A.; Sedeh A.M.; Zhang M.","Rausch, Andreas (8586021000); Sedeh, Azarmidokht Motamedi (57244413800); Zhang, Meng (57191831692)","8586021000; 57244413800; 57191831692","Autoencoder-based semantic novelty detection: Towards dependable ai-based systems","2021","Applied Sciences (Switzerland)","11","21","9881","","","","10.3390/app11219881","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117570385&doi=10.3390%2fapp11219881&partnerID=40&md5=5c205be4b163fce32286f1c8f653cbec","Many autonomous systems, such as driverless taxis, perform safety-critical functions. Autonomous systems employ artificial intelligence (AI) techniques, specifically for environmental per-ception. Engineers cannot completely test or formally verify AI-based autonomous systems. The accuracy of AI-based systems depends on the quality of training data. Thus, novelty detection, that is, identifying data that differ in some respect from the data used for training, becomes a safety measure for system development and operation. In this study, we propose a new architecture for autoencoder-based semantic novelty detection with two innovations: architectural guidelines for a semantic autoencoder topology and a semantic error calculation as novelty criteria. We demonstrate that such a semantic novelty detection outperforms autoencoder-based novelty detection approaches known from the literature by minimizing false negatives. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85117570385"
"Myllyaho L.; Raatikainen M.; Männistö T.; Mikkonen T.; Nurminen J.K.","Myllyaho, Lalli (57211425624); Raatikainen, Mikko (36125446900); Männistö, Tomi (6601957357); Mikkonen, Tommi (57220096141); Nurminen, Jukka K. (6603849383)","57211425624; 36125446900; 6601957357; 57220096141; 6603849383","Systematic literature review of validation methods for AI systems","2021","Journal of Systems and Software","181","","111050","","","","10.1016/j.jss.2021.111050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112415717&doi=10.1016%2fj.jss.2021.111050&partnerID=40&md5=5effdf8b47fc5b128e3b499b5557b7d2","Context: Artificial intelligence (AI) has made its way into everyday activities, particularly through new techniques such as machine learning (ML). These techniques are implementable with little domain knowledge. This, combined with the difficulty of testing AI systems with traditional methods, has made system trustworthiness a pressing issue. Objective: This paper studies the methods used to validate practical AI systems reported in the literature. Our goal is to classify and describe the methods that are used in realistic settings to ensure the dependability of AI systems. Method: A systematic literature review resulted in 90 papers. Systems presented in the papers were analysed based on their domain, task, complexity, and applied validation methods. Results: The validation methods were synthesized into a taxonomy consisting of trial, simulation, model-centred validation, and expert opinion. Failure monitors, safety channels, redundancy, voting, and input and output restrictions are methods used to continuously validate the systems after deployment. Conclusions: Our results clarify existing strategies applied to validation. They form a basis for the synthesization, assessment, and refinement of AI system validation in research and guidelines for validating individual systems in practice. While various validation strategies have all been relatively widely applied, only few studies report on continuous validation. © 2021 The Author(s)","2-s2.0-85112415717"
"Agarwal S.; Mouatadid L.; Sreepathy A.; Furbish K.; Kimbrell M.; Gabriel M.","Agarwal, Sudhir (57614122800); Mouatadid, Lalla (56267551800); Sreepathy, Anu (57610803100); Furbish, Kevin (57610803200); Kimbrell, Morgen (57613471800); Gabriel, Mike (57612817400)","57614122800; 56267551800; 57610803100; 57610803200; 57613471800; 57612817400","Actionable Recommendations for Small Businesses With Hybrid AI","2022","CEUR Workshop Proceedings","3121","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128718360&partnerID=40&md5=6b32255fdf3e6906593a0af91678e08f","We present a business use case for computing actionable recommendations for SMBs to prevent near-future or existing critical situations for which a Hybrid AI solution seems more promising than a pure Machine Learning or a pure Symbolic AI solution. For one of the most common of such critical situations, namely, insufficient operating funds, we provide details on the complexity of the problem as well as the requirements on actionable recommendations. We argue why the requirements cannot be satisfied by an end-to-end Machine Learning or Symbolic AI system. We show a breakdown of the monolith into sub-problems, and justify the selection of the most appropriate AI technique for each component, in particular, Machine Learning, Symbolic Rules, and Mathematical Optimization. We also discuss some of the challenges industry would face when adopting Hybrid AI solutions. © 2022 Copyright for this paper by its authors","2-s2.0-85128718360"
"Park S.; Kim H.K.; Lee Y.; Park G.; Lee D.","Park, Sunyoung (57374754400); Kim, Hyun K. (57094273400); Lee, Yuryeon (57213814236); Park, Gyuwon (57553197400); Lee, Danbi (57552031800)","57374754400; 57094273400; 57213814236; 57553197400; 57552031800","User Experience Design for Defense Systems with AI","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13184 LNCS","","","242","247","5","10.1007/978-3-030-98404-5_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127195397&doi=10.1007%2f978-3-030-98404-5_23&partnerID=40&md5=2232799d778e6ef4992fea32dc59d799","As artificial intelligence (AI) is applied at an increasing frequency in various fields, the number of studies on the user experience (UX) design of human-AI interaction is also increasing. However, the results of these studies on AI UX design principles are insufficient for actual AI systems. In light of this fact, the purpose of this study was to upgrade the UX design of a defense system that uses AI technology to detect land changes and targets. In order to upgrade the UX design of this AI system, a three-step procedure was executed. First, AI UX principles were derived by analyzing literature related to human-AI interaction. Second, ideation was performed to improve the interface. Finally, the results of the ideation were utilized to construct the UX prototype of the AI system with Adobe XD. The results of this study are expected to be used as fundamental data for future research that will develop UX principles and advanced methods for AI systems. © 2022, Springer Nature Switzerland AG.","2-s2.0-85127195397"
"Stieler F.; Rabe F.; Bauer B.","Stieler, Fabian (57199423327); Rabe, Fabian (57202611088); Bauer, Bernhard (35241718100)","57199423327; 57202611088; 35241718100","Towards domain-specific explainable AI: Model interpretation of a skin image classifier using a human approach","2021","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","","","","1802","1809","7","10.1109/CVPRW53098.2021.00199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116038250&doi=10.1109%2fCVPRW53098.2021.00199&partnerID=40&md5=0286196b93336b6996d78c3ff3f113b3","Machine Learning models have started to outperform medical experts in some classification tasks. Meanwhile, the question of how these classifiers produce certain results is attracting increasing research attention. Current interpretation methods provide a good starting point in investigating such questions, but they still massively lack the relation to the problem domain. In this work, we present how explanations of an AI system for skin image analysis can be made more domain-specific. We apply the synthesis of Local Interpretable Model-agnostic Explanations (LIME) with the ABCD-rule, a diagnostic approach of dermatologists, and present the results using a Deep Neural Network (DNN) based skin image classifier. © 2021 IEEE.","2-s2.0-85116038250"
"Bogner J.; Verdecchia R.; Gerostathopoulos I.","Bogner, Justus (57189261793); Verdecchia, Roberto (57200754960); Gerostathopoulos, Ilias (54787703800)","57189261793; 57200754960; 54787703800","Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study","2021","Proceedings - 2021 IEEE/ACM International Conference on Technical Debt, TechDebt 2021","","","","64","73","9","10.1109/TechDebt52882.2021.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114832074&doi=10.1109%2fTechDebt52882.2021.00016&partnerID=40&md5=d2a18c8a42af690521e2a1a5b47df62c","Background: With the rising popularity of Artificial Intelligence (AI), there is a growing need to build large and complex AI-based systems in a cost-effective and manageable way. Like with traditional software, Technical Debt (TD) will emerge naturally over time in these systems, therefore leading to challenges and risks if not managed appropriately. The influence of data science and the stochastic nature of AI-based systems may also lead to new types of TD or antipatterns, which are not yet fully understood by researchers and practitioners. Objective: The goal of our study is to provide a clear overview and characterization of the types of TD (both established and new ones) that appear in AI-based systems, as well as the antipatterns and related solutions that have been proposed. Method: Following the process of a systematic mapping study, 21 primary studies are identified and analyzed. Results: Our results show that (i) established TD types, variations of them, and four new TD types (data, model, configuration, and ethics debt) are present in AI-based systems, (ii) 72 antipatterns are discussed in the literature, the majority related to data and model deficiencies, and (iii) 46 solutions have been proposed, either to address specific TD types, antipatterns, or TD in general. Conclusions: Our results can support AI professionals with reasoning about and communicating aspects of TD present in their systems. Additionally, they can serve as a foundation for future research to further our understanding of TD in AI-based systems.  © 2021 IEEE.","2-s2.0-85114832074"
"Lanubile F.; Calefato F.; Quaranta L.; Amoruso M.; Fumarola F.; Filannino M.","Lanubile, Filippo (7003587349); Calefato, Fabio (8303001500); Quaranta, Luigi (57211035024); Amoruso, Maddalena (57222956807); Fumarola, Fabio (26325359300); Filannino, Michele (25633782800)","7003587349; 8303001500; 57211035024; 57222956807; 26325359300; 25633782800","Towards productizing AI/ML Models: An industry perspective from data scientists","2021","Proceedings - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI, WAIN 2021","","","9474371","129","132","3","10.1109/WAIN52551.2021.00027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113230759&doi=10.1109%2fWAIN52551.2021.00027&partnerID=40&md5=1ebb426937eeade0127fb75bd8847457","The transition from AI/ML models to production-ready AI-based systems is a challenge for both data scientists and software engineers. In this paper, we report the results of a workshop conducted in a consulting company to understand how this transition is perceived by practitioners. Starting from the need for making AI experiments reproducible, the main themes that emerged are related to the use of the Jupyter Notebook as the primary prototyping tool, and the lack of support for software engineering best practices as well as data science specific functionalities.  © 2021 IEEE.","2-s2.0-85113230759"
"Antoniadi A.M.; Du Y.; Guendouz Y.; Wei L.; Mazo C.; Becker B.A.; Mooney C.","Antoniadi, Anna Markella (57215383205); Du, Yuhan (57220115062); Guendouz, Yasmine (57224537857); Wei, Lan (57219011267); Mazo, Claudia (55348155300); Becker, Brett A. (24436490600); Mooney, Catherine (56251250500)","57215383205; 57220115062; 57224537857; 57219011267; 55348155300; 24436490600; 56251250500","Current challenges and future opportunities for xai in machine learning-based clinical decision support systems: A systematic review","2021","Applied Sciences (Switzerland)","11","11","5088","","","","10.3390/app11115088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107556681&doi=10.3390%2fapp11115088&partnerID=40&md5=32428f478e5780cc8ba68bd71a0055e8","Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85107556681"
"Saponara S.; Elhanashi A.; Gagliardi A.","Saponara, Sergio (57213944920); Elhanashi, Abdussalam (57219848645); Gagliardi, Alessio (57189904340)","57213944920; 57219848645; 57189904340","Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19","2021","Journal of Real-Time Image Processing","18","6","","1937","1947","10","10.1007/s11554-021-01070-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099932482&doi=10.1007%2fs11554-021-01070-6&partnerID=40&md5=ca1d53a8ef06999000911c057866b0d9","COVID-19 is a disease caused by a severe respiratory syndrome coronavirus. It was identified in December 2019 in Wuhan, China. It has resulted in an ongoing pandemic that caused infected cases including many deaths. Coronavirus is primarily spread between people during close contact. Motivating to this notion, this research proposes an artificial intelligence system for social distancing classification of persons using thermal images. By exploiting YOLOv2 (you look at once) approach, a novel deep learning detection technique is developed for detecting and tracking people in indoor and outdoor scenarios. An algorithm is also implemented for measuring and classifying the distance between persons and to automatically check if social distancing rules are respected or not. Hence, this work aims at minimizing the spread of the COVID-19 virus by evaluating if and how persons comply with social distancing rules. The proposed approach is applied to images acquired through thermal cameras, to establish a complete AI system for people tracking, social distancing classification, and body temperature monitoring. The training phase is done with two datasets captured from different thermal cameras. Ground Truth Labeler app is used for labeling the persons in the images. The proposed technique has been deployed in a low-cost embedded system (Jetson Nano) which is composed of a fixed camera. The proposed approach is implemented in a distributed surveillance video system to visualize people from several cameras in one centralized monitoring system. The achieved results show that the proposed method is suitable to set up a surveillance system in smart cities for people detection, social distancing classification, and body temperature analysis. © 2021, The Author(s).","2-s2.0-85099932482"
"Otoum S.; Al Ridhawi I.; Mouftah H.T.","Otoum, Safa (55868260900); Al Ridhawi, Ismaeel (49862114100); Mouftah, Hussein T. (7102957682)","55868260900; 49862114100; 7102957682","Preventing and Controlling Epidemics through Blockchain-Assisted AI-Enabled Networks","2021","IEEE Network","35","3","9454578","34","41","7","10.1109/MNET.011.2000628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112574657&doi=10.1109%2fMNET.011.2000628&partnerID=40&md5=72a46afb8b0dbff863629c0968d76bc2","The COVID-19 pandemic, which spread rapidly in late 2019, has revealed that the use of computing and communication technologies provides significant aid in preventing, controlling, and combating infectious diseases. With the ongoing research in next-generation networking (NGN), the use of secure and reliable communication and networking is of utmost importance when dealing with users' health records and other sensitive information. Through the adaptation of artificial-intelligence-enabled NGN, the shape of healthcare systems can be altered to achieve smart and secure healthcare capable of coping with epidemics that may emerge at any given moment. In this article, we envision a cooperative and distributed healthcare framework that relies on state-of-the-art computing, communication, and intelligence capabilities, namely, federated learning, mobile edge computing, and blockchain, to enable epidemic (or suspicious infectious disease) discovery, remote monitoring, and fast health authority response. The introduced framework can also enable secure medical data exchange at the edge and between different health entities. This technique, coupled with the low latency and high bandwidth functionality of 5G and beyond networks, would enable mass surveillance, monitoring, and analysis to occur at the edge. Challenges, issues, and design guidelines are also discussed in this article with highlights on some trending solutions.  © 1986-2012 IEEE.","2-s2.0-85112574657"
"Voulgari I.; Zammit M.; Stouraitis E.; Liapis A.; Yannakakis G.","Voulgari, Iro (24825483100); Zammit, Marvin (57226000737); Stouraitis, Elias (57195428369); Liapis, Antonios (53264261900); Yannakakis, Georgios (14036725000)","24825483100; 57226000737; 57195428369; 53264261900; 14036725000","Learn to Machine Learn: Designing a Game Based Approach for Teaching Machine Learning to Primary and Secondary Education Students","2021","Proceedings of Interaction Design and Children, IDC 2021","","","","593","598","5","10.1145/3459990.3465176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110159144&doi=10.1145%2f3459990.3465176&partnerID=40&md5=0d4788628c2215e7b9e69076fdad24f3","With the ubiquitous role of Artificial Intelligence (AI) in everyday applications such as smartphones and social media, children need digital literacy skills to navigate the digital world, critically view, and reflect on the social and ethical implications of the design and architecture of AI systems. To address this increasing need for AI literacy skills, particularly for younger students, this paper presents the rationale of the LearnML project which aims to develop a framework and game-based educational material for promoting AI literacy among primary and secondary education students. We also describe the design and initial assessment of the game ""ArtBot"", developed as part of the LearnML project. We review existing literature, discuss the educational game design and development of ""ArtBot""and describe the initial feedback of students and teachers. Our goal is to provide insights and suggest guidelines for the implementation of game-based learning environments for supporting AI literacy skills of students. © 2021 Owner/Author.","2-s2.0-85110159144"
"Sari O.; Celik S.","Sari, Onur (57226832807); Celik, Sener (57226827013)","57226832807; 57226827013","Legal evaluation of the attacks caused by artificial intelligence-based lethal weapon systems within the context of Rome statute","2021","Computer Law and Security Review","42","","105564","","","","10.1016/j.clsr.2021.105564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112789421&doi=10.1016%2fj.clsr.2021.105564&partnerID=40&md5=dc3e8c9be3ce79a804528a6b785ac62c","Artificial intelligence (AI) as of the level of development reached today has become a scientific reality that is subject to study in the fields of law, political science, and other social sciences besides computer and software engineering. AI systems which perform relatively simple tasks in the early stages of the development period are expected to become fully or largely autonomous in the near future. Thanks to this, AI which includes the concepts of machine learning, deep learning, and autonomy, has begun to play an important role in producing and using smart arms. However, questions about AI-Based Lethal Weapon Systems (AILWS) and attacks that can be carried out by such systems have not been fully answered under legal aspect. More particularly, it is a controversial issue who will be responsible for the actions that an AILWS has committed. In this article, we discussed whether AILWS can commit offense in the context of the Rome Statute, examined the applicable law regarding the responsibility of AILWS, and tried to assess whether these systems can be held responsible in the context of international law, crime of aggression, and individual responsibility. It is our finding that international legal rules including the Rome Statute can be applied regarding the responsibility for the act/crime of aggression caused by AILWS. However, no matter how advanced the cognitive capacity of an AI software, it will not be possible to resort to the personal responsibility of this kind of system since it has no legal personality at all. In such a case, responsibility will remain with the actors who design, produce, and use the system. Last but not least, since no AILWS software does have specific codes of conduct that can make legal and ethical reasonings for today, at the end of the study it was recommended that states and non-governmental organizations together with manifacturers should constitute the necessary ethical rules written in software programs to prevent these systems from unlawful acts and to develop mechanisms that would restrain AI from working outside human control. © 2021 The Authors","2-s2.0-85112789421"
"Urban Davis J.; Anderson F.; Stroetzel M.; Grossman T.; Fitzmaurice G.","Urban Davis, Josh (57204728681); Anderson, Fraser (26030893800); Stroetzel, Merten (57225074135); Grossman, Tovi (7003520062); Fitzmaurice, George (7005241818)","57204728681; 26030893800; 57225074135; 7003520062; 7005241818","Designing Co-Creative AI for Virtual Environments","2021","ACM International Conference Proceeding Series","","","3465260","","","","10.1145/3450741.3465260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109090525&doi=10.1145%2f3450741.3465260&partnerID=40&md5=8bf340fb83e1967c780ceab22d39d6ad","Co-creative AI tools provide a method of creative collaboration between a user and machine. One form of co-creative AI called generative design requires the user to input design parameters and wait substantial periods of time while the system computes design solutions. We explore this interaction dynamic by providing an embodied experience in VR. Calliope is a virtual reality (VR) system that enables users to explore and manipulate generative design solutions in real time. Calliope accounts for the typical idle times in the generative design process by using a virtual environment to encourage parallelized and embodied data-exploration and synthesis, while maintaining a tight human-in-The-loop collaboration with the underlying algorithms. In this paper we discuss design considerations informed by formative studies with generative designers and artists and provide design guidelines to aid others in the development of co-creative AI systems in virtual environments.  © 2021 ACM.","2-s2.0-85109090525"
"Avina-Bravo E.G.; Cassirame J.; Escriba C.; Acco P.; Fourniols J.-Y.; Soto-Romero G.","Avina-Bravo, Eli Gabriel (57220175216); Cassirame, Johan (21933498200); Escriba, Christophe (24536964600); Acco, Pascal (6507666899); Fourniols, Jean-Yves (6603247239); Soto-Romero, Georges (16176786900)","57220175216; 21933498200; 24536964600; 6507666899; 6603247239; 16176786900","Smart Electrically Assisted Bicycles as Health Monitoring Systems: A Review","2022","Sensors","22","2","468","","","","10.3390/s22020468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122383129&doi=10.3390%2fs22020468&partnerID=40&md5=9c693c84845838456d50760fff1f9858","This paper aims to provide a review of the electrically assisted bicycles (also known as e-bikes) used for recovery of the rider’s physical and physiological information, monitoring of their health state, and adjusting the “medical” assistance accordingly. E-bikes have proven to be an excellent way to do physical activity while commuting, thus improving the user’s health and reducing air pollutant emissions. Such devices can also be seen as the first step to help unhealthy sedentary people to start exercising with reduced strain. Based on this analysis, the need to have e-bikes with artificial intelligence (AI) systems that recover and processe a large amount of data is discussed in depth. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines were used to complete the relevant papers’ search and selection in this systematic review. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85122383129"
"Tutul A.A.; Nirjhar E.H.; Chaspari T.","Tutul, Abdullah Aman (57221598740); Nirjhar, Ehsanul Haque (57207912830); Chaspari, Theodora (55351228300)","57221598740; 57207912830; 55351228300","Investigating Trust in Human-Machine Learning Collaboration: A Pilot Study on Estimating Public Anxiety from Speech","2021","ICMI 2021 - Proceedings of the 2021 International Conference on Multimodal Interaction","","","","288","296","8","10.1145/3462244.3479926","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118976660&doi=10.1145%2f3462244.3479926&partnerID=40&md5=b574d97c2f21c3eb92d69a3969f22385","Trust is a key element in the development of effective collaborative relationships between humans and increasingly complex artificial intelligence (AI) systems. Here, we examine trust in AI in the context of a human-AI partnership that involves a joint decision making task for estimating levels of public speaking anxiety based on speech signals. The AI system is comprised of an explainable machine learning (ML) algorithm, that takes acoustic characteristics as input and outputs the estimate of public speaking anxiety levels, a local explanation about the most important features that contributed to the decision of each speech sample, and a global explanation about the most important features for the data overall. We analyze interactions between AI and human annotators with background in psychological sciences, and measure trust over time via the annotators' agreement with the AI model and the annotators' self-reports. We further examine factors of trust that are related to the characteristics of the human annotator and the ML algorithm. Results indicate that trust in AI depends on the openness level of the annotator and the importance level of input features. Findings from this study can provide guidelines to designing solutions that properly calibrate human trust in AI in collaborative human-AI tasks. © 2021 ACM.","2-s2.0-85118976660"
"Foidl H.; Felderer M.; Ramler R.","Foidl, Harald (57188978973); Felderer, Michael (24832720900); Ramler, Rudolf (23095597800)","57188978973; 24832720900; 23095597800","Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems","2022","Proceedings - 1st International Conference on AI Engineering - Software Engineering for AI, CAIN 2022","","","","229","239","10","10.1145/3522664.3528590","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133411277&doi=10.1145%2f3522664.3528590&partnerID=40&md5=4ccc26a1a57379126b4d3150b1f12927","High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.  © 2022 ACM.","2-s2.0-85133411277"
"Larsen B.C.","Larsen, Benjamin Cedric (57226711074)","57226711074","A Framework for Understanding AI-Induced Field Change: How AI Technologies are Legitimized and Institutionalized","2021","AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society","","","","683","694","11","10.1145/3461702.3462591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112459231&doi=10.1145%2f3461702.3462591&partnerID=40&md5=a8f9fd2c2cba1ee5ace8f6396b9e0d71","Artificial intelligence (AI) systems operate in increasingly diverse areas, from healthcare to facial recognition, the stock market, autonomous vehicles, and so on. While the underlying digital infrastructure of AI systems is developing rapidly, each area of implementation is subject to different degrees and processes of legitimization. By combining elements from institutional theory and information systems-theory, this paper presents a conceptual framework to analyze and understand AI-induced field-change. The introduction of novel AI-agents into new or existing fields creates a dynamic in which algorithms (re)shape organizations and institutions while existing institutional infrastructures determine the scope and speed at which organizational change is allowed to occur. Where institutional infrastructure and governance arrangements, such as standards, rules, and regulations, still are unelaborate, the field can move fast but is also more likely to be contested. The institutional infrastructure surrounding AI-induced fields is generally little elaborated, which could be an obstacle to the broader institutionalization of AI-systems going forward. © 2021 ACM.","2-s2.0-85112459231"
"Mahmood U.; Shrestha R.; Bates D.D.B.; Mannelli L.; Corrias G.; Erdi Y.E.; Kanan C.","Mahmood, Usman (57193232216); Shrestha, Robik (57214463346); Bates, David D. B. (57208460371); Mannelli, Lorenzo (8915660200); Corrias, Giuseppe (57196402567); Erdi, Yusuf Emre (7004240791); Kanan, Christopher (35185157400)","57193232216; 57214463346; 57208460371; 8915660200; 57196402567; 7004240791; 35185157400","Detecting Spurious Correlations With Sanity Tests for Artificial Intelligence Guided Radiology Systems","2021","Frontiers in Digital Health","3","","671015","","","","10.3389/fdgth.2021.671015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126443147&doi=10.3389%2ffdgth.2021.671015&partnerID=40&md5=ae3d0cc2617c7c6ea508b3eba2d9c896","Artificial intelligence (AI) has been successful at solving numerous problems in machine perception. In radiology, AI systems are rapidly evolving and show progress in guiding treatment decisions, diagnosing, localizing disease on medical images, and improving radiologists' efficiency. A critical component to deploying AI in radiology is to gain confidence in a developed system's efficacy and safety. The current gold standard approach is to conduct an analytical validation of performance on a generalization dataset from one or more institutions, followed by a clinical validation study of the system's efficacy during deployment. Clinical validation studies are time-consuming, and best practices dictate limited re-use of analytical validation data, so it is ideal to know ahead of time if a system is likely to fail analytical or clinical validation. In this paper, we describe a series of sanity tests to identify when a system performs well on development data for the wrong reasons. We illustrate the sanity tests' value by designing a deep learning system to classify pancreatic cancer seen in computed tomography scans. © Copyright © 2021 Mahmood, Shrestha, Bates, Mannelli, Corrias, Erdi and Kanan.","2-s2.0-85126443147"
"Mohseni S.; Zarei N.; Ragan E.D.","Mohseni, Sina (57209223901); Zarei, Niloofar (57191032764); Ragan, Eric D. (26667185300)","57209223901; 57191032764; 26667185300","A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems","2021","ACM Transactions on Interactive Intelligent Systems","11","3-4","24","","","","10.1145/3387166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139251634&doi=10.1145%2f3387166&partnerID=40&md5=f6fa7ed698ff06828e3b45803350e231","The need for interpretable and accountable intelligent systems grows along with the prevalence of artificial intelligence (AI) applications used in everyday life. Explainable AI (XAI) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.  © 2021 Association for Computing Machinery.","2-s2.0-85139251634"
"Planas E.; Martínez S.; Brambilla M.; Cabot J.","Planas, Elena (34771955200); Martínez, Salvador (57197244754); Brambilla, Marco (57226223274); Cabot, Jordi (8963493600)","34771955200; 57197244754; 57226223274; 8963493600","Towards Access Control Models for Conversational User Interfaces","2022","Lecture Notes in Business Information Processing","450","","","310","317","7","10.1007/978-3-031-07475-2_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131304426&doi=10.1007%2f978-3-031-07475-2_21&partnerID=40&md5=2df6f7070118cb4a02a2456f8fc7969d","Conversational User Interfaces (CUIs), such as chatbots, are becoming a common component of many software systems and they are evolving in many directions (including advanced features, often powered by AI-based components). However, less attention has been paid to their security aspects, such as access-control, which may pose a clear risk. In this paper, we apply Model-Driven techniques to define more secure CUIs. In particular, we propose a framework to integrate an Access-Control protocol into the CUI specification and implementation through a set of policy rules described using a Domain-Specific Language (DSL) integrated with the core CUI language. © 2022, Springer Nature Switzerland AG.","2-s2.0-85131304426"
"Liu B.","Liu, Bingjie (57194180819)","57194180819","In AI We Trust? Effects of Agency Locus and Transparency on Uncertainty Reduction in Human-AI Interaction","2021","Journal of Computer-Mediated Communication","26","6","","384","402","18","10.1093/jcmc/zmab013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129128755&doi=10.1093%2fjcmc%2fzmab013&partnerID=40&md5=6b6f7d89e3d5013c17e7e32dc5c53ccc","Artificial intelligence (AI) is increasingly used to make decisions for humans. Unlike traditional AI that is programmed to follow human-made rules, machine-learning AI generates rules from data. These machine-generated rules are often unintelligible to humans. Will users feel more uncertainty about decisions governed by such rules? To what extent does rule transparency reduce uncertainty and increase users' trust? In a 2 × 3 × 2 between-subjects online experiment, 491 participants interacted with a website that was purported to be a decision-making AI system. Three factors of the AI system were manipulated: agency locus (human-made rules vs. machine-learned rules), transparency (no vs. placebic vs. real explanations), and task (detecting fake news vs. assessing personality). Results show that machine-learning AI triggered less social presence, which increased uncertainty and lowered trust. Transparency reduced uncertainty and enhanced trust, but the mechanisms for this effect differed between the two types of AI. © 2021 The Author(s). Published by Oxford University Press on behalf of International Communication Association.","2-s2.0-85129128755"
"Nikitin O.; Lukyanova O.; Kunin A.","Nikitin, Oleg (57192275660); Lukyanova, Olga (57192264783); Kunin, Alex (57223374302)","57192275660; 57192264783; 57223374302","Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks","2021","Neural Networks","143","","","783","797","14","10.1016/j.neunet.2021.08.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114123043&doi=10.1016%2fj.neunet.2021.08.016&partnerID=40&md5=c2ccb6d89da8b7918447870939f075e0","Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. However, most common neural cell models, including biologically plausible, such as Hodgkin–Huxley or Izhikevich, do not possess predictive dynamics on a single-cell level. Moreover, the modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. The present article introduces new mechanics of interconnection between neuron firing rate homeostasis and weight change through STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We show how these cellular dynamics help neurons filter out the intense noise signals to help neurons keep a stable firing rate. We also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems. © 2021 Elsevier Ltd","2-s2.0-85114123043"
"Yan Y.-J.; Cheng N.-L.; Jan C.-I.; Tsai M.-H.; Chiou J.-C.; Ou-Yang M.","Yan, Yung-Jhe (57013796700); Cheng, Nai-Lun (57014340900); Jan, Chia-Ing (7102342203); Tsai, Ming-Hsui (7403551304); Chiou, Jin-Chern (57154888400); Ou-Yang, Mang (57138106000)","57013796700; 57014340900; 7102342203; 7403551304; 57154888400; 57138106000","Band-selection of a portal LED-induced autofluorescence multispectral imager to improve oral cancer detection","2021","Sensors","21","9","3219","","","","10.3390/s21093219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105132927&doi=10.3390%2fs21093219&partnerID=40&md5=b1d7c251058d6b67902796a68109ae70","This aim of this study was to find effective spectral bands for the early detection of oral cancer. The spectral images in different bands were acquired using a self-made portable light-emit-ting diode (LED)-induced autofluorescence multispectral imager equipped with 365 and 405 nm excitation LEDs, emission filters with center wavelengths of 470, 505, 525, 532, 550, 595, 632, 635, and 695 nm, and a color image sensor. The spectral images of 218 healthy points in 62 healthy participants and 218 tumor points in 62 patients were collected in the ex vivo trials at China Medical University Hospital. These ex vivo trials were similar to in vivo because the spectral images of anatomical specimens were immediately acquired after the on-site tumor resection. The spectral images associated with red, blue, and green filters correlated with and without nine emission filters were quantized by four computing method, including summated intensity, the highest number of the intensity level, entropy, and fractional dimension. The combination of four computing methods, two excitation light sources with two intensities, and 30 spectral bands in three experiments formed 264 classifiers. The quantized data in each classifier was divided into two groups: one was the training group optimizing the threshold of the quantized data, and the other was validating group tested under this optimized threshold. The sensitivity, specificity, and accuracy of each classifier were de-rived from these tests. To identify the influential spectral bands based on the area under the region and the testing results, a single-layer network learning process was used. This was compared to conventional rules-based approaches to show its superior and faster performance. Consequently, four emission filters with the center wavelengths of 470, 505, 532, and 550 nm were selected by an AI-based method and verified using a rule-based approach. The sensitivities of six classifiers using these emission filters were more significant than 90%. The average sensitivity of these was about 96.15%, the average specificity was approximately 69.55%, and the average accuracy was about 82.85%. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85105132927"
"Tan R.; Shi Y.; Fan Y.; Zhu W.; Wu T.","Tan, Rumeng (57202986695); Shi, Ying (58594131500); Fan, Yingying (57712523000); Zhu, Wentao (57713548000); Wu, Tong (57214679687)","57202986695; 58594131500; 57712523000; 57713548000; 57214679687","Energy Saving Technologies and Best Practices for 5G Radio Access Network","2022","IEEE Access","10","","","51747","51756","9","10.1109/ACCESS.2022.3174089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130834107&doi=10.1109%2fACCESS.2022.3174089&partnerID=40&md5=00d15977f508bed0900de11e4358e6d9","This article identifies energy-saving potential of the fifth generation (5G) Radio Access Network, and describes main energy-saving principles and technologies. It explores how to use network energy saving technologies, such as carrier shutdown, channel shutdown, and symbol shutdown in 5G network, that have been inherited from 4G. Some enhanced technologies for 5G like equipment deep sleep and symbol aggregation have also been introduced in this article. However, it is far from enough and an innovative energy-saving solution should be considered. To meet the requirements and development of intelligent and self-adaptive energy-saving solution, Artificial Intelligence (AI) and big data analysis are introduced to form a more precise energy-saving strategy based on site-specific traffic and site-related conditions, thus improving the efficiency and reducing the manpower. Finally, two commercial application practices of AI-based energy-saving solution are elaborated. One is the practice of AI-based service awareness energy saving for 4G/5G collaborative networks, the energy benefits can be improved up to 20%; The other practice is the adoption of a new architecture Active Antenna Unit (AAU) with beam pattern optimization, its energy benefits can be promoted by 30%. These two practices could help mobile network operators (MNOs) to achieve the most energy-efficient network with good network performance and lower Operating Expense (OPEX).  © 2013 IEEE.","2-s2.0-85130834107"
"Vakkuri V.; Kemell K.-K.; Abrahamsson P.","Vakkuri, Ville (57203640458); Kemell, Kai-Kristian (57203633786); Abrahamsson, Pekka (7006011356)","57203640458; 57203633786; 7006011356","Technical Briefing: Hands-On Session on the Development of Trustworthy AI Software","2021","Proceedings - International Conference on Software Engineering","","","","332","333","1","10.1109/ICSE-Companion52605.2021.00142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115678849&doi=10.1109%2fICSE-Companion52605.2021.00142&partnerID=40&md5=13f308188dbbbc16424581015b230e44","Following various real-world incidents involving both purely digital and cyber-physical Artificial Intelligence (AI) systems, AI Ethics has become a prominent topic of discussion in both research and practice, accompanied by various calls for trustworthy AI systems. Failures are often costly, and many of them stem from issues that could have been avoided during development. For example, AI ethics issues, such as data privacy are currently highly topical. However, implementing AI ethics in practice remains a challenge for organizations. Various guidelines have been published to aid companies in doing so, but these have not seen widespread adoption and may feel impractical. In this technical briefing, we discuss how to implement AI ethics. We showcase a method developed for this purpose, ECCOLA, which is based on academic research. ECCOLA is intended to make AI ethics more practical for developers in order to make it easier to incorporate into AI development to create trustworthy AI systems. It is a sprint-based and adaptive tool designed for agile development that facilitates reflection within the development team and helps developers make ethics into tangible product backlog items. © 2021 IEEE.","2-s2.0-85115678849"
"Voronova A.V.; Tsareva P.E.","Voronova, Anna V. (57216272217); Tsareva, Polina E. (57216273025)","57216272217; 57216273025","The Problem of Analyzing Data Models in Non-Euclidean Spaces in Artificial Intelligence Systems","2022","Proceedings of the 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2022","","","","493","496","3","10.1109/ElConRus54750.2022.9755848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129512194&doi=10.1109%2fElConRus54750.2022.9755848&partnerID=40&md5=0b36af75d93688f6e9a9da30d1d87c6c","This article provides an overview of the problems of analyzing data models in non-Euclidean spaces in artificial intelligence systems. Both clustering and classification of information as methods of data analysis are widely used in AI systems. When working with Euclidean space, we do not always get the result that is correct for us in one context or another, so we use non-Euclidean spaces, the result of which satisfies us more. When working with these spaces, we face various problems, one of which is the lack of clear rules for measuring the distance, finding the length between points, selecting the right coordinates so that it is easier to straighten the segment and subsequently work with the analyzed information. © 2022 IEEE.","2-s2.0-85129512194"
"Chen Y.-H.; Lai Y.-C.; Lu C.-H.; Huang Y.-C.; Chang S.-C.; Jan P.-T.","Chen, Yen-Hung (56034163900); Lai, Yuan-Cheng (7401512145); Lu, Cho-Hsun (57478871100); Huang, Yu-Ching (57562445500); Chang, Shun-Chieh (57219387487); Jan, Pi-Tzong (55309109500)","56034163900; 7401512145; 57478871100; 57562445500; 57219387487; 55309109500","A Deep Learning Methodology to Detect Trojaned AI-based DDoS Defend Model","2022","2022 8th International Conference on Automation, Robotics and Applications, ICARA 2022","","","","243","246","3","10.1109/ICARA55094.2022.9738571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127606976&doi=10.1109%2fICARA55094.2022.9738571&partnerID=40&md5=ab4d7ce15a17b7e9f006e44f4c067e81","DDoS attack arranges bots to send low-speed traffic to backbone links and paralyze all servers in the target area. DDoS is difficultly defended due to the two research problems (1) indistinguishability of the changing DDoS characteristics and (2) the time series attack pattern, leading that the raising attention of developing varying DDoS defending methodologies. The conventional methods to defend DDoS apply a rules-based methodology that relies on the experience of algorithm designers and cannot reflect the changing attack characteristics of DDoS in a timely manner. Numerous artificial intelligence (AI) methodologies, therefore, are introduced to defend DDoS through end-to-end functionality (Input: network status; Output: defending action) without any manual intervention. However, the AI-based DDoS Defending model often outsources training to a machine-learning-as-a-service (MLaaS) provider because of the scarce training dataset and high hardware requirement. This may cause the model been trained maliciously, which is called the Artificial Intelligence Trojan attack (AI Trojan). AI Trojan means an AI model encounters a malicious training process and then have a good performance on normal data but behaves maliciously with certain data. This study proposes GAN based AI Robustness test algorithm, Deep Learning Attack Generator (DLAG), to verify that the artificial intelligence model has been fully trained to ensure the robustness of the model. DLAG can be divided into five steps: (1) DLAG randomly generates a sample, (2) generates noise that participates in the generation of a confrontation network (DLAG), (3) input the synthetic sample to the testing AI, (4) the test results will be recorded in the test report and fed back to GAN, and (5) a new synthetic sample will be generated again for the next test cycle. The simulation shows that our proposed DLAG can detect that the AI based DDoS/LFA detector is trained by imbalance data. The simulation results also demonstrate the potential and suggested development trait of AI Trojan detection methodology. © 2022 IEEE.","2-s2.0-85127606976"
"La Gatta V.; Moscato V.; Postiglione M.; Sperlì G.","La Gatta, Valerio (57219926632); Moscato, Vincenzo (8300789300); Postiglione, Marco (57219928964); Sperlì, Giancarlo (55510822500)","57219926632; 8300789300; 57219928964; 55510822500","CASTLE: Cluster-aided space transformation for local explanations","2021","Expert Systems with Applications","179","","115045","","","","10.1016/j.eswa.2021.115045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105321243&doi=10.1016%2fj.eswa.2021.115045&partnerID=40&md5=a44529047539082850ad06a8d7f230c9","With Artificial Intelligence becoming part of a rapidly increasing number of industrial applications, more and more requirements about their transparency and trustworthiness are being demanded to AI systems, especially in military, medical and financial domains, where decisions have a huge impact on lives. In this paper, we propose a novel model-agnostic Explainable AI (XAI) technique, named Cluster-aided Space Transformation for Local Explanation (CASTLE), able to provide rule-based explanations based on both the local and global model's workings, i.e. its detailed ”knowledge” in the neighborhood of the target instance and its general knowledge on the training dataset, respectively. The framework has been evaluated on six datasets in terms of temporal efficiency, cluster quality and model significance. Eventually, we asked 36 users to evaluate the explainability of the framework, getting as result an increase of interpretability of 6% with respect to another state-of-the-art technique, named Anchors. © 2021 Elsevier Ltd","2-s2.0-85105321243"
"Jüngling S.; Peraic M.; Zhu C.","Jüngling, Stephan (36882543000); Peraic, Martin (57216894385); Zhu, Cheng (57203114712)","36882543000; 57216894385; 57203114712","Using the Strategy Design Pattern for Hybrid AI System Design","2022","CEUR Workshop Proceedings","3121","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128713363&partnerID=40&md5=45e7d00981a5a7a0572339e9abe84b26","The idea of design patterns originated in the architecture domain, subsequently shaped the standardization and communication of object-oriented system design for IT architectures, and facilitated the description of best practices in business process design. Recently, the idea of design patterns not only stipulated an initial collection and classification of machine learning patterns, but has also been used to structure and document machine learning based systems from a traditional software engineering perspective. We promote the idea of using design patterns as a general means to visualize the design of hybrid AI systems and present how the strategy design pattern in particular can be used for a passenger counting system by switching the implementation strategies from a standard YOLOv5 based object recognition with Deep Sort tracking to a customized head-based YOLOv5 detection in combination with a customized Deep Sort tracking strategy. In our example, the newly presented human head detector and tracker could significantly improve the overall accuracy of passenger counting in dense and crowded situations. Furthermore, we show, how rule-based symbolic decisions can be allocated to an abstractstrategy class, while the sub-symbolic machine learning task is delegated to the most appropriate person- or head-based ConcreteStrategy class during run-time. © 2022 Copyright for this paper by its authors","2-s2.0-85128713363"
"Satheesh Kumar M.; Ben-Othman J.; Srinivasagan K.G.; Umarani P.","Satheesh Kumar, M. (57205229828); Ben-Othman, Jalel (57189042083); Srinivasagan, K.G. (24484966400); Umarani, P. (57491139000)","57205229828; 57189042083; 24484966400; 57491139000","Machine Learning Methods for Enhanced Cyber Security Intrusion Detection System","2022","Lecture Notes in Networks and Systems","289","","","733","754","21","10.1007/978-3-030-87049-2_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126514779&doi=10.1007%2f978-3-030-87049-2_27&partnerID=40&md5=a391e46b932cfce661777490216d2d47","In the ever-changing world of information security, networks had expanded in scale and complexity that integrates wide range of business functions, intrusion threats have increased in occurrence and intelligence. Network administrators and vendors are now moving beyond conventional Intrusion-Detection Systems (IDS), that only identify problems after they have occurred, to a novel, constructive approach termed Artificial Intelligence (AI) based intrusion detection system. Conventional network Intrusion Detection Systems and firewalls are usually preconfigured to spot malicious network attacks. Now-a-days attackers have become profounder and can try evading common detection rules. There are a few targeted areas where Artificial Intelligence will distribute the extreme evolution for Cybersecurity. To design a proactive defence mechanism, the system has to understand the intelligence of threats that are currently targeting the organization. The implementation of Machine Learning (ML) and threat intelligent-based solutions into blend can revolutionize the landscape in cyber security industry against any kinds of network attacks. Machine Learning is an application of AI that uses a system which is capable of learning from experience. Even in the era of extremely large amount of data and cybersecurity skill shortage, ML can aid in solving the most common tasks including regression, prediction, and classification. In this chapter, the origin and evolution of IDS has been described, followed by the classification of IDS. This chapter will provide a truly interactive learning experience to help and prepare the researchers for the challenges in traditional IDS and the contributions of ML in IDS. This comprehensive review briefs the prominent current works, and an outline of the datasets frequently used for evaluation purpose. Moreover, this chapter will also describe the Collaborative Intrusion Detection that enhances the Big Data Security. Finally, it presents the IDS research issues and challenges; and the skills that need to survive and thrive in today’s threat-ridden and target-rich cyber environment. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85126514779"
"Reed N.; Leiman T.; Palade P.; Martens M.; Kester L.","Reed, Nick (36132031400); Leiman, Tania (55790072400); Palade, Paula (57290321400); Martens, Marieke (7102563292); Kester, Leon (6701699324)","36132031400; 55790072400; 57290321400; 7102563292; 6701699324","Ethics of automated vehicles: breaking traffic rules for road safety","2021","Ethics and Information Technology","23","4","","777","789","12","10.1007/s10676-021-09614-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116824375&doi=10.1007%2fs10676-021-09614-x&partnerID=40&md5=f79d707e36725c2e9bc4926f64bf08d1","In this paper, we explore and describe what is needed to allow connected and automated vehicles (CAVs) to break traffic rules in order to minimise road safety risk and to operate with appropriate transparency (according to recommendation 4 in Bonnefon et al., European Commission, 2020). Reviewing current traffic rules with particular reference to two driving situations (speeding and mounting the pavement), we illustrate why current traffic rules are not suitable for CAVs and why making new traffic rules specifically for CAVs would be inappropriate. In defining an alternative approach to achieving safe CAV driving behaviours, we describe the use of ethical goal functions as part of hybrid AI systems, suggesting that functions should be defined by governmental bodies with input from citizens and stakeholders. Ethical goal functions for CAVs would enable developers to optimise driving behaviours for safety under conditions of uncertainty whilst allowing for differentiation of products according to brand values. Such functions can differ between regions according to preferences for safety behaviours within that region and can be updated over time, responding to continual socio-technological feedback loops. We conclude that defining ethical goal functions is an urgent and necessary step from governmental bodies to enable the safe and transparent operation of CAVs and accelerate the reduction in road casualties they promise to achieve. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","2-s2.0-85116824375"
"Satapathy S.K.; Loganathan D.","Satapathy, Santosh Kumar (57216801019); Loganathan, D. (8248761600)","57216801019; 8248761600","Machine Learning Approaches with Automated Sleep Staging System based on Two-Layer Heterogeneous Ensemble Learning Stacking Model","2022","International Journal of Computing and Digital Systems","11","1","","725","742","17","10.12785/ijcds/110159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123518195&doi=10.12785%2fijcds%2f110159&partnerID=40&md5=4a926d3043f5a951426d2d025cc952cb","Sleep is an essential requirement for human health and well-being, but many people face sleep problems. These problems can lead to several neurological and physical disorders and adversely affect the overall quality of life. Artificial intelligence (AI)based methods for automated sleep stage classification is a fundamental approach to evaluating and treating this public health challenge.The main contribution of this research work is to develop an Automated Sleep Staging System based on Two-Layer Heterogeneous Ensemble Learning Stacking Model (ASSS-TL-HELSM) for sleep staging under the American Academy of Sleep Medicine (AASM) sleep scoring rules. The main aim of this model is to enhance sleep staging accuracy, reduce overfitting and handle overdrift. For signal preprocessing, we use two different feature selection techniques, Fisher Score (FS), and ReliefF (ReF). For feature extraction, we obtain a total of 28 features.The proposed model analyzes the sleep behavior of the subject using the seasonal and trend components. Sleep recordings from two different subgroups of Institute of Systems and Robotics University of Coimbra (ISRUC-Sleep) were obtained for our experiments.Compared with recent studies using single-channel electro encephalogram (EEG) signals, our proposed ASSS-TL-HELSM model shows the best sleep staging classification accuracy performance on a five sleep stages classification (SC-5) task. The overall classification accuracy is 97.93%, and 97% for features selected through FS and ReF respectively, with the subgroup-I(SG-I) data; similarly, for the subgroup-III(SG-III) data, the features selected through FS, and ReF show a classification accuracy of 98.16% and 98.78% respectively. The comparisons between the proposed model and the existing model show that the proposed model gives better sleep staging accuracy for the five-sleep state's classification. © 2022 University of Bahrain. All rights reserved.","2-s2.0-85123518195"
"Mehta N.; Born K.; Fine B.","Mehta, Nishila (57196057052); Born, Karen (36923157000); Fine, Benjamin (56106234600)","57196057052; 36923157000; 56106234600","How artificial intelligence can help us ‘Choose Wisely’","2021","Bioelectronic Medicine","7","1","5","","","","10.1186/s42234-021-00066-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142685775&doi=10.1186%2fs42234-021-00066-8&partnerID=40&md5=86a1190ad200c26601153a1b9238651d","The overuse of low value medical tests and treatments drives costs and patient harm. Efforts to address overuse, such as Choosing Wisely campaigns, typically rely on passive implementation strategies- a form of low reliability system change. Embedding guidelines into clinical decision support (CDS) software is a higher leverage approach to provide ordering suggestions through an interface embedded within the clinical workflow. Growth in computing power is increasingly enabling artificial intelligence (AI) to augment such decision making tools. This article offers a roadmap of opportunities for AI-enabled CDS to reduce overuse, which are presented according to a patient’s journey of care. © 2021, The Author(s).","2-s2.0-85142685775"
"Chen B.; Wen M.; Shi Y.; Lin D.; Rajbahadur G.K.; Jiang Z.M.","Chen, Boyuan (57189213914); Wen, Mingzhi (57226720133); Shi, Yong (57456671700); Lin, Dayi (57192114831); Rajbahadur, Gopi Krishnan (57195249851); Jiang, Zhen Ming (57197839751)","57189213914; 57226720133; 57456671700; 57192114831; 57195249851; 57197839751","Towards Training Reproducible Deep Learning Models","2022","Proceedings - International Conference on Software Engineering","2022-May","","","2202","2214","12","10.1145/3510003.3510163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133524626&doi=10.1145%2f3510003.3510163&partnerID=40&md5=f1a7180e8d9783683745ed633f880a9b","Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models. © 2022 ACM.","2-s2.0-85133524626"
"Borghesi A.; Di Modica G.; Bellavista P.; Gowtham V.; Willner A.; Nehls D.; Kintzler F.; Cejka S.; Tisbeni S.R.; Costantini A.; Galletti M.; Antonacci M.; Ahouangonou J.C.","Borghesi, Andrea (56154931300); Di Modica, Giuseppe (57209339075); Bellavista, Paolo (6603925242); Gowtham, Varun (56081112600); Willner, Alexander (36728264300); Nehls, Daniel (37081495700); Kintzler, Florian (6506096184); Cejka, Stephan (57189052641); Tisbeni, Simone Rossi (57212339775); Costantini, Alessandro (8979348400); Galletti, Matteo (57257985600); Antonacci, Marica (56584165600); Ahouangonou, Jean Christian (57258543400)","56154931300; 57209339075; 6603925242; 56081112600; 36728264300; 37081495700; 6506096184; 57189052641; 57212339775; 8979348400; 57257985600; 56584165600; 57258543400","IoTwins: Design and implementation of a platform for the management of digital twins in industrial scenarios","2021","Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021","","","","625","633","8","10.1109/CCGrid51090.2021.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114856329&doi=10.1109%2fCCGrid51090.2021.00075&partnerID=40&md5=28892ec00120005aa243c8acf6649194","With the increase of the volume of data produced by IoT devices, there is a growing demand of applications capable of elaborating data anywhere along the IoT-to-Cloud path (Edge/Fog). In industrial environments, strict real-time constraints require computation to run as close to the data origin as possible (e.g., IoT Gateway or Edge nodes), whilst batch-wise tasks such as Big Data analytics and Machine Learning model training are advised to run on the Cloud, where computing resources are abundant. The H2020 IoTwins project leverages the digital twin concept to implement virtual representation of physical assets (e.g., machine parts, machines, production/control processes) and deliver a software platform that will help enterprises, and in particular SMEs, to build highly innovative, AI-based services that exploit the potential of IoT/Edge/Cloud computing paradigms. In this paper, we discuss the design principles of the IoTwins reference architecture, delving into technical details of its components and offered functionalities, and propose an exemplary software implementation. © 2021 IEEE.","2-s2.0-85114856329"
"Curto G.; Jojoa Acosta M.F.; Comim F.; Garcia-Zapirain B.","Curto, Georgina (57768342900); Jojoa Acosta, Mario Fernando (57192165756); Comim, Flavio (14629987000); Garcia-Zapirain, Begoña (35732954700)","57768342900; 57192165756; 14629987000; 35732954700","Are AI systems biased against the poor? A machine learning analysis using Word2Vec and GloVe embeddings","2022","AI and Society","","","","","","","10.1007/s00146-022-01494-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132983098&doi=10.1007%2fs00146-022-01494-z&partnerID=40&md5=fe707cadd0380212c4594f1036b79a3a","Among the myriad of technical approaches and abstract guidelines proposed to the topic of AI bias, there has been an urgent call to translate the principle of fairness into the operational AI reality with the involvement of social sciences specialists to analyse the context of specific types of bias, since there is not a generalizable solution. This article offers an interdisciplinary contribution to the topic of AI and societal bias, in particular against the poor, providing a conceptual framework of the issue and a tailor-made model from which meaningful data are obtained using Natural Language Processing word vectors in pretrained Google Word2Vec, Twitter and Wikipedia GloVe word embeddings. The results of the study offer the first set of data that evidences the existence of bias against the poor and suggest that Google Word2vec shows a higher degree of bias when the terms are related to beliefs, whereas bias is higher in Twitter GloVe when the terms express behaviour. This article contributes to the body of work on bias, both from and AI and a social sciences perspective, by providing evidence of a transversal aggravating factor for historical types of discrimination. The evidence of bias against the poor also has important consequences in terms of human development, since it often leads to discrimination, which constitutes an obstacle for the effectiveness of poverty reduction policies. © 2022, The Author(s).","2-s2.0-85132983098"
"Plissonneau A.; Trentesaux D.; Ben-Messaoud W.; Bekrar A.","Plissonneau, Antoine (57262606300); Trentesaux, Damien (6601942051); Ben-Messaoud, Wael (56700322100); Bekrar, Abdelghani (23974300900)","57262606300; 6601942051; 56700322100; 23974300900","AI-based speed control models for the autonomous train: A literature review","2021","2021 3rd International Conference on Transportation and Smart Technologies, TST 2021","","","","9","15","6","10.1109/TST52996.2021.00009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115199639&doi=10.1109%2fTST52996.2021.00009&partnerID=40&md5=6908ea993c8fd8134fa46783e13c4d5a","The railway industry recently showed interest in the potential use of AI to render trains autonomous in order to reduce cost and improve security and performance. This paper focuses on the integration of AI into Automatic Train Operation (ATO) systems to control train speed. The objective of this paper is to present and analyze a review of the literature made in that context. The review is done according to a typology based on three axis: The inputs and objectives of the model, the AI method used by authors and last, the validation process. Our review shows that AI based approaches outperform classical approaches and that learning based methods are superior to rule-based systems. Meanwhile, the contributions present incomplete validation processes, difficulties to generalize the proposed AI method and last, a lack of use of perceptual data during decision making. This analysis enables us to draw some prospects relevant to the solving of the listed limitations.  © 2021 IEEE.","2-s2.0-85115199639"
"Barkane I.","Barkane, Irena (57763365100)","57763365100","Questioning the EU proposal for an Artificial Intelligence Act: The need for prohibitions and a stricter approach to biometric surveillance","2022","Information Polity","27","2","","147","162","15","10.3233/IP-211524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132719755&doi=10.3233%2fIP-211524&partnerID=40&md5=ed70336f3ca16e3e871619b9afeb242b","Artificial Intelligence (AI)-based surveillance technologies such as facial recognition, emotion recognition and other biometric technologies have been rapidly introduced by both public and private entities all around the world, raising major concerns about their impact on fundamental rights, the rule of law and democracy. This article questions the efficiency of the European Commission's Proposal for Regulation of Artificial Intelligence, known as the AI Act, in addressing the threats and risks to fundamental rights posed by AI biometric surveillance systems. It argues that in order to meaningfully address risks to fundamental rights the proposed classification of these systems should be reconsidered. Although the draft AI Act acknowledges that some AI practices should be prohibited, the multiple exceptions and loopholes should be closed, and in addition new prohibitions, in particular to emotional recognition and biometric categorisation systems, should be added to counter AI surveillance practices violating fundamental rights. The AI Act should also introduce stronger legal requirements, such as third-party conformity assessment, fundamental rights impact assessment, transparency obligations as well as enhance existing EU data protection law and the rights and remedies available to individuals, thus not missing the unique opportunity to adopt the first legal framework that truly promotes trustworthy AI.  © 2022-The authors. Published by IOS Press.","2-s2.0-85132719755"
"Abirami M.; Saundariya K.; Senthil Kumaran R.; Yamuna I.","Abirami, M. (58576001100); Saundariya, K. (57223920504); Senthil Kumaran, R. (57216893217); Yamuna, I. (57223931810)","58576001100; 57223920504; 57216893217; 57223931810","Contactless Temperature Detection of Multiple People and Detection of Possible Corona Virus Affected Persons Using AI Enabled IR Sensor Camera","2021","2021 International Conference on Wireless Communications, Signal Processing and Networking, WiSPNET 2021","","","9419439","166","170","4","10.1109/WiSPNET51692.2021.9419439","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106472308&doi=10.1109%2fWiSPNET51692.2021.9419439&partnerID=40&md5=a77387253dfdde6e5af189ffd1ceac04","Today our whole world is entangled with the most dreadful disease Corona which is caused by the successor of SARS known as SARS-Cov-2 virus. Coronavirus is the influenza-like respiratory disease causing damage to the respiratory system of the humans through the ACE2 receptors which acts as an entry gate for the virus to enter. The Corona virus was identified in late 2019 in the city of Wuhan, China which later spread to the most of the territories in China. The spread was first identified by the Bluedot which is a Saas service designed to track and detect the spread of infectious disease. When the other countries came to know the severity of the virus they made various steps to prevent the spread of the virus. The initial symptoms of coronavirus are rise in temperature, loss of taste and smell and short breathness. As the entry level check many institutions and offices, checks the body temperature of the people and checks whether the person is wearing a mask or not. To make this process fully automatic without human intervention the use of AI enabled IR camera sensor with the Arduino UNO is made. The detection of temperature can be made possible by the use of the computer leveraging vision techniques which is equipped with the Raspberry-pi camera module. The process is based on the thermal imaging of the person which can detect the elevated temperature of the person and prevents them from entering into the institution or offices thereby the spread due to the possibly affected persons can be avoided thereby the spread can be controlled. The system not only identifies the person with high temperature but also checks whether the person is wearing a mask or not. The real time analysis of the system is the major advantage of the proposed system.  © 2021 IEEE.","2-s2.0-85106472308"
"Elton D.C.","Elton, Daniel C. (26031409000)","26031409000","Applying Deutsch's concept of good explanations to artificial intelligence and neuroscience – An initial exploration","2021","Cognitive Systems Research","67","","","9","17","8","10.1016/j.cogsys.2020.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098939880&doi=10.1016%2fj.cogsys.2020.12.002&partnerID=40&md5=b4ae0a7095bdbc7cbf0eb3b88d04cd24","Artificial intelligence has made great strides since the deep learning revolution, but AI systems remain incapable of learning principles and rules which allow them to extrapolate outside of their training data to new situations. For inspiration we look to the domain of science, where scientists have been able to develop theories which show remarkable ability to extrapolate and sometimes even predict the existence of phenomena which have never been observed before. According to David Deutsch, this type of extrapolation, which he calls “reach”, is due to scientific theories being hard to vary. In this work we investigate Deutsch's hard-to-vary principle and how it relates to more formalized principles in deep learning such as the bias-variance trade-off and Occam's razor. We distinguish internal variability, how much a model/theory can be varied internally while still yielding the same predictions, with external variability, which is how much a model must be varied to predict new, out-of-distribution data. We discuss how to measure internal variability using the notion of the Rashomon set and how to measure external variability using Kolmogorov complexity. We explore what role hard-to-vary explanations play in intelligence by looking at the human brain, the only example of highly general purpose intelligence known. We distinguish two learning systems in the brain – the first operates similar to deep learning and likely underlies most of perception while the second is a more creative system capable of generating hard-to-vary models and explanations of the world. We make contact with Popperian epistemology which suggests that the generation of scientific theories is a not an inductive process but rather an evolutionary process which proceeds through conjecture and refutation. We argue that figuring out how replicate this second system, which is capable of generating hard-to-vary explanations, is a key challenge which needs to be solved in order to realize artificial general intelligence. © 2020 Elsevier B.V.","2-s2.0-85098939880"
"Srinivasan R.; Chander A.","Srinivasan, Ramya (57213029012); Chander, Ajay (57198332405)","57213029012; 57198332405","Biases in AI Systems","2021","Queue","19","2","","45","64","19","10.1145/3466132.3466134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110537565&doi=10.1145%2f3466132.3466134&partnerID=40&md5=a1d1167f44b581a0362e680c7bccd058","This article provides an organization of various kinds of biases that can occur in the AI pipeline starting from dataset creation and problem formulation to data analysis and evaluation. It highlights the challenges associated with the design of bias-mitigation strategies, and it outlines some best practices suggested by researchers. Finally, a set of guidelines is presented that could aid ML developers in identifying potential sources of bias, as well as avoiding the introduction of unwanted biases. The work is meant to serve as an educational resource for ML developers in handling and addressing issues related to bias in AI systems.  © 2021 ACM.","2-s2.0-85110537565"
"Sachan S.; Almaghrabi F.; Yang J.-B.; Xu D.-L.","Sachan, Swati (57212036901); Almaghrabi, Fatima (57212037172); Yang, Jian-Bo (57206004267); Xu, Dong-Ling (8832629200)","57212036901; 57212037172; 57206004267; 8832629200","Evidential reasoning for preprocessing uncertain categorical data for trustworthy decisions: An application on healthcare and finance","2021","Expert Systems with Applications","185","","115597","","","","10.1016/j.eswa.2021.115597","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111606362&doi=10.1016%2fj.eswa.2021.115597&partnerID=40&md5=8091763624ede5c7322ad57dfff29dcc","The uncertainty attributed by discrepant data in AI-enabled decisions is a critical challenge in highly regulated domains such as health care and finance. Ambiguity and incompleteness due to missing values in output and input attributes, respectively, is ubiquitous in these domains. It could have an adverse impact on a certain unrepresented set of people in the training data without a developer's intention to discriminate. The inherently non-numerical nature of categorical attributes than numerical attributes and the presence of incomplete and ambiguous categorical attributes in a dataset increases the uncertainty in decision-making. This paper addresses the challenges in handling categorical attributes as it is not addressed comprehensively in previous research. Three sources of uncertainties in categorical attributes are recognised in this research. The informational uncertainty, unforeseeable uncertainty in the decision task environment, and the uncertainty due to lack of pre-modelling explainability in categorical attributes are addressed in the proposed methodology on maximum likelihood evidential reasoning (MAKER). It can transform and impute incomplete and ambiguous categorical attributes into interpretable numerical features. It utilises a notion of weight and reliability to include subjective expert preference over a piece of evidence and the quality of evidence in a categorical attribute, respectively. The MAKER framework strives to integrate the recognised uncertainties in the transformed input data that allow a model to perceive data limitations during the training regime and acknowledge doubtful predictions by supporting trustworthy pre-modelling and post modelling explainability. The ability to handle uncertainty and its impact on explainability is demonstrated on a real-world healthcare and finance data for different missing data scenarios in three types of AI algorithms: deep-learning, tree-based, and rule-based model. © 2021 Elsevier Ltd","2-s2.0-85111606362"
"Mitrou L.; Janssen M.; Loukis E.","Mitrou, Lilian (12783223800); Janssen, Marijn (16199813000); Loukis, Euripidis (35581752800)","12783223800; 16199813000; 35581752800","Human Control and Discretion in AI-driven Decision-making in Government","2021","ACM International Conference Proceeding Series","","","","10","16","6","10.1145/3494193.3494195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122976069&doi=10.1145%2f3494193.3494195&partnerID=40&md5=8e06abd8160154e401b34da9d56e715b","Traditionally public decision-makers have been given discretion in many of the decisions they have to make in how to comply with legislation and policies. In this way, the context and specific circumstances can be taken into account when making decisions. This enables more acceptable solutions, but at the same time, discretion might result in treating individuals differently. With the advance of AI-based decisions, the role of the decision-makers is changing. The automation might result in fully automated decisions, humans-in-the-loop or AI might only be used as recommender systems in which humans have the discretion to deviate from the suggested decision. The predictability of and the accountability of the decisions might vary in these circumstances, although humans always remain accountable. Hence, there is a need for human-control and the decision-makers should be given sufficient authority to control the system and deal with undesired outcomes. In this direction this paper analyzes the degree of discretion and human control needed in AI-driven decision-making in government. Our analysis is based on the legal requirements set/posed to the administration, by the extensive legal frameworks that have been created for its operation, concerning the rule of law, the fairness-non-discrimination, the justifiability and accountability, and the certainty/predictability.  © 2021 ACM.","2-s2.0-85122976069"
"Poirot V.; Landsiedel O.","Poirot, Valentin (57209585019); Landsiedel, Olaf (8725107000)","57209585019; 8725107000","Dimmer: Self-adaptive network-wide flooding with reinforcement learning","2021","Proceedings - International Conference on Distributed Computing Systems","2021-July","","","293","303","10","10.1109/ICDCS51616.2021.00036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117123025&doi=10.1109%2fICDCS51616.2021.00036&partnerID=40&md5=5524f775b6c0cd295c1bf600c951c955","The last decade saw an emergence of Synchronous Transmissions (ST) as an effective communication paradigm in low-power wireless networks. Numerous ST protocols provide high reliability and energy efficiency in normal wireless conditions, for a large variety of traffic requirements. Recently, with the EWSN dependability competitions, the community pushed ST to harsher and highly-interfered environments, improving upon classical ST protocols through the use of custom rules, hand-tailored parameters, and additional retransmissions. The results are sophisticated protocols, that require prior expert knowledge and extensive testing, often tuned for a specific deployment and envisioned scenario. In this paper, we explore how ST protocols can benefit from self-adaptivity; a self-adaptive ST protocol selects itself its best parameters to (1) tackle external environment dynamics and (2) adapt to its topology over time. We introduce Dimmer as a self-adaptive ST protocol. Dimmer builds on LWB and uses Reinforcement Learning to tune its parameters and match the current properties of the wireless medium. By learning how to behave from an unlabeled dataset, Dimmer adapts to different interference types and patterns, and is able to tackle previously unseen interference. With Dimmer, we explore how to efficiently design AI-based systems for constrained devices, and outline the benefits and downfalls of AI-based low-power networking. We evaluate our protocol on two deployments of resource-constrained nodes achieving 95.8 % reliability against strong, unknown WiFi interference. Our results outperform baselines such as non-adaptive ST protocols (27%) and PID controllers, and show a performance close to hand-crafted and more sophisticated solutions, such as Crystal (99 %).  © 2021 IEEE.","2-s2.0-85117123025"
"Methnani L.; Aler Tubella A.; Dignum V.; Theodorou A.","Methnani, Leila (57311632600); Aler Tubella, Andrea (57195542788); Dignum, Virginia (6603389724); Theodorou, Andreas (57194338709)","57311632600; 57195542788; 6603389724; 57194338709","Let Me Take Over: Variable Autonomy for Meaningful Human Control","2021","Frontiers in Artificial Intelligence","4","","737072","","","","10.3389/frai.2021.737072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117951859&doi=10.3389%2ffrai.2021.737072&partnerID=40&md5=d9f9d77c27d945e21f5602ac7d5ee0ac","As Artificial Intelligence (AI) continues to expand its reach, the demand for human control and the development of AI systems that adhere to our legal, ethical, and social values also grows. Many (international and national) institutions have taken steps in this direction and published guidelines for the development and deployment of responsible AI systems. These guidelines, however, rely heavily on high-level statements that provide no clear criteria for system assessment, making the effective control over systems a challenge. “Human oversight” is one of the requirements being put forward as a means to support human autonomy and agency. In this paper, we argue that human presence alone does not meet this requirement and that such a misconception may limit the use of automation where it can otherwise provide so much benefit across industries. We therefore propose the development of systems with variable autonomy—dynamically adjustable levels of autonomy—as a means of ensuring meaningful human control over an artefact by satisfying all three core values commonly advocated in ethical guidelines: accountability, responsibility, and transparency. © Copyright © 2021 Methnani, Aler Tubella, Dignum and Theodorou.","2-s2.0-85117951859"
"Khullar A.; Panjal P.; Pandey R.; Burnwal A.; Raj P.; Jha A.A.; Hitesh P.; Reddy R.J.; Himanshu H.; Seth A.","Khullar, Aman (57232052500); Panjal, Paramita (57217247983); Pandey, Rachit (57231354600); Burnwal, Abhishek (57232282300); Raj, Prashit (57232969500); Jha, Ankit Akash (57232282400); Hitesh, Priyadarshi (57231354700); Reddy, R Jayanth (57232282500); Himanshu, Himanshu (57492099700); Seth, Aaditeshwar (14632854300)","57232052500; 57217247983; 57231354600; 57232282300; 57232969500; 57232282400; 57231354700; 57232282500; 57492099700; 14632854300","Experiences with the Introduction of AI-based Tools for Moderation Automation of Voice-based Participatory Media Forum","2021","ACM International Conference Proceeding Series","","","","30","39","9","10.1145/3506469.3506473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125849699&doi=10.1145%2f3506469.3506473&partnerID=40&md5=66c8bda92fe7717ffb829f1360a50422","Voice-based discussion forums where users can record audio messages which are then published for other users to listen and comment, are often moderated to ensure that the published audios are of good quality, relevant, and adhere to editorial guidelines of the forum. There is room for the introduction of AI-based tools in the moderation process, such as to identify and filter out blank or noisy audios, use speech recognition to transcribe the voice messages in text, and use natural language processing techniques to extract relevant metadata from the audio transcripts. We design such tools and deploy them within a social enterprise working in India that runs several voice-based discussion forums. We present our findings in terms of the time and cost-savings made through the introduction of these tools, and describe the feedback of the moderators towards the acceptability of AI-based automation in their workflow. Our work forms a case-study in the use of AI for automation of several routine tasks, and can be especially relevant for other researchers and practitioners involved with the use of voice-based technologies in developing regions of the world. © 2021 ACM.","2-s2.0-85125849699"
"Shaikh T.A.; Mir W.A.; Sofi S.","Shaikh, Tawseef Ayoub (57193888269); Mir, Waseem Ahmad (57224619085); Sofi, Shabir (55170500000)","57193888269; 57224619085; 55170500000","Decrypting the Black Boxing of Artificial Intelligence Using Explainable Artificial Intelligence in Smart Healthcare","2022","Studies in Computational Intelligence","1021","","","53","82","29","10.1007/978-3-030-97929-4_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132661670&doi=10.1007%2f978-3-030-97929-4_3&partnerID=40&md5=810c460c01baca4e4064d7cb45468755","Artificial Intelligence (AI) is creating a revolution in the healthcare industry with its recent developments in organized and amorphous data and quick progress in analytic techniques. The usefulness of AI in healthcare is being recognised at the same time as people begin to be concerned with the possible lack of explainability and bias in the models created. This explains the concept of explainable artificial intelligence (XAI), which increases the faith held in a system, thus leading to more widespread use of AI in healthcare. In this chapter, we offer diverse ways of viewing the XAI concepts, understandability and interpretability of explainable AI systems, mainly focussing on the healthcare domain. The intention is to educate healthcare providers on the understandability and interpretability of explainable AI systems. The medical model is the root cause of life, and we should be assured adequate to treat the patient according to its rules. This chapter uses AI explainability as a way to help build trustworthiness in the medical domain and takes a look at the recent developments in the area of explainable AI which encourages creativity, and at times are necessities in practice to raise awareness. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85132661670"
"Adrian A.; Kohlhase M.; Rapp M.","Adrian, Axel (57219183937); Kohlhase, Michael (55885173500); Rapp, Max (57189630048)","57219183937; 55885173500; 57189630048","A novel understanding of legal syllogism as a starting point for better legal symbolic AI systems","2021","Jusletter IT","","May","","169","178","9","10.38023/1945d5d5-b8fe-40b6-b05c-00e55cfb8bad","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111521516&doi=10.38023%2f1945d5d5-b8fe-40b6-b05c-00e55cfb8bad&partnerID=40&md5=c12a76618efbd5d002b89090448091cd","In the two most relevant categories of legal systems, the codified law systems and the case law systems, legal argumentation and legal reasoning are at the heart of legal theory and practice. Here we show that the concept of legal syllogism can be used as a starting point in both legal systems for new computational models of legal reasoning. We argue that legal syllogisms are not merely analytic logical inference rules but involve ampliative analogical inference. We aim to operationalize our account in terms of Context Graphs, i.e. internally consistent logical theories linked through rigorously defined analogical relations called views and argumentative relations such as attack and support. © 2021 Editions Weblaw. All rights reserved.","2-s2.0-85111521516"
"Sholla S.; Mir R.N.; Chishti M.A.","Sholla, Sahil (57194552064); Mir, Roohie Naaz (55532452500); Chishti, Mohammad Ahsan (26325249300)","57194552064; 55532452500; 26325249300","A fuzzy logic-based method for incorporating ethics in the internet of things","2021","International Journal of Ambient Computing and Intelligence","12","3","","98","122","24","10.4018/IJACI.2021070105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106929047&doi=10.4018%2fIJACI.2021070105&partnerID=40&md5=e4c4547c99f7bd0b1f80dac5b3e6fb9b","IoT is expected to have far-reaching consequences on society due to a wide spectrum of applications like smart healthcare, smart transportation, smart agriculture, smart home, etc. However, ethical considerations of AI-enabled smart devices have not been duly considered from a design perspective. In this paper, the authors propose a novel fuzzy logic-based method to incorporate ethics within smart things of IoT. Ethical considerations relevant to a machine context are represented in terms of fuzzy ethics variables (FEVs) and ethics rules. For each ethics rule, a value called scaled ethics value (SEV) is used to indicate its ethical desirability. In order to model flexibility in ethical response, the authors employ the concept of ethics modes that selectively allow scenarios depending on the value of SEV. The method offers a viable mechanism for smart devices to imbue ethical sensitivity that can pave the way for a technology society amenable to human ethics. However, the method does not account for varying ethics, as such incorporating learning mechanisms represent a promising research direction. Copyright © 2021, IGI Global.","2-s2.0-85106929047"
"McEwan C.; Thielscher M.","McEwan, Cameron (57552485000); Thielscher, Michael (6701317963)","57552485000; 6701317963","Knowledge Transfer for Deep Reinforcement Agents in General Game Playing","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13151 LNAI","","","53","66","13","10.1007/978-3-030-97546-3_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127134596&doi=10.1007%2f978-3-030-97546-3_5&partnerID=40&md5=293323bff104fe2618f33ab767364206","Learning to master new games with nothing but the rules given is a hallmark of human intelligence. This ability has recently been successfully replicated in AI systems through a combination of Knowledge Representation, Monte Carlo Tree Search and Deep Reinforcement Learning: Generalised AlphaZero [7] provides a method for building general game-playing agents that can learn any game describable in a formal specification language. We investigate how to boost the ability of deep reinforcement agents for general game playing by applying transfer learning for new game variants. Experiments show that transfer learning can significantly reduce the training time on variations of games that were previously learned, and our results further suggest that the most successful method is to train a source network that uses the guidance of multiple expert networks. © 2022, Springer Nature Switzerland AG.","2-s2.0-85127134596"
"Jussupow E.; Spohrer K.; Heinzl A.; Gawlitza J.","Jussupow, Ekaterina (57202584397); Spohrer, Kai (36835530200); Heinzl, Armin (6603170209); Gawlitza, Joshua (57189056020)","57202584397; 36835530200; 6603170209; 57189056020","Augmenting medical diagnosis decisions? An investigation into physicians' decision-making process with artificial intelligence","2021","Information Systems Research","32","3","","713","735","22","10.1287/ISRE.2020.0980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114614146&doi=10.1287%2fISRE.2020.0980&partnerID=40&md5=cc197d49b41538ec8aa9db3013929737","Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Much research currently aims to improve AI technologies and debates their societal implications. Surprisingly little effort is spent on understanding the cognitive challenges of decision augmentation with AI-based systems although these systems make it more difficult for decision makers to evaluate the correctness of system advice and to decide whether to reject or accept it. As little is known about the cognitive mechanisms that underlie such evaluations, we take an inductive approach to understand how AI advice influences physicians' decision-making process. We conducted experiments with a total of 68 novice and 12 experienced physicians who diagnosed patient cases with an AI-based system that provided both correct and incorrect advice. Based on qualitative data from think-aloud protocols, interviews, and questionnaires, we elicit five decision-making patterns and develop a process model of medical diagnosis decision augmentation with AI advice. We show that physicians use second-order cognitive processes, namely metacognitions, to monitor and control their reasoning while assessing AI advice. These metacognitions determine whether physicians are able to reap the full benefits of AI or not. Specifically, wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers' own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial information search. Our findings provide a first perspective on the metacognitive mechanisms that decision makers use to evaluate system advice. Overall, our study sheds light on an overlooked facet of decision augmentation with AI, namely, the crucial role of human actors in compensating for technological errors. Copyright: © 2021 INFORMS","2-s2.0-85114614146"
"Zhou L.; Yu H.; Lan Y.; Xing M.","Zhou, Lifan (36611093000); Yu, Hanwen (36723007000); Lan, Yang (57189307939); Xing, Mengdao (7005922869)","36611093000; 36723007000; 57189307939; 7005922869","Artificial Intelligence in Interferometric Synthetic Aperture Radar Phase Unwrapping: A Review","2021","IEEE Geoscience and Remote Sensing Magazine","9","2","9410354","10","28","18","10.1109/MGRS.2021.3065811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104658160&doi=10.1109%2fMGRS.2021.3065811&partnerID=40&md5=a02c8417cb2916b945543429979175d0","Interferometric synthetic aperture radar (InSAR) is a radar technique widely used in geodesy and remote sensing applications, e.g., topography reconstruction and subsidence estimation. Phase unwrapping (PU) is one of the key procedures of InSAR signal processing. Artificial intelligence (AI) techniques have proven to be potentially powerful in many fields and have been introduced into the PU domain, achieving superior performance. In this article, we provide a comprehensive overview of AI-based PU techniques in InSAR. We survey the AI-based single-baseline (SB) PU methods and then review the AI techniques related to multibaseline (MB) PU. In addition, we show several experimental examples of these methods, from both simulated and real InSAR data sets, which gives readers an overview of AI-based PU processing's potential and limitations. It is our hope that this article will provide researchers with guidelines and inspiration to further enhance the development of AI-based PU.  © 2013 IEEE.","2-s2.0-85104658160"
"Ehsan U.; Wintersberger P.; Liao Q.V.; Mara M.; Streit M.; Wachter S.; Riener A.; Riedl M.O.","Ehsan, Upol (57195223484); Wintersberger, Philipp (55485458100); Liao, Q. Vera (36095944800); Mara, Martina (55145156100); Streit, Marc (14039302500); Wachter, Sandra (57193720955); Riener, Andreas (23012938100); Riedl, Mark O. (7004421643)","57195223484; 55485458100; 36095944800; 55145156100; 14039302500; 57193720955; 23012938100; 7004421643","Operationalizing Human-Centered Perspectives in Explainable AI","2021","Conference on Human Factors in Computing Systems - Proceedings","","","","","","","10.1145/3411763.3441342","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105803279&doi=10.1145%2f3411763.3441342&partnerID=40&md5=e41ca57fde9fe93f5f9919d289225a73","The realm of Artificial Intelligence (AI)'s impact on our lives is far reaching - with AI systems proliferating high-stakes domains such as healthcare, finance, mobility, law, etc., these systems must be able to explain their decision to diverse end-users comprehensibly. Yet the discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. There is a need to chart the domain and shape the discourse of XAI with reflective discussions from diverse stakeholders. The goal of this workshop is to examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on ""operationalizing"", aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI. © 2021 Owner/Author.","2-s2.0-85105803279"
"Kim J.-S.; Yi C.-Y.; Park Y.-J.","Kim, Joon-Soo (57195320213); Yi, Chang-Yong (36614886300); Park, Young-Jun (57191258386)","57195320213; 36614886300; 57191258386","Image processing and qr code application method for construction safety management","2021","Applied Sciences (Switzerland)","11","10","4400","","","","10.3390/app11104400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106685608&doi=10.3390%2fapp11104400&partnerID=40&md5=df073380b4a5ff6a0393d9f8ec6fb2ff","Construction safety accidents occur due to a combination of factors. Even a minor accident that could have been treated as a simple injury can lead to a serious accident or death, depending on when and where it occurred. Currently, methods for tracking worker behavior to manage such construction safety accidents are being studied. However, applying the methods to the construction site, various additional elements (e.g., sensors, transmitters, wearing equipment, and control systems) that must be additionally installed and managed are required. The cost of installation and management of these factors increases in proportion to the size of the site and the number of targets to be managed. In addition, the application of new equipment and new rules lowers the work efficiency of workers. In this paper, the following contents are described: (1) system overview, (2) image processing-QR code-based safety management target recognition methodology, and (3) object location discrimination technique applying the geometric transformation. Finally, the proposed methodology was tested to confirm the operation in the field, and the experimental results and conclusions were described in the paper. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85106685608"
"Quaranta L.","Quaranta, Luigi (57211035024)","57211035024","Assessing the Quality of Computational Notebooks for a Frictionless Transition from Exploration to Production","2022","Proceedings - International Conference on Software Engineering","","","","256","260","4","10.1109/ICSE-Companion55297.2022.9793798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132395661&doi=10.1109%2fICSE-Companion55297.2022.9793798&partnerID=40&md5=8340ae7a93b28121554e6125d6f393e4","The massive trend of integrating data-driven AI capabilities into traditional software systems is rising new intriguing challenges. One of such challenges is achieving a smooth transition from the explorative phase of Machine Learning projects - in which data scientists build prototypical models in the lab - to their production phase - in which software engineers translate prototypes into production-ready AI components. To narrow down the gap between these two phases, tools and practices adopted by data scientists might be improved by incorporating consolidated software engineering solutions. In particular, computational notebooks have a prominent role in determining the quality of data science prototypes. In my research project, I address this challenge by studying the best practices for collaboration with computational notebooks and proposing proof-of-concept tools to foster guidelines compliance.CCS CONCEPTS • Software and its engineering; • Computing methodologies → Machine learning; © 2022 IEEE.","2-s2.0-85132395661"
"Said B.; Sadovykh A.; Brosse E.; Bagnato A.","Said, Bilal (57210786324); Sadovykh, Andrey (24479058100); Brosse, Etienne (56989268300); Bagnato, Alessandra (36052505500)","57210786324; 24479058100; 56989268300; 36052505500","Towards AIDOaRt Objectives via Joint Model-based Architectural Effort","2022","CEUR Workshop Proceedings","3144","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131226947&partnerID=40&md5=79578a689e47ab0a1b0fedf9a731d5d6","This paper outlines the AIDOaRt project (AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development in Cyber-Physical Systems) objectives, the status, and current achievements. In particular we briefly outline one of its notable results so far, a model-based requirements engineering process that the project adopted to cope with the challenges of producing coherent joint technical results based on contributions of 32 partners. We shortly overview the process and give reference to the complete process that has been already applied and evaluated in several European Research projects. That way we intend to share the best practices in reaching ambitious objectives as targeted by the European research agenda. The project has received funding by the European Union KDT JU Key Digital Technologies Joint Undertaking, and it began in April 2021 for a period of 36 months. The Research Challenges in Information Science conference topics covered by the paper are the following: Information Systems Transformations, Model-Driven Engineering, User-Centered Design, Method Engineering.  © 2021 The Authors.","2-s2.0-85131226947"
"Kane A.","Kane, Angela (58343488000)","58343488000","Regulating AI: Considerations that apply across domains","2021","Robotics, AI, and Humanity: Science, Ethics, and Policy","","","","251","259","8","10.1007/978-3-030-54173-6_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148812741&doi=10.1007%2f978-3-030-54173-6_21&partnerID=40&md5=725c09659393134cb77e312d8742b54a","Awareness that AI-based technologies have far outpaced the existing regulatory frameworks have raised challenging questions about how to set limits on the most dangerous developments (lethal autonomous weapons or surveillance bots, for instance). Under the assumption that the robotics industry cannot be relied on to regulate itself, calls for government intervention within the regulatory space-national and international-have multiplied. The various approaches to regulating AI fall into two main categories. A sectoral approach looks to identify the societal risks posed by individual technologies, so that preventive or mitigating strategies can be implemented, on the assumption that the rules applicable to AI, in say the financial industry, would be very different from those relevant to heath care providers. A cross-sectoral approach, by contrast, involves the formulation of rules (whether norms adopted by industrial consensus or laws set down by governmental authority) that, as the name implies, would have application to AI-based technologies in their generality. After surveying some domestic and international initiatives that typify the two approaches, the chapter concludes with a list of 15 recommendations to guide reflection on the promotion of societally beneficial AI. © The Author(s) 2021. All rights reserved.","2-s2.0-85148812741"
"Camilli M.; Felderer M.; Giusti A.; Matt D.T.; Perini A.; Russo B.; Susi A.","Camilli, Matteo (55320192900); Felderer, Michael (24832720900); Giusti, Andrea (57117439400); Matt, Dominik T. (23974953600); Perini, Anna (7003847681); Russo, Barbara (9335579000); Susi, Angelo (9038664800)","55320192900; 24832720900; 57117439400; 23974953600; 7003847681; 9335579000; 9038664800","Towards risk modeling for collaborative AI","2021","Proceedings - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI, WAIN 2021","","","9474409","51","54","3","10.1109/WAIN52551.2021.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113243583&doi=10.1109%2fWAIN52551.2021.00014&partnerID=40&md5=85b9b702bd1848f784eaf37b60f88954","Collaborative AI systems aim at working together with humans in a shared space to achieve a common goal. This setting imposes potentially hazardous circumstances due to contacts that could harm human beings. Thus, building such systems with strong assurances of compliance with requirements domain specific standards and regulations is of greatest importance. Challenges associated with the achievement of this goal become even more severe when such systems rely on machine learning components rather than such as top-down rule-based AI. In this paper, we introduce a risk modeling approach tailored to Collaborative AI systems. The risk model includes goals, risk events and domain specific indicators that potentially expose humans to hazards. The risk model is then leveraged to drive assurance methods that feed in turn the risk model through insights extracted from run-time evidence. Our envisioned approach is described by means of a running example in the domain of Industry 4.0, where a robotic arm endowed with a visual perception component, implemented with machine learning, collaborates with a human operator for a production-relevant task.  © 2021 IEEE.","2-s2.0-85113243583"
"Lu Y.; Li S.; Gao Y.; Dai Y.; Feng B.; Han F.; Han J.; He J.; Li X.; Lin G.; Liu Q.; Wang G.; Wang Q.; Wang Z.; Wang Z.; Wu A.; Wu B.; Yang Y.; Yao H.; Zhang W.; Zhou J.; Hao A.; Zhang Z.","Lu, Yun (36196906200); Li, Shuai (35107382000); Gao, Yuan (56805510200); Dai, Yong (34975271300); Feng, Bo (57204267458); Han, Fanghai (7202398099); Han, Jiagang (57199890657); He, Jingjing (57224364417); Li, Xinxiang (24577149400); Lin, Guole (15056407500); Liu, Qian (56822476500); Wang, Guiying (56287694800); Wang, Quan (55797205800); Wang, Zhenning (7410050908); Wang, Zheng (56182894800); Wu, Aiwen (48161853100); Wu, Bin (56648633200); Yang, Yingchi (23135775000); Yao, Hongwei (35072066800); Zhang, Wei (58845409000); Zhou, Jianping (57191734786); Hao, Aimin (36445833300); Zhang, Zhongtao (57780295400)","36196906200; 35107382000; 56805510200; 34975271300; 57204267458; 7202398099; 57199890657; 57224364417; 24577149400; 15056407500; 56822476500; 56287694800; 55797205800; 7410050908; 56182894800; 48161853100; 56648633200; 23135775000; 35072066800; 58845409000; 57191734786; 36445833300; 57780295400","Chinese guidelines for the application of colon cancer staging recognition systems based on artificial intelligence platforms (2021)","2021","Intelligent Medicine","1","1","","37","42","5","10.1016/j.imed.2021.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134457259&doi=10.1016%2fj.imed.2021.03.002&partnerID=40&md5=1862de1a69b7bcc0496ac39ae8337431","The incidence and mortality of colon cancer in China are increasing each year. At present, treatment selection for colon cancer patients mainly depends on imaging results, which require a large number of radiologists to interpret. In China, there is a shortage and uneven distribution of experienced radiologists, which leads to delays and bias in the evaluation of imaging data. Based on these considerations, the Colorectal Surgery Group of the Surgery Branch of the Chinese Medical Association in collaboration with experts at Beihang University has independently developed an artificial intelligence (AI)-based recognition system for the preoperative determination of colon cancer stage to partially replace the work of and relieve the pressure on radiologists. These guidelines aim to standardize the use of AI-based recognition systems in the preoperative staging of colon cancer and guide their clinical application. © 2021","2-s2.0-85134457259"
"Dev S.; Sameki M.; Dhamala J.; Hsieh C.-J.","Dev, Sunipa (57214691205); Sameki, Mehrnoosh (55515620900); Dhamala, Jwala (57192068111); Hsieh, Cho-Jui (24502954900)","57214691205; 55515620900; 57192068111; 24502954900","Measures and Best Practices for Responsible AI","2021","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","4118","","","10.1145/3447548.3469458","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114953604&doi=10.1145%2f3447548.3469458&partnerID=40&md5=ea9fe802d9de704f72e9e5165e4934d5","The use of machine learning (ML) based systems has become ubiquitous including their usage in critical applications like medicine and assistive technologies. Therefore, it is important to determine the trustworthiness of these ML models and tasks. A key component in this determination is the development of task specific datasets, metrics, and best practices which are able to measure the various aspects of responsible model development and deployment including robustness, interpretability and fairness. Further, datasets are also key when training for a given task, be it coreference resolution in language modeling or facial recognition in computer vision. Imbalances and inadequate representation in datasets can have repercussions of an undesirable nature. Some common examples include how coreference resolution systems in NLU are often not all gender inclusive, discrepancies in the measurement of how robust and trustworthy machine predictions are in domains where the selective labels problem is prevalent, and discriminatory determination of pain or care levels of people belonging to different demographics in health science applications. Development of task specific datasets which do better in this regard is also extremely vital. In this workshop, we invite contributions towards different (i) datasets which help enhance task performance and inclusivity, (ii) measures and metrics which help in determining the trustworthiness of a model/dataset, (iii) assessment or remediation tools for fairer, more transparent, robust, and reliable models, and (iv) case studies describing responsible development and deployment of AI systems across fields such as healthcare, financial services, insurance, etc. The datasets, measures, mitigation techniques, and best practices could focus on different areas including (but not restricted to) the following: Fairness and Bias Robustness Reliability and Safety Interpretability Explainability Ethical AI Causal Inference Counterfactual Example Analysis They could also be focussed on the applications in diverse fields such as industry, finance, healthcare and beyond. Text based datasets can be in languages other than English as well.  © 2021 Owner/Author.","2-s2.0-85114953604"
"Abououf M.; Otrok H.; Mizouni R.; Singh S.; Damiani E.","Abououf, Menatalla (57202135212); Otrok, Hadi (20436645500); Mizouni, Rabeb (8572417600); Singh, Shakti (57191471628); Damiani, Ernesto (57195375517)","57202135212; 20436645500; 8572417600; 57191471628; 57195375517","How Artificial Intelligence and Mobile Crowd Sourcing are Inextricably Intertwined","2021","IEEE Network","35","3","9261959","252","258","6","10.1109/MNET.011.2000516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097157183&doi=10.1109%2fMNET.011.2000516&partnerID=40&md5=e7499b6b3fefae6e21a24793528fe229","Mobile Crowd Sourcing (MCS) has been an enabler in the development of artificial intelligence (AI) in general, and machine learning in particular. From collecting data to giving meaning to the data, there has been considerable work supporting the use of MCS in AI. While successful, current MCS solutions still suffer from limitations such as workers recruitment, data quality, trust, and so on, that can benefit a great deal from AI. However, the integration of AI in MCS is still at a nascent stage, thus opening various opportunities for further research. In this article, we review and discuss the integration of AI in MCS solutions, highlight its research challenges, and suggest means to address them. We also propose a novel architecture for AI-based MCS, where AI techniques are integrated and embedded in the different layers of MCS framework to provide efficient and trusted MCS applications. In particular, a machine learning (ML)-based selection using behaviors of individual workers is proposed, and its efficacy is gauged by analyzing a use-case study. The results show that by implementing a hybrid approach, the efficiency of selection was considerably improved. This article demonstrates a clear overview of AI-based MCS solutions and provide guidelines on applying AI to solve the current challenges and open issues.  © 1986-2012 IEEE.","2-s2.0-85097157183"
"Averkin A.N.; Yarushev S.A.","Averkin, A.N. (57192557075); Yarushev, S.A. (57190259686)","57192557075; 57190259686","Review of Research in the Field of Developing Methods to Extract Rules From Artificial Neural Networks","2021","Journal of Computer and Systems Sciences International","60","6","","966","980","14","10.1134/S1064230721060046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121449439&doi=10.1134%2fS1064230721060046&partnerID=40&md5=7db311c4808b16c1195521caab81270a","Abstract: A large-scale review and analysis of the existing methods and approaches to extract rules from artificial neural networks, including deep learning neural networks, is carried out. A wide range of methods and approaches to extract rules and related approaches to develop explainable artificial intelligence (AI) systems are considered. The taxonomy and several directions in studies of explainable neural networks related to the extraction of rules from neural networks, which allow the user to get an idea of how the neural network uses the input data, and also, using rules, to reveal the hidden relationships of the input data and the results found, are explored. This review focuses on the relationship of the most common rule-based explanation systems in AI with the most powerful machine learning algorithms using neural networks. In addition to rule extraction, other methods of constructing explainable AI systems are considered based on the construction of special modules that interpret each step of changing the neural network’s weights. A comprehensive analysis of the existing research makes it possible to draw conclusions about the appropriateness of using certain approaches. The results of the analysis will allow us to get a detailed picture of the state of research in this area and create our own applications based on neural networks, the results of which can be studied in detail and their reliability evaluated. The development of such systems is necessary for the development of the digital economy in Russia and the creation of applications that allow making responsible and explainable management decisions in critical areas of the national economy. © 2021, Pleiades Publishing, Ltd.","2-s2.0-85121449439"
"Kwon S.; Yu J.; Park S.; Jun J.-A.; Pyo C.-S.","Kwon, Soonhyun (56115728600); Yu, Jaehak (25227980300); Park, Sejin (57191670651); Jun, Jong-Arm (7202753066); Pyo, Cheol-Sig (7003471086)","56115728600; 25227980300; 57191670651; 7202753066; 7003471086","Stroke Medical Ontology for Supporting AI-based Stroke Prediction System using Bio-Signals","2021","International Conference on Ubiquitous and Future Networks, ICUFN","2021-August","","","53","59","6","10.1109/ICUFN49451.2021.9528529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115644849&doi=10.1109%2fICUFN49451.2021.9528529&partnerID=40&md5=eba3c38d4eb4cb9342bb2f4c3338def5","In this paper, we propose a stroke medical ontology that provides medical knowledge to accompany AI-based stroke disease prediction system's results that were arrived at based on EMG information. This system was developed as a result of the limitations mentioned above being encountered in previous studies. We approached the problem from a viewpoint of knowledge engineering with the aim of modeling medical knowledge related to strokes. Using web ontology language (OWL), a standard ontology language, we developed schema-level stroke ontologies with concepts and properties based on the brain's anatomical structures, lesions, and disease related to strokes. Also, we developed an instance-level medical terms ontology that can span standard medical terms such as those in the international classification diseases (ICD), systematized nomenclature of medicine - clinical terms (SNOMED-CT), and foundational model of anatomy (FMA). The above schema ontology and instance ontology are meaningfully mapped to each other to apply layered ontology modeling techniques that separate schemas from instances. Through semantic web rule language (SWRL)-based inference, we predict lesions, diseases, and anatomical brain structural ripple effects based on the patient's current lesions and diseases. The inferred knowledge information is provided via the SPARQL protocol and RDF query language (SPARQL), a standard ontology query language. To verify the stroke medical ontology proposed in this paper, we developed an ontology-based stroke disease prediction system. This system achieved knowledge augmentation performance of 67.82% by comparing the patients' current lesions and diseases with the lesions, diseases, and areas of disability found by SWRL-based inference using actual stroke emergency data from 37 patients.  © 2021 IEEE.","2-s2.0-85115644849"
"Fraga-Lamas P.; Lopes S.I.; Fernández-Caramés T.M.","Fraga-Lamas, Paula (56039568800); Lopes, Sérgio Ivan (23767089100); Fernández-Caramés, Tiago M. (24467756100)","56039568800; 23767089100; 24467756100","Green iot and edge AI as key technological enablers for a sustainable digital transition towards a smart circular economy: An industry 5.0 use case","2021","Sensors","21","17","5745","","","","10.3390/s21175745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113574069&doi=10.3390%2fs21175745&partnerID=40&md5=bc6c1db753bad7dc5477c0a30938eefe","Internet of Things (IoT) can help to pave the way to the circular economy and to a more sustainable world by enabling the digitalization of many operations and processes, such as water distribution, preventive maintenance, or smart manufacturing. Paradoxically, IoT technologies and paradigms such as edge computing, although they have a huge potential for the digital transition towards sustainability, they are not yet contributing to the sustainable development of the IoT sector itself. In fact, such a sector has a significant carbon footprint due to the use of scarce raw materials and its energy consumption in manufacturing, operating, and recycling processes. To tackle these issues, the Green IoT (G-IoT) paradigm has emerged as a research area to reduce such carbon footprint; however, its sustainable vision collides directly with the advent of Edge Artificial Intelligence (Edge AI), which imposes the consumption of additional energy. This article deals with this problem by exploring the different aspects that impact the design and development of Edge-AI G-IoT systems. Moreover, it presents a practical Industry 5.0 use case that illustrates the different concepts analyzed throughout the article. Specifically, the proposed scenario consists in an Industry 5.0 smart workshop that looks for improving operator safety and operation tracking. Such an application case makes use of a mist computing architecture composed of AI-enabled IoT nodes. After describing the application case, it is evaluated its energy consumption and it is analyzed the impact on the carbon footprint that it may have on different countries. Overall, this article provides guidelines that will help future developers to face the challenges that will arise when creating the next generation of Edge-AI G-IoT systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85113574069"
"Firmansyah E.; Pardamean B.; Ginting C.; Mawandha H.G.; Pratama Putra D.; Suparyanto T.","Firmansyah, Erick (57280772500); Pardamean, Bens (55009925500); Ginting, Candra (57280262500); Mawandha, Hangger Gahara (57281601800); Pratama Putra, Dian (57280646300); Suparyanto, Teddy (55869147900)","57280772500; 55009925500; 57280262500; 57281601800; 57280646300; 55869147900","Development of artificial intelligence for variable rate application based oil palm fertilization recommendation system","2021","Proceedings of 2021 International Conference on Information Management and Technology, ICIMTech 2021","","","","116","119","3","10.1109/ICIMTech53080.2021.9535082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116122876&doi=10.1109%2fICIMTech53080.2021.9535082&partnerID=40&md5=0868c3e0e6a8944271dfa74c09d99614","The need for fertilization knowledge that meets good cultivation principles is the background for the need for a platform that can help provide advice on fertilization implementation. The conventional method through leaf and soil analysis to determine the dose of fertilization has many obstacles in its implementation. The availability of experts to provide advice is also not available at all times. One way to transfer knowledge to non-experts is to use Artificial Intelligence (AI) in the form of a dynamic expert system. The purpose of this research is to create a dynamic expert system that can provide advice and apply fertilization quickly, cheaply, accurately, and available at all times. In building this AI system, a knowledge base, working memory, inference engine, and interface are needed. The implementation of dynamic expert system development consists of four stages, namely (1) literature study, (2) laboratory analysis, (3) construction of an inference engine, and (4) interface creation. Based on the literature study that has been carried out, it is known that there are three domains of knowledge of oil palm fertilization, namely the domain of soil, plants and climate. Each of these knowledge domains consists of attributes, sub-attributes, and facts of knowledge which are then arranged in the form of mathematical rules. The relationship between the three knowledge domains is used as the basis for making fertilization rules. The result of this research is an application with Artificial Intelligence to provide information on nutritional needs according to plant age, population, production, land area and location. The application provides recommendations for the type, frequency, amount of fertilizer, and time of application.  © 2021 IEEE.","2-s2.0-85116122876"
"Kühnel K.; Au-Yong-Oliveira M.","Kühnel, Klaus (57698262400); Au-Yong-Oliveira, Manuel (57218856174)","57698262400; 57218856174","Optimal Distribution of Current Resources in a Production Environment - A Sustainable and Ethical Framework for the Digital Era","2022","Lecture Notes in Networks and Systems","470 LNNS","","","609","619","10","10.1007/978-3-031-04829-6_55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130268964&doi=10.1007%2f978-3-031-04829-6_55&partnerID=40&md5=579ceae72cb150a7de6d9a0891d762e9","Digital transformation has been achieved in one application (user interface – related to workplace excellence and the whole company environment) in a large chemical company in Germany. In connection with variable corporate goals such as fluctuating workload, agile responsiveness to customer inquiries, ecological and economic sustainability which require an intelligent and forward-looking management of the company. Hence, a prototype solution has been created to respond to a very dynamic market. Based on Microsoft PowerPoint (ISpring) and with some add-ons pre-selected operators may interact, including with video content. The current architecture of the IT system has already been done. Adjustments will still be made to become more agile and future-driven to follow all of the company business rules. An artificial intelligence (AI)-based methodical analysis and synthesis approach is followed, for human and other resource input calculation, to follow business KPIs (key performance indicators) and other business goals with an algorithm. This evolution or control system is seen as a natural response to a very complex environment where human effort and error must be minimized (through simplification and a mathematical algorithm and a fast loop e.g., every ten minutes KPIs may be re-calculated according to existing capacity due to availability of equipment and human resources). This holistic approach shortens reaction times to market situations and at the same time minimizes non-value-adding processes. The business roles are determined depending on the culture/size of the company and strategic parameters. The continuously available flexibility in product design and the instability of all resources is of significant importance. After initial research it was found that commercial systems do not have this ability to dynamically and agilely automatically adapt to the given optimum. Instead of isolated partial optimizations, the expected results are compared with the real results in a continuous dynamic simulation and readjusted promptly [1]. This algorithm represents the actual added value, which has a high economic but also humanity advantage, especially in the manufacturing industry. In the future most manufacturing enterprises will have to follow this AI and agile path to competitive advantage vis-à-vis Asian competitors. The last quarter of 2021 experienced a 10% productivity improvement due to this implementation, based on the prototype, and mainly due to one product implementation champion (in an area with 270 employees). © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85130268964"
"Vilchis-Medina J.-L.; Godary-Dejean K.; Lesire C.","Vilchis-Medina, Jose-Luis (57205615878); Godary-Dejean, Karen (36801647200); Lesire, Charles (8941481100)","57205615878; 36801647200; 8941481100","Autonomous Decision-Making with Incomplete Information and Safety Rules Based on Non-Monotonic Reasoning","2021","IEEE Robotics and Automation Letters","6","4","9511268","8357","8362","5","10.1109/LRA.2021.3103048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114745365&doi=10.1109%2fLRA.2021.3103048&partnerID=40&md5=903b6f204d6a1cc22f3f87afb6eeb4cb","In this article we propose a decision process integrating Non-Monotonic Reasoning (NMR), embedded in a deliberative architecture. The NMR process uses Default Logic to implement goal reasoning, managing partially observable or incomplete information, allowing the design of default behaviours completed by the handling of specific situations, in order to manage the current mission objective as well as safety rules. We illustrate our approach through an application of an underwater robot performing a marine biology mission. © 2016 IEEE.","2-s2.0-85114745365"
"Antikainen J.; Agbese M.; Alanen H.-K.; Halme E.; Isomaki H.; Jantunen M.; Kemell K.-K.; Rousi R.; Vainio-Pekka H.; Vakkuri V.","Antikainen, Jani (57322091000); Agbese, Mamia (57322330600); Alanen, Hanna-Kaisa (57223426134); Halme, Erika (57222063097); Isomaki, Hannakaisa (8988679300); Jantunen, Marianna (57217089350); Kemell, Kai-Kristian (57203633786); Rousi, Rebekah (55785577500); Vainio-Pekka, Heidi (57321978000); Vakkuri, Ville (57203640458)","57322091000; 57322330600; 57223426134; 57222063097; 8988679300; 57217089350; 57203633786; 55785577500; 57321978000; 57203640458","A Deployment Model to Extend Ethically Aligned AI Implementation Method ECCOLA","2021","Proceedings of the IEEE International Conference on Requirements Engineering","2021-September","","","230","235","5","10.1109/REW53955.2021.00043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118430231&doi=10.1109%2fREW53955.2021.00043&partnerID=40&md5=4f986cf3fdbc6535f139ebff5cfb898f","There is a struggle in Artificial intelligence (AI) ethics to gain ground in actionable methods and models to be utilized by practitioners while developing and implementing ethically sound AI systems. AI ethics is a vague concept without a consensus of definition or theoretical grounding and bearing little connection to practice. Practice involving primarily technical tasks like software development is not aptly equipped to process and decide upon ethical considerations. Efforts to create tools and guidelines to help people working with AI development have been concentrating almost solely on the technical aspects of AI. A few exceptions do apply, such as the ECCOIA method for creating ethically aligned AI -systems. ECCOIA has proven results in terms of increased ethical considerations in AI systems development. Yet, it is a novel innovation, and room for development still exists. This study aims to extend ECCOIA with a deployment model to drive the adoption of ECCOIA, as any method - no matter how good -is of no value without adoption and use. The model includes simple metrics to facilitate the communication of ethical gaps or outcomes of ethical AI development. It offers the opportunity to assess any AI system at any given life-cycle phase, e.g., opening possibilities like analyzing the ethicality of an AI system under acquisition.  © 2021 IEEE.","2-s2.0-85118430231"
"Cheng J.; Luo H.; Lin W.; Hu G.","Cheng, Jianxin (57203433827); Luo, Haoming (57280517100); Lin, Wenyi (56344534400); Hu, Guopeng (57280388800)","57203433827; 57280517100; 56344534400; 57280388800","Pros and Cons of Artificial Intelligence - Lessons from E-Government Services in the COVID-19 Pandemic","2021","Proceedings - 2021 2nd International Conference on Artificial Intelligence and Education, ICAIE 2021","","","","167","173","6","10.1109/ICAIE53562.2021.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116118828&doi=10.1109%2fICAIE53562.2021.00042&partnerID=40&md5=4b909495c937694c3c373f1fbaaa48e2","How to understand the role and impact of information technology and artificial intelligence has triggered a big debate. To explore the pros and cons of artificial intelligence and its applications, this article takes the face mask distribution programs in the COVID-19 pandemic as research objects, conducting a multi-case comparative study of three cities in China. By manual coding of a total of 4560 We Chat official account messages, and by analyzing information related to the distribution process, it was found that: (1) On the demand side, the task complexity, the demand diversity, and the unstructured decision-making process in the public health emergency have exposed some limitations of AI in data collecting and unstructured problem-solving. (2) On the supply side, the procedural and substantive rules designed, together with the reliability of an AI system, will shape the performance of the AI service channel. (3) Though AI and other new technologies are advancing drastically in the pandemic, there is still much room for improvement whether by the optimization of AI systems, or by political control and social participation, and by the supplement of alternative channels such as the community service delivery. © 2021 IEEE.","2-s2.0-85116118828"
"Hatwell J.; Gaber M.M.; Muhammad Atif Azad R.","Hatwell, Julian (57217070625); Gaber, Mohamed Medhat (8927664800); Muhammad Atif Azad, R. (57212536667)","57217070625; 8927664800; 57212536667","Gbt-hips: Explaining the classifications of gradient boosted tree ensembles","2021","Applied Sciences (Switzerland)","11","6","2511","","","","10.3390/app11062511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103049103&doi=10.3390%2fapp11062511&partnerID=40&md5=aafb816af50871fcf30e90bd51d2a98d","This research presents Gradient Boosted Tree High Importance Path Snippets (gbt-HIPS), a novel, heuristic method for explaining gradient boosted tree (GBT) classification models by extracting a single classification rule (CR) from the ensemble of decision trees that make up the GBT model. This CR contains the most statistically important boundary values of the input space as antecedent terms. The CR represents a hyper-rectangle of the input space inside which the GBT model is, very reliably, classifying all instances with the same class label as the explanandum instance. In a benchmark test using nine data sets and five competing state-of-the-art methods, gbt-HIPS offered the best trade-off between coverage (0.16–0.75) and precision (0.85–0.98). Unlike competing methods, gbt-HIPS is also demonstrably guarded against under-and over-fitting. A further distinguishing feature of our method is that, unlike much prior work, our explanations also provide counterfactual detail in accordance with widely accepted recommendations for what makes a good explanation. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85103049103"
"Rak R.","Rak, Richard (57298033800)","57298033800","Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems","2021","ACM International Conference Proceeding Series","","","","481","484","3","10.1145/3494193.3494260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122976759&doi=10.1145%2f3494193.3494260&partnerID=40&md5=83f4bd607b56ea3fb5035aef399e86df","The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.  © 2021 ACM.","2-s2.0-85122976759"
"Amkor A.; Barbri N.E.; Maaider K.","Amkor, Ali (57218712227); Barbri, Noureddine El (16021899700); Maaider, Kamal (55328926300)","57218712227; 16021899700; 55328926300","A comparison between PLSR, SVMR and NARX network for the mint treatment day prediction based on multisensor system","2021","2021 International Conference on Optimization and Applications, ICOA 2021","","","9442652","","","","10.1109/ICOA51614.2021.9442652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107643329&doi=10.1109%2fICOA51614.2021.9442652&partnerID=40&md5=a2913ff7e220657a6e145c43f53d6f78","The ability to distinguish between edible aromatic plants treated with insecticides holds the attention of researchers in view of the toxicity of insecticides in human health. The malathion has a distinctive smell it an insecticide widely used to protect mint crops. In the present paper, three regression and artificial intelligence (AI)-based methods such as partial least squares (PLS) regression, support vector machine (SVM) regression, and the nonlinear autoregressive with exogenous input (NARX) were investigated to predict the mint treatment day with malathion. The data used in this work are collected using a multi-sensor system designed based on commercial gas sensors. In this case, the nonlinear autoregressive with exogenous input (NARX) was found the most effective achieving a correlation coefficient (R) of 0.99 with a very minimal mean squared error (MSE) of about 1.10288e-14. Thanks to the right choice of the appropriate algorithm, the mint treatment day could be predicted with a simple multisensor gas array.  © 2021 IEEE.","2-s2.0-85107643329"
"Ye Y.","Ye, Yanping (57223028755)","57223028755","Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology","2022","Security and Communication Networks","2022","","9913450","","","","10.1155/2022/9913450","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128280924&doi=10.1155%2f2022%2f9913450&partnerID=40&md5=eb51af7c6fbd2fe05999a22adf8d2eee","With the development of the Internet, ""Internet Plus""has been widely used in various fields, and the Internet has become a great opportunity to transform CET. People's demand for education, especially higher education, has also increased rapidly. With the attention and investment of the state in recent years, higher education has developed rapidly, accounting for half of China's higher education. However, the increase in the number of students has brought great pressure to CET. How to improve the teaching efficiency of large classes is an urgent problem to be solved. The development of sci and tech, especially computer, has brought us new hope. Computer-assisted instruction has been introduced into CET. However, there are some unreasonable points in the design of computer-aided marking system in China, which is not suitable for CET. It is very important to research and design a computer-aided marking system that can expand CET methods and maximize the integration of English instructional resources. This paper introduces the principle, characteristics, and application fields of AI; analyzes the problems faced by CET; and puts forward a CET path based on computer-aided technology. © 2022 Yanping Ye.","2-s2.0-85128280924"
"Balasubramaniam N.; Kauppinen M.; Hiekkanen K.; Kujala S.","Balasubramaniam, Nagadivya (57201946113); Kauppinen, Marjo (9044243800); Hiekkanen, Kari (37017103300); Kujala, Sari (55377510200)","57201946113; 9044243800; 37017103300; 55377510200","Transparency and Explainability of AI Systems: Ethical Guidelines in Practice","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13216 LNCS","","","3","18","15","10.1007/978-3-030-98464-9_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127079762&doi=10.1007%2f978-3-030-98464-9_1&partnerID=40&md5=4c5c035b7cd1247ed59dce04b8122472","[Context and Motivation] Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. [Question] The goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems. We analyzed the ethical guidelines in 16 organizations representing different industries and public sector. [Results] In the ethical guidelines, the importance of transparency was highlighted by almost all of the organizations, and explainability was considered as an integral part of transparency. Building trust in AI systems was one of the key reasons for developing transparency and explainability, and customers and users were raised as the main target groups of the explanations. The organizations also mentioned developers, partners, and stakeholders as important groups needing explanations. The ethical guidelines contained the following aspects of the AI system that should be explained: the purpose, role of AI, inputs, behavior, data utilized, outputs, and limitations. The guidelines also pointed out that transparency and explainability relate to several other quality requirements, such as trustworthiness, understandability, traceability, privacy, auditability, and fairness. [Contribution] For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a structured way to define explainability requirements of AI systems. © 2022, Springer Nature Switzerland AG.","2-s2.0-85127079762"
"Saheb T.; Saheb T.; Carpenter D.O.","Saheb, Tahereh (57195776188); Saheb, Tayebeh (58304177400); Carpenter, David O. (7201795413)","57195776188; 58304177400; 7201795413","Mapping research strands of ethics of artificial intelligence in healthcare: A bibliometric and content analysis","2021","Computers in Biology and Medicine","135","","104660","","","","10.1016/j.compbiomed.2021.104660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111534377&doi=10.1016%2fj.compbiomed.2021.104660&partnerID=40&md5=597190d5824b07f7812e31d53e4e72e0","The growth of artificial intelligence in promoting healthcare is rapidly progressing. Notwithstanding its promising nature, however, AI in healthcare embodies certain ethical challenges as well. This research aims to delineate the most influential elements of scientific research on AI ethics in healthcare by conducting bibliometric, social network analysis, and cluster-based content analysis of scientific articles. Not only did the bibliometric analysis identify the most influential authors, countries, institutions, sources, and documents, but it also recognized four ethical concerns associated with 12 medical issues. These ethical categories are composed of normative, meta-ethics, epistemological and medical practice. The content analysis complemented this list of ethical categories and distinguished seven more ethical categories: ethics of relationships, medico-legal concerns, ethics of robots, ethics of ambient intelligence, patients' rights, physicians’ rights, and ethics of predictive analytics. This analysis likewise identified 40 general research gaps in the literature and plausible future research strands. This analysis furthers conversations on the ethics of AI and associated emerging technologies such as nanotech and biotech in healthcare, hence, advances convergence research on the ethics of AI in healthcare. Practically, this research will provide a map for policymakers and AI engineers and scientists on what dimensions of AI-based medical interventions require stricter policies and guidelines and robust ethical design and development. © 2021 Elsevier Ltd","2-s2.0-85111534377"
"Barclay I.; Taylor H.; Preece A.; Taylor I.; Verma D.; de Mel G.","Barclay, Iain (57211075715); Taylor, Harrison (57219421646); Preece, Alun (7004934245); Taylor, Ian (9733768300); Verma, Dinesh (57214983108); de Mel, Geeth (24343692800)","57211075715; 57219421646; 7004934245; 9733768300; 57214983108; 24343692800","A framework for fostering transparency in shared artificial intelligence models by increasing visibility of contributions","2021","Concurrency and Computation: Practice and Experience","33","19","e6129","","","","10.1002/cpe.6129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097032199&doi=10.1002%2fcpe.6129&partnerID=40&md5=35021be6327c7408aa2e08f0431f2531","Increased adoption of artificial intelligence (AI) systems into scientific workflows will result in an increasing technical debt as the distance between the data scientists and engineers who develop AI system components and scientists, researchers and other users grows. This could quickly become problematic, particularly where guidance or regulations change and once-acceptable best practice becomes outdated, or where data sources are later discredited as biased or inaccurate. This paper presents a novel method for deriving a quantifiable metric capable of ranking the overall transparency of the process pipelines used to generate AI systems, such that users, auditors and other stakeholders can gain confidence that they will be able to validate and trust the data sources and contributors in the AI systems that they rely on. The methodology for calculating the metric, and the type of criteria that could be used to make judgements on the visibility of contributions to systems are evaluated through models published at ModelHub and PyTorch Hub, popular archives for sharing science resources, and is found to be helpful in driving consideration of the contributions made to generating AI systems and approaches toward effective documentation and improving transparency in machine learning assets shared within scientific communities. © 2020 John Wiley & Sons, Ltd.","2-s2.0-85097032199"
"Hallamaa J.","Hallamaa, Jaana (6506392571)","6506392571","Improving AI Systems Through Trade-Offs Between Values","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13320 LNCS","","","329","343","14","10.1007/978-3-031-06018-2_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133003405&doi=10.1007%2f978-3-031-06018-2_23&partnerID=40&md5=bc0e2a6d3b135c2bf5118b015a2c9f69","EU regulation mechanisms are typically designed to reinforce European values of human dignity, freedom, equality, democracy, human rights, and rule of law while establishing mechanisms that mobilize products and services and supporting economic and technological development. The EU Machinery Directive 2006 has had a pivotal role in securing the quality and safety of machines and devices on the European common market. This article discusses the points of convergence and divergence of values in light of various EU regulations, particularly in relation to digital products and AI applications. To distinguish the types of value conflicts, the article refers to Erik Hollnagel’s Efficiency-Thoroughness-Trade-Off (ETTO) principle and discusses how a reasonable balance between diverse values could be negotiated in designing AI-integrated devices and services. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85133003405"
"Golbin I.; Rao A.S.; Hadjarian A.; Krittman D.","Golbin, Ilana (57216153602); Rao, Anand S. (57201738578); Hadjarian, Ali (55962605000); Krittman, Daniel (57222726970)","57216153602; 57201738578; 55962605000; 57222726970","Responsible AI: A Primer for the Legal Community","2020","Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020","","","9377738","2121","2126","5","10.1109/BigData50022.2020.9377738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103813833&doi=10.1109%2fBigData50022.2020.9377738&partnerID=40&md5=6251e702b163d661d3923bc684ab04f7","Artificial intelligence (AI) is increasingly being adopted for automation and decision-making tasks across all industries, public sector, and law. Applications range from hiring and credit limit decisions, to loan and healthcare claim approvals, to criminal sentencing, and even the selective provision of information by social media companies to different groups of viewers. The increased adoption of AI, affecting so many aspects of our daily lives, highlights the potential risks around automated decision making and the need for better governance and ethical standards when deploying such systems. In response to that need, governments, states, municipalities, private sector organizations, and industry groups around the world have drafted hundreds, perhaps even thousands at this point - of new, regulatory proposals and guidelines; many already in effect and more on the way. The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility or increasingly commonplace regulatory requirements to confirm they work as intended and are deployed in a responsible manner, lest they run the risk of reputational damage, regulatory fines, and/or legal action. The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems. © 2020 IEEE.","2-s2.0-85103813833"
"Komatsu T.; Lopez M.G.; Makri S.; Porlezza C.; Cooper G.; MacFarlane A.; Missaoui S.","Komatsu, Tomoko (57219864383); Lopez, Marisela Gutierrez (57219870401); Makri, Stephann (16031468000); Porlezza, Colin (55577738500); Cooper, Glenda (57160661400); MacFarlane, Andrew (7102685938); Missaoui, Sondess (23098143400)","57219864383; 57219870401; 16031468000; 55577738500; 57160661400; 7102685938; 23098143400","AI should embody our values: Investigating journalistic values to inform AI technology design","2020","ACM International Conference Proceeding Series","","","","","","","10.1145/3419249.3420105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123041496&doi=10.1145%2f3419249.3420105&partnerID=40&md5=120d784f1a78433ae1fd64108dc589d8","In the current climate of shrinking newsrooms and revenues, journalists face increasing pressures exerted by the industry's for-profit focus and the expectation of intensified output. While AI-enabled journalism has great potential to help alleviate journalists' pressures, it might also disrupt journalistic norms and, at worst, interfere with their duty to inform the public. For AI systems to be as useful as possible, designers should understand journalists' professional values and incorporate them into their designs. We report findings from interviews with journalists to understand their perceptions of how professional values that are important to them (such as truth, impartiality and originality) might be supported and/or undermined by AI technologies. Based on these findings, we provide design insight and guidelines for incorporating values into the design of AI systems. We argue HCI design can achieve the strongest possible value alignment by moving beyond merely supporting important values, to truly embodying them. © 2020 ACM.","2-s2.0-85123041496"
"Bashayreh M.; Sibai F.N.; Tabbara A.","Bashayreh, Mohammad (26643716200); Sibai, Fadi N. (6603450078); Tabbara, Amer (57220179362)","26643716200; 6603450078; 57220179362","Artificial intelligence and legal liability: towards an international approach of proportional liability based on risk sharing","2021","Information and Communications Technology Law","30","2","","169","192","23","10.1080/13600834.2020.1856025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097173847&doi=10.1080%2f13600834.2020.1856025&partnerID=40&md5=879f7604e45c02433d1448270e853034","This paper critically examines the allocation of liability when autonomous artificial intelligence (AI) systems cause accidents. Problems of applying existing principles of legal liability in AI environment are addressed. This paper argues that the sharing of risk as a basis for proportionate liability should be a basis for a new liability regime to govern future autonomous machines. It is argued that this approach favors the reality of parties’ consent to taking the risk of unpredictable AI behavior over the technicality of existing principles of legal liability. The suggested approach also encourages transparency and responsible decisions of developers and owners of AI systems. A flowchart to clarify possible outcomes of applying the suggested approach is provided. The paper also discusses the need for harmonization of national laws and international cooperation regarding AI incidents crossing national borders to ensure predictability of legal rules governing the liability ensuing from AI applications. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","2-s2.0-85097173847"
"Khan M.; Yaseen Q.; Mumtaz A.; Saleem A.; Ishaq S.; Udeen H.","Khan, Maryam (57221603913); Yaseen, Qareena (57221602810); Mumtaz, Asia (57221596843); Saleem, Ayesha (57221614343); Ishaq, Seemab (57221605895); Udeen, Haseeb (57221605683)","57221603913; 57221602810; 57221596843; 57221614343; 57221605895; 57221605683","Severe Analysis of Cardiac Disease Detection using the Wearable Device by Artificial Intelligence","2020","2020 IEEE International Conference for Innovation in Technology, INOCON 2020","","","9298388","","","","10.1109/INOCON50539.2020.9298388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099591248&doi=10.1109%2fINOCON50539.2020.9298388&partnerID=40&md5=a298fd328427ec0c403d34a77a009348","In the current era of technology, Artificial Intelligence (AI) is playing a vital role in the health care sector especially cardiac disease detection which is a major cause of sudden death. Both the elderly and young are at the risk of sudden cardiac death at the ratio of 1-2% all around the world. Although AI technology with wearable technology is being used to detect heart diseases for quite some time now, sometimes it fails due to multiple reasons which include algorithm failure, high cost of treatment, limited battery time wearable device, data training issues, security and privacy issue in IoT, slow working of devices, poor internet or patients don't reach the hospital on time. Which gives rise to false results. Security and privacy issues in the old devices are the biggest flaws due to which old devices work slowly and the internet issues are common, it helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload, cost issues and to line onward. Meanwhile, these problems can be overcome by using modern models such as ECG assessment, AI-based guidelines, Visy's model which can recognize five critical diseases. A Wearable ECG patch is a very lightweight model that provides high accuracy and efficiency. These devices are trained by using a machine learning algorithm, and AI plays a prime role to detect the diseases. It helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload and cost issues, and the devices provide updated information as real-time data is stored online and secured with firebase authentication. It is concluded that all modern devices are more efficacious, cost-effective, user friendly, and more secure. © 2020 IEEE.","2-s2.0-85099591248"
"Patyal S.; Bhatia T.","Patyal, Shama (57408756100); Bhatia, Tejasvi (56506795000)","57408756100; 56506795000","Artificial Intelligence with Radio-Diagnostic Modalities in Forensic Science - A Systematic Review","2021","CEUR Workshop Proceedings","3058","","71","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122677710&partnerID=40&md5=d2c51fe0a5e768770894bd8df4763823","PURPOSE: The aim of this study was to provide an overview of Artificial intelligence in Forensic science with the aid of radio-diagnostic modalities. DATA SOURCES and SYNTHESIS: The data is gathered by searching the articles in varioussearch engines which have been published between January 2010 to December 2020. A total of 20 studies were found eligible after following inclusion and exclusion criteria described in the below article. Prisma Guidelines and Prisma Flowchart was followed. CONCLUSION: Artificial intelligence (AI) is a technology that involves computerised algorithms to dichotomize complex data. AI is widely used in diagnostic imaging for detection and quantification of a clinical condition. This systematic review aimed to explain the role of AI with diagnostic imaging modality of radiology in forensic. AI technology is now widely used for age and sex estimation. Most of the AI models are based on machine learning (ML) programs, artificial neural network(ANN) and convolutional neural network (CNN). The results of the studies are promising, providing great accuracy and decision making. These different AI based models will be act as identification tools in mass disasters cases, medicolegal cases. Further improvement in AI programs and diagnostic tool is needed for better accuracy and specificity in Forensic investigations. ©2021 Copyright for this paper by its authors.","2-s2.0-85122677710"
"Khan S.; Tsutsumi S.; Yairi T.; Nakasuka S.","Khan, Samir (55769263800); Tsutsumi, Seiji (35873737200); Yairi, Takehisa (9744426100); Nakasuka, Shinichi (35401647800)","55769263800; 35873737200; 9744426100; 35401647800","Robustness of AI-based prognostic and systems health management","2021","Annual Reviews in Control","51","","","130","152","22","10.1016/j.arcontrol.2021.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104159432&doi=10.1016%2fj.arcontrol.2021.04.001&partnerID=40&md5=95edd925931629c833b2f7b179c2e8ef","Prognostic and systems Health Management (PHM) is an integral part of a system. It is used for solving reliability problems that often manifest due to complexities in design, manufacturing, operating environment and system maintenance. For safety-critical applications, using a model-based development process for complex systems might not always be ideal but it is equally important to establish the robustness of the solution. The information revolution has allowed data-driven methods to diffuse within this field to construct the requisite process (or system models) to cope with the so-called big data phenomenon. This is supported by large datasets that help machine-learning models achieve impressive accuracy. AI technologies are now being integrated into many PHM related applications including aerospace, automotive, medical robots and even autonomous weapon systems. However, with such rapid growth in complexity and connectivity, a systems’ behaviour is influenced in unforeseen ways by cyberattacks, human errors, working with incorrect or incomplete models and even adversarial phenomena. Many of these models depend on the training data and how well the data represents the test data. These issues require fine-tuning and even retraining the models when there is even a small change in operating conditions or equipment. Yet, there is still ambiguity associated with their implementation, even if the learning algorithms classify accordingly. Uncertainties can lie in any part of the AI-based PHM model, including in the requirements, assumptions, or even in the data used for training and validation. These factors lead to sub-optimal solutions with an open interpretation as to why the requirements have not been met. This warrants the need for achieving a level of robustness in the implemented PHM, which is a challenging task in a machine learning solution. This article aims to present a framework for testing the robustness of AI-based PHM. It reviews some key milestones achieved in the AI research community to deal with three particular issues relevant for AI-based PHM in safety-critical applications: robustness to model errors, robustness to unknown phenomena and empirical evaluation of robustness during deployment. To deal with model errors, many techniques from probabilistic inference and robust optimisation are often used to provide some robustness guarantee metric. In the case of unknown phenomena, techniques include anomaly detection methods, using causal models, the construction of ensembles and reinforcement learning. It elicits from the authors’ work on fault diagnostics and robust optimisation via machine learning techniques to offer guidelines to the PHM research community. Finally, challenges and future directions are also examined; on how to better cope with any uncertainties as they appear during the operating life of an asset. © 2021","2-s2.0-85104159432"
"Chandramouli K.; Izquierdo E.","Chandramouli, Krishna (24483264500); Izquierdo, Ebroul (35553751500)","24483264500; 35553751500","An Advanced Framework for Critical Infrastructure Protection Using Computer Vision Technologies","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12618 LNCS","","","107","122","15","10.1007/978-3-030-69781-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102743266&doi=10.1007%2f978-3-030-69781-5_8&partnerID=40&md5=6228bca8b785abcc9e78b282ae74321c","Over the past decade, there has been unprecedented advancements in the field of computer vision by adopting AI-based solutions. In particular, cutting edge computer vision technology based on deep-learning approaches has been deployed with an extraordinary degree of success. The ability to extract semantic concepts from continuous processing of video stream in real-time has led to the investigation of such solutions to enhance the operational security of critical infrastructure against intruders. Despite the success of computer vision technologies validated in a laboratory environment, there still exists several challenges that limit the deployment of these solutions in operational environment. Addressing these challenges, the paper presents a framework that integrates three main computer vision technologies namely (i) person detection; (ii) person re-identification and (iii) face recognition to enhance the operational security of critical infrastructure perimeter. The novelty of the proposed framework relies on the integration of key technical innovations that satisfies the operational requirements of critical infrastructure in using computer vision technologies. One such requirement relates to data privacy and citizen rights, following the implementation of General Data Protection Regulation across Europe for the successful adoption of video surveillance for infrastructure security. The video analytics solution proposed in the paper integrates privacy preserving technologies, high-level rule engine for threat identification and a knowledge model for escalating threat categorises to human operator. The various components of the proposed framework has been validated using commercially available graphical processing units for detecting intruders. The performance o the proposed framework has been evaluated in operational environments of the critical infrastructure. An overall accuracy of 97% is observed in generating alerts against malicious intruders. © 2021, Springer Nature Switzerland AG.","2-s2.0-85102743266"
"Mallia N.; Dingli A.; Haddod F.","Mallia, Natalia (57222256269); Dingli, Alexiei (7801315512); Haddod, Foaad (57210143433)","57222256269; 7801315512; 57210143433","MIRAI: A Modifiable, Interpretable, and Rational AI Decision Support System","2021","Studies in Computational Intelligence","928","","","127","141","14","10.1007/978-3-030-61045-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102054350&doi=10.1007%2f978-3-030-61045-6_10&partnerID=40&md5=566fc319bfbdeb97880093c5ba299ad1","With the recent advancements and results obtained by Deep Learning, several corporations are eager to begin adapting AI into their workflow to benefit from these systems, especially with the emergence of Industry 4.0. However, decision makers find themselves unable to fully trust AI systems from evaluation metrics alone and require some more transparency in their systems. As such, research has gone in the direction of Explainable AI (XAI), where the inner mechanics and reasoning processes of these learning systems are presented in such a way that it is interpretable by humans, opening the Black Box of opaque AI algorithms. This study intends to develop a Big Data and Online Learning-based Explaining AI architecture which utilizes a novel approach of combining Rule-Based Reasoning methodology alongside an explainable Deep Learning framework in order to create a system capable of a higher level of reasoning, or ‘Deep Understanding’. Evaluation for this system is to take place by means of standard Machine Learning evaluation metrics such as F1-Scores, Precision, Recall, and ROC Curves. Alongside this, user-feedback evaluation forms from relevant personnel will be used to verify how useful the explanations are in production. © 2021, Springer Nature Switzerland AG.","2-s2.0-85102054350"
"Kumar S.; Panwal A.; Gharat S.; Ghatte N.; Karia D.","Kumar, Siddhant (57226008610); Panwal, Anushka (57454802900); Gharat, Sahil (57454803000); Ghatte, Najib (57205423120); Karia, Deepak (36004944700)","57226008610; 57454802900; 57454803000; 57205423120; 36004944700","AI Based Smart Remedial Observants in COVID-19 Crisis","2021","Proceedings - International Conference on Communication, Information and Computing Technology, ICCICT 2021","","","","","","","10.1109/ICCICT50803.2021.9510051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124702352&doi=10.1109%2fICCICT50803.2021.9510051&partnerID=40&md5=6660656586d1be9aa715491e5350a8b8","Coronavirus disease (COVID-19) is a contagious [1] disease caused by becoming infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [2]. Numerous nations have acquainted social distancing measures to slow down the spread of the COVID-19 pandemic as people can spread the virus before they know they are sick. The solution focuses on a web-based solution to alert the residents and outsiders in case of any non-compliance of rules. In this work, an AI-powered solution is developed that leverages Machine learning based algorithm to guarantee that individuals are keeping up a safe distance from one another. A software-based approach is taken for providing a simple and engaging user experience to the user that will help the society and other authorities track and analyses the implications of such rules. The web application will be used to alert the users in case of any breaking of the law. Along with this, a system that detects if people are wearing a mask or not will also be verified by the algorithm. The model built can be deployed in the existing CCTV cameras to monitor each and every place of gathering without the need for any additional hardware systems. © 2021 IEEE","2-s2.0-85124702352"
"Sadamoto T.; Chakrabortty A.","Sadamoto, Tomonori (53064435500); Chakrabortty, Aranya (16308759500)","53064435500; 16308759500","Fast Real-Time Reinforcement Learning for Partially-Observable Large-Scale Systems","2020","IEEE Transactions on Artificial Intelligence","1","3","","206","218","12","10.1109/TAI.2021.3058228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142810367&doi=10.1109%2fTAI.2021.3058228&partnerID=40&md5=26218020832ae93e155c5a6bc5705563","We propose a fast real-time reinforcement learning (RL) control algorithm for large-scale partially-observable linear dynamic systems. We first develop a one-shot RL method for designing model-free optimal controllers based on a finite-time history of the inputs and the outputs. However, when the system dimension is large, this method may suffer from a long learning time. To overcome this problem, in the second half of the paper we introduce a new notion of approximation to the design, where the original set of input-output history is replaced by a much shorter set. We show that this approximation can lead to a nearly optimal controller that is based on a lower-dimensional approximant of the original system in terms of reachability and observability. We provide a guideline for determining an appropriate length of the input-output history to reduce the suboptimality gap. The dimension of the resulting suboptimal controller is far less than that of the optimal controller, thereby speeding up learning time. The learned controller, however may cause instability when implemented in the original high-dimensional system by adversely exciting the approximation error. We theoretically establish the conditions for closed-loop stability using robust control theory, followed by numerical investigations of the trade-offs between learning time, length of input/output history, and closed-loop performance. The effectiveness of the method is illustrated using examples from electric power systems, modeled by partially-observable nonlinear differential-algebraic equations. Impact Statement-Timing is a critical factor in the design and implementation of all AI-based control systems. For example, when avoiding collisions in a transportation network, or when controlling the electric power grid, control actions need to be taken just-in-time to avoid catastrophic consequences that could occur. Existing AI-based control laws have poor scalability due to the significant time needed to learn a controller on-the-fly. The problem is compounded due to constraints imposed by sensors and the limited set of measurements associated with partial observability of a plant. This paper proposes an approximation framework for large networks with such constraints, whereby the size of the controller can be projected onto a significantly lower-dimensional space, allowing orders of magnitude speed-up in learning and design time. The approach has the potential to transform AI-based control from slow models to fast ones with practical implications for any extreme-scale control application. © 2021 IEEE.","2-s2.0-85142810367"
"Johnson A.; Vong W.K.; Lake B.M.; Gureckis T.M.","Johnson, Aysja (57222758407); Vong, Wai Keen (55803962600); Lake, Brenden M. (56123187100); Gureckis, Todd M. (6506126125)","57222758407; 55803962600; 56123187100; 6506126125","Fast and flexible: Human program induction in abstract reasoning tasks","2021","Proceedings of the 43rd Annual Meeting of the Cognitive Science Society: Comparative Cognition: Animal Minds, CogSci 2021","","","","2471","2477","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139446576&partnerID=40&md5=05fb28666b307d4ddfbb88df86756f57","The Abstraction and Reasoning Corpus (ARC) is a collection program induction tasks that was recently proposed by Chollet (2019) as a measure of machine intelligence. Here, we report a preliminary set of results from a behavioral study of humans solving a subset of tasks from ARC (40 out of 1000). We found that humans were able to infer the underlying program and generate the correct test output for a novel test input example, with an average of 84% of tasks solved per participant, and with 65% of tasks being solved by more than 80% of participants. Additionally, we find interesting patterns of behavioral consistency and variability across the action sequences to generate their responses, the natural language descriptions used to describe the rule for each task, and the errors people make. Our findings suggest that people can quickly and reliably determine the relevant features and properties of a task to compose a correct solution, despite limited experience in this domain. This dataset offers useful insights for designing AI systems that can solve abstract reasoning tasks such as ARC with the fluidity of human intelligence. © Cognitive Science Society: Comparative Cognition: Animal Minds, CogSci 2021.All rights reserved.","2-s2.0-85139446576"
"Jiang Z.; Gao W.; Tang F.; Wang L.; Xiong X.; Luo C.; Lan C.; Li H.; Zhan J.","Jiang, Zihan (57212001997); Gao, Wanling (56019066100); Tang, Fei (57226289161); Wang, Lei (57070611300); Xiong, Xingwang (57212006258); Luo, Chunjie (55347385000); Lan, Chuanxin (57219639982); Li, Hongxiao (57224913609); Zhan, Jianfeng (23098716000)","57212001997; 56019066100; 57226289161; 57070611300; 57212006258; 55347385000; 57219639982; 57224913609; 23098716000","HPC AI500 V2.0: The Methodology, Tools, and Metrics for Benchmarking HPC AI Systems","2021","Proceedings - IEEE International Conference on Cluster Computing, ICCC","2021-September","","","47","58","11","10.1109/Cluster48925.2021.00022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117658092&doi=10.1109%2fCluster48925.2021.00022&partnerID=40&md5=54c62c14cfd604f49e22363ccea66319","Recent years witness a trend of applying large-scale distributed deep learning algorithms (HPC AI) in both business and scientific computing areas, whose goal is to speed up the training time to achieve a state-of-the-art quality. The HPC AI benchmarks accelerate the process. Unfortunately, benchmarking HPC AI systems at scale raises serious challenges. This paper presents a comprehensive HPC AI benchmarking methodology that achieves equivalence, representativeness, repeatability, and affordability. Among the nineteen AI workloads of AIBench Training-by far the most comprehensive AI benchmarks suite, we choose two representative and repeatable AI workloads in terms of both AI model and micro-architectural characteristics. The selected HPC AI benchmarks include both business and scientific computing: Image Classification and Extreme Weather Analytics. Finally, we propose three high levels of benchmarking and the corresponding rules to assure equivalence. To rank the performance of HPC AI systems, we present a new metric named Valid FLOPS, emphasizing both throughput performance and target quality. The evaluations show our methodology, benchmarks, and metrics can measure and rank the HPC AI systems in a simple, affordable and repeatable way. The specification, source code, datasets, and HPC AI500 ranking numbers are publicly available from https: //www.benchcouncil.org/aibench/hpcai500/index.html.  ©2021 IEEE.","2-s2.0-85117658092"
"Strauß S.","Strauß, Stefan (39161935300)","39161935300","Deep automation bias: How to tackle a wicked problem of ai?","2021","Big Data and Cognitive Computing","5","2","18","","","","10.3390/bdcc5020018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105222700&doi=10.3390%2fbdcc5020018&partnerID=40&md5=b8926db5986dd6c2d1b46074868b51cd","The increasing use of AI in different societal contexts intensified the debate on risks, ethical problems and bias. Accordingly, promising research activities focus on debiasing to strengthen fairness, accountability and transparency in machine learning. There is, though, a tendency to fix societal and ethical issues with technical solutions that may cause additional, wicked problems. Alternative analytical approaches are thus needed to avoid this and to comprehend how societal and ethical issues occur in AI systems. Despite various forms of bias, ultimately, risks result from eventual rule conflicts between the AI system behavior due to feature complexity and user practices with limited options for scrutiny. Hence, although different forms of bias can occur, automation is their common ground. The paper highlights the role of automation and explains why deep automation bias (DAB) is a metarisk of AI. Based on former work it elaborates the main influencing factors and develops a heuristic model for assessing DAB-related risks in AI systems. This model aims at raising problem awareness and training on the sociotechnical risks resulting from AI-based automation and contributes to improving the general explicability of AI systems beyond technical issues. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","2-s2.0-85105222700"
"Rjoob K.; Bond R.; Finlay D.; McGilligan V.; Leslie S.J.; Rababah A.; Iftikhar A.; Guldenring D.; Knoery C.; McShane A.; Peace A.","Rjoob, Khaled (57204770661); Bond, Raymond (36019802200); Finlay, Dewar (8977626000); McGilligan, Victoria (15762848200); Leslie, Stephen J. (57202677736); Rababah, Ali (56904089300); Iftikhar, Aleeha (57210747030); Guldenring, Daniel (36459546000); Knoery, Charles (57202587350); McShane, Anne (57210787090); Peace, Aaron (25655320100)","57204770661; 36019802200; 8977626000; 15762848200; 57202677736; 56904089300; 57210747030; 36459546000; 57202587350; 57210787090; 25655320100","Towards Explainable Artificial Intelligence and Explanation User Interfaces to Open the ‘Black Box’ of Automated ECG Interpretation","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12585 LNCS","","","96","108","12","10.1007/978-3-030-68007-7_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102652393&doi=10.1007%2f978-3-030-68007-7_6&partnerID=40&md5=b970a597d371c1bf29a05c6c655aa6b3","This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system. © 2021, Springer Nature Switzerland AG.","2-s2.0-85102652393"
"Kher Y.; Saxena A.; Tamizharasan P.S.; Joshi A.D.","Kher, Yatharth (57224404654); Saxena, Aditya (58727691000); Tamizharasan, P.S. (56405540900); Joshi, Amit D. (55572120100)","57224404654; 58727691000; 56405540900; 55572120100","Deep Learning-Based Smart Parking Management System and Business Model","2021","Communications in Computer and Information Science","1378 CCIS","","","116","127","11","10.1007/978-981-16-1103-2_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107506139&doi=10.1007%2f978-981-16-1103-2_11&partnerID=40&md5=bbce4ce71e6b76905911afe95fa14638","In this fast-developing world, the increase in the number of vehicles demands a smart parking system in smart cities. The issue of spending a lot of time finding parking slots needs to be addressed. The increase of smartphones provides the space to develop smart applications enabled with AI and deep learning. This paper proposes an AI-based smart parking management system and a business model to provide a solution for both user and the owner of the parking space. Owners of the parking slots can opt for fixed or variable timeslots to make use of their parking spaces. Registered users can check the availability of the parking spaces at the destination in real-time and details of the users such as the time and vehicle details can be detected and updated automatically. Billing for the parking space usage will also be done automatically as per the regulated guidelines. Raspberry Pi and deep learning tools are used for the implementation. The proposed system is cost-effective and reduces time and energy. © 2021, Springer Nature Singapore Pte Ltd.","2-s2.0-85107506139"
"Bozenhard J.","Bozenhard, Jonas (57225082242)","57225082242","Can GPT-3 speak? Wittgensteinian perspectives on human-machine communication","2021","AISB Convention 2021: Communication and Conversations","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109079564&partnerID=40&md5=4b2dda2225f9d49ea2a7628c5a039b53","There has been a lot of hype surrounding OpenAI’s impressive language model GPT-3 ever since it was released in mid-2020. Not only AI researchers and journalists were astound-ed by its spectacular performance at generating human-like text in a wide variety of domains – there was also great astonishment in the philosophical community. David Chalmers, for example, calls OpenAI’s autoregressive language model “one of the most interesting and important AI systems ever produced” [1]. This assessment seems appropriate – not least because GPT-3 raises intricate philosophical questions, for instance: “Does the ability to generate ‘speech’ imply communicative ability?” [2] In other words, do machines that produce text or speech possess linguistic competence and qualify as speakers? More trenchantly put: Can GPT-3 speak? My paper develops a framework of human-machine communication which casts new light on the conversational capacity of GPT-3 and other AI-powered text generators. As a major source of inspiration serves Ludwig Wittgenstein’s later philosophy, particularly his much-discussed reflections on rule-following and private language. © 2021 AISB Convention 2021: Communication and Conversations. All rights reserved.","2-s2.0-85109079564"
"Poudyal S.; Dasgupta D.","Poudyal, Subash (57207728272); Dasgupta, DIpankar (7103226630)","57207728272; 7103226630","Analysis of Crypto-Ransomware Using ML-Based Multi-Level Profiling","2021","IEEE Access","9","","9526633","122532","122547","15","10.1109/ACCESS.2021.3109260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114768095&doi=10.1109%2fACCESS.2021.3109260&partnerID=40&md5=814745beef69115538564328fa8866c1","Crypto-ransomware is the most prevalent form of modern malware, has affected various industries, demanding a significant amount of ransom. Mainly, small businesses, healthcare, education, and government sectors have been under continuous attacks by these adversaries. Various static and dynamic analysis techniques exist, but these methods become less efficient as the malware writers continuously trick the defenders. Numerous research of ransomware with AI techniques often lack the behavioral analysis and its correlation mapping. In this work, we developed an AI-powered hybrid approach overcoming the recent challenges to detect ransomware. Specifically, we proposed a deep inspection approach for multi-level profiling of crypto-ransomware, which captures the distinct features at Dynamic link library, function call, and assembly levels. We showed how the code segments correlate at these levels for studied samples. Our hybrid multi-level analysis approach includes advanced static and dynamic methods and a novel strategy of analyzing behavioral chains with AI techniques. Moreover, association rule mining, natural language processing techniques, and machine learning classifiers are integrated for building ransomware validation and detection model. We experimented with crypto-ransomware samples (collected from VirusTotal). One of the machine learning algorithms achieved the highest accuracy of 99.72% and a false positive rate of 0.003 with two class datasets. The result exhibited that multi-level profiling can better detect ransomware samples with higher accuracy. The multi-level feature sequence can be extracted from most of the applications running in the different operating systems; therefore, we believe that our method can detect ransomware for devices on multiple platforms. We designed a prototype, AIRaD (AI-based Ransomware Detection) tool, which will allow researchers and the defenders to visualize the analysis with proper interpretation.  © 2013 IEEE.","2-s2.0-85114768095"
"Maree C.; Modal J.E.; Omlin C.W.","Maree, Charl (57221647637); Modal, Jan Erik (57221643264); Omlin, Christian W. (6701361209)","57221647637; 57221643264; 6701361209","Towards Responsible AI for Financial Transactions","2020","2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020","","","9308456","16","21","5","10.1109/SSCI47803.2020.9308456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099715927&doi=10.1109%2fSSCI47803.2020.9308456&partnerID=40&md5=512ee3829095cc4192418d992d1c251f","The application of AI in finance is increasingly dependent on the principles of responsible AI. These principles-explainability, fairness, privacy, accountability, transparency and soundness form the basis for trust in future AI systems. In this empirical study, we address the first principle by providing an explanation for a deep neural nenvork that is trained on a mixture of numerical, categorical and textual inputs for financial transaction classification. The explanation is achieved through (1) a feature importance analysis using Shapley additive explanations (SHAP) and (2) a hybrid approach of text clustering and decision tree classifiers. We then test the robustness of the model by exposing it to a targeted evasion attack, leveraging the knowledge we gained about the model through the extracted explanation.  © 2020 IEEE.","2-s2.0-85099715927"
"Zhou Y.; Boussard M.; Delaborde A.","Zhou, Yongxin (57226595395); Boussard, Matthieu (57204166287); Delaborde, Agnes (58680788000)","57226595395; 57204166287; 58680788000","Towards an XAI-Assisted Third-Party Evaluation of AI Systems: Illustration on Decision Trees","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12688 LNAI","","","158","172","14","10.1007/978-3-030-82017-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113333532&doi=10.1007%2f978-3-030-82017-6_10&partnerID=40&md5=db57674cad21e4523b43981b1f61d564","We explored the potential contribution of eXplainable Artificial Intelligence (XAI) for the evaluation of Artificial Intelligence (AI), in a context where such an evaluation is performed by independent third-party evaluators, for example in the objective of certification. The experimental approach of this paper is based on “explainable by design” decision trees that produce predictions on health data and bank data. Results presented in this paper show that the explanations could be used by the evaluators to identify the parameters used in decision making and their levels of importance. The explanations would thus make it possible to orient the constitution of the evaluation corpus, to explore the rules followed for decision-making and to identify potentially critical relationships between different parameters. In addition, the explanations make it possible to inspect the presence of bias in the database and in the algorithm. These first results lay the groundwork for further additional research in order to generalize the conclusions of this paper to different XAI methods. © 2021, Springer Nature Switzerland AG.","2-s2.0-85113333532"
"Zaman S.; Alhazmi K.; Aseeri M.A.; Ahmed M.R.; Khan R.T.; Kaiser M.S.; Mahmud M.","Zaman, Shakila (57213556983); Alhazmi, Khaled (56285302600); Aseeri, Mohammed A. (12752663200); Ahmed, Muhammad Raisuddin (58494866000); Khan, Risala Tasin (56693715000); Kaiser, M. Shamim (56446362000); Mahmud, Mufti (35173453700)","57213556983; 56285302600; 12752663200; 58494866000; 56693715000; 56446362000; 35173453700","Security Threats and Artificial Intelligence Based Countermeasures for Internet of Things Networks: A Comprehensive Survey","2021","IEEE Access","9","","9456954","94668","94690","22","10.1109/ACCESS.2021.3089681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110756846&doi=10.1109%2fACCESS.2021.3089681&partnerID=40&md5=4bf64d9fc3151422ffae3db84707d1f5","The Internet of Things (IoT) has emerged as a technology capable of connecting heterogeneous nodes/objects, such as people, devices, infrastructure, and makes our daily lives simpler, safer, and fruitful. Being part of a large network of heterogeneous devices, these nodes are typically resource-constrained and became the weakest link to the cyber attacker. Classical encryption techniques have been employed to ensure the data security of the IoT network. However, high-level encryption techniques cannot be employed in IoT devices due to the limitation of resources. In addition, node security is still a challenge for network engineers. Thus, we need to explore a complete solution for IoT networks that can ensure nodes and data security. The rule-based approaches and shallow and deep machine learning algorithms- branches of Artificial Intelligence (AI)- can be employed as countermeasures along with the existing network security protocols. This paper presented a comprehensive layer-wise survey on IoT security threats, and the AI-based security models to impede security threats. Finally, open challenges and future research directions are addressed for the safeguard of the IoT network. © 2013 IEEE.","2-s2.0-85110756846"
"Remoaldo D.; Jesus I.S.","Remoaldo, Diogo (57221682586); Jesus, Isabel S. (9333348500)","57221682586; 9333348500","Analysis of a traditional and a fuzzy logic enhanced perturb and observe algorithm for the mppt of a photovoltaic system","2021","Algorithms","14","1","24","","","","10.3390/a14010024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099783233&doi=10.3390%2fa14010024&partnerID=40&md5=c9fdcc6380719a745639771d25258ffa","This paper presents the results obtained for the maximum power point tracking (MPPT) technique applied to a photovoltaic (PV) system, composed of five solar panels in series using two different methodologies. First, we considered a traditional Perturb and Observe (P&O) algorithm and in a second stage we applied a Fuzzy Logic Controller (FLC) that uses fuzzy logic concepts to improve the traditional P&O; both were implemented in a boost converter. The main aim of this paper is to study if an artificial intelligence (AI) based MPPT method, can be more efficient, stable and adaptable than a traditional MPPT method, in varying environment conditions, namely solar irradiation and/or environment temperature and also to analyze their behaviour in steady state conditions. The proposed FLC with a rule base collection of 25 rules outperformed the controller using the traditional P&O algorithm due to its adaptative step size, enabling the FLC to adapt the PV system faster to changing environment conditions, guessing the correct maximum power point (MPP) faster and achieving lower oscillations in steady state conditions, leading to higher generated energy due to lower losses both in steady state and dynamic environment conditions. The simulations in this study were performed using MATLAB (Version 2018)/Simulink. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85099783233"
"Kiru M.U.; Belaton B.; Mohamad S.M.S.; Usman G.M.; Kazaure A.A.","Kiru, Muhammad Ubale (57213686164); Belaton, Bahari (6504014356); Mohamad, Sharifah Mashita Syed (57221463263); Usman, Gana Mohammed (57205723157); Kazaure, Abdullahi Aminu (57213687871)","57213686164; 6504014356; 57221463263; 57205723157; 57213687871","Intelligent Automatic Door System based on Supervised Learning","2020","2020 IEEE Conference on Open Systems, ICOS 2020","","","9293673","43","47","4","10.1109/ICOS50156.2020.9293673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099202272&doi=10.1109%2fICOS50156.2020.9293673&partnerID=40&md5=4d5783aeaafe8d7d4a90fc003ab32c9d","The widespread adoption of automatic sliding doors in both commercial and non-commercial environments globally has necessitated the need to improve their efficiency, safety, and mode of operation. The automatic door gives access to go into or outside a building by sensing the approaching individual using sensors. However, it does not have the intuition to understand when a person is not authorized to go outside based on their age limit, for example, children. To address this problem, researchers have proposed solutions ranging from the use of fuzzy logic to rule-based approaches to make automatic doors better than the previous ones. In this study, an AI-based automatic door system is proposed, which uses a supervised machine learning approach to train classifiers using human body measurement. Our evaluation of different classifiers indicates that SVM is capable of classifying the instances correctly while achieving about 88.9% F-score. Thus, the proposed approach is expected to improve the safety of automatic doors, thereby making them smarter and more intelligent.  © 2020 IEEE.","2-s2.0-85099202272"
"Udenwagu N.E.; Azeta A.A.; Misra S.; Nwaocha V.O.; Enosegbe D.L.; Sharma M.M.","Udenwagu, Nnaemeka E. (57223614368); Azeta, Ambrose A. (24069688600); Misra, Sanjay (56962766700); Nwaocha, Vivian O. (56655151300); Enosegbe, Daniel L. (57223636758); Sharma, Mayank Mohan (57214452513)","57223614368; 24069688600; 56962766700; 56655151300; 57223636758; 57214452513","ExplainEx: An Explainable Artificial Intelligence Framework for Interpreting Predictive Models","2021","Advances in Intelligent Systems and Computing","1375 AIST","","","505","515","10","10.1007/978-3-030-73050-5_51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105938022&doi=10.1007%2f978-3-030-73050-5_51&partnerID=40&md5=6ff145ae8730999d5ef243913dee7e16","Artificial Intelligence (AI) systems are increasingly dependent on machine learning models which lack interpretability and algorithmic transparency, and hence may not be trusted by its users. The fear of failure in these systems is driving many governments to demand more explanation and accountability. Take, for example, the “Right of Explanation” rule proposed in the European Union in 2019, which gives citizens the right to demand an explanation from AI-based predictions. Explainable Artificial Intelligence (XAI) is an attempt to open up the “black box” and create more explainable systems which create predictive models whose results are easily understandable to humans. This paper describes an explanation model called ExplainEx which automatically generates natural language explanation for predictive models by consuming REST API provided by ExpliClas open-source web service. The classification model consists of four main decision tree algorithms including J48, Random Tree, RepTree and FURIA. The user interface was designed based on Microsoft.Net Framework programming platform. At the background is a software engine automating a seamless interaction between Expliclas API and the trained datasets, to provide natural language explanation to users. Unlike other studies, our proposed model is both a stand-alone and client-server based system capable of providing global explanations for any decision tree classifier. It supports multiple concurrent users in a client-server environment and can apply all four algorithms concurrently on a single dataset, returning both precision score and explanation. It is a ready tool for researchers who have datasets and classifiers prepared for explanation. This work bridges the gap between prediction and explanation, thereby allowing researchers to concentrate on data analysis and building state-of-the-art predictive models. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85105938022"
"Sheth A.; Gaur M.; Roy K.; Faldu K.","Sheth, Amit (57200763252); Gaur, Manas (57204944466); Roy, Kaushik (57221320197); Faldu, Keyur (57221152990)","57200763252; 57204944466; 57221320197; 57221152990","Knowledge-Intensive Language Understanding for Explainable AI","2021","IEEE Internet Computing","25","5","","19","24","5","10.1109/MIC.2021.3101919","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113254520&doi=10.1109%2fMIC.2021.3101919&partnerID=40&md5=647ed99e093187e0c95d97783bfaeb5f","AI systems have seen significant adoption in various domains. At the same time, further adoption in some domains is hindered by the inability to fully trust an AI system that it will not harm a human. Besides, fairness, privacy, transparency, and explainability are vital to developing trust in AI systems. As stated in Describing Trustworthy AI,aa.https://www.ibm.com/watson/trustworthy-ai. Trust comes through understanding. How AI-led decisions are made and what determining factors were included are crucial to understand. The subarea of explaining AI systems has come to be known as XAI. Multiple aspects of an AI system can be explained; these include biases that the data might have, lack of data points in a particular region of the example space, fairness of gathering the data, feature importances, etc. However, besides these, it is critical to have human-centered explanations directly related to decision-making, similar to how a domain expert makes decisions based on domain knowledge, including well-established, peer-validated explicit guidelines. To understand and validate an AI system's outcomes (such as classification, recommendations, predictions) that lead to developing trust in the AI system, it is necessary to involve explicit domain knowledge that humans understand and use. Contemporary XAI methods are yet addressed explanations that enable decision-making similar to an expert. Figure 1 shows the stages of adoption of an AI system into the real world.  © 1997-2012 IEEE.","2-s2.0-85113254520"
"Fisichella M.; Garolla F.","Fisichella, Marco (36607884300); Garolla, Filippo (57207112126)","36607884300; 57207112126","Can Deep Learning Improve Technical Analysis of Forex Data to Predict Future Price Movements?","2021","IEEE Access","9","","","153083","153101","18","10.1109/ACCESS.2021.3127570","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119401557&doi=10.1109%2fACCESS.2021.3127570&partnerID=40&md5=780ad3009cfc10182de483519f08d265","The foreign exchange market (Forex) is the world's largest market for trading foreign money, with a trading volume of over 5.1 trillion dollars per day. It is known to be very complicated and volatile. Technical analysis is the observation of past market movements with the aim of predicting future prices and dealing with the effects of market movements. A trading system is based on technical indicators derived from technical analysis. In our work, a complete trading system with a combination of trading rules on Forex time series data is developed and made available to the scientific community. The system is implemented in two phases: In the first phase, each trading rule, both the AI-based rule and the trading rules from the technical indicators, is tested for selection; in the second phase, profitable rules are selected among the qualified rules and combined. Training data is used in the training phase of the trading system. The proposed trading system was extensively trained and tested on historical data from 2010 to 2021. To determine the effectiveness of the proposed method, we also conducted experiments with datasets and methodologies used in recent work by Hernandez-Aguila et al., 2021 and by Munkhdalai et al., 2019. Our method outperforms all other methodologies for almost all Forex markets, with an average percentage gain of 20.2%. A particular focus was on training our AI-based rule with two different architectures: the first is a widely used convolutional network for image classification, i.e. ResNet50; the second is an attention-based network Vision Transformer (ViT). The results provide a clear answer to the main question that guided our research and which is the title of this paper.  © 2013 IEEE.","2-s2.0-85119401557"
"Ali S.; Park H.W.; Breazeal C.","Ali, Safinah (57207448534); Park, Hae Won (57191796621); Breazeal, Cynthia (7003691791)","57207448534; 57191796621; 7003691791","Can Children Emulate a Robotic Non-Player Character's Figural Creativity?","2020","CHI PLAY 2020 - Proceedings of the Annual Symposium on Computer-Human Interaction in Play","","","","499","509","10","10.1145/3410404.3414251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097490664&doi=10.1145%2f3410404.3414251&partnerID=40&md5=7762d080285fd0c3398b5ccda20a1dd7","Can intelligent non-player game characters (NPCs) increase children's creativity during collaborative gameplay? Children's creativity is influenced by collaborative play with creative peers through social emulation. In this paper, we study children's emulation of an AI-enabled social Non-Player Character (NPC) as a new type of game mechanism to elicit creative expression. We developed Magic Draw, a collaborative drawing game designed to foster children's figural creativity that allows us to investigate the efficacy of an NPC's creativity demonstration in enhancing children's creativity in the resulting drawings. The NPC is an emotively expressive social robot that plays Magic Draw with a child as a peer-like playmate. We present the results of a study in which participants co-draw figures with a social robot that demonstrates different levels of figural creativity, to understand whether an NPC's creativity in its own contributions stimulates figural creativity in children. 78 participants (ages 5 - 10) were randomly assigned to a non-creative robot control condition (C-) and a creative robot condition (C+). Participants who interacted with the creative robot generated significantly more creative drawings, and hence exhibited higher levels of figural creativity. We infer that the social robotic peers' demonstration of figural creativity in a collaborative drawing game is emulated by young children. We discuss a new game design principle grounded in the social learning mechanism of emulation, specifically, that social and intelligent NPCs in games should demonstrate creative behavior to foster the same in human players.  © 2020 Owner/Author.","2-s2.0-85097490664"
"Sarker I.H.; Hoque M.M.; Uddin M.K.; Alsanoosy T.","Sarker, Iqbal H. (56997358700); Hoque, Mohammed Moshiul (55436576000); Uddin, Md. Kafil (57221024500); Alsanoosy, Tawfeeq (57203503502)","56997358700; 55436576000; 57221024500; 57203503502","Mobile Data Science and Intelligent Apps: Concepts, AI-Based Modeling and Research Directions","2021","Mobile Networks and Applications","26","1","","285","303","18","10.1007/s11036-020-01650-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091038942&doi=10.1007%2fs11036-020-01650-z&partnerID=40&md5=0ea78808a658db275e40b7f3df23098a","Artificial intelligence (AI) techniques have grown rapidly in recent years in the context of computing with smart mobile phones that typically allows the devices to function in an intelligent manner. Popular AI techniques include machine learning and deep learning methods, natural language processing, as well as knowledge representation and expert systems, can be used to make the target mobile applications intelligent and more effective. In this paper, we present a comprehensive view on “mobile data science and intelligent apps” in terms of concepts and AI-based modeling that can be used to design and develop intelligent mobile applications for the betterment of human life in their diverse day-to-day situation. This study also includes the concepts and insights of various AI-powered intelligent apps in several application domains, ranging from personalized recommendation to healthcare services, including COVID-19 pandemic management in recent days. Finally, we highlight several research issues and future directions relevant to our analysis in the area of mobile data science and intelligent apps. Overall, this paper aims to serve as a reference point and guidelines for the mobile application developers as well as the researchers in this domain, particularly from the technical point of view. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","2-s2.0-85091038942"
"Sætra H.S.","Sætra, Henrik Skaug (57202855771)","57202855771","A Typology of AI Applications in Politics","2021","Advanced Sciences and Technologies for Security Applications","","","","27","43","16","10.1007/978-3-030-88972-2_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120553776&doi=10.1007%2f978-3-030-88972-2_3&partnerID=40&md5=1f884aa92bb93683982e88e7ceead014","Politics relates to the most fundamental questions of humans’ existence, and modern western societies tend to pride themselves on basing politics on democratic principles, including principles of inclusivity, participation, and autonomy and self-rule. Meanwhile, the continuously improving capabilities of various artificial intelligence (AI) based systems have led to the use of AI in an increasing amount of politically significant settings. AI is now also used in official government decision-making processes, and the political significance of using AI in the political system is the topic of this chapter. The purpose is to examine the potential for AI in official political settings, distinguishing between five types of AI used to support, assist, alleviate, augment or supplant decision makers. The chapter explores the practical and theoretical potential for AI applications in politics, and the main contribution of the chapter is the development of a typology that can guide the evaluation of the impacts of such applications. AI in politics has the potential to drastically change how politics is performed, and as politics entails answering some of society’s most fundamental questions the article concludes that the issues here discussed should be subject to public processes, both in politics and society at large. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85120553776"
"Bisong O.E.; Oommen B.J.","Bisong, O. Ekaba (57208835466); Oommen, B. John (57208835756)","57208835466; 57208835756","On utilizing an enhanced object partitioning scheme to optimize self-organizing lists-on-lists","2021","Evolving Systems","12","1","","123","154","31","10.1007/s12530-020-09327-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079428578&doi=10.1007%2fs12530-020-09327-4&partnerID=40&md5=cc6439abd11d56c6e8d9ae6098e15e0b","With the advent of “Big Data” as a field, in and of itself, there are at least three fundamentally new questions that have emerged, namely the Artificially Intelligence (AI)-based algorithms required, the hardware to process the data, and the methods to store and access the data efficiently. This paper (The work of the second author was partially supported by NSERC, the Natural Sciences and Engineering Council of Canada. We are very grateful for the feedback from the anonymous Referees of the original submission. Their input significantly improved the quality of this final version.) presents some novel schemes for the last of the three areas. There have been thousands of papers written regarding the algorithms themselves, and the hardware vendors are scrambling for the market share. However, the question of how to store, manage and access data, which has been central to the field of Computer Science, is even more pertinent in these days when megabytes of data are being generated every second. This paper considers the problem of minimizing the cost of retrieval using the most fundamental data structure, i.e., a Singly-Linked List (SLL). We consider a SLL in which the elements are accessed by a Non-stationary Environment (NSE) exhibiting the so-called “Locality of Reference”. We propose a solution to the problem by designing an “Adaptive” Data Structure (ADS), which is created by utilizing a composite of hierarchical data “sub”-structures to constitute the overall data structure (In this paper, the primitive data structure is the SLL. However, these concepts can be extended to more complicated data structures.). In this paper, we design hierarchical Lists-on-Lists (LOLs) by assembling a SLL into a hierarchical scheme that results in SLLs on SLLs (SLLs-on-SLLs) comprising of an outer-list and sublist contexts. The goal is that elements that are more likely to be accessed together are grouped within the same sub-context, while the sublists themselves are moved “en masse” towards the head of the list-context to minimize the overall access cost. This move is carried out by employing the “de-facto” list re-organization schemes, i.e., the Move-To-Front (MTF) and Transposition (TR) rules. To achieve the clustering of elements within the sublists, we invoke the Object Migration Automaton (OMA) family of reinforcement schemes from the theory of Learning Automata (LA). They capture the probabilistic dependence of the elements in the data structure, receiving query accesses from the Environment. We show that SLLs-on-SLLs augmented with the Enhanced OMA (EOMA) minimizes the retrieval cost for elements in NSEs, and are superior to the stand-alone MTF and TR schemes, and also superior to the OMA-augmented SLLs-on-SLLs operating in such Environments. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","2-s2.0-85079428578"
"Muhammad A.P.","Muhammad, Amna Pir (57222810378)","57222810378","Methods and Guidelines for Incorporating Human Factors Requirements in Automated Vehicles Development","2021","CEUR Workshop Proceedings","2857","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105563951&partnerID=40&md5=ad34670736fdcff1dedf57fcffcf6562","Automated vehicles (AV) are transforming the future of the transportation and improving the quality of life. However, due to their societal impact in urban environments, AV development challenges the current development process. Particularly, it is unclear how human factors requirements can be communicated to developers of AI-based AV. It is quite challenging especially in agile development, where the focus is on continuous deployment and rapid release cycles with short lead-Times. Due to the importance of human factors and its impact on trust, acceptance, and safety of AV in urban environments, my work aims at providing a suitable requirements engineering perspective and method. © 2021 CEUR-WS. All rights reserved.","2-s2.0-85105563951"
"Gao W.; Tang F.; Zhan J.; Wen X.; Wang L.; Cao Z.; Lan C.; Luo C.; Liu X.; Jiang Z.","Gao, Wanling (56019066100); Tang, Fei (57226289161); Zhan, Jianfeng (23098716000); Wen, Xu (57205884662); Wang, Lei (57070611300); Cao, Zheng (8420576700); Lan, Chuanxin (57219639982); Luo, Chunjie (55347385000); Liu, Xiaoli (57225058142); Jiang, Zihan (57212001997)","56019066100; 57226289161; 23098716000; 57205884662; 57070611300; 8420576700; 57219639982; 55347385000; 57225058142; 57212001997","AIBench Scenario: Scenario-distilling AI Benchmarking","2021","Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT","2021-September","","","142","158","16","10.1109/PACT52795.2021.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125755705&doi=10.1109%2fPACT52795.2021.00018&partnerID=40&md5=c6d98e0533eec2cba1e8bb8cd06b3ddc","Modern real-world application scenarios like Internet services consist of a diversity of AI and non-AI modules with huge code sizes and long and complicated execution paths, which raises serious benchmarking or evaluating challenges. Using AI components or micro benchmarks alone can lead to error-prone conclusions. This paper presents a methodology to attack the above challenge. We formalize a real-world application scenario as a Directed Acyclic Graph-based model and propose the rules to distill it into a permutation of essential AI and non-AI tasks, which we call a scenario benchmark. Together with seventeen industry partners, we extract nine typical scenario benchmarks. We design and implement an extensible, configurable, and flexible benchmark framework. We implement two Internet service AI scenario benchmarks based on the framework as proxies to two real-world application scenarios. We consider scenario, component, and micro benchmarks as three indispensable parts for evaluating. Our evaluation shows the advantage of our methodology against using component or micro AI benchmarks alone. The specifications, source code, testbed, and results are publicly available from https://www.benchcouncil.org/aibench/scenario/. © 2021 IEEE","2-s2.0-85125755705"
"Mehdiyev N.; Houy C.; Gutermuth O.; Mayer L.; Fettke P.","Mehdiyev, Nijat (35782063300); Houy, Constantin (36191671000); Gutermuth, Oliver (57202536773); Mayer, Lea (57221984175); Fettke, Peter (55888276100)","35782063300; 36191671000; 57202536773; 57221984175; 55888276100","Explainable Artificial Intelligence (XAI) Supporting Public Administration Processes – On the Potential of XAI in Tax Audit Processes","2021","Lecture Notes in Information Systems and Organisation","46","","","413","428","15","10.1007/978-3-030-86790-4_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118191720&doi=10.1007%2f978-3-030-86790-4_28&partnerID=40&md5=bdffe476639656a305713b8517ea3e57","Artificial Intelligence (AI) can offer significant potential for public administrations which – in Germany – are likely to face considerable skills shortages in the next few years. AI systems can especially support the automation of processes and thus disburden administrative staff. As transparency and fairness play a major role in administrative processes, explainable AI (XAI) approaches are expected to enable a proper usage of AI in public administration. In this article, we investigate the potential of XAI for the support of tax authority processes, especially the selection of tax audit target organizations. We illustrate relevant tax audit scenarios and present the potential of different XAI techniques which we currently develop in these scenarios. It shows that XAI can significantly support tax audit preparations resulting in more efficient processes and a better performance of tax authorities concerning their main responsibilities. A further contribution of this article lies in the exemplary application of XAI usage guidelines in the public administration context. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85118191720"
"Nevanperä M.; Rajamäki J.; Helin J.","Nevanperä, Minna (57292031700); Rajamäki, Jyri (6602563131); Helin, Jaakko (57291575600)","57292031700; 6602563131; 57291575600","Design science research and designing ethical guidelines for the SHAPES AI developers","2021","Procedia Computer Science","192","","","2330","2339","9","10.1016/j.procs.2021.08.223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116942735&doi=10.1016%2fj.procs.2021.08.223&partnerID=40&md5=343f3579ac7e4682fefa147058f27466","This article targets the design process of ethical guidelines for the SHAPES project (Smart and Healthy Aging through People Engaging in Supportive Systems) which is a H2020 Innovation Action project. The aim of the project is to build solutions that can make it easier for older individuals to live at home, such as, robots, wearables and sensor technologies that apply artificial intelligence (AI). The guiding method of the design process of ethical guidelines is Alan Hevner's Design Science Research. Theoretical background consists of a form of literature overview, which contains the most relevant ethical theories and research on AI ethics, machine ethics and human rights. This article introduces the process of building the ethical guidelines for the SHAPES project and further discussion if providing guidelines is the sufficient tool to developers to take ethical action in development of the AI systems. The SHAPES guidelines include the following themes; accountability, transparency and explainability, diversity, inclusion and fairness, safety and security and societal wellbeing and humanity. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.","2-s2.0-85116942735"
"Poudyal S.; Dasgupta D.","Poudyal, Subash (57207728272); Dasgupta, Dipankar (7103226630)","57207728272; 7103226630","AI-Powered Ransomware Detection Framework","2020","2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020","","","9308387","1154","1161","7","10.1109/SSCI47803.2020.9308387","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099692637&doi=10.1109%2fSSCI47803.2020.9308387&partnerID=40&md5=bbd390a0dd140921162666972e544d73","Ransomware attacks are taking advantage of the ongoing pandemics and attacking the vulnerable systems in business, health sector, education, insurance, bank, and government sectors. Various approaches have been proposed to combat ransomware, but the dynamic nature of malware writers often bypasses the security checkpoints. There are commercial tools available in the market for ransomware analysis and detection, but their performance is questionable. This paper aims at proposing an AI-based ransomware detection framework and designing a detection tool (AIRaD) using a combination of both static and dynamic malware analysis techniques. Dynamic binary instrumentation is done using PIN tool, function call trace is analyzed leveraging Cuckoo sandbox and Ghidra. Features extracted at DLL, function call, and assembly level are processed with NLP, association rule mining techniques and fed to different machine learning classifiers. Support vector machine and Adaboost with J48 algorithms achieved the highest accuracy of 99.54% with 0.005 false-positive rates for a multi-level combined term frequency approach.  © 2020 IEEE.","2-s2.0-85099692637"
"Halme E.; Vakkuri V.; Kultanen J.; Jantunen M.; Kemell K.-K.; Rousi R.; Abrahamsson P.","Halme, Erika (57222063097); Vakkuri, Ville (57203640458); Kultanen, Joni (57212190406); Jantunen, Marianna (57217089350); Kemell, Kai-Kristian (57203633786); Rousi, Rebekah (55785577500); Abrahamsson, Pekka (7006011356)","57222063097; 57203640458; 57212190406; 57217089350; 57203633786; 55785577500; 7006011356","How to Write Ethical User Stories? Impacts of the ECCOLA Method","2021","Lecture Notes in Business Information Processing","419 LNBIP","","","36","52","16","10.1007/978-3-030-78098-2_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111394929&doi=10.1007%2f978-3-030-78098-2_3&partnerID=40&md5=9aa9dd952db8a72b8cef2f34bf464ced","Artificial Intelligence (AI) systems are increasing in significance within software services. Unfortunately, these systems are not flawless. Their faults, failures and other systemic issues have emphasized the urgency for consideration of ethical standards and practices in AI engineering. Despite the growing number of studies in AI ethics, comparatively little attention has been placed on how ethical issues can be mitigated in software engineering (SE) practice. Currently understanding is lacking regarding the provision of useful tools that can help companies transform high-level ethical guidelines for AI ethics into the actual workflow of developers. In this paper, we explore the idea of using user stories to transform abstract ethical requirements into tangible outcomes in Agile software development. We tested this idea by studying master’s level student projects (15 teams) developing web applications for a real industrial client over the course of five iterations. These projects resulted in 250+ user stories that were analyzed for the purposes of this paper. The teams were divided into two groups: half of the teams worked using the ECCOLA method for AI ethics in SE, while the other half, a control group, was used to compare the effectiveness of ECCOLA. Both teams were tasked with writing user stories to formulate customer needs into system requirements. Based on the data, we discuss the effectiveness of ECCOLA, and Primary Empirical Contributions (PECs) from formulating ethical user stories in Agile development. © 2021, The Author(s).","2-s2.0-85111394929"
"Paardekooper J.-P.; Comi M.; Grappiolo C.; Snijders R.; van Vught W.; Beekelaar R.","Paardekooper, Jan-Pieter (57210646341); Comi, Mauro (57473321700); Grappiolo, Corrado (35145678700); Snijders, Ron (57211393749); van Vught, Willeke (57188804787); Beekelaar, Rutger (57215305211)","57210646341; 57473321700; 35145678700; 57211393749; 57188804787; 57215305211","A hybrid-ai approach for competence assessment of automated driving functions","2021","CEUR Workshop Proceedings","2808","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101221380&partnerID=40&md5=ed01e02e7d4f0b9674a0ec98c6eee705","An increasing number of tasks is being taken over from the human driver as automated driving technology is developed. Accidents have been reported in situations where the automated driving technology was not able to function according to specifications. As data-driven Artificial Intelligence (AI) systems are becoming more ubiquitous in automated vehicles, it is increasingly important to make AI systems situational aware. One aspect of this is determining whether these systems are competent in the current and immediate traffic situation, or that they should hand over control to the driver or safety system. We aim to increase the safety of automated driving functions by combining data-driven AI systems with knowledge-based AI into a hybrid-AI system that can reason about competence in the traffic state now and in the next few seconds. We showcase our method using an intention prediction algorithm that is based on a deep neural network and trained with real-world data of traffic participants performing a cut-in maneuver in front of the vehicle. This is combined with a unified, quantitative representation of the situation on the road represented by an ontology-based knowledge graph and first-order logic inference rules, that takes as input both the observations of the sensors of the automated vehicle as well as the output of the intention prediction algorithm. The knowledge graph utilises the two features of importance, based on domain knowledge, and doubt, based on the observations and information about the dataset, to reason about the competence of the intention prediction algorithm. We have applied the competence assessment of the intention prediction algorithm to two cut-in scenarios: a traffic situation that is well within the operational design domain described by the training data set, and a traffic situation that includes an unknown entity in the form of a motorcycle that was not part of the training set. In the latter case the knowledge graph correctly reasoned that the intention prediction algorithm was incapable of producing a reliable prediction. This shows that hybrid AI for situational awareness holds great promise to reduce the risk of automated driving functions in an open world containing unknowns. Automated driving is one of the most appealing applications of artificial intelligence in an open world. It holds the promise of reducing the number of casualties (1.35 million yearly (WHO 2018)), increasing the comfort of travel by taking over the driving task from humans, and bringing mobility to those unable to drive. While fleets of fully automated vehicles that can run unrestrained in an open world are still far away (Koopman and Wagner 2016), many vehicles are already equipped with Advanced Driver Assistence Systems (Okuda, Kajiwara, and Terashima 2014), like Lane Keep Assist and Adaptive Cruise Control. According to The Geneva Convention on road traffic of 1949 and the Vienna Convention on road traffic 1968, on which many countries base their national traffic laws, a human driver has to be present in the vehicle (Vellinga 2019). Artificial Intelligence (AI) opens up the possibility of automation in increasingly complex situations, but also makes it increasingly complex for human drivers to understand the limitations of the system (Thill, Hemeren, and Nilsson 2014). Copyright © 2021for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85101221380"
"Bang J.; Kim S.; Nam J.W.; Yang D.-G.","Bang, Junseong (57210794982); Kim, Sineae (57486534300); Nam, Jang Won (57485290600); Yang, Dong-Geun (57485077700)","57210794982; 57486534300; 57485290600; 57485077700","Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations","2021","2021 International Conference on Platform Technology and Service, PlatCon 2021 - Proceedings","","","","","","","10.1109/PlatCon53246.2021.9680760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126254756&doi=10.1109%2fPlatCon53246.2021.9680760&partnerID=40&md5=c1adfcc34ee611e791a3514721a1fafe","AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.  © 2021 IEEE.","2-s2.0-85126254756"
"Nguyen M.N.H.; Pandey S.R.; Thar K.; Tran N.H.; Chen M.; Saad Bradley W.; Hong C.S.","Nguyen, Minh N.H. (57189065079); Pandey, Shashi Raj (57202054436); Thar, Kyi (56811684000); Tran, Nguyen H. (23398461300); Chen, Mingzhe (57113807700); Saad Bradley, Walid (57203259001); Hong, Choong Seon (56623778200)","57189065079; 57202054436; 56811684000; 23398461300; 57113807700; 57203259001; 56623778200","Distributed and Democratized Learning: Philosophy and Research Challenges","2021","IEEE Computational Intelligence Magazine","16","1","9321418","49","62","13","10.1109/MCI.2020.3039068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099595631&doi=10.1109%2fMCI.2020.3039068&partnerID=40&md5=0903963d48a6f94321a6d1b5b36b8800","Due to the availability of huge amounts of data and processing abilities, current artificial intelligence (AI) systems are effective in solving complex tasks. However, despite the success of AI in different areas, the problem of designing AI systems that can truly mimic human cognitive capabilities such as artificial general intelligence, remains largely open. Consequently, many emerging cross-device AI applications will require a transition from traditional centralized learning systems towards large-scale distributed AI systems that can collaboratively perform multiple complex learning tasks. In this paper, we propose a novel design philosophy called democratized learning (Dem-AI) whose goal is to build large-scale distributed learning systems that rely on the self-organization of distributed learning agents that are wellconnected, but limited in learning capabilities. Correspondingly, inspired by the societal groups of humans, the specialized groups of learning agents in the proposed Dem-AI system are selforganized in a hierarchical structure to collectively perform learning tasks more efficiently. As such, the Dem-AI learning system can evolve and regulate itself based on the underlying duality of two processes which we call specialized and generalized processes. In this regard, we present a reference design as a guideline to realize future Dem-AI systems, inspired by various interdisciplinary fields. Accordingly, we introduce four underlying mechanisms in the design such as plasticity-stability transition mechanism, self-organizing hierarchical structuring, specialized learning, and generalization. Finally, we establish possible extensions and new challenges for the existing learning approaches to provide better scalable, flexible, and more powerful learning systems with the new setting of Dem-AI.  © 2005-2012 IEEE.","2-s2.0-85099595631"
"Baviskar D.; Ahirrao S.; Potdar V.; Kotecha K.","Baviskar, Dipali (57221235200); Ahirrao, Swati (55787397400); Potdar, Vidyasagar (9736293700); Kotecha, Ketan (6506676097)","57221235200; 55787397400; 9736293700; 6506676097","Efficient Automated Processing of the Unstructured Documents Using Artificial Intelligence: A Systematic Literature Review and Future Directions","2021","IEEE Access","9","","9402739","72894","72936","42","10.1109/ACCESS.2021.3072900","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104231001&doi=10.1109%2fACCESS.2021.3072900&partnerID=40&md5=a491adfd231ef48853fc9116fd9b01dd","The unstructured data impacts 95% of the organizations and costs them millions of dollars annually. If managed well, it can significantly improve business productivity. The traditional information extraction techniques are limited in their functionality, but AI-based techniques can provide a better solution. A thorough investigation of AI-based techniques for automatic information extraction from unstructured documents is missing in the literature. The purpose of this Systematic Literature Review (SLR) is to recognize, and analyze research on the techniques used for automatic information extraction from unstructured documents and to provide directions for future research. The SLR guidelines proposed by Kitchenham and Charters were adhered to conduct a literature search on various databases between 2010 and 2020. We found that: 1. The existing information extraction techniques are template-based or rule-based, 2. The existing methods lack the capability to tackle complex document layouts in real-time situations such as invoices and purchase orders, 3. The datasets available publicly are task-specific and of low quality. Hence, there is a need to develop a new dataset that reflects real-world problems. Our SLR discovered that AI-based approaches have a strong potential to extract useful information from unstructured documents automatically. However, they face certain challenges in processing multiple layouts of the unstructured documents. Our SLR brings out conceptualization of a framework for construction of high-quality unstructured documents dataset with strong data validation techniques for automated information extraction. Our SLR also reveals a need for a close association between the businesses and researchers to handle various challenges of the unstructured data analysis. © 2013 IEEE.","2-s2.0-85104231001"
"Kalliokoski T.","Kalliokoski, Tuomo (35725719100)","35725719100","Requirement analysis for an artificial intelligence model for the diagnosis of the COVID-19 from chest X-ray data","2021","Proceedings - 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021","","","","3157","3164","7","10.1109/BIBM52615.2021.9669525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125194706&doi=10.1109%2fBIBM52615.2021.9669525&partnerID=40&md5=1c22aa399bb51bdea8fcb0b3b41cf13d","There are multiple papers published about different AI models for the COVID-19 diagnosis with promising results. Unfortunately according to the reviews many of the papers do not reach the level of sophistication needed for a clinically usable model. In this paper I go through multiple review papers, guidelines, and other relevant material in order to generate more comprehensive requirements for the future papers proposing a AI based diagnosis of the COVID-19 from chest X-ray data (CXR). Main findings are that a clinically usable AI needs to have an extremely good documentation, comprehensive statistical analysis of the possible biases and performance, and an explainability module.  © 2021 IEEE.","2-s2.0-85125194706"
"Shen Y.; Zhang J.; Song S.H.; Letaief K.B.","Shen, Yifei (57203618753); Zhang, Jun (36659981100); Song, S.H. (8397688900); Letaief, Khaled B. (55666697100)","57203618753; 36659981100; 8397688900; 55666697100","AI Empowered Resource Management for Future Wireless Networks","2021","2021 IEEE International Mediterranean Conference on Communications and Networking, MeditCom 2021","","","","252","257","5","10.1109/MeditCom49071.2021.9647580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120485930&doi=10.1109%2fMeditCom49071.2021.9647580&partnerID=40&md5=6afac80155fde9743e4c8fc8dca9dc6f","Resource management plays a pivotal role in wireless networks, which, unfortunately, leads to challenging NP-hard problems. Artificial Intelligence (AI), especially deep learning techniques, has recently emerged as a disruptive technology to solve such challenging problems in a real-time manner. However, although promising results have been reported, practical design guidelines and performance guarantees of AI-based approaches are still missing. In this paper, we endeavor to address two fundamental questions: 1) What are the main advantages of AI-based methods compared with classical techniques; and 2) Which learning method should we choose for a given resource management task. For the first question, four advantages are identified and discussed. For the second question, optimality gap, i.e., the gap to the optimal performance, is proposed as a measure for selecting model architectures, as well as, for enabling a theoretical comparison between different AI-based approaches. Specifically, for K-user interference management problem, we theoretically show that graph neural networks (GNNs) are superior to multi-layer perceptrons (MLPs), and the performance gap between these two methods grows with √K. © 2021 IEEE.","2-s2.0-85120485930"
"Arntz A.; Eimler S.C.; Hoppe H.U.","Arntz, Alexander (57209304162); Eimler, Sabrina C. (6506752642); Hoppe, H. Ulrich (34769829400)","57209304162; 6506752642; 34769829400","'The Robot-Arm Talks Back to Me' - Human Perception of Augmented Human-Robot Collaboration in Virtual Reality","2020","Proceedings - 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2020","","","9319082","307","312","5","10.1109/AIVR50618.2020.00062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100051139&doi=10.1109%2fAIVR50618.2020.00062&partnerID=40&md5=ff81062b0da7f329d85ebcad3b37bc70","The usage of AI enhanced robots in shared task environments is likely to become more and more common with the increase of digitalization in different industrial sectors. To take up this new challenge, research on the design of Human-Robot-Collaboration (HRC) involving AI-based systems has yet to establish common targets and guidelines. This paper presents results from an explorative qualitative study. Participants (N= 80) were either exposed to a virtual representation of an industrial robot-arm equipped with several augmentation channels for communication with the human operator (lights, textual statements about intentions, etc.) or one with no communicative functions at all. Across all conditions, participants recognized the benefit of collaborating with robots in industrial scenarios regarding work efficiency and alleviation of working conditions. However, a communication channel from the robot to the human is crucial for achieving these benefits. Participants interacting with the non-communicative robot expressed dissatisfaction about the workflow. In both conditions we found remarks about the insufficient speed of the robot-arm for an efficient collaborative process. Our results indicate a wider spectrum of questions to be further explored in the design of collaborative experiences with intelligent technological counterparts considering efficiency, safety, economic success and well-being.  © 2020 IEEE.","2-s2.0-85100051139"
"Calvaresi D.; Calbimonte J.-P.; Siboni E.; Eggenschwiler S.; Manzo G.; Hilfiker R.; Schumacher M.","Calvaresi, Davide (56358489700); Calbimonte, Jean-Paul (36719884300); Siboni, Enrico (57219804191); Eggenschwiler, Stefan (57215302659); Manzo, Gaetano (57189321881); Hilfiker, Roger (26648630400); Schumacher, Michael (22235461500)","56358489700; 36719884300; 57219804191; 57215302659; 57189321881; 26648630400; 22235461500","EREBOTS: Privacy-compliant agent-based platform for multi-scenario personalized health-assistant chatbots","2021","Electronics (Switzerland)","10","6","666","1","30","29","10.3390/electronics10060666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102393472&doi=10.3390%2felectronics10060666&partnerID=40&md5=54dafd673b5c9a1bc4464dbb158a4a28","Context. Asynchronous messaging is increasingly used to support human–machine inter-actions, generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g., work, leisure, and health-related) and are becoming ingrained into humans’ habits due to factors including (i) the availability of mobile devices such as smartphones and tablets, (ii) the increasingly engaging nature of chatbot interactions, (iii) the release of dedicated APIs from messaging platforms, and (iv) increasingly complex AI-based mechanisms to power the bots’ behav-iors. Nevertheless, most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches, neglecting personalization, data-stream privacy management, multi-topic management/interconnection, and multimodal interactions. Objective. This work ad-dresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e., Telegram, dedicated App, and web interface), (ii) enabling the configuration of multi-scenario behaviors (i.e., preventive physical conditioning, smoking cessa-tion, and support for breast-cancer survivors), (iii) online learning, (iv) personalized conversations and recommendations (i.e., mood boost, anti-craving persuasion, and balance-preserving physical exercises), and (v) responsive multi-device monitoring interface (i.e., doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age, gender, and country distribution have actively participated in the experimentation, reporting advancements in the physical balance and overall satisfaction of the interaction and exercises’ variety they have been proposed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85102393472"
"Böckle M.; Yeboah-Antwi K.; Kouris I.","Böckle, Martin (56556925800); Yeboah-Antwi, Kwaku (58188969200); Kouris, Iana (57226635179)","56556925800; 58188969200; 57226635179","Can You Trust the Black Box? The Effect of Personality Traits on Trust in AI-Enabled User Interfaces","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12797 LNAI","","","3","20","17","10.1007/978-3-030-77772-2_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112209426&doi=10.1007%2f978-3-030-77772-2_1&partnerID=40&md5=875ad270036a54dda71689faaaa4f9e7","Human-centred artificial intelligence is a fast-growing research stream within the artificial intelligence (AI) and human–computer interaction (HCI) communities. One key focus of this stream is the enablement of trust between end users and the intelligent solution. Although, the current body of literature discusses and proposes a range of best practices for the design of user interfaces for intelligent solutions, there is a dearth of research how such interfaces are perceived by users and especially focusing on trust in these interfaces. In this paper, we investigate how the Big Five personality traits affect trust in AI-enabled user interfaces. We then experimentally verify which design best practices and guidelines proposed by Google enable trust in AI-enabled user interfaces for the different personality types. Initial results (n = 211) reveal that three of the Big Five personality traits – Extraversion, Agreeableness and Open-Mindedness – show a significant correlation between the degree of the personality trait and trust in the proposed storyboards. In addition, we identified significant positive relationships between the perception of trust by users and four out of the twelve design principles: review implicit feedback; connect the feedback to UX changes; create opportunities for feedback; fail gracefully and highlight failure. This paper is of a highly explorative character and provides first experimental results on designing for trust to the HCI/AI community and also highlights future research directions in the form of a research agenda. © 2021, Springer Nature Switzerland AG.","2-s2.0-85112209426"
"Areiqat A.Y.; Alheet A.F.","Areiqat, Ahmad Yousef (36835453800); Alheet, Ahmad Fathi (57204912379)","36835453800; 57204912379","Artificial Intelligence and Its Impact on Public Management and Decision-Making","2021","Studies in Computational Intelligence","935","","","231","240","9","10.1007/978-3-030-62796-6_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101982648&doi=10.1007%2f978-3-030-62796-6_13&partnerID=40&md5=88ae37dfe66ac3befa5a2df4f5c9bdd7","Artificial Intelligence (AI) is a high-speed technology that influences our everyday lives. It is traditional to mean an artificial development of an intelligence that enables the learning, planification, perception, or process of natural language to create vast and ethical and socio-economic opportunities. As AI is a technology activated by the Internet, the Internet Society recognizes that an Internet with which people can trust is important to the creation of an opportunity and challenge associated with AI. At the same time, in this dynamic area, AI or machine learning problems are more common and involve concerns when it comes to users’ trust in the internet. This happens most frequently in goods and services. A variety of problems, including the socio-economic effects, concerns on openness, partiality, and accountability, new uses of data, health, ethical issues and how AI makes it easier to build new ecosystems, have to be addressed when it comes to dealing with AI. We plan to give policymakers and other players in the broader Internet ecosystem help in this chapter. Nonetheless, if it continues unabated some people find AI to be a threat to mankind. Others claim AI would create the possibility of mass unemployment, as opposed to past technological revolutions. This chapter describes the basics of the AI system, described key technology issues and challenges, examined the AI impacts on the performance of organizations and finally provided some guidelines for coping with this technology. © 2020, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85101982648"
"Rathee G.; Khelifi A.; Iqbal R.","Rathee, Geetanjali (56357928400); Khelifi, Adel (15057867500); Iqbal, Razi (56377142400)","56357928400; 15057867500; 56377142400","Artificial Intelligence- (AI-) Enabled Internet of Things (IoT) for Secure Big Data Processing in Multihoming Networks","2021","Wireless Communications and Mobile Computing","2021","","5754322","","","","10.1155/2021/5754322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113749668&doi=10.1155%2f2021%2f5754322&partnerID=40&md5=03a09e2be4c4d36f43a9f1685fad6af5","The automated techniques enabled with Artificial Neural Networks (ANN), Internet of Things (IoT), and cloud-based services affect the real-time analysis and processing of information in a variety of applications. In addition, multihoming is a type of network that combines various types of networks into a single environment while managing a huge amount of data. Nowadays, the big data processing and monitoring in multihoming networks provide less attention while reducing the security risk and efficiency during processing or monitoring the information. The use of AI-based systems in multihoming big data with IoT- and AI-integrated systems may benefit in various aspects. Although multihoming security issues and their analysis have been well studied by various scientists and researchers; however, not much attention is paid towards big data security processing in multihoming especially using automated techniques and systems. The aim of this paper is to propose an IoT-based artificial network to process and compute big data processing by ensuring a secure communication multihoming network using the Bayesian Rule (BR) and Levenberg-Marquardt (LM) algorithms. Further, the efficiency and effect on multihoming information processing using an AI-assisted mechanism are experimented over various parameters such as classification accuracy, classification time, specificity, sensitivity, ROC, and F-measure. © 2021 Geetanjali Rathee et al.","2-s2.0-85113749668"
"Alomari M.K.; Khan H.U.; Khan S.; Al-Maadid A.A.; Abu-Shawish Z.K.; Hammami H.","Alomari, Mohammad Kamel (55389149200); Khan, Habib Ullah (55507524000); Khan, Sulaiman (57212048687); Al-Maadid, Alanoud Ali (57193676470); Abu-Shawish, Zaki Khalid (57195243778); Hammami, Helmi (10143556900)","55389149200; 55507524000; 57212048687; 57193676470; 57195243778; 10143556900","Systematic Analysis of Artificial Intelligence-Based Platforms for Identifying Governance and Access Control","2021","Security and Communication Networks","2021","","8686469","","","","10.1155/2021/8686469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122538785&doi=10.1155%2f2021%2f8686469&partnerID=40&md5=374401ef194a0b9084307b9e0a397b4f","Artificial intelligence (AI) has become omnipotent with its variety of applications and advantages. Considering the other side of the coin, the eruption of technology has created situations that need more caution about the safety and security of data and systems at all levels. Thus, to hedge against the growing threats of cybersecurity, the need for a robust AI platform supported by machine learning and other supportive technologies is well recognized by organizations. AI is a much sought-after topic, and there is extolling literature available in repositories. Hence, a systematic arrangement of the literature that can help identify the right AI platform that can provide identity governance and access control is the need of the hour. Having this background, the present study is commissioned a Systematic Literature Review (SLR) to accomplish the necessity. Literature related to AI and Identity and Access Management (IAM) is collected from renowned peer-reviewed digital libraries for systematic analysis and assessment purposes using the systematic review guidelines. Thus, the final list of articles relevant to the framed research questions related to the study topic is fetched and is reviewed thoroughly. For the proposed systematic research work, the literature reported during the period ranging from 2016 to 2021 (a portion of 2021 is included) is analyzed and a total of 43 papers were depicted more relevant to the selected research domain. These articles were accumulated from ProQuest, Scopus, Taylor & Franics, Science Direct, and Wiley online repositories. The article's contribution can supplement the AI-based IAM information and steer the entities of diverse sectors concerning seamless implementation. Appropriate suggestions are proposed to encourage research work in the required fields.  © 2021 Mohammad Kamel Alomari et al.","2-s2.0-85122538785"
"Garain A.; Ray B.; Singh P.K.; Ahmadian A.; Senu N.; Sarkar R.","Garain, Avishek (57216330001); Ray, Biswarup (57219324655); Singh, Pawan Kumar (57205269219); Ahmadian, Ali (55602202100); Senu, Norazak (55670963500); Sarkar, Ram (13607482600)","57216330001; 57219324655; 57205269219; 55602202100; 55670963500; 13607482600","GRA_Net: A Deep Learning Model for Classification of Age and Gender from Facial Images","2021","IEEE Access","9","","9446083","85672","85689","17","10.1109/ACCESS.2021.3085971","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107371767&doi=10.1109%2fACCESS.2021.3085971&partnerID=40&md5=8e54c5e5abc4e5d4398b4c18b5c7c40f","The problem of gender and age identification has been addressed by many researchers, however, the attention given to it compared to the other related problems of face recognition in particular is far less. The success achieved in this domain has not seen much improvement compared to the other face recognition problems. Any language in the world has a separate set of words and grammatical rules when addressing people of different ages. The decision associated with its usage, relies on our ability to demarcate these individual characteristics like gender and age from the facial appearances at one glance. With the rapid usage of Artificial Intelligence (AI) based systems in different fields, we expect that such decision making capability of these systems match as much as to the human capability. To this end, in this work, we have designed a deep learning based model, called GRA-Net (Gated Residual Attention Network), for the prediction of age and gender from the facial images. This is a modified and improved version of Residual Attention Network where we have included the concept of Gate in the architecture. Gender identification is a binary classification problem whereas prediction of age is a regression problem. We have decomposed this regression problem into a combination of classification and regression problems for achieving better accuracy. Experiments have been done on five publicly available standard datasets namely FG-Net, Wikipedia, AFAD, UTKFAce and AdienceDB. Obtained results have proven its effectiveness for both age and gender classification, thus making it a proper candidate for the same against any other state-of-the-art methods.  © 2013 IEEE.","2-s2.0-85107371767"
"Kuk M.; Bobek S.; Nalepa G.J.","Kuk, Michał (57218769050); Bobek, Szymon (49661044900); Nalepa, Grzegorz J. (55879229400)","57218769050; 49661044900; 55879229400","Explainable clustering with multidimensional bounding boxes","2021","2021 IEEE 8th International Conference on Data Science and Advanced Analytics, DSAA 2021","","","","","","","10.1109/DSAA53316.2021.9564220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126103060&doi=10.1109%2fDSAA53316.2021.9564220&partnerID=40&md5=01a9460d34f0c6421f6f88c35f315a36","Explainable Artificial Intelligence (XAI) aims at introducing transparency and intelligibility into decision-making process of AI systems. Most of the work in this area is focused on supervised machine learning tasks such as classification and regression. Unsupervised algorithms such as clustering can also be explained with existing approaches. This is most often achieved by explaining a classifier trained on cluster data with cluster labels as a dependant variable. However, with such a transformation the information about cluster shape and distribution is lost, which may lead to wrong interpretation of explanations. In this paper, we introduce a method that aids end experts in cluster analysis with human-readable rule-based explanations. We use state-of-the-art explanation mechanism on the multidimensional bounding boxes that represent arbitrarily-shaped clusters. We demonstrate our approach on reproducible synthetic datasets. © 2021 IEEE.","2-s2.0-85126103060"
"Larasati R.; Liddo A.D.; Motta E.","Larasati, Retno (57197729397); Liddo, Anna De (13008594300); Motta, Enrico (7006092143)","57197729397; 13008594300; 7006092143","AI Healthcare System Interface: Explanation Design for Non-Expert User Trust","2021","CEUR Workshop Proceedings","2903","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110537156&partnerID=40&md5=7503134c25fb33e3b4c04db92fc19c8a","Research indicates that non-expert users tend to either over-trust or distrust AI systems. This raises concerns when AI is applied to healthcare, where a patient trusting the advice of an unreliable system, or completely distrusting a reliable one, can lead to fatal incidents or missed healthcare opportunities. Previous research indicated that explanations can help users to make appropriate judgements on AI Systems' trust, but how to design AI explanation interfaces for non-expert users in a medical support scenarios is still an open research challenge. This paper explores a stage-based participatory design process to develop a trustworthy explanation interface for non-experts in an AI medical support scenario. A trustworthy explanation is an explanation that helps users to make considered judgments on trusting (or not) and AI system for their healthcare. The objective of this paper was to identify the explanation components that can effectively inform the design of a trustworthy explanation interface. To achieve that, we undertook three data collections, examining experts' and non-experts' perceptions of AI medical support system's explanations. We then developed a User Mental Model, an Expert Mental Model, and a Target Mental Model of explanation, describing how non-expert and experts understand explanations, how their understandings differ, and how it can be combined. Based on the Target Mental Model, we then propose a set of 14 explanation design guidelines for trustworthy AI Healthcare System explanation, that take into account non-expert users needs, medical experts practice, and AI experts understanding. © 2020  Copyright © 2021 for this paper by its authors.","2-s2.0-85110537156"
"van der Waa J.; Nieuwburg E.; Cremers A.; Neerincx M.","van der Waa, Jasper (57193858656); Nieuwburg, Elisabeth (57220186178); Cremers, Anita (8313925500); Neerincx, Mark (9133405200)","57193858656; 57220186178; 8313925500; 9133405200","Evaluating XAI: A comparison of rule-based and example-based explanations","2021","Artificial Intelligence","291","","103404","","","","10.1016/j.artint.2020.103404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097186283&doi=10.1016%2fj.artint.2020.103404&partnerID=40&md5=2dc64f782fbf224d99b1f248a99de26e","Current developments in Artificial Intelligence (AI) led to a resurgence of Explainable AI (XAI). New methods are being researched to obtain information from AI systems in order to generate explanations for their output. However, there is an overall lack of valid and reliable evaluations of the effects on users' experience of, and behavior in response to explanations. New XAI methods are often based on an intuitive notion what an effective explanation should be. Rule- and example-based contrastive explanations are two exemplary explanation styles. In this study we evaluate the effects of these two explanation styles on system understanding, persuasive power and task performance in the context of decision support in diabetes self-management. Furthermore, we provide three sets of recommendations based on our experience designing this evaluation to help improve future evaluations. Our results show that rule-based explanations have a small positive effect on system understanding, whereas both rule- and example-based explanations seem to persuade users in following the advice even when incorrect. Neither explanation improves task performance compared to no explanation. This can be explained by the fact that both explanation styles only provide details relevant for a single decision, not the underlying rational or causality. These results show the importance of user evaluations in assessing the current assumptions and intuitions on effective explanations. © 2020 Elsevier B.V.","2-s2.0-85097186283"
"Narita K.; Akita M.; Kim K.-S.; Iwase Y.; Watanaka Y.; Nakagawa T.; Zhong Q.","Narita, Kenichiro (57557784900); Akita, Michitaka (57558555800); Kim, Kyoung-Sook (57184508400); Iwase, Yuta (57558026200); Watanaka, Yuichi (57559326400); Nakagawa, Takao (57558795400); Zhong, Qiang (57557504400)","57557784900; 57558555800; 57184508400; 57558026200; 57559326400; 57558795400; 57557504400","Qunomon: A FAIR testbed of quality evaluation for machine learning models","2021","Proceedings - Asia-Pacific Software Engineering Conference, APSEC","","","","21","24","3","10.1109/APSECW53869.2021.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127381337&doi=10.1109%2fAPSECW53869.2021.00015&partnerID=40&md5=de0f769da0c469d3d019f8e15413f5e4","Rapid development of artificial intelligence (AI) technologies brings quality and reliability issues to real-world applications and business products, as well as their advanced performance. However, traditional testing methods of the quality of engineering systems have difficulties supporting AI systems with machine learning (ML) based on large-scale data due to their uncertainty, non-deterministic, and vulnerability. Academic fields have studied new techniques to manage and guarantee high-quality ML components in AI systems with the importance of realizing trustworthy AI. Moreover, regulatory authorities have developed new guidelines and rules for safe and broad market adoption to control quality. Although there is a lot of effort from both sides, ML quality control and assessment pose challenges that arise from gaps between their different points of view. This paper proposes a new testbed called 'Qunomon (QUality + gNOMON)' that harmonizes gaps of two sides and supports the combination and comparison of various testing methods in ML component quality. The testbed is designed to improve the findability, accessibility, interoperability, and reusability of testing methods. Furthermore, we show the efficiency of quality testing and reporting with case studies where our testbed is applied. © 2021 IEEE.","2-s2.0-85127381337"
"Yang X.; Ho S.-B.","Yang, Xiwen (57207732724); Ho, Seng-Beng (56152356200)","57207732724; 56152356200","Simultaneous Causal Noise Removal for Causal Rule Discovery and Learning","2021","2021 IEEE Symposium Series on Computational Intelligence, SSCI 2021 - Proceedings","","","","","","","10.1109/SSCI50451.2021.9659961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125818556&doi=10.1109%2fSSCI50451.2021.9659961&partnerID=40&md5=f190b697e6b2b1b8ebea01d7b69f827d","Identifying cause and effect, or for that matter correlations, between events is critical for the operations of general AI or robotic systems. Being able to learn correlations or causalities enables the system to predict what future events may occur based on the currently observed events, or to know what actions can be taken to effect future consequences. This is useful for prediction and problem solving processes that are very important aspects of intelligent capabilities. However, the purported correlations or causalities are often accompanied by unrelated noisy events. The noise can intervene between the relevant events, and are termed diachronic causal or correlational noise. The noise can also occur concomitantly with the events of interest, and are termed simultaneous causal or correlational noise. While there has been previous work that addresses the issue of diachronic causal or correlational noise, simultaneous causal or correlational noise, especially in a symbolic rule learning process, has not been adequately addressed. This paper presents an algorithm to remove simultaneous causal noise in order to recover the correct causal rules involved. The same method can also be applied to a correlational situation. © 2021 IEEE.","2-s2.0-85125818556"
"Begum N.; Hazarika M.K.","Begum, Ninja (57658050900); Hazarika, Manuj Kumar (55661416100)","57658050900; 55661416100","Artificial Intelligence in Agri-Food Systems—An Introduction","2021","Studies in Big Data","99","","","45","63","18","10.1007/978-981-16-6210-2_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129211084&doi=10.1007%2f978-981-16-6210-2_3&partnerID=40&md5=32a7b041bb8fdd1d33faa5dc287bc324","Artificial intelligence (AI) is a replacement to human intelligence with expanded capabilities that has empowered the industries to handle and drive more complex systems. In agri-food industrial systems, an artificial intelligent system would drive a system towards the set objectives based on the information and knowledge gathered from the consumers, farmers, machines, and domain experts. Machine learning (ML) is the preferred tool to process the knowledge and information for identifying some underlying rules and patterns to support the implementation of the AI based solution. ML-based AI is preferred, because the heterogeneity in consumer preference, biological variability of material characteristics, and unpredictable system behavior presents a highly complex system to be handled by the rule based expert systems. This chapter gives an insight of the fundamentals of machine learning and deep learning with the emphasis on their application for AI implementation in the field of agri-food material handling. Popular ML algorithms viz., support vector machine (SVM), K-nearest neighbor (KNN), artificial neural networks (ANN), decision trees, and convolutional neural networks (CNN) are discussed as feature description methods for classification and recognition, based on the product images. Works from different researchers are cited to demonstrate the potential application of these techniques for solving real-life complex problems. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.","2-s2.0-85129211084"
"Parimbelli E.; Gabetta M.; Lanzola G.; Polce F.; Wilk S.; Glasspool D.; Kogan A.; Leizer R.; Gisko V.; Veggiotti N.; Panzarasa S.; de Groot R.; Ottaviano M.; Sacchi L.; Cornet R.; Peleg M.; Quaglini S.","Parimbelli, Enea (57195936697); Gabetta, Matteo (36188129400); Lanzola, Giordano (6602699444); Polce, Francesca (57224207156); Wilk, Szymon (7102743049); Glasspool, David (6602259798); Kogan, Alexandra (57207267935); Leizer, Roy (57224206947); Gisko, Vitali (57226377071); Veggiotti, Nicole (57226387118); Panzarasa, Silvia (13907744600); de Groot, Rowdy (57221091338); Ottaviano, Manuel (24723259500); Sacchi, Lucia (57192331744); Cornet, Ronald (57201825238); Peleg, Mor (55928701300); Quaglini, Silvana (55080856700)","57195936697; 36188129400; 6602699444; 57224207156; 7102743049; 6602259798; 57207267935; 57224206947; 57226377071; 57226387118; 13907744600; 57221091338; 24723259500; 57192331744; 57201825238; 55928701300; 55080856700","CAncer PAtients Better Life Experience (CAPABLE) First Proof-of-Concept Demonstration","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12721 LNAI","","","298","303","5","10.1007/978-3-030-77211-6_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111393299&doi=10.1007%2f978-3-030-77211-6_34&partnerID=40&md5=5d1d351ee9b7d3362da7c33e30008b50","The CAncer PAtient Better Life Experience (CAPABLE) project combines the most advanced technologies for data and knowledge management with a socio-psychological approach, to develop a coaching system for improving the quality of life of cancer patients managed at home. The team includes complementary expertise in data- and knowledge-driven AI, data integration, telemedicine and decision support. The time is right to fully exploit Artificial Intelligence for cancer care and bring the benefits right to patients’ homes. CAPABLE relies on predictive models based on both retrospective and prospective data, integrated with computer interpretable guidelines and made available to oncologists. CAPABLE’s Virtual Coach component identifies unexpected needs and provides patient-specific decision support and lifestyle guidance to improve mental and physical wellbeing of patients. The demo, designed around a use-case scenario developed with clinicians involved in the project, addresses the ESMO Diarrhea guideline. It revolves around a prototypical fictional patient named Maria. Maria, 66, is affected by renal cell carcinoma and moderate insomnia. The demo follows Maria during the first three days of using the CAPABLE system. This allows the audience to understand the scope and innovation behind this AI-based decision-support and coaching system that personalizes lifestyle and medication interventions to patients, their carer and clinicians. © 2021, Springer Nature Switzerland AG.","2-s2.0-85111393299"
"Schmager S.; Sousa S.","Schmager, Stefan (57352535200); Sousa, Sonia (54883324200)","57352535200; 54883324200","A Toolkit to Enable the Design of Trustworthy AI","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13095 LNCS","","","536","555","19","10.1007/978-3-030-90963-5_41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119841373&doi=10.1007%2f978-3-030-90963-5_41&partnerID=40&md5=b25c8a8a84fbe5f3c71385a4023d35b6","Technological progress in artificial intelligence (AI) and machine learning (ML) has an enormous impact on our society, economy and environment. And although the urgent need for creating sustainable and ethical AI technology is admitted, there exists a lack of design tools and expertise to facilitate this advancement. This study investigates how to help designers design for the value of trust in AI systems. A literature review unveiled a myriad of ethical AI principles as well as gathered existing tools addressing the research area. Iterative reviews together with an expert on trust in technology evaluated these guidelines and a first iteration of the toolkit containing 28 design principles had been created. Through multiple participatory design workshops the next iteration of the toolkit was co-designed in collaboration with design professionals. The result is an iterated toolkit comprising 16 principles relevant in the design for trust in AI systems, and providing tool suggestions for each principle. © 2021, Springer Nature Switzerland AG.","2-s2.0-85119841373"
"Ruiz C.; Quaresma M.","Ruiz, Cinthia (57226402090); Quaresma, Manuela (6603776143)","57226402090; 6603776143","UX Aspects of AI Principles: The Recommender System of VoD Platforms","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12781 LNCS","","","535","552","17","10.1007/978-3-030-78227-6_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132771708&doi=10.1007%2f978-3-030-78227-6_38&partnerID=40&md5=fd81456b489af167b83dbab0896829e6","This paper aims to investigate the user experience with recommender systems of Video on Demand (VoD) platforms based in Machine Learning (ML), focusing on the Artificial Intelligence (AI) principles. We start from the hypothesis that the inclusion of AI algorithms has the potential to improve the user experience in digital systems, but they are still developed with a greater focus on technology, however, they should also consider more aspects regarding human factors. Nine principles on AI related to UX were selected from a compilation of seven lists of government and industry entities to understand the bases that every AI system should respect to ensure a good user experience. In sequence, we discuss their effects on the user experience of VoD platforms. To finish, the experience with these platforms were explored in a directed storytelling method involving thirty-one participants. Some behaviors and patterns found were analyzed and discussed to suggest guidelines to be applied to ML algorithms of VoD Platforms. © Springer Nature Switzerland AG 2021.","2-s2.0-85132771708"
"Thakker D.; Mishra B.K.; Abdullatif A.; Mazumdar S.; Simpson S.","Thakker, Dhavalkumar (15062035000); Mishra, Bhupesh Kumar (57193168606); Abdullatif, Amr (57191254130); Mazumdar, Suvodeep (36696771100); Simpson, Sydney (57210377578)","15062035000; 57193168606; 57191254130; 36696771100; 57210377578","Explainable artificial intelligence for developing smart cities solutions","2020","Smart Cities","3","4","","1353","1382","29","10.3390/smartcities3040065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103519567&doi=10.3390%2fsmartcities3040065&partnerID=40&md5=f2c6c30c3c3ff732ff0bd0f278f6fda2","Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of ‘explainable deep learning’ as a subset of the ‘explainable AI’ problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts’ knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85103519567"
"Ramzanpour M.; Ludwig S.A.","Ramzanpour, Mohammadreza (57205526002); Ludwig, Simone A. (56221323400)","57205526002; 56221323400","Association Rule Mining Based Algorithm for Recovery of Silent Data Corruption in Convolutional Neural Network Data Storage","2020","2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020","","","9308545","3057","3064","7","10.1109/SSCI47803.2020.9308545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099686660&doi=10.1109%2fSSCI47803.2020.9308545&partnerID=40&md5=89bf1ca71d655837516f81243f4f90ee","Embedded systems are finding their way into almost every aspects of our daily life from mp3 players and console games to the mobile phones. Different Artificial Intelligence (AI) based applications are commonly utilized in embedded systems from which computer vision based approaches are included. The demand for higher accuracy in computer vision applications is associated with the increased complexity of convolutional neural networks and the storage requirement for saving pre-trained networks. Different factors can lead to the data corruption in the storage units of the embedded systems, which can result in drastic failures due to the propagation of the errors. Hence, the development of software-based algorithms for the detection and recovery of data corruption is crucial for improvement and failure-prevention of embedded systems. This paper proposes a new algorithm for the recovery of the data in the case of single event upset (SEU) error. The association rule mining based algorithm will be used to find the probability of the corruption in each of the bits. The recovery algorithm was tested on four different pre-trained ResNet (ResNet32 and ResNet110 at two different accuracy levels each) and the best recovery rate of 66% was found in the most complex scenario, i.e., random bit corruption. However, for the special cases of SEU errors, e.g. error in the frequently repeated bits, the recovery rate was found to be perfect with a value of 100%. © 2020 IEEE.","2-s2.0-85099686660"
"Uchida H.; Matsubara M.; Wakabayashi K.; Morishima A.","Uchida, Hikaru (57201690031); Matsubara, Masaki (55608696000); Wakabayashi, Kei (23399137900); Morishima, Atsuyuki (36829985300)","57201690031; 55608696000; 23399137900; 36829985300","Human-in-the-loop Approach towards Dual Process AI Decisions","2020","Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020","","","9378459","3096","3098","2","10.1109/BigData50022.2020.9378459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103827119&doi=10.1109%2fBigData50022.2020.9378459&partnerID=40&md5=62d15823f4053f21e8940fdead72cf50","How to develop AI systems that can explain how they made decisions is one of the important and hot topics today. Inspired by the dual-process theory in psychology, this paper proposes a human-in-the-loop approach to develop System-2 AI that makes an inference logically and outputs interpretable explanation. Our proposed method first asks crowd workers to raise understandable features of objects of multiple classes and collect training data from the Internet to generate classifiers for the features. Logical decision rules with the set of generated classifiers can explain why each object is of a particular class. In our preliminary experiment, we applied our method to an image classification of Asian national flags and examined the effectiveness and issues of our method. In our future studies, we plan to combine the System-2 AI with System-1 AI (e.g., neural networks) to efficiently output decisions. © 2020 IEEE.","2-s2.0-85103827119"
"Inan M.S.K.; Hasan R.; Prama T.T.","Inan, Muhammad Sakib Khan (57222612963); Hasan, Rizwan (57222612646); Prama, Tabia Tanzin (57223635723)","57222612963; 57222612646; 57223635723","An Integrated Expert System with a Supervised Machine Learning based Probabilistic Approach to Play Tic-Tac-Toe","2021","2021 IEEE 12th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2021","","","","116","120","4","10.1109/UEMCON53757.2021.9666728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125168732&doi=10.1109%2fUEMCON53757.2021.9666728&partnerID=40&md5=2649bd29ddfb49ce2dde3b23faf92988","Tic-Tac-Toe, also known as Noughts and Crosses, is a widely popular game among people of all ages. In recent times, due to the rapid development of Artificial Intelligence (AI) based algorithms, AI in Games has become an interesting topic for research in both academia and industry. Due to the complicated yet competent nature of AI algorithms, the design and implementation of such AI-driven approaches in games are challenging and time intensive. In this regard, we propose a supervised Machine Learning (ML)-based approach that contributes in designing an innovative and less complex Tic-Tac-Toc expert system. Integrating AI and ML in the solution process will lead the concerned community toward a more lightweight and computationally efficient systems for playing games. In this study, we propose a novel algorithmic solution by combining an ensemble-based boosting approach and rule-based inference to build a probabilistic expert system that strategically chooses the best optimal move for next possible state of the game. A benchmark dataset containing 255,168 unique game states of Tic Tac Toe was utilized at training stage. The proposed strategy is able to successfully settle a draw against never-loosing MiniMax algorithm in 18 standard test cases.  © 2021 IEEE.","2-s2.0-85125168732"
"Ehrlinger L.; Schrott J.; Melichar M.; Kirchmayr N.; Wöß W.","Ehrlinger, Lisa (57063205600); Schrott, Johannes (57274493000); Melichar, Martin (57275081100); Kirchmayr, Nicolas (57275379500); Wöß, Wolfram (6603077033)","57063205600; 57274493000; 57275081100; 57275379500; 6603077033","Data Catalogs: A Systematic Literature Review and Guidelines to Implementation","2021","Communications in Computer and Information Science","1479 CCIS","","","148","158","10","10.1007/978-3-030-87101-7_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115820982&doi=10.1007%2f978-3-030-87101-7_15&partnerID=40&md5=c3c7578b2ca96c198bf9003f78355301","In enterprises, data is usually distributed across multiple data sources and stored in heterogeneous formats. The harmonization and integration of data is a prerequisite to leverage it for AI initiatives. Recently, data catalogs pose a promising solution to semantically classify and organize data sources across different environments and to enrich raw data with metadata. Data catalogs therefore allow to create a single, clear, and easy-accessible interface for training and testing computational models. Despite a lively discussion among practitioners, there is little research on data catalogs. In this paper, we systematically review existing literature and answer the following questions: (1) What are the conceptual components of a data catalog? and (2) Which guidelines can be recommended to implement a data catalog? The results benefit practitioners in implementing a data catalog to accelerate any AI initiative and researchers with a compilation of future research directions. © 2021, Springer Nature Switzerland AG.","2-s2.0-85115820982"
"Nevanperä M.; Helin J.; Rajamäki J.","Nevanperä, Minna (57292031700); Helin, Jaakko (57291575600); Rajamäki, Jyri (6602563131)","57292031700; 57291575600; 6602563131","Comparison of European Commission's Ethical Guidelines for AI to Other Organizational Ethical Guidelines","2021","3rd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2021","","","","132","137","5","10.34190/EAIR.21.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143806279&doi=10.34190%2fEAIR.21.023&partnerID=40&md5=12da5f8f6c0b23cad82bdd32c86ce3d0","The European Commission's Ethical Guidelines for AI has a great relevance on the field since it is very thorough. Hagerdorff (2020) has evaluated 22 different ethical guidelines for AI. He found that in 80 per cent of the guidelines handle privacy, fairness and accountability as minimal requirements of responsible AI system. He also noted that these matters in addition to robustness and explainability are more easily solved as technical matters than the social issues that might be arising from the development of AI system. He found that the company codes of ethics were the most minimalistic which was also verified in our paper. Hagerdorff also found that the ethical guidelines usually do not commit to larger societal interests. This paper compares EC's ethical guidelines with those of IBM, Google and IEEE for getting a picture how the ethical issues are approached in commercial environment. The applied analysis method is data-driven; the ethical guidelines are examined and the common themes are noted to appear. The EC's ethical guidelines are the basis of the comparison. Noticed common themes of these guidelines are accountability, transparency and explainability, diversity, inclusion and fairness, safety and security, and societal wellbeing and humanity, even though all the themes are not discussed in all guidelines in detail. It seems that the ethical guidelines usually do not commit to larger societal interests because the societal issues and wider effects that AI has on the society are hard to write on the form of the simple guidelines. The discussion on the effects of the artificial intelligence on the societies needs to be addressed to political decision-makers and wider audience of researchers than just the developers of the AI or business organizations that exploit artificial intelligence. There is also need for involving the users and target groups to this discussion. © 2021 3rd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2021. All rights reserved.","2-s2.0-85143806279"
"Harris H.; Burke A.","Harris, Hannah (57217058095); Burke, Andrew (57215721260)","57217058095; 57215721260","Artificial Intelligence, Policing and Ethics - A best practice model for AI enabled policing in Australia","2021","Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOCW","","","","53","58","5","10.1109/EDOCW52865.2021.00032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123016547&doi=10.1109%2fEDOCW52865.2021.00032&partnerID=40&md5=63174bf9220d66c5649e433285430403","The application of Artificial Intelligence (AI) to policing processes and practices has transformative potential. Despite its potential, utilising AI for policing also comes with risks and challenges. The objective of this article is to provide a starting point for the development of a best practice model for the application of AI to policing in Australia. Such a best practice model would be the first of its kind and could put Australian police departments at the forefront of AI application - enabling Australian police to deploy AI in a way that has broad stake-holder support, maximising effectiveness and ensuring ethical concerns are adequately addressed  © 2021 IEEE.","2-s2.0-85123016547"
"Singh Y.S.; Kirani Y.; Singh Y.J.","Singh, Yumnam Somananda (57220813497); Kirani, Yumnam (57220812656); Singh, Yumnam Jayanta (57216827243)","57220813497; 57220812656; 57216827243","Local Analytical System for Early Epidemic Detection","2021","Lecture Notes on Data Engineering and Communications Technologies","60","","","29","37","8","10.1007/978-981-15-9682-7_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097662952&doi=10.1007%2f978-981-15-9682-7_4&partnerID=40&md5=1ba119db75cae4e0aaf98cb10b957902","An Epidemic is a big threat to humanity. To reduce its catastrophic effect, many clinical practices and AI-based models are introduced to detect the onset of future Epidemic. An Analytical System can be useful for the prediction of an epidemic by collecting Quality data, modelling them and visualizing in different dimensions. This study deals with designing a Local Analytical System for early Epidemic detection in which the data related to human regular needs and responses are stored in the in-cube format. Analytical rules are used to produced faster pre-computed and pre-summarized inputs of the warehouse. Some desired inputs are selected from many local Warehouses which are then consolidated to form an incremental next higher-level data using the Layered Architecture style. This system can find the most commonly deviated data from the most frequently occurred patterns in the data submitted from the participating warehouses. The above-summarized patterns are mined using an FP-Growth algorithm to predict a new pattern. The patterns are ranked and inspected with their correlations for a possible unknown Epidemic. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85097662952"
"Wright S.A.","Wright, Steven A. (57199462153)","57199462153","AI in the Law: Towards Assessing Ethical Risks","2020","Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020","","","9377950","2160","2169","9","10.1109/BigData50022.2020.9377950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103842801&doi=10.1109%2fBigData50022.2020.9377950&partnerID=40&md5=ad6a379d6a6bb7b60ee110193497911d","The exponential growth in data over the past decade has impacted the legal industry; both requiring automated solutions for the cost effective and efficient management of the volume and variety of big (legal) data; and, enabling artificial intelligence techniques based on machine learning for the analysis of that data. While many legal practitioners focus on specific services niches, the impact of AI in the law is much broader than individual niches. While AI systems and concerns for their ethical operation are not new, the scale of impact and adoption of AI systems in legal practice makes consideration of the ethics of these systems timely. While there has been recent progress in development of ethical guidelines for AI systems, much of this is targeted at the developers of these systems in general, or the actions of these AI systems as autonomous entities, rather than in the legal practice context. Much of the ethical guidance - whether for AI systems or legal professional is captured in high level principles within more narrowly defined domains, more specific guidance may be appropriate to identify and assess ethical risks. As adoption and operation of AI software in routine legal practice becomes more commonplace, more detailed guidance on assessing the scope and scale of ethical risks is needed. © 2020 IEEE.","2-s2.0-85103842801"
"Ahmad K.; Bano M.; Abdelrazek M.; Arora C.; Grundy J.","Ahmad, Khlood (57419307200); Bano, Muneera (36661996700); Abdelrazek, Mohamed (56080446200); Arora, Chetan (55848706400); Grundy, John (7102156137)","57419307200; 36661996700; 56080446200; 55848706400; 7102156137","What's up with Requirements Engineering for Artificial Intelligence Systems?","2021","Proceedings of the IEEE International Conference on Requirements Engineering","","","","1","12","11","10.1109/RE51729.2021.00008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120538358&doi=10.1109%2fRE51729.2021.00008&partnerID=40&md5=ab0058fcd692cf342f894173230c4e17","In traditional approaches to building software systems (that do not include an Artificial Intelligent (AI) or Machine Learning (ML) component), Requirements Engineering (RE) activities are well-established and researched. However, building software systems with one or more AI components may depend heavily on data with limited or no insight into the system's workings. Therefore, engineering such systems poses significant new challenges to RE. Our search showed that literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI). Our study's main objective was to investigate current approaches in writing requirements for AI/ML systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. We performed a Systematic Literature Review (SLR) of current RE4AI methods and identified 27 primary studies. Using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing RE4AI practices. We further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in Google PAIR). The SLR findings highlighted that present RE applications were not adaptive to manage most AI/ML systems and emphasised the need to provide new techniques and tools to support RE4AI.  © 2021 IEEE.","2-s2.0-85120538358"
"Przybyszewski A.W.","Przybyszewski, Andrzej W. (6603763540)","6603763540","Theory of Mind Helps to Predict Neurodegenerative Processes in Parkinson’s Disease","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12744 LNCS","","","542","555","13","10.1007/978-3-030-77967-2_45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111356375&doi=10.1007%2f978-3-030-77967-2_45&partnerID=40&md5=5997d909c7e395789ba9d967b1bcb5c1","Normally, it takes many years of theoretical and clinical training for a physician to be the movement disorder specialist. It takes additional multiple years of the clinical practice to handle various “non-typical” cases. The purpose of our study was to predict neurodegenerative disease development by abstract rules learned from experienced neurologists. Theory of mind (ToM) is human’s ability to represent mental states such as emotions, intensions or knowledge of others. ToM is crucial not only in human social interactions but also is used by neurologists to find an optimal treatment for patients with neurodegenerative pathologies such as Parkinson’s disease (PD). On the basis of doctors’ expertise, we have used supervised learning to build AI system that consists of abstract granules representing ToM of several movement disorders neurologists (their knowledge and intuitions). We were looking for similarities between granules of patients in different disease stages to granules of more advanced PD patients. We have compared group of 23 PD with attributes measured three times every half of the year (G1V1, G1V2, G1V3) to other group of 24 more advanced PD (G2V1). By means of the supervised learning and rough set theory we have found rules describing symptoms of G2V1 and applied them to G1V1, G1V2, and G1V3. We have obtained the following accuracies for all/speed/emotion/cognition attributes: G1V1: 68/59/53/72%; G1V2: 72/70/79/79%; G1V3: 82/92/71/74%. These results support our hypothesis that divergent sets of granules were characteristic for different brain’s parts that might degenerate in non-uniform ways with Parkinson’s disease progression. © 2021, Springer Nature Switzerland AG.","2-s2.0-85111356375"
"Li C.; Yang H.J.","Li, Chen (57192578646); Yang, Hong Ji (35070638900)","57192578646; 35070638900","Bot-X: An AI-based virtual assistant for intelligent manufacturing","2021","Multiagent and Grid Systems","17","1","","1","14","13","10.3233/MGS-210340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105019794&doi=10.3233%2fMGS-210340&partnerID=40&md5=7bd85ba02b690bb6d23a2b1f005ee8b0","In light of recent trends toward introducing Artificial Intelligence (AI) to enhance the Human Machine Interface (HMI), companies need to identify the key issues of the communication between operator and production machines. Despite the fact that the industrial company starts to introduce chatbots to assist the communication between humans and machines, the virtual assistant (or digital assistant) by using human natural language is still widely required in the manufacturing domain. In this paper, we introduce an AI-based virtual assistant, Bot-X, for the manufacturing industry to handle a variety of complex services, e.g., order processing, production execution. This work expands the idea in three directions. Firstly, we introduce the design motivation of Bot-X, e.g., knowledge boundary in the manufacturing context. Secondly, the design principle of Bot-X is presented, including the framework, system architecture, model architecture, and the core algorithm. Then, three scenarios are presented to test the Bot-X usability and flexibility regarding the manufacturing environment.  © 2021 - IOS Press. All rights reserved.","2-s2.0-85105019794"
"Zicari R.V.; Brusseau J.; Blomberg S.N.; Christensen H.C.; Coffee M.; Ganapini M.B.; Gerke S.; Gilbert T.K.; Hickman E.; Hildt E.; Holm S.; Kühne U.; Madai V.I.; Osika W.; Spezzatti A.; Schnebel E.; Tithi J.J.; Vetter D.; Westerlund M.; Wurth R.; Amann J.; Antun V.; Beretta V.; Bruneault F.; Campano E.; Düdder B.; Gallucci A.; Goffi E.; Haase C.B.; Hagendorff T.; Kringen P.; Möslein F.; Ottenheimer D.; Ozols M.; Palazzani L.; Petrin M.; Tafur K.; Tørresen J.; Volland H.; Kararigas G.","Zicari, Roberto V. (6601913906); Brusseau, James (57221720725); Blomberg, Stig Nikolaj (57205544956); Christensen, Helle Collatz (57213901006); Coffee, Megan (56600546500); Ganapini, Marianna B. (57190390251); Gerke, Sara (57199176578); Gilbert, Thomas Krendl (57210411782); Hickman, Eleanore (56398173700); Hildt, Elisabeth (24479649800); Holm, Sune (55376827900); Kühne, Ulrich (58722378800); Madai, Vince I. (36145221300); Osika, Walter (14018523100); Spezzatti, Andy (57221100489); Schnebel, Eberhard (6506606437); Tithi, Jesmin Jahan (55658165000); Vetter, Dennis (57777020900); Westerlund, Magnus (56288627500); Wurth, Renee (57209603518); Amann, Julia (57189727341); Antun, Vegard (57219544822); Beretta, Valentina (57204919271); Bruneault, Frédérick (57224437713); Campano, Erik (58001442500); Düdder, Boris (55794748200); Gallucci, Alessio (57220076612); Goffi, Emmanuel (56010196600); Haase, Christoffer Bjerre (57208298663); Hagendorff, Thilo (57194142411); Kringen, Pedro (57776793700); Möslein, Florian (55824608900); Ottenheimer, Davi (58304084500); Ozols, Matiss (57200243340); Palazzani, Laura (6603503331); Petrin, Martin (55229854300); Tafur, Karin (58722379400); Tørresen, Jim (6602518300); Volland, Holger (58722650700); Kararigas, Georgios (36189316500)","6601913906; 57221720725; 57205544956; 57213901006; 56600546500; 57190390251; 57199176578; 57210411782; 56398173700; 24479649800; 55376827900; 58722378800; 36145221300; 14018523100; 57221100489; 6506606437; 55658165000; 57777020900; 56288627500; 57209603518; 57189727341; 57219544822; 57204919271; 57224437713; 58001442500; 55794748200; 57220076612; 56010196600; 57208298663; 57194142411; 57776793700; 55824608900; 58304084500; 57200243340; 6603503331; 55229854300; 58722379400; 6602518300; 58722650700; 36189316500","On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls","2021","Frontiers in Human Dynamics","3","","673104","","","","10.3389/fhumd.2021.673104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177815584&doi=10.3389%2ffhumd.2021.673104&partnerID=40&md5=8c82bbbf634ed47bce98b905d8326140","Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice. Copyright © 2021 Zicari, Brusseau, Blomberg, Christensen, Coffee, Ganapini, Gerke, Gilbert, Hickman, Hildt, Holm, Kühne, Madai, Osika, Spezzatti, Schnebel, Tithi, Vetter, Westerlund, Wurth, Amann, Antun, Beretta, Bruneault, Campano, Düdder, Gallucci, Goffi, Haase, Hagendorff, Kringen, Möslein, Ottenheimer, Ozols, Palazzani, Petrin, Tafur, Tørresen, Volland and Kararigas.","2-s2.0-85177815584"
"Davahli M.R.; Karwowski W.; Fiok K.; Wan T.; Parsaei H.R.","Davahli, Mohammad Reza (57218517550); Karwowski, Waldemar (35600960600); Fiok, Krzysztof (36607907800); Wan, Thomas (7103236795); Parsaei, Hamid R. (7004106551)","57218517550; 35600960600; 36607907800; 7103236795; 7004106551","Controlling safety of artificial intelligence‐based systems in healthcare","2021","Symmetry","13","1","102","1","25","24","10.3390/sym13010102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099263217&doi=10.3390%2fsym13010102&partnerID=40&md5=36b6a91580e029d4ffd57416e27d9c27","In response to the need to address the safety challenges in the use of artificial intelligence (AI), this research aimed to develop a framework for a safety controlling system (SCS) to address the AI black‐box mystery in the healthcare industry. The main objective was to propose safety guidelines for implementing AI black‐box models to reduce the risk of potential healthcare‐related incidents and accidents. The system was developed by adopting the multi‐attribute value model approach (MAVT), which comprises four symmetrical parts: extracting attributes, generating weights for the attributes, developing a rating scale, and finalizing the system. On the basis of the MAVT approach, three layers of attributes were created. The first level contained six key dimensions, the second level included 14 attributes, and the third level comprised 78 attributes. The key first level dimensions of the SCS included safety policies, incentives for clinicians, clinician and patient training, communication and interaction, planning of actions, and control of such actions. The proposed system may provide a basis for detecting AI utilization risks, preventing incidents from occurring, and developing emergency plans for AI‐related risks. This approach could also guide and control the implementation of AI systems in the healthcare industry. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85099263217"
"Shanti M.Z.; Cho C.-S.; Byon Y.-J.; Yeun C.Y.; Kim T.-Y.; Kim S.-K.; Altunaiji A.","Shanti, Mohammad Z. (57386970300); Cho, Chung-Suk (57196022684); Byon, Young-Ji (23994896700); Yeun, Chan Yeob (6508380997); Kim, Tae-Yeon (56160127800); Kim, Song-Kyoo (57206675586); Altunaiji, Ahmed (37081155300)","57386970300; 57196022684; 23994896700; 6508380997; 56160127800; 57206675586; 37081155300","A Novel Implementation of an AI-Based Smart Construction Safety Inspection Protocol in the UAE","2021","IEEE Access","9","","","166603","166616","13","10.1109/ACCESS.2021.3135662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121771436&doi=10.1109%2fACCESS.2021.3135662&partnerID=40&md5=d9de723d2f18c74b35940aa1e0c4e2ec","The safety of workers at construction sites is one of the most important aspects that should be considered while performing their required tasks. Many rules and regulations have been implemented in the UAE to reduce injuries and fatalities in the jobsites. However, the number of accidents continues to increase. For instance, an accident category of fall-from-height is considered as the top cause of injuries and fatalities. Thus, this paper develops a novel technique that monitors the workers whether they are complying with a safety standard of the Personal Fall Arrest System (PFAS). This paper establishes a real time detection algorithm based on a Convolutional Neural Network (CNN) model in order to detect two main components of the PFAS that are, safety harness and life-line, in addition to a standard safety measure of using a safety helmet. The YOLOv3 algorithm is adopted for a deep learning network used to train the desired model. The model achieved an accuracy rate of 91.26% and around 99% precision. Moreover, the overall recall of the model was 90.2%. The obtained results verify the effectiveness of our proposed model in construction sites to control potential violations and to avoid unnecessary accidents. The main contribution of this paper is to provide an AI-based image detection framework to mitigate the likelihood of fall-from-height accidents.  © 2013 IEEE.","2-s2.0-85121771436"
"Bonsón E.; Alejo V.; Lavorato D.","Bonsón, Enrique (8935661200); Alejo, Víctor (57227057800); Lavorato, Domenica (57219569219)","8935661200; 57227057800; 57219569219","Artificial Intelligence Disclosure in the Annual Reports of Spanish IBEX-35 Companies (2018–2019)","2021","Lecture Notes in Information Systems and Organisation","44","","","147","155","8","10.1007/978-3-030-73261-5_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113302895&doi=10.1007%2f978-3-030-73261-5_14&partnerID=40&md5=169213e2eda79ea35175d50fe72932c1","This paper explores the information on Artificial Intelligence (AI) that Spanish IBEX 35 listed companies are including in their annual/sustainability reports. The study mainly focuses on the AI systems that companies indicate they are using or developing, the projects they are tackling and the extent to which they follow some principles or ethical guidelines when using AI-based technologies. The study analyses, both from a qualitative and quantitative perspective, the content of the reports of IBEX 35 companies for 2018 and 2019. The findings suggest that although AI reporting is growing because of the interest in these technologies, it is growing in a non-structured way, and that the adoption of ethical approaches to AI is at a very preliminary stage. The paper analyzes some evidence about a part of non-financial disclosure, AI disclosure, which has not been explored yet. It may serve as a starting point for researchers and companies interested in developing clear guidelines on what kind of information is relevant and mandatory for companies to report, what ethical principles or regulations AI applications must follow and how it has to be disclosed. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85113302895"
"Stumpf S.; Strappelli L.; Ahmed S.; Nakao Y.; Naseer A.; Gamba G.D.; Regoli D.","Stumpf, Simone (10239347500); Strappelli, Lorenzo (57226129943); Ahmed, Subeida (57212960784); Nakao, Yuri (57207916666); Naseer, Aisha (22635523000); Gamba, Giulia Del (57222724819); Regoli, Daniele (23973503900)","10239347500; 57226129943; 57212960784; 57207916666; 22635523000; 57222724819; 23973503900","Design Methods for Artificial Intelligence Fairness and Transparency","2021","CEUR Workshop Proceedings","2903","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110508546&partnerID=40&md5=c9528fa9c5915e2957e740ce9f79d387","Fairness and transparency in artificial intelligence (AI) continue to become more prevalent as topics for research, design and development. General principles and guidelines for designing ethical and responsible AI systems have been proposed, yet there is a lack of design methods for these kinds of systems. In this paper, we present CoFAIR, a novel method to design user interfaces for exploring fairness, consisting of series of co-design workshops, and wider evaluation. This method can be readily applied in practice by researchers, designers and developers to create responsible and ethical AI systems. ©2021 Copyright for this paper by its authors.","2-s2.0-85110508546"
"Medgyes B.; Illes B.; Krammer O.; Tzanova S.; Gavra S.","Medgyes, B. (24341807100); Illes, B. (24080029800); Krammer, O. (14024484200); Tzanova, S. (6603644981); Gavra, S. (57454709800)","24341807100; 24080029800; 14024484200; 6603644981; 57454709800","Curriculum and Training Development in the METIS project","2021","2021 IEEE 27th International Symposium for Design and Technology in Electronic Packaging, SIITME 2021 - Conference Proceedings","","","","258","263","5","10.1109/SIITME53254.2021.9663582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124685184&doi=10.1109%2fSIITME53254.2021.9663582&partnerID=40&md5=adf943d9440d602fb06029f746b3dc4c","To improve its competitiveness, the EU microelectronics area needs to overcome critical skills deficits. In this context, METIS (MicroElectronics Training, Industry and Skills) gives an individual European partnership establishing a sustainable structure to: Analyze main global biases effecting on the area and offer strategic insights and foresights, predict rising skills demands, identify job rules/jobs of the future, determine important occupational profiles and observe progress in the domain of human capital for microelectronics, develop a Sector Skills Strategy to support the global leadership of the EU microelectronics industry, establishing operational linkages between skills and the future of the area, federate European synergies towards the needs of data-driven technologies such as artificial intelligence (AI) enabled by advanced microelectronics and its skills demands, establish an EU Microelectronics Observatory Skills Council, plan and produce a modular and blended curriculum, integrating work-oriented learning that uses open education resources (OER), pave the way for the pan-European recognition of innovative Vocational Education and Training (VET), use innovative tools such as industry mentoring to facilitate inter-generational transfer of knowledge in the area, embed social (diversity inclusion) and environmental sustainability (circular economy) subjects and EU policy aims in the development of workforce.  © 2021 IEEE.","2-s2.0-85124685184"
"Mehfooz F.; Jha S.; Singh S.; Saini S.; Sharma N.","Mehfooz, Fahad (57221105756); Jha, Sakshi (57221084658); Singh, Sahil (57221084236); Saini, Shreya (57221093889); Sharma, Nidhi (57682142400)","57221105756; 57221084658; 57221084236; 57221093889; 57682142400","Medical Chatbot for Novel COVID-19","2021","Lecture Notes in Networks and Systems","154","","","423","430","7","10.1007/978-981-15-8354-4_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098136136&doi=10.1007%2f978-981-15-8354-4_42&partnerID=40&md5=c8d8ee412d670ba3628187cfa97fc65f","Conversational agents or more universally known as the chatbot were industrialized to respond to user’s queries in a particular domain. Chatbot would serve as a software delegate which enables a computer to converse with human via natural language. A chatbot is a human-like conversational character (Shaikh et al. Int J Eng Sci Comput 6:3117–3119, 2016 [1]. This technology was coined in 1960s, with the intention to impersonate a human (how he would reply to a particular situation) so that the user feels that he is talking to a real person and not a machine. Conversational agent that interacts with user’s turn by turn using natural language (Shawar A, Atwell E (2005) ICAME J Int Comput Arch Mod Med English J 29, 5–24, 2005 [2]). The world of chatbot has seen much of the advance since the invention, and they have progressed from conventional rule-based chatbot to unorthodox AI-based chatbot. The chat agents are expert in their fields [3]. The prime focus of this paper is to show implementation of a retrieval-based chabot with voice support, and we will investigate other standing chatbot and how it is useful in helping the patients fetching all the necessary details about COVID-19. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","2-s2.0-85098136136"
"Satyaloka D.; Giamiko S.; Hidayat A.","Satyaloka, Dio (57546264900); Giamiko, Stacyana (57547033600); Hidayat, Akik (57194832655)","57546264900; 57547033600; 57194832655","SK-MOEFS Multi-Objective Evolutionary Fuzzy System Library effectiveness as User-Friendly Cryptocurrency Prediction Tool","2021","2021 International Conference on Artificial Intelligence and Big Data Analytics, ICAIBDA 2021","","","","242","246","4","10.1109/ICAIBDA53487.2021.9689763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126974193&doi=10.1109%2fICAIBDA53487.2021.9689763&partnerID=40&md5=00a62e5ef78bcd86827844b17bad5c1b","The emergence of Cryptocurrency has long foreshadowed a more accessible exchange market. Cryptocurrency is easy to use and trade, and this ease of access into the market brought newcomers into the Crypto-trading scene. This surge of inexperienced newcomers causes market instability and major loss amongst themselves. AI models, algorithms, and systems have been long used as an important aspect of prediction. However, the use of AI systems is complex. AI tools and systems often use complicated mathematical formulas and are not easily understood. Amongst these AI systems, Fuzzy Rule-Based Systems (FRBSs) has one of the most easily understood displays. With accuracy that rivals of other less-understood methods, such as Neural Network, FRBSs present us a choice that is easily used by users while keeping the interface as basic and simple as possible. This paper aims to study the use of FRBSs using SK-MOEFS (SciKit-Multi Objective Evolutionary Fuzzy System) Python Library in predicting a bull signal or a bear signal in the Cryptocurrency market while still preserving FRBSs user-friendly nature. The fuzzy sets are partitioned as Very Low, Low, Medium, High, and Very High. Then the resulting classification are used to signal whether a Cryptocurrency is bearish or bullish on the current day. The parameter used on the system yields an undesirable result of 53% accuracy with 25 Total Rule Length, however still producing the desired ease-of-use nature of FRBSs.  © 2021 IEEE.","2-s2.0-85126974193"
"Curry A.C.; Abercrombie G.; Rieser V.","Curry, Amanda Cercas (57200410103); Abercrombie, Gavin (57224891279); Rieser, Verena (24345304600)","57200410103; 57224891279; 24345304600","ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational AI","2021","EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings","","","","7388","7403","15","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121622933&partnerID=40&md5=fa057a4b7a845d8ccdd11f6211b0db09","We present the first English corpus study on abusive language towards three conversational AI systems gathered 'in the wild': an open-domain social bot, a rule-based chatbot, and a task-based system. To account for the complexity of the task, we take a more 'nuanced' approach where our ConvAI dataset reflects fine-grained notions of abuse, as well as views from multiple expert annotators. We find that the distribution of abuse is vastly different compared to other commonly used datasets, with more sexually tinted aggression towards the virtual persona of these systems. Finally, we report results from bench-marking existing models against this data. Unsurprisingly, we find that there is substantial room for improvement with F1 scores below 90%. © 2021 Association for Computational Linguistics","2-s2.0-85121622933"
"Vakkuri V.; Jantunen M.; Halme E.; Kemell K.-K.; Nguyen-Duc A.; Mikkonen T.; Abrahamsson P.","Vakkuri, Ville (57203640458); Jantunen, Marianna (57217089350); Halme, Erika (57222063097); Kemell, Kai-Kristian (57203633786); Nguyen-Duc, Anh (55925400800); Mikkonen, Tommi (57220096141); Abrahamsson, Pekka (7006011356)","57203640458; 57217089350; 57222063097; 57203633786; 55925400800; 57220096141; 7006011356","Time for AI (Ethics) maturity model is now","2021","CEUR Workshop Proceedings","2808","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101250684&partnerID=40&md5=ae29854c16765f30a08f71d9197fb39d","There appears to be a common agreement that ethical concerns are of high importance when it comes to systems equipped with some sort of Artificial Intelligence (AI). Demands for ethical AI are declared from all directions. As a response, in recent years, public bodies, governments, and universities have rushed in to provide a set of principles to be considered when AI based systems are designed and used. We have learned, however, that high-level principles do not turn easily into actionable advice for practitioners. Hence, also companies are publishing their own ethical guidelines to guide their AI development. This paper argues that AI software is still software and needs to be approached from the software development perspective. The software engineering paradigm has introduced maturity model thinking, which provides a roadmap for companies to improve their performance from the selected viewpoints known as the key capabilities. We want to voice out a call for action for the development of a maturity model for AI software. We wish to discuss whether the focus should be on AI ethics or, more broadly, the quality of an AI system, called a maturity model for the development of AI systems. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85101250684"
"Milea D.; Najjar R.","Milea, Dan (6701636955); Najjar, Raymond (55376172800)","6701636955; 55376172800","Artificial Intelligence in Neuro-ophthalmology","2021","Artificial Intelligence in Ophthalmology","","","","239","242","3","10.1007/978-3-030-78601-4_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160717617&doi=10.1007%2f978-3-030-78601-4_21&partnerID=40&md5=1d8f5ef209f511518699dd96971aa138","Despite the current hype in almost every area of the society and medicine, artificial intelligence (AI) is not very new. Machine learning (ML), one of the first AI methods, was described in the 50s, followed recently by an extraordinary technical development of computers and processing power leading to the current achievements of deep learning (DL). DL is the current state-of-art technique in ML, particularly well adapted for image analysis. DL techniques have allowed new algorithms to make predictions on various outcomes and diagnosis, based on « learning » (training) on large datasets, using either a supervised (labelled data) or un-supervised (unlabelled data) approach. As in other areas of DL, the input data is used for training purposes and needs to be selected according to the highest clinical diagnostic standards, because it represents the « ground truth » or the « reference standard ». All the results provided by a DL algorithm will be compared to this ground truth. After the training phase, the performance of the algorithm is tested, first via internal validation (cross-validation) and, more importantly, via external testing (in totally novel datasets). The datasets used for training, internal validation and external testing need to be distinct and should not intersect at any time. The performance of an algorithm is expressed as diagnostic accuracy, sensitivity, specificity and area under the receiving operating curve (AUC), compared to the reference standard. The current, extraordinary boom of AI requires a high need of rigorous, controlled, prospective evaluations to demonstrate the impact of AI systems in health outcomes. In response to this need, AI consensus groups have recently elaborated international guidelines regarding AI interventions, including instructions and skills required for use of AI systems, including considerations for the handling of input and output data, the human–AI interaction and analysis of error cases [1]. © Springer Nature Switzerland AG 2021. All rights are reserved.","2-s2.0-85160717617"
"Shchanikov S.; Bordanov I.; Belov A.; Korolev D.; Shamshin M.; Gryaznov E.; Kazantsev V.; Mikhaylov A.; Makarov V.A.","Shchanikov, Sergey (56440216400); Bordanov, Ilya (57210341196); Belov, Alexey (7202832059); Korolev, Dmitry (57217519896); Shamshin, Maxim (57205658136); Gryaznov, Evgeny (56503868300); Kazantsev, Victor (7005605401); Mikhaylov, Alexey (6701888444); Makarov, Valeri A. (7401690155)","56440216400; 57210341196; 7202832059; 57217519896; 57205658136; 56503868300; 7005605401; 6701888444; 7401690155","Memristive Concept of a High-Dimensional Neuron","2021","Proceedings - 3rd International Conference ""Neurotechnologies and Neurointerfaces"", CNN 2021","","","","96","99","3","10.1109/CNN53494.2021.9580310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126259036&doi=10.1109%2fCNN53494.2021.9580310&partnerID=40&md5=abaed1e70c19280c2a3f0e2411b19671","We propose a novel concept of a hardware implementation of high-dimensional neurons with the aim of a functional simulation of the human hippocampus. To implement a high-dimensional neuron, we suggest using the arrays of trainable memristive devices as part of the custom-made software-hardware system to provide full neuronal functionality with fine-tuning of synaptic weights according to the self-learning rule. The proposed architecture can enable new efficient approaches to processing big data in artificial intelligence (AI) systems and a new generation of robots. © 2021 IEEE.","2-s2.0-85126259036"
"Nieuważny J.; Nowakowski K.; Ptaszyński M.; Masui F.; Rzepka R.; Araki K.","Nieuważny, Jagna (57210286846); Nowakowski, Karol (57210290820); Ptaszyński, Michal (25960287400); Masui, Fumito (56078264200); Rzepka, Rafal (6603550196); Araki, Kenji (7402551308)","57210286846; 57210290820; 25960287400; 56078264200; 6603550196; 7402551308","Does change in ethical education influence core moral values? Towards history- and culture-aware morality model with application in automatic moral reasoning","2021","Cognitive Systems Research","66","","","89","99","10","10.1016/j.cogsys.2020.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097337309&doi=10.1016%2fj.cogsys.2020.10.011&partnerID=40&md5=f7dac1f66b112b5b56e91c3b59992a77","In this study, we focus on ethical education as a means to improve artificial companion's conceptualization of moral decision-making process in human users. In particular, we focus on automatically determining whether changes in ethical education influenced core moral values in humans throughout the century. We analyze ethics as taught in Japan before WWII and today to verify how much the pre-WWII moral attitudes have in common with those of contemporary Japanese, to what degree what is taught as ethics in school overlaps with the general population's understanding of ethics, as well as to verify whether a major reform of the guidelines for teaching the school subject of “ethics” at school after 1946 has changed the way common people approach core moral questions (such as those concerning the sacredness of human life). We selected textbooks used in teaching ethics at school from between 1935 and 1937, and those used in junior high schools today (2019) and analyzed what emotional and moral associations such contents generated. The analysis was performed with an automatic moral and emotional reasoning agent and based on the largest available text corpus in Japanese as well as on the resources of a Japanese digital library. As a result, we found out that, despite changes in stereotypical view on Japan's moral sentiments, especially due to historical events, past and contemporary Japanese share a similar moral evaluation of certain basic moral concepts, although there is a large discrepancy between how they perceive some actions to be beneficial to the society as a whole while at the same time being inconclusive when it comes to assessing the same action's outcome on the individual performing them and in terms of emotional consequences. Some ethical categories, assessed positively before the war, while being associated with a nationalistic trend in education have also disappeared from the scope of interest of post- war society. The findings of this study support suggestions proposed by others that the development of personal AI systems requires supplementation with moral reasoning. Moreover, the paper builds upon this idea and further suggests that AI systems need to be aware of ethics not as a constant, but as a function with a correction on historical and cultural changes in moral reasoning. © 2020 Elsevier B.V.","2-s2.0-85097337309"
"Casas-Roma J.; Conesa J.","Casas-Roma, Joan (57197726226); Conesa, Jordi (22333384000)","57197726226; 22333384000","A literature review on artificial intelligence and ethics in online learning","2021","Intelligent Systems and Learning Data Analytics in Online Education","","","","111","131","20","10.1016/B978-0-12-823410-5.00006-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124792048&doi=10.1016%2fB978-0-12-823410-5.00006-1&partnerID=40&md5=70e44ffe82e17afeafee00db619693e2","In recent years, artificial intelligence (AI) has been used in online learning to improve teaching and learning, with the aim of providing a more efficient, purposeful, adaptive, ubiquitous, and fair learning experiences. However, and as it has been seen in other contexts, the integration of AI can have unforeseen consequences with detrimental effects which can result in unfair and discriminatory decisions. Therefore it is worth thinking about potential risks that learning environments integrating AI systems might pose. This work explores the intersections between AI, online learning, and ethics in order to understand the ethical concerns surrounding this crossroads. We review the main ethical challenges identified in the literature and distill a set of guidelines to support the ethical design and integration of AI systems in online learning environments. This should help ensure that online learning is how is meant to be: accessible, inclusive, fair, and beneficial to society. © 2021 Elsevier Inc. All rights reserved.","2-s2.0-85124792048"
"Prokic S.; Grujic K.-G.; Luburic N.; Slivka J.; Kovacevic A.; Vidakovic D.; Sladic G.","Prokic, Simona (57417181300); Grujic, Katarina-Glorija (57417316900); Luburic, Nikola (57191406831); Slivka, Jelena (36700444700); Kovacevic, Aleksandar (27967812900); Vidakovic, Dragan (19934628500); Sladic, Goran (6506063604)","57417181300; 57417316900; 57191406831; 36700444700; 27967812900; 19934628500; 6506063604","Clean Code and Design Educational Tool","2021","2021 44th International Convention on Information, Communication and Electronic Technology, MIPRO 2021 - Proceedings","","","","1601","1606","5","10.23919/MIPRO52101.2021.9597196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123059087&doi=10.23919%2fMIPRO52101.2021.9597196&partnerID=40&md5=c048af3f2e7a6b73758bb942e5463be8","Many different code snippets can implement the same software feature. However, a significant subset of these possible solutions contains difficult-to-understand code that harms the software's maintainability and evolution. Such low-quality code snippets directly harm profit, as frequent and fast code change enables businesses to seize new opportunities. Unfortunately, they are also prevalent in an industry that consists mostly of junior programmers. We developed a platform called Clean CaDET to tackle the prevalence of low-quality code from two angles. The Smell Detector module presents a framework for integrating AI-based code quality assessment algorithms to identify low-quality code as the programmer is writing it. The Smart Tutor module hosts a catalog of educational content that helps the programmer understand the identified issue and suggests possible solutions. By combining the quality assessment with the educational aspect, our integrated solution presents a novel approach for increasing the quality of code produced by our industry.  © 2021 Croatian Society MIPRO.","2-s2.0-85123059087"
"Kuleshov A.; Ignatiev A.; Abramova A.","Kuleshov, Andrey (57194563875); Ignatiev, Andrey (57219266836); Abramova, Anna (57192180013)","57194563875; 57219266836; 57192180013","The Deficiency of 'Redline/Greenline' Approach to Risk Management in AI Applications","2021","Proceedings - 2021 International Conference Engineering Technologies and Computer Science, EnT 2021","","","","49","55","6","10.1109/EnT52731.2021.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123999160&doi=10.1109%2fEnT52731.2021.00015&partnerID=40&md5=ebaca307d2d361e8bc616432c8c9af0f","Expanding application of technologies classified as AI draws public attention to associated risks and effective measures for risk mitigation. Policy makers in most countries are currently looking for effective approaches to securing the public interest against AI-related risks and unforeseen consequences of widening AI use. In this connection, there is widespread talk of defining 'red' and 'green' areas for AI technologies, frequently leading to calls to draw 'red lines' and 'green lines' for technological innovation. The authors draw on the analysis of AI related risks in a number of international fora and question the efficacy of this 'redline/greenline' approach in terms of making the benefits of AI available in the society, while not impeding innovation and technological progress. The authors propose that a more nuanced approach is required, which could involve certification of AI system in sensitive applications, or could apply codified ethical principles to derive specific rules for AI use dependent on the risks created by AI in a particular application. © 2021 IEEE.","2-s2.0-85123999160"
"Hussain F.; Abbas S.G.; Husnain M.; Fayyaz U.U.; Shahzad F.; Shah G.A.","Hussain, Faisal (57214034473); Abbas, Syed Ghazanfar (57221632086); Husnain, Muhammad (57215127084); Fayyaz, Ubaid U. (55979096700); Shahzad, Farrukh (57213080222); Shah, Ghalib A. (14042806500)","57214034473; 57221632086; 57215127084; 55979096700; 57213080222; 14042806500","IoT DoS and DDoS Attack Detection using ResNet","2020","Proceedings - 2020 23rd IEEE International Multi-Topic Conference, INMIC 2020","","","9318216","","","","10.1109/INMIC50486.2020.9318216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100614855&doi=10.1109%2fINMIC50486.2020.9318216&partnerID=40&md5=6671fbc07169b15a0c40e8fd18444d20","The network attacks are increasing both in frequency and intensity with the rapid growth of internet of things (IoT) devices. Recently, denial of service (DoS) and distributed denial of service (DDoS) attacks are reported as the most frequent attacks in IoT networks. The traditional security solutions like firewalls, intrusion detection systems, etc., are unable to detect the complex DoS and DDoS attacks since most of them filter the normal and attack traffic based upon the static predefined rules. However, these solutions can become reliable and effective when integrated with artificial intelligence (AI) based techniques. During the last few years, deep learning models especially convolutional neural networks achieved high significance due to their outstanding performance in the image processing field. The potential of these convolutional neural network (CNN) models can be used to efficiently detect the complex DoS and DDoS by converting the network traffic dataset into images. Therefore, in this work, we proposed a methodology to convert the network traffic data into image form and trained a state-of-the-art CNN model, i.e., ResNet over the converted data. The proposed methodology accomplished 99.99% accuracy for detecting the DoS and DDoS in case of binary classification. Furthermore, the proposed methodology achieved 87% average precision for recognizing eleven types of DoS and DDoS attack patterns which is 9% higher as compared to the state-of-the-art. © 2020 IEEE.","2-s2.0-85100614855"
"Wotawa F.","Wotawa, Franz (6603677377)","6603677377","On the use of available testing methods for verification & validation of ai-based software and systems","2021","CEUR Workshop Proceedings","2808","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101205766&partnerID=40&md5=4c98f764be4731291d6112bb9edaa739","Verification and validation of software and systems is the essential part of the development cycle in order to meet given quality criteria including functional and non-functional requirements. Testing and in particular its automation has been an active research area for decades providing many methods and tools for automating test case generation and execution. Due to the increasing use of AI in software and systems, the question arises whether it is possible to utilize available testing techniques in the context of AI-based systems. In this position paper, we elaborate on testing issues arising when using AI methods for systems, consider the case of different stages of AI, and start investigating on the usefulness of certain testing methods for testing AI. We focus especially on testing at the system level where we are interesting not only in assuring a system to be correctly implemented but also to meet given criteria like not contradicting moral rules, or being dependable. We state that some well-known testing techniques can still be applied providing being tailored to the specific needs. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribute 4.0 International (CC BY 4.0).","2-s2.0-85101205766"
"Zierau N.; Hausch M.; Bruhin O.; Söllner M.","Zierau, Naim (57207467699); Hausch, Michael (57222613351); Bruhin, Olivia (57222614381); Söllner, Matthias (36191945500)","57207467699; 57222613351; 57222614381; 36191945500","Towards developing trust-supporting design features for AI-based chatbots in customer service","2021","International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103435065&partnerID=40&md5=d5d4da6cd8153a85885bf8840a3014ca","Chatbots are predicted to play a key role in customer service based on recent advances in the area of Artificial Intelligence (AI). However, a lack of user trust impedes the widespread adaption of AI-based chatbots. Still, there is a lack of systematically derived design knowledge concerning user trust in those agents. In this short paper, we report on the first steps of our design science research project on which design principles are relevant for building trust in chatbots. Based on trust literature and user interviews, we propose preliminary requirements and design principles for trust-enhancing design features for chatbots in customer service. Furthermore, we present a first instantiation of those principles. These insights will support researchers and practitioners to better understand how user trust in chatbots can be systematically built to increase adoption and usage. © ICIS 2020. All rights reserved.","2-s2.0-85103435065"
"Ruff C.; Horch A.; Benthien B.; Loh W.; Orlowski A.","Ruff, Christopher (56019368200); Horch, Andrea (54405628600); Benthien, Benedict (57361445200); Loh, Wulf (57202956487); Orlowski, Alexander (57361488200)","56019368200; 54405628600; 57361445200; 57202956487; 57361488200","DAMA - A transparent meta-assistant for data self-determination in smart environments","2021","Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)","P-312","","","119","130","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120530136&partnerID=40&md5=e642bd016229f9b401c975aea44a980b","Global sales of AI-based smart voice assistants and other smart devices are increasing every year. Smart devices are becoming ubiquitous, including living and workspaces. These spaces often have very high privacy requirements, like living rooms, bedrooms or meeting rooms in office environments. Users of smart devices have security and privacy concerns regarding personal data collection, data storage and the use of such data by the devices and the providers. These concerns are aggravated by a lack of transparency by the device manufacturers. As a result, users have limited possibilities to make an informed decision due to missing information or interfaces. While this leads to limited trust regarding the security and privacy of smart devices, for most users, the practical benefit dominates. The project DAMA wants to address user's security and privacy concerns by creating transparency and regulating the smart devices in connection with the respective context (e.g. when users are alone at home or when they have visitors). For this purpose, the project is developing a “meta-assistant”, an assistant that regulates other AI-based assistants and other smart devices. It uses artificial intelligence (AI) for context detection and device regulation. The regulation processes are based on established ethical guidelines, which are adjusted to the project context. © 2021 Gesellschaft fur Informatik (GI). All rights reserved.","2-s2.0-85120530136"
"Dominguez G.A.; Kawaai K.; Maruyama H.","Dominguez, Gonzalo Aguirre (57210090273); Kawaai, Keigo (57559067800); Maruyama, Hiroshi (55188877400)","57210090273; 57559067800; 55188877400","FAILS: A tool for assessing risk in ML systems","2021","Proceedings - Asia-Pacific Software Engineering Conference, APSEC","","","","1","4","3","10.1109/APSECW53869.2021.00010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127457619&doi=10.1109%2fAPSECW53869.2021.00010&partnerID=40&md5=48a0f0cef02963071fe75620c8608d7f","Quality assurance of AI based systems presents a unique set of challenges to software engineers, making it difficult to assess the risks involved when deploying them. We present a risk assessment tool based on the widely used failure mode effect analysis (FMEA) methodology, as well as quality assurance guidelines released in recent years. The tool aims to support the search for potential risks in machine learning (ML) components used in the design and development of AI products. A preliminary evaluation showed its effectiveness and pointed toward areas for future improvement. © 2021 IEEE.","2-s2.0-85127457619"
"Mahapatra B.; Bhorekar K.K.","Mahapatra, Bandana (57189377230); Bhorekar, Kumarsanjay K. (57222252681)","57189377230; 57222252681","Analyzing the Economic Depression Post-COVID-19 Using Big Data Analytics","2021","Studies in Systems, Decision and Control","324","","","309","325","16","10.1007/978-3-030-60039-6_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102057766&doi=10.1007%2f978-3-030-60039-6_16&partnerID=40&md5=4e7e743475f8a2dd436f5aa96210c6a0","Various industries like technology, food, agriculture, and education are predicted to suffer major financial and production depreciation. The economic crisis suffered by the major large-scale industry on the other hand is predicted to effect the other economic enterprises effecting the world on a major scale. The lockdown incurred upon the general public is implemented all over the world in order to control the widespread of this pandemic. Coronavirus has hit the worldwide economy tremendously all over the world. Various countries have suffered life loss, temporary stop gap in various industries, economic growth, loss in revenues collected, etc. Though after a span the lockdown was made open, certain extra policies and rules were implemented such as social distancing and no gathering of people more than two or three in a close proximity. Restriction over number of people who can board at the same time over any public places like shops malls have effected the cash inflow to a huge extent. This chapter aims at analyzing the depression suffered by various sectors post-COVID-19 as a result of the lockdown along with various recent policies implemented. It also covers visualizing these issues with big data analytics perspective and how the concept of AI and other technologies is working across in order to solve these issues. It covers in brief how these upcoming technologies have been able to contribute in the healthcare sector while fighting against COVID-19 or uplifting the economy by helping the industry to build and design new models or plans to regain the cash inflow. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","2-s2.0-85102057766"
"Khodabandehloo E.; Riboni D.; Alimohammadi A.","Khodabandehloo, Elham (56541769400); Riboni, Daniele (6505466404); Alimohammadi, Abbas (23391900800)","56541769400; 6505466404; 23391900800","HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline","2021","Future Generation Computer Systems","116","","","168","189","21","10.1016/j.future.2020.10.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095701881&doi=10.1016%2fj.future.2020.10.030&partnerID=40&md5=b64a3d89344cc55912dbe8586fd67c1f","Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system's predictions are significantly correlated to the person's actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline. © 2020","2-s2.0-85095701881"
"Lenarduzzi V.; Lomio F.; Moreschini S.; Taibi D.; Tamburri D.A.","Lenarduzzi, Valentina (55348964400); Lomio, Francesco (57216456159); Moreschini, Sergio (57196187277); Taibi, Davide (55920884000); Tamburri, Damian Andrew (35488974800)","55348964400; 57216456159; 57196187277; 55920884000; 35488974800","Software Quality for AI: Where We Are Now?","2021","Lecture Notes in Business Information Processing","404","","","43","53","10","10.1007/978-3-030-65854-0_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101567404&doi=10.1007%2f978-3-030-65854-0_4&partnerID=40&md5=302e47bc21ecacfb73db69887f6615e2","Artificial Intelligence is getting more and more popular, being adopted in a large number of applications and technology we use on a daily basis. However, a large number of Artificial Intelligence applications are produced by developers without proper training on software quality practices or processes, and in general, lack in-depth knowledge regarding software engineering processes. The main reason is due to the fact that the machine-learning engineer profession has been born very recently, and currently there is a very limited number of training or guidelines on issues (such as code quality or testing) for machine learning and applications using machine learning code. In this work, we aim at highlighting the main software quality issues of Artificial Intelligence systems, with a central focus on machine learning code, based on the experience of our four research groups. Moreover, we aim at defining a shared research road map, that we would like to discuss and to follow in collaboration with the workshop participants. As a result, the software quality of AI-enabled systems is often poorly tested and of very low quality. © 2021, Springer Nature Switzerland AG.","2-s2.0-85101567404"
"Gerdes A.","Gerdes, Anne (35482227700)","35482227700","Dialogical Guidelines Aided by Knowledge Acquisition: Enhancing the Design of Explainable Interfaces and Algorithmic Accuracy","2021","Advances in Intelligent Systems and Computing","1288","","","243","257","14","10.1007/978-3-030-63128-4_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096464793&doi=10.1007%2f978-3-030-63128-4_19&partnerID=40&md5=c127dabbcb478a51b8b0806ade733e3b","Understanding expert domain knowledge may inform the design of explainable interfaces that convey comprehensible information by “mirroring” the explanation practice of domain experts. Likewise, scrutinizing expert domain knowledge is pivotal to guarantee data quality and enhance algorithmic accuracy, by zooming in on the types of data and information that constitute relevant and reliable representations in a given domain. Against this backdrop, the paper revitalizes the field of knowledge acquisition and presents easily applicable user-centered and value-oriented dialogical guidelines to unravel domain knowledge with the aim of enhancing the design of explainable interfaces and algorithmic accuracy. While it might seem counter-intuitive to revisit the field of knowledge acquisition in the era of machine learning and deep learning, there are plenty of cases in which AI systems, trained on biased data, have led to epistemological deficiencies with morally harmful consequences. In order to improve the data preparation and modelling stage in the development of ML models, this paper suggests that AI developers could benefit from the pragmatic application of manageable dialogical guidelines aided by knowledge acquisition to cultivate shared understanding between AI developers and domain expert end users. © 2021, Springer Nature Switzerland AG.","2-s2.0-85096464793"
"Balagué C.","Balagué, Christine (35742615700)","35742615700","The challenge of responsible AI","2021","Artificial Intelligence for Sustainable Value Creation","","","","99","121","22","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130206734&partnerID=40&md5=2e6e454bb62f4ae2063668dcfae56a7d","The dichotomic vision of artificial intelligence, which emerged during the last years, underlines both the benefits of machine learning in innovation and the negative consequences of AI on organizations and more globally on society. After an historical contextualization of digital transformation, this chapter first provides an understanding of the potential negative impacts of AI, second presents the concept of ethics and its application to AI systems, third describes different initiatives to tackle the issue of negative consequences of AI. It also illustrates the theoretical aspects of ethics in AI by analyzing current technologies presented at CES 2020 in Las Vegas. Finally, the chapter provides guidelines for managers to address the issue of ethics in AI, including metrics for corporate social responsibility. © Margherita Pagani and Renaud Champion 2021.","2-s2.0-85130206734"
"Feldkamp N.; Bergmann S.; Strassburger S.","Feldkamp, Niclas (56811669700); Bergmann, Soeren (44061207400); Strassburger, Steffen (6602802776)","56811669700; 44061207400; 6602802776","Simulation-Based Deep Reinforcement Learning for Modular Production Systems","2020","Proceedings - Winter Simulation Conference","2020-December","","9384089","1596","1607","11","10.1109/WSC48552.2020.9384089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103891394&doi=10.1109%2fWSC48552.2020.9384089&partnerID=40&md5=ec0c21c0ffc9c3fa8192fd88b0b659b4","Modular production systems aim to supersede the traditional line production in the automobile industry. The idea here is that highly customized products can move dynamically and autonomously through a system of flexible workstations without fixed production cycles. This approach has challenging demands regarding planning and organization of such systems. Since each product can define its way through the system freely and individually, implementing rules and heuristics that leverage the flexibility in the system in order to increase performance can be difficult in this dynamic environment. Transport tasks are usually carried out by automated guided vehicles (AGVs). Therefore, integration of AI-based control logics offer a promising alternative to manually implemented decision rules for operating the AGVs. This paper presents an approach for using reinforcement learning (RL) in combination with simulation in order to control AGVs in modular production systems. We present a case study and compare our approach to heuristic rules. © 2020 IEEE.","2-s2.0-85103891394"
"Gallina B.; Pacaci G.; Johnson D.; McKeever S.; Hamfelt A.; Costantini S.; Dell’Acqua P.; Crisan G.-C.","Gallina, Barbara (23396891300); Pacaci, Görkem (55976568100); Johnson, David (57203598638); McKeever, Steve (57206494647); Hamfelt, Andreas (55975340700); Costantini, Stefania (8707974500); Dell’Acqua, Pierangelo (55928655300); Crisan, Gloria-Cerasela (17433683300)","23396891300; 55976568100; 57203598638; 57206494647; 55975340700; 8707974500; 55928655300; 17433683300","Towards explainable, compliant and adaptive human-automation interaction","2021","CEUR Workshop Proceedings","2891","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109217296&partnerID=40&md5=16e47671cf6e24f119b8f17ef61c4208","AI-based systems use trained machine learning models to make important decisions in critical contexts. The EU guidelines for trustworthy AI emphasise the respect for human autonomy, prevention of harm, fairness, and explicability. Many successful machine learning methods, however, deliver opaque models where the reasons for decisions remain unclear to the end user. Hence, accountability and trust are difficult to ascertain. In this position paper, we focus on AI systems that are expected to interact with humans and we propose our visionary architecture, called ECA-HAI (Explainable, Compliant and Adaptive Human-Automation Interaction)-RefArch. ECA-HAI-RefArch allows for building intelligent systems where humans and AIs form teams, able to learn from data but also to learn from each other by playing “serious games”, for a continuous improvement of the overall system. Finally, conclusions are drawn. © 2020 for this paper by its authors.","2-s2.0-85109217296"
"Fujii G.; Hamada K.; Ishikawa F.; Masuda S.; Matsuya M.; Myojin T.; Nishi Y.; Ogawa H.; Toku T.; Tokumoto S.; Tsuchiya K.; Ujita Y.","Fujii, Gaku (57219901878); Hamada, Koichi (58253019200); Ishikawa, Fuyuki (33367760100); Masuda, Satoshi (36803608600); Matsuya, Mineo (57218865089); Myojin, Tomoyuki (55555882700); Nishi, Yasuharu (35119148100); Ogawa, Hideto (26032684700); Toku, Takahiro (57218868119); Tokumoto, Susumu (55383584000); Tsuchiya, Kazunori (57218867636); Ujita, Yasuhiro (57218867074)","57219901878; 58253019200; 33367760100; 36803608600; 57218865089; 55555882700; 35119148100; 26032684700; 57218868119; 55383584000; 57218867636; 57218867074","Guidelines for Quality Assurance of Machine Learning-Based Artificial Intelligence","2020","International Journal of Software Engineering and Knowledge Engineering","30","11-12","","1589","1606","17","10.1142/S0218194020400227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096006542&doi=10.1142%2fS0218194020400227&partnerID=40&md5=772ec7e1f2201c5251764b201c4a66c6","Significant effort is being put into developing industrial applications for artificial intelligence (AI), especially those using machine learning (ML) techniques. Despite the intensive support for building ML applications, there are still challenges when it comes to evaluating, assuring, and improving the quality or dependability. The difficulty stems from the unique nature of ML, namely, system behavior is derived from training data not from logical design by human engineers. This leads to black-box and intrinsically imperfect implementations that invalidate many principles and techniques in traditional software engineering. In light of this situation, the Japanese industry has jointly worked on a set of guidelines for the quality assurance of AI systems (in the Consortium of Quality Assurance for AI-based Products and Services) from the viewpoint of traditional quality-assurance engineers and test engineers. We report on the second version of these guidelines, which cover a list of quality evaluation aspects, catalogue of current state-of-the-art techniques, and domain-specific discussions in five representative domains. The guidelines provide significant insights for engineers in terms of methodologies and designs for tests driven by application-specific requirements. © 2020 The Author(s).","2-s2.0-85096006542"
"Gunson N.; Sieińska W.; Walsh C.; Dondrup C.; Lemon O.","Gunson, Nancie (36188108600); Sieińska, Weronika (57215089194); Walsh, Christopher (57220117642); Dondrup, Christian (56086338900); Lemon, Oliver (6603015795)","36188108600; 57215089194; 57220117642; 56086338900; 6603015795","It's Good to Chat?: Evaluation and Design Guidelines for Combining Open-Domain Social Conversation with Task-Based Dialogue in Intelligent Buildings","2020","Proceedings of the 20th ACM International Conference on Intelligent Virtual Agents, IVA 2020","","","","","","","10.1145/3383652.3423889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096959310&doi=10.1145%2f3383652.3423889&partnerID=40&md5=5d733b396028c51775bc6eab6c308612","We present and evaluate a deployed conversational AI system that acts as a host of a working public building on a university campus. The system combines open-domain social chat with task-based conversation regarding navigation in the building, live resource updates (e.g. available computers), and events in the building. We investigated the impact of open-domain social chat on task completion and user preferences by comparing the combined system with a task-only version. We find that there is no significant difference in task completion or several aspects of user preference between the two systems, but that users would be significantly happier to talk to the task-only system in the future. This suggests that the ""walk-up""public setting and workplace nature of the environment creates a markedly different use case to the in-home, and more individual and private ""companion/assistant""setting which is commonly assumed for systems like Alexa. We discuss the implications for the design of conversational systems in other public settings. © 2020 ACM.","2-s2.0-85096959310"
"Nguyen T.T.; Le A.D.; Hoang H.T.; Nguyen T.","Nguyen, Trung Thanh (58732834300); Le, Anh Duc (57357682300); Hoang, Ha Thanh (57226804397); Nguyen, Tuan (57212283993)","58732834300; 57357682300; 57226804397; 57212283993","NEU-chatbot: Chatbot for admission of National Economics University","2021","Computers and Education: Artificial Intelligence","2","","100036","","","","10.1016/j.caeai.2021.100036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123929683&doi=10.1016%2fj.caeai.2021.100036&partnerID=40&md5=b4f7c067a30229421af1f0dc004be04a","In the last few years, intelligent chatbot systems have been prevalent in various application fields, especially in education. Therefore, the demand for such online consulting services like chatbots is getting higher respectively. However, most communications between potential students and universities are performed manually, which is very time-consuming procedure, becoming a burden on the head of admissions. In this paper, we introduce an AI-based chatbot where students can instantly get daily updates of curriculum, admission for new students, tuition fees, IELTS writing task II score, etc. Our chatbot was developed by Deep Learning models, which are already integrated into the Rasa framework. We also proposed a rational pipeline for Vietnamese chatbots with our data preprocessing to obtain optimal accuracy and to avoid the overfitting of the model. Our model can detect more than fifty types of questions from users' input with an accuracy of 97.1% on test set. The chatbot was applied for National Economics University's official admission Fanpage on the Facebook platform, which is the most famous social network in Vietnam. This research shows detailed guidelines on how to build an AI chatbot from scratch, and the techniques we used, which can be applied to any language globally. © 2021 The Authors","2-s2.0-85123929683"
"Zhu G.; Liu D.; Du Y.; You C.; Zhang J.; Huang K.","Zhu, Guangxu (56060833200); Liu, Dongzhu (57208539875); Du, Yuqing (57204116803); You, Changsheng (57189048701); Zhang, Jun (36659981100); Huang, Kaibin (15834779200)","56060833200; 57208539875; 57204116803; 57189048701; 36659981100; 15834779200","Toward an Intelligent Edge: Wireless Communication Meets Machine Learning","2020","IEEE Communications Magazine","58","1","8970161","19","25","6","10.1109/MCOM.001.1900103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078757648&doi=10.1109%2fMCOM.001.1900103&partnerID=40&md5=594219bf4fa400f5fe81533bcfaf7704","The recent revival of AI is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and IoT devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interest in realizing an ""intelligent edge"" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, has emerged, which crosses and revolutionizes two disciplines: wireless communication and machine learning. A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design guidelines for wireless communication in edge learning, collectively called learning- driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design guidelines. Unique research opportunities are identified. © 1979-2012 IEEE.","2-s2.0-85078757648"
"Choi I.; Kim H.","Choi, Inyeop (57218207791); Kim, Hyogon (7410128369)","57218207791; 7410128369","An on-device deep learning approach to battery saving on industrial mobile terminals","2020","Sensors (Switzerland)","20","14","4044","1","20","19","10.3390/s20144044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088233367&doi=10.3390%2fs20144044&partnerID=40&md5=5e143772c83ca56b6b5c40a57791c4d0","The mobile terminals used in the logistics industry can be exposed to wildly varying environments, which may hinder effective operation. In particular, those used in cold storages can be subject to frosting in the scanner window when they are carried out of the warehouses to a room-temperature space outside. To prevent this, they usually employ a film heater on the scanner window. However, the temperature and humidity conditions of the surrounding environment and the temperature of the terminal itself that cause frosting vary widely. Due to the complicated frost-forming conditions, existing industrial mobile terminals choose to implement rather simple rules that operate the film heater well above the freezing point, which inevitably leads to inefficient energy use. This paper demonstrates that to avoid such waste, on-device artificial intelligence (AI) a.k.a. edge AI can be readily employed to industrial mobile terminals and can improve their energy efficiency. We propose an artificial-intelligence-based approach that utilizes deep learning technology to avoid the energy-wasting defrosting operations. By combining the traditional temperature-sensing logic with a convolutional neural network (CNN) classifier that visually checks for frost, we can more precisely control the defrosting operation. We embed the CNN classifier in the device and demonstrate that the approach significantly reduces the energy consumption. On our test terminal, the net ratio of the energy consumption by the existing system to that of the edge AI for the heating film is almost 14:1. Even with the common current-dissipation accounted for, our edge AI system would increase the operating hours by 86%, or by more than 6 h compared with the system without the edge AI. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85088233367"
"Hagendorff T.","Hagendorff, Thilo (57194142411)","57194142411","The Ethics of AI Ethics: An Evaluation of Guidelines","2020","Minds and Machines","30","1","","99","120","21","10.1007/s11023-020-09517-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078946650&doi=10.1007%2fs11023-020-09517-8&partnerID=40&md5=4a90182c8735c1cedf9d1cb78ebd6682","Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the “disruptive” potentials of new AI technologies. Designed as a semi-systematic evaluation, this paper analyzes and compares 22 guidelines, highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems—and how the effectiveness in the demands of AI ethics can be improved. © 2020, The Author(s).","2-s2.0-85078946650"
"Omone O.M.; Aggrey E.; Takacs M.; Kozlovszky M.","Omone, Ogbolu Melvin (57217175966); Aggrey, Eric (57219973781); Takacs, Marta (22036707800); Kozlovszky, Miklos (6505786011)","57217175966; 57219973781; 22036707800; 6505786011","Implementation of A Fuzzy Logic Progression for Alcohol Addicts Using Fuzzy Control System(FCS)","2020","SISY 2020 - IEEE 18th International Symposium on Intelligent Systems and Informatics, Proceedings","","","9217079","161","166","5","10.1109/SISY50555.2020.9217079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096352154&doi=10.1109%2fSISY50555.2020.9217079&partnerID=40&md5=00da27334f2e975975f340b0ba0ce44d","The use of the Reduced Alcohol Intake (RAI) logic model is to help monitor alcoholic addicts and help them reduce alcohol intake for a better life and improved academic performance. The purpose of this study is to use the Mamdani Fuzzy Inference System (MFIS) component, which includes the application of a T-S (Takagi-Sugeno) model-based Fuzzy Control System (FCS) and a Fuzzy Logic System (FLS) as a rule-based system (Fuzzy Control System - FCS) to assemble all inputs in the RAI model to achieve classified fuzzy outputs. As initiated in the theoretical logic model (the RAI logic model), there is a direct identification of breakpoints for a transition between phases in the model. Thus, it can be used as an AI system that is efficient to monitor and examine the progression of alcohol addicts (to know what percentage of improvement they have reached overtime). Using the T-S method, the core parameters (motivation and self-determined state) of the RAI model were analyzed to find a linear interaction between the existing variables. In this paper, the variables of motivation and self-determined state are scaled between 0 to 10 to predict the level of improvement in percentage (%).  © 2020 IEEE.","2-s2.0-85096352154"
"Suárez-Figueroa M.C.; Ruckhaus E.; López-Guerrero J.; Cano I.; Cervera Á.","Suárez-Figueroa, Mari Carmen (56005389600); Ruckhaus, Edna (10242585700); López-Guerrero, Jorge (57219161638); Cano, Isabel (57219166665); Cervera, Álvaro (57219165778)","56005389600; 10242585700; 57219161638; 57219166665; 57219165778","Towards the assessment of easy-to-read guidelines using artificial intelligence techniques","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12376 LNCS","","","74","82","8","10.1007/978-3-030-58796-3_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091538196&doi=10.1007%2f978-3-030-58796-3_10&partnerID=40&md5=eb607625dec62d67bb8f5c63f9b2ea1a","The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities, who have difficulties in reading comprehension. The main goal of the E2R Methodology is to present clear and easily understood documents. This methodology includes a set of guidelines and recommendations that affect the writing of texts, the supporting images, the design and layout of documents, and the final editing format. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. The process of adapting existing documents is cyclic and implies three activities: analysis, transformation, and validation. All these activities are human resource consuming, due to the need of involving people with cognitive disabilities as well as E2R experts. In order to alleviate such processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to perform the analysis and transformation of documents in a (semi)-automatic fashion. In this paper we present our AI-based method for assessing a particular document with respect to the E2R guidelines as well as an initial implementation of such a method; our research on the transformation of documents is out of the scope of this paper. We carried out a comparative evaluation of the results obtained by our initial implementation against the results of the document analysis performed by people with cognitive disabilities. © Springer Nature Switzerland AG 2020.","2-s2.0-85091538196"
"Rashid S.M.","Rashid, Sabbir M. (57195276644)","57195276644","Employing hybrid reasoning to support clinical decision-making","2020","CEUR Workshop Proceedings","2798","","","9","16","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099392435&partnerID=40&md5=2cf0cb6d106813f83d4a71de8276cef2","Clinical reasoning, involving abstraction, abduction, deduction, and induction, is the primary tool that physicians use when making clinical decisions. To support them, we focus on the creation of an AI system that is able to emulate clinical reasoning. We leverage Semantic Web technologies to perform a set of AI tasks involving the various forms of inference associated with clinical reasoning strategies. In particular, for the scope of this work, we focus on clinical problems that require differential diagnosis techniques. For a given clinical scenario, overlapping reasoning types and strategies may be employed by a physician in conjunction, signifying the need for our AI system to perform hybrid reasoning. Therefore, we consider the construction of a hybrid reasoner that is compatible with description logics. For medical scenarios where description logics may not have some needed expressivity, we consider possible extensions that will allow for the representation of such a scenario. The reasoning system, clinical rule representation, and the resulting recommendations will be evaluated based on domain expert consultation in order to determine whether the recommendation aligns with what the expert would recommend. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85099392435"
"Schaekermann M.; Beaton G.; Sanoubari E.; Lim A.; Larson K.; Law E.","Schaekermann, Mike (57194266491); Beaton, Graeme (57209221269); Sanoubari, Elaheh (57201554792); Lim, Andrew (36340122500); Larson, Kate (7102154796); Law, Edith (35173013200)","57194266491; 57209221269; 57201554792; 36340122500; 7102154796; 35173013200","Ambiguity-aware AI Assistants for Medical Data Analysis","2020","Conference on Human Factors in Computing Systems - Proceedings","","","3376506","","","","10.1145/3313831.3376506","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091288601&doi=10.1145%2f3313831.3376506&partnerID=40&md5=4f20a9b70e4adb42a6f660b05bb5a299","Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments. © 2020 Owner/Author.","2-s2.0-85091288601"
"Beyene T.A.; Sahu A.","Beyene, Tewodros A. (55813417400); Sahu, Amit (55098716400)","55813417400; 55098716400","Rule-Based Safety Evidence for Neural Networks","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12235 LNCS","","","328","335","7","10.1007/978-3-030-55583-2_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096550813&doi=10.1007%2f978-3-030-55583-2_24&partnerID=40&md5=da8e633f33a9f4d7d44b68dfb62a6908","Neural networks have many applications in safety and mission critical systems. As industrial standards in various safety-critical domains require developers of critical systems to provide safety assurance, tools and techniques must be developed that enable effective creation of safety evidence for AI systems. In this position paper, we propose the use of rules extracted from neural networks as artefacts for safety evidence. We discuss the rationale behind the use of rules and illustrate it using the MNIST dataset. © 2020, Springer Nature Switzerland AG.","2-s2.0-85096550813"
"Hoffmann C.H.; Hahn B.","Hoffmann, Christian Hugo (57190062996); Hahn, Benjamin (57226853403)","57190062996; 57226853403","Decentered ethics in the machine era and guidance for AI regulation","2020","AI and Society","35","3","","635","644","9","10.1007/s00146-019-00920-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074580605&doi=10.1007%2fs00146-019-00920-z&partnerID=40&md5=0e526c994e8aec86767b476522d20de6","Recent advancements in AI have prompted a large number of AI ethics guidelines published by governments and nonprofits. While many of these papers propose concrete or seemingly applicable ideas, few philosophically sound proposals are made. In particular, we observe that the line of questioning has often not been examined critically and underlying conceptual problems not always dealt with at the root. In this paper, we investigate the nature of ethical AI systems and what their moral status might be by first turning to the notions of moral agency and patience. We find that their explication would come at a too high cost which is why we, second, articulate a different approach that avoids vague and ambiguous concepts or the problem of other minds. Third, we explore the impact of our philosophical and conceptual analysis on the regulatory landscape, make this link explicit, and finally propose a set of promising policy steps. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","2-s2.0-85074580605"
"Lima P.U.; Azevedo C.; Brzozowska E.; Cartucho J.; Dias T.J.; Gonçalves J.; Kinarullathil M.; Lawless G.; Lima O.; Luz R.; Miraldo P.; Piazza E.; Silva M.; Veiga T.; Ventura R.","Lima, Pedro U. (35550404900); Azevedo, Carlos (57189891941); Brzozowska, Emilia (57210803736); Cartucho, João (57204141345); Dias, Tiago J. (57215789585); Gonçalves, João (36830501700); Kinarullathil, Mithun (57205218210); Lawless, Guilherme (57194835809); Lima, Oscar (57195302853); Luz, Rute (57204954151); Miraldo, Pedro (54955645900); Piazza, Enrico (57207942923); Silva, Miguel (58842863400); Veiga, Tiago (36803028200); Ventura, Rodrigo (7102796668)","35550404900; 57189891941; 57210803736; 57204141345; 57215789585; 36830501700; 57205218210; 57194835809; 57195302853; 57204954151; 54955645900; 57207942923; 58842863400; 36803028200; 7102796668","SocRob@Home: Integrating AI Components in a Domestic Robot System","2019","KI - Kunstliche Intelligenz","33","4","","343","356","13","10.1007/s13218-019-00618-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088042613&doi=10.1007%2fs13218-019-00618-w&partnerID=40&md5=ffcd63d8ebb424e61bd8a0c2565bb59f","This paper describes the SocRob@Home robot system, consisting of a mobile robot (MBOT) equipped with several sensors and actuators, including a manipulator arm, and several software modules that provide the skills and capability to perform domestic tasks while interacting with humans in a domestic environment. We describe the whole system holistically, explaining how it integrates the contributing modules, and then we focus on the most relevant sub-systems, pointing out the original contributions of our research and development on the system in the last 5 years. The robot system includes metric and semantic mapping, several navigation modes (way-point navigation, person following and multi-sensor obstacle detection and avoidance), vision-based object detection, recognition, servoing and grasping, speech understanding, task planning and task execution. The robot system is mostly activated by speech commands from a human, and these commands, after being interpreted, are executed by the robot sub-systems, coordinated by a task executor. Lessons learned during the development and use of this system, which are useful as guidelines for the development of similar robot systems, are provided. MBOT’s performance is assessed using the task benchmarks scoring system of the European Robotics League competitions on Consumer Service robots. © 2019, Gesellschaft für Informatik e.V. and Springer-Verlag GmbH Germany, part of Springer Nature.","2-s2.0-85088042613"
"Grua E.M.; De Sanctis M.; Lago P.","Grua, Eoin Martino (57207728498); De Sanctis, Martina (56358489900); Lago, Patricia (56187491900)","57207728498; 56358489900; 56187491900","A reference architecture for personalized and self-adaptive e-health apps","2020","Communications in Computer and Information Science","1269 CCIS","","","195","209","14","10.1007/978-3-030-59155-7_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091502971&doi=10.1007%2f978-3-030-59155-7_15&partnerID=40&md5=510a7aab699df0b751765b51b9f4ac95","A wealth of e-Health mobile apps are available for many purposes, such as life style improvement, mental coaching, etc. The interventions, prompts, and encouragements of e-Health apps sometimes take context into account (e.g., previous interactions or geographical location of the user), but they still tend to be rigid, e.g., by using fixed rule sets or being not sufficiently tailored towards individuals. Personalization to the different users’ characteristics and run-time adaptation to their changing needs and context provide a great opportunity for getting users continuously engaged and active, eventually leading to better physical and mental conditions. This paper presents a reference architecture for enabling AI-based personalization and self-adaptation of mobile apps for e-Health. The reference architecture makes use of multiple MAPE loops operating at different levels of granularity and for different purposes. © Springer Nature Switzerland AG 2020.","2-s2.0-85091502971"
"Kuwajima H.; Ishikawa F.","Kuwajima, Hiroshi (25027829000); Ishikawa, Fuyuki (33367760100)","25027829000; 33367760100","Adapting square for quality assessment of artificial intelligence systems","2019","Proceedings - 2019 IEEE 30th International Symposium on Software Reliability Engineering Workshops, ISSREW 2019","","","8990311","13","18","5","10.1109/ISSREW.2019.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080861178&doi=10.1109%2fISSREW.2019.00035&partnerID=40&md5=dc8eaabf2d5a6ec47bb4b44643a5c3fa","More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional software systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and Ethics guidelines for trustworthy AI from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts. © 2019 IEEE.","2-s2.0-85080861178"
"Anwar S.M.; Altaf T.; Rafique K.; Raviprakash H.; Mohy-Ud-din H.; Bagci U.","Anwar, Syed Muhammad (36781722700); Altaf, Tooba (57200964427); Rafique, Khola (57219525672); Raviprakash, Harish (57201352764); Mohy-Ud-din, Hassan (36176181800); Bagci, Ulas (24176491700)","36781722700; 57200964427; 57219525672; 57201352764; 36176181800; 24176491700","A survey on recent advancements for AI enabled radiomics in neuro-oncology","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11991 LNCS","","","24","35","11","10.1007/978-3-030-40124-5_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081597560&doi=10.1007%2f978-3-030-40124-5_3&partnerID=40&md5=b7b36f4ea45ca74acc17733cddecd4e0","Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistance in diagnosis of cancer, planning of treatment strategy, and prediction of survival. Radiomics in neuro-oncology has progressed significantly in the recent past. Deep learning has outperformed conventional machine learning methods in most image-based applications. Convolutional neural networks (CNNs) have seen some popularity in radiomics, since they do not require hand-crafted features and can automatically extract features during the learning process. In this regard, it is observed that CNN based radiomics could provide state-of-the-art results in neuro-oncology, similar to the recent success of such methods in a wide spectrum of medical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology. © Springer Nature Switzerland AG 2020.","2-s2.0-85081597560"
"Ertl T.; Taugerbeck S.; Esau M.; Aal K.; Tolmie P.; Wulf V.","Ertl, Tanja (57212448773); Taugerbeck, Sebastian (57212450062); Esau, Margarita (57212454329); Aal, Konstantin (55734678000); Tolmie, Peter (6602706528); Wulf, Volker (55072850600)","57212448773; 57212450062; 57212454329; 55734678000; 6602706528; 55072850600","The social mile - How (Psychosocial) ICT can help to promote resocialization and to overcome prison","2019","Proceedings of the ACM on Human-Computer Interaction","3","GROUP","248","","","","10.1145/3370270","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076692356&doi=10.1145%2f3370270&partnerID=40&md5=081a21b57715ba06f0e5faae6303bdeb","There is currently uncertainty in the research community as to how ICT can and should be designed in such a way that it can be convincingly integrated into the everyday lives of prison inmates. In this paper, we discuss a design fiction that closes this research gap. The descriptions and results of the study are purely fictitious. Excluded is the State of the Art as well as the description of the legal situation of prisons in Germany. The analysis of the fictional study data designed here thus refers to the real world in order to derive ethical guidelines and draw practical conclusions. It is our intention to use these results as a possible basis for further research. The paper presents results of an explorative study dealing with the design, development and evaluation of an AI-based Smart Mirror System, Prison AI 2.0, in a German prison. Prison AI 2.0 was developed for daily use and voluntarily tested by eight prisoners over a period of 12 months to gain insight into their individual and social impact, with an emphasis on its ability to actively support rehabilitation. Based on qualitative data, our findings suggest that intelligent AI-based devices can actually help promote such an outcome. Our results also confirm the valuable impact of (Psychosocial) ICT on the psychological, social and individual aspects of prison life, and in particular how prisoners used the Smart Mirror system to improve and maintain their cognitive, mental and physical state and to restore social interactions with the outside world. With the presentation of these results we want to initiate discussions about the use of ICT by prisoners in closed prisons in order to identify opportunities and risks. Copyright is held by the owner/author(s). Publication rights licensed to ACM. © 2019 Association for Computing Machinery. All rights reserved.","2-s2.0-85076692356"
"Samuel S.S.; Abdullah N.N.B.; Raj A.","Samuel, Sanjay Sekar (57218715405); Abdullah, Nik Nailah Binti (23090482500); Raj, Anil (7006091957)","57218715405; 23090482500; 7006091957","Interpretation of SVM Using Data Mining Technique to Extract Syllogistic Rules: Exploring the Notion of Explainable AI in Diagnosing CAD","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12279 LNCS","","","249","266","17","10.1007/978-3-030-57321-8_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090173196&doi=10.1007%2f978-3-030-57321-8_14&partnerID=40&md5=ae425cc6a1401916ba1dfc3ca2d4f54f","Artificial Intelligence (AI) systems that can provide clear explanations of their behaviors have been suggested in many studies as a critical feature for human users to develop reliance and trust when using such systems. Medical Experts (ME) in particular while using an AI assistant system must understand how the system generates disease diagnoses before making patient care decisions based on the AI’s output. In this paper, we report our work in progress and preliminary findings toward the development of a human-centered explainable AI (XAI) specifically for the diagnosis of Coronary Artery Disease (CAD). We applied syllogistic inference rules based on CAD Clinical Practice Guidelines (CPGs) to interpret the data mining results using a Support Vector Machine (i.e., SVM) classification technique—which forms an early model for a knowledge base (KB). The SVM’s inference rules are then explained through a voice system to the MEs. Based on our initial findings, we discovered that MEs trusted the system’s diagnoses when the XAI described the chain of reasoning behind the diagnosis process in a more interpretable form—suggesting an enhanced level of trust. Using syllogistic rules alone, however, to interpret the classification of the SVM algorithm lacked sufficient contextual information—which required augmentation with more descriptive explanations provided by a medical expert. © 2020, IFIP International Federation for Information Processing.","2-s2.0-85090173196"
"Martínez-Rojas A.; Barba I.; Enríquez J.G.","Martínez-Rojas, Antonio (57211522155); Barba, Irene (15041816300); Enríquez, José González (56203929000)","57211522155; 15041816300; 56203929000","Towards a Taxonomy of Cognitive RPA Components","2020","Lecture Notes in Business Information Processing","393 LNBIP","","","161","175","14","10.1007/978-3-030-58779-6_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091335240&doi=10.1007%2f978-3-030-58779-6_11&partnerID=40&md5=bddd21671ae031b99c742521b9b783bf","Robotic Process Automation (RPA) is a discipline that is increasingly growing hand in hand with Artificial Intelligence (AI) and Machine Learning enabling the so-called cognitive automation. In such context, the existing RPA platforms that include AI-based solutions classify their components, i.e. constituting part of a robot that performs a set of actions, in a way that seems to obey market or business decisions instead of common-sense rules. To be more precise, components that present similar functionality are identified with different names and grouped in different ways depending on the platform that provides the components. Therefore, the analysis of different cognitive RPA platforms to check their suitability for facing a specific need is typically a time-consuming and error-prone task. To overcome this problem and to provide users with support in the development of an RPA project, this paper proposes a method for the systematic construction of a taxonomy of cognitive RPA components. Moreover, such a method is applied over components that solve selected real-world use cases from the industry obtaining promising results. © 2020, Springer Nature Switzerland AG.","2-s2.0-85091335240"
"Davoust A.; Rovatsos M.","Davoust, Alan (24337490900); Rovatsos, Michael (8860226200)","24337490900; 8860226200","Social contracts for non-cooperative games","2020","AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society","","","","43","49","6","10.1145/3375627.3375829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082175399&doi=10.1145%2f3375627.3375829&partnerID=40&md5=972ba2201a1c2450895935dc03ec39b9","In future agent societies, we might see AI systems engaging in selfish, calculated behavior, furthering their owners' interests instead of socially desirable outcomes. How can we promote morally sound behaviour in such settings, in order to obtain more desirable outcomes? A solution from moral philosophy is the concept of a social contract, a set of rules that people would voluntarily commit to in order to obtain better outcomes than those brought by anarchy. We adapt this concept to a game-theoretic setting, to systematically modify the payoffs of a non-cooperative game, so that agents will rationally pursue socially desirable outcomes. We show that for any game, a suitable social contract can be designed to produce an optimal outcome in terms of social welfare. We then investigate the limitations of applying this approach to alternative moral objectives, and establish that, for any alternative moral objective that is significantly different from social welfare, there are games for which no such social contract will be feasible that produces non-negligible social benefit compared to collective selfish behaviour. © 2020 Copyright held by the owner/author(s).","2-s2.0-85082175399"
"Hardcastle V.G.","Hardcastle, Valerie Gray (7003992122)","7003992122","Group-to-individual (G2i) inferences: challenges in modeling how the U.S. court system uses brain data","2020","Artificial Intelligence and Law","28","1","","51","68","17","10.1007/s10506-018-9234-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055278147&doi=10.1007%2fs10506-018-9234-0&partnerID=40&md5=b8789a73a04b31e2ab5272c6f4c86522","Regardless of formalization used, one on-going challenge for AI systems that model legal proceedings is accounting for contextual issues, particularly where judicial decisions are made in criminal cases. The law assumes a rational approach to rule application in deciding a defendant’s guilt; however, judges and juries can behave irrationally. What should a model prize: efficiency, accuracy, or fairness? Exactly whether and how to incorporate the psychology of courtroom interactions into formal models or expert systems has only just begun to be examined in a serious fashion. Here, I outline data from the United States which suggest that trying to incorporate psychological biases into formal models of legal decision-making will be challenging. I focus on the use of neuroscience data in criminal trials, homing in on so-called group-to-individual (G2i) inferences. I argue that data which should be the most effective at swaying judicial decisions are in fact those most likely not to make a difference in the disposition of the case. I conclude that judges often assign culpability by ignoring what our best science regarding how human decision-making occurs. © 2018, Springer Nature B.V.","2-s2.0-85055278147"
"Liu X.; He S.; Maedche A.","Liu, Xuanhui (57194243805); He, Simin (57217047055); Maedche, Alexander (6603610788)","57194243805; 57217047055; 6603610788","Designing an AI-based advisory platform for design techniques","2020","27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087105807&partnerID=40&md5=125b406b6650b0800d14e3df202cbea4","The usage of design techniques in design processes is an important driver for the success of digital services. However, before using design techniques, suitable techniques need to be selected. With the continuous growth of the number of design techniques, the selection of appropriate ones becomes more difficult, especially for design novices with limited knowledge and expertise. In order to support the selection process, we propose design principles for the development of an advisory platform that interacts with design novices to suggest design techniques for different design situations using artificial intelligence (AI) techniques. Specifically, we leverage conversational agents, recommender techniques, and taxonomic background knowledge to conceptualize and implement an AI-based advisory platform. Following a design science research methodology, we contribute design knowledge for the class of advanced advisory platforms. Furthermore, from a practical point of view, we help design novices with our implemented advisory platform in the contextualized selection process of design techniques. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.","2-s2.0-85087105807"
"Wickramasinghe C.S.; Marino D.L.; Grandio J.; Manic M.","Wickramasinghe, Chathurika S. (57201792033); Marino, Daniel L. (57192210929); Grandio, Javier (57219132675); Manic, Milos (6603474732)","57201792033; 57192210929; 57219132675; 6603474732","Trustworthy AI development guidelines for human system interaction","2020","International Conference on Human System Interaction, HSI","2020-June","","9142644","130","136","6","10.1109/HSI49210.2020.9142644","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091398123&doi=10.1109%2fHSI49210.2020.9142644&partnerID=40&md5=731def9409838f43d9fe3fb1024ed2c4","Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, 'Trustworthy AI' research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.  © 2020 IEEE.","2-s2.0-85091398123"
"Wallach D.P.; Flohr L.A.; Kaltenhauser A.","Wallach, Dieter P. (57193143418); Flohr, Lukas A. (57214990607); Kaltenhauser, Annika (56160070800)","57193143418; 57214990607; 56160070800","Beyond the buzzwords: On the perspective of AI in UX and vice versa","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12217 LNCS","","","146","166","20","10.1007/978-3-030-50334-5_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088752196&doi=10.1007%2f978-3-030-50334-5_10&partnerID=40&md5=b6bbc73ae6bf118f2d9b5e20999b914d","Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies. © Springer Nature Switzerland AG 2020.","2-s2.0-85088752196"
"Bennett S.J.","Bennett, Sarah Joy (57212169673)","57212169673","Investigating the role of moral decision-making in emerging artificial intelligence technologies","2019","Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW","","","","28","32","4","10.1145/3311957.3361858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076101605&doi=10.1145%2f3311957.3361858&partnerID=40&md5=2a892a7ef13fd4e9ca99f4928e555ab8","In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development. © 2019 Copyright is held by the author/owner(s).","2-s2.0-85076101605"
"Alonso J.M.; Ducange P.; Pecori R.; Vilas R.","Alonso, Jose M. (58258461100); Ducange, Pietro (16425459700); Pecori, Riccardo (35186369500); Vilas, Raul (57950513500)","58258461100; 16425459700; 35186369500; 57950513500","Building explanations for fuzzy decision trees with the expliclas software","2020","IEEE International Conference on Fuzzy Systems","2020-July","","9177725","","","","10.1109/FUZZ48607.2020.9177725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089584790&doi=10.1109%2fFUZZ48607.2020.9177725&partnerID=40&md5=3dc6590d1f6254f99645900a2f2c656b","Fairness, Accountability, Transparency and Explainability have become strong requirements in most practical applications of Artificial Intelligence (AI). Fuzzy sets and systems are recognized world-wide because of their outstanding contribution to model AI systems with a good interpretability-accuracy trade-off. Accordingly, fuzzy sets and systems are at the core of the so-called Explainable AI. ExpliClas is a software as a service which paves the way for interpretable and self-explainable intelligent systems. Namely, this software provides users with both graphical visualizations and textual explanations associated with intelligent classifiers automatically learned from data. This paper presents the new functionality of ExpliClas regarding the generation, evaluation and explanation of fuzzy decision trees along with fuzzy inference-grams. This new functionality is validated with two well-known classification datasets (i.e., Wine and Pima), but also with a real-world beer-style classifier. © 2020 IEEE.","2-s2.0-85089584790"
"Kawamura T.; Egami S.; Tamura K.; Hokazono Y.; Ugai T.; Koyanagi Y.; Nishino F.; Okajima S.; Murakami K.; Takamatsu K.; Sugiura A.; Shiramatsu S.; Zhang X.; Kozaki K.","Kawamura, Takahiro (7401949024); Egami, Shusaku (56500236200); Tamura, Koutarou (57215413282); Hokazono, Yasunori (57215410491); Ugai, Takanori (23391288500); Koyanagi, Yusuke (57205398857); Nishino, Fumihito (56269693500); Okajima, Seiji (22835438000); Murakami, Katsuhiko (7403891960); Takamatsu, Kunihiko (57191334406); Sugiura, Aoi (57215411906); Shiramatsu, Shun (24605680200); Zhang, Xiangyu (57215436901); Kozaki, Kouji (8419239000)","7401949024; 56500236200; 57215413282; 57215410491; 23391288500; 57205398857; 56269693500; 22835438000; 7403891960; 57191334406; 57215411906; 24605680200; 57215436901; 8419239000","Report on the first knowledge graph reasoning challenge 2018: Toward the eXplainable AI system","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12032 LNCS","","","18","34","16","10.1007/978-3-030-41407-8_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080871686&doi=10.1007%2f978-3-030-41407-8_2&partnerID=40&md5=8a4050ba698b4587c6a70630d5968f95","A new challenge for knowledge graph reasoning started in 2018. Deep learning has promoted the application of artificial intelligence (AI) techniques to a wide variety of social problems. Accordingly, being able to explain the reason for an AI decision is becoming important to ensure the secure and safe use of AI techniques. Thus, we, the Special Interest Group on Semantic Web and Ontology of the Japanese Society for AI, organized a challenge calling for techniques that reason and/or estimate which characters are criminals while providing a reasonable explanation based on an open knowledge graph of a well-known Sherlock Holmes mystery story. This paper presents a summary report of the first challenge held in 2018, including the knowledge graph construction, the techniques proposed for reasoning and/or estimation, the evaluation metrics, and the results. The first prize went to an approach that formalized the problem as a constraint satisfaction problem and solved it using a lightweight formal method; the second prize went to an approach that used SPARQL and rules; the best resource prize went to a submission that constructed word embedding of characters from all sentences of Sherlock Holmes novels; and the best idea prize went to a discussion multi-agents model. We conclude this paper with the plans and issues for the next challenge in 2019. © Springer Nature Switzerland AG 2020.","2-s2.0-85080871686"
"Jüngling S.; Peraic M.; Martin A.","Jüngling, Stephan (36882543000); Peraic, Martin (57216894385); Martin, Andreas (55708423600)","36882543000; 57216894385; 55708423600","Towards AI-based Solutions in the System Development Lifecycle","2020","CEUR Workshop Proceedings","2600","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085159097&partnerID=40&md5=43d367a321584566a2fadac7adb031f7","Many teams across different industries and organizations explicitly apply agile methodologies such as Scrum in their system development lifecycle (SDLC). The choice of the technology stack, the programming language, or the decision whether AI solutions could be incorporated into the system design either is given by corporate guidelines or is chosen by the project team based on their individual skill set. The paper describes the business case of implementing an AI-based automatic passenger counting system for public transportation, shows preliminary results of the prototype using anonymous passenger recognition on the edge with the help of Google Coral devices. It shows how different solutions could be integrated with the help of rule base systems and how AI-based solutions could be established in the SDLC as valid and cost-saving alternatives to traditionally programmed software components. Copyright © 2020 held by the author(s).","2-s2.0-85085159097"
"Saariluoma P.; Leikas J.","Saariluoma, Pertti (6701538700); Leikas, Jaana (14008025600)","6701538700; 14008025600","Designing ethical AI in the shadow of Hume’s guillotine","2020","Advances in Intelligent Systems and Computing","1131 AISC","","","594","599","5","10.1007/978-3-030-39512-4_92","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081937280&doi=10.1007%2f978-3-030-39512-4_92&partnerID=40&md5=e85667f93b5ebb1b4991d0368b2a232f","Artificially intelligent systems can collect knowledge regarding epistemic information, but can they be used to derive new values? Epistemic information concerns facts, including how things are in the world, and ethical values concern how actions should be taken. The operation of artificial intelligence (AI) is based on facts, but it require values. A critical question here regards Hume’s Guillotine, which claims that one cannot derive values from facts. Hume’s Guillotine appears to divide AI systems into two ethical categories: weak and strong. Ethically weak AI systems can be applied only within given value rules, but ethically strong AI systems may be able to generate new values from facts. If Hume is correct, ethically strong AI systems are impossible, but there are, of course, no obstacles to designing ethically weak AI systems. © Springer Nature Switzerland AG 2020.","2-s2.0-85081937280"
"Vakkuri V.; Kemell K.-K.; Abrahamsson P.","Vakkuri, Ville (57203640458); Kemell, Kai-Kristian (57203633786); Abrahamsson, Pekka (7006011356)","57203640458; 57203633786; 7006011356","ECCOLA - A Method for Implementing Ethically Aligned AI Systems","2020","Proceedings - 46th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2020","","","9226275","195","204","9","10.1109/SEAA51224.2020.00043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096603337&doi=10.1109%2fSEAA51224.2020.00043&partnerID=40&md5=338ff4dfe5cd9462bd546222b2e24e7f","Various recent Artificial Intelligence (AI) system failures, some of which have made the global headlines, have highlighted issues in these systems. These failures have resulted in calls for more ethical AI systems that better take into account their effects on various stakeholders. However, implementing AI ethics into practice is still an on-going challenge. High-level guidelines for doing so exist, devised by governments and private organizations alike, but lack practicality for developers. To address this issue, in this paper, we present a method for implementing AI ethics. The method, ECCOLA, has been iteratively developed using a cyclical action design research approach. The method aims at making the high-level AI ethics principles more practical, making it possible for developers to more easily implement them in practice.  © 2020 IEEE.","2-s2.0-85096603337"
"Diosan L.; Motogna S.","Diosan, Laura (14032958500); Motogna, Simona (24438406300)","14032958500; 24438406300","Artificial intelligence meets software engineering in the classroom","2019","EASEAI 2019 - Proceedings of the 1st ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence, co-located with ESEC/FSE 2019","","","","35","38","3","10.1145/3340435.3342718","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077817307&doi=10.1145%2f3340435.3342718&partnerID=40&md5=e8bbacace84e8e486199e234b1e0d1bb","We aimed to assess the reliability of teaching Artificial Intelligence for Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements. We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.; The current study presents the experience gained while introducing a course with two main purposes: i) use of AI methods and algorithms in solving real life problems and ii) integrate AI specific solutions in software systems. We explained the principle in designing the course content, with a special attention dedicated to the applicative part. We described in detail how the application stages interleaves AI tasks (model representation, training, statistical analysis) with SE tasks (requirements engineering, SE processes, project management). In the end, we give an overview of the course evaluation. The essential characteristics that differentiate the course from a generalist one, is dealing with real life industry data and specific software development phases for integrated AI projects. © 2019 Association for Computing Machinery.","2-s2.0-85077817307"
"Osmani N.","Osmani, Nora (57217830496)","57217830496","The complexity of criminal liability of AI systems","2020","Masaryk University Journal of Law and Technology","14","1","","53","82","29","10.5817/MUJLT2020-1-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087649303&doi=10.5817%2fMUJLT2020-1-3&partnerID=40&md5=7b7dacbccf86f12485eba2867b5185fb","Technology is advancing at a rapid pace. As we anticipate a rapid increase in artificial intelligence (AI), we may soon find ourselves dealing with fully autonomous technology with the capacity to cause harm and injuries. What then? Who is going to be held accountable if AI systems harm us? Currently there is no answer to this question and the existing regulatory framework falls short in addressing the accountability regime of autonomous systems. This paper analyses criminal liability of AI systems, evaluated under the existing rules of criminal law. It highlights the social and legal implications of the current criminal liability regime as it is applied to the complex nature of industrial robots. Finally, the paper explores whether corporate liability is a viable option and what legal standards are possible for imposing criminal liability on the companies who deploy AI systems. The paper reveals that traditional criminal law and legal theory are not well positioned to answer the questions at hand, as there are many practical problems that require further evaluation. I have demonstrated that with the development of AI, more questions will surface and legal frameworks will inevitably need to adapt. The conclusions of this paper could be the basis for further research. © 2020, Masaryk University Journal of Law and Technology. All rights reserved.","2-s2.0-85087649303"
"Ange T.; Roger N.; Aude D.","Ange, Tato (56912125000); Roger, Nkambou (22433265700); Aude, Dufresne (57203073258)","56912125000; 22433265700; 57203073258","Using ai techniques in a serious game for socio-moral reasoning development","2020","AAAI 2020 - 34th AAAI Conference on Artificial Intelligence","","","","13477","13484","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106461615&partnerID=40&md5=9af90739b8fd3c8be6a691928d8a5617","We present a serious game designed to help players/learners develop socio-moral reasoning (SMR) maturity. It is based on an existing computerized task that was converted into a game to improve the motivation of learners. The learner model is computed using a hybrid deep learning architecture, and adaptation rules are provided by both human experts and machine learning techniques. We conducted some experiments with two versions of the game (the initial version and the adaptive version with AI-Based learner modeling). The results show that the adaptive version provides significant better results in terms of learning gain.  © 2020, Association for the Advancement of Artificial Intelligence.","2-s2.0-85106461615"
"de Filippis M.L.; Federici S.; Mele M.L.; Borsci S.; Bracalenti M.; Gaudino G.; Cocco A.; Amendola M.; Simonetti E.","de Filippis, Maria Laura (56490853000); Federici, Stefano (8595217000); Mele, Maria Laura (35332599300); Borsci, Simone (26656618800); Bracalenti, Marco (56983015600); Gaudino, Giancarlo (24080042300); Cocco, Antonello (57195603385); Amendola, Massimo (57202610767); Simonetti, Emilio (57210161095)","56490853000; 8595217000; 35332599300; 26656618800; 56983015600; 24080042300; 57195603385; 57202610767; 57210161095","Preliminary results of a systematic review: Quality assessment of conversational agents (chatbots) for people with disabilities or special needs","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12376 LNCS","","","250","257","7","10.1007/978-3-030-58796-3_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091494475&doi=10.1007%2f978-3-030-58796-3_30&partnerID=40&md5=0b170510c88745c7b705c76186ff1761","People with disabilities or special needs can benefit from AI-based conversational agents, which are used in competence training and well-being management. Assessment of the quality of interactions with these chatbots is key to being able to reduce dissatisfaction with them and to understand their potential long-term benefits. This will in turn help to increase adherence to their use, thereby improving the quality of life of the large population of end-users that they are able to serve. We systematically reviewed the literature on methods of assessing the perceived quality of interactions with chatbots, and identified only 15 of 192 papers on this topic that included people with disabilities or special needs in their assessments. The results also highlighted the lack of a shared theoretical framework for assessing the perceived quality of interactions with chatbots. Systematic procedures based on reliable and valid methodologies continue to be needed in this field. The current lack of reliable tools and systematic methods for assessing chatbots for people with disabilities and special needs is concerning, and may lead to unreliable systems entering the market with disruptive consequences for users. Three major conclusions can be drawn from this systematic analysis: (i) researchers should adopt consolidated and comparable methodologies to rule out risks in use; (ii) the constructs of satisfaction and acceptability are different, and should be measured separately; (iii) dedicated tools and methods for assessing the quality of interaction with chatbots should be developed and used to enable the generation of comparable evidence. © Springer Nature Switzerland AG 2020.","2-s2.0-85091494475"
"Jiang X.","Jiang, Xiuhua (57221258392)","57221258392","AI-based Research and Application of Fault Diagnosis for Steam Turbine Regenerative System","2020","Proceedings - 2020 International Conference on Information Science, Parallel and Distributed Systems, ISPDS 2020","","","9258563","333","335","2","10.1109/ISPDS51347.2020.00077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098658115&doi=10.1109%2fISPDS51347.2020.00077&partnerID=40&md5=5c8c7fbd74176f82463fb3f77f05f363","As the key equipment of electric power plant, the safe operation of steam turbine plays a vital role in practical production. At the same time, the normal and stable operation of excitation system, water-oxygen cooling system, regenerative system and other set system also play a decisive role in the safe operation of the unit. Fault diagnosis in the past mainly relied on the domain experts to judge the type of fault based on its experience, which has too much limitation, it is difficult to make effective diagnosis for the unconspicuous fault. The paper analyzed the common failures of the steam turbine regenerative system and established a typical fault set of the regenerative system. On the basis of using the fuzzy rules to establish knowledge base of fault symptom of regenerative system, a fault diagnosis method of regenerative system based on support vector machine multi-classification algorithm was proposed. Finally, the method was applied to the fault diagnosis of the regenerative system of a steam turbine. The experimental results showed that the model could effectively identify the fault of the regenerative system. © 2020 IEEE.","2-s2.0-85098658115"
"Ahuja M.K.; Belaid M.-B.; Bernab P.; Collet M.; Gotlieb A.; Lal C.; Marijan D.; Sen S.; Sharif A.; Spieker H.","Ahuja, Mohit Kumar (57218949684); Belaid, Mohamed-Bachir (57208898379); Bernab, Pierre (57219759577); Collet, Mathieu (57209274580); Gotlieb, Arnaud (56247674500); Lal, Chhagan (46661734600); Marijan, Dusica (34872942800); Sen, Sagar (57191630408); Sharif, Aizaz (57218950297); Spieker, Helge (57189329650)","57218949684; 57208898379; 57219759577; 57209274580; 56247674500; 46661734600; 34872942800; 57191630408; 57218950297; 57189329650","Opening the software engineering toolbox for the assessment of trustworthy AI","2020","CEUR Workshop Proceedings","2659","","","67","70","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090901906&partnerID=40&md5=053ba6b4c8911ffab65c6cb88fe8c0ac","Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85090901906"
"Park S.Y.; Kuo P.-Y.; Barbarin A.; Kaziunas E.; Chow A.; Singh K.; Wilcox L.; Lasecki W.S.","Park, Sun Young (52864509600); Kuo, Pei-Yi (55800600600); Barbarin, Andrea (57189308738); Kaziunas, Elizabeth (37023365200); Chow, Astrid (58253871800); Singh, Karandeep (56531139000); Wilcox, Lauren (23040470800); Lasecki, Walter S. (54383728900)","52864509600; 55800600600; 57189308738; 37023365200; 58253871800; 56531139000; 23040470800; 54383728900","Identifying challenges and opportunities in human-AI collaboration in healthcare","2019","Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW","","","","506","510","4","10.1145/3311957.3359433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076091592&doi=10.1145%2f3311957.3359433&partnerID=40&md5=33cd170342790cfd26067b51e6327e53","The proposed workshop will identify research questions that will enable the field to uncover the types of work, labor relations, and social impacts that should be considered when designing AI-based healthcare technology. The workshop aims to outline key challenges, guidelines, and future agendas for the field, and provide collaboration opportunities for CSCW researchers, social scientists, AI researchers, clinicians, and relevant stakeholders in healthcare, to share their perspectives and co-create sociotechnical approaches to tackle timely issues related to AI and automation in healthcare work. © 2019 Copyright is held by the author/owner(s).","2-s2.0-85076091592"
"Zhang T.; Li H.; Xu L.; Gao J.; Guan J.; Cheng X.","Zhang, Tao (57192590288); Li, Haibin (57215539071); Xu, Lexi (35207681600); Gao, Jie (57192576453); Guan, Jian (57192590765); Cheng, Xinzhou (36631926300)","57192590288; 57215539071; 35207681600; 57192576453; 57192590765; 36631926300","Comprehensive IoT SIM card anomaly detection algorithm based on big data","2019","Proceedings - 2019 IEEE International Conferences on Ubiquitous Computing and Communications and Data Science and Computational Intelligence and Smart Computing, Networking and Services, IUCC/DSCI/SmartCNS 2019","","","8982655","602","606","4","10.1109/IUCC/DSCI/SmartCNS.2019.00126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081103089&doi=10.1109%2fIUCC%2fDSCI%2fSmartCNS.2019.00126&partnerID=40&md5=7528323a18fdac8d70408bf637da1103","The mobile Internet of Things (IoT) industry in China has developed rapidly and is expected to maintain rapid growth in the next decade. For the three mobile operators in China, IoT gradually becomes the new/key engine for profit growth. However, at the early stage of IoT development, due to the low cost of IoT SIM card, some illegal organizations and individuals take advantage of this loophole to earn illegal profits, which cause huge losses for mobile operators. In this paper, we explore comprehensive abnormal IoT SIM card detection algorithm based on IoT big data. For different IoT scenarios, this paper proposes two kinds of algorithms, including various rule-based detection algorithm (RDA) and AI-based detection algorithm (AIDA). The result of use case also shows that RDA and AIDA can greatly improve the anomaly detection accuracy and can benefit both of the telecommunication operators and enterprise customers. © 2019 IEEE.","2-s2.0-85081103089"
"Loreggia A.; Mattei N.; Rossi F.; Venable K.B.","Loreggia, Andrea (55960531800); Mattei, Nicholas (35234406800); Rossi, Francesca (56066648900); Venable, K. Brent (13105383400)","55960531800; 35234406800; 56066648900; 13105383400","CPMetric: Deep siamese networks for metric learning on structured preferences","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12158 LNAI","","","217","234","17","10.1007/978-3-030-56150-5_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090097667&doi=10.1007%2f978-3-030-56150-5_11&partnerID=40&md5=35e3eb02f92e089c352f7c245812c7f7","Preferences are central to decision making by both machines and humans. Representing, learning, and reasoning with preferences is an important area of study both within computer science and across the social sciences. When we give our preferences to an AI system we expect the system to make decisions or recommendations that are consistent with our preferences but the decisions should also adhere to certain norms, guidelines, and ethical principles. Hence, when working with preferences it is necessary to understand and compute a metric (distance) between preferences – especially if we encode both the user preferences and ethical systems in the same formalism. In this paper we investigate the use of CP-nets as a formalism for representing orderings over actions for AI systems. We leverage a recently proposed metric for CP-nets and propose a neural network architecture to learn an approximation of the metric, CPMetric. Using these two tools we look at how one can build a fast and flexible value alignment system (This is an expanded version of our paper, “Metric Learning for Value Alignment”[38]. In this version we have added the classification and regression results and significantly expanded the description of the CPMetric network.). © Springer Nature Switzerland AG 2020.","2-s2.0-85090097667"
"Sildatke M.; Karwanni H.; Kraft B.; Schmidts O.; Zündorf A.","Sildatke, Michael (57219488927); Karwanni, Hendrik (57219491147); Kraft, Bodo (57213973214); Schmidts, Oliver (57209339552); Zündorf, Albert (56000503100)","57219488927; 57219491147; 57213973214; 57209339552; 56000503100","Automated Software Quality Monitoring in Research Collaboration Projects","2020","Proceedings - 2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops, ICSEW 2020","","","","603","610","7","10.1145/3387940.3391478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093118440&doi=10.1145%2f3387940.3391478&partnerID=40&md5=6844825bf966111b5c2a5766e56a96fc","In collaborative research projects, both researchers and practitioners work together solving business-critical challenges. These projects often deal with ETL processes, in which humans extract information from non-machine-readable documents by hand. AI-based machine learning models can help to solve this problem. Since machine learning approaches are not deterministic, their quality of output may decrease over time. This fact leads to an overall quality loss of the application which embeds machine learning models. Hence, the software qualities in development and production may differ. Machine learning models are black boxes. That makes practitioners skeptical and increases the inhibition threshold for early productive use of research prototypes. Continuous monitoring of software quality in production offers an early response capability on quality loss and encourages the use of machine learning approaches. Furthermore, experts have to ensure that they integrate possible new inputs into the model training as quickly as possible. In this paper, we introduce an architecture pattern with a reference implementation that extends the concept of Metrics Driven Research Collaboration with an automated software quality monitoring in productive use and a possibility to auto-generate new test data coming from processed documents in production. Through automated monitoring of the software quality and auto-generated test data, this approach ensures that the software quality meets and keeps requested thresholds in productive use, even during further continuous deployment and changing input data.  © 2020 ACM.","2-s2.0-85093118440"
"Rouzbahani H.M.; Faraji Z.; Amiri-Zarandi M.; Karimipour H.","Rouzbahani, Hossein Mohammadi (57215660781); Faraji, Zahra (57224249735); Amiri-Zarandi, Mohammad (56431124700); Karimipour, Hadis (35386597500)","57215660781; 57224249735; 56431124700; 35386597500","AI-Enabled Security Monitoring in Smart Cyber Physical Grids","2020","Security of Cyber-Physical Systems: Vulnerability and Impact","","","","145","167","22","10.1007/978-3-030-45541-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127217628&doi=10.1007%2f978-3-030-45541-5_8&partnerID=40&md5=c40d1b957873dcaf26b9abb20f526015","According to the increasing demand for electrical energy, the development of power systems and using smart grid technologies are vital. Smart grids are known as the new generation of power systems applying intelligent tools and features to provide higher performance, stability, reliability, and manageability. For these purposes, power systems face two major challenges. The first one is the systems are more vulnerable to a cyberattack. This vulnerability originates from relying on Information and Communication Technology (ICT) systems. The second challenge is the consumption of fossil fuels as a major power source increases, which is costly and pollutes the environment, so it is necessary to use renewable energy like the wind as an alternative. Regarding enormous fluctuations in wind speed at different months and even each minute of a day, whereas it is impossible to store electrical energy on a massive scale, prediction plays a major rule to integrate the power grid and wind energy. Therefore, to address these challenges, some of the Machine Learning algorithms are tested to detect attacks and predict wind power generation. This chapter first detects attacks on a dataset that comes from a smart grid, the results are compared based on F-Score (Precision/Recall) Accuracy and also considering the velocity. The results show the best performance belongs to the Random forest if test time (score time) is ignored otherwise the K-Nearest Neighbor (KNN) has great performance. Towards the end, predict wind power generation by using a dataset that has been collected over a period of six years, by considering the nature of the dataset as a time series pattern, several methods of learning like Neural network (NN), Long short-term memory (LSTM) have been applied. Finally, Mean Absolute Error (MAE) and accuracy are chosen to evaluate the performance of the methods. © Springer Nature Switzerland AG 2020.","2-s2.0-85127217628"
"Díaz-Rodríguez N.; Pisoni G.","Díaz-Rodríguez, Natalia (55904010200); Pisoni, Galena (56007943500)","55904010200; 56007943500","Accessible Cultural Heritage through Explainable Artificial Intelligence","2020","UMAP 2020 Adjunct - Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization","","","","317","324","7","10.1145/3386392.3399276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089279398&doi=10.1145%2f3386392.3399276&partnerID=40&md5=2414463b2e49420162364734f4c286c9","Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy. © 2020 ACM.","2-s2.0-85089279398"
"Vakkuri V.; Kemell K.-K.; Kultanen J.; Abrahamsson P.","Vakkuri, Ville (57203640458); Kemell, Kai-Kristian (57203633786); Kultanen, Joni (57212190406); Abrahamsson, Pekka (7006011356)","57203640458; 57203633786; 57212190406; 7006011356","The Current State of Industrial Practice in Artificial Intelligence Ethics","2020","IEEE Software","37","4","9055379","50","57","7","10.1109/MS.2020.2985621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083006137&doi=10.1109%2fMS.2020.2985621&partnerID=40&md5=aaba6981f5c34875848add2db6ccf5a7","High-level guidelines and tools for managing artificial intelligence (AI) ethics have been introduced to help industry organizations make more ethical AI systems. The results of a survey of 211 software companies provide insights into the current state of industrial practice. © 1984-2012 IEEE.","2-s2.0-85083006137"
"Fujita S.; Gidel T.; Kaeri Y.; Tucker A.; Sugawara K.; Moulin C.","Fujita, Shigeru (35420085100); Gidel, Thierry (16636227600); Kaeri, Yuki (36998309100); Tucker, Andrea (57215058069); Sugawara, Kenji (7202558822); Moulin, Claude (22433426000)","35420085100; 16636227600; 36998309100; 57215058069; 7202558822; 22433426000","AI-based Automatic Activity Recognition of Single Persons and Groups during Brainstorming","2020","Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","2020-October","","9282981","3782","3787","5","10.1109/SMC42975.2020.9282981","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098882993&doi=10.1109%2fSMC42975.2020.9282981&partnerID=40&md5=175ba5ed8cc754351b5e00b9c4691407","In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person's motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person's activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students' work sessions. © 2020 IEEE.","2-s2.0-85098882993"
"Saariluoma P.","Saariluoma, Pertti (6701538700)","6701538700","Hume’s Guillotine Resolved","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12215 LNCS","","","123","132","9","10.1007/978-3-030-50267-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089165744&doi=10.1007%2f978-3-030-50267-6_10&partnerID=40&md5=001adb8321de0a77001fb69e39a56788","According to Hume’s guillotine, one cannot derive values from facts. Since intelligent systems are fact processors, one can ask how ethical machines can be possible. However, ethics is a real-life process. People analyze actions and situations emotionally and cognitively. Thus they learn rules, such as “this situation feels good/bad.” The cognitive analysis of actions is associated with emotional analysis. The association of action, emotion and cognition can be termed a primary ethical schema. Through an ethical information process in which emotions and cognitions interact in social discourse, primary ethical schemas are refined into ethical norms. Each component of the process is different, but they cooperate to construct an ethical approach to thinking. Hume’s guillotine mistakenly breaks down primary ethical schemas and juxtaposes emotions and cognitions. There is no ethics without coordinated emotional, cognitive and social analysis. Therefore, his theory can be seen as a pseudo problem. In the future, ethical processes will involve intelligent systems that can make ethical choices. Weak ethical artificial intelligence (AI) systems can apply given ethical rules to data, while strong ethical AI systems can derive their own rules from data and knowledge about human emotions. Resolving Hume’s guillotine introduces new ways to develop stronger forms of ethical AI. © 2020, Springer Nature Switzerland AG.","2-s2.0-85089165744"
"Marino D.L.; Grandio J.; Wickramasinghe C.S.; Schroeder K.; Bourne K.; Filippas A.V.; Manic M.","Marino, Daniel L. (57192210929); Grandio, Javier (57219132675); Wickramasinghe, Chathurika S. (57201792033); Schroeder, Kyle (57220509284); Bourne, Keith (36441077700); Filippas, Afroditi V. (55657397000); Manic, Milos (6603474732)","57192210929; 57219132675; 57201792033; 57220509284; 36441077700; 55657397000; 6603474732","AI augmentation for trustworthy AI: Augmented robot teleoperation","2020","International Conference on Human System Interaction, HSI","2020-June","","9142659","155","161","6","10.1109/HSI49210.2020.9142659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091399844&doi=10.1109%2fHSI49210.2020.9142659&partnerID=40&md5=591fe4a855eab6f72eb645b9be397949","Despite the performance of state-of-the-art Artificial Intelligence (AI) systems, some sectors hesitate to adopt AI because of a lack of trust in these systems. This attitude is prevalent among high-risk areas, where there is a reluctance to remove humans entirely from the loop. In these scenarios, Augmentation provides a preferred alternative over complete Automation. Instead of replacing humans, AI Augmentation uses AI to improve and support human operations, creating an environment where humans work side by side with AI systems. In this paper, we discuss how AI Augmentation can provide a path for building Trustworthy AI. We exemplify this approach using Robot Teleoperation. We lay out design guidelines and motivations for the development of AI Augmentation for Robot Teleoperation. Finally, we discuss the design of a Robot Teleoperation testbed for the development of AI Augmentation systems.  © 2020 IEEE.","2-s2.0-85091399844"
"Balasubramaniam N.; Kauppinen M.; Kujala S.; Hiekkanen K.","Balasubramaniam, Nagadivya (57201946113); Kauppinen, Marjo (9044243800); Kujala, Sari (55377510200); Hiekkanen, Kari (37017103300)","57201946113; 9044243800; 55377510200; 37017103300","Ethical Guidelines for Solving Ethical Issues and Developing AI Systems","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12562 LNCS","","","331","346","15","10.1007/978-3-030-64148-1_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097645237&doi=10.1007%2f978-3-030-64148-1_21&partnerID=40&md5=d3d0639120d844fa94c9c3033eaebee6","Artificial intelligence (AI) has become a fast-growing trend. Increasingly, organizations are interested in developing AI systems, but many of them have realized that the use of AI technologies can raise ethical questions. The goal of this study was to analyze what kind of ethical guidelines companies have for solving potential ethical issues of AI and developing AI systems. This paper presents the results of the case study conducted in three companies. The ethical guidelines defined by the case companies focused on solving potential ethical issues, such as accountability, explainability, fairness, privacy, and transparency. To analyze different viewpoints on critical ethical issues, two of the companies recommended using multi-disciplinary development teams. The companies also considered defining the purposes of their AI systems and analyzing their impacts to be important practices. Based on the results of the study, we suggest that organizations develop and use ethical guidelines to prioritize critical quality requirements of AI. The results also indicate that transparency, explainability, fairness, and privacy can be critical quality requirements of AI systems. © 2020, Springer Nature Switzerland AG.","2-s2.0-85097645237"
"Nguyen T.-L.; Kavuri S.; Lee M.","Nguyen, Tuan-Linh (57754841100); Kavuri, Swathi (34881754200); Lee, Minho (57191730119)","57754841100; 34881754200; 57191730119","A multimodal convolutional neuro-fuzzy network for emotion understanding of movie clips","2019","Neural Networks","118","","","208","219","11","10.1016/j.neunet.2019.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068521737&doi=10.1016%2fj.neunet.2019.06.010&partnerID=40&md5=6877fe50695bc699097c38c79499fd3e","Multimodal emotion understanding enables AI systems to interpret human emotions. With accelerated video surge, emotion understanding remains challenging due to inherent data ambiguity and diversity of video content. Although deep learning has made a considerable progress in big data feature learning, they are viewed as deterministic models used in a “black-box” manner which does not have capabilities to represent inherent ambiguities with data. Since the possibility theory of fuzzy logic focuses on knowledge representation and reasoning under uncertainty, we intend to incorporate the concepts of fuzzy logic into deep learning framework. This paper presents a novel convolutional neuro-fuzzy network, which is an integration of convolutional neural networks in fuzzy logic domain to extract high-level emotion features from text, audio, and visual modalities. The feature sets extracted by fuzzy convolutional layers are compared with those of convolutional neural networks at the same level using t-distributed Stochastic Neighbor Embedding. This paper demonstrates a multimodal emotion understanding framework with an adaptive neural fuzzy inference system that can generate new rules to classify emotions. For emotion understanding of movie clips, we concatenate audio, visual, and text features extracted using the proposed convolutional neuro-fuzzy network to train adaptive neural fuzzy inference system. In this paper, we go one step further to explain how deep learning arrives at a conclusion that can guide us to an interpretable AI. To identify which visual/text/audio aspects are important for emotion understanding, we use direct linear non-Gaussian additive model to explain the relevance in terms of causal relationships between features of deep hidden layers. The critical features extracted are input to the proposed multimodal framework to achieve higher accuracy. © 2019 Elsevier Ltd","2-s2.0-85068521737"
"Ahir S.; Telavane D.; Thomas R.","Ahir, Shiva (57219612337); Telavane, Dipali (57219609570); Thomas, Riya (57220843600)","57219612337; 57219609570; 57220843600","The impact of Artificial Intelligence, Blockchain, Big Data and evolving technologies in Coronavirus Disease-2019 (COVID-19) curtailment","2020","Proceedings - International Conference on Smart Electronics and Communication, ICOSEC 2020","","","9215294","113","120","7","10.1109/ICOSEC49089.2020.9215294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094192816&doi=10.1109%2fICOSEC49089.2020.9215294&partnerID=40&md5=69d3c375651de733ecaebe1d529028be","The pandemic of Coronavirus Disease 2019 (COVID-19) is proliferating across the globe obnoxiously and it is the most heard buzzword in recent times. Every person ranging from older people, persons with disabilities, youth, indigenous people have become a part of this chain and are most likely to suffer in the upcoming chronology. Social distancing is likely to become a new norm where 'Work from Home', Online Lectures' and 'Meetings' ensue on social media applications. Technology has always lent a helping hand for mankind's problems. The idea focuses on highlighting the advancements in technology in the midst of a bizarre situation. Deep Learning applications to detect the symptoms of COVID-19, AI based robots to maintain social distancing, Blockchain technology to maintain patient records, Mathematical modeling to predict and assess the situation and Big Data to trace the spread of the virus and other technologies. These technologies have immensely contributed to curtailing this pandemic. Strong will power, patience and optimistic guidelines catered by the respective government are some of the altercations to COVID-19.. © 2020 IEEE.","2-s2.0-85094192816"
"Lee T.S.-H.; Liu S.-Y.; Wei Y.-L.; Chang L.-Y.","Lee, Tony Szu-Hsien (16836617800); Liu, Shiang-Yao (11840124000); Wei, Yin-Ling (57321285800); Chang, Li-Yun (55569481500)","16836617800; 11840124000; 57321285800; 55569481500","A Comparative Study on Ethics Guidelines for Artificial Intelligence Across Nations","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12555 LNCS","","","289","295","6","10.1007/978-3-030-63885-6_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097533665&doi=10.1007%2f978-3-030-63885-6_33&partnerID=40&md5=1d265596ba1715009c509a48901478ad","This study aimed to investigate the commonality and differences among AI research and development (R&D) guidelines across nations. Content analysis was conducted on AI R&D guidelines issued by more economically developed countries because they may guide the trend of AI-based applications in education. Specifically, this study consisted of three phases: 1) information retrieval, (2) key term extraction, and (3) data visualization. First, Fisher’s exact test was employed to ensure that different AI R&D guidelines (e.g., the latest ones in the US, EU, Japan, Mainland, and Taiwan) were comparable. Second, the Key Word Extraction System was developed to retrieve essential information in the guidelines. Third, data visualization techniques were performed on key terms across multiple guidelines. A word cloud revealed the similarity among guidelines (e.g., key terms that these guidelines share in common) while a color-coding scheme showed the differences (e.g., occurrence of a key term across guidelines and its frequency within a guideline). Importantly, three key terms, namely, AI, human, and development, are identified as essential commonality across guidelines. As for key terms that only extracted from particular guidelines, interestingly, results with the color-coding scheme suggested that these key terms were weighted differently depends on the developmental emphasis of a nation. Collectively, we discussed how these findings concerning ethics guidelines may shed light on AI research and development to educational technology. © 2020, Springer Nature Switzerland AG.","2-s2.0-85097533665"
"Wang L.; Yan J.; Mu L.; Huang L.","Wang, Lizhe (23029267900); Yan, Jining (55560283600); Mu, Lin (15071932700); Huang, Liang (57213187190)","23029267900; 55560283600; 15071932700; 57213187190","Knowledge discovery from remote sensing images: A review","2020","Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery","10","5","e1371","","","","10.1002/widm.1371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085027407&doi=10.1002%2fwidm.1371&partnerID=40&md5=fd1f20bfbe68d86b9535a8a21680664d","The development of Earth observation (EO) technology has made the volume of remote sensing data archiving continually larger, but the knowledge hidden in massive remote sensing images has not been fully exploited. Through in-depth research on the artificial intelligence (AI)-based knowledge discovery approaches from remote sensing images, we divided them into four typical types according to their development stage, including rule-based approaches, data-driven approaches, reinforcement learning approaches, and ensemble methods. The basic principles, typical applications, advantages, and disadvantages have been detailed for commonly used algorithms within each category. Conclusions include the following: (a) Rule-based, data-driven and reinforcement learning algorithms form a trilogy from knowledge to data, and to capabilities. (b) Rule-based data mining algorithms can provide prior knowledge for data-driven approaches, the knowledge discovered by data-driven models can be as an important complement to expert knowledge and rule sets, and reinforcement learning approaches can effectively make up for the lack of training samples or small training sample in data-driven models. (c) The traditional data-driven machine learning approaches and their ensemble methods are the current and may be the future mainstream methods for large regional and even global scale long time series remote sensing data mining and analysis, and improving their computing efficiency is the key research direction. (d) Deep learning, deep reinforcement learning, transfer learning, and an ensemble approach of the three may be the main means for small-area scope, short time series, and key geoscience information extraction from remote sensing images within a long time of the future. This article is categorized under: Algorithmic Development > Spatial and Temporal Data Mining Fundamental Concepts of Data and Knowledge > Big Data Mining Technologies > Artificial Intelligence. © 2020 Wiley Periodicals LLC.","2-s2.0-85085027407"
"Sivasangari A.; Nivetha S.; Pavithra; Ajitha P.; Gomathi R.M.","Sivasangari, A. (56622983700); Nivetha, S. (58627404300); Pavithra (57221788741); Ajitha, P. (56378348300); Gomathi, R.M. (6507109762)","56622983700; 58627404300; 57221788741; 56378348300; 6507109762","Indian Traffic Sign Board Recognition and Driver Alert System Using CNN","2020","4th International Conference on Computer, Communication and Signal Processing, ICCCSP 2020","","","9315260","","","","10.1109/ICCCSP49186.2020.9315260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100186702&doi=10.1109%2fICCCSP49186.2020.9315260&partnerID=40&md5=99ef1d35dec2937765fd427f855d40a9","Affirmation of traffic signs (TSR) is a popular bit of some ADA (ADAS) and vehicle drivers ' (ADS) schemes. As either the leading main technology of TSR, unveiling of traffic signs (TSD) is a worrying issue due to various styles, small size, complicated riding scenarios and obstacles. From late on various TSD figurations also relied on the view of the computer and even the pattern. A full description of the TSD structure is given in this article. We recommend splitting the field procedures under review into two rule groups: possibility-based, form-based systems. The proposed system is exhaustively apportioned into, data planning, data gathering, and getting ready and testing. System uses variety of picture planning strategies to improve the image quality and to oust non-illuminating pixel, and recognizing edges. Feature extractors are used to find the features of picture. Moved AI figuring Convolutional Neural Networks (CNN) is used to gather the differing traffic sign pictures reliant on their features by using the progressing camera.  © 2020 IEEE.","2-s2.0-85100186702"
"Terra A.; Riaz H.; Raizer K.; Hata A.; Inam R.","Terra, Ahmad (57217302131); Riaz, Hassam (57217304220); Raizer, Klaus (24390809100); Hata, Alberto (35317195500); Inam, Rafia (54381601500)","57217302131; 57217304220; 24390809100; 35317195500; 54381601500","Safety vs. Efficiency: AI-Based Risk Mitigation in Collaborative Robotics","2020","2020 6th International Conference on Control, Automation and Robotics, ICCAR 2020","","","9108037","151","160","9","10.1109/ICCAR49639.2020.9108037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087058230&doi=10.1109%2fICCAR49639.2020.9108037&partnerID=40&md5=7856800f69933207884cf7f106d5eefe","use of AI-based risk mitigation is increasing to provide safety in the areas of smart manufacturing, automated logistics etc, where the human-robot collaboration operations are in use. This paper presents our work on implementation of fuzzy logic system (FLS) and reinforcement learning (RL) to build risk mitigation modules for human-robot collaboration scenarios. Risk mitigation using FLS strategy is developed by manually defining the linguistic values, tuning the membership functions and generating the rules based on ISO/TS15066:2016. RL-based risk mitigation modules are developed using three different Qnetworks to estimate the Q-value function. Our purpose is twofold: to perform a comparative analysis of FLS and RL in terms of safety perspectives and further to evaluate the efficiency to accomplish the task. Our results present that all the proposed risk mitigation strategies improve the safety aspect by up to 26% as compared to a default setup where the robot is just relying on a navigation module without risk mitigation. efficiency of using FLS model is maintained to the default setup, while the efficiency of using RL model is reduced by 26% from the default setup. We also compare the computation performance of risk mitigation between centralized and edge execution where the edge execution is 27.5 times faster than the centralized one. © 2020 IEEE.","2-s2.0-85087058230"
"Niforatos E.; Palma A.; Gluszny R.; Vourvopoulos A.; Liarokapis F.","Niforatos, Evangelos (55221816500); Palma, Adam (57219113908); Gluszny, Roman (57219108676); Vourvopoulos, Athanasios (48762198300); Liarokapis, Fotis (7801416785)","55221816500; 57219113908; 57219108676; 48762198300; 7801416785","Would you do it?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making","2020","Conference on Human Factors in Computing Systems - Proceedings","","","3376788","","","","10.1145/3313831.3376788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091313894&doi=10.1145%2f3313831.3376788&partnerID=40&md5=eb9fbff1754876697db314787cf7e01c","A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas - -The Trolley and the Mad Bomber - -influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems. © 2020 ACM.","2-s2.0-85091313894"
"Wanner J.; Heinrich K.; Janiesch C.; Zschech P.","Wanner, Jonas (57208756773); Heinrich, Kai (55204945400); Janiesch, Christian (23389119300); Zschech, Patrick (56436770700)","57208756773; 55204945400; 23389119300; 56436770700","How much AI do you require? Decision factors for adopting AI technology","2020","International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099537611&partnerID=40&md5=0958a73e399d8c123e887e8063c1955c","Artificial intelligence (AI) based on machine learning technology disrupts how knowledge is gained. Nevertheless, ML's improved accuracy of prediction comes at the cost of low traceability due to its black-box nature. The field of explainable AI tries to counter this. However, for practical use in IT projects, these two research streams offer only partial advice for AI adoption as the trade-off between accuracy and explainability has not been adequately discussed yet. Thus, we simulate a decision process by implementing three best practice AI-based decision support systems for a high-stake maintenance decision scenario and evaluate the decision and attitude factors using the Analytical Hierarchy Process (AHP) through an expert survey. The combined results indicate that system performance is still the most important factor and that implementation effort and explainability are relatively even factors. Further, we found that systems using similarity-based matching or direct modeling for remaining useful life estimation performed best. © ICIS 2020. All rights reserved.","2-s2.0-85099537611"
"Churchill D.; Buro M.; Kelly R.","Churchill, David (57224614728); Buro, Michael (10244652400); Kelly, Richard (57211240858)","57224614728; 10244652400; 57211240858","Robust continuous build-order optimization in starcraft","2019","IEEE Conference on Computatonal Intelligence and Games, CIG","2019-August","","8848109","","","","10.1109/CIG.2019.8848109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073099050&doi=10.1109%2fCIG.2019.8848109&partnerID=40&md5=9fd9537e2096471a5aef39b5c1b8ea81","To solve complex real-world planning problems it is often beneficial to decompose tasks into high-level and low-level components and optimize actions separately. Examples of such modularization include car navigation (a high-level path planning problem) and obstacle avoidance (a lower-level control problem), and decomposing playing policies in modern video games into strategic (""macro"") and tactical (""micro"") components. In real-time strategy (RTS) video games such as StarCraft, players face decision problems ranging from economic development to maneuvering units in combat situations. A popular strategy employed in building AI agents for complex games like StarCraft is to use this strategy of task decomposition to construct separate AI systems for each of these sub-problems, combining them to form a complete game-playing agent. Existing AI systems for such games often contain build-order planning systems that attempt to minimize makespans for constructing specific sets of units, which are typically decided by hand-coded human expert knowledge rules. Drawbacks of this approach include the human expert effort involved in constructing these rules, as well as a lack of online adaptability to unforeseen circumstances, which can lead to brittle behavior that can be exploited by more advanced opponents. In this paper we introduce a new robust build-order planning system for RTS games that automatically produces build-orders which optimize unit compositions toward strategic game concepts (such as total unit firepower), without the need for specific unit goals. When incorporated into an existing StarCraft AI agent in a real tournament setting, it outperformed the previous state-of-the-art planning system which relied on human expert knowledge rules for deciding unit compositions. © 2019 IEEE.","2-s2.0-85073099050"
"Calvaresi D.; Schumacher M.; Calbimonte J.-P.","Calvaresi, Davide (56358489700); Schumacher, Michael (22235461500); Calbimonte, Jean-Paul (36719884300)","56358489700; 22235461500; 36719884300","Agent-based Modeling for Ontology-driven Analysis of Patient Trajectories","2020","Journal of Medical Systems","44","9","158","","","","10.1007/s10916-020-01620-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088900165&doi=10.1007%2fs10916-020-01620-8&partnerID=40&md5=b9f8bd1f753248bab218af7092525eab","Patients are often required to follow a medical treatment after discharge, e.g., for a chronic condition, rehabilitation after surgery, or for cancer survivor therapies. The need to adapt to new lifestyles, medication, and treatment routines, can produce an individual burden to the patient, who is often at home without the full support of healthcare professionals. Although technological solutions –in the form of mobile apps and wearables– have been proposed to mitigate these issues, it is essential to consider individual characteristics, preferences, and the context of a patient in order to offer personalized and effective support. The specific events and circumstances linked to an individual profile can be abstracted as a patient trajectory, which can contribute to a better understanding of the patient, her needs, and the most appropriate personalized support. Although patient trajectories have been studied for different illnesses and conditions, it remains challenging to effectively use them as the basis for data analytics methodologies in decentralized eHealth systems. In this work, we present a novel approach based on the multi-agent paradigm, considering patient trajectories as the cornerstone of a methodology for modelling eHealth support systems. In this design, semantic representations of individual treatment pathways are used in order to exchange patient-relevant information, potentially fed to AI systems for prediction and classification tasks. This paper describes the major challenges in this scope, as well as the design principles of the proposed agent-based architecture, including an example of its use through a case scenario for cancer survivors support. © 2020, The Author(s).","2-s2.0-85088900165"
"Kuleshov A.; Ignatiev A.; Abramova A.; Marshalko G.","Kuleshov, Andrey (57194563875); Ignatiev, Andrey (57219266836); Abramova, Anna (57192180013); Marshalko, Grigory (57209234036)","57194563875; 57219266836; 57192180013; 57209234036","Addressing AI ethics through codification","2020","Proceedings - 2020 International Conference Engineering Technologies and Computer Science, EnT 2020","","","9140627","24","30","6","10.1109/EnT48576.2020.00011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091986094&doi=10.1109%2fEnT48576.2020.00011&partnerID=40&md5=b16f639dea5b90a9d953c3400d51d88b","AI ethics rapidly becomes one of the most significant issues in assessing the impact of AI on social welfare and development. A technology that does not meet the ethical criteria of a society is likely to face a long and hard process of acceptance regardless of its potentially tremendous positive potential for long-term socio-economic development. The development of artificial intelligence (AI) technologies is undoubtedly associated with the need to answer ethical questions, and the perception of AI in society will be largely determined by compliance with ethical criteria, whether written or not. At the same time, AI as a technological system itself does not have a natural ethical content; the authors believe that in practice ethical concerns may be addressed by means of ethical codes and compliance rules that articulate what constitutes ethical behaviour in specific areas of application of AI systems. Such a set of rules (a code for AI ethics) could be followed by all actors throughout the complete lifecycle of the system starting with the design stage. The specification of general ethical principles as industry-specific codes of practice would also facilitate classification, evaluation and measurement of systems, both at the technical level and at the level of public perception and trust.The article considers examples of codification of ethical principles and offers several approaches for practical use in solving issues of ethics in the field of AI at the national and international level.  © 2020 IEEE.","2-s2.0-85091986094"
"Mostafazadeh N.; Kalyanpur A.; Moon L.; Buchanan D.; Berkowitz L.; Biran O.; Chu-Carroll J.","Mostafazadeh, Nasrin (39061829100); Kalyanpur, Aditya (23008871500); Moon, Lori (54943632100); Buchanan, David (29367504500); Berkowitz, Lauren (57221142622); Biran, Or (54392566700); Chu-Carroll, Jennifer (6602607876)","39061829100; 23008871500; 54943632100; 29367504500; 57221142622; 54392566700; 6602607876","GLUCOSE: GeneraLized and contextualized story explanations","2020","EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference","","","","4569","4586","17","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098784673&partnerID=40&md5=771e6873af2d80ba084a228b5b6c7a2b","When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of 670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models. © 2020 Association for Computational Linguistics","2-s2.0-85098784673"
"Muzyka K.","Muzyka, Kamil (57208003679)","57208003679","The basic rules for coexistence: The possible applicability of metalaw for human-AGI relations","2020","Paladyn","11","1","","104","117","13","10.1515/pjbr-2020-0011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084764995&doi=10.1515%2fpjbr-2020-0011&partnerID=40&md5=a11fa6f09e5c52ceab8018a97520c88c","Human-AGI relations are soon going to be a subject to number of policies and regulations. Although most current Blue Sky de lege ferenda postulates towards robot and artificial intelligence regulatory framework are focused on the liability of the producer or the owner of the AI based product, one might try to conceptualize the legal relations and rules for the coexistence between humans and an anthropocognitive AI's (AGI) possessing proper capacity. The main purpose of this article is to explore the possibility of applying the principles of Metalaw to mentioned relations. The scope shall consider a non-chattel and non-property based status of those types of AIs, as well as sufficient advancement of such entities, or the emergence of advanced non-human based intelligence. © 2020 Kamil Muzyka, published by De Gruyter 2020.","2-s2.0-85084764995"
"Martinez-Plumed F.; Hernandez-Orallo J.","Martinez-Plumed, Fernando (36716636100); Hernandez-Orallo, Jose (6602454434)","36716636100; 6602454434","Dual Indicators to Analyze AI Benchmarks: Difficulty, Discrimination, Ability, and Generality","2020","IEEE Transactions on Games","12","2","8550672","121","131","10","10.1109/TG.2018.2883773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082172773&doi=10.1109%2fTG.2018.2883773&partnerID=40&md5=98ebc49013b528808a70348ee38275ec","With the purpose of better analyzing the result of artificial intelligence (AI) benchmarks, we present two indicators on the side of the AI problems, difficulty and discrimination, and two indicators on the side of the AI systems, ability and generality. The first three are adapted from psychometric models in item response theory (IRT), whereas generality is defined as a new metric that evaluates whether an agent is consistently good at easy problems and bad at difficult ones. We illustrate how these key indicators give us more insight on the results of two popular benchmarks in AI, the Arcade Learning Environment (Atari 2600 games) and the General Video Game AI competition, and we include some guidelines to estimate and interpret these indicators for other AI benchmarks and competitions. © 2018 IEEE.","2-s2.0-85082172773"
"Sithungu S.P.; Ehlers E.M.","Sithungu, Siphesihle Philezwini (57209576078); Ehlers, Elizabeth Marie (7005161648)","57209576078; 7005161648","Adaptive Game AI-Based Dynamic Difficulty Scaling via the Symbiotic Game Agent","2020","IFIP Advances in Information and Communication Technology","581 AICT","","","107","117","10","10.1007/978-3-030-46931-3_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087743476&doi=10.1007%2f978-3-030-46931-3_11&partnerID=40&md5=dd597fc44b784d7c907fb8960be5203e","This work presents AdaptiveSGA, a model for implementing Dynamic Difficulty Scaling through Adaptive Game AI via the Symbiotic Game Agent framework. The use of Dynamic Difficulty Balancing in modern computer games is useful when looking to improve the entertainment value of a game. Moreover, the Symbiotic Game Agent, as a framework, provides flexibility and robustness as a design principle for game agents. The work presented here leverages both the advantages of Adaptive Game AI and Symbiotic Game Agents to implement a robust, efficient and testable model for game difficulty scaling. The model is discussed in detail and is compared to the original Symbiotic Game Agent architecture. Finally, the paper describes how it was applied in simulated soccer. Finally, experimental results, which show that Dynamic Difficulty Balancing was achieved, are briefly analyzed. © 2020, IFIP International Federation for Information Processing.","2-s2.0-85087743476"
"Alam M.M.; Nayyeri M.; Xu C.; Al Hasan Rony M.R.; Yazdi H.S.; Sadeghi A.; Lehmann J.","Alam, Mirza Mohtashim (57202902190); Nayyeri, Mojtaba (35776892400); Xu, Chengjin (57195741972); Al Hasan Rony, Md Rashad (57203302415); Yazdi, Hamed Shariat (54883989600); Sadeghi, Afshin (55667648200); Lehmann, Jens (35229806900)","57202902190; 35776892400; 57195741972; 57203302415; 54883989600; 55667648200; 35229806900","The effect of rule injection in a leakage free datasets","2020","CEUR Workshop Proceedings","3020","","","28","35","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120680222&partnerID=40&md5=b2936c454b9048102ff7a8f027f49c48","Knowledge graph embedding (KGE) has become a prominent topic for many AI-based tasks such as recommendation systems, natural language processing, and link prediction. Inclusion of additional knowledge such as ontology, logical rules and text improves the learning process of KGE models. One of the main characteristics of knowledge graphs (KGs) is the existence of relational patterns (e.g., symmetric and inverse relations) which usually remain unseen by the embedding models. Inclusion of logical rules provides embedding models with additional information about the patterns already present in the KGs. The injection of logical rules has not yet been studied in depth for KGE models. In this paper, we propose an approach for rule-based learning on top of the two embedding models namely RotatE and TransE within this scope of the paper. We first study the effect of rule injection in the performance of the selected models. Second, we explore how the removal of leakage from popular KGs such as FB15k and WN18 affects the results. By leakage we are referring to the patterns exist in the training set from the test set (e.g. if the test set contains (h, r, t) then it also contains t, r, h in the training set which is considered as a symmetric leakage where t, r and h refers to tail, relation and head respectively). Empirical results suggest that incorporation of logical rules in the training process improves the performance of KGE models. © 2020 CEUR-WS. All rights reserved.","2-s2.0-85120680222"
"Huang C.-C.; Liang W.-Y.; Lin S.-H.; Tseng T.-L.; Wang Y.-H.; Wu K.-H.","Huang, Chun-Che (36079895200); Liang, Wen-Yau (7402026606); Lin, Shian-Hua (7407158281); Tseng, Tzu-Liang (23393519800); Wang, Yu-Hsien (56523426500); Wu, Kuo-Hsin (57219471964)","36079895200; 7402026606; 7407158281; 23393519800; 56523426500; 57219471964","Detection of potential controversial issues for social sustainability: Case of green energy","2020","Sustainability (Switzerland)","12","19","8057","1","22","21","10.3390/su12198057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092938951&doi=10.3390%2fsu12198057&partnerID=40&md5=4c62c0858de7141c0f106a11a815e66d","More and more people are involved in sustainability-related activities through social network to support/protect their idea or motivation for sustainable development. Understanding the variety of issues of social pulsation is crucial in development of social sustainability. However, issues in social media generally change overtime. Issues not identified in advance may soon become popular topics discussed in society, particularly controversial issues. Previous studies have focused on the detection of hot topics and discussion of controversial issues, rather than the identification of potential controversial issues, which truly require paying attention to social sustainability. Furthermore, previous studies have focused on issue detection and tracking based on historical data. However, not all controversial issues are related to historical data to foster the cases. To avoid the above-mentioned research gap, Artificial Intelligence (AI) plays an essential role in issue detection in the early stage. In this study, an AI-based solution approach is proposed to resolve two practical problems in social media: (1) the impact caused by the number of fan pages from Facebook and (2) awareness of the levels for an issue. The proposed solution approach to detect potential issues is based on the popularity of public opinion in social media using a Web crawler to collect daily posts related to issues in social media under a big data environment. Some analytical findings are carried out via the congregational rules proposed in this research, and the solution approach detects the attentive subjects in the early stages. A comparison of the proposed method to the traditional methods are illustrated in the domain of green energy. The computational results demonstrate that the proposed approach is accurate and effective and therefore it provides significant contribution to upsurge green energy deployment. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","2-s2.0-85092938951"
"Elton D.C.","Elton, Daniel C. (26031409000)","26031409000","Self-explaining ai as an alternative to interpretable ai","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12177 LNAI","","","95","106","11","10.1007/978-3-030-52152-3_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088502282&doi=10.1007%2f978-3-030-52152-3_10&partnerID=40&md5=f324f1aefccd288a7eb8e6bad0299a16","The ability to explain decisions made by AI systems is highly sought after, especially in domains where human lives are at stake such as medicine or autonomous vehicles. While it is often possible to approximate the input-output relations of deep neural networks with a few human-understandable rules, the discovery of the double descent phenomena suggests that such approximations do not accurately capture the mechanism by which deep neural networks work. Double descent indicates that deep neural networks typically operate by smoothly interpolating between data points rather than by extracting a few high level rules. As a result, neural networks trained on complex real world data are inherently hard to interpret and prone to failure if asked to extrapolate. To show how we might be able to trust AI despite these problems we introduce the concept of self-explaining AI. Self-explaining AIs are capable of providing a human-understandable explanation of each decision along with confidence levels for both the decision and explanation. Some difficulties with this approach along with possible solutions are sketched. Finally, we argue it is important that deep learning based systems include a “warning light” based on techniques from applicability domain analysis to warn the user if a model is asked to extrapolate outside its training distribution. © Springer Nature Switzerland AG 2020.","2-s2.0-85088502282"
"Bigras É.; Léger P.-M.; Sénécal S.","Bigras, Émilie (57203094242); Léger, Pierre-Majorique (57202616738); Sénécal, Sylvain (57200814456)","57203094242; 57202616738; 57200814456","Recommendation agent adoption: How recommendation presentation influences employees' perceptions, behaviors, and decision quality","2019","Applied Sciences (Switzerland)","9","20","4244","","","","10.3390/app9204244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074195396&doi=10.3390%2fapp9204244&partnerID=40&md5=18b2823fc9aad2f0d5d8bbb2d205f61a","The purpose of this paper is to report the results of a laboratory experiment that investigated how assortment planners' perceptions, usage behavior, and decision quality are influenced by the way recommendations of an artificial intelligence (AI)-based recommendation agent (RA) are presented. A within-subject laboratory experiment was conducted with twenty subjects. Participants perceptions and usage behavior toward anRAwhile making decisions were assessed using validated measurement scales and eye-tracking technology. The results of this study show the importance of a transparent RA demanding less cognitive effort to understand and access the explanations of a transparent RA on assortment planners' perceptions (i.e., source credibility, sense of control, decision quality, and satisfaction), usage behavior, and decision quality. Results from this study suggest that designing RAs with more transparency for the users bring perceptual and attitudinal benefits that influence both the adoption and continuous use of those systems by employees. This study contributes to filling the literature gap on RAs in organizational contexts, thus advancing knowledge in the human-computer interaction literature. The findings of this study provide guidelines for RA developers and user experience (UX) designers on how to best create and present an AI-based RA to employees. © 2019 by the authors.","2-s2.0-85074195396"
"Shneiderman B.","Shneiderman, Ben (7006313615)","7006313615","Bridging the gap between ethics and practice: Guidelines for reliable, safe, and trustworthy human-centered AI systems","2020","ACM Transactions on Interactive Intelligent Systems","10","4","26","","","","10.1145/3419764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096998670&doi=10.1145%2f3419764&partnerID=40&md5=64b8af777ccd9469712e24c94f60ec19","This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, nongovernmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society. © 2020 Association for Computing Machinery.","2-s2.0-85096998670"
"Tsiros A.; Palladini A.","Tsiros, Augoustinos (56300971900); Palladini, Alessandro (58145846700)","56300971900; 58145846700","Towards a human-centric design framework for ai assisted music production","2020","Proceedings of the International Conference on New Interfaces for Musical Expression","","","","399","404","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150258623&partnerID=40&md5=489d9c63c874b3892548649ff2431d84","In this paper, we contribute to the discussion on how to best design human-centric MIR tools for live audio mixing by bridging the gap between research on complex systems, the psychology of automation and the design of tools that support creativity in music production. We present the design of the Channel-AI, an embedded AI system which performs instrument recognition and generates parameter settings suggestions for gain levels, gating, compression and equalization which are specific to the input signal and the instrument type. We discuss what we believe to be the key design principles and perspectives on the making of intelligent tools for creativity and for experts in the loop. We demonstrate how these principles have been applied to inform the design of the interaction between expert live audio mixing engineers with the Channel-AI (i.e. a corpus of AI features embedded in the Midas HD Console. We report the findings from a preliminary evaluation we conducted with three professional mixing engineers and reflect on mixing engineers’ comments about the Channel-AI on social media. © 2020, Steering Committee of the International Conference on New Interfaces for Musical Expression. All rights reserved.","2-s2.0-85150258623"
"Martel Y.; Roßmann A.; Sultanow E.; Weiß O.; Wissel M.; Pelzel F.; Seßler M.","Martel, Yannick (57556173000); Roßmann, Arne (57556356200); Sultanow, Eldar (36167522600); Weiß, Oliver (57556546800); Wissel, Matthias (57557122400); Pelzel, Frank (57556546900); Seßler, Matthias (57218940255)","57556173000; 57556356200; 36167522600; 57556546800; 57557122400; 57556546900; 57218940255","Software Architecture Best Practices for Enterprise Artificial Intelligence","2020","Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)","P-307","","","165","181","16","10.18420/inf2020_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127339915&doi=10.18420%2finf2020_16&partnerID=40&md5=165b4d942b7a2e1fffbff3379abd6757","AI systems are increasingly evolving from laboratory experiments in data analysis to increments of productive software products. A professional AI platform must therefore not only function as a laboratory environment but must be designed and procured as a workbench for the development, productive implementation, operation and maintenance of ML models. Subsequently, it needs to integrate within a global software engineering approach. This way, Enterprise Architecture Management (EAM) must implement efficient governance of the development cycle, to enable organization-wide collaboration, to accelerate the go-live and to standardize operations. In this paper we highlight obstacles and show best practices on how architects can integrate data science and AI in their environment. Additionally, we suggest an integrated approach adapting the best practices from both the data science and DevOps. © 2020 Gesellschaft fur Informatik (GI). All rights reserved.","2-s2.0-85127339915"
"Chen J.Q.","Chen, Jim Q. (56685114600)","56685114600","On handling ethical dilemmas in artificial intelligence systems","2020","Proceedings of the European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020","","","","49","57","8","10.34190/EAIR.20.051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097833167&doi=10.34190%2fEAIR.20.051&partnerID=40&md5=7f074d741fac283d1ce9ca570cbe78f4","Artificial intelligence (AI) has been created to help humans to achieve goals, not to help AI itself to achieve its own goals. Hence, AI has to be designed, controlled, and utilized for humans. To be accepted in a human society, AI has to be armed with law and ethics, because law and ethics provide fundamental principles, rules, and guidance for interactions in a human society. Without them, a human society can hardly survive in a peaceful way. However, implementing ethics in AI systems is absolutely a challenge. There are several layers that need to be taken into consideration. There are dilemmas in each layer, making implementation even more complex and challenging. This paper intends to tackle this challenge. It starts with a hypothetical but possible case that an AI-enabled self-driving vehicle may encounter. It examines various dilemmas involved in this case, especially the ethical one. It reveals the ineffectiveness of the current approaches in dealing with the ethical dilemma. It then proposes a novel approach that fully utilizes both the unique strengths of AI systems and the unique strengths of humans in exploring paradigm-shift solutions in dealing with this type of dilemmas. As a result, ethics can be successfully implemented and dynamically executed in AI systems. © ECIAIR 2020.All right reserved.","2-s2.0-85097833167"
"Ivanova Y.","Ivanova, Yordanka (56506741600)","56506741600","The Data Protection Impact Assessment as a Tool to Enforce Non-discriminatory AI","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12121 LNCS","","","3","24","21","10.1007/978-3-030-55196-4_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093857325&doi=10.1007%2f978-3-030-55196-4_1&partnerID=40&md5=ab61573b0ea44904f3017bfeac4ec4e0","This paper argues that the novel tools under the General Data Protection Regulation (GDPR) may provide an effective legally binding mechanism for enforcing non-discriminatory AI systems. Building on relevant guidelines, the generic literature on impact assessments and algorithmic fairness, this paper aims to propose a specialized methodological framework for carrying out a Data Protection Impact Assessment (DPIA) to enable controllers to assess and prevent ex ante the risk to the right to non-discrimination as one of the key fundamental rights that GDPR aims to safeguard. © 2020, Springer Nature Switzerland AG.","2-s2.0-85093857325"
"Leijnen S.; Aldewereld H.; van Belkom R.; Bijvank R.; Ossewaarde R.","Leijnen, Stefan (57218950781); Aldewereld, Huib (8658897900); van Belkom, Rudy (57218948693); Bijvank, Roland (57079058200); Ossewaarde, Roelant (55453827600)","57218950781; 8658897900; 57218948693; 57079058200; 55453827600","An agile framework for trustworthy AI","2020","CEUR Workshop Proceedings","2659","","","75","78","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090887923&partnerID=40&md5=c4eade46c5f0624335533fb50f515b01","The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85090887923"
"Mari A.; Mandelli A.; Algesheimer R.","Mari, Alex (57189693827); Mandelli, Andreina (55544668300); Algesheimer, René (8631748700)","57189693827; 55544668300; 8631748700","The evolution of marketing in the context of voice commerce: A managerial perspective","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12204 LNCS","","","405","425","20","10.1007/978-3-030-50341-3_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088741393&doi=10.1007%2f978-3-030-50341-3_32&partnerID=40&md5=553a2566ff3384141fa8b4edfea7ab38","The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N = 62) revealed the expected impact of voice assistants on the shopping process. Findings show that managers consider voice assistants a disruptive technology assuming a central relational role in the consumer market. However, they often divergence in opinions across industry, function, and seniority level. Besides, managers’ familiarity with voice commerce is correlated to a higher optimism towards voice technologies (opportunity for brands) but also a greater sense of urgency (short-term focus) with implications for marketing strategy. This article offers support to brand owners explaining how voice assistants work and examining their effects on consumption. The authors discuss empirical results while providing managerial guidelines to create resilient and sustainable brands in the era of voice commerce. © Springer Nature Switzerland AG 2020.","2-s2.0-85088741393"
"Jadhav K.P.; Thorat S.A.","Jadhav, Komal P. (57212008705); Thorat, Sandeep A. (25928097700)","57212008705; 25928097700","Towards Designing Conversational Agent Systems","2020","Advances in Intelligent Systems and Computing","1025","","","533","542","9","10.1007/978-981-32-9515-5_51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075676936&doi=10.1007%2f978-981-32-9515-5_51&partnerID=40&md5=8281d960bcb27193b2298aa06e0f8be6","Conversation is interactive communication between two and more people which enhances knowledge among these people. It is key to exchange thoughts and ideas while listening to each other. Based on this idea the advances in artificial intelligence started to develop technologies in which computer can communicate with human in a more natural way. A computer program which acts as an automated conversation agent is also called as a Chatbot. Chatbots are useful in many different applications like health care, education, financial marketing, banking, agriculture, etc. This paper presents a survey on different issues in designing conversational agents. The paper discusses the types and applications of Chatbot; it lists research challenges while designing and implementing these systems. The paper presents a study and comparison of different techniques like NLP (Natural Language Processing), Deep Learning and Neural Networks used for designing these systems. The paper also presents various datasets being used by popular Chatbots in the industry. The paper ends by summarizing scope for future work in this domain. © 2020, Springer Nature Singapore Pte Ltd.","2-s2.0-85075676936"
"Kim C.; Kim J.; Osborn J.C.","Kim, Chanha (57223799000); Kim, Jaden (57223827746); Osborn, Joseph C. (56443499800)","57223799000; 57223827746; 56443499800","Synthesizing retro game screenshot datasets for sprite detection","2020","CEUR Workshop Proceedings","2862","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106145829&partnerID=40&md5=5ccd1ba036bcf3cdd146dd4a5f3d8515","Scenes in 2D videogames generally consist of a static terrain and a set of dynamic sprites which move around freely. AI systems that aim to understand game rules (for design support or automated gameplay) must be able to distinguish moving elements from the background. To this end, we re-purposed an object detection model from deep learning literature, developing along the way YOLO Artificial Retro-game Data Synthesizer, or YARDS, which efficiently produces semi-realistic, retro-game sprite detection datasets without manual labeling. Provided with sprites, background images, and a set of parameters, the package uses sprite frequency spaces to create synthetic gameplay images along with their corresponding labels. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","2-s2.0-85106145829"
"Igelmo V.; Syberfeldt A.; Högberg D.; García Rivera F.; Pérez Luque E.","Igelmo, Víctor (57219091415); Syberfeldt, Anna (25639958400); Högberg, Dan (7801380814); García Rivera, Francisco (57219089120); Pérez Luque, Estela (57219088583)","57219091415; 25639958400; 7801380814; 57219089120; 57219088583","Aiding observational ergonomic evaluation methods using MOCAP systems supported by AI-based posture recognition","2020","Advances in Transdisciplinary Engineering","11","","","419","429","10","10.3233/ATDE200050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091239183&doi=10.3233%2fATDE200050&partnerID=40&md5=78caa6e77832ffeb81adc3a4a223ada0","Observational ergonomic evaluation methods have inherent subjectivity. Observers' assessment results might differ even with the same dataset. While motion capture (MOCAP) systems have improved the speed and the accuracy of motion-data gathering, the algorithms used to compute assessments seem to rely on predefined conditions to perform them. Moreover, the authoring of these conditions is not always clear. Making use of artificial intelligence (AI), along with MOCAP systems, computerized ergonomic assessments can become more alike to human observation and improve over time, given proper training datasets. AI can assist ergonomic experts with posture detection, useful when using methods that require posture definition, such as Ovako Working Posture Assessment System (OWAS). This study aims to prove the usefulness of an AI model when performing ergonomic assessments and to prove the benefits of having a specialized database for current and future AI training. Several algorithms are trained, using Xsens MVN MOCAP datasets, and their performance within a use case is compared. AI algorithms can provide accurate posture predictions. The developed approach aspires to provide with guidelines to perform AI-assisted ergonomic assessment based on observation of multiple workers.  © 2020 The authors and IOS Press.","2-s2.0-85091239183"
"Reis T.; Krause T.; Bornschlegl M.X.; Hemmje M.L.","Reis, Thoralf (57205614322); Krause, Thomas (57189703325); Bornschlegl, Marco X. (57190072605); Hemmje, Matthias L. (55979769600)","57205614322; 57189703325; 57190072605; 55979769600","A conceptual architecture for AI-based big data analysis and visualization supporting metagenomics research","2020","CEUR Workshop Proceedings","2815","","","183","190","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101636299&partnerID=40&md5=0609620ea3d46b9fd4a04607f1fa4c2c","This paper targets to introduce an architecture for Artificial Intelligence (AI) based Big Data Analysis and Visualization supported metagenomics research based on the AI2VIS4BigData Reference Model. Metagenomics research covers the examination of huge amounts of data to improve the understanding of microbial communities. Technological and methodical improvements in Big Data Analysis drive progress in metagenomics research and thereby support practical applications like, e.g., the analysis of cattle rumen with the research goal of reducing the negative impact of cattle breeding on global warming. AI2VIS4BigData is a reference model for the combined application areas of Big Data Analysis, AI, and Visualization. Its purpose is to support scientific and industrial activities with guidelines and a common terminology to enable efficient exchange of knowledge and information and thereby prevent”reinventing the wheel”. The general applicability of the AI2VIS4BigData model for metagenomics has been validated in a previous publication. As a next step, this paper derives a conceptual architecture that specifies a possible adaption of AI2VIS4BigData for metagenomics. For this, three new metagenomic publications utilizing AI and Visualizations are assessed. Copyright © 2020 for this paper by its authors.","2-s2.0-85101636299"
"Hamada K.; Ishikawa F.; Masuda S.; Matsuya M.; Myojin T.; Nishi Y.; Ogawa H.; Toku T.; Tokumoto S.; Tsuchiya K.; Ujita Y.","Hamada, Koichi (58253019200); Ishikawa, Fuyuki (33367760100); Masuda, Satoshi (36803608600); Matsuya, Mineo (57218865089); Myojin, Tomoyuki (55555882700); Nishi, Yasuharu (35119148100); Ogawa, Hideto (26032684700); Toku, Takahiro (57218868119); Tokumoto, Susumu (55383584000); Tsuchiya, Kazunori (57218867636); Ujita, Yasuhiro (57218867074)","58253019200; 33367760100; 36803608600; 57218865089; 55555882700; 35119148100; 26032684700; 57218868119; 55383584000; 57218867636; 57218867074","Guidelines for quality assurance of machine learning-based artificial intelligence","2020","Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE","PartF162440","","","335","341","6","10.18293/SEKE2020-094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090506905&doi=10.18293%2fSEKE2020-094&partnerID=40&md5=0dba7bcb61d07ce6162928ce5e352e13","Great efforts are currently underway to develop industrial applications for artificial intelligence (AI), especially those using machine learning (ML) techniques. Despite the intensive support for building ML applications, there are still challenges when it comes to evaluating, assuring, and improving the quality or dependability. The difficulty stems from the unique nature of ML: namely, that the system behavior is derived from training data, not from logical design by human engineers. This leads to black-box and intrinsically imperfect implementations that invalidate many of the existing principles and techniques in traditional software engineering. In light of this situation, the Japanese industry has jointly worked on a set of guidelines for the quality assurance of AI systems (in the QA4AI consortium) from the viewpoint of traditional quality-assurance engineers and test engineers. We report the initial version of these guidelines, which cover a list of the quality evaluation aspects, a catalogue of current state-of-the-art techniques, and domain-specific discussions in four representative domains. The guidelines provide significant insights for engineers in terms of methodologies and designs for tests driven by application-specific requirements. © 2020 Knowledge Systems Institute Graduate School. All rights reserved.","2-s2.0-85090506905"
"Lewis D.; Hogan L.; Filip D.; Wall P.J.","Lewis, Dave (57035492800); Hogan, Linda (28367681300); Filip, David (55217562500); Wall, P.J. (57194421064)","57035492800; 28367681300; 55217562500; 57194421064","Global challenges in the standardization of ethics for trustworthy AI","2020","Journal of ICT Standardization","8","2","","123","150","27","10.13052/jicts2245-800X.823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091288117&doi=10.13052%2fjicts2245-800X.823&partnerID=40&md5=a46fb9d2a399abf0beeb96880bef7c0b","In this paper, we examine the challenges of developing international standards for Trustworthy AI that aim both to be global applicable and to address the ethical questions key to building trust at a commercial and societal level. We begin by examining the validity of grounding standards that aim for international reach on human right agreements, and the need to accommodate variations in prioritization and tradeoffs in implementing rights in different societal and cultural settings. We then examine the major recent proposals from the OECD, the EU and the IEEE on ethical governance of Trustworthy AI systems in terms of their scope and use of normative language. From this analysis, we propose a preliminary minimal model for the functional roles relevant to Trustworthy AI as a framing for further standards development in this area. We also identify the different types of interoperability reference points that may exist between these functional roles and remark on the potential role they could play in future standardization. Finally we examine a current AI standardization effort under ISO/IEC JTC1 to consider how future Trustworthy AI standards may be able to build on existing standards in developing ethical guidelines and in particular on the ISO standard on Social Responsibility. We conclude by proposing some future directions for research and development of Trustworthy AI standards. © 2020 the Author(s). All rights reserved.","2-s2.0-85091288117"
"Al Banna M.H.; Taher K.A.; Kaiser M.S.; Mahmud M.; Rahman M.S.; Hosen A.S.M.S.; Cho G.H.","Al Banna, Md. Hasan (57843300400); Taher, Kazi Abu (36069993500); Kaiser, M. Shamim (56446362000); Mahmud, Mufti (35173453700); Rahman, Md. Sazzadur (58265736900); Hosen, A. S. M. Sanwar (55354658100); Cho, Gi Hwan (22333305400)","57843300400; 36069993500; 56446362000; 35173453700; 58265736900; 55354658100; 22333305400","Application of Artificial Intelligence in Predicting Earthquakes: State-of-the-Art and Future Challenges","2020","IEEE Access","8","","9218936","192880","192923","43","10.1109/ACCESS.2020.3029859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095969114&doi=10.1109%2fACCESS.2020.3029859&partnerID=40&md5=fcd8e3943cdbb6f2398cf50233b50800","Predicting the time, location and magnitude of an earthquake is a challenging job as an earthquake does not show specific patterns resulting in inaccurate predictions. Techniques based on Artificial Intelligence (AI) are well known for their capability to find hidden patterns in data. In the case of earthquake prediction, these models also produce a promising outcome. This work systematically explores the contributions made to date in earthquake prediction using AI-based techniques. A total of 84 scientific research papers, which reported the use of AI-based techniques in earthquake prediction, have been selected from different academic databases. These studies include a range of AI techniques including rule-based methods, shallow machine learning and deep learning algorithms. Covering all existing AI-based techniques in earthquake prediction, this article provides an account of the available methodologies and a comparative analysis of their performances. The performance comparison has been reported from the perspective of used datasets and evaluation metrics. Furthermore, using comparative analysis of performances the paper aims to facilitate the selection of appropriate techniques for earthquake prediction. Towards the end, it outlines some open challenges and potential research directions in the field.  © 2013 IEEE.","2-s2.0-85095969114"
"Raymond A.; Gunes H.; Prorok A.","Raymond, Alex (57219585581); Gunes, Hatice (7005067251); Prorok, Amanda (25925347200)","57219585581; 7005067251; 25925347200","Culture-based explainable human-agent deconfliction","2020","Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS","2020-May","","","1107","1115","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096668412&partnerID=40&md5=2765f9b0085e1fc83cc46b940f0ebb06","Law codes and regulations help organise societies for centuries, and as AI systems gain more autonomy, we question how human-agent systems can operate as peers under the same norms, especially when resources are contended. We posit that agents must be accountable and explainable by referring to which rules justify their decisions. The need for explanations is associated with user acceptance and trust. This paper's contribution is twofold: i) we propose an argumentation-based human-agent architecture to map human regulations into a culture for artificial agents with explainable behaviour. Our architecture leans on the notion of argumentative dialogues and generates explanations from the history of such dialogues; and ii) we validate our architecture with a user study in the context of human-agent path deconfliction. Our results show that explanations provide a significantly higher improvement in human performance when systems are more complex. Consequently, we argue that the criteria defining the need of explanations should also consider the complexity of a system. Qualitative findings show that when rules are more complex, explanations significantly reduce the perception of challenge for humans. © 2020 International Foundation for Autonomous.","2-s2.0-85096668412"
"Mahdavi M.; Kazemi H.","Mahdavi, Mehrzad (57491852600); Kazemi, Hossein (7102412464)","57491852600; 7102412464","It’s All About Data: How to Make Good Decisions in a World Awash with Information","2020","Journal of Financial Data Science","2","2","","8","16","8","10.3905/jfds.2020.1.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124065451&doi=10.3905%2fjfds.2020.1.025&partnerID=40&md5=a8e44b10dacd4d1e58f655f0a2aa105d","The rise of big and alternative data has created significant new business opportunities in the financial sector. As we start on this journey of fast-moving technology disruption, f inancial professionals have a rare opportunity to balance the exponential growth of artif icial intelligence (AI)/data science with ethics, bias, and privacy to create trusted data-driven decision making. In this article, the authors discuss the nuances of big data sets that are critical when one considers standards, processes, best practices, and modeling algorithms for the deployment of AI systems. In addition, this industry is widely guided by a fiduciary standard that puts the interests of the client above all else. It is therefore critical to have a thorough understanding of the limitations of our knowledge, because there are many known unknowns and unknown unknowns that can have a signif icant impact on outcomes. The authors emphasize key success factors for the deployment of AI initiatives: talent and bridging the skills gap. To achieve a lasting impact of big data initiatives, multidisciplinary teams with well-defined roles need to be established with continuing training and education. The prize is the finance of the future. © 2020, With intelligence. All rights reserved.","2-s2.0-85124065451"
"Banerjee R.; Ghose A.; Sinha A.; Pal A.; Mandana K.M.","Banerjee, Rohan (55609319600); Ghose, Avik (36554120800); Sinha, Aniruddha (26639682200); Pal, Arpan (57203638167); Mandana, K.M. (7801503220)","55609319600; 36554120800; 26639682200; 57203638167; 7801503220","A multi-modal approach for non-invasive detection of coronary artery disease","2019","UbiComp/ISWC 2019- - Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers","","","","543","550","7","10.1145/3341162.3349331","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072890077&doi=10.1145%2f3341162.3349331&partnerID=40&md5=499b9cadd66fe2891d3296cdfba8823c","Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity = 0.96 and specificity = 0.91 in classifying CAD patients on an in-house hospital dataset, recorded using commercially available sensors. © 2019 Association for Computing Machinery.","2-s2.0-85072890077"
"Siau K.; Wang W.","Siau, Keng (7003774702); Wang, Weiyu (57208538673)","7003774702; 57208538673","Artificial intelligence (AI) Ethics: Ethics of AI and ethical AI","2020","Journal of Database Management","31","2","","74","87","13","10.4018/JDM.2020040105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097225749&doi=10.4018%2fJDM.2020040105&partnerID=40&md5=b95af7bef3c9320e038e344e4417da8e","Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI? Copyright © 2020, IGI Global.","2-s2.0-85097225749"
"Gallo G.; Ferrari V.; Marcelloni F.; Ducange P.","Gallo, Gionatan (57217109024); Ferrari, Vincenzo (57189717806); Marcelloni, Francesco (7003309696); Ducange, Pietro (16425459700)","57217109024; 57189717806; 7003309696; 16425459700","SK-MOEFS: A Library in Python for Designing Accurate and Explainable Fuzzy Models","2020","Communications in Computer and Information Science","1239 CCIS","","","68","81","13","10.1007/978-3-030-50153-2_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086225224&doi=10.1007%2f978-3-030-50153-2_6&partnerID=40&md5=857a0eb389e022d6f60e05af09d9d7f6","Recently, the explainability of Artificial Intelligence (AI) models and algorithms is becoming an important requirement in real-world applications. Indeed, although AI allows us to address and solve very difficult and complicated problems, AI-based tools act as a black box and, usually, do not explain how/why/when a specific decision has been taken. Among AI models, Fuzzy Rule-Based Systems (FRBSs) are recognized world-wide as transparent and interpretable tools: they can provide explanations in terms of linguistic rules. Moreover, FRBSs may achieve accuracy comparable to those achieved by less transparent models, such as neural networks and statistical models. In this work, we introduce SK-MOEFS (acronym of SciKit-Multi Objective Evolutionary Fuzzy System), a new Python library that allows the user to easily and quickly design FRBSs, employing Multi-Objective Evolutionary Algorithms. Indeed, a set of FRBSs, characterized by different trade-offs between their accuracy and their explainability, can be generated by SK-MOEFS. The user, then, will be able to select the most suitable model for his/her specific application. © 2020, Springer Nature Switzerland AG.","2-s2.0-85086225224"
"Boonpramuk M.; Tunyasirut S.; Puangdownreong D.","Boonpramuk, Manoon (57200151120); Tunyasirut, Satean (16644169800); Puangdownreong, Deacha (56403375200)","57200151120; 16644169800; 56403375200","Artificial intelligence-based optimal PID controller design for BLDC motor with phase advance","2019","Indonesian Journal of Electrical Engineering and Informatics","7","4","","720","733","13","10.52549/ijeei.v7i4.1372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078503909&doi=10.52549%2fijeei.v7i4.1372&partnerID=40&md5=82e703cd105ab5eb8e579582e38db6d8","This paper proposes the artificial intelligence (AI)-based optimal PID controller design optimization of brushless direct current (BLDC) motor speed control with phase advance approach. The proposed control system allows the speed adjustment of the BLDC motor by phase advance technique. In this paper, two selected AI algorithms, i.e., the adaptive tabu search (ATS) and the intensified current search (ICS) are conducted as the optimizer for the PID controller design. The proposed control system is simulated by MATLAB/SIMULINK. Results obtained by the ATS and ICS will be compared with those obtained by the Ziegler-Nichols (ZN) tuning rule and the genetic algorithm (GA). It shows that the speed response of the BLDC motor by phase advance with the PID controller optimized by the ICS outperforms better than the ZN, GA and ATS. © 2019 Institute of Advanced Engineering and Science. All rights reserved.","2-s2.0-85078503909"
"Wang J.; Chen B.","Wang, Jinyan (57214101345); Chen, Bo (55723079800)","57214101345; 55723079800","A Multi-agent Simulation for the Research on the Market Equilibrium Phenomena Using Q-Network Algorithm","2019","International Conference on Communication Technology Proceedings, ICCT","","","8947047","356","361","5","10.1109/ICCT46805.2019.8947047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078160479&doi=10.1109%2fICCT46805.2019.8947047&partnerID=40&md5=59444521e8dd15cf6c4e50c31bc3a4bf","For the problems related to market equilibrium in complex market environments, analyses are conducted in the past, using some mathematical models and the game theory. These methods are based on the economic structural equations themselves, ignoring the interactions between economic subjects, and the hypothesis of subject homogeneity has no reference in the real world. On contrast, this paper proposes a multi-agent simulation model, from the microscopic point of view. In such simulation, agents interact with each other, and the decisions are made by agent-embedded AI systems, the Q-network. Therefore, there is no need to elaborate the behavioral rule for each agent, or manually set up too many assumptions. This paper assumes that the simulated market operates in a hypothetical way, in which there are two types of economic entities, namely, banks and enterprises. Banks and enterprises lending behaviors lead to a symbiotic relationship between the banks and the enterprises, while business-to-business transactions make the enterprises symbiotically compete with each other. In the experiment, the observed behavior of each agent can be reasonably explained. Agents endogenously generate intelligent behavioral patterns compatible with the environment. Therefore, this AI-based method can replace the artificially designated decision-making strategy in simulations of market, thus facilitating related economic researches. © 2019 IEEE.","2-s2.0-85078160479"
"Khokhar M.N.; Bashir M.B.; Fiaz M.","Khokhar, Muhammad Nadeem (26435275500); Bashir, Muhammad Bilal (35301932700); Fiaz, Muhammad (57216929809)","26435275500; 35301932700; 57216929809","Metamorphic testing of AI-based applications: A critical review","2020","International Journal of Advanced Computer Science and Applications","11","4","","754","761","7","10.14569/IJACSA.2020.0110498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085277768&doi=10.14569%2fIJACSA.2020.0110498&partnerID=40&md5=3dc94f803ee4db930288a0c08c91bdb6","Metamorphic testing is the youngest testing approach among other members of the testing family. It is designed to test software, which are complex in nature and it is difficult to compute test oracle for them against a given set of inputs. Metamorphic testing approach tests the software with the help of metamorphic relations that guide the tester to check if the observed output can be produced after applying a certain input. Since its first appearance, a lot of research has been done to check its effectiveness on different complex families of software applications like search engines, compilers, artificial intelligence (AI) and so on. Artificial intelligence has gained immense attention due to its successfully application in many of the computer science and even other domains like medical science, social science, economic, and so on. AI-based applications are quite complex in nature as compared to other conventional software applications and because of that they are hard to test. We have selected specifically testing of AI-based applications for this research study. Although all the researchers claim to propose the best set of metamorphic relations to test AI-based applications but that still needs to be verified. In this study, we have performed a critical review supported by rigorous set of parameters that we have prepared after thorough literature survey. The survey shows that researchers have applied metamorphic testing on applications that are either based on Genetic Algorithm (GA) or Machine Learning (ML). Our analysis has helped us identifying the strengths and weaknesses of the proposed approaches. Research still needs to be done to design a generalized set of metamorphic rules that can test a family of AI applications rather than just one. The findings are supported by strong arguments and justified with logical reasoning. The identified problem domains can be targeted by the researchers in future to further enhance the capabilities of metamorphic testing and its range of applications. © 2020 Science and Information Organization.","2-s2.0-85085277768"
"Gottesman O.; Futoma J.; Liu Y.; Parbhoo S.; Celi L.A.; Brunskill E.; Doshi-Velez F.","Gottesman, Omer (55055866100); Futoma, Joseph (56703705700); Liu, Yao (57208444281); Parbhoo, Sonali (57204600963); Celi, Leo Anthony (16033282700); Brunskill, Emma (15762040900); Doshi-Velez, Finale (34874672900)","55055866100; 56703705700; 57208444281; 57204600963; 16033282700; 15762040900; 34874672900","Interpretable off-policy evaluation in reinforcement learning by highlighting influential transitions","2020","37th International Conference on Machine Learning, ICML 2020","PartF168147-5","","","3616","3625","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102164669&partnerID=40&md5=39a9b6087b90aca76fa83df49b58407f","Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares, as well as importance sampling methods. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust. Copyright 2020 by the author(s).","2-s2.0-85102164669"
"Richert A.; Schiffmann M.; Yuan C.","Richert, Anja (36176257900); Schiffmann, Michael (57009004800); Yuan, Chunrong (57033368700)","36176257900; 57009004800; 57033368700","A Nursing Robot for Social Interactions and Health Assessment","2020","Advances in Intelligent Systems and Computing","962","","","83","91","8","10.1007/978-3-030-20467-9_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067901674&doi=10.1007%2f978-3-030-20467-9_8&partnerID=40&md5=f96e8e3edc0731b43845706e50c1c5c2","Social Robotics for nursing care gain increasing importance in the age of demographic change and fast development of artificial intelligence. Social robots are automated or autonomous machines capable of interacting with people on the basis of social rules and are mostly humanoid and mobile. The Cologne Cobots Lab (Cologne Cobots Lab is an interdisciplinary research lab of the TH K&#x00F6;ln &#x2013; University of Applied Sciences, with its main research focus in the areas of collaborative and social robotics) is currently carrying out research in social and cognitive robotics. In the context of nursing care, approaches for capturing emotions and the state of mind of patients through different interaction analytics will be developed. We will use the humanoid robot pepper and extend its software functions so that it can take initiatives in human-machine-conversation. We conduct different user-centered experiments in real-world conditions and investigate the verbal interactions among human users and the robot system. In this regard, it would be both valuable and interesting to find out whether an AI enabled humanoid robot is able to stimulate or encourage conversation or even perform better than a natural conversation partner. &#x00A9; 2020, Springer Nature Switzerland AG.","2-s2.0-85067901674"
"Gupta L.; Salman T.; Zolanvari M.; Erbad A.; Jain R.","Gupta, Lav (56903725200); Salman, Tara (56446577200); Zolanvari, Maede (57193152775); Erbad, Aiman (24528481900); Jain, Raj (56038963500)","56903725200; 56446577200; 57193152775; 24528481900; 56038963500","Fault and performance management in multi-cloud virtual network services using AI: A tutorial and a case study","2019","Computer Networks","165","","106950","","","","10.1016/j.comnet.2019.106950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073944593&doi=10.1016%2fj.comnet.2019.106950&partnerID=40&md5=2cfa634944b133872319f00ab907151f","Carriers find Network Function Virtualization (NFV) and multi-cloud computing a potent combination for deploying their network services. The resulting virtual network services (VNS) offer great flexibility and cost advantages to them. However, vesting such services with a level of performance and availability akin to traditional networks has proved to be a difficult problem for academics and practitioners alike. There are a number of reasons for this complexity. The challenging nature of management of fault and performance issues of NFV and multi-cloud based VNSs is an important reason. Rule-based techniques that are used in the traditional physical networks do not work well in the virtual environments. Fortunately, machine and deep learning techniques of Artificial Intelligence (AI) are proving to be effective in this scenario. The main objective of this tutorial is to understand how AI-based techniques can help in fault detection and localization to take such services closer to the performance and availability of the traditional networks. A case study, based on our work in this area, has been included for a better understanding of the concepts. © 2019","2-s2.0-85073944593"
"Mandel T.; Best J.; Tanaka R.H.; Temple H.; Haili C.; Carter S.J.; Schlechtinger K.; Szeto R.","Mandel, Travis (54581401000); Best, Jahnu (57219508294); Tanaka, Randall H. (57219510830); Temple, Hiram (57219510347); Haili, Chansen (57219508759); Carter, Sebastian J. (57219612202); Schlechtinger, Kayla (57219505121); Szeto, Roy (57218567041)","54581401000; 57219508294; 57219510830; 57219510347; 57219508759; 57219612202; 57219505121; 57218567041","Using the Crowd to Prevent Harmful AI Behavior","2020","Proceedings of the ACM on Human-Computer Interaction","4","CSCW2","97","","","","10.1145/3415168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094203495&doi=10.1145%2f3415168&partnerID=40&md5=e4bc9f9d5dd687f27996af79cfea554e","To prevent harmful AI behavior, people need to specify constraints that forbid undesirable actions. Unfortunately, this is a complex task, since writing rules that distinguish harmful from non-harmful actions tends to be quite difficult in real-world situations. Therefore, such decisions have historically been made by a small group of powerful AI companies and developers, with limited community input. In this paper, we study how to enable a crowd of non-AI experts to work together to communicate high-quality, reliable constraints to AI systems. We first focus on understanding how humans reason about temporal dynamics in the context of AI behavior, finding through experiments on a novel game-based testbed that participants tend to adopt a long-term notion of harm, even in uncertain situations that do not affect them directly. Building off of this insight, we explore task design for long-term constraint specification, developing new filtering approaches and new methods of promoting user reflection. Next, we develop a novel rule-based interface which allows people to craft rules in an accessible fashion without programming knowledge. We test our approaches on a real-world AI problem in the domain of education, and find that our new filtering mechanisms and interfaces significantly improve constraint quality and human efficiency. We also demonstrate how these systems can be applied to other real-world AI problems (e.g. in social networks).  © 2020 ACM.","2-s2.0-85094203495"
"Toth-Haasz G.; Baracskai Z.","Toth-Haasz, Gabriella (57219972767); Baracskai, Zoltan (8257598700)","57219972767; 8257598700","Beyond 160 applications of an expert system: Key to a better usability","2020","11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings","","","9237822","563","568","5","10.1109/CogInfoCom50765.2020.9237822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096362201&doi=10.1109%2fCogInfoCom50765.2020.9237822&partnerID=40&md5=e4df31179552887f0cf7ad85122cf0e7","The most influential relevant thinkers have complained of the 'poverty' of Expert Systems (ES) both in the past (Dreyfus and Dreyfus, 1986) and in recently studies as well (Müller and Bostrom, 2016). We developed our own AI-Based Expert System shell for rule-based and case-based reasoning three decades ago and now there are 160 Knowledge Engineering (KE) process behind us with this system. We hope that this experience give us the right to formulate an opinion about that what is the key to a better usability and user experience in understanding of the result of the decision making process. While we do not think that ES is an omnipotent panacea, we also do not think that its applicability is determined only by the shell capabilities. However, one ability is essential; namely, presenting the result as simply as possible in order to that the decision-maker also can understand it. Our finding is that ES shells are only able to be transparent if they are designed by people who have an understanding of the human thinking process instead of a strong math-based software development approach. © 2020 IEEE.","2-s2.0-85096362201"
"Moran A.; Frasser C.F.; Roca M.; Rossello J.L.","Moran, Alejandro (57202222849); Frasser, Christiam F. (55966029100); Roca, Miquel (36004476500); Rossello, Josep L. (34772002500)","57202222849; 55966029100; 36004476500; 34772002500","Energy-Efficient Pattern Recognition Hardware with Elementary Cellular Automata","2020","IEEE Transactions on Computers","69","3","8883070","392","401","9","10.1109/TC.2019.2949300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079671255&doi=10.1109%2fTC.2019.2949300&partnerID=40&md5=41ba4b0edce5f929811abc327b94a5c4","The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) is able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy. © 1968-2012 IEEE.","2-s2.0-85079671255"
"Campolo C.; Lia G.; Amadeo M.; Ruggeri G.; Iera A.; Molinaro A.","Campolo, Claudia (16479841900); Lia, Gianmarco (57216310109); Amadeo, Marica (24342783300); Ruggeri, Giuseppe (7005708769); Iera, Antonio (7007176996); Molinaro, Antonella (7005836392)","16479841900; 57216310109; 24342783300; 7005708769; 7007176996; 7005836392","Towards Named AI Networking: Unveiling the Potential of NDN for Edge AI","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12338 LNCS","","","16","22","6","10.1007/978-3-030-61746-2_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093846473&doi=10.1007%2f978-3-030-61746-2_2&partnerID=40&md5=37576abf1289dc8e7171eaf64c5e0536","Thanks to recent advancements in edge computing, the traditional centralized cloud-based approach to deploy Artificial Intelligence (AI) techniques will be soon replaced or complemented by the so-called edge AI approach. By pushing AI at the network edge, close to the large amount of raw input data, the traffic traversing the core network as well as the inference latency can be reduced. Despite such neat benefits, the actual deployment of edge AI across distributed nodes raises novel challenges to be addressed, such as the need to enforce proper addressing and discovery procedures, to identify AI components, and to chain them in an interoperable manner. Named Data Networking (NDN) has been recently argued as one of the main enablers of network and computing convergence, which edge AI should build upon. However, the peculiarities of such a new paradigm entails to go a step further. In this paper we disclose the potential of NDN to support the orchestration of edge AI. Several motivations are discussed, as well as the challenges which serve as guidelines for progress beyond the state of the art in this topic. © 2020, Springer Nature Switzerland AG.","2-s2.0-85093846473"
"Vergne M.","Vergne, Matthieu (55446303600)","55446303600","Trustworthy AI: Towards the golden age of RE?","2020","CEUR Workshop Proceedings","2584","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082686661&partnerID=40&md5=896ac644a1cb29a9bb2dcea045638707","In April, 2018, the European Commission established its vision of Arti- ficial Intelligence (AI), leading to the production of guidelines to achieve trustworthy AI one year later. These guidelines, although not men- tioning it explicitly, overow with issues well known in Requirements Engineering (RE). By relating recent RE works to these guidelines, this position paper attempts to show that RE is one of the core components for achieving trustworthy AI, and thus can have a critical impact on the evolution of AI systems and the AI field as a whole for the next few years in Europe. Copyright © 2020 for this paper by its authors.","2-s2.0-85082686661"
"DIlmaghani S.; Brust M.R.; Danoy G.; Cassagnes N.; Pecero J.; Bouvry P.","DIlmaghani, Saharnaz (57215605374); Brust, Matthias R. (15061114300); Danoy, Gregoire (6508125036); Cassagnes, Natalia (57215613976); Pecero, Johnatan (56013709600); Bouvry, Pascal (6603233977)","57215605374; 15061114300; 6508125036; 57215613976; 56013709600; 6603233977","Privacy and Security of Big Data in AI Systems: A Research and Standards Perspective","2019","Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019","","","9006283","5737","5743","6","10.1109/BigData47090.2019.9006283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081411737&doi=10.1109%2fBigData47090.2019.9006283&partnerID=40&md5=0b2dd4df12d38ca7798a09ab50d5825f","The huge volume, variety, and velocity of big data have empowered Machine Learning (ML) techniques and Artificial Intelligence (AI) systems. However, the vast portion of data used to train AI systems is sensitive information. Hence, any vulnerability has a potentially disastrous impact on privacy aspects and security issues. Nevertheless, the increased demands for high-quality AI from governments and companies require the utilization of big data in the systems. Several studies have highlighted the threats of big data on different platforms and the countermeasures to reduce the risks caused by attacks. In this paper, we provide an overview of the existing threats which violate privacy aspects and security issues inflicted by big data as a primary driving force within the AI/ML workflow. We define an adversarial model to investigate the attacks. Additionally, we analyze and summarize the defense strategies and countermeasures of these attacks. Furthermore, due to the impact of AI systems in the market and the vast majority of business sectors, we also investigate Standards Developing Organizations (SDOs) that are actively involved in providing guidelines to protect the privacy and ensure the security of big data and AI systems. Our far-reaching goal is to bridge the research and standardization frame to increase the consistency and efficiency of AI systems developments guaranteeing customer satisfaction while transferring a high degree of trustworthiness. © 2019 IEEE.","2-s2.0-85081411737"
"Turan E.; Çetin G.","Turan, Ertan (57207469317); Çetin, Gürcan (57200282936)","57207469317; 57200282936","Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island","2019","Computer Standards and Interfaces","66","","103361","","","","10.1016/j.csi.2019.103361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067381625&doi=10.1016%2fj.csi.2019.103361&partnerID=40&md5=f0a09fa7b84692e3905cdd57e9823b05","The remarkable development of the computer graphic techniques enables the creation and management of more realistic games and virtual environments. However, placing the Artificial Intelligence (AI) in a virtual world get making these environments both more interactive and more believable. One of the most ambitious goals of the AI is to create virtual worlds in which a big number of virtual characters or humans being interacted and behave in an autonomous way. For this purpose, placing embodied intelligence characters in a virtual world offers a unique opportunity to evaluate the AI concept. This paper introduces a Virtual Island developed in an innovative way based on fuzzy rules at the user interaction mechanism. We have used fuzzy tactics to create AI-based animals having various behavior types from an eagles’ perspective which called ‘Flight Simulation’. The simulation utilizes an eagle flying over the airspace of the Island of Chios. The AI on the ground is triggered by other animals when they enter a radius area with a certain speed defined in the software. It then decides how to behave according to health, behavior type and confidence level. Also, there is non-AI sparrow herd placed over the island to make user understand how fast he is and give the user sense of speed what can be called as an in-project feature. Consequently, the used Fuzzy Tactics have been tested in realized Unity 3D simulation. The results of the study have proven that the virtual environment consisting AI-based animals has a good performance in terms of animal-user interactions and provided satisfactory results in run time. © 2019","2-s2.0-85067381625"
"Esmaeilzadeh P.","Esmaeilzadeh, Pouyan (36173960900)","36173960900","Use of AI-based tools for healthcare purposes: A survey study from consumers' perspectives","2020","BMC Medical Informatics and Decision Making","20","1","170","","","","10.1186/s12911-020-01191-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088428041&doi=10.1186%2fs12911-020-01191-1&partnerID=40&md5=e62f9285cde6bfc9bed85fea39f3cebe","Background: Several studies highlight the effects of artificial intelligence (AI) systems on healthcare delivery. AI-based tools may improve prognosis, diagnostics, and care planning. It is believed that AI will be an integral part of healthcare services in the near future and will be incorporated into several aspects of clinical care. Thus, many technology companies and governmental projects have invested in producing AI-based clinical tools and medical applications. Patients can be one of the most important beneficiaries and users of AI-based applications whose perceptions may affect the widespread use of AI-based tools. Patients should be ensured that they will not be harmed by AI-based devices, and instead, they will be benefited by using AI technology for healthcare purposes. Although AI can enhance healthcare outcomes, possible dimensions of concerns and risks should be addressed before its integration with routine clinical care. Methods: We develop a model mainly based on value perceptions due to the specificity of the healthcare field. This study aims at examining the perceived benefits and risks of AI medical devices with clinical decision support (CDS) features from consumers' perspectives. We use an online survey to collect data from 307 individuals in the United States. Results: The proposed model identifies the sources of motivation and pressure for patients in the development of AI-based devices. The results show that technological, ethical (trust factors), and regulatory concerns significantly contribute to the perceived risks of using AI applications in healthcare. Of the three categories, technological concerns (i.e., performance and communication feature) are found to be the most significant predictors of risk beliefs. Conclusions: This study sheds more light on factors affecting perceived risks and proposes some recommendations on how to practically reduce these concerns. The findings of this study provide implications for research and practice in the area of AI-based CDS. Regulatory agencies, in cooperation with healthcare institutions, should establish normative standard and evaluation guidelines for the implementation and use of AI in healthcare. Regular audits and ongoing monitoring and reporting systems can be used to continuously evaluate the safety, quality, transparency, and ethical factors of AI-based services.  © 2020 The Author(s).","2-s2.0-85088428041"
"Kocaballi A.B.; Coiera E.; Berkovsky S.","Kocaballi, A. Baki (57218145510); Coiera, Enrico (7003453209); Berkovsky, Shlomo (8945336100)","57218145510; 7003453209; 8945336100","Revisiting habitability in conversational systems","2020","Conference on Human Factors in Computing Systems - Proceedings","","","3383014","","","","10.1145/3334480.3383014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090205913&doi=10.1145%2f3334480.3383014&partnerID=40&md5=3fb8095514d74b18060ce084496d8602","Conversational systems are inherently disadvantaged when indicating either what capabilities they have or the state they are in. The notion of habitability, the appropriate balancing in design between the language people use and the language a system can accept, emerged out of these early difficulties with conversational systems. This literature review aims to summarize progress in habitability research and explore implications for the design of current AI-enabled conversational systems. We found that i) the definitions of habitability focus mostly on matching between user expectations and system capabilities by employing well-balanced restrictions on language use; ii) there are two comprehensive design perspectives on different domains of habitability; iii) there is one standardized questionnaire with a sub-scale to measure habitability in a limited way. The review has allowed us to propose a working definition of habitability and some design implications that may prove useful for guiding future research and practice in this field. © 2020 Owner/Author.","2-s2.0-85090205913"
"Asif M.; Ilyas A.; Sajjad S.M.; Masood A.","Asif, Muhammad (57216121053); Ilyas, Azeem (50061325200); Sajjad, Syed Muhammad (56342241200); Masood, Adnan (57215434447)","57216121053; 50061325200; 56342241200; 57215434447","Automatic alert generation against pre-defined rules-set for perimetric security of sensitive premises using YOLOv3","2019","15th International Conference on Emerging Technologies, ICET 2019","","","8994686","","","","10.1109/ICET48972.2019.8994686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080932625&doi=10.1109%2fICET48972.2019.8994686&partnerID=40&md5=c13f2ce4a6c4bf9e74acff00637c4d15","Adaptation of artificial intelligence (AI) based solutions at sensitive locations is growing rapidly. Use of these techniques along with surveillance cameras has become a primary requirement of smart cities to convert data into intelligible information. Consequently, these solutions are minimizing the effort of training and reliance on human resource. In this research paper, we have devised use cases of object detection with focus on human and luggage detection in real-time using a Convolutional Neural Network (CNN) technique YOLOv3. This technique, trained on MS-COCO dataset, has not been able to produce desirable results when tested on images from subcontinent region containing luggage, human or both. As a case study, we enhanced MS-COCO dataset by incorporating our own collection of realistic images. The study is carried out on a commodity hardware to strengthen our claim to use technology over humans. The proposed solution is developed for analysing video streams in real time against a predefined rules-set. Idea to automate the process of surveillance at strategic locations without human intervention opens a new window of research for literary community to develop cost effective solutions. © 2019 IEEE.","2-s2.0-85080932625"
"Alonso J.M.","Alonso, Jose M. (58258461100)","58258461100","Explainable artificial intelligence for kids","2020","Proceedings of the 11th Conference of the European Society for Fuzzy Logic and Technology, EUSFLAT 2019","","","","134","141","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089592709&partnerID=40&md5=7d8fb2cb0e358cca570616c919a35e80","Artificial Intelligence (AI) is part of our everyday life and has become one of the most outstanding and strategic technologies of the 21st century. Explainable AI (XAI in short) is expected to endow AI systems with explanation ability when interacting with humans. This paper describes how to provide kids with natural explanations, i.e., explanations verbalized in Natural Language, in the context of identifying/recognizing roles of basketball players. Semantic grounding is achieved through fuzzy concepts such as tall or short. Selected players are automatically classified by an ensemble of three different decision trees and one fuzzy rule-based classifier. All the single classifiers were first trained with the open source Weka software and then natural explanations were generated by the open source web service ExpliClas. The Human-Computer Interaction interface is implemented in Scratch, that is a visual programming language adapted to kids. The developed Scratch program is used for dissemination purposes when high-school teenagers visit the Research Center in Intelligent Technologies of the University of Santiago de Compostela. Copyright © 2019, the Authors. Published by Atlantis Press. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by-nc/4.0/).","2-s2.0-85089592709"
"Alonso J.M.; Toja-Alamancos J.; Bugarin A.","Alonso, Jose M. (58258461100); Toja-Alamancos, J. (57218863676); Bugarin, A. (55910844200)","58258461100; 57218863676; 55910844200","Experimental study on generating multi-modal explanations of black-box classifiers in terms of gray-box classifiers","2020","IEEE International Conference on Fuzzy Systems","2020-July","","9177770","","","","10.1109/FUZZ48607.2020.9177770","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090496626&doi=10.1109%2fFUZZ48607.2020.9177770&partnerID=40&md5=b44c964ec9c573b82dbd62334e857367","Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets. © 2020 IEEE.","2-s2.0-85090496626"
"Pedreschi D.; Giannotti F.; Guidotti R.; Monreale A.; Ruggieri S.; Turini F.","Pedreschi, Dino (6603935985); Giannotti, Fosca (7004495132); Guidotti, Riccardo (56506805200); Monreale, Anna (35113703300); Ruggieri, Salvatore (35240601200); Turini, Franco (7004433304)","6603935985; 7004495132; 56506805200; 35113703300; 35240601200; 7004433304","Meaningful explanations of black box ai decision systems","2019","33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019","","","","9780","9784","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072855846&partnerID=40&md5=ee5a858b704c262308c636a2d3ccb9e6","Black box AI systems for automated decision making, often based on machine learning over (big) data, map a user's features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases inherited by the algorithms from human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We focus on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems, introducing the local-to-global framework for black box explanation, articulated along three lines: (i) the language for expressing explanations in terms of logic rules, with statistical and causal interpretation; (ii) the inference of local explanations for revealing the decision rationale for a specific case, by auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of many local explanations into simple global ones, with algorithms that optimize for quality and comprehensibility. We argue that the local-first approach opens the door to a wide variety of alternative solutions along different dimensions: a variety of data sources (relational, text, images, etc.), a variety of learning problems (multi-label classification, regression, scoring, ranking), a variety of languages for expressing meaningful explanations, a variety of means to audit a black box. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85072855846"
"Rossi F.; Mattei N.","Rossi, Francesca (56066648900); Mattei, Nicholas (35234406800)","56066648900; 35234406800","Building ethically bounded ai","2019","33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019","","","","9785","9789","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070966680&partnerID=40&md5=8f8b0508de7a074ad3fe06a32f3c0392","The more AI agents are deployed in scenarios with possibly unexpected situations, the more they need to be flexible, adaptive, and creative in achieving the goal we have given them. Thus, a certain level of freedom to choose the best path to the goal is inherent in making AI robust and flexible enough. At the same time, however, the pervasive deployment of AI in our life, whether AI is autonomous or collaborating with humans, raises several ethical challenges. AI agents should be aware and follow appropriate ethical principles and should thus exhibit properties such as fairness or other virtues. These ethical principles should define the boundaries of AI's freedom and creativity. However, it is still a challenge to understand how to specify and reason with ethical boundaries in AI agents and how to combine them appropriately with subjective preferences and goal specifications. Some initial attempts employ either a data-driven example-based approach for both, or a symbolic rule-based approach for both. We envision a modular approach where any AI technique can be used for any of these essential ingredients in decision making or decision support systems, paired with a contextual approach to define their combination and relative weight. In a world where neither humans nor AI systems work in isolation, but are tightly interconnected, e.g., the Internet of Things, we also envision a compositional approach to building ethically bounded AI, where the ethical properties of each component can be fruitfully exploited to derive those of the overall system. In this paper we define and motivate the notion of ethically-bounded AI, we describe two concrete examples, and we outline some outstanding challenges. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85070966680"
"Vakkuri V.; Kemell K.-K.","Vakkuri, Ville (57203640458); Kemell, Kai-Kristian (57203633786)","57203640458; 57203633786","Implementing artificial intelligence ethics: A tutorial","2019","Lecture Notes in Business Information Processing","370 LNBIP","","","439","442","3","10.1007/978-3-030-33742-1_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076153467&doi=10.1007%2f978-3-030-33742-1_38&partnerID=40&md5=2369cec807d8625be709526fb7ddef79","Artificial Intelligence (AI) Ethics have steadily gained attention following various real-world incidents surrounding both purely digital and cyber-physical AI systems. Concerns have been raised over the ethical aspects of these systems for example in relation to data privacy, or material harm in the case of cyber-physical systems. Though academic activity in the area has grown recently, much of the current corpus consists of theoretical and conceptual studies. Attempts to bring this on-going discussion into practice have been primarily made in the form of various guidelines for ethical development of AI systems. However, these guidelines have not been adopted out on the field. The current situation in the area calls for more actionable methods for AI ethics, focusing on the point of view of developers. In this paper, we discuss current methods for implementing ethics in different contexts and then provide an introduction to a tutorial on a developer-focused method for implementing AI ethics, the Ethics Card Deck. © Springer Nature Switzerland AG 2019.","2-s2.0-85076153467"
"Rajaratnam D.; Thielscher M.","Rajaratnam, David (23397871300); Thielscher, Michael (6701317963)","23397871300; 6701317963","Execution monitoring as meta-games for general game-playing robots","2015","IJCAI International Joint Conference on Artificial Intelligence","2015-January","","","3178","3185","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949812532&partnerID=40&md5=e56d081be7b7436a8239658008a0c7ca","General Game Playing aims to create AI systems that can understand the rules of new games and learn to play them effectively without human intervention. The recent proposal for general game-playing robots extends this to AI systems that play games in the real world. Execution monitoring becomes a necessity when moving from a virtual to a physical environment, because in reality actions may not be executed properly and (human) opponents may make illegal game moves. We develop a formal framework for execution monitoring by which an action theory that provides an axiomatic description of a game is automatically embedded in a meta-game for a robotic player - called the arbiter - whose role is to monitor and correct failed actions. This allows for the seamless encoding of recovery behaviours within a meta-game, enabling a robot to recover from these unexpected events.","2-s2.0-84949812532"
"Martinez-Maldonado R.; Clayphan A.; Yacef K.; Kay J.","Martinez-Maldonado, Roberto (55255183300); Clayphan, Andrew (25928244000); Yacef, Kalina (6505989104); Kay, Judy (7201938514)","55255183300; 25928244000; 6505989104; 7201938514","Towards providing notifications to enhance teacher's awareness in the classroom","2014","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","8474 LNCS","","","510","515","5","10.1007/978-3-319-07221-0_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958542637&doi=10.1007%2f978-3-319-07221-0_64&partnerID=40&md5=224908d12c0670be5c8ec707d8c79684","Students often need prompt feedback to make the best from the learning activities. Within classrooms, being aware of students' achievements and weaknesses can help teachers decide how to time feedback. However, they usually cannot easily assess student's progress. We present an approach to generate automated notifications that can enhance teacher's awareness in runtime. This paper formulates the theoretical framing and describes the technological infrastructure of a system that can help teachers orchestrate learning activities and monitor small groups in a multi-tabletop classroom. We define the design guidelines underpinning our system, which include: i) generating notifications from teacher-designed or AI-based sources; ii) enhancing teacher's awareness in the orchestration loop; iii) presenting both positive and negative notifications; iv) allowing teachers to tune the system; and v) providing a private teacher's user interface. Our approach aims to guide research on ways to generate notifications that can help teachers drive their attention and provide relevant feedback for small group learning activities in the classroom. © 2014 Springer International Publishing Switzerland.","2-s2.0-84958542637"
"Frick N.R.J.; Brünker F.; Ross B.; Stieglitz S.","Frick, Nicholas R.J. (57192159515); Brünker, Felix (57211821217); Ross, Björn (57195061365); Stieglitz, Stefan (8982225800)","57192159515; 57211821217; 57195061365; 8982225800","Towards Successful Collaboration: Design Guidelines for AI-based Services enriching Information Systems in Organisations","2019","ACIS 2019 Proceedings - 30th Australasian Conference on Information Systems","","","","355","361","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099284170&partnerID=40&md5=8ed9ac52f64cb5c73573446562601575","Information systems (IS) are widely used in organisations to improve business performance. The steady progression in improving technologies like artificial intelligence (AI) and the need of securing future success of organisations lead to new requirements for IS. This research in progress firstly introduces the term AI-based services (AIBS) describing AI as a component enriching IS aiming at collaborating with employees and assisting in the execution of work-related tasks. The study derives requirements from ten expert interviews to successful design AIBS following Design Science Research (DSR). For a successful deployment of AIBS in organisations the D&M IS Success Model will be considered to validated requirements within three major dimensions of quality: Information Quality, System Quality, and Service Quality. Amongst others, preliminary findings propose that AIBS must be preferably authentic. Further discussion and research on AIBS is forced, thus, providing first insights on the deployment of AIBS in organisations. © 2019 Frick, Brünker, Ross & Stieglitz.","2-s2.0-85099284170"
"Torresen J.","Torresen, Jim (6602518300)","6602518300","A Review of Future and Ethical Perspectives of Robotics and AI","2018","Frontiers in Robotics and AI","4","","75","","","","10.3389/frobt.2017.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052191929&doi=10.3389%2ffrobt.2017.00075&partnerID=40&md5=b6bf68cfe561595f3482f8bdc24bcafc","In recent years, there has been increased attention on the possible impact of future robotics and AI systems. Prominent thinkers have publicly warned about the risk of a dystopian future when the complexity of these systems progresses further. These warnings stand in contrast to the current state-of-the-art of the robotics and AI technology. This article reviews work considering both the future potential of robotics and AI systems, and ethical considerations that need to be taken in order to avoid a dystopian future. References to recent initiatives to outline ethical guidelines for both the design of systems and how they should operate are included. © Copyright © 2018 Torresen.","2-s2.0-85052191929"
"Rademacher T.","Rademacher, Timo (57216940988)","57216940988","Artificial intelligence and law enforcement","2019","Regulating Artificial Intelligence","","","","225","254","29","10.1007/978-3-030-32361-5_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085450918&doi=10.1007%2f978-3-030-32361-5_10&partnerID=40&md5=c602bf744f289ae7d11e95486eb8836b","Artificial intelligence is increasingly able to autonomously detect suspicious activities (‘smart’ law enforcement). In certain domains, technology already fulfills the task of detecting suspicious activities better than human police officers ever could. In such areas, i.e. if and where smart law enforcement technologies actually work well enough, legislators and law enforcement agencies should consider their use. Unfortunately, the German Constitutional Court, the European Court of Justice, and the US Supreme Court are all struggling to develop convincing and clear-cut guidelines to direct these legislative and administrative considerations. This article attempts to offer such guidance: First, lawmakers need to implement regulatory provisions in order to maintain human accountability if AI-based law enforcement technologies are to be used. Secondly, AI law enforcement should be used, if and where possible, to overcome discriminatory traits in human policing that have plagued some jurisdictions for decades. Finally, given that smart law enforcement promises an ever more effective and even ubiquitous enforcement of the law-a ‘perfect’ rule of law, in that sense-it invites us as democratic societies to decide if, where, and when we might wish to preserve the freedom to disobey the rule(s) of law. © Springer Nature Switzerland AG 2020.","2-s2.0-85085450918"
"Rajaratnam D.; Thielscher M.","Rajaratnam, David (23397871300); Thielscher, Michael (6701317963)","23397871300; 6701317963","Towards general game-playing robots: Models, architecture and game controller","2013","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","8272 LNAI","","","271","276","5","10.1007/978-3-319-03680-9_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893802241&doi=10.1007%2f978-3-319-03680-9_29&partnerID=40&md5=bba4e172a8d479fbd3fef632649d5ecc","General Game Playing aims at AI systems that can understand the rules of new games and learn to play them effectively without human intervention. Our paper takes the first step towards general game-playing robots, which extend this capability to AI systems that play games in the real world.We develop a formal model for general games in physical environments and provide a systems architecture that allows the embedding of existing general game players as the ""brain"" and suitable robotic systems as the ""body"" of a general game-playing robot. We also report on an initial robot prototype that can understand the rules of arbitrary games and learns to play them in a fixed physical game environment. © Springer International Publishing 2013.","2-s2.0-84893802241"
"Verdiesen I.","Verdiesen, Ilse (57191337584)","57191337584","The Design of Human Oversight in Autonomous Weapon Systems","2018","AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society","","","","388","389","1","10.1145/3278721.3278785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061031253&doi=10.1145%2f3278721.3278785&partnerID=40&md5=60a051be6db64196c1457572aeb9e761","As the reach and capabilities of Artificial Intelligence (AI) systems increases, there is also a growing awareness of the ethical, legal and societal impact of the potential actions and decisions of these systems. Many are calling for guidelines and regulations that can ensure the responsible design, development, implementation, and policy of AI. In scientific literature, AI is characterized by the concepts of Adaptability, Interactivity and Autonomy (Floridi & Sanders, 2004). According to Floridi and Sanders (2004), Adaptability means that the system can change based on its interaction and can learn from its experience. Machine learning techniques are an example of this. Interactivity occurs when the system and its environment act upon each other and Autonomy implies that the system itself can change its state. © 2018 Author.","2-s2.0-85061031253"
"Schiel A.","Schiel, Andrea (57203922481)","57203922481","Production systems: New techniques in AAA games","2015","Game AI Pro 2: Collected Wisdom of Game AI Professionals","","","","59","68","9","10.1201/b18373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053588684&doi=10.1201%2fb18373&partnerID=40&md5=db77bab72dfeb8a143ad1de4dfcd4ad3","Production systems have been around since the 1940s and are now applied in a wide array of applications and ongoing research. AAA games bring a unique set of challenges to production systems; they require that AI systems be runtime efficient, deterministic, memory lean, and above all, implementable within the development cycle. Over the course of many of our titles, production systems have developed along different lines. This chapter tries to describe the majority of our more unique production systems, assuming that the reader has a basic knowledge of production systems. For readers who want to code their first production system, there is a list of references that describe basic production systems in more detail [Luger 93, Millington 09, Laird 12, Bourg 04] and these 9.1 Introduction 9.2 What Decisions Is the System Trying to Make? 9.3 Choice of Rules Representation 9.4 Method of Rules Authoring 9.5 Choice of Matching System 9.6 What Happens If the AI Fails to Find a Rule? © 2015 by Taylor & Francis Group, LLC.","2-s2.0-85053588684"
"Amershi S.; Begel A.; Bird C.; DeLine R.; Gall H.; Kamar E.; Nagappan N.; Nushi B.; Zimmermann T.","Amershi, Saleema (23007675700); Begel, Andrew (6506114539); Bird, Christian (17433640400); DeLine, Robert (6602118069); Gall, Harald (56223438700); Kamar, Ece (23009039400); Nagappan, Nachiappan (8261920700); Nushi, Besmira (54581306500); Zimmermann, Thomas (16308551800)","23007675700; 6506114539; 17433640400; 6602118069; 56223438700; 23009039400; 8261920700; 54581306500; 16308551800","Software Engineering for Machine Learning: A Case Study","2019","Proceedings - 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP 2019","","","8804457","291","300","9","10.1109/ICSE-SEIP.2019.00042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072111655&doi=10.1109%2fICSE-SEIP.2019.00042&partnerID=40&md5=8c03592773800ea1ac1b5a71f9fae249","Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components-models may be 'entangled' in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations. © 2019 IEEE.","2-s2.0-85072111655"
"Soviany C.","Soviany, Cristina (23135787400)","23135787400","The benefits of using artificial intelligence in payment fraud detection: A case study","2018","Journal of Payments Strategy and Systems","12","2","","102","110","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059097189&partnerID=40&md5=8ee77b5acd4b4bdaad3b054deb5a8b1d","This paper presents a case study on the use of advanced artificial intelligence (AI) for the detection of payments fraud. The process applies AI within a typical online payment environment to detect fraudulent transactions in real time. The design focuses on an effective supervised learning engine with a data analytics component to support high-performance fraud detection, improving the predictive value of the original data.The design exploits the discriminant properties of customer data by finding hidden patterns. This feature significantly improves fraud detection rate and performance stability compared with a rule-based solution.The developed solution, based on an advanced AI-based technology and platform increased fraud detection rate from 85 per cent to 90 per cent (in terms of number of transaction records) and to 95 per cent in related amount volume (in terms of transaction value), while the alert rate (the percentage of daily transactions investigated manually) was reduced from 40 per cent to 10 per cent.The solution falls under the category of explainable AI because it can explain the rationale behind the decisions. © Henry Stewart Publications, 1750-1806.","2-s2.0-85059097189"
"Curry A.C.; Rieser V.","Curry, Amanda Cercas (57200410103); Rieser, Verena (24345304600)","57200410103; 24345304600","#MeToo: How conversational systems respond to sexual harassment","2018","Proceedings of the 2nd ACL Workshop on Ethics in Natural Language Processing, EthNLP 2018 at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HTL 2018","","","","7","15","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119976046&partnerID=40&md5=819ede2841d3529e0456ae6828d366d6","Conversational AI systems are rapidly developing from purely transactional systems to social chatbots, which can respond to a wide variety of user requests. In this article, we establish how current state-of-the-art conversational systems react to inappropriate requests, such as bullying and sexual harassment on the part of the user, by collecting and analysing the novel #MeToo corpus. Our results show that commercial systems mainly avoid answering, while rule-based chatbots show a variety of behaviours and often deflect. Data-driven systems, on the other hand, are often non-coherent, but also run the risk of being interpreted as flirtatious and sometimes react with counter-aggression. This includes our own system, trained on “clean” data, which suggests that inappropriate system behaviour is not caused by data bias. © 2018 Association for Computational Linguistics","2-s2.0-85119976046"
"LaRosa E.; Danks D.","LaRosa, Emily (57205671302); Danks, David (36169046300)","57205671302; 36169046300","Impacts on Trust of Healthcare AI","2018","AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society","","","","210","215","5","10.1145/3278721.3278771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061064808&doi=10.1145%2f3278721.3278771&partnerID=40&md5=6fa3bad9132906894911b2590d69dc8b","Artificial Intelligence and robotics are rapidly moving into healthcare, playing key roles in specific medical functions, including diagnosis and clinical treatment. Much of the focus in the technology development has been on human-machine interactions, leading to a host of related technology-centric questions. In this paper, we focus instead on the impact of these technologies on human-human interactions and relationships within the healthcare domain. In particular, we argue that trust plays a central role for relationships in the healthcare domain, and the introduction of healthcare AI can potentially have significant impacts on those relations of trust. We contend that healthcare AI systems ought to be treated as assistive technologies that go beyond the usual functions of medical devices. As a result, we need to rethink regulation of healthcare AI systems to ensure they advance relevant values. We propose three distinct guidelines that can be universalized across federal regulatory boards to ensure that patient-doctor trust is not detrimentally affected by the deployment and widespread adoption of healthcare AI technologies. © 2018 ACM.","2-s2.0-85061064808"
"Wang X.; Li X.; Leung V.C.M.","Wang, Xiaofei (35118116900); Li, Xiuhua (56453986200); Leung, Victor C. M. (7102336029)","35118116900; 56453986200; 7102336029","Artificial intelligence-based techniques for emerging heterogeneous network: State of the arts, opportunities, and challenges","2015","IEEE Access","3","","7185326","1379","1391","12","10.1109/ACCESS.2015.2467174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959852995&doi=10.1109%2fACCESS.2015.2467174&partnerID=40&md5=9f2801938639c05a2f871e4edd3e5c19","Recently, mobile networking systems have been designed with more complexity of infrastructure and higher diversity of associated devices and resources, as well as more dynamical formations of networks, due to the fast development of current Internet and mobile communication industry. In such emerging mobile heterogeneous networks (HetNets), there are a large number of technical challenges focusing on the efficient organization, management, maintenance, and optimization, over the complicated system resources. In particular, HetNets have attracted great interest from academia and industry in deploying more effective solutions based on artificial intelligence (AI) techniques, e.g., machine learning, bio-inspired algorithms, fuzzy neural network, and so on, because AI techniques can naturally handle the problems of large-scale complex systems, such as HetNets towards more intelligent and automatic-evolving ones. In this paper, we discuss the state-of-the-art AI-based techniques for evolving the smarter HetNets infrastructure and systems, focusing on the research issues of self-configuration, self-healing, and self-optimization, respectively. A detailed taxonomy of the related AI-based techniques of HetNets is also shown by discussing the pros and cons for various AI-based techniques for different problems in HetNets. Opening research issues and pending challenges are concluded as well, which can provide guidelines for future research work. © 2015 IEEE.","2-s2.0-84959852995"
"Khummongkol R.; Yokota M.","Khummongkol, Rojanee (24512140900); Yokota, Masao (7201923880)","24512140900; 7201923880","An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations","2017","Proceedings - 2017 IEEE 8th International Conference on Awareness Science and Technology, iCAST 2017","2018-January","","","254","259","5","10.1109/ICAwST.2017.8256457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050676198&doi=10.1109%2fICAwST.2017.8256457&partnerID=40&md5=ee010c1616f6d3f71cd27627245e7301","It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL. © 2017 IEEE.","2-s2.0-85050676198"
"Roselli D.; Matthews J.; Talagala N.","Roselli, Drew (6602760776); Matthews, Jeanna (7402837019); Talagala, Nisha (23037266400)","6602760776; 7402837019; 23037266400","Managing bias in AI","2019","The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019","","","","539","544","5","10.1145/3308560.3317590","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066905886&doi=10.1145%2f3308560.3317590&partnerID=40&md5=927da2c596b0455c03ea0c78aea98272","Recent awareness of the impacts of bias in AI algorithms raises the risk for companies to deploy such algorithms, especially because the algorithms may not be explainable in the same way that non-AI algorithms are. Even with careful review of the algorithms and data sets, it may not be possible to delete all unwanted bias, particularly because AI systems learn from historical data, which encodes historical biases. In this paper, we propose a set of processes that companies can use to mitigate and manage three general classes of bias: those related to mapping the business intent into the AI implementation, those that arise due to the distribution of samples used for training, and those that are present in individual input samples. While there may be no simple or complete solution to this issue, best practices can be used to reduce the effects of bias on algorithmic outcomes. � 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND 4.0 License.","2-s2.0-85066905886"
"Tajane K.; Dave S.; Jahagirdar P.; Ghadge A.; Musale A.","Tajane, Kapil (56538589600); Dave, Saransh (57208574656); Jahagirdar, Pankaj (57208578571); Ghadge, Abhijeet (57209385236); Musale, Akash (57208580465)","56538589600; 57208574656; 57208578571; 57209385236; 57208580465","AI Based Chat-Bot Using Azure Cognitive Services","2018","Proceedings - 2018 4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018","","","8697737","","","","10.1109/ICCUBEA.2018.8697737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065192135&doi=10.1109%2fICCUBEA.2018.8697737&partnerID=40&md5=708d53441b6e6cab2e5f56233e9fb16d","Letters ruled the earlier era in communication. Then with emergence of Telephones and subsequently mobile phones, voice conversations ruled the communication. However, currently, with the emergence of Internet and lots of social media, chat conversations are ruling the world. Think of your closest friend and ask yourself, have you talked more or chatted more? So, with popularity of chat in today's world, many technologists envisioned that chat couldn't just be a mode of communication between humans but also between a human and a computer. That's what chat-bot is. In some cases it is powered by machine learning (the more you interact with the chat-bot the smarter it gets). Or, more commonly, it is driven using intelligent rules (i.e. if a person says this, respond with that). A chat-bot can be useful in providing services in a variety of scenarios. These services include life-saving health messages, it may also include weather forecast or to purchase a new laptop, smartphone, and anything else in between. Many of the big companies like Google (Google Assistant), Amazon (Alexa), Microsoft (Cortana) and Oracle are spending good amount of energy and money for research on personal assistants. The following subjects would be touched upon for the development of chat-bot: •Using Azure Bot Architecture •Using NLP for Language Understanding from the user and for the Language Generation •Using Custom Vision services for the image recognition. © 2018 IEEE.","2-s2.0-85065192135"
"Rawat S.S.S.; Mor D.D.; Roy S.S.; Kumar A.; Ramesh R.","Rawat, Sarvesh S.S. (55639485500); Mor, Dheeraj Dilip (56412999800); Roy, Sanjiban Sekhar (55476505900); Kumar, Anugrah (55662716300); Ramesh, Rohit (58355154700)","55639485500; 56412999800; 55476505900; 55662716300; 58355154700","Improving circuit miniaturization and its efficiency using rough set theory","2014","Proceedings - 2013 International Conference on Machine Intelligence Research and Advancement, ICMIRA 2013","","","6918856","374","378","4","10.1109/ICMIRA.2013.79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910022177&doi=10.1109%2fICMIRA.2013.79&partnerID=40&md5=940beef1541eb5d53da5d931c6cf0e5f","High-speed, accuracy, meticulousness and quick responses are the notion of the vital necessities for modern digital world. An efficient electronic circuit unswervingly affects the maneuver of the whole system. Different tools are required to unravel different types of engineering tribulations. Improving the efficiency, accuracy and low power consumption in an electronic circuit is always been a bottle neck problem. So the need of circuit miniaturization is always there. It saves a lot of time and power while switching of gates and reduces the wiring-crises. Therefore to trounce with this problem we have proposed an artificial intelligence (AI) based approach that makes use of Rough Set Theory for its implementation. Theory of rough set has been proposed by Z Pawlak in the year 1982. Rough set theory is a new mathematical tool which deals with uncertainty and vagueness. Decisions can be generated using rough set theory by reducing the unwanted and superfluous data. We have condensed the number of gates without upsetting the productivity of the given circuit. This paper proposes an approach using artificial intelligence technique with the help of rough set theory which basically lessens the number of gates in the circuit, based on decision rules. © 2013 IEEE.","2-s2.0-84910022177"
"Gorban A.N.; Burton R.; Romanenko I.; Tyukin I.Y.","Gorban, Alexander N. (7005285942); Burton, Richard (57205662760); Romanenko, Ilya (36728062700); Tyukin, Ivan Yu. (6603442271)","7005285942; 57205662760; 36728062700; 6603442271","One-trial correction of legacy AI systems and stochastic separation theorems","2019","Information Sciences","484","","","237","254","17","10.1016/j.ins.2019.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060987660&doi=10.1016%2fj.ins.2019.02.001&partnerID=40&md5=094c6407f454571e777c84a0d9941fc8","We consider the problem of efficient “on the fly” tuning of existing, or legacy, Artificial Intelligence (AI) systems. The legacy AI systems are allowed to be of arbitrary class, albeit the data they are using for computing interim or final decision responses should posses an underlying structure of a high-dimensional topological real vector space. The tuning method that we propose enables dealing with errors without the need to re-train the system. Instead of re-training a simple cascade of perceptron nodes is added to the legacy system. The added cascade modulates the AI legacy system's decisions. If applied repeatedly, the process results in a network of modulating rules “dressing up” and improving performance of existing AI systems. Mathematical rationale behind the method is based on the fundamental property of measure concentration in high dimensional spaces. The method is illustrated with an example of fine-tuning a deep convolutional network that has been pre-trained to detect pedestrians in images. © 2019 Elsevier Inc.","2-s2.0-85060987660"
"Alikhademi K.; Richardson B.; Ross K.; Sung J.; Gilbert J.E.; Kwon W.-S.; Chattaraman V.","Alikhademi, Kiana (57201906629); Richardson, Brianna (57210154562); Ross, Kassandra (57204788169); Sung, Jihyun (57210146888); Gilbert, Juan E. (8365435900); Kwon, Wi-Suk (17135349200); Chattaraman, Veena (12793986300)","57201906629; 57210154562; 57204788169; 57210146888; 8365435900; 17135349200; 12793986300","AI-Based Technical Approach for Designing Mobile Decision Aids","2019","Communications in Computer and Information Science","1033","","","163","169","6","10.1007/978-3-030-23528-4_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069670666&doi=10.1007%2f978-3-030-23528-4_23&partnerID=40&md5=9f85dcec7a042ffeaffca580775391d1","Conversational Voice User Interfaces (VUIs) help us in performing tasks in a wide range of domains these days. While there have been several efforts around designing dialogue systems and conversation flows, little information is available about technical concepts to extract critical information for addressing the users’ needs. For conversational VUIs to function appropriately as a decision aid, artificial intelligence (AI) that recognizes and supports diverse user decision strategies is a critical need. Following the design principle proposed by Kwon et al. [1] regarding the conversational flow between the user and conversational VUI, we developed an AI-based mobile-decision-aid (MODA) that predictively models and addresses users’ decision strategies to facilitate users’ in-store shopping decision process. In this paper, technical details about how MODA processes users’ natural language queries and generate the most appropriate and intelligent recommendations have been discussed. This developmental approach provides broad implications to conversational VUIs for diverse complex decision-making contexts and decision-makers with a critical need for decision assistants. © Springer Nature Switzerland AG 2019.","2-s2.0-85069670666"
"Verheij B.","Verheij, Bart (6602409964)","6602409964","Arguments for ethical systems design","2016","Frontiers in Artificial Intelligence and Applications","294","","","101","110","9","10.3233/978-1-61499-726-9-101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014767113&doi=10.3233%2f978-1-61499-726-9-101&partnerID=40&md5=b7d4d887eddb91fef16d266a8f8a59b3","Today's AI applications are so successful that they inspire renewed concerns about AI systems becoming ever more powerful. Addressing these concerns requires AI systems that are designed as ethical systems, in the sense that their choices are context-dependent, value-guided and rule-following. It is shown how techniques connecting qualitative and quantitative primitives recently developed for evidential argumentation in the law can be used for the design of such ethical systems. In this way, AI and Law techniques are extended to the theoretical understanding of intelligent systems guided by embedded values. © 2016 The authors and IOS Press. All rights reserved.","2-s2.0-85014767113"
"Stephanakis I.M.; Chochliouros I.P.; Sfakianakis E.; Shirazi S.N.; Hutchison D.","Stephanakis, Ioannis M. (6603596373); Chochliouros, Ioannis P. (35585314700); Sfakianakis, Evangelos (35312224000); Shirazi, Syed Noorulhassan (57190341027); Hutchison, David (56976429600)","6603596373; 35585314700; 35312224000; 57190341027; 56976429600","Hybrid self-organizing feature map (SOM) for anomaly detection in cloud infrastructures using granular clustering based upon value-difference metrics","2019","Information Sciences","494","","","247","277","30","10.1016/j.ins.2019.03.069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065059715&doi=10.1016%2fj.ins.2019.03.069&partnerID=40&md5=696e0dbb05b90f822599f5eb5c15fb25","We have witnessed an increase in the availability of data from diverse sources over the past few years. Cloud computing, big data and Internet-of-Things (IoT) are distinctive cases of such an increase which demand novel approaches for data analytics in order to process and analyze huge volumes of data for security and business use. Cloud computing has been becoming popular for critical structure IT mainly due to cost savings and dynamic scalability. Current offerings, however, are not mature enough with respect to stringent security and resilience requirements. Mechanisms such as anomaly detection hybrid systems are required in order to protect against various challenges that include network based attacks, performance issues and operational anomalies. Such hybrid AI systems include Neural Networks, blackboard systems, belief (Bayesian) networks, case-based reasoning and rule-based systems and can be implemented in a variety of ways. Traffic in the cloud comes from multiple heterogeneous domains and changes rapidly due to the variety of operational characteristics of the tenants using the cloud and the elasticity of the provided services. The underlying detection mechanisms rely upon measurements drawn from multiple sources. However, the characteristics of the distribution of measurements within specific subspaces might be unknown. We argue in this paper that there is a need to cluster the observed data during normal network operation into multiple subspaces each one of them featuring specific local attributes, i.e. granules of information. Clustering is implemented by the inference engine of a model hybrid NN system. Several variations of the so-called value-difference metric (VDM) are investigated like local histograms and the Canberra distance for scalar attributes, the Jaccard distance for binary word attributes, rough sets as well as local histograms over an aggregate ordering distance and the Canberra measure for vectorial attributes. Low-dimensional subspace representations of each group of points (measurements) in the context of anomaly detection in critical cloud implementations is based upon VD metrics and can be either parametric or non-parametric. A novel application of a Self-Organizing-Feature Map (SOFM) of reduced/aggregate ordered sets of objects featuring VD metrics (as obtained from distributed network measurements) is proposed. Each node of the SOFM stands for a structured local distribution of such objects within the input space. The so-called Neighborhood-based Outlier Factor (NOOF) is defined for such reduced/aggregate ordered sets of objects as a value-difference metric of histogrammes. Measurements that do not belong to local distributions are detected as anomalies, i.e. outliers of the trained SOFM. Several methods of subspace clustering using Expectation-Maximization Gaussian Mixture Models (a parametric approach) as well as local data densities (a non-parametric approach) are outlined and compared against the proposed method using data that are obtained from our cloud testbed in emulated anomalous traffic conditions. The results—which are obtained from a model NN system—indicate that the proposed method performs well in comparison with conventional techniques. © 2019 Elsevier Inc.","2-s2.0-85065059715"
"Revina A.","Revina, Aleksandra (57206201451)","57206201451","Assessing process suitability for AI-based automation. research idea and design","2019","Lecture Notes in Business Information Processing","339","","","697","706","9","10.1007/978-3-030-04849-5_59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061579395&doi=10.1007%2f978-3-030-04849-5_59&partnerID=40&md5=246908715f88683044854d035fee1ccf","Recent advancements in Big Data and Machine Learning (ML) have triggered progressive adoption of Artificial Intelligence (AI) in the enterprise domains to address growing business process complexity. What is yet largely missing in the traditional Business Process Management (BPM) approaches, are formal frameworks and guidelines for decision making support when applying AI in a company. Proposed research aims to extend existing BPM frameworks and guidelines by novel methods, this way increasing understanding of business processes in the view of recent technology developments in Big Data, AI and ML. © Springer Nature Switzerland AG 2019.","2-s2.0-85061579395"
"Xu J.; Wu K.","Xu, Jun (57200036536); Wu, Kaishun (22982222400)","57200036536; 22982222400","Living with Artificial Intelligence: A Paradigm Shift toward Future Network Traffic Control","2018","IEEE Network","32","6","8553661","92","99","7","10.1109/MNET.2018.1800119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057964992&doi=10.1109%2fMNET.2018.1800119&partnerID=40&md5=85329f9b5bbdb4fee316bbb2cc5e07b5","Future Internet is expected to meet explosive traffic growth and extremely complex architecture, which tend to make the traditional NTC strategies inefficient and even ineffective. Inspired by the latest breakthroughs of AI and its power to address large-scale and complex difficulties, the network community has begun to consider shifting the NTC paradigm from legacy rule-based to novel AI-based. As an applied inter-discipline, design and implementation are important. Although there have been some preliminary explorations along this frontier, they are either limited by only envisioning the prospects, or too scattered to provide high-level insight into a general methodology. To this end, we start with the domain knowledge relationships of AI and NTC, summarizing a baseline workflow toward deep reinforcement learning, which will be the dominant method for the AI-NTC paradigm. On top of that, we argue that AI-NTC training and running must be carried out in online environments in closed-loop fashion for the purpose of putting ti into practice. A series of challenges and opportunities are discussed from a realistic viewpoint, and a set of new architecture and mechanism to enable the online and closed-loop AI-NTC paradigm are proposed. Hopefully, this work can help the AI community to better understand NTC and the NTC community to better live with AI. © 1986-2012 IEEE.","2-s2.0-85057964992"
"Ishihara M.; Harada T.; Miyazaki T.; Thawonmas R.; Chu C.Y.","Ishihara, Makoto (57189055818); Harada, Tomohiro (41261288400); Miyazaki, Taichi (57189053978); Thawonmas, Ruck (6701619884); Chu, Chun Yin (57188986035)","57189055818; 41261288400; 57189053978; 6701619884; 57188986035","Applying and improving monte-carlo tree search in a fighting game AI","2016","ACM International Conference Proceeding Series","","","a27","","","","10.1145/3001773.3001797","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014645037&doi=10.1145%2f3001773.3001797&partnerID=40&md5=d5955b37c567787d999e57befa15490a","This paper evaluates the performance of Monte-Carlo Tree Search (MCTS) in a fighting game AI and proposes an improvement for the algorithm. Most existing fighting game AIs rely on rule bases and react to every situation with predefined actions, making them predictable for human players. We attempt to overcome this weakness by applying MCTS, which can adapt to different circumstances without relying on predefined action patterns or tactics. In this paper, an AI based on Upper Confidence bounds applied to Trees (UCT) and MCTS is first developed. Next, the paper proposes improving the AI with Roulette Selection and a rule base. Through testing and evaluation using Fighting-ICE, an international fighting game AI competition platform, it is proven that the aforementioned MCTS-based AI is effective in a fighting game, and our proposed improvement can further enhance its performance. © 2016 ACM.","2-s2.0-85014645037"
"Etzioni A.; Etzioni O.","Etzioni, Amitai (7102886487); Etzioni, Oren (7004312379)","7102886487; 7004312379","The ethics of robotic caregivers","2017","Interaction Studies","18","2","","174","190","16","10.1075/is.18.2.02etz","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038403756&doi=10.1075%2fis.18.2.02etz&partnerID=40&md5=756cc085f92d245f4a1f69fc2eba6aa2","As Artificial Intelligence technology seems poised for a major take-off and changing societal dynamics are creating a high demand for caregivers for elders, children, and those infirmed, robotic caregivers may well be used much more often. This article examines the ethical concerns raised by the use of AI caregivers and concludes that many of these concerns are avoided when AI caregivers operate as partners rather than substitutes. Furthermore, most of the remaining concerns are minor and are faced by human caregivers as well. Nonetheless, because AI caregivers' systems are learning systems, an AI caregiver could stray from its initial guidelines. Therefore, subjecting AI caregivers to an AI-based oversight system is proposed to ensure that their actions remain both legal and ethical.","2-s2.0-85038403756"
"Shin S.H.; Kim J.H.; Do Chi S.","Shin, Suk Hoon (56879631700); Kim, Jung Hoon (56119462200); Do Chi, Sung (7202336237)","56879631700; 56119462200; 7202336237","Dynamic rule-based agent","2018","International Journal of Engineering Research and Technology","11","4","","605","614","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055591344&partnerID=40&md5=72a9e6cc0d831bcd436b72cfaf48ffeb","This paper proposes a dynamic rule-based agent that can support the dynamic reasoning by coherently combining the conventional rule-based expert system agent with the dynamic modelling framework. The dynamic reasoning is one of essential mechanisms to mimic the human decision-making process. Since the timing difference between internal rule firing and externally incoming fact is critical to conclude the final decision. Unfortunately conventional AI systems cannot deal with such problems. In order to overcome this limitation, we have proposed the dynamic rule structure that consists of the condition and action as well as the inferencing time. Then we also have developed the dynamic inference algorithm that can handle the time-based rules. Our approach is compared with others in that it can support the dynamic rule structure and dynamic inference. Simulation test performed on the baseball example has been successfully applied to illustrate the feasibility of our technique. © International Research Publication House.","2-s2.0-85055591344"
"Stansfield K.E.; Azmat F.","Stansfield, Kim E. (57194467039); Azmat, Freeha (57196071555)","57194467039; 57196071555","Developing high value IoT solutions using AI enhanced ISO 16355 for QFD integrating market drivers into the design of IoT offerings","2017","Proceedings of 2017 International Conference on Communication, Computing and Digital Systems, C-CODE 2017","","","7918967","412","416","4","10.1109/C-CODE.2017.7918967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020292279&doi=10.1109%2fC-CODE.2017.7918967&partnerID=40&md5=c1125043422fb32d213ea28f601d3c51","The Internet of Things (IoT) provides huge opportunities for organisations developing new business models supported by interconnected product, service and software systems. Due to the complexity of IoT systems, the understanding and development of attractive new system functions is a great challenge compared with traditional, stand-alone product systems. Methods that focus on the integration of market and business analysis with product design and development emerged from Japan in the late 1960s under the title of Quality Function Deployment (QFD). These have undergone considerable development over the last 30 years to ensure they are appropriate for the development of both complex hardware, software and service systems and the current best practices are described in the recently published ISO 16355 for QFD. Recent significant progress in development of cognitive artificial intelligence (AI) systems such as IBM's Watson system, provides opportunities to gather and analyse significant volumes of market and technological information to support the core objectives of QFD i.e. aligning new product system design to customer and stakeholder priorities. This involves targeting information sources, refining analysis algorithms to ensure market priorities with associated underlying trends are identified reliably. In this paper, background concepts related to QFD are discussed and the areas where cognitive AI can have most significant impact on the QFD approach towards design and development of IoT systems will be covered. © 2017 IEEE.","2-s2.0-85020292279"
"Vaithianathasamy S.","Vaithianathasamy, Swami (57210435146)","57210435146","AI vs AI: fraudsters turn defensive technology into an attack tool","2019","Computer Fraud and Security","2019","8","","6","8","2","10.1016/S1361-3723(19)30083-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070686326&doi=10.1016%2fS1361-3723%2819%2930083-1&partnerID=40&md5=261671410527954d779d76a69dde770b","The first rule of managing online fraud and mitigating risk is to remember that fraudsters are entrepreneurs. While it's tempting to think of those committing digital fraud as hoody-wearing lone wolves spending hours in their bedroom working to weasel their way into someone's online account, in reality professional fraud operations look more like the JP Morgan trading floor. Cyber criminals are not simple, hoodie-wearing lone wolves. Many are sophisticated fraud operations using the most advanced technology, including artificial intelligence (AI). The energy and ingenuity with which fraud rings and cyber criminals have deployed AI-based solutions has matched that of the businesses and organisations that work to protect themselves from bad actors. Machines have been put to malicious use in ways ranging from click farms to complex model extraction schemes, explains Swami Vaithianathasamy of Signifyd. © 2019 Elsevier Ltd","2-s2.0-85070686326"
"Peng L.; Xiaohong S.","Peng, Liu (57204365875); Xiaohong, Si (57204364543)","57204365875; 57204364543","Predictions for the Potential Development of Artificial Intelligence in Chinese Education","2018","ACM International Conference Proceeding Series","","","","26","29","3","10.1145/3234825.3234839","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055336879&doi=10.1145%2f3234825.3234839&partnerID=40&md5=27015d6c55a9a1bb31f8fa0f83b4e35a","Artificial intelligence (AI) is the simulation of human thought processes and consciousness on computer systems. Experts have gone so far as to chart the future development of AI systems that surpass human intelligence as a single civilization-shifting event, known as the ""technological singularity"" or ""the Singularity."" But in the more near future, AI promises to have more concrete applications throughout our everyday lives, including in education, a challenge that China has already taken up. At present, the main applications of this so-called ""weak"" artificial intelligence in Chinese education are MOOC, web classes, and the flipped class model, with the results already proving outstanding. With the deeper combination of AI and education, we can look forward to benefits like the increasing usefulness of after-school tutoring robots, reliving teachers of burdensome responsibilities, and balancing global education resources. We should, however, also use AI in education reasonably by contextualizing gathered data, strengthening legal protections, and developing moral guidelines in machine programming. Addressing these three points will address the concerns of many laypeople as AI systems are implemented, offering protection for their fragile beginnings in education and encouraging the development of better ones in the future. © 2018 ACM.","2-s2.0-85055336879"
"Etzioni A.; Etzioni O.","Etzioni, Amitai (7102886487); Etzioni, Oren (7004312379)","7102886487; 7004312379","Viewpoint designing ai systems that obey our laws and values calling for research on automatic oversight for artificial intelligence systems.","2016","Communications of the ACM","59","9","","29","31","2","10.1145/2955091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984858107&doi=10.1145%2f2955091&partnerID=40&md5=79b91e13630d5b0c7f01db374f8cbf5f","OPERATIONAL AI SYSTEMS (for example, self-driving cars) need to obey both the law of the land and our values. We propose AI oversight systems (""AI Guardians"") as an approach to addressing this challenge, and to respond to the potential risks associated with increasingly autonomous AI systems.a These AI oversight systems serve to verify that operational systems did not stray unduly from the guidelines of their programmers and to bring them back in compliance if they do stray. The introduction of such second-order, oversight systems is not meant to suggest strict, powerful, or rigid (from here on 'strong') controls. Operations systems need a great degree of latitude in order to follow the lessons of their learning from additional data mining and experience and to be able to render at least semiautonomous decisions (more about this later). However, all operational systems need some boundaries, both in order to not violate the law and to adhere to ethical norms. Developing such oversight systems, AI Guardians, is a major new mission for the AI community.","2-s2.0-84984858107"
"Dasgupta I.; Guo D.; Stuhlmüller A.; Gershman S.J.; Goodman N.D.","Dasgupta, Ishita (57194405744); Guo, Demi (57208522002); Stuhlmüller, Andreas (55208728200); Gershman, Samuel J. (35108983800); Goodman, Noah D. (12767629400)","57194405744; 57208522002; 55208728200; 35108983800; 12767629400","Evaluating Compositionality in Sentence Embeddings","2018","Proceedings of the 40th Annual Meeting of the Cognitive Science Society, CogSci 2018","","","","1596","1601","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071189501&partnerID=40&md5=4c264a6f8c09300d5a5fa3ec8f93103d","An important challenge for human-like AI is compositional semantics. Recent research has attempted to address this by using deep neural networks to learn vector space embeddings of sentences, which then serve as input to other tasks. We present a new dataset for one such task, “natural language inference” (NLI), that cannot be solved using only word-level knowledge and requires some compositionality. We find that the performance of state of the art sentence embeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We analyze the decision rules learned by InferSent and find that they are largely driven by simple heuristics that are ecologically valid in its training dataset. Further, we find that augmenting training with our dataset improves test performance on our dataset without loss of performance on the original training dataset. This highlights the importance of structured datasets in better understanding and improving AI systems. © 2018 Proceedings of the 40th Annual Meeting of the Cognitive Science Society, CogSci 2018. All rights reserved.","2-s2.0-85071189501"
"Hernández-Orallo J.","Hernández-Orallo, José (6602454434)","6602454434","Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement","2017","Artificial Intelligence Review","48","3","","397","447","50","10.1007/s10462-016-9505-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982270121&doi=10.1007%2fs10462-016-9505-7&partnerID=40&md5=9a9f6a0f4b8935720a27f9990c7c3ebb","The evaluation of artificial intelligence systems and components is crucial for the progress of the discipline. In this paper we describe and critically assess the different ways AI systems are evaluated, and the role of components and techniques in these systems. We first focus on the traditional task-oriented evaluation approach. We identify three kinds of evaluation: human discrimination, problem benchmarks and peer confrontation. We describe some of the limitations of the many evaluation schemes and competitions in these three categories, and follow the progression of some of these tests. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more integrated approaches under the perspective of universal psychometrics. We analyse some evaluation tests from AI that are better positioned for an ability-oriented evaluation and discuss how their problems and limitations can possibly be addressed with some of the tools and ideas that appear within the paper. Finally, we enumerate a series of lessons learnt and generic guidelines to be used when an AI evaluation scheme is under consideration. © 2016, Springer Science+Business Media Dordrecht.","2-s2.0-84982270121"
"Gade K.; Geyik S.C.; Kenthapadi K.; Mithal V.; Taly A.","Gade, Krishna (55321364800); Geyik, Sahin Cem (25960659800); Kenthapadi, Krishnaram (12239006400); Mithal, Varun (26646794300); Taly, Ankur (57208046968)","55321364800; 25960659800; 12239006400; 26646794300; 57208046968","Explainable AI in industry","2019","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","3203","3204","1","10.1145/3292500.3332281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071169118&doi=10.1145%2f3292500.3332281&partnerID=40&md5=5d18b8ba6c38975577344b992a4bae14","Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability [6]. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare [1] and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling. As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale [8, 9, 19]. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks. In this tutorial, we will present an overview of model interpretability and explainability in AI [4], key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems [7]. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community. © 2019 Copyright held by the owner/author(s).","2-s2.0-85071169118"
"Djeffal C.","Djeffal, Christian (55972677300)","55972677300","Artificial intelligence and public governance: Normative guidelines for artificial intelligence in government and public administration","2019","Regulating Artificial Intelligence","","","","277","293","16","10.1007/978-3-030-32361-5_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085422637&doi=10.1007%2f978-3-030-32361-5_12&partnerID=40&md5=25e816939ad170623f5692448ed7fc59","This chapter discusses normative guidelines for the use of artificial intelligence in Germany against the backdrop of international debates. Artificial intelligence (AI) is increasingly changing our lives and our social coexistence. AI is a research question and a field of research producing an ever-increasing number of technologies. It is set of technologies that are still evolving. These are driven and influenced by guidelines in the form of laws or strategies. This chapter examines AI systems in public administration and raises the question of what guidelines already exist and what trends are emerging. After defining AI and providing some examples from government and administration, identify ethics and politics as possible points of reference for guidelines. This chapter presents the law, technology, organization, strategy and visions as possible ways to influence and govern AI along with describing current developments. The chapter concludes with a call for interdisciplinary research and moderate regulation of technology in order to enhance its positive potential. © Springer Nature Switzerland AG 2020.","2-s2.0-85085422637"
"Kim J.B.","Kim, Jeong Beom (56716941600)","56716941600","Implementation of artificial intelligence system and traditional system: A comparative study","2019","Journal of System and Management Sciences","9","3","","135","146","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079242536&partnerID=40&md5=095ea5ad689cca9bfd2ab0e5f281403e","The main purpose of this paper is to study about efficient AI project implementation as a case study. For the purpose of successful AI implementation, the project plan should be complete and robust with long term view. The implementation plan includes top management decision, organization and human resource, infra structure for AI system, end user support, and company strategy. The biggest benefits of AI systems are cost reduction, quality improvement, and faster response time. The goal of this study is to provide AI system team members with successful AI project implementation guidelines compared with traditional ones as recommendation. © 2019, Success Culture Press. All rights reserved.","2-s2.0-85079242536"
"Correia A.; Schneider D.; Fonseca B.; Paredes H.","Correia, António (36462301200); Schneider, Daniel (23398339800); Fonseca, Benjamim (34968950600); Paredes, Hugo (23398113700)","36462301200; 23398339800; 34968950600; 23398113700","Crowdsourcing and massively collaborative science: A systematic literature review and mapping study","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11001 LNCS","","","133","154","21","10.1007/978-3-319-99504-5_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053122480&doi=10.1007%2f978-3-319-99504-5_11&partnerID=40&md5=63ab205dc2d9207107447fa0541284da","Current times are denoting unprecedented indicators of scientific data production, and the involvement of the wider public (the crowd) on research has attracted increasing attention. Drawing on review of extant literature, this paper outlines some ways in which crowdsourcing and mass collaboration can leverage the design of intelligent systems to keep pace with the rapid transformation of scientific work. A systematic literature review was performed following the guidelines of evidence-based software engineering and a total of 148 papers were identified as primary after querying digital libraries. From our review, a lack of methodological frameworks and algorithms for enhancing interactive intelligent systems by combining machine and crowd intelligence is clearly manifested and we will need more technical support in the future. We lay out a vision for a cyberinfrastructure that comprises crowd behavior, task features, platform facilities, and integration of human inputs into AI systems. © Springer Nature Switzerland AG 2018.","2-s2.0-85053122480"
"Smith G.","Smith, Gillian (23071941200)","23071941200","Procedural content generation: An overview","2015","Game AI Pro 2: Collected Wisdom of Game AI Professionals","","","","501","518","17","10.1201/b18373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053591096&doi=10.1201%2fb18373&partnerID=40&md5=a443a4528a291b81b49ed00e32dbd090","Procedural content generation (PCG) is the process of using an AI system to author aspects of a game that a human designer would typically be responsible for creating, from textures and natural effects to levels and quests, and even to the game rules themselves. Therefore, the creator of a PCG system is responsible for capturing some aspect of a designer’s expertise-a challenging task for an AI! © 2015 by Taylor & Francis Group, LLC.","2-s2.0-85053591096"
"Eckersley P.","Eckersley, Peter (57044624200)","57044624200","Impossibility and uncertainty theorems in AI value alignment or why your AGI should not have a utility function","2019","CEUR Workshop Proceedings","2301","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060611282&partnerID=40&md5=556a373ca14f2b53146d7d313ba556de","Utility functions or their equivalents (value functions, objective functions, loss functions, reward functions, preference orderings) are a central tool in most current machine learning systems. These mechanisms for defining goals and guiding optimization run into practical and conceptual difficulty when there are independent, multi-dimensional objectives that need to be pursued simultaneously and cannot be reduced to each other. Ethicists have proved several impossibility theorems that stem from this origin; those results appear to show that there is no way of formally specifying what it means for an outcome to be good for a population without violating strong human ethical intuitions (in such cases, the objective function is a social welfare function). We argue that this is a practical problem for any machine learning system (such as medical decision support systems or autonomous weapons) or rigidly rule-based bureaucracy that will make high stakes decisions about human lives: such systems should not use objective functions in the strict mathematical sense. We explore the alternative of using uncertain objectives, represented for instance as partially ordered preferences, or as probability distributions over total orders. We show that previously known impossibility theorems can be transformed into uncertainty theorems in both of those settings, and prove lower bounds on how much uncertainty is implied by the impossibility results. We close by proposing two conjectures about the relationship between uncertainty in objectives and severe unintended consequences from AI systems. © 2019 CEUR-WS. All rights reserved.","2-s2.0-85060611282"
"Schofield M.; Thielscher M.","Schofield, Michael (55445177500); Thielscher, Michael (6701317963)","55445177500; 6701317963","Lifting model sampling for General Game Playing to incomplete-information models","2015","Proceedings of the National Conference on Artificial Intelligence","5","","","3585","3591","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961213433&partnerID=40&md5=c15e7cd054ed9f92e3dd24aa2fe31aa7","General Game Playing is the design of AI systems able to understand the rules of new games and to use such descriptions to play those games effectively. Games with incomplete information have recently been added as a new challenge for general game-playing systems. The only published solutions to this challenge are based on sampling complete information models. In doing so they ground all of the unknown information, thereby making information gathering moves of no value; a well-known criticism of such sampling based systems. We present and analyse a method for escalating reasoning from complete information models to incomplete information models and show how this enables a general game player to correctly value information in incomplete information games. Experimental results demonstrate the success of this technique over standard model sampling. © Copyright 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-84961213433"
"Kim J.M.; Lee S.J.","Kim, Jae Min (57203060061); Lee, Seung Jun (51763897900)","57203060061; 51763897900","Framework to Develop Artificial Intelligent Autonomous Operating System for Nuclear Power Plants","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","10905 LNCS","","","508","517","9","10.1007/978-3-319-92046-7_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050396116&doi=10.1007%2f978-3-319-92046-7_42&partnerID=40&md5=7b2e8b344d08184df7af9b4207812ffe","As artificial intelligent (AI) technology has been dramatically developed, various industries have been challenged to apply it. In a view of nuclear power plants (NPP), it seems that AI technology applies to NPPs at the last because NPPs are required the most stringent level of regulatory guideline for safety. To overcome it, AI technology should be applied incrementally into the NPPs rather than all at once. According to the unintended shutdown records during startup and shutdown operation from 1997 to 2017 in Korea, it is reported that human errors accounts for 40% of the total. This is because operators feel heavy burden to monitor hundreds of parameters for a long time of operating time. Also, there are lots of startup and shutdown operating history that can be used for correcting the data from the NPP simulator. Therefore, this work proposes a framework to develop AI automatic operating system for startup and shutdown operations of NPPs. Operating procedures of startup and shutdown operations are categorized. In addition, AI technologies will be introduced to find out the most suitable learning algorithm. It is expected that economic loss from human error during startup and shutdown operation will be reduced as AI system developed. © Springer International Publishing AG, part of Springer Nature 2018.","2-s2.0-85050396116"
"Cambria E.; Poria S.; Bajpai R.; Schuller B.","Cambria, Erik (56140547500); Poria, Soujanya (55316592700); Bajpai, Rajiv (56875259000); Schuller, Björn (6603767415)","56140547500; 55316592700; 56875259000; 6603767415","SenticNet 4: A semantic resource for sentiment analysis based on conceptual primitives","2016","COLING 2016 - 26th International Conference on Computational Linguistics, Proceedings of COLING 2016: Technical Papers","","","","2666","2677","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046586891&partnerID=40&md5=24955d2efda5f17971a03215a990ee82","An important difference between traditional AI systems and human intelligence is the human ability to harness commonsense knowledge gleaned from a lifetime of learning and experience to make informed decisions. This allows humans to adapt easily to novel situations where AI fails catastrophically due to a lack of situation-specific rules and generalization capabilities. Commonsense knowledge also provides background information that enables humans to successfully operate in social situations where such knowledge is typically assumed. Since commonsense consists of information that humans take for granted, gathering it is an extremely difficult task. Previous versions of SenticNet were focused on collecting this kind of knowledge for sentiment analysis but they were heavily limited by their inability to generalize. SenticNet 4 overcomes such limitations by leveraging on conceptual primitives automatically generated by means of hierarchical clustering and dimensionality reduction. © 1963-2018 ACL.","2-s2.0-85046586891"
"Nauck D.","Nauck, Detlef (57225262950)","57225262950","Responsible ai","2019","Journal of the Institute of Telecommunications Professionals","13","","","14","19","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069503961&partnerID=40&md5=009f2ca05650ea0859741d4b40eee785","Since the Cambridge Analytica case broke, the discussion on how to use Artificial Intelligence (AI) ethically has intensified. Some companies, especially those that are building and selling AI solutions, began publishing guidelines for ethical AI. Microsoft already did so in 2017 [1] while the AI leader Google followed in 2018 [2]. Recently, ethical guidelines have been criticised as vague and unenforceable. The discussion in the AI community is shifting towards how engineering principles can be used to ensure that AI systems are designed and used responsibly. © 2019 Institute of Telecommunications Professionals. All rights reserved.","2-s2.0-85069503961"
"Scholz R.W.; Bartelsman E.J.; Diefenbach S.; Franke L.; Grunwald A.; Helbing D.; Hill R.; Hilty L.; Höjer M.; Klauser S.; Montag C.; Parycek P.; Prote J.P.; Renn O.; Reichel A.; Schuh G.; Steiner G.; Pereira G.V.","Scholz, Roland W. (7202807447); Bartelsman, Eric J. (6603474321); Diefenbach, Sarah (25723185400); Franke, Lude (56310093600); Grunwald, Arnim (7006172361); Helbing, Dirk (7005232363); Hill, Richard (36028080800); Hilty, Lorenz (6602531251); Höjer, Mattias (6603197013); Klauser, Stefan (57202496869); Montag, Christian (23009620300); Parycek, Peter (6506212131); Prote, Jan Philipp (55890597600); Renn, Ortwin (55392453800); Reichel, André (53463981000); Schuh, Günther (7004013060); Steiner, Gerald (57213131334); Pereira, Gabriela Viale (55681618400)","7202807447; 6603474321; 25723185400; 56310093600; 7006172361; 7005232363; 36028080800; 6602531251; 6603197013; 57202496869; 23009620300; 6506212131; 55890597600; 55392453800; 53463981000; 7004013060; 57213131334; 55681618400","Unintended side effects of the digital transition: European scientists' messages from a proposition-based expert round table","2018","Sustainability (Switzerland)","10","6","2001","","","","10.3390/su10062001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048560543&doi=10.3390%2fsu10062001&partnerID=40&md5=aa6a401f4a39f68747149a296d4a1bdf","We present the main messages of a European Expert Round Table (ERT) on the unintended side effects (unseens) of the digital transition. Seventeen experts provided 42 propositions from ten different perspectives as input for the ERT. A full-day ERT deliberated communalities and relationships among these unseens and provided suggestions on (i) what the major unseens are; (ii) how rebound effects of digital transitioning may become the subject of overarching research; and (iii) what unseens should become subjects of transdisciplinary theory and practice processes for developing socially robust orientations. With respect to the latter, the experts suggested that the ""ownership, economic value, use and access of data"" and, related to this, algorithmic decision-making call for transdisciplinary processes that may provide guidelines for key stakeholder groups on how the responsible use of digital data can be developed. A cluster-based content analysis of the propositions, the discussion and inputs of the ERT, and a theoretical analysis of major changes to levels of human systems and the human-environment relationship resulted in the following greater picture: The digital transition calls for redefining economy, labor, democracy, and humanity. Artificial Intelligence (AI)-based machines may take over major domains of human labor, reorganize supply chains, induce platform economics, and reshape the participation of economic actors in the value chain. (Digital) Knowledge and data supplement capital, labor, and natural resources as major economic variables. Digital data and technologies lead to a post-fuel industry (post-) capitalism. Traditional democratic processes can be (intentionally or unintentionally) altered by digital technologies. The unseens in this field call for special attention, research and management. Related to the conditions of ontogenetic and phylogenetic development (humanity), the ubiquitous, global, increasingly AI-shaped interlinkage of almost every human personal, social, and economic activity and the exposure to indirect, digital, artificial, fragmented, electronically mediated data affect behavioral, cognitive, psycho-neuro-endocrinological processes on the level of the individual and thus social relations (of groups and families) and culture, and thereby, the essential quality and character of the human being (i.e., humanity). The findings suggest a need for a new field of research, i.e., focusing on sustainable digital societies and environments, in which the identification, analysis, and management of vulnerabilities and unseens emerging in the sociotechnical digital transition play an important role. © 2018 by the authors.","2-s2.0-85048560543"
"Jain A.; Keller J.; Popescu M.","Jain, Akshay (56704103100); Keller, James (7403486724); Popescu, Mihail (7201384279)","56704103100; 7403486724; 7201384279","Explainable AI for Dataset Comparison","2019","IEEE International Conference on Fuzzy Systems","2019-June","","8858911","","","","10.1109/FUZZ-IEEE.2019.8858911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073793229&doi=10.1109%2fFUZZ-IEEE.2019.8858911&partnerID=40&md5=aad9a966e55b61c67cd7a1dad70f32c9","With the increasing use of intelligent systems to make sense of data, lately, explainable AI systems are gaining a lot of traction. A distance measure that can distinguish data sets in linguistic terms can help AI systems in achieving explainability. We make use of Linguistic Protoform Summaries in tandem with Fuzzy Rules to design a system that can compare datasets numerically, as well as explain the difference in Natural Language. We validate our method with the help of synthetic data and show that it produces high correlation with the well-known Euclidean distance measure. We also employ the proposed method to explain changes in daily pulse rate measurements of an elderly resident living in a sensor equipped smart home. We postulate that the method will help in future endeavors to produce explainable pattern recognition systems. © 2019 IEEE.","2-s2.0-85073793229"
"Satyanarayana V.; Shankar S.; Sruthi V.; Das B.","Satyanarayana, Vibha (57209651866); Shankar, Shruthi (57216152303); Sruthi, V. (57189245735); Das, Bhaskarjyoti (57191032605)","57209651866; 57216152303; 57189245735; 57191032605","A Study of Artificial Social Intelligence in Conversational Agents","2018","Proceedings of the 3rd International Conference on Inventive Computation Technologies, ICICT 2018","","","9034313","545","550","5","10.1109/ICICT43934.2018.9034313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082724318&doi=10.1109%2fICICT43934.2018.9034313&partnerID=40&md5=6cc52ec80c90365a9899ec91ef802257","The main goal of Artificial Intelligence (AI) is to make a machine as intelligent as a human. While AI has advanced significantly over the past years, with its ability surpassing humans in several fields, the one thing that it still lacks is social awareness i.e. have the social skills of a human, a sense of what is appropriate and what isn't and make decisions based on that. These are highly subjective and there is no single set of rules to determine them. With the use of AI increasing at such a high rate that AI has become a part of people's everyday lives it is absolutely necessary for AI systems to know what is socially acceptable. In this paper, we have conducted a thorough and systematic study of the current state of the art for implementing social and emotional intelligence into a conversational agent. © 2018 IEEE.","2-s2.0-85082724318"
"Torabi A.J.; Er M.J.; Li X.; Lim B.S.; Zhai L.; Oentaryo R.J.; Peen G.O.; Zurada J.M.","Torabi, Amin Jahromi (35171837600); Er, Meng Joo (7102842925); Li, Xiang (55718362700); Lim, Beng Siong (14834099500); Zhai, Lianyin (55268123200); Oentaryo, Richard J. (8622959700); Peen, Gan Oon (37013824800); Zurada, Jacek M. (35593077400)","35171837600; 7102842925; 55718362700; 14834099500; 55268123200; 8622959700; 37013824800; 35593077400","A survey on artificial intelligence-based modeling techniques for high speed milling processes","2015","IEEE Systems Journal","9","3","6663603","1069","1080","11","10.1109/JSYST.2013.2282479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027944397&doi=10.1109%2fJSYST.2013.2282479&partnerID=40&md5=c2170330442937ea5dfdd2f82c167298","The process of high speed milling is regarded as one of the most sophisticated and complicated manufacturing operations. In the past four decades, many investigations have been conducted on this process, aiming to better understand its nature and improve the surface quality of the products as well as extending tool life. To achieve these goals, it is necessary to form a general descriptive reference model of the milling process using experimental data, thermomechanical analysis, statistical or artificial intelligence (AI) models. Moreover, increasing demands for more efficient milling processes, qualified surface finishing, and modeling techniques have propelled the development of more effective modeling methods and approaches. In this paper, an extensive literature survey of the state-of-the-art modeling techniques of milling processes will be carried out, more specifically of recent advances and applications of AI-based modeling techniques. The comparative study of the available methods as well as the suitability of each method for corresponding types of experiments will be presented. In addition, the weaknesses of each method as well as open research challenges will be presented. Therefore, a comprehensive comparison of recent developments in the field will be a guideline for choosing the most suitable modeling technique for this process regarding its goals, conditions, and specifications. © 2007-2012 IEEE.","2-s2.0-85027944397"
"Huang Y.-L.; Sun W.-L.; Yeh K.-W.","Huang, Yu-Lun (7501572200); Sun, Wen-Lin (57203641253); Yeh, Kai-Wei (57210205429)","7501572200; 57203641253; 57210205429","MLoC: A Cloud Framework adopting Machine Learning for Industrial Automation","2019","2019 12th Asian Control Conference, ASCC 2019","","","8764986","1413","1418","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069922192&partnerID=40&md5=692f31b47c4e6e73acabcfbb554edf41","By leveraging the modern machine learning algorithms, we can build up more Artificial Intelligence (AI) systems, like self-driving cars, smart factories and financial analysis systems, to improve our daily life. In addition to building up an AI system, several prerequisites are required to drive the system, including data collection, data storage, machine learning models, training dataset, parameters tuning, and so on. To obtain the benefit of scalability and flexibility, most AI systems are built on a cloud platform, which shares resources with others in the same infrastructure. Though the above concept is trivial, the implementation faces big challenges when realizing it. In this paper, an easy-to-use cloud framework for machine learning as well as its implementation guideline is presented for building up a cloud-based development platform. We conduct several experiments on analyzing and monitoring the health condition of bearings of motors. We compare and analyze the feasibility of the proposed framework. © 2019 JSME.","2-s2.0-85069922192"
"Almeida M.; Laskaridis S.; Leontiadis I.; Venieris S.I.; Lane N.D.","Almeida, Mario (55584406900); Laskaridis, Stefanos (57199864065); Leontiadis, Ilias (22938304400); Venieris, Stylianos I. (57188695783); Lane, Nicholas D. (23135333200)","55584406900; 57199864065; 22938304400; 57188695783; 23135333200","EmBench: Quantifying performance variations of deep neural networks across modern commodity devices","2019","EMDL 2019 - Proceedings of the 3rd International Workshop on Deep Learning for Mobile Systems and Applications, co-located with MobiSys 2019","","","","1","6","5","10.1145/3325413.3329793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074469989&doi=10.1145%2f3325413.3329793&partnerID=40&md5=9aa1fa2052623ef40ee19333b25696b0","In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators. © 2019 ACM.","2-s2.0-85074469989"
"Loreggia A.; Mattei N.; Rossi F.; Venable K.B.","Loreggia, Andrea (55960531800); Mattei, Nicholas (35234406800); Rossi, Francesca (56066648900); Venable, K. Brent (13105383400)","55960531800; 35234406800; 56066648900; 13105383400","Metric learning for value alignment","2019","CEUR Workshop Proceedings","2419","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071011100&partnerID=40&md5=9c1e49f47cd12db5db9008ac44a128d8","Preference are central to decision making by both machines and humans. Representing, learning, and reasoning with preferences is an important area of study both within computer science and across the social sciences. When we give our preferences to an AI system we expect the system to make decisions or recommendations that are consistent with our preferences but the decisions should also adhere to certain norms, guidelines, and ethical principles. Hence, when working with preferences it is necessary to understand and compute a metric (distance) between preferences - especially if we encode both the user preferences and ethical systems in the same formalism. In this paper we investigate the use of CP-nets as a formalism for representing orderings over actions for AI systems. We leverage a recently proposed metric for CP-nets and a neural network architecture, CPMETRIC, for computing this metric. Using these two tools we look at the how one can build a fast and flexible value alignment system. © 2019 CEUR-WS. All rights reserved.","2-s2.0-85071011100"
"Jüngling S.; Hofer A.","Jüngling, Stephan (36882543000); Hofer, Angelin (57208512436)","36882543000; 57208512436","Leverage white-collar workers with AI","2019","CEUR Workshop Proceedings","2350","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064966705&partnerID=40&md5=7272bd29074ca3f08c55d9b09b30d0a8","While in the manufacturing industry robots do the majority of the assembly tasks, robotics process automation, where software robots are taking over repetitive tasks from humans have been introduced only recently. Many routine tasks continue to be executed without adequate assistance from tools that would be in reach of the current technical capabilities of AI. Using the example of taking meeting minutes, the paper presents some intermediate results of the capabilities and problems of currently available natural language processing systems to automatically record meeting minutes. It further highlights the potential of optimizing the allocation of tasks between humans and machines to take the particular strengths and weaknesses of both into account. In order to combine the functionality of supervised and unsupervised machine learning with rule-based AI or traditionally programmed software components, the capabilities of AI-based system actors need to be incorporated into the system design process as early as possible. Treating AI as actors enables a more effective allocation of tasks upfront, which makes it easier to come up with a hybrid workplace scenario where AI can support humans in doing their work more efficiently. Copyright held by the author(s).","2-s2.0-85064966705"
"Calimeri F.; Germano S.; Ianni G.; Pacenza F.; Perri S.; Zangari J.","Calimeri, Francesco (8685471300); Germano, Stefano (55886840200); Ianni, Giovambattista (6601981219); Pacenza, Francesco (57203855891); Perri, Simona (8079877900); Zangari, Jessica (56406475500)","8685471300; 55886840200; 6601981219; 57203855891; 8079877900; 56406475500","Integrating rule-based AI tools into mainstream game development","2018","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11092 LNCS","","","310","317","7","10.1007/978-3-319-99906-7_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053190994&doi=10.1007%2f978-3-319-99906-7_23&partnerID=40&md5=f972beed1745283caadf83b51ff5f7d5","Rule-based declarative formalisms enjoy several advantages when compared with imperative solutions, especially when dealing with AI-based application development: solid theoretical bases, no need for algorithm design or coding, explicit and easily modifiable knowledge bases, executable declarative specifications, fast prototyping, quick error detection, modularity. For these reasons, ways for combining declarative paradigms, such as Answer Set Programming (ASP), with traditional ones have been significantly studied in the recent years; there are however relevant contexts, in which this road is unexplored, such as development of real-time games. In such a setting, the strict requirements on reaction times, the presence of computer-human interactivity and a generally increased impedance between the two development paradigms make the task nontrivial. In this work we illustrate how to embed rule-based reasoning modules into the well-known Unity game development engine. To this end, we present an extension of EmbASP, a framework to ease the integration of declarative formalisms with generic applications. We prove the viability of our approach by developing a proof-of-concept Unity game that makes use of ASP-based AI modules. © Springer Nature Switzerland AG 2018.","2-s2.0-85053190994"
"Intal R.C.D.; Dadios E.P.; Fillone A.M.","Intal, Ramon Christhoper Dj. (56771484700); Dadios, Elmer P. (6602629924); Fillone, Alexis M. (39961309200)","56771484700; 6602629924; 39961309200","Software-based bus dispatching system for Epifanio Delos Santos Avenue","2016","8th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management, HNICEM 2015","","","7393238","","","","10.1109/HNICEM.2015.7393238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965098627&doi=10.1109%2fHNICEM.2015.7393238&partnerID=40&md5=d5db73e418aa9c19aa7e0eabd359d867","In this study a Software-based Artificial Intelligence (AI) System and Neural Network (NN) System were combined to achieve a highly responsive and a self-learning machine capable in predicting the dispatch time and scheduling of buses in Epifanio Delos Santos Avenue (EDSA) which is a congested road in Metro Manila. The AI system is a software-based program that can learn through data gathering and use its pre-defined rules. The NN system used the learned data generated by the AI system to do a quick determination of bus schedule. © 2015 IEEE.","2-s2.0-84965098627"
"Wang K.; Dong J.; Wang Y.; Yin H.","Wang, Kai (55712743300); Dong, Jiaqing (56126565500); Wang, Ying (57209645901); Yin, Hao (8314524400)","55712743300; 56126565500; 57209645901; 8314524400","Securing Data with Blockchain and AI","2019","IEEE Access","7","","8733072","77981","77989","8","10.1109/ACCESS.2019.2921555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068340161&doi=10.1109%2fACCESS.2019.2921555&partnerID=40&md5=082b8d9868735ed42c49345eb0e0366a","Data is the input for various artificial intelligence (AI) algorithms to mine valuable features, yet data in Internet is scattered everywhere and controlled by different stakeholders who cannot believe in each other, and usage of the data in complex cyberspace is difficult to authorize or to validate. As a result, it is very difficult to enable data sharing in cyberspace for the real big data, as well as a real powerful AI. In this paper, we propose the SecNet, an architecture that can enable secure data storing, computing, and sharing in the large-scale Internet environment, aiming at a more secure cyberspace with real big data and thus enhanced AI with plenty of data source, by integrating three key components: 1) blockchain-based data sharing with ownership guarantee, which enables trusted data sharing in the large-scale environment to form real big data; 2) AI-based secure computing platform to produce more intelligent security rules, which helps to construct a more trusted cyberspace; 3) trusted value-exchange mechanism for purchasing security service, providing a way for participants to gain economic rewards when giving out their data or service, which promotes the data sharing and thus achieves better performance of AI. Moreover, we discuss the typical use scenario of SecNet as well as its potentially alternative way to deploy, as well as analyze its effectiveness from the aspect of network security and economic revenue. © 2013 IEEE.","2-s2.0-85068340161"
"Crowder J.A.; Carbone J.N.","Crowder, James A. (36700984500); Carbone, John N. (55177224600)","36700984500; 55177224600","Methodologies for continuous life-long machine learning for AI systems","2018","2018 World Congress in Computer Science, Computer Engineering and Applied Computing, CSCE 2018 - Proceedings of the 2018 International Conference on Artificial Intelligence, ICAI 2018","","","","44","50","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068407702&partnerID=40&md5=378c9f121ec3c09a7582f2aa8b2bc430","Current machine learning architectures, strategies, and methods are typically static and non-interactive, making them incapable of adapting to changing and/or heterogeneous data environments, either in real-time, or in near-real-time. Typically, in real-time applications, large amounts of disparate data must be processed, learned from, and actionable intelligence provided in terms of recognition of evolving activities. Applications like Rapid Situational Awareness (RSA) used for support of critical systems (e.g., Battlefield Management and Control) require critical analytical assessment and decision support by automatically processing massive and increasingly amounts of data to provide recognition of evolving events, alerts, and providing actionable intelligence to operators and analysts [2 and 4]. Herein we prescribe potential methods and strategies for continuously adapting, life-long machine learning within a self-learning and self-evaluation environment to enhance real-time/near real-time support for mission critical systems. We describe the notion of continuous adaptation, which requires an augmented paradigm for enhancing traditional probabilistic machine learning. Specifically, systems which must more aptly operate in harsh/soft unknown environments without the need of a priori statistically trained neural networks nor fully developed learning rules for situations that have never been thought of yet. This leads to a hypothesis requiring new machine learning processes, in which abductive learning is applied. We utilize varying unsupervised/self-supervised learning techniques, statistical/fuzzy models for entities, relationships, and descriptor extraction. We also involve topic and group discovery and abductive inference algorithms. to expand system aperture in order to envision what outlying factors could have also caused current observations. Once extended plausible explanations are found, we will show how a system uses the afore mentioned implements to potentially learn about new or modified causal relationships and extend, reinterpret, or create new situational driven memories. CSREA Press ©.","2-s2.0-85068407702"
"HÅkansson A.","HÅkansson, Anne (15055825600)","15055825600","AIC - An AI-system for Combination of senses","2013","Procedia Computer Science","22","","","40","49","9","10.1016/j.procs.2013.09.079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896958303&doi=10.1016%2fj.procs.2013.09.079&partnerID=40&md5=120e22005d63ee77758e8c5af0b1ac93","AI-complete systems developed today, are commonly used for solving different artificial intelligence problems. A problem is a typical image recognition or speech recognition, but it can also be language processing, as well as, other complex systems dealing with general problem solving. However, no AI-complete system, which models the human brain or behavior, can exist without looking at the totality of the whole situation and, and hence, incorporating an AI-computerized sensory systems into a totality that constitute a combination of senses. This paper proposes a combination of sensory systems to form a comprehensive AI-system by combining the different senses, called AIC-AI-system for a combination of senses. The AIC-system is not a complete system in the sense that it contains a total set of information or uses all kinds of digital sensory systems. Nonetheless, it is a system under self-development. It develops its own knowledge base, as experiences, which will be based on the different characteristics: images, sounds, smells, tastes, touches with emotions/feelings and expressions. The result is a kind of perception of the surrounding environment. © 2013 The Authors.","2-s2.0-84896958303"
"Amick T.; Soles L.; Snider D.","Amick, T. (57209639270); Soles, L. (56741346700); Snider, D. (56406967000)","57209639270; 56741346700; 56406967000","Moving towards an adaptive enterprise intrusion detection and prevention system","2019","Proceedings of the 2015 International Conference on Artificial Intelligence, ICAI 2015 - WORLDCOMP 2015","","","","228","231","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068331729&partnerID=40&md5=e7f7e9f268dcde098f94490beaaf99ed","In this paper, we describe our plans to create a smarter network defense system through the collection and analysis of network signatures generated by real security threats. To meet this goal, we plan to create software agents interconnected to a central behavior analysis database service where each software agent records attack meta-information collected during previous intrusion attempts. The central database warehouses and analyzes the meta-information collected by the interconnected agents. The agents can then utilize both instantaneous and historical data by integrating rules derived from the data collection and analysis process into intrusion prevention policies. The result is a modular and scalable network defense system that should be more responsive and adaptable to imminent threats. © 2019 ICAI 2015 - WORLDCOMP 2015. All rights reserved.","2-s2.0-85068331729"
"Kumar V.; Gaur P.; Mittal A.P.","Kumar, Vikas (58787225000); Gaur, Prerna (7003317811); Mittal, A.P. (9335616100)","58787225000; 7003317811; 9335616100","Novel AI based on-line sequential learning technique for high performance DC servo motor control","2015","Control Engineering and Applied Informatics","17","2","","3","11","8","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934285915&partnerID=40&md5=7cc975af5f41767e71a781efc7a5463e","In this paper a neuro-fuzzy based adaptive tracking controller which is trained when the controller is operating in an online mode for high performance DC servo motor control is presented. The proposed structure consists of five layer feed-forward network which is trained using sequential learning method. Extreme Learning Machine (ELM), a recently developed novel method for the training of the single hidden layer feed forward neural networks (SLFNs) is used to initialize the training algorithm with a small chunk of training data. The membership function for each rule is determined using heuristics based methods and the consequent parameters of the Tagaki-Sugeno-Kang (TSK) type fuzzy inference are then determined in an online manner using the recursive least square method. The performance of the proposed technique in terms of the training time, training accuracy for tracking a reference trajectory is evaluated and is compared with the adaptive neuro-fuzzy based controller and other existing faster training algorithms such as ELM. The robustness of the proposed scheme is tested under DC motor parameters variations such as armature resistance, viscous friction and moment of inertia for all implemented controllers. Results obtained ensure the robustness of the proposed controller versus other implemented controllers.","2-s2.0-84934285915"
"Molnár-Gábor F.","Molnár-Gábor, Fruzsina (57190245265)","57190245265","Artificial intelligence in healthcare: Doctors, patients and liabilities","2019","Regulating Artificial Intelligence","","","","337","360","23","10.1007/978-3-030-32361-5_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085440893&doi=10.1007%2f978-3-030-32361-5_15&partnerID=40&md5=98b007066be6db3c881b7b3ef8951d69","AI is increasingly finding its way into medical research and everyday healthcare. However, the clear benefits offered to patients are accompanied not only by general limitations typical of the application of AI systems but also by challenges that specifically characterize the operationalization of the concepts of disease and health. Traditionally, these challenges have been dealt with in the physician-patient relationship in both medical ethics and civil law. The potential for incorrect decisions (and the question of who is responsible for such decisions) in cases where AI is used in a medical context calls for a differentiated implementation of medical ethical principles and a graduated model of liability law. Nevertheless, on closer examination of both fields covering relevant obligations towards patients and users against the backdrop of current medical use cases of AI, it seems that despite a certain level of differentiation in the assignment of responsibilities through rules on liability, those affected, in the end, are generally left to deal with any AI-specific risks and damages on their own. The role played by the physician in all this remains unclear. Taking into account the physician-patient relationship as a contractual obligation in a broad sense can assist in clarifying physicians’ roles and determining their duties in a sustainable and patient-friendly manner when applying AI-based medical systems. This can contribute to reinforcing their established ethical and legal status in the context of AI applications. © Springer Nature Switzerland AG 2020.","2-s2.0-85085440893"
"Ivy B.P.U.","Ivy, B. Persis Urbana (57199218174)","57199218174","Design of real time game system using fuzzy logic","2018","Journal of Advanced Research in Dynamical and Control Systems","10","12 Special Issue","","1076","1079","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081613006&partnerID=40&md5=046d2ffeb8853c5abf5d4580859ee453","This paper proposed the model and execution of a AI system based on real time fuzzy for an bilateral game. This game is a Repair of Pac-Man style game in which competitor select BDI knowledgeable buyers. System parts and schemes applied in fuzzifying game rules and mutable are powwow. Thereto, the proposed fuzzy resolving and are warped between crisp and fuzzy range. © 2018, Institute of Advanced Scientific Research, Inc. All rights reserved.","2-s2.0-85081613006"
"Tsai H.-J.; Lu H.-C.; Wu T.-H.; Lee C.-S.","Tsai, Hsine-Jen (12766297400); Lu, Hao-Chun (30467793700); Wu, Tung-Huan (56963061400); Lee, Chiang-Sheng (26663480100)","12766297400; 30467793700; 56963061400; 26663480100","A comparison of hybrid neural network based breast cancer diagnosis systems","2015","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9191","","","633","639","6","10.1007/978-3-319-20895-4_59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947255337&doi=10.1007%2f978-3-319-20895-4_59&partnerID=40&md5=b6115425cfe6fc93339c0f61508401b1","Breast cancer is the second leading cause of death among the women aged between 40 and 59 in the world. The diagnosis of such disease has been a challenging research problem. With the advancement of artificial intelligence in medical science, numerous AI based breast cancer diagnosis system have been proposed. Many researches combine different algorithms to develop hybrid systems to improve the diagnosis accuracy. In this study, we propose three artificial neural network based hybrid diagnosis systems respectively combining association rule, correlation and genetic algorithm. The effectiveness of these systems is examined on Wisconsin Breast Cancer Dataset. We then compare the accuracy of these three hybrid diagnosis systems. The results indicated that the neural network combining with association rule not only has excellent dimensionality reduction ability but also has the similar accurate prediction with correlation based neural network which has best accurate prediction rate among all three systems compared. © Springer International Publishing Switzerland 2015.","2-s2.0-84947255337"
"Hennemann M.","Hennemann, Moritz (57670259600)","57670259600","Artificial intelligence and competition law","2019","Regulating Artificial Intelligence","","","","361","388","27","10.1007/978-3-030-32361-5_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085460423&doi=10.1007%2f978-3-030-32361-5_16&partnerID=40&md5=4617981fcbbcc0f92c31e93a876da5a9","Artificial Intelligence (AI) is ‘in the air’. The disruptive technologies AI is based on (as well as respective applications) are likely to influence the competition on and for various markets in due course. The handling of opportunities and threats re AI are so far still an open question-and research on the competitive effects of AI has just commenced recently. Statements about AI and the corresponding effects are thereby necessarily only of a temporary nature. From a jurisprudential point of view, it is however important to underline (not only) the framework for AI provided by competition law. On the basis of the 9th amendment of the German Act Against Restraints of Competition (ARC) 2017, German competition law seems to be-to a large extent-adequately prepared for the phenomenon of AI. Nevertheless, considering the characteristics of AI described in this paper, at least the interpretation of German (and European) competition law rules requires an ‘update’. In particular, tacit collusion as well as systematic predispositions of AI applications re market abuse and cartelization analyzed in this paper are to be pictured. Additionally, this paper stresses that further amendments to (European and German) competition law rules should be examined with respect to the liability for AI and law enforcement, whereby the respective effects on innovation and the market themselves will have to be considered carefully. Against this background, this paper argues that strict liability for AI might lead to negative effects on innovation and discusses a limited liability re public sanctions in analogy to intermediary liability concepts developed in tort law, unfair competition law and intellectual property law. Addressing the topic of a ‘legal personality’ for AI-based autonomous systems, this paper finally engages with the consequences of such a status for competition law liability. © Springer Nature Switzerland AG 2020.","2-s2.0-85085460423"
"Rana H.; Rajiv; Lal M.","Rana, Hemant (57217025872); Rajiv (56252163700); Lal, Manohar (55488750600)","57217025872; 56252163700; 55488750600","Rough set based system for effective E-learning","2014","2014 International Conference on Computing for Sustainable Global Development, INDIACom 2014","","","6828126","192","196","4","10.1109/IndiaCom.2014.6828126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903834424&doi=10.1109%2fIndiaCom.2014.6828126&partnerID=40&md5=cc69ef3e2a088582444851b98b1038e4","To achieve intelligence over the web is underlying research topic and continuous efforts have been made in this direction. The results of these efforts in its practical form of applications have been achieved using modern tools & techniques. Artificial Intelligence (AI) has evolved as one of the promising technology for achieving intelligence over web. To facilitate quality education, the identification & selection of various factors that may influence a students' academic performance is very important. Knowing these factors is important for parents & teachers working positively on these factors may improve the performance of the student.. In this paper we propose an approach of decision rule induction to induce knowledge that can facilitate the proper decision making process. The approach for rule induction process is based on AI based rough set theory. The proposed system may be seen as a helping hand to creators of contents, educators and teachers of the course. © 2014 IEEE.","2-s2.0-84903834424"
"Hernández-Orallo J.","Hernández-Orallo, José (6602454434)","6602454434","AI generality and Spearman’s law of diminishing returns","2019","Journal of Artificial Intelligence Research","64","","","529","562","33","10.1613/jair.1.11388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065259456&doi=10.1613%2fjair.1.11388&partnerID=40&md5=a88a27b6dbfedc714717f99ba6b09706","Many areas of AI today use benchmarks and competitions with larger and wider sets of tasks. This tries to deter AI systems (and research effort) from specialising to a single task, and encourage them to be prepared to solve previously unseen tasks. It is unclear, however, whether the methods with best performance are actually those that are most general and, in perspective, whether the trend moves towards more general AI systems. This question has a striking similarity with the analysis of the so-called positive manifold and general factors in the area of human intelligence. In this paper, we first show how the existence of a manifold (positive average pairwise task correlation) can also be analysed in AI, and how this relates to the notion of agent generality, from the individual and the populational points of view. From the populational perspective, we analyse the following question: is this manifold correlation higher for the most or for the least able group of agents? We contrast this analysis with one of the most controversial issues in human intelligence research, the so-called Spearman’s Law of Diminishing Returns (SLODR), which basically states that the relevance of a general factor diminishes for most able human groups. We perform two empirical studies on these issues in AI. We analyse the results of the 2015 general video game AI (GVGAI) competition, with games as tasks and “controllers” as agents, and the results of a synthetic setting, with modified elementary cellular automata (ECA) rules as tasks and simple interactive programs as agents. In both cases, we see that SLODR does not appear. The data, and the use of just two scenarios, does not clearly support the reverse either, a Universal Law of Augmenting Returns (ULOAR), but calls for more experiments on this question. © 2019 AI Access Foundation. All rights reserved.","2-s2.0-85065259456"
"Lewis R.","Lewis, Rory (8866989100)","8866989100","ISR-brain machine intelligence for unmanned aircraft systems","2018","ACM International Conference Proceeding Series","","","","","","","10.1145/3271553.3271594","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058630297&doi=10.1145%2f3271553.3271594&partnerID=40&md5=b6d082fd18d06e7761e9b78a9493d3dd","This paper presents a system for extrapolating knowledge and classification rules from existing ISR FMV and creating an ISRBrain. As combat operations have grown to depend upon assured, live ISR support during operations, US forces are presented with formidable challenges to integrate artificial intelligence (AI) capabilities with existing ISR systems. The common challenge being the variance at which advances in commercial and academic AI are deployed compared to rate of speed that innovative AI systems are developed and utilized in military domains. ISR, USAF and SOCOM need to develop a means to seamlessly integrate military and commercial state-of-the-art systems. The ISR-Brain presented will be capable of converting classifiers in existing ISR FMV to machine learning rules for real time ISR sensor, multi-source, multi-enclave data and adaptable with ongoing research efforts with A2, SOCOM, JIEDO, MITRE and Project MAVEN to develop and test and ISR-Brain to enable the system to integrate with all ISR sensors and predict future Troops in Contact events (TIC) and IED events. © 2018 Association for Computing Machinery.","2-s2.0-85058630297"
"Di Maro M.; Valentino M.; Riccio A.; Origlia A.","Di Maro, Maria (57205469419); Valentino, Marco (57349857200); Riccio, Anna (57349857300); Origlia, Antonio (24605794100)","57205469419; 57349857200; 57349857300; 24605794100","Graph databases for designing high-performance speech recognition grammars","2017","12th International Conference on Computational Semantics, IWCS 2017 - Short Papers","","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067355920&partnerID=40&md5=01ba202fb320b0b93414b82a015a607b","The present paper reports on the advantages of using graph databases in the development of dynamic language models in Spoken Language Understanding applications, such as spoken dialogue systems. First of all, we introduce Neo4J graph databases and, specifically, MultiWordNet-Extended, a graph representing linguistic knowledge. After this first overview, we show how information included in graphs can be used in speech recognition grammars to automatically extend a generic rule structure. This can be the case of linguistic elements, such as synonyms, hypernyms, meronyms and phonological neighbours, which are semantically or structurally related to each other in our mental lexicon. In all the AI based approaches depending on a training process using large and representative corpora, the probability to correctly predict the creativity a speaker can perform in using language and posing questions is lower than expected. Trying to capture most of the possible words and expressions a speaker could use is extremely necessary, but even an empirical, finite collection of cases could not be enough. For this reason, the use of our tool appears as an appealing solution, capable of including many pieces of information. In addition, we used the proposed tool to develop a spoken dialogue system for museums and the preliminary results are shown and discussed in this paper. © IWCS 2017. All rights reserved.","2-s2.0-85067355920"
"Thekkilakattil A.; Dodig-Crnkovic G.","Thekkilakattil, Abhilash (36700536800); Dodig-Crnkovic, Gordana (24452264900)","36700536800; 24452264900","Ethics Aspects of Embedded and Cyber-Physical Systems","2015","Proceedings - International Computer Software and Applications Conference","2","","7273594","39","44","5","10.1109/COMPSAC.2015.41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962148615&doi=10.1109%2fCOMPSAC.2015.41&partnerID=40&md5=314cb0b3413eed2194e30220de4b607a","The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the 'responsibility' of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical 'responsibility' of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities. © 2015 IEEE.","2-s2.0-84962148615"
"Liu F.; Zhang Y.; Shi Y.; Chen Z.; Feng X.","Liu, Fangyao (56118147300); Zhang, Yuejin (43362063400); Shi, Yong (7404963015); Chen, Zhengxin (55754100800); Feng, Xixi (57206844167)","56118147300; 43362063400; 7404963015; 55754100800; 57206844167","Analyzing the Impact of Characteristics on Artificial Intelligence IQ Test: A Fuzzy Cognitive Map Approach","2018","Procedia Computer Science","139","","","82","90","8","10.1016/j.procs.2018.10.221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062032441&doi=10.1016%2fj.procs.2018.10.221&partnerID=40&md5=05f000791eab97a367361032e1a3690c","This research paper we present a Fuzzy Cognitive Map (FCM)-based approach to improving a previously proposed IQ test for Artificial Intelligence (AI) systems. Starting from linguistic terms analyses, fuzzy logic along with triangular membership function is adopted for the defuzzification process. Based on the defuzzification result, a calculated defuzzified value is assigned for the quantitative weights of each edge in the resulting FCM. Mean Square Error (MSE) is used for evaluation. Experiments have shown that the FCM-based approach outperforms other methods (including Delphi weights). © 2018 The Authors. Published by Elsevier B.V.","2-s2.0-85062032441"
"Senatore R.; Cioppa A.D.; Marcelli A.","Senatore, Rosa (36983155800); Cioppa, Antonio Della (57215948865); Marcelli, Angelo (7005267205)","36983155800; 57215948865; 7005267205","Automatic Diagnosis of Neurodegenerative Diseases: An evolutionary approach for facing the interpretability problem","2019","Information (Switzerland)","10","1","30","","","","10.3390/info10010030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063767849&doi=10.3390%2finfo10010030&partnerID=40&md5=7cfd53375cf1df053f325aee39aba8be","Background: The use of Artificial Intelligence (AI) systems for automatic diagnoses is increasingly in the clinical field, being a useful support for the identification of several diseases. Nonetheless, the acceptance of AI-based diagnoses by the physicians is hampered by the black-box approach implemented by most performing systems, which do not clearly state the classification rules adopted. Methods: In this framework we propose a classification method based on a Cartesian Genetic Programming (CGP) approach, which allows for the automatic identification of the presence of the disease, and concurrently, provides the explicit classification model used by the system. Results: The proposed approach has been evaluated on the publicly available HandPD dataset, which contains handwriting samples drawn by Parkinson's disease patients and healthy controls. We show that our approach compares favorably with state-of-the-art methods, and more importantly, allows the physician to identify an explicit model relevant for the diagnosis based on the most informative subset of features. Conclusion: The obtained results suggest that the proposed approach is particularly appealing in that, starting from the explicit model, it allows the physicians to derive a set of guidelines for defining novel testing protocols and intervention strategies. © 2019 by the authors.","2-s2.0-85063767849"
"Han C.; Lee S.-W.; Heo Y.; Kang W.; Jun J.; Zhang B.-T.","Han, C. (57195923239); Lee, Sang-Woo (56025161100); Heo, Yujung (57188995752); Kang, Wooyoung (57195916694); Jun, Jaehyun (57195917955); Zhang, Byoung-Tak (55765845700)","57195923239; 56025161100; 57188995752; 57195916694; 57195917955; 55765845700","Criteria for human-compatible AI in two-player vision-language tasks","2017","CEUR Workshop Proceedings","1926","","","28","33","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030088746&partnerID=40&md5=5a1ac7e25b8c159227c2aa8167ad93a1","We propose rule-based search systems that outperform not only the state-of-the-art but the human performance, measured in accuracy, in Guess- What?!, a vision-language game where either of two players can be a human. Although those systems achieve the high accuracy, they do not meet other requirements to be considered as an AI system that communicates effectively with humans. To clarify what they lack, we suggest the use of three criteria to enable effective communication with humans in vision-language tasks. These criteria also apply to other two-player vision-language tasks that require communication with humans, e.g., ReferIt.","2-s2.0-85030088746"
"Vasconcelos M.; Cardonha C.; Gonçalves B.","Vasconcelos, Marisa (7006465043); Cardonha, Carlos (35191566400); Gonçalves, Bernardo (25654961400)","7006465043; 35191566400; 25654961400","Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions","2018","AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society","","","","323","329","6","10.1145/3278721.3278751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061028426&doi=10.1145%2f3278721.3278751&partnerID=40&md5=d886933656e36500df0d7c5d7caf6a60","Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase. © 2018 ACM.","2-s2.0-85061028426"
"Ford M.; Mallery C.; Palmasani F.; Rabb M.; Turner R.; Soles L.; Snider D.","Ford, Mike (57198113317); Mallery, Cody (57190435302); Palmasani, Frank (57190444163); Rabb, Michael (57190439877); Turner, Reid (57190442149); Soles, Lem (56741346700); Snider, Dallas (56406967000)","57198113317; 57190435302; 57190444163; 57190439877; 57190442149; 56741346700; 56406967000","A process to transfer Fail2ban data to an adaptive enterprise intrusion detection and prevention system","2016","Conference Proceedings - IEEE SOUTHEASTCON","2016-July","","7506771","","","","10.1109/SECON.2016.7506771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980048143&doi=10.1109%2fSECON.2016.7506771&partnerID=40&md5=1012a5cc206a5c705c951d9b59af4b7b","In this paper, we describe a process that has been developed to transfer network intrusion data captured by Fail2ban to an adaptive enterprise intrusion detection and prevention system. The process involves software agents that we have created that are interconnected to a central behavior analysis database service where each software agent records attack meta-information collected during previous intrusion attempts. These distributed agents are the first phase of an overall plan to create a smarter network defense system through the collection and analysis of network signatures generated by real security threats. The central database to which the agents report warehouses and analyzes the meta-information collected by the interconnected agents. The agents can then utilize both instantaneous and historical data by integrating rules derived from the data collection and analysis process into intrusion prevention policies. The final result will be a modular and scalable network defense system that should be more responsive and adaptable to imminent threats. © 2016 IEEE.","2-s2.0-84980048143"
"Dignum V.","Dignum, Virginia (6603389724)","6603389724","Can we build guidelines for trustworthy, ethical AI?","2019","ITU News","2019","3","","57","59","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092057706&partnerID=40&md5=db183350b1d15e75c5d9e3b2cf484671","[No abstract available]","2-s2.0-85092057706"
"Cantone D.; Golińska-Pilarek J.; Nicolosi-Asmundo M.","Cantone, Domenico (55892604800); Golińska-Pilarek, Joanna (15059824200); Nicolosi-Asmundo, Marianna (57219458614)","55892604800; 15059824200; 57219458614","A relational dual tableau decision procedure for multimodal and description logics","2014","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","8480 LNAI","","","466","477","11","10.1007/978-3-319-07617-1_41","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902491376&doi=10.1007%2f978-3-319-07617-1_41&partnerID=40&md5=298870c8bf66925d6c0fc28192a39998","We present a dual tableau based decision procedure for a class of fragments of the classical relational logic of binary relations. The logics considered share a common language involving a restricted composition operator and infinitely many relational constants which may have the properties of reflexivity, transitivity, and heredity. The construction of the dual tableau is carried out by applying in a deterministic way axioms and inference rules of the system without resorting to external tools. An important feature of the dual tableau procedure is a rule to handle the relational composition operator, that permits to decompose in a single step compositional formulae and negative compositional formulae with the same left object variable. Our relational dual tableau can be used as a decision procedure for validity verification in the multimodal logic K, the description logic ALC, and several non-classical logics for reasoning in various AI systems. © 2014 Springer International Publishing.","2-s2.0-84902491376"
"Agostini A.; Alenyà G.; Fischbach A.; Scharr H.; Wörgötter F.; Torras C.","Agostini, Alejandro (24528329400); Alenyà, Guillem (6508265237); Fischbach, Andreas (36797834700); Scharr, Hanno (23393543900); Wörgötter, Florentin (7003438923); Torras, Carme (7003421114)","24528329400; 6508265237; 36797834700; 23393543900; 7003438923; 7003421114","A cognitive architecture for automatic gardening","2017","Computers and Electronics in Agriculture","138","","","69","79","10","10.1016/j.compag.2017.04.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018286068&doi=10.1016%2fj.compag.2017.04.015&partnerID=40&md5=057515b929b1479a51957ed2f8a0f336","In large industrial greenhouses, plants are usually treated following well established protocols for watering, nutrients, and shading/light. While this is practical for the automation of the process, it does not tap the full potential for optimal plant treatment. To more efficiently grow plants, specific treatments according to the plant individual needs should be applied. Experienced human gardeners are very good at treating plants individually. Unfortunately, hiring a crew of gardeners to carry out this task in large greenhouses is not cost effective. In this work we present a cognitive system that integrates artificial intelligence (AI) techniques for decision-making with robotics techniques for sensing and acting to autonomously treat plants using a real-robot platform. Artificial intelligence techniques are used to decide the amount of water and nutrients each plant needs according to the history of the plant. Robotic techniques for sensing measure plant attributes (e.g. leaves) from visual information using 3D model representations. These attributes are used by the AI system to make decisions about the treatment to apply. Acting techniques execute robot movements to supply the plants with the specified amount of water and nutrients. © 2017 Elsevier B.V.","2-s2.0-85018286068"
"Oh S.-Y.","Oh, Sei-Youen (57209827067)","57209827067","A comparative study on ai-based anti-terror crime system","2019","International Journal of Innovative Technology and Exploring Engineering","8","8","","1103","1107","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068846470&partnerID=40&md5=a93329b3ad88d55c1463a94abbbdfc5d","Background/Objectives: Recent terrorisms are not restrained in time and place, but have occurred simultaneously and throughout the world in various ways against random people. Therefore, the research suggests AI-based Anti-terror System module to predict terrorisms in advance, in a response to recognition of severity of the current terrorism state. Methods/Statistical analysis:AI-based Anti-terror System module consists of 6 components - Data Collection and Filtering Module, 1st Analysis of Data and Rule Generation Module, D/B, Monitoring Device, 2nd Analysis of Data and Rule Generation Module and Crime Response Module - more accurate and rapid terror responses is enabled through systematic process of collection, analysis, monitoring, response and feedback on terror-related risk data from each of the modules and devices. Findings: The proposal module collect relevant data to terror suspects with Big Data, analyze the realistically high terror-risk data, but filtered and stored, in two different phases, and generate and modify each rule based on extracted pattern of the analyzed data. Then, consistent monitoring on risky data of probable terrors is performed in concerns of the saved analysis and Crime Response Modules are triggered on the basis of the consequent results.Such a proposal module can improve the accuracy of related date, but save duration time in collection of particular data as it only collects relevant data to terror risks via Big Data Source and Filtering Module compared to the existing module. Furthermore, the operation manuals of 1st/2nd phase Data Analysis Modules systematically analyze the terror risks and probabilities, thus can minimize the risk of actual terrorisms in fields by triggering Terror Crime Response Modules rapidly by phases with an increased terror prediction accuracy. As Monitoring Device is additionally incorporated, constant supervision and feedbacks regarding certain risk data relevant to terrors are enabled - as a result, detailed analysis of high risk data is available. Improvements/Applications: Owing to connections among recent terror groups, terror risks are omnipresent throughout the world and prior data collection for time and patterns of terrors has become difficult, hence the AI-based Anti-terror System Module would allow minimization of consequent terror damages, enabling preliminary terror prevention and rapid crime responses. © BEIESP.","2-s2.0-85068846470"
"Loi D.","Loi, Daria (34971581400)","34971581400","Intelligent, affective systems: Peoples perspective & implications","2018","ACM International Conference Proceeding Series","Part F137694","","","101","104","3","10.1145/3205946.3205962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053661733&doi=10.1145%2f3205946.3205962&partnerID=40&md5=3a5f472cb7f7ecdbfc1893fc1fa128c4","AI-based systems are shifting and will increasingly shift how we relate to content, context and each other. This extended keynote abstract discusses insights from a global study that focused on peoples perceptions, attitudes, thresholds and expectations of intelligent systems as well as their perspectives on smart home, autonomous cars, and smart workspace. Insights helped create ten design guidelines to assist intelligent systems designers, technologists and decision makers. © 2018 Copyright is held by the owner/author(s).","2-s2.0-85053661733"
"Bozdogan D.; Kasap B.; Köse U.","Bozdogan, Derya (55965373900); Kasap, Buket (57195350516); Köse, Utku (36544118500)","55965373900; 57195350516; 36544118500","Design principles for an intelligent-Augmented-Reality-based M-learning application to improve engineering students' English language skills","2018","Virtual and Augmented Reality: Concepts, Methodologies, Tools, and Applications","1","","","378","395","17","10.4018/978-1-5225-5469-1.ch018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046618261&doi=10.4018%2f978-1-5225-5469-1.ch018&partnerID=40&md5=7801a36067b1158bd52229ae7c828d17","Introducing an intelligent augmented reality based M-learning application designed and developed for improving engineering students' English language skills, this chapter reports a work-in-progress that focuses on system design procedure. The application consists of Artificial Intelligence (AI) based functions to ensure an effective learning flow while taking advantages of game-based learning by providing a story board structure with a content tree. Four design principles ""fair use, flexible use, fault tolerance, educational climate"" by Elias in addition to Stockwell and Hubbard's principles for mobile supported language learning have been taken into account. Furthermore, the proposed system here employs an effective approach combining both real and virtual environments to achieve an Augmented Reality based learning experiences for students. After the introduction of the application, the chapter outlines how it will be processed in the future. © 2018, IGI Global.","2-s2.0-85046618261"
"Wang T.; Liaw K.-T.","Wang, Tsaipei (7405565451); Liaw, Keng-Te (56405298100)","7405565451; 56405298100","Driving style imitation in simulated car racing using style evaluators and multi-objective evolution of a fuzzy logic controller","2014","2014 IEEE Conference on Norbert Wiener in the 21st Century: Driving Technology's Future, 21CW 2014 - Incorporating the Proceedings of the 2014 North American Fuzzy Information Processing Society Conference, NAFIPS 2014, Conference Proceedings","","","6893872","","","","10.1109/NORBERT.2014.6893872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908610795&doi=10.1109%2fNORBERT.2014.6893872&partnerID=40&md5=292b83cc1d55d20af6b69b6196f1d3c7","This paper describes a new approach to driving style imitation in simulated car racing games. Our goal is to be able to create non-personal characters (NPCs) that both run competitively and exhibit some driving style traits of the player being imitated. We introduce a style evaluator function that can measure the style similarity between driving records even from different tracks. The effectiveness of such style evaluators are verified using driving records of both NPCs and human players. To build NPC drivers that can imitate particular human players, we use a base driver AI based on a fuzzy logic controller and optimizes its parameters using multi-objective evolution. This is the first work on driver imitation that actually allows several human players to drive in their only natural, not instructed, styles. Our results show evidences that the created imitator NPCs do possess traits of styles of the respective human players being modeled. © 2014 IEEE.","2-s2.0-84908610795"
"Marechal C.; Mikołajewski D.; Tyburek K.; Prokopowicz P.; Bougueroua L.; Ancourt C.; Węgrzyn-Wolska K.","Marechal, Catherine (25928622600); Mikołajewski, Dariusz (36996644200); Tyburek, Krzysztof (25646968600); Prokopowicz, Piotr (36903019100); Bougueroua, Lamine (16177403800); Ancourt, Corinne (6602518710); Węgrzyn-Wolska, Katarzyna (8977389700)","25928622600; 36996644200; 25646968600; 36903019100; 16177403800; 6602518710; 8977389700","Survey on AI-based multimodal methods for emotion detection","2019","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","11400","","","307","324","17","10.1007/978-3-030-16272-6_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063788887&doi=10.1007%2f978-3-030-16272-6_11&partnerID=40&md5=37e1eec11c14ca2ece9022e04094f7a0","Automatic emotion recognition constitutes one of the great challenges providing new tools for more objective and quicker diagnosis, communication and research. Quick and accurate emotion recognition may increase possibilities of computers, robots, and integrated environments to recognize human emotions, and response accordingly to them a social rules. The purpose of this paper is to investigate the possibility of automated emotion representation, recognition and prediction its state-of-the-art and main directions for further research. We focus on the impact of emotion analysis and state of the arts of multimodal emotion detection. We present existing works, possibilities and existing methods to analyze emotion in text, sound, image, video and physiological signals. We also emphasize the most important features for all available emotion recognition modes. Finally, we present the available platform and outlines the existing projects, which deal with multimodal emotion analysis. © The Author(s) 2019.","2-s2.0-85063788887"
"Bozdogan D.; Kasap B.; Kose U.","Bozdogan, Derya (55965373900); Kasap, Buket (57195350516); Kose, Utku (36544118500)","55965373900; 57195350516; 36544118500","Design Principles for an intelligent-augmented-reality-based m-learning application to improve engineering students' English language skills","2018","Intelligent Systems: Concepts, Methodologies, Tools, and Applications","","","","881","899","18","10.4018/978-1-5225-5643-5.ch036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059722223&doi=10.4018%2f978-1-5225-5643-5.ch036&partnerID=40&md5=09d64a918d48ccaa1d3d5b686e725fd7","Introducing an intelligent augmented reality based M-learning application designed and developed for improving engineering students' English language skills, this chapter reports a work-in-progress that focuses on system design procedure. The application consists of Artificial Intelligence (AI) based functions to ensure an effective learning flow while taking advantages of game-based learning by providing a story board structure with a content tree. Four design principles ""fair use, flexible use, fault tolerance, educational climate"" by Elias in addition to Stockwell and Hubbard's principles for mobile supported language learning have been taken into account. Furthermore, the proposed system here employs an effective approach combining both real and virtual environments to achieve an Augmented Reality based learning experiences for students. After the introduction of the application, the chapter outlines how it will be processed in the future. © 2018, IGI Global. All rights reserved.","2-s2.0-85059722223"
"Aljaafreh A.; Al-Oudat N.","Aljaafreh, Ahmad (36095672400); Al-Oudat, Naeem (55191335700)","36095672400; 55191335700","Development of a computer player for seejeh (a.k.a seega, siga, kharbga) board game with deep reinforcement learning","2019","Procedia Computer Science","160","","","241","247","6","10.1016/j.procs.2019.09.463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079103447&doi=10.1016%2fj.procs.2019.09.463&partnerID=40&md5=f699d5a5d07b99e73b9561869b3d286c","Recent years have proven (he existing room of deep reinforcement learning (DRL) applications. DRL has been utilized as an AI computer player in many board games. Seejeh is an ancient board game, where no one attempts to create an AI system that is able to learn to play it. Seejeh is a t\vo-player, zero-sum, discrete, finite and deterministic game of perfect information. Seejeh board game is different from all other strategic board games. It has two stages; Positioning and moving. Player place two tiles at each action in stage one. A player might have a sequence of moves in the second stage unlike Othello and Go. In this work, we develop an automated player based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. This paper presents a self-play algorithm utilizing DRL and search algorithms. The system starts with a neural network that knows nothing about the game of Seejeh. It then plays games against itself, by combining this neural network with powerful search algorithms. To the best of our knowledge, we are the first who develop an agent that learns to play Seejeh game. © 2019 The Authors. Published by Elsevier B.V.","2-s2.0-85079103447"
"Kkhera S.; Kumar K.","Kkhera, Shelej (57204635962); Kumar, Krishan (57225661720)","57204635962; 57225661720","An efficient vertical handoff choice in subsequent generation wireless networks","2018","Proceedings - 2nd International Conference on Intelligent Circuits and Systems, ICICS 2018","","","8479569","201","205","4","10.1109/ICICS.2018.00048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056456848&doi=10.1109%2fICICS.2018.00048&partnerID=40&md5=73ba9fd1b719073452861ba1bc2385f9","Next Generation (4G) wireless networks tend to be diverse, integrating unlike networks to provide constant admission for mobile users with multi mode access potential. The Next creation communications systems are about a worldwide wireless communications system and define a cost efficient, adapted according to the users' needs concept. Within this research paper an efficient vertical handoff conclusion is planned. A refined, intelligent Associative Rule Mining (ARM) and Artificial Intelligence (AI) based technique is mandatory to execute the vertical handoff system in subsequent generation wireless networks to create an valuable service which reduces handoff delay and convolution. © 2018 IEEE.","2-s2.0-85056456848"
"Venu Gopal B.T.; Shivakumar E.G.","Venu Gopal, B.T. (57207911707); Shivakumar, E.G. (6505911229)","57207911707; 6505911229","Design and simulation of neuro-fuzzy controller for indirect vector-controlled induction motor drive","2019","Lecture Notes in Networks and Systems","43","","","155","167","12","10.1007/978-981-13-2514-4_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063237218&doi=10.1007%2f978-981-13-2514-4_14&partnerID=40&md5=c2d23d7c3239b0a25cd03ee5f8816b74","This paper displays a unique adaptable Neuro-Fuzzy Controller (NFC)-based speed control for three-phase induction motor drive. The suggested NFC integrates fuzzy logic idea with a four-layer Artificial Neural Network (ANN). Speed and change in speed are sent as input to Neuro-Fuzzy Controller and it winds up noticeably fit for real-time electromechanical drives. The complete simulation model for indirect vector control of induction motor including the suggested NFC is developed. Induction motor assumes an imperative part in the field of electric drives. Without genuine controlling of the speed, it is difficult to accomplish required errand for specific application. AC motors are solid, less cost, reliable, and maintenance free. In light of absence of capacity of regular control strategies like PID and PI controllers to work in a broad range of operations, AI-based controllers are extensively utilized as a part of the industry like Neural Networks, Fuzzy Logic, and Neuro-Fuzzy controller. The principle issue with the typical fuzzy-based controllers is that the parameters related with the membership functions and the rules depend predominantly on instinct of the specialists, fuzzy logic cannot naturally get the rules utilized for settling on the decision, however, great at clarifying the decision. To overcome from this issue, Neuro-Fuzzy Controller [ability to learn without anyone else alongside decision-making] is recommended. Keeping in mind the end goal to prove the predominance of the proposed Neuro-Fuzzy Controller, the results of the suggested NFC technique is compared with the results of PI controller. NFC-based control of induction motor will end up being more trustworthy than other conventional control techniques. © Springer Nature Singapore Pte Ltd 2019.","2-s2.0-85063237218"
"Morocho Cayamcela M.E.; Lim W.","Morocho Cayamcela, Manuel Eugenio (57202499664); Lim, Wansu (26326390400)","57202499664; 26326390400","Artificial Intelligence in 5G Technology: A Survey","2018","9th International Conference on Information and Communication Technology Convergence: ICT Convergence Powered by Smart Intelligence, ICTC 2018","","","8539642","860","865","5","10.1109/ICTC.2018.8539642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059447427&doi=10.1109%2fICTC.2018.8539642&partnerID=40&md5=6b73635c9afc6a29f4d403f7d07f3775","A fully operative and efficient 5G network cannot be complete without the inclusion of artificial intelligence (AI) routines. Existing 4G networks with all-IP (Internet Protocol) broadband connectivity are based on a reactive conception, leading to a poorly efficiency of the spectrum. AI and its subcategories like machine learning and deep learning have been evolving as a discipline, to the point that nowadays this mechanism allows fifth-generation (5G) wireless networks to be predictive and proactive, which is essential in making the 5G vision conceivable. This paper is motivated by the vision of intelligent base stations making decisions by themselves, mobile devices creating dynamically-adaptable clusters based on learned data rather than pre-established and fixed rules, that will take us to a improve in the efficiency, latency, and reliability of the current and real-time network applications in general. An exploration of the potential of AI-based solution approaches in the context of 5G mobile and wireless communications technology is presented, evaluating the different challenges and open issues for future research. © 2018 IEEE.","2-s2.0-85059447427"
"Wang Y.; Friyia D.; Liu K.; Cohen R.","Wang, Yetian (57195534486); Friyia, Daniel (57200374960); Liu, Kanzhe (57222388993); Cohen, Robin (7404158300)","57195534486; 57200374960; 57222388993; 7404158300","An architecture for a military AI system with ethical rules","2018","AAAI Spring Symposium - Technical Report","2018-March","","","81","87","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075482965&partnerID=40&md5=68394d9cc91ebeaf83fb64d57afb431c","The current era of computer science has seen a significant increase in the application of machine learning (ML) and knowledge representation (KR). The problem with the current situation regarding ethics and AI is the weaknesses of ML and KR when used separately. ML will “learn” ethical behaviour as it is observed and may therefore disagree with human morals. On the other hand, KR is too rigid and can only process scenarios that have been predefined. This paper proposes a solution to the question posed by Rossi (2016) “How to combine bottom-up learning approaches with top-down rule-based approaches in defining ethical principles for AI systems?” This system focuses on potential unethical behaviors that are caused by human nature instead of ethical dilemmas caused by technology insufficiency in the wartime scenarios. Our solution is an architecture that combines a classifier to identify targets in wartime scenarios and a rules-based system in the form of ontologies to guide an AI agent’s behaviour in the given circumstance. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85075482965"
"Sun R.; Lian Z.; Tang Y.; Xiao J.","Sun, Rongju (56404995000); Lian, Zhouhui (23493219700); Tang, Yingmin (36609495000); Xiao, Jianguo (35520554800)","56404995000; 23493219700; 36609495000; 35520554800","Aesthetic visual quality evaluation of Chinese handwritings","2015","IJCAI International Joint Conference on Artificial Intelligence","2015-January","","","2510","2516","6","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949811371&partnerID=40&md5=8e6cba0e647d8cf12e05b517d71bc208","Aesthetic evaluation of Chinese calligraphy is one of the most challenging tasks in Artificial Intelligence. This paper attempts to solve this problem by proposing a number of aesthetic feature representations and feeding them into Artificial Neural Networks. Specifically, 22 global shape features are presented to describe a given handwritten Chinese character from different aspects according to classical calligraphic rules, and a new 10-dimensional feature vector is introduced to represent the component layout information using sparse coding. Moreover, a Chinese Handwriting Aesthetic Evaluation Database (CHAED) is also built by collecting 1000 Chinese handwriting images with diverse aesthetic qualities and inviting 33 subjects to evaluate the aesthetic quality for each calligraphic image. Finally, back propagation neural networks are constructed with the concatenation of the proposed features as input and then trained on our CHAED database for the aesthetic evaluation of Chinese calligraphy. Experimental results demonstrate that the proposed AI system provides a comparable performance with human evaluation. Through our experiments, we also compare the importance of each individual feature and reveal the relationship between our aesthetic features and the aesthetic perceptions of human beings.","2-s2.0-84949811371"
"Ozatay M.; Aygun L.; Jia H.; Kumar P.; Mehlman Y.; Wu C.; Wagner S.; Sturm J.C.; Verma N.","Ozatay, M. (57202379820); Aygun, L. (54901766600); Jia, H. (57195607152); Kumar, P. (57203982192); Mehlman, Y. (57195433782); Wu, C. (57195353135); Wagner, S. (7402231247); Sturm, J.C. (7202194762); Verma, N. (8590063100)","57202379820; 54901766600; 57195607152; 57203982192; 57195433782; 57195353135; 7402231247; 7202194762; 8590063100","Artificial intelligence meets large-scale sensing: Using Large-Area Electronics (LAE) to enable intelligent spaces","2018","2018 IEEE Custom Integrated Circuits Conference, CICC 2018","","","","1","8","7","10.1109/CICC.2018.8357031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048143986&doi=10.1109%2fCICC.2018.8357031&partnerID=40&md5=9df49644bc4c8733f909c216c23c56fb","The tremendous value artificial intelligence (AI) is showing across a broad range of applications is driving it from cyber-systems to systems pervading every aspect of our lives. But real-world data challenges the efficiency and robustness with which AI systems of today can perform, due to the highly dynamic and noisy scenarios they face. While algorithmic solutions are required, this paper also explores technological solutions based on large-scale sensing. Specifically, Large-Area Electronics (LAE) is a technology that can make large-scale, form-fitting sensors possible for broad deployment in our lives. System-design principles, architectural approaches, supporting circuits, and underlying technological concerns surrounding LAE and its use in emerging systems for intelligent sensing are explored. © 2018 IEEE.","2-s2.0-85048143986"
"Hadfield-Menell D.; Andrus M.; Hadfield G.K.","Hadfield-Menell, Dylan (55921863400); Andrus, McKane (57210419060); Hadfield, Gillian K. (7003546468)","55921863400; 57210419060; 7003546468","Legible normativity for AI alignment: The value of silly rules","2019","AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society","","","","115","121","6","10.1145/3306618.3314258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070575562&doi=10.1145%2f3306618.3314258&partnerID=40&md5=92c8e4221a77dce15edc1cd8da3cb11b","It has become commonplace to assert that autonomous agents will have to be built to follow human rules of behavior-social norms and laws. But human laws and norms are complex and culturally varied systems; in many cases agents will have to learn the rules. This requires autonomous agents to have models of how human rule systems work so that they can make reliable predictions about rules. In this paper we contribute to the building of such models by analyzing an overlooked distinction between important rules and what we call silly rules -rules with no discernible direct impact on welfare. We show that silly rules render a normative system both more robust and more adaptable in response to shocks to perceived stability. They make normativity more legible for humans, and can increase legibility for AI systems as well. For AI systems to integrate into human normative systems, we suggest, it may be important for them to have models that include representations of silly rules. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2-s2.0-85070575562"
"Mesentier Silva F.D.; Lee S.; Togelius J.; Nealen A.","Mesentier Silva, Fernando De (57193644149); Lee, Scott (57194773771); Togelius, Julian (55918891800); Nealen, Andy (10141261500)","57193644149; 57194773771; 55918891800; 10141261500","AI-based playtesting of contemporary board games","2017","ACM International Conference Proceeding Series","Part F130151","","A13","","","","10.1145/3102071.3102105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030788695&doi=10.1145%2f3102071.3102105&partnerID=40&md5=e3c4cf4b61241d8720d2097f043845b7","Ticket to Ride is a popular contemporary board game for two to four players, featuring a number of expansions with additional maps and tweaks to the core game mechanics. In this paper, four different game-playing agents that embody different playing styles are defined and used to analyze Ticket to Ride. Different playing styles are shown to be effective depending on the map and rule variation, and also depending on how many players play the game. The performance profiles of the different agents can be used to characterize maps and identify the most similar maps in the space of playstyles. Further analysis of the automatically played games reveal which cities on the map are most desirable, and that the relative attractiveness of cities is remarkably consistent across numbers of players. Finally, the automated analysis also reveals two classes of failures states, where the agents find states which are not covered by the game rules; this is akin to finding bugs in the rules. We see the analysis performed here as a possible template for AI-based playtesting of contemporary board games. © 2017 ACM.","2-s2.0-85030788695"
"Patel R.N.; Barot M.P.","Patel, Rachit N. (57215808312); Barot, Mehul P. (57205579153)","57215808312; 57205579153","Development Of Methodology for Precise Diagnosis of ECG By Artificial Intelligent","2019","Proceedings of 2019 3rd IEEE International Conference on Electrical, Computer and Communication Technologies, ICECCT 2019","","","8869413","","","","10.1109/ICECCT.2019.8869413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074338896&doi=10.1109%2fICECCT.2019.8869413&partnerID=40&md5=f26f89965b113c0d4954e31a9b46a4d6","Implementation of Artificial Intelligence in medical diagnosis is a subject of intense study in nowadays. One of the current interests of developing an Artificial Intelligent is to develop an AI system for diagnosis of heart disease from Electrocardiogram (ECG). Few AI programs have also been developed for ECG diagnosis system, but most of them are based on pattern comparison algorithm which can never achieve the sufficient precision and accuracy for diagnosis task. To eliminate these deficiencies, this paper proposes a new methodology that makes AI system more capable for ECG diagnosis. The proposed methodology and design for AI diagnosis system is based on the statistical analysis of ECG and implementation of standard ECG Interpretation Principles for diagnosis of cardiac arrhythmias. This method is completely knowledge based and it applies the same methods and rules of cardiology which are implemented by a medical expert (cardiologist) to make a report of patient's ECG. The proposed methodology also provides an ability of self learning to AI system in order to utilize the experiences in further diagnosis service. © 2019 IEEE.","2-s2.0-85074338896"
"Oudah M.; Rahwan T.; Crandall T.; Crandall J.W.","Oudah, Mayada (56809270600); Rahwan, Talal (10239828100); Crandall, Tawna (57205542278); Crandall, Jacob W. (7004904337)","56809270600; 10239828100; 57205542278; 7004904337","How AI wins friends and influences people in repeated games with cheap talk","2018","32nd AAAI Conference on Artificial Intelligence, AAAI 2018","","","","1519","1526","7","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060483661&partnerID=40&md5=c7065e806e1946cccb3b09f560c8414f","Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as “if you can't say something nice, don't say anything at all” and principles articulated in Carnegie's classic How to Win Friends and Influence People, offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","2-s2.0-85060483661"
"Ghosh A.; Huang S.","Ghosh, Aritra (57209815110); Huang, Shihong (8290713300)","57209815110; 8290713300","Cooperative Traffic Control where Autonomous Cars Meet Human Drivers","2019","Conference Proceedings - IEEE SOUTHEASTCON","2019-April","","9020663","","","","10.1109/SoutheastCon42311.2019.9020663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082386850&doi=10.1109%2fSoutheastCon42311.2019.9020663&partnerID=40&md5=7e132ede55c41d192c414fe2a84f4293","Co-adaptive system is a close coupling between human and software system cooperating to achieve shared goals. This co-adaption requires adaptive actions to react to unpredictable circumstances. One of the challenges is to deal with uncertainties, and consequently, decision making under uncertainty, which may arise because of the change in the environment, the unpredictable resources, etc. Human behavior does contribute to large amounts of uncertainty. This paper presents an approach for using a simulator as a means of feedback to a human's decision under uncertainty that can assist human in automated planning to generate cooperative and symbiotic strategy of human and the system to achieve given tasks. To validate the approach, this paper presents a customizable traffic simulator to measure the delays associated with passing vehicles through intersections. The simulator contains AI-based self-adaptive vehicles which can evaluate the quality of traffic at an intersection and change their driving behavior. The human operator from the outside of the system can manipulate the signaling time, the number of predicates per driving rule, number of rules per rule set, learning factor (adaption) etc. to overcome any unexpected traffic. This research proves that our simulator is more efficient than the individual human-operated and automated traffic system and makes a true cooperative traffic example. © 2019 IEEE.","2-s2.0-85082386850"
