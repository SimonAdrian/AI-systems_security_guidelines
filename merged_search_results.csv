"","","","","","keywords","ACM"
"Artificial Intelligence in HCI: Second International Conference, AI-HCI 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings","Human-centred artificial intelligence is a fast-growing research stream within the artificial intelligence (AI) and human–computer interaction (HCI) communities. One key focus of this stream is the enablement of trust between end users and the intelligent solution. Although, the current body of literature discusses and proposes a range of best practices for the design of user interfaces for intelligent solutions, there is a dearth of research how such interfaces are perceived by users and especially focusing on trust in these interfaces. In this paper, we investigate how the Big Five personality traits affect trust in AI-enabled user interfaces. We then experimentally verify which design best practices and guidelines proposed by Google enable trust in AI-enabled user interfaces for the different personality types. Initial results (n ","10.1007/978-3-030-77772-2_1","Conference","2021","keywords","ACM"
"Artificial Intelligence  in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium: 23rd International Conference, AIED 2022, Durham, UK, July 27–31, 2022, Proceedings, Part II","How do you advance the science and engineering of digital learning solutions at your institution, business, or organization? Bring your current ways of working to this tutorial and get ready to innovate them alongside your fellow researchers, practitioners, business owners, and policy makers. As we work together to share our knowledge and lived experiences, presenters will assist participants in co-creating action plans for how they can utilize best practices from user-centered design (UCD), Design thinking, and Agile to deliver user-obsessed, AI-enabled, efficacious learning solutions.","10.1007/978-3-031-11647-6_21","Conference","2022","keywords","ACM"
"Radiomics and Radiogenomics in Neuro-Oncology: First International Workshop, RNO-AI 2019, Held in Conjunction with MICCAI 2019, Shenzhen, China, October 13, 2019, Proceedings","Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistance in diagnosis of cancer, planning of treatment strategy, and prediction of survival. Radiomics in neuro-oncology has progressed significantly in the recent past. Deep learning has outperformed conventional machine learning methods in most image-based applications. Convolutional neural networks (CNNs) have seen some popularity in radiomics, since they do not require hand-crafted features and can automatically extract features during the learning process. In this regard, it is observed that CNN based radiomics could provide state-of-the-art results in neuro-oncology, similar to the recent success of such methods in a wide spectrum of medical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology.","10.1007/978-3-030-40124-5_3","Conference","2019","keywords","ACM"
"Product-Focused Software Process Improvement: 23rd International Conference, PROFES 2022, Jyv\""{a}skyl\""{a","Many modern software products embed AI components. As a result, their development requires multidisciplinary teams with diverse skill sets. Diversity may lead to communication issues or misapplication of best practices. Process models, which prescribe how software should be developed within an organization, can alleviate this problem. In this paper, we introduce a domain-specific language for modeling AI engineering processes. The DSL concepts stem from our analysis of scientific and gray literature that describes how teams are developing AI-based software. This DSL contributes a structured framework and a common ground for designing, enacting and automating AI engineering processes.","10.1007/978-3-031-21388-5_4","Conference","2022","keywords","ACM"
"Proceedings of the 1st ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence","We aimed to assess the reliability of teaching Artificial Intelligencefor Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements.We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.","10.1145/3340435.3342718","Conference","2019","keywords","ACM"
"Requirements practices and gaps when engineering human-centered Artificial Intelligence systems","","10.1016/j.asoc.2023.110421","Journal","2023","keywords","ACM"
"Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance","The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.","10.1145/3494193.3494260","Conference","2022","keywords","ACM"
"Companion Proceedings of the 28th International Conference on Intelligent User Interfaces","The right to obtain an explanation of the decision reached by an Artificial Intelligence&nbsp;(AI) model is now an EU regulation. Different stakeholders of an AI system&nbsp;(e.g. managers, developers, auditors, etc.) may have different background knowledge, competencies and goals, thus requiring different kinds of interpretations and explanations. Fortunately, there is a growing armoury of tools to interpret ML models and explain their predictions, recommendations and diagnoses which we will refer to collectively as explanation strategies. As these explanation strategies mature, practitioners will gain experience that helps them know which strategies to deploy in different circumstances. What is lacking, and is addressed by iSee, is capturing, sharing and re-using explanation strategies based on past positive experiences. The goal of the iSee platform is to improve every user’s experience of AI, by harnessing experiences and best practices in Explainable AI.","10.1145/3581754.3584137","Conference","2023","keywords","ACM"
"Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering","Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The Responsible AI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and responsible-AI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement responsible AI.","10.1145/3626234","Journal","2023","keywords","ACM"
"Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02","The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the ""responsibility"" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical ""responsibility"" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities.","10.1109/COMPSAC.2015.41","Conference","2015","keywords","ACM"
"Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice","Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.","10.1109/ICSE-SEIP.2019.00042","Conference","2019","keywords","ACM"
"Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2–6, 2023, Proceedings, Part II","Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors’ posts on the Internet. Research on ID becomes important when authors’ written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author’s post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit “r/AmItheAsshole” as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach. ()","10.1007/978-3-031-28238-6_22","Conference","2023","keywords","ACM"
"Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020","Motivated by the Foreword of Licklider's ""Libraries of the Future"" (dedicated to Vannevar Bush), this keynote focuses on users, exploration, and future directions of the digital library (DL) field, which moves toward procognitive systems. Many different digital library ""users,"" each a member of a Society, engage in a diversity of Scenarios, often involving some aspect of exploration, usually of the DL content Streams. Services -- e.g., searching, browsing, recommending, and visualizing -- help those users leverage knowledge Structures and Spatial representations. Following on the final sentence of Licklider's book, we ""call for a formal base plus an overlay of experience, "" leading to a new way to build better DLs. Licklider said we seek ""the facts, concepts, principles, and ideas that lie behind the visible and tangible aspects of documents,"" to help us acquire and use knowledge. Put simply: ""The console of the procognitive system will have two special buttons, a silver one labeled 'Where am I"" and a gold one labeled 'What should I do next?' ""How can we build and use this?For more than 55 years, researchers have applied artificial intelligence (AI), natural language processing (NLP), representations (data, information, knowledge), question-answering, databases, human-computer interaction, and other techniques described by Licklider, to these challenges. We have a vast range of hardware and software services available, but without a more formal approach, will not enable adaptive self-organization and tailored exploration.The 5S framework can help us build, apply, and improve digital libraries to facilitate exploration, through a formal approach that will simplify such efforts, making them extensible through both human and computing agents. For example, to more easily build DLs, we propose collaboratively building knowledge graphs -- involving both User eXperience designers, subject matter experts, and developers -- that specify connections to services and workflows, enabling DL operation atop a workflow engine. User exploration, additional help by UX designers, recommendations of adaptations of existing workflows, and AI-based optimizations and solutions to new problems, will all expand the knowledge graph to ensure new and more helpful assistance.When this is accomplished, we must teach and learn about this next generation of digital libraries, further developing suitable curriculum and educational modules, that rest upon a solid theoretical foundation, helping spread understanding of key concepts and best practices.","10.1145/3383583.3398496","Conference","2020","keywords","ACM"
"Proceedings of the 26th International Academic Mindtrek Conference","This workshop is designed to facilitate an exploration of collaborative methodologies from both academia and industry practice to advance insight into the emergent problem space of designing AI-enabled information systems. The recent developments and implementations of AI-enabled technologies have seen a parallel proliferation of practical approaches to ensure human-centred and ethical design principles are imbedded into AI development which has largely been in response to widespread industry criticism of unethical practices and unintended negative consequences of ‘black box’ algorithmic decision making. Our prototype design cards and collaborative design process are targeted at current problems and limitations with intelligent human-machine systems that can be averted with more inclusive collaboration with users as stakeholders in system design. Our intention is to refine our AI design methodology and design cards over several international workshops and to provide them to the public as a free open-source tool for AI researchers and practitioners.","10.1145/3616961.3616969","Conference","2023","keywords","ACM"
"The Role of Digital Technologies in Shaping the Post-Pandemic World: 21st IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2022, Newcastle upon Tyne, UK, September 13–14, 2022, Proceedings","AI applications are increasing in the field of education, from laboratory set-ups to contemporary and complex learning systems. A great example of such systems is AI-enabled adaptive learning systems (AI-ALS) that promote adaptive learning. Despite its promised potential, there are challenges such as design issues, highly complex models, and lack of evidence-based guidelines and design principles that hinder the large-scale adoption and implementation of AI-ALS. The goal of this paper thus is to establish a set of empirically grounded design principles (DPs) of AI-ALS, that would serve well in a university context. 22 interviews were con-ducted with experts knowledgeable about the design and development of AI-ALS. Several rounds of coding and deep analysis of the expert interviews revealed features and functionalities of AI-ALS; purposes for designing and using AI-ALS; and recommended improvements for AI-ALS as requirements. These requirements were translated to 13 preliminary DPs. The findings of this study serve as a guide on how to better design AI-ALS, that will improve the learning experiences of students.","10.1007/978-3-031-15342-6_7","Conference","2022","keywords","ACM"
"Integrating AI ethics in wildlife conservation AI systems in South Africa: a review, challenges, and future research agenda","With the increased use of Artificial Intelligence (AI) in wildlife conservation, issues around whether AI-based monitoring tools in wildlife conservation comply with standards regarding AI Ethics are on the rise. This review aims to summarise current debates and identify gaps as well as suggest future research by investigating (1) current AI Ethics and AI Ethics issues in wildlife conservation, (2) Initiatives Stakeholders in AI for wildlife conservation should consider integrating AI Ethics in wildlife conservation. We find that the existing literature weakly focuses on AI Ethics and AI Ethics in wildlife conservation while at the same time ignores AI Ethics integration in AI systems for wildlife conservation. This paper formulates an ethically aligned AI system framework and discusses pre-eminent on-demand AI systems in wildlife conservation. The proposed framework uses agile software life cycle methodology to implement guidelines towards the ethical upgrade of any existing AI system or the development of any new ethically aligned AI system. The guidelines enforce, among others, the minimisation of intentional harm and bias, diversity in data collection, design compliance, auditing of all activities in the framework and ease of code inspection. This framework will inform AI developers, users, conservationists, and policymakers on what to consider when integrating AI Ethics into AI-based systems for wildlife conservation.","10.1007/s00146-021-01285-y","Journal","2021","keywords","ACM"
"Design Science Research for a New Society: Society 5.0: 18th International Conference on Design Science Research in Information Systems and Technology, DESRIST 2023, Pretoria, South Africa, May 31 – June 2, 2023, Proceedings","Future healthcare ecosystems integrating human-centered artificial intelligence (AI) will be indispensable. AI-based healthcare technologies can support diagnosis processes and make healthcare more accessible globally. In this context, we conducted a design science research project intending to introduce design principles for user interfaces (UIs) of explainable AI-based (XAI) medical decision support systems (XAI-based MDSS). We used an archaeological approach to analyze the UI of an existing web-based system in the context of skin lesion classification called DIAnA (Dermatological Images – Analysis and Archiving). One of DIAnA’s unique characteristics is that it should be usable for the stakeholder groups of physicians and patients. We conducted the in-situ analysis with these stakeholders using the think-aloud method and semi-structured interviews. We anchored our interview guide in concepts of the Theory of Interactive Media Effects (TIME), which formulates UI features as causes and user psychology as effects. Based on the results, we derived 20 design requirements and developed nine design principles grounded in TIME for this class of XAI-based MDSS, either associated with the needs of physicians, patients, or both. Regarding evaluation, we first conducted semi-structured interviews with software developers to assess the reusability of our design principles. Afterward, we conducted a survey with user experience/interface designers. The evaluation uncovered that 77% of the participants would adopt the design principles, and 82% would recommend them to colleagues for a suitable project. The findings prove the reusability of the design principles and highlight a positive perception by potential implementers.","10.1007/978-3-031-32808-4_7","Conference","2023","keywords","ACM"
"Designing Transparency for Effective Human-AI Collaboration","The field of artificial intelligence (AI) is advancing quickly, and systems can increasingly perform a multitude of tasks that previously required human intelligence. Information systems can facilitate collaboration between humans and AI systems such that their individual capabilities complement each other. However, there is a lack of consolidated design guidelines for information systems facilitating the collaboration between humans and AI systems. This work examines how agent transparency affects trust and task outcomes in the context of human-AI collaboration. Drawing on the 3-Gap framework, we study agent transparency as a means to reduce the information asymmetry between humans and the AI. Following the Design Science Research paradigm, we formulate testable propositions, derive design requirements, and synthesize design principles. We instantiate two design principles as design features of an information system utilized in the hospitality industry. Further, we conduct two case studies to evaluate the effects of agent transparency: We find that trust increases when the AI system provides information on its reasoning, while trust decreases when the AI system provides information on sources of uncertainty. Additionally, we observe that agent transparency improves task outcomes as it enhances the accuracy of judgemental forecast adjustments.","10.1007/s10796-022-10284-3","Journal","2022","keywords","ACM"
"Artificial Intelligence in HCI: 4th International Conference, AI-HCI 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part I","AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing.","10.1007/978-3-031-35891-3_8","Conference","2023","keywords","ACM"
"Predicting regulatory activities for socially shared regulation to optimize collaborative learning","","10.1016/j.chb.2023.107737","Journal","2023","keywords","ACM"
"Intelligent Human Computer Interaction: 13th International Conference, IHCI 2021, Kent, OH, USA, December 20–22, 2021, Revised Selected Papers","As artificial intelligence (AI) is applied at an increasing frequency in various fields, the number of studies on the user experience (UX) design of human-AI interaction is also increasing. However, the results of these studies on AI UX design principles are insufficient for actual AI systems. In light of this fact, the purpose of this study was to upgrade the UX design of a defense system that uses AI technology to detect land changes and targets. In order to upgrade the UX design of this AI system, a three-step procedure was executed. First, AI UX principles were derived by analyzing literature related to human-AI interaction. Second, ideation was performed to improve the interface. Finally, the results of the ideation were utilized to construct the UX prototype of the AI system with Adobe XD. The results of this study are expected to be used as fundamental data for future research that will develop UX principles and advanced methods for AI systems.","10.1007/978-3-030-98404-5_23","Conference","2021","keywords","ACM"
"Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems","User interface (UI) and user experience (UX) design have become an indispensable part of today’s tech industry. Recently, much progress has been made in machine-learning-enabled design support tools for UX designers. However, few of these tools have been adopted by practitioners. To learn the underlying reasons and understand user needs for bridging this gap, we conducted a retrospective analysis with 8 UX professionals to understand their practice and identify opportunities for future research. We found that the current AI-enabled systems to support UX work mainly work on graphical interface elements, while design activities that involve more ‘design thinking” such as user interviews and user testings are more helpful for designers. Many current systems were also designed for overly-simplistic and generic use scenarios. We identified 4 areas in the UX workflow that can benefit from additional AI-enabled assistance: design inspiration search, design alternative exploration, design system customization, and design guideline violation check.","10.1145/3491101.3519809","Conference","2022","keywords","ACM"
"AI-Enabled Cybersecurity Analytics: Detecting and Defending against Cyber Threats","Cyber attacks are estimated to cost the global economy $6 trillion annually by 2021. To combat these attacks, many cybersecurity organizations rely on manual cyber threat detection and mitigation approaches for cyber defense. However, the fast-paced nature of the cyber threat landscape and the sheer volume of the data preclude effective cyber defense via manual approaches or ad-hoc software programs. Artificial Intelligence (AI)-enabled cybersecurity is an emerging approach that draws upon statistical and machine learning theories to yield AI agents that address this issue. These agents can automatically conduct cyber defense operations at a large scale, provide predictive insights in complex tasks, and improve incident response. Consequently, major cybersecurity analytics firms are increasingly incorporating AI agents into their cyber defense fabric. Despite their promise, AI agents are vulnerable to adversarial attacks from AI-enabled adversaries. These adversarial attacks incur damage by automatically generating malicious input data that misleads these AI agents. Given the societal impact of AI-enabled cybersecurity and the crucial need for resistant cybersecurity AI agents, this dissertation presents six essays to contribute to two broad aspects of AI-enabled cybersecurity: AI agents for cybersecurity – designing AI agents to automate detecting cyber threats (three essays), and (2) security of AI agents – designing AI agents for defending against adversarial attacks (three essays). To make concrete contributions to cyber defense, each of these aspects is focused on a high-impact cybersecurity application domain. The first aspect concerns dark web analytics – focusing on cyber threat detection in international hidden anonymous platforms. The second area focuses on malware analytics – targeting the robustness of malware detectors against adversarial attacks. The essays follow design science guidelines to draw on statistical machine learning theories to develop Information Technology (IT) artifacts that address cybersecurity research inquiries via novel designs that enhance IS (information systems) knowledge base. Each proposed design also contributes to the state-of-the-art in the reference discipline (i.e., statistical machine learning) via one or more novel algorithms in transductive learning, transfer learning, adversarial learning, and reinforcement learning theory. Essays I-III are dedicated to AI for cybersecurity. Specifically, Essay I offers a cybersecurity AI agent to identify key cyber threats in English dark net markets using transductive learning. Essay II generalizes the first essay to a multilingual setting for detecting cyber threats within the international dark web using transfer and adversarial learning. Essay III extends the second essay from text to image analytics in illegal e-commerce markets by presenting a more general framework leveraging adversarial kernel learning and deep dictionary learning. Essays IV-VI target the security of AI agents. Specifically, Essay IV focuses on a high-impact application of AI for improving the security of AI-enabled malware detectors as the first line of defense in cybersecurity. Essay V generalizes Essay IV to improve the robustness of any cybersecurity AI agent against adversarial attacks via reinforcement learning (RL) and robust optimization theory. Finally, Essay VI offers a generalized approach to defend against adversarial attacks based on sequential decision making and learning action representations in RL to minimize reliance on insider knowledge about the attack target.","","Thesis","2021","keywords","ACM"
"Augmented Reality and Artificial Intelligence in industry: Trends, tools, and future challenges","","10.1016/j.eswa.2022.118002","Journal","2022","keywords","ACM"
"Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems","Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.","10.1145/3544548.3580900","Conference","2023","keywords","ACM"
"Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society","In the current climate of shrinking newsrooms and revenues, journalists face increasing pressures exerted by the industry’s for-profit focus and the expectation of intensified output. While AI-enabled journalism has great potential to help alleviate journalists’ pressures, it might also disrupt journalistic norms and, at worst, interfere with their duty to inform the public. For AI systems to be as useful as possible, designers should understand journalists’ professional values and incorporate them into their designs. We report findings from interviews with journalists to understand their perceptions of how professional values that are important to them (such as truth, impartiality and originality) might be supported and/or undermined by AI technologies. Based on these findings, we provide design insight and guidelines for incorporating values into the design of AI systems. We argue HCI design can achieve the strongest possible value alignment by moving beyond merely supporting important values, to truly embodying them.","10.1145/3419249.3420105","Conference","2020","keywords","ACM"
"The 3rd International Workshop on Deep Learning for Mobile Systems and Applications","In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators.","10.1145/3325413.3329793","Conference","2019","keywords","ACM"
"Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety","AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.","10.1109/MIC.2022.3182349","Journal","2022","keywords","ACM"
"Transparency-Check: An Instrument for the Study and Design of Transparency in AI-based Personalization Systems","As AI-based systems become commonplace in our daily lives, they need to provide understandable information to their users about how they collect, process, and output information that concerns them. The importance of such transparency practices has gained significance due to recent ethical guidelines and regulation, as well as research suggesting a positive relationship between the transparency of AI-based systems and users’ satisfaction. This paper provides a new tool for the design and study of transparency in AI-based systems that use personalization. The tool, called Transparency-Check, is based on a checklist of questions about transparency in four areas of a system: input (data collection), processing (algorithmic models), output (personalized recommendations) and user control (user feedback mechanisms to adjust elements of the system). Transparency-Check can be used by researchers, designers, and end users of computer systems. To demonstrate the usefulness of Transparency-Check from a researcher perspective, we collected the responses of 108 student participants who used the transparency checklist to rate five popular real-world systems (Amazon, Facebook, Netflix, Spotify, and YouTube). Based on users’ subjective evaluations, the systems showed low compliance with transparency standards, with some nuances about individual categories (specifically data collection, processing, user control). We use these results to compile design recommendations for improving transparency in AI-based systems, such as integrating information about the system’s behavior during the user’s interactions with it.","10.1145/3636508","Journal","2023","keywords","ACM"
"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","Qualitative research can produce a rich understanding of a phenomenon but requires an essential and strenuous data annotation process known as coding. Coding can be repetitive and time-consuming, particularly for large datasets. Existing AI-based approaches for partially automating coding, like supervised machine learning (ML) or explicit knowledge represented in code rules, require high technical literacy and lack transparency. Further, little is known about the interaction of researchers with AI-based coding assistance. We introduce Cody, an AI-based system that semi-automates coding through code rules and supervised ML. Cody supports researchers with interactively (re)defining code rules and uses ML to extend coding to unseen data. In two studies with qualitative researchers, we found that (1) code rules provide structure and transparency, (2) explanations are commonly desired but rarely used, (3) suggestions benefit coding quality rather than coding speed, increasing the intercoder reliability, calculated with Krippendorff’s Alpha, from 0.085 (MAXQDA) to 0.33 (Cody).","10.1145/3411764.3445591","Conference","2021","keywords","ACM"
"Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI","High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.","10.1145/3522664.3528590","Conference","2022","keywords","ACM"
"Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining","The potential for AI technologies to enhance human capabilities and improve our lives is of little debate; yet, neither is their potential to cause harm and social disruption. While preventing or minimizing AI biases and harms is justifiably the subject of intense study in academic, industrial and even legal communities, an approach centered on acknowledging and planning for AI-based failures has the potential to shed new light on how to develop and deploy responsible AI-based systems.In this talk, I will discuss the sociotechnical nature of several inherent and unavoidable AI failures and why it is important for the industry to systematically and proactively identify, assess, and mitigate harms caused by such failures in our AI-based products and services. I will then present Microsoft's recently released Guidelines for Human-AI Interaction and how we've been using them at Microsoft to help teams think through and prepare for different types of AI failures.","10.1145/3394486.3409557","Conference","2020","keywords","ACM"
"Requirements engineering framework for human-centered artificial intelligence software systems","","10.1016/j.asoc.2023.110455","Journal","2023","keywords","ACM"
"Toward an Intelligent Edge: Wireless Communication Meets Machine Learning","The recent revival of AI is revolutionizing almost every branch of science and technology. Given the ubiquitous smart mobile gadgets and IoT devices, it is expected that a majority of intelligent applications will be deployed at the edge of wireless networks. This trend has generated strong interest in realizing an ""intelligent edge"" to support AI-enabled applications at various edge devices. Accordingly, a new research area, called edge learning, has emerged, which crosses and revolutionizes two disciplines: wireless communication and machine learning. A major theme in edge learning is to overcome the limited computing power, as well as limited data, at each edge device. This is accomplished by leveraging the mobile edge computing platform and exploiting the massive data distributed over a large number of edge devices. In such systems, learning from distributed data and communicating between the edge server and devices are two critical and coupled aspects, and their fusion poses many new research challenges. This article advocates a new set of design guidelines for wireless communication in edge learning, collectively called learning- driven communication. Illustrative examples are provided to demonstrate the effectiveness of these design guidelines. Unique research opportunities are identified.","10.1109/MCOM.001.1900103","Journal","2020","keywords","ACM"
"Proceedings of the Eighteenth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment","We present Loose Ends, a mixed-initiative co-creative storytelling play experience in which a human player and an AI system work together to compose a story. Loose Ends specifically aims to provide computational support for managing multiple parallel plot threads and bringing these threads to satisfying conclusions—something that has proven difficult in past attempts to facilitate playful mixed-initiative storytelling. We describe the overall human-AI interaction loop in Loose Ends, including the implementation of the rules-based AI system that enables this interaction loop; discuss four examples of desirable mixed-initiative interactions that are possible in Loose Ends, but not in similar systems; and present results from a preliminary expert evaluation of Loose Ends. Altogether, we find that Loose Ends shows promise for creating a sense of coauthorship in the player while also mitigating the directionlessness reported by players of earlier systems.","10.1609/aiide.v18i1.21955","Conference","2022","keywords","ACM"
"Machine Learning and Knowledge Extraction: 7th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2023, Benevento, Italy, August 29 – September 1, 2023, Proceedings","With the deployment of applications based on machine learning techniques the need for understandable explanations of these systems’ results becomes evident. This paper clarifies the concept of an “explanation”: the main goal of an explanation is to build trust in the recipient of the explanation. This can only be achieved by creating an understanding of the results of the AI systems in terms of the users’ domain knowledge. In contrast to most of the approaches found in the literature, which base the explanation of the AI system’s results on the model provided by the machine learning algorithm, this paper tries to find an explanation in the specific expert knowledge of the system’s users. The domain knowledge is defined as a formal model derived from a set of if-then-rules provided by experts. The result from the AI system is represented as a proposition in a temporal logic. Now we attempt to formally prove this proposition within the domain model. We use model checking algorithms and tools for this purpose. If the proof is successful, the result of the AI system is consistent with the model of the domain knowledge. The model contains the rules it is based on and hence the path representing the proof can be translated back to the rules: this explains, why the proposition is consistent with the domain knowledge. The paper describes the application of this approach to a real world example from meteorology, the short-term forecasting of cloud coverage for particular locations.","10.1007/978-3-031-40837-3_11","Conference","2023","keywords","ACM"
"Meaningful Explanation Effect on User’s Trust in an AI Medical System: Designing Explanations for Non-Expert Users","Whereas most research in AI system explanation for healthcare applications looks at developing algorithmic explanations targeted at AI experts or medical professionals, the question we raise is: How do we build meaningful explanations for laypeople? And how does a meaningful explanation affect user’s trust perceptions? Our research investigates how the key factors affecting human-AI trust change in the light of human expertise, and how to design explanations specifically targeted at non-experts. By means of a stage-based design method, we map the ways laypeople understand AI explanations in a User Explanation Model. We also map both medical professionals and AI experts’ practice in an Expert Explanation Model. A Target Explanation Model is then proposed, which represents how experts’ practice and layperson’s understanding can be combined to design meaningful explanations. Design guidelines for meaningful AI explanations are proposed, and a prototype of AI system explanation for non-expert users in a breast cancer scenario is presented and assessed on how it affect users’ trust perceptions.","10.1145/3631614","Journal","2023","keywords","ACM"
"Development of an automated combined positive score prediction pipeline using artificial intelligence on multiplexed immunofluorescence images","","10.1016/j.compbiomed.2022.106337","Journal","2023","keywords","ACM"
"Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering","Society’s increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.","10.1145/3593434.3593453","Conference","2023","keywords","ACM"
"A review of artificial intelligence methods for engineering prognostics and health management with implementation guidelines","The past decade has witnessed the adoption of artificial intelligence (AI) in various applications. It is of no exception in the area of prognostics and health management (PHM) where the capacity of AI has been highlighted through numerous studies. In this paper, we present a comprehensive review of AI-based solutions in engineering PHM. This review serves as a guideline for researchers and practitioners with varying levels of experience seeking to broaden their know-how about AI-based PHM. Specifically, we provide both a broad quantitative analysis and a comprehensive qualitative examination of the roles of AI in PHM. The quantitative analysis offers an insight into the research community’s interest in AI-based approaches, focusing on the evolution of research trends and their developments in different PHM application areas. The qualitative survey gives a complete picture on the employment of AI in each stage of the PHM process, from data preparation to decision support. Based on the strengths and weaknesses of existing methods, we derive a general guideline for choosing proper techniques for each specific PHM task, aiming to level up maintenance practitioners’ efficiency in implementing PHM solutions. Finally, the review discusses challenges and future research directions in the development of autonomous intelligent PHM solutions.","10.1007/s10462-022-10260-y","Journal","2022","keywords","ACM"
"Proceedings of the 32nd ACM International Conference on Information and Knowledge Management","Improving logistics efficiency is a challenging task in logistic systems, since planning the vehicle routes highly relies on the changing traffic conditions and diverse demand scenarios. However, most existing approaches either neglect the dynamic traffic environment or adopt manually designed rules, which fails to efficiently find a high-quality routing strategy. In this paper, we present a novel artificial intelligence (AI) based framework for logistic systems. This framework can simulate the spatio-temporal traffic conditions to form a dynamic environment in a data-driven manner. Under such a simulated environment, it adopts deep reinforcement learning techniques to intelligently generate the optimized routing strategy. Meanwhile, we also design an interactive frontend to visualize the simulated environment and routing strategies, which help operators evaluate the task performance. We will showcase the results of AI-based simulation and optimization in our demonstration.","10.1145/3583780.3614732","Conference","2023","keywords","ACM"
"Smart Health: Intelligent Healthcare Systems in the Metaverse, Artificial Intelligence, and Data Science Era","In recent decades, healthcare organizations around the world have increasingly appreciated the value of information technologies for a variety of applications. Three of the new technological advancements that are impacting smart health are metaverse, artificial intelligence (AI), and data science. The metaverse is the intersection of three major technologies — AI, augmented reality (AR), and virtual reality (VR). Metaverse provides new possibilities and potential that are still emerging. The increased work efficiency enabled by artificial intelligence and data science in hospitals not only improves patient care but also cuts costs and workload for healthcare providers. Artificial intelligence, coupled with machine learning, is transforming the healthcare industry. The availability of big data enables data scientists to use the data for descriptive, predictive, and prescriptive analytics. This article reviews multiple case studies and the literature on AI and data science applications in hospital administration. The article also presents unresolved research questions and challenges in the applications of the metaverse, AI, and data science in the smart health context. For researchers, in addition to providing a good synopsis of the development and applications of the metaverse, AI, and data science in the healthcare area, this article identifies possible future research directions and discusses the possibilities of the metaverse, artificial intelligence, and data science in smart health. For practitioners, this article provides both hospital decision-makers and healthcare workers with practical guidelines and a smart health management model.","10.4018/JOEUC.308814","Journal","2022","keywords","ACM"
"HCI International 2022 – Late Breaking Papers: Interacting with EXtended Reality and Artificial Intelligence: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, June 26 – July 1, 2022, Proceedings","Research within AI-based Industry 4.0 (I4.0) work systems has predominantly focused on technical and process performance, while human and psychosocial factors are rarely examined. These factors must be considered to design human-centred systems that cultivate sustainable human-AI interaction, i.e., human-AI interaction that promotes long-term well-being, engagement, and performance. The European Commission has brought forward a new vision of I4.0 called Industry 5.0, where well-being and technological advancement are jointly considered, thus overcoming the weaknesses of I4.0. To move forward with Industry 5.0, it is necessary to consolidate our knowledge of human-technology interaction within I4.0. This systematic review aims to uncover the antecedents and consequences of human and psychosocial factors within AI-based I4.0 systems, with an end goal of providing guidelines for the sustainable design, implementation, and use of these systems. This protocol presents the background and the methodology behind our review, as well as preliminary results and expected contributions.","10.1007/978-3-031-21707-4_34","Conference","2022","keywords","ACM"
"A survey on artificial intelligence techniques for security event correlation: models, challenges, and opportunities","Information systems need to process a large amount of event monitoring data. The process of finding the relationships between events is called correlation, which creates a context between independent events and previously collected information in real time and normalizes it for subsequent processing. In cybersecurity, events can determine the steps of attackers and can be analyzed as part of a specific attack strategy. In this survey, we present the systematization of security event correlation models in terms of their representation in AI-based monitoring systems as: rule-based, semantic, graphical and machine learning based-models. We define the main directions of current research in the field of AI-based security event correlation and the methods used for the correlation of both single events and their sequences in attack scenarios. We also describe the prospects for the development of hybrid correlation models. In conclusion, we identify the existing problems in the field and possible ways to overcome them.","10.1007/s10462-022-10381-4","Journal","2023","keywords","ACM"
"2022 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.","10.1109/FUZZ-IEEE55066.2022.9882675","Conference","2022","keywords","ACM"
"Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society","As of 2021, there were more than 170 guidelines on AI ethics and responsible, trustworthy AI in circulation according to the AI Ethics Guidelines Global Inventory maintained by AlgorithmWatch, an organisation which tracks the effects of increased digitalisation on everyday lives. However, from the perspective of day-to-day work, for those engaged in designing, developing, and maintaining AI systems identifying relevant guidelines and translating them into practice presents a challenge.The aim of this paper is to help anyone engaged in building a responsible AI system by identifying an indicative long-list of potential stakeholders. This list of impacted stakeholders is intended to enable such AI system builders to decide which guidelines are most suited to their practice. The paper draws on a literature review of articles short-listed based on searches conducted in the ACM Digital Library and Google Scholar. The findings are based on content analysis of the short-listed literature guided by probes which draw on the ISO 26000:2010 Guidance on social responsibility.The paper identifies three levels of potentially relevant stakeholders when responsible AI systems are considered: individual stakeholders (including users, developers, and researchers), organisational stakeholders, and national / international stakeholders engaged in making laws, rules, and regulations. The main intended audience for this paper is software, requirements, and product engineers engaged in building AI systems. In addition, business executives, policy makers, legal/regulatory experts, AI researchers, public, private, and third sector organisations developing responsible AI guidelines, and anyone interested in seeing functional responsible AI systems are the other intended audience for this paper.","10.1145/3514094.3534187","Conference","2022","keywords","ACM"
"Artificial intelligence implication on energy sustainability in Internet of Things: A survey","","10.1016/j.ipm.2022.103212","Journal","2023","keywords","ACM"
"Augmenting Medical Diagnosis Decisions? An Investigation into Physicians’ Decision-Making Process with Artificial Intelligence","Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions, but they are not without errors and biases. Failure to detect those may result in wrong diagnoses and medical errors. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Thus, it is difficult, yet critical, for physicians to carefully evaluate AI advice. This study uncovers the cognitive challenges that medical decision makers face when they receive potentially incorrect advice from AI-based diagnosis systems and must decide whether to follow or reject it. In experiments with 68 novice and 12 experienced physicians, novice physicians with and without clinical experience as well as experienced radiologists made more inaccurate diagnosis decisions when provided with incorrect AI advice than without advice at all. We elicit five decision-making patterns and show that wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial evaluation of the AI advice. Our study has implications for the training of physicians and spotlights the crucial role of human actors in compensating for AI errors.Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Much research currently aims to improve AI technologies and debates their societal implications. Surprisingly little effort is spent on understanding the cognitive challenges of decision augmentation with AI-based systems although these systems make it more difficult for decision makers to evaluate the correctness of system advice and to decide whether to reject or accept it. As little is known about the cognitive mechanisms that underlie such evaluations, we take an inductive approach to understand how AI advice influences physicians’ decision-making process. We conducted experiments with a total of 68 novice and 12 experienced physicians who diagnosed patient cases with an AI-based system that provided both correct and incorrect advice. Based on qualitative data from think-aloud protocols, interviews, and questionnaires, we elicit five decision-making patterns and develop a process model of medical diagnosis decision augmentation with AI advice. We show that physicians use second-order cognitive processes, namely metacognitions, to monitor and control their reasoning while assessing AI advice. These metacognitions determine whether physicians are able to reap the full benefits of AI or not. Specifically, wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers’ own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial information search. Our findings provide a first perspective on the metacognitive mechanisms that decision makers use to evaluate system advice. Overall, our study sheds light on an overlooked facet of decision augmentation with AI, namely, the crucial role of human actors in compensating for technological errors.","10.1287/isre.2020.0980","Journal","2021","keywords","ACM"
"Proceedings of the 12th Indian Conference on Human-Computer Interaction","Voice-based discussion forums where users can record audio messages which are then published for other users to listen and comment, are often moderated to ensure that the published audios are of good quality, relevant, and adhere to editorial guidelines of the forum. There is room for the introduction of AI-based tools in the moderation process, such as to identify and filter out blank or noisy audios, use speech recognition to transcribe the voice messages in text, and use natural language processing techniques to extract relevant metadata from the audio transcripts. We design such tools and deploy them within a social enterprise working in India that runs several voice-based discussion forums. We present our findings in terms of the time and cost-savings made through the introduction of these tools, and describe the feedback of the moderators towards the acceptability of AI-based automation in their workflow. Our work forms a case-study in the use of AI for automation of several routine tasks, and can be especially relevant for other researchers and practitioners involved with the use of voice-based technologies in developing regions of the world.","10.1145/3506469.3506473","Conference","2022","keywords","ACM"
"2021 IEEE International Symposium on Technology and Society (ISTAS)","By 2030, forecasts suggest that urban areas will house 60 percent of the world’s population and one in every three people will live in cities with at least half a million inhabitants. Within the same time frame, the number of global megacities is expected to jump from 33 today to 43 in 2030 [1]. Underpinning these large urban areas will be an interconnected network of critical physical infrastructures reliant on Internet-connected Industrial Control Systems and susceptible to increasingly sophisticated, e.g., AI-enabled, cyber threats. In hand, the cyber threat landscape is shifting rapidly. We are seeing a sharp rise in the number of cyberattacks on critical infrastructure [2] with significant impacts cascading across multiple sectors and causing disruption to the provisioning of essential goods and services. Security scholars suggest that these impacts are not always equitable and that disruption to critical infrastructure can affect vulnerable groups differently [3], which further emphasizes the need to improve cybersecurity between critical infrastructure sectors [4]. Through structured analysis of city statistics, demographic information, cyber incidents, and current cyber policy, our presentation will articulate potential social implications of megacity growth through the lens of cyber-physical infrastructure disruption. We investigate the largest 15 megacities in the world and find that megacities continue to grow in population but not in cyber policy. We highlight recent examples of cyber-physical disruption in Mumbai and New York City with focus on implications for vulnerable populations. Our work suggests the need for future research on social responsibility regarding security of these critical infrastructure sectors and on the need for technology-focused law, policy, and regulation guidelines.","10.1109/ISTAS52410.2021.9629170","Conference","2021","keywords","ACM"
"Artificial Intelligence techniques applied as estimator in chemical process systems - A literature survey","Intensive review of AI applied as estimators in chemical process systems.Provide guidelines to select and design AI-based estimators.Discussed the advantages, limitations and compare each algorithm.Future suggestions and directions of the research. The versatility of Artificial Intelligence (AI) in process systems is not restricted to modelling and control only, but also as estimators to estimate the unmeasured parameters as an alternative to the conventional observers and hardware sensors. These estimators, also known as software sensors have been successfully applied in many chemical process systems such as reactors, distillation columns, and heat exchanger due to their robustness, simple formulation, adaptation capabilities and minimum modelling requirements for the design. However, the various types of AI methods available make it difficult to decide on the most suitable algorithm to be applied for any particular system. Hence, in this paper, we provide a broad literature survey of several AI algorithms implemented as estimators in chemical systems together with their advantages, limitations, practical implications and comparisons between one another to guide researchers in selecting and designing the AI-based estimators. Future research suggestions and directions in improvising and extending the usage of these estimators in various chemical operating units are also presented.","10.1016/j.eswa.2015.03.023","Journal","2015","keywords","ACM"
"Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island","","10.1016/j.csi.2019.103361","Journal","2019","keywords","ACM"
"Proceedings of the 4th International Conference on Human-Computer Interaction and User Experience in Indonesia, CHIuXiD '18","AI-based systems are shifting and will increasingly shift how we relate to content, context and each other. This extended keynote abstract discusses insights from a global study that focused on people's perceptions, attitudes, thresholds and expectations of intelligent systems as well as their perspectives on smart home, autonomous cars, and smart workspace. Insights helped create ten design guidelines to assist intelligent systems designers, technologists and decision makers.","10.1145/3205946.3205962","Conference","2018","keywords","ACM"
"Companion Publication of the 2019 Conference on Computer Supported Cooperative Work and Social Computing","In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development.","10.1145/3311957.3361858","Conference","2019","keywords","ACM"
"Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security","In Autonomous Driving (AD) systems, perception is both security and safety-critical. Among different attacks on AD perception, object-hiding adversarial attack is one of the most critical ones due to the direct impact on safety-critical driving decisions such as collision avoidance. However, all of the prior works on physical object-hiding adversarial attacks only study the security of the AI component alone rather than with the entire AD system pipeline with closed-loop control. This thus inevitably raises a critical research question: can these prior works actually achieve system-level effects (e.g., vehicle collisions, traffic rule violation) under real-world AD settings with closed-loop control?To answer this critical question, in this work we take the necessary first step by performing the first measurement study on whether and how effective the existing designs can lead to system-level effects. Our early results find that RP2 and FTE, as two representative examples of prior works, cannot achieve any system-level effect in a representative closed-loop AD setup in common STOP sign-controlled road speeds. In the future, we plan to 1) perform a more comprehensive measurement study using both simulated environments and a real vehicle-sized AD R&amp;D chassis; and 2) analyze the measurement study results and explore new attack designs that can better achieve the system-level effect in AD systems.","10.1145/3548606.3563539","Conference","2022","keywords","ACM"
"Following the Path of Small and Medium-Sized Medical Technology Startups Seeking Funding Before FDA Clearance","There is a problem for medical technology startups in the US with obtaining funding for the regulation of new medical devices before FDA clearance. The selection criteria identified small and medium medical device companies (SMMDCs) in the top 15 cities for the medical technology industry excluding non-US SMMDCs. Limited responses required secondary data to supplement the interviews conducted. The application of a semi-structure interview allowed a comprehensive data analysis with only three participants. While consensus was observed for all participants regarding the FDA's cybersecurity program with the FDA' medical device breakthrough, the sample size was small which required approval for modifying the study by the Northcentral University' Institutional Review Board. Thus, secondary data was acquired from the SMMDC' websites as press releases, newswires, and branding of a combination medical device. The CEO and decision maker of several SMMDCs depended also on the Securities Exchange Commission's (SEC) EDGAR search engine to identify Form D document, rule 506 (b and c) for private placement. Recommendations for practice is the integration of primary and secondary data with NVivo version 12 software. The thematic analysis indicated two and three-word group associations to infer as saturation and triangulation respectively. Recommendations for future research were telehealth with artificial intelligence (AI), augmented reality (AR), three-dimensional (3-D) Printing, and Blockchain technology a qualitative management system for a combination medical device. Finally, a coalition model addressed technological innovation diffusion with business incubators and accelerators relative to government and non-governmental organizations. Crunchbase, as an accelerator portal, identified SMMDC's pre seed and seed capital for early-stage funding under $1-3 million and late-stage funding for Series A and Series B funding as $20 - $50 million to avoid the valley of death and for expansion and growth.","","Thesis","2022","keywords","ACM"
"HCI in Business, Government and Organizations: 7th International Conference, HCIBGO 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings","The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N ","10.1007/978-3-030-50341-3_32","Conference","2020","keywords","ACM"
"Ethics in the Age of AI: An Analysis of AI Practitioners’ Awareness and Challenges","Ethics in AI has become a debated topic of public and expert discourse in recent years. But what do people who build AI – AI practitioners – have to say about their understanding of AI ethics and the challenges associated with incorporating it into the AI-based systems they develop? Understanding AI practitioners’ views on AI ethics is important as they are the ones closest to the AI systems and can bring about changes and improvements. We conducted a survey aimed at understanding AI practitioners’ awareness of AI ethics and their challenges in incorporating ethics. Based on 100 AI practitioners’ responses, our findings indicate that the majority of AI practitioners had a reasonable familiarity with the concept of AI ethics, primarily due to workplace rules and policies. Privacy protection and security was the ethical principle that the majority of them were aware of. Formal education/training was considered somewhat helpful in preparing practitioners to incorporate AI ethics. The challenges that AI practitioners faced in the development of ethical AI-based systems included (i) general challenges, (ii) technology-related challenges, and (iii) human-related challenges. We also identified areas needing further investigation and provided recommendations to assist AI practitioners and companies in incorporating ethics into AI development.","10.1145/3635715","Journal","2023","keywords","ACM"
"Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency","Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and widespread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them---and who is not---are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.","10.1145/3351095.3375784","Conference","2020","keywords","ACM"
"Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining","With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.","10.1145/3447548.3470823","Conference","2021","keywords","ACM"
"Frontiers in Handwriting Recognition: 18th International Conference, ICFHR 2022, Hyderabad, India, December 4–7, 2022, Proceedings","What makes a handwriting good? If the aesthetic judgment of handwriting follows implicit rules, can those rules be recovered by observing good and bad examples? To answer these questions, we apply explainability techniques to the classification of good and bad handwriting. We show that it is indeed possible to recover these inherent rules. We develop an AI system that uses a modified version of LIME Image Explainer and generates images containing suggestions for improvement. We use single-character and word-level datasets labelled with binary labels generated via accepted rules for handwriting classification. We discuss the possible improvements to the current system as well as where this research could be applied, such as user-specific auto-suggestions.","10.1007/978-3-031-21648-0_23","Conference","2022","keywords","ACM"
"A compositional approach to creating architecture frameworks with an application to distributed AI systems","","10.1016/j.jss.2022.111604","Journal","2023","keywords","ACM"
"Machine Learning and Image Processing for Clinical Outcome Prediction: Applications in Medical Data from Patients with Traumatic Brain Injury, Ulcerative Colitis, and Heart Failure","Artificial intelligence (AI) and machine learning (ML) have achieved extensive success in many fields. They are powerful in pattern recognition and function modeling. The digitization of health data provides an important opportunity for improving care delivery and patient management through the AI-based clinical decision-support (CDS) system. Medical images are important components in evaluating the disease severity. While the human's interpretation of medical images is subjective and qualitative, AI-based models can analyze those data in a more reproducible, quantitative, and less expensive way. With clinical observations and quantitative findings extracted from medical images, ML methods can be used to learn and discover knowledge. The automated CDS system can provide recommendations on diagnosis, treatment, and outcome prediction by leveraging massive medical data. Those systems can facilitate drug development, disease pathology research, and clinical practice. This dissertation investigates medical image analysis and CDS systems development in a more reliable, interpretable manner. Limitations exist in applying AI/ML techniques in medical problems. Medical data may have high variability in terms of the patient population, collection site, equipment, and imaging protocols. It is crucial that the ML and image processing algorithms have a good generalizability and can be reliably applied to unseen patient data. In addition, a broad spectrum of AI/ML methods is among the ""black box"" models. The lack of justification leads to concerns and hesitations of using AI/ML techniques in clinical or research practice. Features with clinical meaning and models that can be well explained can gain more trust and are more favorable to end-users. In this dissertation, several AI-based CDS systems have been designed and implemented to facilitate clinical and research practice. Novel algorithms are proposed to overcome the challenges of applying AI/ML techniques. To improve the generalizability of the deep learning models, a robust learning algorithm is proposed to encourage the network to be invariant to hematoma intensity variability. A Scale Module and filter pruning technique are proposed to reduce the network's size and complexity. To improve the interpretability of the CDS systems, a transparent ML algorithm is proposed based on tropical geometry and fuzzy logic, which can learn humanly understandable rules from the dataset and integrate existing domain knowledge to facilitate the model training. Domain knowledge plays an important role in the design of CDS systems. With automated image analysis methods, quantitative and objective measurements are extracted to capture the patient's condition and disease characteristics in a meaningful and reproducible way. The proposed CDS systems have been validated using data collected from routine practice and clinical trials. The datasets used in this dissertation are from multiple medial centers, which increases the generalizability of the proposed frameworks and trained models. This work aims to research the capacity of AI models toward fully automated CDS systems that can replicate expert judgment and provide insight for the patient. Efforts have been made to improve the generalizability and interpretability of AI/ML models, which are the major limitations that hinder a broad application of AI techniques in practice. The proposed algorithms and strategies in this dissertation leverage big data to improve the healthcare system and disease research. Additionally, the proposed methods are transferable beyond the target application. The contributions of this dissertation have a meaningful impact on applying AI-based systems to clinical and research practice.","","Thesis","2021","keywords","ACM"
"On the use of artificial intelligence to deal with privacy in IoT systems: A systematic literature review","","10.1016/j.jss.2022.111475","Journal","2022","keywords","ACM"
"Evidential reasoning for preprocessing uncertain categorical data for trustworthy decisions: An application on healthcare and finance","","10.1016/j.eswa.2021.115597","Journal","2021","keywords","ACM"
"An AI-based Approach for Grading Students’ Collaboration","Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made—something that proved to be very important to teachers.","10.1109/TLT.2022.3225432","Journal","2023","keywords","ACM"
"The object migration automata: its field, scope, applications, and future research challenges","Partitioning, in and of itself, is an NP-hard problem. Prior to the Artificial Intelligence (AI)-based solutions, it was solved in the 1970s by optimization-based strategies. However, AI-based solutions appeared in the 1980s in a pioneering way, by using a Learning Automaton (LA)-motivated strategy known as the so-called Object Migrating Automaton (OMA). Although the OMA and its derivatives have been used in numerous applications since then, the basic kernel has remained the same. Because the number of possible partitions in a partitioning problem can be combinatorially exponential and the underlying tasks are NP-hard, the most advanced OMA algorithms could, until recently, only solve issues involving equally sized groups. Due to our recent innovations cited in the body of this paper, the enhanced OMA now also handles non-equally sized groups. Earlier, we had presented in Omslandseter (Pattern Anal Appl, 2023), a comprehensive survey of the state-of-the-art enhancements of the best-known OMA. We believe that these results will be the benchmark for a few decades and that it will be very hard to beat these results. This is a companion paper, intended to augment the contents of Omslandseter (Pattern Anal Appl, 2023). In this paper, we first discuss the OMA’s prior applications, its historical and current innovations, and the OMA-based algorithms’ relevance to societal needs. We also provide well-specified guidelines for future researchers so that they can use them for unresolved tasks, and also develop further advancements.","10.1007/s10044-023-01163-x","Journal","2023","keywords","ACM"
"2022 IEEE International Professional Communication Conference (ProComm)","This paper examines AI-based writing systems and how humans might partner with these systems to produce effective professional communication. We offer a taxonomy for examining roles in human-machine teaming for writing: Resource Tool, Assistant, Writer, and Executive Decision-Maker (whether at the beginning or end of the project). In particular, we focus on humanmachine teaming in relation to what we call rhetorical intelligence, the ability to invent and write for audience, purpose, and context. We examine human-machine writing by focusing on two cases: GameChanger and Phrazor by vPhrase. We conclude by proposing some guidelines for human-machine teaming for the production of professional communication.","10.1109/ProComm53155.2022.00078","Conference","2022","keywords","ACM"
"Using artificial intelligence to find design errors in the engineering drawings","Artificial intelligence is increasingly becoming important to businesses because many companies have realized the benefits of applying machine learning (ML) and deep learning (DL) in their operations. ML and DL have become attractive technologies for organizations looking to automate repetitive tasks to reduce manual work and free up resources for innovation. Unlike rule‐based automation, typically used for standardized and predictable processes, machine learning, especially deep learning, can handle more complex tasks and learn over time, leading to greater accuracy and efficiency improvements. One of such promising applications is to use AI to reduce manual engineering work. This paper discusses a particular case within McDermott where the research team developed a DL model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). We also present a cost‐benefit analysis and potential scale‐up of the developed software. Our goal is to share the successful experience of AI‐based product development that can substantially reduce the engineering hours and, therefore, reduce the project's overall costs. The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry. It also could motivate practitioners and researchers to create similar products for the various fields within engineering industry.This paper discusses a particular case where the research team developed a deep learning model to do a quality check of complex blueprints. We describe the development and the final product of this case—AI‐based software for the engineering, procurement, and construction (EPC) industry that helps to find the design mistakes buried inside very complex engineering drawings called piping and instrumentation diagrams (P&amp;IDs). The developed solution can also be potentially applied to other EPC companies doing a similar design for complex installations with high safety standards like oil and gas or petrochemical plants because the design errors it captures are common within this industry.


image
image","10.1002/smr.2543","Journal","2023","keywords","ACM"
"An AI-Based Pick-and-Place Control for Quality Enhancement in Surface Mount Technology","The main goal of this dissertation is to investigate an AI-based pick-and-placeclosed-loop control system capable of identifying optimal placement positions in adynamic manufacturing environment. According to the industrial survey, assembly defects account for over 55% of field failures in passive components (the mostfrequently used chips on printed circuit boards). Moreover, the pick and placement(P&amp;P) cause over half of the assembly defects. Thus, the P&amp;P process is criticalto improving surface mount technology (SMT). Components have traditionallybeen aligned with the pad centers, referred to as a place-on-pad (PP), and it isthe most widely used method in the industry. However, with the miniaturizationof electronic components, assembly defects have increased. Recently, an adaptiveplacement strategy has been introduced to improve assembly quality [1], called the""place-on-paste"" (PPS). In our experiment with miniature passive components,PPS outperformed PP in some instances. As a result, an advanced placementstrategy should be developed to improve the mini-size component assembly consistently. With limited historical data, this research proposes an AI-based P&amp;Pcontrol system that uses both rule-based and machine learning-based placementmethods. For the former, a PB is used to account for the offsets of the printedpaste. Then, multiple dynamic placement options with synthetic placement dataare generated. A hybrid machine learning algorithm predicts the final componentivmisalignment based on the data. Finally, multiple decision-making rules identify the optimal placement option based on the prediction results. According tothe experimental results, the machine learning-based model outperforms PP in adynamic environment. In various application scenarios, the proposed frameworkoutperforms industrial placement strategies.","","Thesis","2022","keywords","ACM"
"Effects of Agency Locus and Transparency of Artificial Intelligence: Uncertainty Reduction and Emerging Mind","Existing research and mass media conceptualize interactive technologies, such as social robots and voice assistants, as machines without true agency despite their apparent autonomy and human-likeness. This is because they are often machines fully programmed by humans and act by following human-made rules. However, self-learning artificial intelligence (AI), which is increasingly used in powering many interactive technologies, is not fully programmed and does not merely follow human-made rules, but instead, learns rules from data with so little human interference that we quite often do not even understand the rules it has learned. The shift of agency locus from human to machine and the lack of transparency of the learning outcomes raise new questions for human-machine communication. How do individuals react to machines that learn autonomously yet remain opaque and mysterious? What measures should we take to cultivate appropriate levels of trust in such machines?To answer these questions, the current study examines the effects of an AI system's agency locus, meaning whether it makes decisions by following human-made rules (human-agency AI) or rules it has learned from data by itself (machine-agency AI), and the level of transparency about such rules (no transparency vs. placebic transparency vs. real transparency), upon users' cognitions, affects, and behaviors toward an AI system. Two online experiments following a 2 (agency locus: human vs. machine) X 3 (transparency: no vs. placebic vs. real) factorial design were conducted in two contexts (fake news detection and personality evaluation).Across contexts, the human-agency AI triggered more person presence, homophily, and was more trusted than the machine-agency AI. The machine-agency AI was perceived as more autonomous and triggered more ""mind perception,"" which also enhanced trust. Real transparency about AI's internal states (i.e., rules) reduced uncertainty and increased mind perception, both of which enhanced trust. By reducing uncertainty, real transparency reduced anxiety and induced more excitement. Underlying the influence of agency locus and transparency of AI on trust are both a route of anthropomorphism (person presence → uncertainty reduction → trust) and a non-anthropomorphism route of mind perception (perceived autonomy or direct access → mind perception → trust).The actual processes are found to be governed by laws of intergroup communication, interpersonal communication, and information processing. Specifically, participants were less influenced by peripheral cues with categorical information (i.e., agency locus) when they had enough cognitive resources (i.e., more past experience with AI applications, or with real transparency). Participants were more motivated to scrutinize messages about an AI system's internal states when the need for uncertainty reduction was high (i.e., when interacting with the machine-agency AI). Contexts, as proxies of individuals' goal structures and social densities, were found to influence outcomes of human-machine interaction by potentially influencing their level of involvement and expectancies.Findings suggest that for machine-learning AI, users recognize it as a mind that is not necessarily humanlike, and that having knowledge about its internal states can to some extent help individuals surpass the human-machine ontological boundary, go beyond the anthropomorphism route, and develop trust in AI. Findings shed light on fundamental interpersonal processes and the larger question of the problem of other minds. In addition, findings also have methodological implications for research on human-machine interaction and practical implications for the design of intelligent machines in general and the design of AI transparency in particular, while also informing policy-making about AI regulations in terms of transparency and accountability.","","Thesis","2020","keywords","ACM"
"Toward an intelligent tourism recommendation system based on artificial intelligence and IoT using Apriori algorithm","In recent years, the rapid development of the Internet has promoted the continuous expansion of the scale of China’s tourism industry, and the amount of tourism data has surged. However, tourists need help bringing personal interest and high-value data from the plethora of tourism information. The rise of artificial intelligence has transformed traditional tourism into an intelligent, data-driven industry. This shift has generated vast tourism data, offering both opportunities and challenges. The paper discusses an AI and IoT-based Intelligent Tourism Recommendation System (ITRS) that offers travelers predefined itineraries, personalized suggestions, and tourism insights. This system simplifies attraction discovery, unveiling hidden value within tourism data at the intersection of AI and IoT. The present study thoroughly investigates AI-based recommendation algorithms before delving into the system’s architecture. It categorizes user-based, project-based, and article-based collaborative filtering methodologies tailored to specific goals. First, thoroughly examine AI-based recommendation algorithms before delving into the system architecture. Second, categorize collaborative filtering methods as user-based, project-based, and article-based, each tailored to specific objectives. Third, delve into the Apriori algorithm’s complexity within the context of weighted association rules and introduce an enhanced iteration for improved efficiency. The proposed scheme encompasses an elaborate ITRS plan featuring a user interest model and a client module, crucial for the computation and analysis of users’ long-term and short-term interests. Rigorous performance testing confirms the ITRS’s superiority across varying support levels, with experimental results demonstrating the Apriori algorithm’s exceptional accuracy, achieving a 94.3% improvement over other methods. The Apriori algorithm is better than traditional recommendation algorithms such as Linear Regression, Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, K-nearest neighbor, Naive Bayes, and XGBoost.","10.1007/s00500-023-09330-2","Journal","2023","keywords","ACM"
"The Social Mile - How (Psychosocial) ICT can Help to Promote Resocialization and to Overcome Prison","There is currently uncertainty in the research community as to how ICT can and should be designed in such a way that it can be convincingly integrated into the everyday lives of prison inmates. In this paper, we discuss a design fiction that closes this research gap. The descriptions and results of the study are purely fictitious. Excluded is the State of the Art as well as the description of the legal situation of prisons in Germany. The analysis of the fictional study data designed here thus refers to the real world in order to derive ethical guidelines and draw practical conclusions. It is our intention to use these results as a possible basis for further research. The paper presents results of an explorative study dealing with the design, development and evaluation of an AI-based Smart Mirror System, Prison AI 2.0, in a German prison. Prison AI 2.0 was developed for daily use and voluntarily tested by eight prisoners over a period of 12 months to gain insight into their individual and social impact, with an emphasis on its ability to actively support rehabilitation. Based on qualitative data, our findings suggest that intelligent AI-based devices can actually help promote such an outcome. Our results also confirm the valuable impact of (Psychosocial) ICT on the psychological, social and individual aspects of prison life, and in particular how prisoners used the Smart Mirror system to improve and maintain their cognitive, mental and physical state and to restore social interactions with the outside world. With the presentation of these results we want to initiate discussions about the use of ICT by prisoners in closed prisons in order to identify opportunities and risks.","10.1145/3370270","Journal","2019","keywords","ACM"
"Design, User Experience, and Usability:  Design for Contemporary Technological Environments: 10th International Conference, DUXU 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part III","This paper aims to investigate the user experience with recommender systems of Video on Demand (VoD) platforms based in Machine Learning (ML), focusing on the Artificial Intelligence (AI) principles. We start from the hypothesis that the inclusion of AI algorithms has the potential to improve the user experience in digital systems, but they are still developed with a greater focus on technology, however, they should also consider more aspects regarding human factors. Nine principles on AI related to UX were selected from a compilation of seven lists of government and industry entities to understand the bases that every AI system should respect to ensure a good user experience. In sequence, we discuss their effects on the user experience of VoD platforms. To finish, the experience with these platforms were explored in a directed storytelling method involving thirty-one participants. Some behaviors and patterns found were analyzed and discussed to suggest guidelines to be applied to ML algorithms of VoD Platforms.","10.1007/978-3-030-78227-6_38","Conference","2021","keywords","ACM"
"Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice","In recent years, there has been a lot of discussion around ethics in IT and AI. Researchers and organizations have proposed guidelines to address privacy, fairness, and explainability challenges for creating trustworthy AI. In this work, we outline the importance of compliance with the above-mentioned ethical principles and their influence on the quality of AI systems. We map the relationship between available approaches for compliance with privacy, fairness, explainability principles and the accuracy of AI system decisions. Additionally, we introduce the difference between ensuring fairness for phenomena presented with tabular data and text. Tabular data may contain protected attributes such as gender, age, or race as well as the decision made historically in relation to the people concerned. Data presented in text is not structured and requires sense perception by AI systems to detect bias or unfairness. In the poster, we compare available approaches and present experiments for measuring bias in text data.","10.1145/3633083.3633223","Conference","2023","keywords","ACM"
"Proceedings of the Winter Simulation Conference","To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.","","Conference","2023","keywords","ACM"
"Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction","We are developing a social robot to help children cope with painful and distressing medical procedures in the hospital emergency department. This is a domain where a range of interventions have proven effective at reducing pain and distress, including social robots; however, until now, the robots have been designed with limited stakeholder involvement and have shown limited autonomy. For our system, we have defined and validated the necessary robot behaviour together with children, parents/caregivers, and healthcare professionals, taking into account the ethical and social implications of robotics and AI in the paediatric healthcare context. The result of the co-design process has been captured in a flowchart, which has been converted into a set of concrete design guidelines for the AI-based autonomous robot system.","10.1145/3568294.3580127","Conference","2023","keywords","ACM"
"Explainable and Transparent AI and Multi-Agent Systems: 5th International Workshop, EXTRAAMAS 2023, London, UK, May 29, 2023, Revised Selected Papers","The need for AI systems to explain themselves is increasingly recognised as a priority, particularly in domains where incorrect decisions can result in harm and, in the worst cases, death. Explainable Artificial Intelligence (XAI) tries to produce human-understandable explanations for AI decisions. However, most XAI systems prioritize factors such as technical complexities and research-oriented goals over end-user needs, risking information overload. This research attempts to bridge a gap in current understanding and provide insights for assisting users in comprehending the rule-based system’s reasoning through dialogue. The hypothesis is that employing dialogue as a mechanism can be effective in constructing explanations. A dialogue framework for rule-based AI systems is presented, allowing the system to explain its decisions by engaging in “Why?” and “Why not?” questions and answers. We establish formal properties of this framework and present a small user study with encouraging results that compares dialogue-based explanations with proof trees produced by the AI System.","10.1007/978-3-031-40878-6_4","Conference","2023","keywords","ACM"
"2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets.","10.1109/FUZZ48607.2020.9177770","Conference","2020","keywords","ACM"
"Artificial Intelligence in HCI: First International Conference, AI-HCI 2020, Held as Part of the 22nd HCI International Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020, Proceedings","Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies.","10.1007/978-3-030-50334-5_10","Conference","2020","keywords","ACM"
"Proceedings of the 37th International Conference on Machine Learning","Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares, as well as importance sampling methods. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust.","","Conference","2020","keywords","ACM"
"Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence","Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as ""if you can't say something nice, don't say anything at all"" and principles articulated in Carnegie's classic How to Win Friends and Influence People, offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs.","","Conference","2018","keywords","ACM"
"Artificial Intelligence in Medicine: 20th International Conference on Artificial Intelligence in Medicine, AIME 2022, Halifax, NS, Canada, June 14–17, 2022, Proceedings","There is an increasing shift towards the self-management of long-term chronic illness by patients in a home setting, supported by personal health electronic equipment. Among others, self-management requires comprehensive education on the illness, i.e., understanding the effects of nutritional, fitness, and medication choices on personal health; and long-term health behavior change, i.e., modifying unhealthy lifestyles that contribute to chronic illness. Smart health recommendations, generated using AI-based Clinical Decision Support (CDS), can guide patients towards positive nutritional, fitness, and health behavioral choices. Moreover, we posit that explaining these recommendations to patients, using Explainable AI (XAI) techniques, will effect education and positive behavior change. We present our work towards an explanation framework for rule-based CDS, called EXPLAIN (EXPLanations of AI In N3), which aims to generate human-readable, patient-facing explanations.","10.1007/978-3-031-09342-5_6","Conference","2022","keywords","ACM"
"Bridging the civilian-military divide in responsible AI principles and practices","Advances in AI research have brought increasingly sophisticated capabilities to AI systems and heightened the societal consequences of their use. Researchers and industry professionals have responded by contemplating responsible principles and practices for AI system design. At the same time, defense institutions are contemplating ethical guidelines and requirements for the development and use of AI for warfare. However, varying ethical and procedural approaches to technological development, research emphasis on offensive uses of AI, and lack of appropriate venues for multistakeholder dialogue have led to differing operationalization of responsible AI principles and practices among civilian and defense entities. We argue that the disconnect between civilian and defense responsible development and use practices leads to underutilization of responsible AI research and hinders the implementation of responsible AI principles in both communities. We propose a research roadmap and recommendations for dialogue to increase exchange of responsible AI development and use practices for AI systems between civilian and defense communities. We argue that generating more opportunities for exchange will stimulate global progress in the implementation of responsible AI principles.","10.1007/s10676-023-09693-y","Journal","2023","keywords","ACM"
"Proceedings of the 24th International Conference on Artificial Intelligence","Aesthetic evaluation of Chinese calligraphy is one of the most challenging tasks in Artificial Intelligence. This paper attempts to solve this problem by proposing a number of aesthetic feature representations and feeding them into Artificial Neural Networks. Specifically, 22 global shape features are presented to describe a given handwritten Chinese character from different aspects according to classical calligraphic rules, and a new 10-dimensional feature vector is introduced to represent the component layout information using sparse coding. Moreover, a Chinese Handwriting Aesthetic Evaluation Database (CHAED) is also built by collecting 1000 Chinese handwriting images with diverse aesthetic qualities and inviting 33 subjects to evaluate the aesthetic quality for each calligraphic image. Finally, back propagation neural networks are constructed with the concatenation of the proposed features as input and then trained on our CHAED database for the aesthetic evaluation of Chinese calligraphy. Experimental results demonstrate that the proposed AI system provides a comparable performance with human evaluation. Through our experiments, we also compare the importance of each individual feature and reveal the relationship between our aesthetic features and the aesthetic perceptions of human beings.","","Conference","2015","keywords","ACM"
"Information Processing for Low Resource Processing Based Cognitive Psychology for Second Language Teaching by Opinion Mining using Deep Learning Architecture","Foreign language instruction is crucial and difficult in every nation. Effective teachers must consider students' attitudes, motivation, and knowledge. Quality teaching determines student success. This study presents an AI-based deep learning method for second language and English instruction. This dataset was collected from students' second language and English teaching preferences. Dimensionality reduction and missing value removal were done on the dataset. Fuzzy set-based clustering with stochastic gradient residual neural network (ResNet) architecture classified this processed data. Students' second language and English teaching opinions were collected using fuzzy rules. Fuzzy clustering and stochastic gradient ResNet architecture classified this data. Student opinion mining was used for experimental study of various datasets and the parametric analysis yielded 96% accuracy, 90% sensitivity, 92% specificity, 82% F-1 score, 72% Mean squared error (MSE), and 88% Area Under the Curve (AUC).","10.1145/3590151","Journal","2023","keywords","ACM"
"Fate of AI for Smart City Services in India: A Qualitative Study","With the rollout of the smart city initiative in India, this study explores potential risks and opportunities in adopting artificial intelligence (AI) for citizen services. The study deploys expert interview technique and the data collected from various sources are analyzed using qualitative analysis. It was found that AI implementation needs a critical examination of various socio-technological factors to avoid any undesirable impacts on citizens. Fairness, accountability, transparency, and ethics (FATE) play an important role during the design and execution of AI-based systems. This study provides vital insights into AI implications to smart city managers, citizen groups, and policymakers while delivering promised smart city experience. The study has social implications in terms of ensuring that proper guidelines are developed for using AI technology for citizen services, thereby bridging the ever-critical trust gap between citizens and city administration.","10.4018/IJEGR.298216","Journal","2022","keywords","ACM"
"Proceedings of the 13th International Conference on Advances in Computer Entertainment Technology","This paper evaluates the performance of Monte-Carlo Tree Search (MCTS) in a fighting game AI and proposes an improvement for the algorithm. Most existing fighting game AIs rely on rule bases and react to every situation with predefined actions, making them predictable for human players. We attempt to overcome this weakness by applying MCTS, which can adapt to different circumstances without relying on predefined action patterns or tactics. In this paper, an AI based on Upper Confidence bounds applied to Trees (UCT) and MCTS is first developed. Next, the paper proposes improving the AI with Roulette Selection and a rule base. Through testing and evaluation using FightingICE, an international fighting game AI competition platform, it is proven that the aforementioned MCTS-based AI is effective in a fighting game, and our proposed improvement can further enhance its performance.","10.1145/3001773.3001797","Conference","2016","keywords","ACM"
"Proceedings of the XVII Brazilian Symposium on Information Systems","The interest in Artificial Intelligence (AI) based systems has been gaining momentum at a fast pace, both for software development teams and for society as a whole. This work aims to identify the guidelines and ethical principles for systems based on Artificial Intelligence. Design Science Research methodology was adopted in order to understand the various guidelines and principles existing in the literature. From the current landscape, a body of knowledge in the field of AI ethics is presented, with the purpose of supporting developers and Product Owners in identifying the guidelines and ethical principles in the literature so that they can be used during the software development process. Thus, this work will contribute to the various stakeholders in the development of ethical systems in the context of AI, such as: policy makers, ethicists, users, organizations, data scientists, development teams, among others.","10.1145/3466933.3466969","Conference","2021","keywords","ACM"
"Proceedings of the 6th Joint International Conference on Data Science &amp; Management of Data (10th ACM IKDD CODS and 28th COMAD)","Several explainable AI algorithms have been proposed to help make machine learning models more interpretable and trustworthy. However in spite of numerous methodological advancements, there is still a persistent gap between what researchers develop and what business users seek. In this work, we aim to bridge this gap for an AI system that predicts the remaining useful life of an aircraft’s engine using time series data collected from multiple sensors. We propose a novel approach to compute easily understandable explanations by fusing two explainers in sequence wherein explanations of the first explainer are explained by the second. We use this approach to build a global post-hoc model-agnostic explainer for AI models that ingest multivariate time series data. Our approach fuses a local explainer that yields feature importance weights, with a directly interpretable model that outputs global rules. Our experimental results based on the C-MAPSS open-source dataset demonstrate that the proposed two-stage explainer computes global explanations that are amenable to business users and sheds light on how the behavior of an individual and a group of sensors impacts the remaining useful life of an aircraft’s engine.","10.1145/3570991.3570998","Conference","2023","keywords","ACM"
"Energy-Efficient Pattern Recognition Hardware With Elementary Cellular Automata","The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) is able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy.","10.1109/TC.2019.2949300","Journal","2020","keywords","ACM"
"Development of a Computer Player for Seejeh (A.K.A Seega, Siga, Kharbga) Board Game with Deep Reinforcement Learning","","10.1016/j.procs.2019.09.463","Journal","2019","keywords","ACM"
"Advanced Visual Interfaces. Supporting Artificial Intelligence and Big Data Applications: AVI 2020 Workshops, AVI-BDA and ITAVIS, Ischia, Italy, June 9, 2020 and September 29, 2020, Revised Selected Papers","This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system.","10.1007/978-3-030-68007-7_6","Conference","2020","keywords","ACM"
"Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables","In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.","10.1145/3579628","Journal","2023","keywords","ACM"
"Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems","Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.","10.1145/3313831.3376506","Conference","2020","keywords","ACM"
"AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions","Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or&nbsp;Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or&nbsp;AI-based technical point of view.","10.1007/s42979-021-00557-0","Journal","2021","keywords","ACM"
"Modeling and enforcing access control policies in conversational user interfaces","Conversational user interfaces (CUIs), such as chatbots, are becoming a common component of many software systems. Although they are evolving in many directions (such as advanced language processing features, thanks to new AI-based developments), less attention has been paid to access control and other security concerns associated with CUIs, which may pose a clear risk to the systems they interface with. In this paper, we apply model-driven techniques to model and enforce access-control policies in CUIs. In particular, we present a fully fledged framework to integrate the role-based access-control (RBAC) protocol into CUIs by: (1) modeling a set of access-control rules to specify permissions over the bot resources using a domain-specific language that tailors core RBAC concepts to the CUI domain; and (2) describing a mechanism to show the feasibility of automatically generating the infrastructure to evaluate and enforce the modeled access control policies at runtime.","10.1007/s10270-023-01131-3","Journal","2023","keywords","ACM"
"Design, User Experience, and Usability: 12th International Conference, DUXU 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part IV","Conversational agents (CAs) are increasingly used as an additional convenient and innovative customer service channel to relieve service employees, as in the studied organization. In the process of analyzing and maintaining the present AI-based agent, however, user satisfaction is low as the CA lacks understanding and offers unsatisfactory solutions to users. Nonetheless, solving the requests and providing a positive user experience is crucial to relieve the service employees’ workload permanently. For CAs’ improvement, this study followed action design research (ADR) and used design thinking. We identified the central interaction problems (findability, welcome message, dialog control and fallback issues) with a monitoring process and analysis. Afterward, we interviewed users about their expectations and requirements and addressed these problems by creating user-centric mock-ups. Through a quantitative survey, the most popular solutions were implemented in a prototype. Finally, the resulting CA prototype was evaluated, showing a significantly improved user experience afterward, and design guidelines were discovered.","10.1007/978-3-031-35708-4_22","Conference","2023","keywords","ACM"
"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency","While recent studies indicate that AI could play an important role in detecting early signs of Alzheimer's disease in speech, this use of data from individuals with cognitive decline raises numerous ethical concerns. In this paper, we identify and explain concerns related to autonomy (including consent, depersonalization and disclosure), privacy and data protection (including the handling of personal content and medical information), welfare (including distress, discrimination and reliability), transparency (including the interpretability of language features and AI-based decision-making for developers and clinicians), and fairness (including bias and the distribution of benefits). Our aim is to not only raise awareness of the ethical concerns posed by the use of AI in speech-based Alzheimer's detection, but also identify ways in which these concerns might be addressed. To this end, we conclude with a list of suggestions that could be incorporated into ethical guidelines for researchers and clinicians working in this area.","10.1145/3593013.3594063","Conference","2023","keywords","ACM"
"12th International Conference on Intelligent Tutoring Systems - Volume 8474","Students often need prompt feedback to make the best from the learning activities. Within classrooms, being aware of students' achievements and weaknesses can help teachers decide how to time feedback. However, they usually cannot easily assess student's progress. We present an approach to generate automated notifications that can enhance teacher's awareness in runtime. This paper formulates the theoretical framing and describes the technological infrastructure of a system that can help teachers orchestrate learning activities and monitor small groups in a multi-tabletop classroom. We define the design guidelines underpinning our system, which include: i generating notifications from teacher-designed or AI-based sources; ii enhancing teacher's awareness in the orchestration loop; iii presenting both positive and negative notifications; iv allowing teachers to tune the system; and v providing a private teacher's user interface. Our approach aims to guide research on ways to generate notifications that can help teachers drive their attention and provide relevant feedback for small group learning activities in the classroom.","10.1007/978-3-319-07221-0_64","Conference","2014","keywords","ACM"
"FFTree: A flexible tree to handle multiple fairness criteria","","10.1016/j.ipm.2022.103099","Journal","2022","keywords","ACM"
"Adjunct Publication of the 28th ACM Conference on User Modeling, Adaptation and Personalization","Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy.","10.1145/3386392.3399276","Conference","2020","keywords","ACM"
"Proceedings of the 18th International Conference on Availability, Reliability and Security","The prevalence of encrypted Internet traffic has resulted in a pressing need for advanced analysis techniques for traffic analysis and classification. Traditional rule-based and signature-based approaches have been hindered by the introduction of network encryption methods. With the emergence of machine learning (ML) and deep learning (DL), several preliminary works have been developed for anomaly detection in encrypted network traffic. However, complex Artificial Intelligence (AI) models like neural networks lack explainability, limiting the understanding of their predictions. To address this limitation, eXplainable Artificial Intelligence (XAI) has emerged, aiming to provide users with a rationale for understanding AI system outputs and fostering trust. However, existing explainable frameworks still lack comprehensive support for adversarial attacks and defenses. In this paper, we present Montimage AI Platform (MAIP), a new GUI-based deep learning framework for malicious traffic detection and classification combined with its ability of explaining the decision of the model. We employ popular XAI methods to interpret the prediction of the developed deep learning model. Furthermore, we perform adversarial attacks to assess the accountability and robustness of our model via different quantifiable metrics. We perform extensive experiments with both public and private network traffic. The experimental results demonstrate that our model achieves high performance and robustness, and its outcomes align closely with the domain knowledge.","10.1145/3600160.3605052","Conference","2023","keywords","ACM"
"Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society","Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.","10.1145/3278721.3278751","Conference","2018","keywords","ACM"
"Human Interface and the Management of Information. Information in Applications and Services: 20th International Conference, HIMI 2018, Held as Part of HCI International 2018, Las Vegas, NV, USA, July 15-20, 2018, Proceedings, Part II","As artificial intelligent (AI) technology has been dramatically developed, various industries have been challenged to apply it. In a view of nuclear power plants (NPP), it seems that AI technology applies to NPPs at the last because NPPs are required the most stringent level of regulatory guideline for safety. To overcome it, AI technology should be applied incrementally into the NPPs rather than all at once. According to the unintended shutdown records during startup and shutdown operation from 1997 to 2017 in Korea, it is reported that human errors accounts for 40% of the total. This is because operators feel heavy burden to monitor hundreds of parameters for a long time of operating time. Also, there are lots of startup and shutdown operating history that can be used for correcting the data from the NPP simulator. Therefore, this work proposes a framework to develop AI automatic operating system for startup and shutdown operations of NPPs. Operating procedures of startup and shutdown operations are categorized. In addition, AI technologies will be introduced to find out the most suitable learning algorithm. It is expected that economic loss from human error during startup and shutdown operation will be reduced as AI system developed.","10.1007/978-3-319-92046-7_42","Conference","2018","keywords","ACM"
"Proceedings of the 2021 International Conference on Multimodal Interaction","Trust is a key element in the development of effective collaborative relationships between humans and increasingly complex artificial intelligence (AI) systems. Here, we examine trust in AI in the context of a human-AI partnership that involves a joint decision making task for estimating levels of public speaking anxiety based on speech signals. The AI system is comprised of an explainable machine learning (ML) algorithm, that takes acoustic characteristics as input and outputs the estimate of public speaking anxiety levels, a local explanation about the most important features that contributed to the decision of each speech sample, and a global explanation about the most important features for the data overall. We analyze interactions between AI and human annotators with background in psychological sciences, and measure trust over time via the annotators’ agreement with the AI model and the annotators’ self-reports. We further examine factors of trust that are related to the characteristics of the human annotator and the ML algorithm. Results indicate that trust in AI depends on the openness level of the annotator and the importance level of input features. Findings from this study can provide guidelines to designing solutions that properly calibrate human trust in AI in collaborative human-AI tasks.","10.1145/3462244.3479926","Conference","2021","keywords","ACM"
"Algorithmic bias in data-driven innovation in the age of AI","","10.1016/j.ijinfomgt.2021.102387","Journal","2021","keywords","ACM"
"Proceedings of the 12th International Conference on the Foundations of Digital Games","Ticket to Ride is a popular contemporary board game for two to four players, featuring a number of expansions with additional maps and tweaks to the core game mechanics. In this paper, four different game-playing agents that embody different playing styles are defined and used to analyze Ticket to Ride. Different playing styles are shown to be effective depending on the map and rule variation, and also depending on how many players play the game. The performance profiles of the different agents can be used to characterize maps and identify the most similar maps in the space of playstyles. Further analysis of the automatically played games reveal which cities on the map are most desirable, and that the relative attractiveness of cities is remarkably consistent across numbers of players. Finally, the automated analysis also reveals two classes of failures states, where the agents find states which are not covered by the game rules; this is akin to finding bugs in the rules. We see the analysis performed here as a possible template for AI-based playtesting of contemporary board games.","10.1145/3102071.3102105","Conference","2017","keywords","ACM"
"OCMR: A comprehensive framework for optical chemical molecular recognition","","10.1016/j.compbiomed.2023.107187","Journal","2023","keywords","ACM"
"Fault and performance management in multi-cloud virtual network services using AI: A tutorial and a case study","","10.1016/j.comnet.2019.106950","Journal","2019","keywords","ACM"
"Proceedings of the First International Symposium on Trustworthy Autonomous Systems","Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address these concerns, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.","10.1145/3597512.3599697","Conference","2023","keywords","ACM"
"The importance of transparency in naming conventions, designs, and operations of safety features: from modern ADAS to fully autonomous driving functions","This paper investigates the importance of standardising and maintaining the transparency of advanced driver-assistance systems (ADAS) functions nomenclature, designs, and operations in all categories up until fully autonomous vehicles. The aim of this paper is to reveal the discrepancies&nbsp;in ADAS functions across automakers and discuss the underlying issues and potential solutions. In this pilot study, user manuals of various brands are reviewed systematically and critical analyses of common ADAS functions are conducted. The result shows that terminologies used to describe ADAS functions vary widely across manufacturers and sometimes do not reflect their fundamental functions intuitively. Operational conditions and control procedures also vary across the selected models under this study. Due to this lack of consensus across the industry, drivers are not aware or well informed about ADAS functions in their vehicles, leading to a very low utilization rate and may lead to misuse of those functions. This paper provides insightful suggestions for the transport industry, Artificial Intelligence (AI) experts, and regulators to design frameworks and guidelines in governing the naming convention, operating conditions, control procedures, and information disclosure of ADAS. Such guidelines can be the foundations for regulating future AI-based self-driving functions.","10.1007/s00146-022-01442-x","Journal","2022","keywords","ACM"
"Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers","Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity","10.1145/3341162.3349331","Conference","2019","keywords","ACM"
"Systematic literature review of validation methods for AI systems","","10.1016/j.jss.2021.111050","Journal","2021","keywords","ACM"
"Requirements Engineering: Foundation for Software Quality: 28th International Working Conference, REFSQ 2022, Birmingham, UK, March 21–24, 2022, Proceedings","[Context and Motivation] Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. [Question] The goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems. We analyzed the ethical guidelines in 16 organizations representing different industries and public sector. [Results] In the ethical guidelines, the importance of transparency was highlighted by almost all of the organizations, and explainability was considered as an integral part of transparency. Building trust in AI systems was one of the key reasons for developing transparency and explainability, and customers and users were raised as the main target groups of the explanations. The organizations also mentioned developers, partners, and stakeholders as important groups needing explanations. The ethical guidelines contained the following aspects of the AI system that should be explained: the purpose, role of AI, inputs, behavior, data utilized, outputs, and limitations. The guidelines also pointed out that transparency and explainability relate to several other quality requirements, such as trustworthiness, understandability, traceability, privacy, auditability, and fairness. [Contribution] For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a structured way to define explainability requirements of AI systems.","10.1007/978-3-030-98464-9_1","Conference","2022","keywords","ACM"
"A cognitive architecture for automatic gardening","A cognitive system to autonomously control the growth of plants is proposed.The system integrates artificial intelligence and robotic techniques.Decisions are made using symbolic planning and machine learning.Plants are modelled using 3D model acquisition of deformable objects (leaves).Action rules are learned during run-time under the guidance of a human gardener. In large industrial greenhouses, plants are usually treated following well established protocols for watering, nutrients, and shading/light. While this is practical for the automation of the process, it does not tap the full potential for optimal plant treatment. To more efficiently grow plants, specific treatments according to the plant individual needs should be applied. Experienced human gardeners are very good at treating plants individually. Unfortunately, hiring a crew of gardeners to carry out this task in large greenhouses is not cost effective. In this work we present a cognitive system that integrates artificial intelligence (AI) techniques for decision-making with robotics techniques for sensing and acting to autonomously treat plants using a real-robot platform. Artificial intelligence techniques are used to decide the amount of water and nutrients each plant needs according to the history of the plant. Robotic techniques for sensing measure plant attributes (e.g. leaves) from visual information using 3D model representations. These attributes are used by the AI system to make decisions about the treatment to apply. Acting techniques execute robot movements to supply the plants with the specified amount of water and nutrients.","10.1016/j.compag.2017.04.015","Journal","2017","keywords","ACM"
"Medical Image Computing and Computer Assisted Intervention – MICCAI 2022: 25th International Conference, Singapore, September 18–22, 2022, Proceedings, Part III","Esophageal cancer is the second most deadly cancer. Early detection of resectable/curable esophageal cancers has a great potential to reduce mortality, but no guideline-recommended screening test is available. Although some screening methods have been developed, they are expensive, might be difficult to apply to the general population, and often fail to achieve satisfactory sensitivity for identifying early-stage cancers. In this work, we investigate the feasibility of esophageal tumor detection and classification (cancer or benign) on the noncontrast CT scan, which could potentially be used for opportunistic cancer screening. To capture the global context, a novel position-sensitive self-attention is proposed to augment nnUNet with non-local interactions. Our model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients. In comparison, the mean sensitivity and specificity of four doctors are 75.0% and 83.8%, respectively. For the classification task, our model outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system, our method has comparable performance and is even more sensitive for early-stage cancer and benign tumor. Our proposed method is a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer.","10.1007/978-3-031-16437-8_33","Conference","2022","keywords","ACM"
"Artificial Intelligence in Medicine: 19th International Conference on Artificial Intelligence in Medicine, AIME 2021, Virtual Event, June 15–18, 2021, Proceedings","The CAncer PAtient Better Life Experience (CAPABLE) project combines the most advanced technologies for data and knowledge management with a socio-psychological approach, to develop a coaching system for improving the quality of life of cancer patients managed at home. The team includes complementary expertise in data- and knowledge-driven AI, data integration, telemedicine and decision support. The time is right to fully exploit Artificial Intelligence for cancer care and bring the benefits right to patients’ homes. CAPABLE relies on predictive models based on both retrospective and prospective data, integrated with computer interpretable guidelines and made available to oncologists. CAPABLE’s Virtual Coach component identifies unexpected needs and provides patient-specific decision support and lifestyle guidance to improve mental and physical wellbeing of patients. The demo, designed around a use-case scenario developed with clinicians involved in the project, addresses the ESMO Diarrhea guideline. It revolves around a prototypical fictional patient named Maria. Maria, 66, is affected by renal cell carcinoma and moderate insomnia. The demo follows Maria during the first three days of using the CAPABLE system. This allows the audience to understand the scope and innovation behind this AI-based decision-support and coaching system that personalizes lifestyle and medication interventions to patients, their carer and clinicians.","10.1007/978-3-030-77211-6_34","Conference","2021","keywords","ACM"
"Proceedings of the 44th International Conference on Software Engineering","Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.","10.1145/3510003.3510163","Conference","2022","keywords","ACM"
"Questioning the EU proposal for an Artificial Intelligence Act: The need for prohibitions and a stricter approach to biometric surveillance1","Artificial Intelligence (AI)-based surveillance technologies such as facial recognition, emotion recognition and other biometric technologies have been rapidly introduced by both public and private entities all around the world, raising major concerns about their impact on fundamental rights, the rule of law and democracy. This article questions the efficiency of the European Commission’s Proposal for Regulation of Artificial Intelligence, known as the AI Act, in addressing the threats and risks to fundamental rights posed by AI biometric surveillance systems. It argues that in order to meaningfully address risks to fundamental rights the proposed classification of these systems should be reconsidered. Although the draft AI Act acknowledges that some AI practices should be prohibited, the multiple exceptions and loopholes should be closed, and in addition new prohibitions, in particular to emotional recognition and biometric categorisation systems, should be added to counter AI surveillance practices violating fundamental rights. The AI Act should also introduce stronger legal requirements, such as third-party conformity assessment, fundamental rights impact assessment, transparency obligations as well as enhance existing EU data protection law and the rights and remedies available to individuals, thus not missing the unique opportunity to adopt the first legal framework that truly promotes trustworthy AI.","10.3233/IP-211524","Journal","2022","keywords","ACM"
"Proceedings of the 2023 ACM International Conference on Interactive Media Experiences Workshops","As with many industries, TV and video production is likely to be transformed by artificial intelligence (AI) and machine learning (ML), with software and algorithms assisting production tasks that, conventionally, could only be carried out by people. Expanded coverage of a diverse range of live events is particularly constrained by the relative scarcity of skilled people, and it is a strong use case for AI-based automation. This article describes the recent research conducted by the British Broadcasting Corporation (BBC) on the potential production benefits of AI algorithms, using visual analysis and other techniques. Rigging small, static ultra high-definition (UHD) cameras, we have enabled a one-person crew to crop UHD footage in multiple ways and cut between the resulting shots, effectively creating multicamera HD coverage of events that cannot accommodate a camera crew. By working with programme-makers to develop simple deterministic rules and, increasingly, training systems using advanced video analysis, we are developing a system of algorithms to automatically frame, sequence, and select shots, and construct acceptable multicamera coverage of previously untelevised types of events. This paper was published in the proceedings of the International Broadcasting Convention in 2018&nbsp;[1], and in SMPTE Motion Imaging Journal in 2020&nbsp;[2].","10.1145/3604321.3604375","Conference","2023","keywords","ACM"
"Artificial Intelligence- (AI-) Enabled Internet of Things (IoT) for Secure Big Data Processing in Multihoming Networks","The automated techniques enabled with Artificial Neural Networks (ANN), Internet of Things (IoT), and cloud-based services affect the real-time analysis and processing of information in a variety of applications. In addition, multihoming is a type of network that combines various types of networks into a single environment while managing a huge amount of data. Nowadays, the big data processing and monitoring in multihoming networks provide less attention while reducing the security risk and efficiency during processing or monitoring the information. The use of AI-based systems in multihoming big data with IoT- and AI-integrated systems may benefit in various aspects. Although multihoming security issues and their analysis have been well studied by various scientists and researchers; however, not much attention is paid towards big data security processing in multihoming especially using automated techniques and systems. The aim of this paper is to propose an IoT-based artificial network to process and compute big data processing by ensuring a secure communication multihoming network using the Bayesian Rule (BR) and Levenberg-Marquardt (LM) algorithms. Further, the efficiency and effect on multihoming information processing using an AI-assisted mechanism are experimented over various parameters such as classification accuracy, classification time, specificity, sensitivity, ROC, and F-measure.","10.1155/2021/5754322","Journal","2021","keywords","ACM"
"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person’s motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person’s activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students’ work sessions.","10.1109/SMC42975.2020.9282981","Conference","2020","keywords","ACM"
"Intelligent Systems: 12th Brazilian Conference, BRACIS 2023, Belo Horizonte, Brazil, September 25–29, 2023, Proceedings, Part I","Context: The use of Artificial Intelligence (AI) in various sectors of the economy is already a reality in Brazil. Consequently, since 2019, the number of cases in the Judiciary involving AI has increased. Cases involving facial recognition systems (FRS) for contracting bank credit are increasing annually, so it is necessary to analyze how the Judiciary handles the issues. Problem: Why is the S\~{a}o Paulo Court of Appeal ruling in favor of banks in all cases involving taking out credit through facial recognition technology? Methodology and Methods: Data were collected and processed using automated computer programs. The qualitative analysis used the analytical, comparative and monographic methods. Results: The Court of Appeal of S\~{a}o Paulo considers it difficult to deceive an AI system, therefore, the burden of proof is on the author, even if there is a consumer relationship. That is, the decisions are contrary to the general rule of the Code of Consumer Protection in Brazil, which consists of reversing the burden of proof in consumer relations when one of the parties is underprivileged. Contributions and Solutions: The research points to the path of jurisprudence in cases involving the contracting of credit through FRS, and the Judiciary is deciding against the bank’s customers, dispensing with the production of evidence by the banking sector. Therefore, it is necessary to alert the National Council of Justice and the Central Bank regarding this situation so that it is disciplined adequately since the FRS is fallible and does not guarantee the absence of fraud.","10.1007/978-3-031-45368-7_2","Conference","2023","keywords","ACM"
"Distributed and Democratized Learning: Philosophy and Research Challenges","Due to the availability of huge amounts of data and processing abilities, current artificial intelligence (AI) systems are effective in solving complex tasks. However, despite the success of AI in different areas, the problem of designing AI systems that can truly mimic human cognitive capabilities such as artificial general intelligence, remains largely open. Consequently, many emerging cross-device AI applications will require a transition from traditional centralized learning systems towards large-scale distributed AI systems that can collaboratively perform multiple complex learning tasks. In this paper, we propose a novel design philosophy called democratized learning (Dem-AI) whose goal is to build large-scale distributed learning systems that rely on the self-organization of distributed learning agents that are wellconnected, but limited in learning capabilities. Correspondingly, inspired by the societal groups of humans, the specialized groups of learning agents in the proposed Dem-AI system are selforganized in a hierarchical structure to collectively perform learning tasks more efficiently. As such, the Dem-AI learning system can evolve and regulate itself based on the underlying duality of two processes which we call specialized and generalized processes. In this regard, we present a reference design as a guideline to realize future Dem-AI systems, inspired by various interdisciplinary fields. Accordingly, we introduce four underlying mechanisms in the design such as plasticity-stability transition mechanism, self-organizing hierarchical structuring, specialized learning, and generalization. Finally, we establish possible extensions and new challenges for the existing learning approaches to provide better scalable, flexible, and more powerful learning systems with the new setting of Dem-AI.","10.1109/MCI.2020.3039068","Journal","2021","keywords","ACM"
"Computational Science – ICCS 2021: 21st International Conference, Krakow, Poland, June 16–18, 2021, Proceedings, Part III","Normally, it takes many years of theoretical and clinical training for a physician to be the movement disorder specialist. It takes additional multiple years of the clinical practice to handle various “non-typical” cases. The purpose of our study was to predict neurodegenerative disease development by abstract rules learned from experienced neurologists. Theory of mind (ToM) is human’s ability to represent mental states such as emotions, intensions or knowledge of others. ToM is crucial not only in human social interactions but also is used by neurologists to find an optimal treatment for patients with neurodegenerative pathologies such as Parkinson’s disease (PD). On the basis of doctors’ expertise, we have used supervised learning to build AI system that consists of abstract granules representing ToM of several movement disorders neurologists (their knowledge and intuitions). We were looking for similarities between granules of patients in different disease stages to granules of more advanced PD patients. We have compared group of 23 PD with attributes measured three times every half of the year (G1V1, G1V2, G1V3) to other group of 24 more advanced PD (G2V1). By means of the supervised learning and rough set theory we have found rules describing symptoms of G2V1 and applied them to G1V1, G1V2, and G1V3. We have obtained the following accuracies for all/speed/emotion/cognition attributes: G1V1: 68/59/53/72%; G1V2: 72/70/79/79%; G1V3: 82/92/71/74%. These results support our hypothesis that divergent sets of granules were characteristic for different brain’s parts that might degenerate in non-uniform ways with Parkinson’s disease progression.","10.1007/978-3-030-77967-2_45","Conference","2021","keywords","ACM"
"Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning","","10.1016/j.chb.2022.107547","Journal","2023","keywords","ACM"
"Transparency of deep neural networks for medical image analysis: A review of interpretability methods","","10.1016/j.compbiomed.2021.105111","Journal","2022","keywords","ACM"
"Computers Helping People with Special Needs: 17th International Conference, ICCHP 2020, Lecco, Italy, September 9–11, 2020, Proceedings, Part I","The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities, who have difficulties in reading comprehension. The main goal of the E2R Methodology is to present clear and easily understood documents. This methodology includes a set of guidelines and recommendations that affect the writing of texts, the supporting images, the design and layout of documents, and the final editing format. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. The process of adapting existing documents is cyclic and implies three activities: analysis, transformation, and validation. All these activities are human resource consuming, due to the need of involving people with cognitive disabilities as well as E2R experts. In order to alleviate such processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to perform the analysis and transformation of documents in a (semi)-automatic fashion. In this paper we present our AI-based method for assessing a particular document with respect to the E2R guidelines as well as an initial implementation of such a method; our research on the transformation of documents is out of the scope of this paper. We carried out a comparative evaluation of the results obtained by our initial implementation against the results of the document analysis performed by people with cognitive disabilities.","10.1007/978-3-030-58796-3_10","Conference","2020","keywords","ACM"
"Simplifying Medical Ultrasound: Third International Workshop, ASMUS 2022, Held in Conjunction with MICCAI 2022, Singapore, September 18, 2022, Proceedings","Left ventricular (LV) function is an important factor in terms of patient management, outcome, and long-term survival of patients with heart disease. The most recently published clinical guidelines for heart failure recognise that over reliance on only one measure of cardiac function (LV ejection fraction) as a diagnostic and treatment stratification biomarker is suboptimal. Recent advances in AI-based echocardiography analysis have shown excellent results on automated estimation of LV volumes and LV ejection fraction. However, from time-varying 2-D echocardiography acquisition, a richer description of cardiac function can be obtained by estimating functional biomarkers from the complete cardiac cycle. In this work we propose for the first time an AI approach for deriving advanced biomarkers of systolic and diastolic LV function from 2-D echocardiography based on segmentations of the full cardiac cycle. These biomarkers will allow clinicians to obtain a much richer picture of the heart in health and disease. The AI model is based on the ’nn-Unet’ framework and was trained and tested using four different databases. Results show excellent agreement between manual and automated analysis and showcase the potential of the advanced systolic and diastolic biomarkers for patient stratification. Finally, for a subset of 50 cases, we perform a correlation analysis between clinical biomarkers derived from echocardiography and cardiac magnetic resonance and we show a very strong relationship between the two modalities.","10.1007/978-3-031-16902-1_8","Conference","2022","keywords","ACM"
"An ensemble extended belief rule base decision model for imbalanced classification problems","","10.1016/j.knosys.2022.108410","Journal","2022","keywords","ACM"
"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society","The socialisation of Artificial Intelligence and the reality of an intelligence economy mark an epochal moment. The impacts of AI are now systemic - restructuring economic organisation and value chains, public sphere architectures and sociality. These shifts carry deep geo-political implications, reinforcing historical exclusions and power relations and disrupting the norms and rules that hold ideas of equality and justice together.At the centre of this rapid change is the intelligent corporation and its obsessive pursuit of data. Directly impinging on bodies and places, the de facto rules forged by the intelligent corporation are disenfranchising the already marginal subjects of development. Using trade deals to liberalise data flows, tighten trade secret rules and enclose AI-based innovation, Big Tech and their political masters have effectively taken away the economic and political autonomy of states in the global south. Big Tech's impunity extends to a brazen exploitation - enslaving labour through data over-reach and violating female bodies to universalise data markets. Thinking through the governance of AI needs new frameworks that can grapple with the fraught questions of data sovereignty, economic democracy, and institutional ethics in a global world with local aspirations. Any effort towards norm development in this domain will need to see the geo-economics of digital intelligence and the geo-politics of development ideologies as two sides of the same coin.","10.1145/3375627.3377139","Conference","2020","keywords","ACM"
"Innovative Technologies and Learning: Third International Conference, ICITL 2020, Porto, Portugal, November 23–25, 2020, Proceedings","This study aimed to investigate the commonality and differences among AI research and development (R&amp;D) guidelines across nations. Content analysis was conducted on AI R&amp;D guidelines issued by more economically developed countries because they may guide the trend of AI-based applications in education. Specifically, this study consisted of three phases: 1) information retrieval, (2) key term extraction, and (3) data visualization. First, Fisher’s exact test was employed to ensure that different AI R&amp;D guidelines (e.g., the latest ones in the US, EU, Japan, Mainland, and Taiwan) were comparable. Second, the Key Word Extraction System was developed to retrieve essential information in the guidelines. Third, data visualization techniques were performed on key terms across multiple guidelines. A word cloud revealed the similarity among guidelines (e.g., key terms that these guidelines share in common) while a color-coding scheme showed the differences (e.g., occurrence of a key term across guidelines and its frequency within a guideline). Importantly, three key terms, namely, AI, human, and development, are identified as essential commonality across guidelines. As for key terms that only extracted from particular guidelines, interestingly, results with the color-coding scheme suggested that these key terms were weighted differently depends on the developmental emphasis of a nation. Collectively, we discussed how these findings concerning ethics guidelines may shed light on AI research and development to educational technology.","10.1007/978-3-030-63885-6_33","Conference","2020","keywords","ACM"
"Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19","COVID-19 is a disease caused by a severe respiratory syndrome coronavirus. It was identified in December 2019 in Wuhan, China. It has resulted in an ongoing pandemic that caused infected cases including many deaths. Coronavirus is primarily spread between people during close contact. Motivating to this notion, this research proposes an artificial intelligence system for social distancing classification of persons using thermal images. By exploiting YOLOv2 (you look at once) approach, a novel deep learning detection technique is developed for detecting and tracking people in indoor and outdoor scenarios. An algorithm is also implemented for measuring and classifying the distance between persons and to automatically check if social distancing rules are respected or not. Hence, this work aims at minimizing the spread of the COVID-19 virus by evaluating if and how persons comply with social distancing rules. The proposed approach is applied to images acquired through thermal cameras, to establish a complete AI system for people tracking, social distancing classification, and body temperature monitoring. The training phase is done with two datasets captured from different thermal cameras. Ground Truth Labeler app is used for labeling the persons in the images. The proposed technique has been deployed in a low-cost embedded system (Jetson Nano) which is composed of a fixed camera. The proposed approach is implemented in a distributed surveillance video system to visualize people from several cameras in one centralized monitoring system. The achieved results show that the proposed method is suitable to set up a surveillance system in smart cities for people detection, social distancing classification, and body temperature analysis.","10.1007/s11554-021-01070-6","Journal","2021","keywords","ACM"
"Application of uncertainty quantification to artificial intelligence in healthcare: A review of last decade (2013–2023)","","10.1016/j.compbiomed.2023.107441","Journal","2024","keywords","ACM"
"Content-Aware AI-Driven Design Assistance Frameworks for Graphic Design Layouts","Designing user interfaces (UIs) for mobile interaction is widespread but still challenging. It is important for the overall user satisfaction and application success. During the design process, designers express their requirements through images describing the UI's layout, structure, and content. Designers, however, encounter key challenges throughout the design process. For example, searching for inspiring design examples is challenging because current search systems rely on only text-based queries and do not consider the UI structure and content. Furthermore, these systems often focus on overall page-level layout over individual UI components. Also, creating wireframe templates is difficult for many designers as it necessitates an understanding of different design guidelines. Therefore, it is critical to support designers by developing effective design tools to help them be more productive and creative.In this dissertation, I aim to explore how to develop design assistance methodologies to augment the process of UI layout design, with a particular focus on visual search and layout generation. Specifically, for this exploration, I seek to investigate the use of advanced deep learning models in the context of mobile UI layout design. Processing layouts differs from processing pixel-level images in that it necessitates processing both the semantic (e.g., labels) and spatial (e.g., coordinates) content of the layout to model the data properly. To achieve this, I explore the design problems from both the data and the model side. First, I present a large-scale UI dataset that accurately specifies the interface's view hierarchy (i.e., UI components and their location). Second, I contribute the VINS framework, which is composed of three systems LayVis, CompVis, and TransVis that addresses layout-based visual search, component-based visual search, and layout generation, respectively.First, I introduce LayVis, an object-detection layout-based retrieval model. It takes as input a UI image and retrieves visually similar design examples. Next, I introduce CompVis, a component-based visual search system to easily retrieve individual UI components via convolutional neural networks (CNNs). Specifically, for a given query, the system allows to retrieve (1) text label synonyms, (2) similar UI components, and (3) design examples containing such components. Finally, I present TransVis, a transformer-based generative framework that investigate how to generate UI layouts according to user specifications and following design practices. It specifically models UI layouts as an ordered sequence of elements based on spatial and semantic relationships for (1) generating complete UI layouts, (2) auto-completing existing UI layouts seamlessly, and (3) supporting many design elements per layout.Overall, the work presented in this dissertation contributes to augmenting the UI layout design. Through quantitative and qualitative evaluation of VINS, we conclude the following: (1) Advanced deep learning models can aid in the development of design assistance methodologies for layout design; and (2) Designers perceive the use of VINS inspiring and useful. Such insights, combined with the open-sourced large-scale dataset, can help the research community develop more effective AI-based data-driven design tools. This work presents future opportunities to investigate different deep learning models within the context of layout design and how designers interact with these AI-based models.","","Thesis","2021","keywords","ACM"
"Computers and Games: International Conference, CG 2022, Virtual Event, November 22–24, 2022, Revised Selected Papers","Online game providers face the challenge of preventing malicious users (cheaters) from breaking the rules and winning games through illegal means. This issue in particular plagues the online chess scene, where the strongest algorithms have long surpassed the world’s best players&nbsp;[4] – any cheater can beat the best human players through computer assistance. Moreover, recent developments in AI-based chess engines have opened the door to even more human-like engines&nbsp;[33], which are increasingly able to mimic legitimate human players. Unfortunately, because major chess websites do not discuss their cheat detection mechanisms publicly, there is limited scientific literature on how to tackle the pervasive problem of cheating in online chess. Certainly, there is no way to validate whether these mechanisms actually work.We take a first step towards formalizing a proper cheat detection framework for online chess by leveraging a large-scale statistical examination of human and computer decision-making tendencies over millions of chess games played online. Although cheaters are not engines (computer players) but centaurs (computer-assisted human players), the insights into computer play serve as a useful guideline for finding the strongest indicators of cheating. We then demonstrate how these findings may distinguish legitimate human players from cheaters in an automated, rules-based manner. Additionally, we argue that the status quo of hiding cheat detection mechanisms from the public eye is dangerous to the integrity of the game, and that cheat detection is foremost a service to society instead of a competitive advantage for chess websites to attract more users. Consistent with Kerckhoffs’ paradigm&nbsp;[24], we believe that the benefits of an open discussion on cheat detection far outweigh the potential drawbacks of cheaters learning about these methods.","10.1007/978-3-031-34017-8_14","Conference","2023","keywords","ACM"
"Socio-Technical Grounded Theory for Software Engineering","Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents &lt;italic&gt;Socio-Technical Grounded Theory&lt;/italic&gt; (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.","10.1109/TSE.2021.3106280","Journal","2022","keywords","ACM"
"How the different explanation classes impact trust calibration: The case of clinical decision support systems","","10.1016/j.ijhcs.2022.102941","Journal","2023","keywords","ACM"
"CADS-ML/DL: efficient cloud-based multi-attack detection system","With the increasing adoption of cloud computing, securing cloud-based systems and applications has become a critical concern for almost every organization. Traditional security approaches such as signature-based and rule-based have limited detection capabilities toward new and sophisticated attacks. To address this issue, there has been an increasing focus on implementing Artificial Intelligence (AI) in cloud security measures. In this research article, we present CADS-ML/DL, an efficient cloud-based multi-attack detection system. We investigate the effectiveness of Machine Learning (ML) and Deep Learning (DL) techniques for detecting cloud attacks. Our approach leverages a realistic dataset consisting of both benign and fourteen common attack network flows that meet real-world criteria on the AWS cloud platform. We evaluate eight Intrusion Detection Systems (IDSs) based on ML and DL algorithms, including Decision Tree (DT), Random Forest (RF), Extreme Gradient Boosting (XGBoost), Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM), Stacked LSTM, and Bidirectional LSTM (Bi-LSTM) models. Experimental results demonstrate that the CADS-ML/DL system, specifically the XGBoost model, outperforms the other models, exhibiting an accuracy of 0.9770 and a false error rate of 0.0230. Furthermore, we validate the effectiveness of our proposed XGBoost model on the AWS benchmark CSE-CICIDS2018 dataset, attaining a remarkable accuracy score of 0.9999 and an exceptionally low false error rate of 0.0001. Our findings suggest that AI-based approaches have the potential to detect cloud attacks effectively and contribute to the development of reliable and efficient IDSs for cloud security.","10.1007/s10207-023-00729-4","Journal","2023","keywords","ACM"
"Proceedings of the 1st Workshop on Software Engineering for Responsible AI","SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers' feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours.","10.1145/3526073.3527593","Conference","2023","keywords","ACM"
"Artificial intelligence-based personalized serious game for enhancing the physical and cognitive abilities of the elderly","","10.1016/j.future.2022.12.017","Journal","2023","keywords","ACM"
"Encrypted Network Traffic Classification and Resource Allocation with Deep Learning in Software Defined Network","The climate has changed absolutely in every area in just a few years as digitized, making high-speed internet service a significant need in the future. Future Internet is supposed to face exponential growth in traffic, and highly complicated infrastructure, threatening to make conventional NTC approaches unreliable and even counterproductive. In recent days, AI Stimulated state-of-the-art breakthroughs with the ability to tackle extensive and multifarious challenges, and the network community is initiated by considering the NTC prototype from legacy rule-based towards a novel AI-based. Design and execution are applied to interdisciplinary become more essential. A smart home network supports various applications and smart devices within the proposed work, including e-health devices, regular computing devices, and home automation devices. Many devices accessible through the Internet by Home GateWay for Congestion (HGC) in a smart home. Throughout this paper, a Software-Defined Network Home GateWay for Congestion (SDNHGC) architecture for improved management of remote smart home networks and protection of the significant network's SDN controller. It enables effective network capacity regulation, focused on real-time traffic analysis and core network resource allocation. It cannot control the Network in dispersed smart homes. Our innovative SDNHGC expands power across the connectivity network, a smart home network enabling improved end-to-end monitoring of networks. The planned SDNHGC directly will gain centralized device identification by classifying traffic through a smart home network. Several of the current traffic classifications approach, checking deep packets, cannot have this real-time device knowledge for encrypted data to solve this issue.","10.1007/s11277-021-08403-5","Journal","2021","keywords","ACM"
"Mapping research strands of ethics of artificial intelligence in healthcare: A bibliometric and content analysis","","10.1016/j.compbiomed.2021.104660","Journal","2021","keywords","ACM"
"Artificial Intelligence Based Customer Churn Prediction Model for Business Markets","The introduction of artificial intelligence (AI) and machine learning (ML) technologies in recent years has resulted in improved company performance. Customer churn forecast is a difficult problem in many corporate sectors, particularly the telecommunications industry. Because customer churns have a direct impact on a company's total revenue, telecommunications firms have begun to develop 76 models to reduce churns at an earlier stage. Previous research has revealed that AI and ML models are effective CCP solutions. According to this viewpoint, this study proposes a unique AI-based CCP model for Telecommunication Business Markets (AICCP-TBM). The AICCP-TBM model's purpose is to control the existence of churners and non-churners in the telecom sector. The proposed AICCP-TBM model employs a Chaotic Salp Swarm Optimization-based Feature Selection (CSSO-FS) method for the best feature assortment. In addition, a Fuzzy Rule-based Classifier(FRC) is used to distinguish between client churners and non-churners. A technique known as Quantum Behaved Particle Swarm Optimization (QPSO) is used to pick the membership functions for the FRC model in order to improve the classification performance of the FRC model. The performance of the AICCP-TBM model is validated using a benchmark CCP dataset and the experimental results are reviewed from several angles. In relations of presentation, the imitation consequences demonstrated that the AICCP-TBM model surpassed the most recent state-of-the-art CPP models. The suggested AICCP-TBM method's comparative accuracy was thoroughly tested on the three datasets used. Using datasets 1-3, this technique obtained better levels of accuracy, with the maximum attainable values being 97.25 %, 97.5 % and 94.33 %. The simulation results for the AICCP-TBM model demonstrated improved prediction performance.","10.1155/2022/1703696","Journal","2022","keywords","ACM"
"Transparency and explainability of AI systems: From ethical guidelines to requirements","","10.1016/j.infsof.2023.107197","Journal","2023","keywords","ACM"
"Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted TSK Fuzzy System","Artificial intelligence– (AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ε-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.","10.1145/3475870","Journal","2021","keywords","ACM"
"Cyber-Physical Security for Critical Infrastructures Protection: First International Workshop, CPS4CIP 2020, Guildford, UK, September 18,  2020, Revised Selected Papers","Over the past decade, there has been unprecedented advancements in the field of computer vision by adopting AI-based solutions. In particular, cutting edge computer vision technology based on deep-learning approaches has been deployed with an extraordinary degree of success. The ability to extract semantic concepts from continuous processing of video stream in real-time has led to the investigation of such solutions to enhance the operational security of critical infrastructure against intruders. Despite the success of computer vision technologies validated in a laboratory environment, there still exists several challenges that limit the deployment of these solutions in operational environment. Addressing these challenges, the paper presents a framework that integrates three main computer vision technologies namely (i) person detection; (ii) person re-identification and (iii) face recognition to enhance the operational security of critical infrastructure perimeter. The novelty of the proposed framework relies on the integration of key technical innovations that satisfies the operational requirements of critical infrastructure in using computer vision technologies. One such requirement relates to data privacy and citizen rights, following the implementation of General Data Protection Regulation across Europe for the successful adoption of video surveillance for infrastructure security. The video analytics solution proposed in the paper integrates privacy preserving technologies, high-level rule engine for threat identification and a knowledge model for escalating threat categorises to human operator. The various components of the proposed framework has been validated using commercially available graphical processing units for detecting intruders. The performance o the proposed framework has been evaluated in operational environments of the critical infrastructure. An overall accuracy of 97% is observed in generating alerts against malicious intruders.","10.1007/978-3-030-69781-5_8","Conference","2020","keywords","ACM"
"Systematic Analysis of Artificial Intelligence-Based Platforms for Identifying Governance and Access Control","Artificial intelligence (AI) has become omnipotent with its variety of applications and advantages. Considering the other side of the coin, the eruption of technology has created situations that need more caution about the safety and security of data and systems at all levels. Thus, to hedge against the growing threats of cybersecurity, the need for a robust AI platform supported by machine learning and other supportive technologies is well recognized by organizations. AI is a much sought-after topic, and there is extolling literature available in repositories. Hence, a systematic arrangement of the literature that can help identify the right AI platform that can provide identity governance and access control is the need of the hour. Having this background, the present study is commissioned a Systematic Literature Review (SLR) to accomplish the necessity. Literature related to AI and Identity and Access Management (IAM) is collected from renowned peer-reviewed digital libraries for systematic analysis and assessment purposes using the systematic review guidelines. Thus, the final list of articles relevant to the framed research questions related to the study topic is fetched and is reviewed thoroughly. For the proposed systematic research work, the literature reported during the period ranging from 2016 to 2021 (a portion of 2021 is included) is analyzed and a total of 43 papers were depicted more relevant to the selected research domain. These articles were accumulated from ProQuest, Scopus, Taylor &amp; Franics, Science Direct, and Wiley online repositories. The article's contribution can supplement the AI-based IAM information and steer the entities of diverse sectors concerning seamless implementation. Appropriate suggestions are proposed to encourage research work in the required fields.","10.1155/2021/8686469","Journal","2021","keywords","ACM"
"Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering","The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN’s practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN’s software system. In particular, we focus on GURI, CRN’s medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster’s black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI’s code. Concerning domain-specific coverage, EvoMaster’s black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster’s black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context.","10.1145/3611643.3613882","Conference","2023","keywords","ACM"
"Immune moral models? Pro-social rule breaking as a moral enhancement approach for ethical AI","We are moving towards a future where Artificial Intelligence (AI) based agents make many decisions on behalf of humans. From healthcare decision-making to social media censoring, these agents face problems, and make decisions with ethical and societal implications. Ethical behaviour is a critical characteristic that we would like in a human-centric AI. A common observation in human-centric industries, like the service industry and healthcare, is that their professionals tend to break rules, if necessary, for pro-social reasons. This behaviour among humans is defined as pro-social rule breaking. To make AI agents more human-centric, we argue that there is a need for a mechanism that helps AI agents identify when to break rules set by their designers. To understand when AI agents need to break rules, we examine the conditions under which humans break rules for pro-social reasons. In this paper, we present a study that introduces a ‘vaccination strategy dilemma’ to human participants and analyzes their response. In this dilemma, one needs to decide whether they would distribute COVID-19 vaccines only to members of a high-risk group (follow the enforced rule) or, in selected cases, administer the vaccine to a few social influencers (break the rule), which might yield an overall greater benefit to society. The results of the empirical study suggest a relationship between stakeholder utilities and pro-social rule breaking (PSRB), which neither deontological nor utilitarian ethics completely explain. Finally, the paper discusses the design characteristics of an ethical agent capable of PSRB and the future research directions on PSRB in the AI realm. We hope that this will inform the design of future AI agents, and their decision-making behaviour.","10.1007/s00146-022-01478-z","Journal","2022","keywords","ACM"
"Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining","Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling.As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks.In this tutorial, we will present an overview of model interpretability and explainability in AI, key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community.","10.1145/3292500.3332281","Conference","2019","keywords","ACM"
"Health Information Science: 11th International Conference, HIS 2022, Virtual Event, October 28–30, 2022, Proceedings","Background: With the development of Internet, many people with suicide risk tend to express their thoughts on social media platforms. AI-based model can early identify social media users with suicide risk and analyze their cognitive and interpersonal characteristics. Then we can do early intervention to help them.Objective: To build an automatic crisis balance analysis model based on artificial intelligence which can perform automatic early suicide identification, suicide risk classification and analyze cognitive distortion and interpersonal relationship of users. Then to validate the predictive efficiency of model.Method: Firstly, based on the suicide knowledge graph, free annotation data set was generated and then Bert-based model was built. Secondly, the data set was refined by psychology students and experts to build fine-tuning model and Psychology+ model. The Psychology+ model was used as final suicide risk assessment model. We enriched and quantified the variables of cognitive and interpersonal characteristics and built the cognitive distortion and interpersonal relationship analysis model. Using F1 score, precision, recall and accuracy to evaluate the model performance and the consistence of model results with expert judgment and scales results to evaluate the model prediction ability.Results: For the suicide risk assessment model, the F1 score, precision, recall rate and accuracy rate of the model are 77.98%, 80.75%, 75.41% and 78.68% respectively. For the cognitive distortion and interpersonal relationship analysis model, the F1 score, accuracy and recall rate of the model are 77.26%, 78.22% and 76.33% respectively. Comparing the results with the results of the scale by chi square test, there was no significant difference in cognitive distortion(P ","10.1007/978-3-031-20627-6_17","Conference","2022","keywords","ACM"
"Trustworthy artificial intelligence in Alzheimer’s disease: state of the art, opportunities, and challenges","Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017–2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer’s Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain.","10.1007/s10462-023-10415-5","Journal","2023","keywords","ACM"
"Karstified zone interpretation using deep learning algorithms: Convolutional neural networks applications and model interpretability with explainable AI","","10.1016/j.cageo.2022.105281","Journal","2023","keywords","ACM"
"SEFAIS '18: Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems","Autonomous systems have been a subject of computer science research for many years. Recent advances in hardware and in artificial intelligence have brought autonomous systems within the reach of product development. For example, most major carmakers are working on autonomous driving.During the early years of autonomous systems research, the focus has been on making autonomous functionality possible in the first place. As we move closer to building end-user products, software engineering concerns are becoming at least equally important. Most conventional embedded software products are built on rule-based control engineering approaches. The corresponding software engineering practices are mature and well understood. For autonomous systems, however, the conventional control engineering approaches are extended by modern artificial intelligence techniques, in particular, machine learning. The corresponding product software engineering approaches are less well understood and need attention.The 2018 ACM/IEEE 1st International Workshop on Software Engineering for AI in Autonomous Systems (SEFAIAS 2018) focuses on software engineering and software architecture approaches that achieve the usual software engineering goals, such as quality, maintainability, scalability, robustness, safety, etc., for systems that are built using a combination of conventional embedded software development and AI. Since many of the relevant techniques are just about to move from the research stage to the product development stage, many of the software engineering ideas and approaches will benefit from the typical ""idea/work in progress"" discussions that are enabled by this workshop.We want to bring together researchers and practitioners to form a community that shares common interests in building robust autonomous systems. In particular, for the application domain of autonomous driving, our goal is to better understand the techniques necessary to verify and validate AI-based autonomous systems, ensure their robustness, safety, security, and other important system properties, in general. To this end, we have grouped three of the workshop contributions to form a special session on the verification of autonomous driving.","","Proceedings","2018","keywords","ACM"
"Low back pain expert systems: Clinical resolution through probabilistic considerations and poset","","10.1016/j.artmed.2021.102163","Journal","2021","keywords","ACM"
"Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges.In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.","10.1145/3534678.3542617","Conference","2022","keywords","ACM"
"Designing AI Experiences: Boundary Representations, Collaborative Processes, and Data Tools","Artificial Intelligence (AI) has transformed our everyday interactions with technology through automation, intelligence augmentation, and human-machine partnership. Nevertheless, we regularly encounter undesirable and often frustrating experiences due to AI. A fundamental challenge is that existing software practices for coordinating system and experience designs fall short when creating AI for diverse human needs, i.e., ``human-centered AI'' or HAI. ``AI-first'' development workflows allow engineers to first develop the AI components, and then user experience (UX) designers create end-user experiences around the AI's capabilities. Consequently, engineers encounter end-user blindness when making critical decisions about AI training data needs, implementation logic, behavior, and evaluation. In the conventional ``UX-first'' process, UX designers lack the needed technical understanding of AI capabilities (technological blindness) that limits their ability to shape system design from the ground up. Human-AI design guidelines have been offered to help but neither describe nor prescribe ways to bridge the gaps in needed expertise in creating HAI.  In this dissertation, I investigate collaboration approaches between designers and engineers to operationalize the vision for HAI as technology inspired by human intelligence that augments human abilities while addressing societal needs. In a series of studies combining technical HCI research with qualitative studies of AI production in practice, I contribute (1) an approach to software development that blurs rigid design-engineering boundaries, (2) a process model for co-designing AI experiences, and (3) new methods and tools to empower designers by making AI accessible to UX designers. Key findings from interviews with industry practitioners include the need for ``leaky'' abstractions shared between UX and AI designers. Because modular development and separation of concerns fail with HAI design, leaky abstractions afford collaboration across expertise boundaries and support human-centered design solutions through vertical prototyping and constant evaluation. Further, by observing how designers and engineers collaborate on HAI design in an in-lab study, I highlight the role of design `probes' with user data to establish common ground between AI system and UX design specifications, providing a critical tool for shaping HAI design. Finally, I offer two design methods and tool implementations --- Data-Assisted Affinity Diagramming and Model Informed Prototyping --- for incorporating end-user data into HAI design. HAI is necessarily a multidisciplinary endeavor, and human data (in multiple forms) is the backbone of AI systems. My dissertation contributions inform how stakeholders with differing expertise can collaboratively design AI experiences by reducing friction across expertise boundaries and maintaining agency within team roles. The data-driven methods and tools I created provide direct support for software teams to tackle the novel challenges of designing with data. Finally, this dissertation offers guidance for imagining future design tools for human-centered systems that are accessible to diverse stakeholders.","","Thesis","2021","keywords","ACM"
"Efficient Combination of Neural and Symbolic Learning for Relational Data","Much has been achieved in AI but to realize its true potential, it is imperative that the AI system should be able to learn generalizable and actionable higher-level knowledge from lowest level percepts. Inspired by this goal, neuro-symbolic systems have been developed for the past four decades. These systems encompass the complementary strengths of fast adaptive learning of neural networks from low-level input signals and the deliberative, generalizable models of the symbolic systems. The advent of deep networks has accelerated the development of these neuro-symbolic systems. While successful, there are several open problems to be addressed in these systems, a few of which we tackle in this dissertation. These include: (i) several primitive neural network architectures have not been well studied in the symbolic context; (ii) lack of generic neuro-symbolic architectures that are do not make distributional assumptions; (iii) generalization abilities of many such systems are limited. The objective of this dissertation is to develop novel neuro-symbolic models that (i) induce symbolic reasoning capabilities to fundamental yet unexplored neural network architectures, and (ii) provide unique solutions to the generalization issues that occur during neuro-symbolic integration.More specifically, we consider one of the primitive models, Restricted Boltzmann Machines, that was originally employed for pre-training the deep neural networks and propose two unique solutions to lift them for relational model. For the first solution, we employ relational random walks to generate relational features for Boltzmann machines. We train the Boltzmann machines by passing these resulting features through a novel transformation layer. For the second solution, we employ the mechanism of functional gradient boosting to learn the structure and the parameters of the lifted Restricted Boltzmann Machines simultaneously. Next, most of the neuro-symbolic models designed till date have focused on incorporating neural capabilities in specific models, resulting in lack of a general relational neural network architecture. To overcome this, we develop a generic neuro-symbolic architecture that exploits the concept of relational parameter tying and combining rules to incorporate the first-order logic rules into the hidden layers of the proposed architecture. One of the prevalent neuro-symbolic models called knowledge graph embedding models encode the symbols as learnable vectors in Euclidean space and lose an important characteristic of generalizability to newer symbols while doing so. We propose two unique solutions to circumvent this problem by exploiting the text description of entities in addition to the knowledge graph triples in both the models. In our first model, we train both the text and knowledge graph data in generative setting, while in the second model, we posit the two data sources in adversarial setting. Our broad results across these several directions demonstrate the efficacy and efficiency of the proposed approaches on benchmarks and novel data sets.In summary, this dissertation takes one of the first steps towards realizing the grand vision of the neuro-symbolic integration by proposing novel models that allow for symbolic reasoning capabilities inside neural networks.","","Thesis","2020","keywords","ACM"
"Personalized Prostate Cancer Management : Ai-Assisted Prostate Pathology and Improved Active Surveillance","Prostate cancer is a major global health concern and is the most common cancer-related causeof death in Sweden. Prostate cancer screening using PSA has been shown to reduce prostatecancer mortality but also leads to significant overdiagnosis and overtreatment of low-risk cancers.Improved risk stratification and effective active surveillance are crucial to balancing thebenefits of screening with the risk of overdiagnosis and overtreatment.In Study I, we studied the uptake and the follow-up of active surveillance using a retrospectivecohort of patients who were diagnosed with low-risk prostate cancer between 2008 and 2017in Stockholm County. Our results showed that only 50% of eligible active surveillance patientsreceived active surveillance as their primary treatment choice at diagnosis. Most men thatenrolled in active surveillance remained on surveillance during the first years after diagnosis(82% during a median 3.5 years), but did not receive a follow up according to guidelines withregard to repeat biopsies and PSA tests.Current clinical practice has seen an increase in the use of magnetic resonance imaging (MRI)and the incorporation of risk prediction models to select men with the highest suspicion of clinicallysignificant prostate cancer for prostate biopsy. However, the effectiveness and how MRIand risk prediction models should be incorporated into active surveillance follow-up have yet tobe established. Study II evaluated the performance of MRI-targeted biopsies and a blood-basedrisk prediction model (the Stockholm3 test) for monitoring disease progression in patients onactive surveillance and compared this to the conventional follow-up using PSA and systematicbiopsies. When MRI-targeted and systematic biopsies were combined, the detection rateof clinically significant prostate cancer increased when compared to conventional systematicbiopsies. Biopsies performed in MRI-positive men resulted in a 49% reduction in performedbiopsies, at the expense of failing to diagnose 1.4% clinically significant prostate cancer in MRInegativemen. The incorporation of the Stockholm3 test showed a 27% reduction in requiredMRI investigations and a 57% reduction in performed biopsies compared to performing onlysystematic biopsies.In Study III, we digitized biopsy cores from STHLM3 participants to develop an artificialintelligence (AI) for prostate cancer diagnostics. The AI system demonstrated clinically usefulperformance that was comparable to that of the study pathologist for cancer detection (AUCof 0.986) and for predictions of cancer length (correlation of 0.87) and grading performancethat was on par with that of expert prostate pathologists.In Study IV, we developed a conformal predictor to estimate the uncertainty of the predictionsfor the model in Study III. The uncertainty estimates were used to control the error rate so thatonly predictions with high confidence are accepted and unreliable predictions can be detected.The conformal predictor was able to identify unreliable predictions as a result of variations indigital pathology scanners, preparation of tissue in different pathology laboratories, and theexistence of unusual prostate tissue that the AI model was not exposed to during training.Little is known about the relationships between prostate cancer genetic risk factors and themorphology of prostate tissue. In Study V:, we investigated whether weakly supervised deeplearning can learn to detect such possible associations. The findings in this paper imply relationshipsbetween prostatic tissue morphology and genetic risk factors for prostate cancer,particularly in young men. These results provide proof of principle for exploring the use ofmorphological information in multi-modal prostate cancer risk prediction algorithms.In conclusion, the purpose of this thesis was to describe possible extensions to improve prostatecancer active surveillance management, as well as to develop prediction models for improvedprostate cancer diagnostics.","","Thesis","2023","keywords","ACM"
"An Explainable Artificial Intelligence Approach Based on Deep Type-2 Fuzzy Logic System","Artificial intelligence (AI) systems have benefitted from the easy availability of computing power and the rapid increase in the quantity and quality of data which has led to the widespread adoption of AI techniques across a wide variety of fields. However, the use of complex (or Black box) AI systems such as Deep Neural Networks, support vector machines, etc., could lead to a lack of transparency. This lack of transparency is not specific to deep learning or complex AI algorithms; other interpretable AI algorithms such as kernel machines, logistic regressions, decision trees, or rules-based algorithms can also become difficult to interpret for high dimensional inputs. The lack of transparency or explainability reduces the effectiveness of AI models in regulated applications (such as medical, financial, etc.), where it is essential to explain the model operation and how it arrived at a given prediction. The need for explainability in AI has led to a new line of research that focuses on developing Explainable AI techniques. There are three main avenues of research that are being explored to achieve explainability; first, Deep Explanations, which involves the modification of existing Deep learning models to add explainability. The methods proposed to do Deep explanations generally provide details about all the input features that affect the output, generally in a visual format as there might be a large number of features. This type of explanation is useful for tasks such as image recognition, but in other tasks, it might be hard to distinguish the most important features. Second, Model induction, which involves methods that are model agnostic, but these methods might not be suitable for use in regulated applications. The third method is to use existing interpretable models such as decision trees, fuzzy logic, etc., but the problem with them is that they can also become opaque for high dimensional data. Hence, this thesis presents a novel AI system by combining the predictive power of Deep Learning with the interpretability of Interval Type-2 Fuzzy Logic Systems. The advantages of such a system are, first, the ability to be trained via labelled and unlabelled data (i.e., mixing supervised and unsupervised learning). Second, having embedded feature selection abilities (i.e., can be trained by hundreds and thousands of inputs with no need for feature selection) while delivering explainable models with small rules bases composed of short rules to maximize the model's interpretability. The proposed model was developed with data from British Telecom (BT). It achieved comparable performance to the deep models such as Stacked Autoencoder (SAE) and Convolution Neural Networks (CNN). In categorical datasets, the model outperformed the SAE by 2%, performed within 2-3% of the CNN and outperformed Multi-Layer Perceptron (MLP) and IT2FLS by 4%. In the regression datasets, the model performed slightly worse than the SAE, MLP and CNN models, but it outperformed the IT2FLS with a 15% lower error. The proposed model achieved excellent interpretability in a survey where it was rated within 2% of the highly interpretable IT2FLS. It was also rated 20% and 17% better than Deep learning XAI tools LIME and SHAP, respectively. The proposed model shows a small loss in performance for significantly higher interpretability, making it a suitable replacement for the other AI models in applications with many features where interpretability is paramount.","","Thesis","2021","keywords","ACM"
"Resilient Operation of Active Distribution Networks via Self-Learning Smart Devices","This dissertation focuses on developing Artificial Intelligence (AI)-based and self-healing control techniques to enhance the resiliency of active distribution networks for upcoming power grid challenges. In the first stage of this work, a high bandwidth primary control layer is developed to achieve an ultra-fast predictive controlled dual active bridge converter interfaced grid-following inverter for voltage and frequency support. The primary control layer is developed by a novel model predictive self-healing control (MPSC) scheme. This control technique heals intrinsic drawbacks in commonly used control approaches by decreasing the potential errors in the control processes. However, the frequency restoration process needs more advanced techniques due to the high nonlinearity of the active distribution networks such as power electronic dominated grids (PEDG). Therefore, an artificial intelligence-based power reference correction (AI-PRC) mechanism is developed to address the shortcomings of frequency restoration of the state-of-the-art virtual synchronous generator (VSG)-based or droop-based grid following inverters (GFLIs) and grid forming inverters (GFMIs) via re-defining GFLI role at grid-edge. A detailed analytical validation is provided that shows control rules in PEDG intrinsically follow the underlying dynamic of the swing-based machines to extend its stability boundary. Considering this fact, comprehensive transient and steady state-based mathematical models are used for constructing the learning database of the proposed AI-PRC mechanism. Subsequently, a neural network is trained by Bayesian Regularization Algorithm (BRA) to realize the proposed AI-PRC for GFLIs. The proposed training approach can deal with all grid characteristics alterations and uncertainties. Thus, this approach incorporates all PEDG's effective variables that shape its dynamic response during transient disturbances. Several simulations and experimental case studies were provided that evaluate the functionality of the proposed AI-PRC for GFLIs towards enhancing transient response and resiliency of PEDG. The provided evaluations demonstrate significant improvement in frequency restoration in response to transient disturbances.Moreover, the proposed control technique is exploited as a shadow controller in the case that the attacker aims to threaten the entire grid stability via stealthy attacks. Some stealthy attack scenarios are investigated on the 14-bus PEDG, and the results have proven the effectiveness of the proposed approach in fast supporting of the grid in the event of stealthy attacks, thus the grid resiliency is enhanced in this case as well.Due to the high importance of power grid resiliency, in the final stage of this work, an intrusion detection system (IDS) is developed to provide another layer of security that monitors grid dynamics and vital variables in other time scales. The groundwork of this technique is based on a load forecasting procedure that benefits from an artificial intelligence approach. In more details, an anomaly detection technique based on a condition monitoring vector and ultra-short demand forecasting is designed and developed for achieving the above-mentioned goals. The designed IDS is more robust against attack scenarios that could bypass other primary control layers. Thus, the proposed approach enables grid operators to take proper and prompt actions for providing a secure operation of the grid.","","Thesis","2022","keywords","ACM"
"Bridging the Gap: Vision-Inspired Two-Phase Heat Transfer Analysis","Liquid-vapor phase-change phenomena have been critical to maintaining sustainable and habitable environments on Earth for countless millennia, and are continuing to play central roles in present-day's industries with ever growing presence. Among different types of phase-change processes, boiling and condensation are two of the most widely used in both domestic and industrial applications. Central to the mechanistic understanding of the thermofluidic processes governing the phase-change phenomena is the rapid and high-fidelity extraction of interpretable physical descriptors from the highly-transient nucleation behaviors. However, extracting quantifiable measures out of dynamic objects with conventional imaging technologies poses a challenge to researchers. This thesis focuses on addressing the fundamentally weak connection between phase-change heat and mass transfer and nucleation statistics available in visual data streams. We outline core ideas of current artificial intelligence (AI) technologies connected to thermal energy science to illustrate how they can be used to push the limit of our knowledge boundaries about boiling and condensation physics. The comprehensive review offers insight into the role of recent advances in AI and computer vision in advancing modern boiling and condensation research. Based on foundational literature analysis and problem definition, the remainder of the thesis proposes various AI-based solutions for connecting visual data streams with heat and mass transfer performances at the device and system level. First, we introduce a data-driven learning framework that correlates high-quality imaging on dynamic bubbles with associated boiling curves. The framework leverages cutting-edge machine learning models including convolutional neural networks and object detection algorithms to automatically extract both hierarchical and physics-based features. By training on these features, our model learns physical boiling laws that statistically describe the manner in which bubbles nucleate, coalesce, and depart under boiling conditions, enabling in situ boiling curve prediction with a mean error of 6%. Our framework offers an automated, learning-based, alternative to conventional boiling heat transfer metrology. Next, we demonstrate an intelligent vision-based framework called Vision Inspired Online Nuclei Tracker (VISION-iT), which unites classical thermofluidic imaging techniques with deep learning to fundamentally address the challenge of extracting high-fidelity interpretable physical descriptors for the highly-transient two-phase processes. We introduce and discuss the detailed construction, algorithms, and optimization guidelines of individual modules so that the framework can easily be adjusted to custom datasets. The concepts and procedures that we propose is transferable, and thus can benefit a broader audience dealing with similar problems. Finally, VISION-iT is deployed in practical phase-change heat transfer analysis applications. For boiling applications, the combined efforts of materials design, deep learning techniques, and data-driven approach shed light on the mechanistic relationship between vapor/liquid pathways, bubble statistics, and phase change performance. For condensation applications, the data-centric analysis enabled by VISION-iT conclusively shows that contrary to classical understanding, the overall condensation performance is governed by a key trade-off between heat transfer rate per individual droplet and droplet population density. Our vision-based approach presents a powerful tool for the study of not only phase-change processes but also any nucleation-based process within and beyond the thermal science community through the harnessing of big data.","","Thesis","2022","keywords","ACM"
"Design Principles for User Interfaces in AI-Based Decision Support Systems: The Case of Explainable Hate Speech Detection","Hate speech in social media is an increasing problem that can negatively affect individuals and society as a whole. Moderators on social media platforms need to be technologically supported to detect problematic content and react accordingly. In this article, we develop and discuss the design principles that are best suited for creating efficient user interfaces for decision support systems that use artificial intelligence (AI) to assist human moderators. We qualitatively and quantitatively evaluated various design options over three design cycles with a total of 641 participants. Besides measuring perceived ease of use, perceived usefulness, and intention to use, we also conducted an experiment to prove the significant influence of AI explainability on end users’ perceived cognitive efforts, perceived informativeness, mental model, and trustworthiness in AI. Finally, we tested the acquired design knowledge with software developers, who rated the reusability of the proposed design principles as high.","10.1007/s10796-021-10234-5","Journal","2022","keywords","ACM"
"Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology","With the development of the Internet, “Internet Plus” has been widely used in various fields, and the Internet has become a great opportunity to transform CET. People’s demand for education, especially higher education, has also increased rapidly. With the attention and investment of the state in recent years, higher education has developed rapidly, accounting for half of China’s higher education. However, the increase in the number of students has brought great pressure to CET. How to improve the teaching efficiency of large classes is an urgent problem to be solved. The development of sci and tech, especially computer, has brought us new hope. Computer-assisted instruction has been introduced into CET. However, there are some unreasonable points in the design of computer-aided marking system in China, which is not suitable for CET. It is very important to research and design a computer-aided marking system that can expand CET methods and maximize the integration of English instructional resources. This paper introduces the principle, characteristics, and application fields of AI; analyzes the problems faced by CET; and puts forward a CET path based on computer-aided technology.","10.1155/2022/9913450","Journal","2022","keywords","ACM"
"Design of AI System for National Fitness Sports Competition Action Based on Association Rules Algorithm","In information system construction, online data migration is a very important link. At present, in different fields, people provide protection for online data migration through the way of project management to ensure the speed and efficiency of online migration. However, some problems may occur in the process of online data migration. In the development of contemporary sports, competitive sports, as the high-end stage of sports development, are constantly pursued by ordinary sports enthusiasts. Therefore, in the national fitness activities, how to combine the national fitness and competitive sports data to provide a more professional storage platform is a focus of research but also a problem to be solved in the process of online data migration. Because the data mining ID3 algorithm only supports querying and retrieving RowKey indexes, it does not support non-RowKey column indexing. Therefore, if you want to query non-RowKey indexes, the data mining ID3 algorithm will search the form in the overall scan, but the performance of this method is low. In order to improve the query speed of non-RowKey columns, this paper designs a secondary index function based on HBase. The sports competition action system can retrieve data from the secondary index of the query state, to avoid scanning the whole world and improve the search speed. In this paper, ID3 algorithm is used to combine national fitness and competitive sports data, which provides a guarantee for the migration of competitive sports data in the national fitness system.","10.1155/2022/1375009","Journal","2022","keywords","ACM"
"Retracted: Rule-Based AI System Application on College English Teaching Path Based on Computer-Aided Technology","","10.1155/2023/9758670","Journal","2023","keywords","ACM"
"Document Title","Abstract","DOI","Document Identifier","Publication Year","","IEEE"
"An AI-Based Heart Failure Treatment Adviser System","Management of heart failure is a major health care challenge. Healthcare providers are expected to use best practices described in clinical practice guidelines, which typically consist of a long series of complex rules. For heart failure management, the relevant guidelines are nearly 80 pages long. Due to their complexity, the guidelines are often difficult to fully comply with, which can result in suboptimal medical practices. In this paper, we describe a heart failure treatment adviser system that automates the entire set of rules in the guidelines for heart failure management. The system is based on answer set programming, a form of declarative programming suited for simulating human-style reasoning. Given a patient's information, the system is able to generate a set of guideline-compliant recommendations. We conducted a pilot study of the system on 21 real and 10 simulated patients with heart failure. The results show that the system can give treatment recommendations compliant with the guidelines. Out of 187 total recommendations made by the system, 176 were agreed upon by the expert cardiologists. Also, the system missed eight valid recommendations. The reason for the missed and discordant recommendations seems to be insufficient information, differing style, experience, and knowledge of experts in decision-making that were not captured in the system at this time. The system can serve as a point-of-care tool for clinics. Also, it can be used as an educational tool for training physicians and an assessment tool to measure the quality metrics of heart failure care of an institution.","10.1109/JTEHM.2018.2883069","IEEE Journals","2018","","IEEE"
"Robust AI-enabled Simulation of Treatment Paths with Markov Decision Process for Breast Cancer Patients","Development in AI/ML-based methodologies has facilitated improvement in clinical decision making at various stages of treatment in breast cancer care. While this addresses patient needs at specific stages of treatment, the overall treatment path of a patient from a holistic standpoint has remained understudied due to challenges in accessing the relevant data. In this study, we propose to develop an AI-enabled treatment path simulation for breast cancer patients while characterizing the treatment paths as a Markov decision process (MDP). In order to avoid the limitations of healthcare records, which are often incomplete and subject to misinformation, we have leveraged clinical practice guidelines and expertise from physicians at Moffitt Cancer Center to develop the MDP. Our study of developing such an MDP, leveraging domain knowledge, contributes to improving research on treatment path simulation for breast cancer patients.","10.1109/CAI54212.2023.00053","IEEE Conferences","2023","","IEEE"
"Challenges in Machine Learning Application Development: An Industrial Experience Report","SAP is the market leader in enterprise application software offering an end-to-end suite of applications and services to enable their customers worldwide to operate their business. Especially, retail customers of SAP deal with millions of sales transactions for their day-to-day business. Transactions are created during retail sales at the point of sale (POS) terminals and those transactions are then sent to some central servers for validations and other business operations. A considerable proportion of the retail transactions may have inconsistencies or anomalies due to many technical and human errors. SAP provides an automated process for error detection but still requires a manual process by dedicated employees using workbench software for correction. However, manual corrections of these errors are time-consuming, labor-intensive, and might be prone to further errors due to incorrect modifications. Thus, automated detection and correction of transaction errors are very important regarding their potential business values and the improvement in the business workflow. In this paper, we report on our experience from a project where we develop an AI-based system to automatically detect transaction errors and propose corrections. We identify and discuss the challenges that we faced during this collaborative research and development project, from two distinct perspectives: Software Engineering and Machine Learning. We report on our experience and insights from the project with guidelines for the identified challenges. We collect developers’ feedback for qualitative analysis of our findings. We believe that our findings and recommendations can help other researchers and practitioners embarking into similar endeavours. CCS CONCEPTS • Software and its engineering → Programming teams.","10.1145/3526073.3527593","IEEE Conferences","2022","","IEEE"
"Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study","Background: With the rising popularity of Artificial Intelligence (AI), there is a growing need to build large and complex AI-based systems in a cost-effective and manageable way. Like with traditional software, Technical Debt (TD) will emerge naturally over time in these systems, therefore leading to challenges and risks if not managed appropriately. The influence of data science and the stochastic nature of AI-based systems may also lead to new types of TD or antipatterns, which are not yet fully understood by researchers and practitioners. Objective: The goal of our study is to provide a clear overview and characterization of the types of TD (both established and new ones) that appear in AI-based systems, as well as the antipatterns and related solutions that have been proposed. Method: Following the process of a systematic mapping study, 21 primary studies are identified and analyzed. Results: Our results show that (i) established TD types, variations of them, and four new TD types (data, model, configuration, and ethics debt) are present in AI-based systems, (ii) 72 antipatterns are discussed in the literature, the majority related to data and model deficiencies, and (iii) 46 solutions have been proposed, either to address specific TD types, antipatterns, or TD in general. Conclusions: Our results can support AI professionals with reasoning about and communicating aspects of TD present in their systems. Additionally, they can serve as a foundation for future research to further our understanding of TD in AI-based systems.","10.1109/TechDebt52882.2021.00016","IEEE Conferences","2021","","IEEE"
"Advancing Trustworthy Knowledge Engineering through User-Centered AI-based Systems: A Systematic Review","This document is a model and instructions for LATEX. This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, or Math in Paper Title or Abstract.","10.1109/AIKE59827.2023.00018","IEEE Conferences","2023","","IEEE"
"Designing User-friendly Medical AI Applications - Methodical Development of User-centered Design Guidelines","Medical artificial intelligence (AI) applications will become increasingly relevant in the future and change the medical technology market. Areas of application are located in the professional as well as in private use. The human-machine interface (HMI) is crucial for a successful use of these AI technologies and for a high user added value. The factors of user experience, usability and joy of use significantly determine the quality of an HMI, but are still insufficiently researched for medical AI applications. This work addresses this gap and provides generally applicable design guidelines to AI-based mobile medical applications. For this purpose, a user-centered requirements analysis was conducted to evaluate possible HMI concepts for a fictitious medical AI application. Based on these findings, specific design guidelines for the HMI of the fictitious application were established. Finally, a universal design catalog for medical AI applications was developed.","10.1109/ICDH55609.2022.00011","IEEE Conferences","2022","","IEEE"
"Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems","High data quality is fundamental for today’s AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.","10.1145/3522664.3528590","IEEE Conferences","2022","","IEEE"
"Designing Cybersecurity AI Based Awareness Games for Citizens: Best Practices and Future Directions","Cybercrimes are a hazard to both people and businesses. Knowing the best techniques for cyber security is essential for defending against these threats. Despite their ability to be useful, conventional learning techniques like reading articles or attending seminars lack interest. Because of this, employing serious games for education is growing in popularity. Serious games give players an involved learning experience while educating them on a subject, like cyber security. In order to give players a useful understanding to defend themselves, this study investigates the best approaches for embedding cyber security education into serious games. Learning about cyber security is made enjoyable and more relevant by using a game-based methodology. In order to evaluate how game design aspects might be utilized to effectively instruct players on cyber security, the paper examines a variety of game design elements, including game mechanics, narrative, and feedback mechanisms. Additionally, it goes into how different players, such as novice and experienced players, might be catered to in serious games. In general, playing serious games is a fun and effective approach to educate yourself about cyber security. Designers and teachers can produce games that are both enjoyable and instructional by adhering to the quality standards described in this paper.","10.1109/ICSCDS56580.2023.10104800","IEEE Conferences","2023","","IEEE"
"AI-based Research and Application of Fault Diagnosis for Steam Turbine Regenerative System","As the key equipment of electric power plant, the safe operation of steam turbine plays a vital role in practical production. At the same time, the normal and stable operation of excitation system, water-oxygen cooling system, regenerative system and other set system also play a decisive role in the safe operation of the unit. Fault diagnosis in the past mainly relied on the domain experts to judge the type of fault based on its experience, which has too much limitation, it is difficult to make effective diagnosis for the unconspicuous fault. The paper analyzed the common failures of the steam turbine regenerative system and established a typical fault set of the regenerative system. On the basis of using the fuzzy rules to establish knowledge base of fault symptom of regenerative system, a fault diagnosis method of regenerative system based on support vector machine multi-classification algorithm was proposed. Finally, the method was applied to the fault diagnosis of the regenerative system of a steam turbine. The experimental results showed that the model could effectively identify the fault of the regenerative system.","10.1109/ISPDS51347.2020.00077","IEEE Conferences","2020","","IEEE"
"Reducing Bias in AI-Based Analysis of Visual Artworks","Empirical research in science and the humanities is vulnerable to bias which, by definition, implies incorrect or misleading findings. Artificial intelligence-based analysis of visual artworks is vulnerable to bias in ways specific to the domain. Works of art belong to a distinct cultural category that often prioritizes such characteristics as hand-craftsmanship, uniqueness, originality, and imaginative content; works of art are also responsive to diverse social and cultural contexts. Ascertaining which features of an artwork can be rightly ascribed to an objective “truth,” without which the concept of bias is not even relevant, is itself challenging. Incorporating expert knowledge into machine learning applications can help reduce bias in final estimates. We review several sources of bias that can occur across different stages of AI-based analysis, protocols, and best practices for reducing bias, and approaches to measuring these biases. This systematic investigation of various types of bias can help researchers better understand bias, become aware of practical solutions, and ultimately cultivate the prudent adoption of AI-based approaches to artwork analysis.","10.1109/MBITS.2022.3197102","IEEE Magazines","2022","","IEEE"
"Artificial Intelligence, Policing and Ethics – a best practice model for AI enabled policing in Australia","The application of Artificial Intelligence (AI) to policing processes and practices has transformative potential. Despite its potential, utilising AI for policing also comes with risks and challenges. The objective of this article is to provide a starting point for the development of a best practice model for the application of AI to policing in Australia. Such a best practice model would be the first of its kind and could put Australian police departments at the forefront of AI application – enabling Australian police to deploy AI in a way that has broad stake-holder support, maximising effectiveness and ensuring ethical concerns are adequately addressed","10.1109/EDOCW52865.2021.00032","IEEE Conferences","2021","","IEEE"
"Energy Saving Technologies and Best Practices for 5G Radio Access Network","This article identifies energy-saving potential of the fifth generation (5G) Radio Access Network, and describes main energy-saving principles and technologies. It explores how to use network energy saving technologies, such as carrier shutdown, channel shutdown, and symbol shutdown in 5G network, that have been inherited from 4G. Some enhanced technologies for 5G like equipment deep sleep and symbol aggregation have also been introduced in this article. However, it is far from enough and an innovative energy-saving solution should be considered. To meet the requirements and development of intelligent and self-adaptive energy-saving solution, Artificial Intelligence (AI) and big data analysis are introduced to form a more precise energy-saving strategy based on site-specific traffic and site-related conditions, thus improving the efficiency and reducing the manpower. Finally, two commercial application practices of AI-based energy-saving solution are elaborated. One is the practice of AI-based service awareness energy saving for 4G/5G collaborative networks, the energy benefits can be improved up to 20%; The other practice is the adoption of a new architecture Active Antenna Unit (AAU) with beam pattern optimization, its energy benefits can be promoted by 30%. These two practices could help mobile network operators (MNOs) to achieve the most energy-efficient network with good network performance and lower Operating Expense (OPEX).","10.1109/ACCESS.2022.3174089","IEEE Journals","2022","","IEEE"
"AI Living Lab: Quality Assurance for AI-based Health systems","The main goal of this project is to develop an AI Living Lab providing methods and software tools for AI trustworthiness analysis, running digital twins to simulate Digital Health solutions (Hardware and Software) integrated with AI elements in vitro for early-stage validation experiments. In this paper, we present the motivation beyond the need of a AI Living Lab methods for researchers and companies, our idea in practice, and the scheduled roadmap. The insights of the AI Living Lab can enable researchers to understand possible problems on the quality of AI-enabled systems opening new research topics and allows companies to understand how to better address quality issues in their systems.","10.1109/CAIN58948.2023.00018","IEEE Conferences","2023","","IEEE"
"Artificial Intelligence (AI) based Detection of Traffic Violations by Two-Wheeler Vehicles","Increasing commuters, bad traffic signal management, and rider mentality are some of the factors contributing to traffic violations in India. Monitoring large traffic volumes physically and tracking violations at the same time is clearly insufficient with only physical traffic police. The result has been that many violators have gone undetected. By violating the traffic laws, the violators cause more serious mishaps on the road, thereby putting both themselves and others in danger. To avoid manual intervention in detecting and catching violators, Artificial Intelligence (AI)-based techniques should be incorporated. This research study demonstrates a novel technique to discover multiple offences on Indian roads electronically, which include helmet detection, using a smartphone while driving, tri cruising, wheeling, and parking illegally, and ultimately model the issuing of tickets by monitoring the infractions and affiliated car number together in record. Through all the automated AI-based traffic offense and booking system, the software will be extremely beneficial in determining diverse safety-related guidelines, facilitating in the imposing of harsher traffic restrictions, and fostering the development of such a green technology atmosphere.","10.1109/ICICCS56967.2023.10142605","IEEE Conferences","2023","","IEEE"
"Hybrid AI-based Control Strategy for a Full-Vehicle Semi-Active Suspension System Equipped with MR Dampers","This paper’s goal is to design a hybrid AI-based controller for a MR-damped semi-active suspension system using a seven-degree-of-freedom model to enhance ride comfort by mitigating the acceleration exerted on the passenger. A fuzzy-logic control strategy is employed to determine the desired force required to be applied to the vehicle body. Also, a recurrent neural network was developed to predict the input voltage of the damper required to generate its actual force. The fuzzy controller rules are designed based on minimizing the vehicle body acceleration. The neural network is trained using the synthetic data produced from the modified Bouc-Wen model. The performance of the proposed hybrid AI-based method was evaluated by applying it to a full suspension system model incorporating an MR damper model with 7-DOF riding on a bumpy road. Based on various simulations, the effectiveness of the proposed strategy is proved by calculating RMS values of the vertical body acceleration, angular acceleration, and the vertical displacement of body center mass.","10.1109/ICRoM57054.2022.10025306","IEEE Conferences","2022","","IEEE"
"How Well Can Masked Language Models Spot Identifiers That Violate Naming Guidelines?","Using meaningful identifiers in source code reduces the risk of errors, the cognitive load of developers, and speeds up the development process. Therefore, recent research has looked into an AI-based analysis of identifiers, for which large-scale language models appear to offer great potential. Based on tokens’ probabilities, such models can suggest identifiers that are likely to appear in a given context. While current research has used language models to predict the most likely identifier names, studies on assessing the quality of given identifiers are scarce. To this end, we explore adherence to identifier naming guidelines as a proxy for identifier quality and propose and evaluate two unsupervised approaches for spotting violations: First, a generative approach, which uses the probability distribution of the language model directly without fine-tuning. Second, a discriminative method, which fine-tunes the model’s encoder to discriminate between original identifiers and similar drop-in replacements suggested by a weak AI. We demonstrate that the proposed approaches can successfully detect violations of common guidelines for identifier naming. To do so, we have developed a dataset built on widely accepted identifier naming guidelines. The manually annotated dataset contains more than 6000 dense annotations of identifiers for 28 common guidelines. Using the data, we show that the generative approach achieves the best results, but that the particular masking strategy and scoring method matter substantially. Also, we demonstrate our approach to outperform other recent code transformers. In a per-guideline analysis, we highlight the potential and limitations of language models, and provide a blue-print for training and evaluating their ability to identify bad identifier names in source code. We make our dataset and models’ implementation publicly available to encourage future research on AI-based identifier quality assessment.","10.1109/SCAM59687.2023.00023","IEEE Conferences","2023","","IEEE"
"AI Empowered Resource Management for Future Wireless Networks","Resource management plays a pivotal role in wireless networks, which, unfortunately, leads to challenging NP-hard problems. Artificial Intelligence (AI), especially deep learning techniques, has recently emerged as a disruptive technology to solve such challenging problems in a real-time manner. However, although promising results have been reported, practical design guidelines and performance guarantees of AI-based approaches are still missing. In this paper, we endeavor to address two fundamental questions: 1) What are the main advantages of AI-based methods compared with classical techniques; and 2) Which learning method should we choose for a given resource management task. For the first question, four advantages are identified and discussed. For the second question, optimality gap, i.e., the gap to the optimal performance, is proposed as a measure for selecting model architectures, as well as, for enabling a theoretical comparison between different AI-based approaches. Specifically, for K-user interference management problem, we theoretically show that graph neural networks (GNNs) are superior to multi-layer perceptrons (MLPs), and the performance gap between these two methods grows with $\sqrt K $.","10.1109/MeditCom49071.2021.9647580","IEEE Conferences","2021","","IEEE"
"Contactless Temperature Detection of Multiple People and Detection of Possible Corona Virus Affected Persons Using AI Enabled IR Sensor Camera","Today our whole world is entangled with the most dreadful disease Corona which is caused by the successor of SARS known as SARS-Cov-2 virus. Coronavirus is the influenza-like respiratory disease causing damage to the respiratory system of the humans through the ACE2 receptors which acts as an entry gate for the virus to enter. The Corona virus was identified in late 2019 in the city of Wuhan, China which later spread to the most of the territories in China. The spread was first identified by the Bluedot which is a Saas service designed to track and detect the spread of infectious disease. When the other countries came to know the severity of the virus they made various steps to prevent the spread of the virus. The initial symptoms of coronavirus are rise in temperature, loss of taste and smell and short breathness. As the entry level check many institutions and offices, checks the body temperature of the people and checks whether the person is wearing a mask or not. To make this process fully automatic without human intervention the use of AI enabled IR camera sensor with the Arduino UNO is made. The detection of temperature can be made possible by the use of the computer leveraging vision techniques which is equipped with the Raspberry-pi camera module. The process is based on the thermal imaging of the person which can detect the elevated temperature of the person and prevents them from entering into the institution or offices thereby the spread due to the possibly affected persons can be avoided thereby the spread can be controlled. The system not only identifies the person with high temperature but also checks whether the person is wearing a mask or not. The real time analysis of the system is the major advantage of the proposed system.","10.1109/WiSPNET51692.2021.9419439","IEEE Conferences","2021","","IEEE"
"DyReT: A Dynamic Rule Framing Engine Equipped With Trust Management for Vehicular Networks","Managing a dynamic traffic system is a challenging task in vehicular environments. Clarity of vehicular data for efficient decision making is vital in Intelligent Transportation Systems (ITS). Huge volumes of vehicular data are collected and processed during vehicular transactions. Pre-processing the huge amounts of raw vehicular data followed by framing effective traffic rules to take appropriate rapid decisions by the ITS on the vehicles continues to be a challenging problem. Most of the current studies done on ITS have proposed decision making strategies to handle only specific vehicular events and many lacked framing intelligent dynamic decision rules along with appropriate actions, representing all traffic events prevailing in the vehicular environment. This study proposes a versatile decision engine implanted with a two-stage mechanism. In the first stage, we propose a novel data cleaning algorithm to identify and remove dirty data from the voluminous vehicular dataset. In the second stage, a unique rule framing mechanism is suggested to frame dynamic traffic rules along with their actions using real-time vehicular data. The vehicular entities take suitable decisions to respond to the traffic events based on these rules and their associated actions. A new Naïve Bayesian classifier is proposed in this study to test the new rule framed with the trained rules set, either to accept or reject the new rule for further processing. The algorithms are developed and implemented using machine learning concepts. Experimental and comparative analysis was carried out with other related referred studies to evaluate the performance of the proposed algorithms. Although the proposed decision engine is generic enough for decision making in most ITS use-cases, discussion in this article elaborates on its applicability in use-cases provisioning trust management.","10.1109/ACCESS.2020.2987414","IEEE Journals","2020","","IEEE"
"Trustworthy AI Development Guidelines for Human System Interaction","Artificial Intelligence (AI) is influencing almost all areas of human life. Even though these AI-based systems frequently provide state-of-the-art performance, humans still hesitate to develop, deploy, and use AI systems. The main reason for this is the lack of trust in AI systems caused by the deficiency of transparency of existing AI systems. As a solution, “Trustworthy AI” research area merged with the goal of defining guidelines and frameworks for improving user trust in AI systems, allowing humans to use them without fear. While trust in AI is an active area of research, very little work exists where the focus is to build human trust to improve the interactions between human and AI systems. In this paper, we provide a concise survey on concepts of trustworthy AI. Further, we present trustworthy AI development guidelines for improving the user trust to enhance the interactions between AI systems and humans, that happen during the AI system life cycle.","10.1109/HSI49210.2020.9142644","IEEE Conferences","2020","","IEEE"
"A Case Study of Privacy Protection Challenges and Risks in AI-Enabled Healthcare App","Artificial intelligence (AI) is increasingly used in healthcare systems and applications (apps) with questions and debates on ethical issues and privacy risks. This research study explores and discusses the ethical challenges, privacy risks, and possible solutions related to protecting user data privacy in AI-enabled healthcare apps. The study is based on the healthcare app named Charlie in one of the fictional case studies designed by Princeton University to elucidate critical thinking and discussions on emerging ethical issues embracing AI.","10.1109/CAI54212.2023.00132","IEEE Conferences","2023","","IEEE"
"An AI based High-speed Railway Automatic Train Operation System Analysis and Design","Recent years, the research and application of High-Speed Railway (HSR) automatic train operation (ATO) system are under fast development, while the safety, energy efficiency and passenger comfort of ATO systems still need improvement. On the other hand, Artificial Intelligence (AI) technology, for example, Deep Learning, has been widely applied in automata industry such as robot control and driverless vehicle. In this paper, we propose a new idea of improving train control system performance with AI technologies such as Deep Reinforcement Learning and Imitation learning, and describe the system objective, structure and development process. The details of key processes such as establishment of Train Running Condition Evaluation Index, acquisition and processing of relevant big data, construction of AI based automatic train operation model and the program of simulation and experiment are presented in this paper, which provides a brand new and practical idea to the development of High-Speed Railway automatic train operation systems.","10.1109/ICIRT.2018.8641650","IEEE Conferences","2018","","IEEE"
"Association Rule Mining Based Algorithm for Recovery of Silent Data Corruption in Convolutional Neural Network Data Storage","Embedded systems are finding their way into almost every aspects of our daily life from mp3 players and console games to the mobile phones. Different Artificial Intelligence (AI) based applications are commonly utilized in embedded systems from which computer vision based approaches are included. The demand for higher accuracy in computer vision applications is associated with the increased complexity of convolutional neural networks and the storage requirement for saving pre-trained networks. Different factors can lead to the data corruption in the storage units of the embedded systems, which can result in drastic failures due to the propagation of the errors. Hence, the development of software-based algorithms for the detection and recovery of data corruption is crucial for improvement and failure-prevention of embedded systems. This paper proposes a new algorithm for the recovery of the data in the case of single event upset (SEU) error. The association rule mining based algorithm will be used to find the probability of the corruption in each of the bits. The recovery algorithm was tested on four different pre-trained ResNet (ResNet32 and ResNet110 at two different accuracy levels each) and the best recovery rate of 66% was found in the most complex scenario, i.e., random bit corruption. However, for the special cases of SEU errors, e.g. error in the frequently repeated bits, the recovery rate was found to be perfect with a value of 100%.","10.1109/SSCI47803.2020.9308545","IEEE Conferences","2020","","IEEE"
"AI-based Automatic Activity Recognition of Single Persons and Groups During Brainstorming","In this paper, we describe an AI-based system that recognizes the activity status of several people from video streams during brainstorming meetings. Deep learning is often used to recognize video characteristics but requires a huge amount of computer resources. This makes it difficult to keep track of the activities of multiple people whose circumstances change. On the other hand, many trained models of one person’s motion recognition have been developed and are available. We propose to use the existing technology but to be able to do that we need to identify a single person’s activities within a group context. This is achieved by segmenting the video and cropping the area with a person, identifying the activity using pre-existing trained models. The activity of the group is recognized by a production rule system based on individual activities. To achieve our goal, we introduce the concept of atomic action to describe activities and propose categories of atomic actions. High-level collaborative categories that indicate the status of a group during collaborative meetings are based on the CIAO model. This paper ends with the results of the first experiments we conducted using video recordings of actual students’ work sessions.","10.1109/SMC42975.2020.9282981","IEEE Conferences","2020","","IEEE"
"Legal Document Summarization Using Ripple Down Rules","This paper presents an approach for legal document summarization using Ripple Down Rules(RDR). RDR is an Artificial Intelligence(AI) based approach and an alternative technique to Machine Learning(ML) algorithms for incrementally building the knowledge base. In this implementation, we have used RDR to develop an improving and increasing knowledge base of classification rules for assigning rhetorical role labels to the sentences in a legal document. The RDR rules for classification are developed using a set of syntactic, semantic and statistical features at word, sentence and document level. For each sentence in the legal document we have assigned an rhetorical role with the help of Ripple Down Rule. We have generated the final summary using the identified thirteen rhetorical roles. The proposed system is evaluated using 50 legal documents from four different domains. Experiments demonstrate that the RDR based Legal Document summarization approach has advantages over supervised and unsupervised ML techniques such as, independence from the need of annotated dataset and continuous updation of classification rules for rhetorical role labeling with the help of expert knowledge.","10.1109/WIECON-ECE57977.2022.10150974","IEEE Conferences","2022","","IEEE"
"A Review of Potential AI-Based Automation for IoT-Enabled Smart Homes","The Internet of Things (IoT) has brought significant changes in the way we interact with technology in our homes. Smart homes equipped with IoT devices offer a comfortable and convenient lifestyle. However, managing these devices and their operations can be challenging, especially for individuals with limited technical expertise. The integration of artificial intelligence (AI) in IoT-based smart homes can potentially overcome these challenges by automating device management and enabling proactive responses to users’ needs. This paper investigates the potential of AI-based automation for IoT-enabled smart homes. We review the literature on AI-based automation and IoT-based smart homes, highlighting their benefits, challenges, and existing solutions. The research methodology used in this study is through deep learning approach. The results indicates that AI-based automation can improve user experience and enhance the efficiency and effectiveness of IoT-based smart homes. However, some technical and ethical challenges, such as privacy and security concerns, need to be addressed.","10.1109/ICSET59111.2023.10295156","IEEE Conferences","2023","","IEEE"
"Run-Time Safety Monitoring Framework for AI-Based Systems: Automated Driving Cases","Intelligent systems based on artificial intelligence techniques are increasing and are recently being accepted in the automotive domain. In the competition of automobile makers to provide fully automated vehicles, it is perceived that artificial intelligence will profoundly influence the automotive electric and electronic architecture in the future. However, while such systems provide highly advanced functions, safety risk increases as AI-based systems may produce uncertain output and behaviour. In this paper, we devise a run-time safety monitoring framework for AI-based intelligence systems focusing on autonomous driving functions. In detail, this paper describes (i) the characteristics of a safety monitoring framework; (ii) the safety monitoring framework itself, and (iii) we develop a prototype and implement the framework for two critical driving functions: Lane detection and object detection. Through an implementation of the framework to a prototypic control environment, we show the possibility of this framework in the real context. Finally, we discuss the techniques used in developing the safety monitoring framework and describes the encountered challenges.","10.1109/APSEC48747.2019.00066","IEEE Conferences","2019","","IEEE"
"AI based Impact of COVID 19 on food industry and technological approach to mitigate","The food industry or the restaurant business has always been one of the most profitable and growing businesses. As technology is evolving day by day and to sustain itself in the food industry the restaurant needs to come up with new and innovative services which they can provide to the customers. Pandemic has made a major impact on the business of the restaurant industry in 2020. This paper will help to understand how technology can help in food ordering, while taking care of the COVID-19 pandemic guidelines. The purpose of this paper is to analyze the impact of COVID-19 in the food industry and suggest methods that would help restaurants to adapt to challenges that originate from COVID-19. One of the ways would be to automate the food ordering process. Our Project “Contactless food ordering system” is a mobile application operated by a voice assistant. That the client (The Restaurant Customer) can use to scan through the restaurant menu and view various food categories and items like “Starter” “Drinks” etc. and place their order through the Application. They can modify and confirm their order, as well as make their payment. The aim of the study is to reduce the point of contact during COVID-19 and automate the ordering and billing process, simplifying the work. Thus, providing a totally computerized, automated, and scalable food ordering system that will assist the business by reducing their workload, provide better management and smooth operation. The restaurant can also use various other means to increase their presence as a business.","10.1109/ICICCS51141.2021.9432152","IEEE Conferences","2021","","IEEE"
"AI Based Approach For Path Traversal","The manuscript intends to provide holistic overview of AI based forward traversal path and backward traversal path. These path are obtained from a collection of web accesses, once the user session are identified. The proposed work contains an alternative approach to generate path traversal and reduced the forward and backward traversal Path.","10.1109/SSTEPS57475.2022.00053","IEEE Conferences","2022","","IEEE"
"Dynamic Network Provisioning with AI-enabled Path Planning","As the number of mobile devices increases and the concept of 5G networks becomes popular, various network infrastructures and services emerge. Also, more users request user-specific network services within limited network resources. Under this complex situation, in order to provide a guaranteed QoS level to users, it requires to consider various factors which affect the performance of network service, and dynamic network provisioning is required. In this paper, we propose a dynamic network provisioning system with AI-enabled path planning, which uses the side channel information such as disaster events, maintenance events, and distribution of users. In this system, we design a user request handler that understands user-specific QoS and spatio-temporal requirements in order to maximize the utilization of a given network resource. Also, this system utilizes side-channel information to optimizing the network provisioning in a realtime manner.","10.23919/APNOMS50412.2020.9236957","IEEE Conferences","2020","","IEEE"
"Dependency on AI-Based Writing Tools in English Learning: Implications for Human-Computer Interaction","This study investigates the reliance of English learners on AI-based writing tools and the repercussions for human-computer interaction (HCI). Through survey and interview administered to a sample of English learners, this study investigates their reliance on AI tools, its impact on their writing skills, and their attitudes toward these technologies. The results disclose a significant reliance on AI tools among participants, with the majority relying on them for writing assignments and having doubts about their writing ability without them. The findings emphasize the potential benefits of AI tools for enhancing learners' writing skills and boosting their confidence. However, they also raise concerns about overdependence, decreased participation in face-to-face learning, and addiction to these technologies. The research highlights the need for a balanced incorporation of AI tools in language learning. The study contributes to the field of Human-Computer Interaction (HCI) by providing insights into user experiences and promoting informed decision-making regarding the incorporation of AI-based writing tools in language learning contexts.","10.1109/ICIMTech59029.2023.10278054","IEEE Conferences","2023","","IEEE"
"Enhanced Interoperating Mechanism Between OneM2M and OCF Platform Based on Rules Engine and Interworking Proxy in Heterogeneous IoT Networks","In recent years, the Internet of Things (IoT) is growing rapidly and is being applied in a variety of industries including healthcare, smart homes, and smart cities. Many standard IoT platforms are proposed to connect and communicate with IoT devices easily and securely such as oneM2M, Google Weave and Apple HomeKit. However, this makes IoT application development difficult as it requires IoT devices and applications to support multiple protocols to connect different IoT platforms. Therefore, it is necessary to provide a consistent schema to support interoperability in heterogeneous IoT networks. In this paper, we propose how to design and implement interoperating schema between two edge servers oneM2M and Open Connectivity Foundation (OCF) with heterogeneous IoT devices. Specifically, we build proxies for bridging oneM2M Mobius edge server and OCF IoTivity edge server. The sensor data is collected from various IoT devices and sent to an edge server with a compatible platform. Next, the data stored in each server will be exchanged with the other server through a proposed interworking proxy. We also use a rules engine to automatically identify registered devices to support edge server interaction within the same domain and across domains. In addition, we build a web application in each edge server to provide friendly IoT services (data visualization) to clients from different environments. In order to evaluate our system, we collect the delay time of each process in the edge servers. The results show that our proposal is completely applicable in practice.","10.1109/ACCESS.2023.3236412","IEEE Journals","2023","","IEEE"
"AI Empowered Quantitative Evaluation Method for Handwritten Chinese Character","In order to solve the problems of untimely evaluation, unspecific and ineffective feedback for writers and to improve writing quality in the daily standardized Chinese character writing practice of primary and secondary school students, a quantitative evaluation method for paper-pen handwritten standardized Chinese character based on neural network is proposed in this paper. It takes handwritten Chinese character by paper-pen writing as the evaluation object, and obtains the quantitative features of Chinese character through feature extraction of handwritten Chinese character image samples. On this basis, CNN classifier is used to complete the classification of handwritten Chinese character images. Then, based on the Gaussian distribution to fit the writing feature values of excellent samples, strict and loose normative interval thresholds are obtained. Finally, the deviation between the quantitative features of handwritten Chinese characters and the threshold is calculated, to realize the general quality evaluation and the detailed quantitative evaluation of strokes.","10.1109/IEIR59294.2023.10391219","IEEE Conferences","2023","","IEEE"
"AI-enabled Multi-modal Network Anomaly Association: A Deep Self/Semi-Supervised Learning Approach","In nowadays large-scale networks, it is challenging for network operation and maintenance systems to analyze the reported massive network anomaly information. To handle this problem, we proposed a deep multi-modal learning approach called multi-modal anomaly root cause analysis, which enables network operation and maintenance systems to automatically and effectively associate the related network anomalies that appear from different modalities or aspects, and then locate the root causes. As a self/semi-supervised approach, our proposal is capable of realizing self-learning, self-adapting, and does not rely on a large number of manual annotations. According to the experimental results in a real large-scale network, without any annotations, our approach achieves up to 14% accuracy improvement in terms of multi-modal network anomaly association and root cause locating compared to the classical association rule mining algorithm Apriori, while its performance turns even much better when a few of labeled training samples are provided. The experiment also well proves the versatility and self-adaptability of our approach, which means our learning-based approach is able to not only achieve fast convergence but also automatically adapt itself to network changes.","10.1109/ICC45855.2022.9839022","IEEE Conferences","2022","","IEEE"
"AI-based botnet attack classification and detection in IoT devices","End-user Internet of Things (IoT) devices, including security cameras, smart appliances, home monitors, and thermostats, are becoming more prevalent in households. Additionally, the proliferation of devices facilitates the propagation of security concerns like DoS and spoofing. However, it is difficult for conventional rule-based security systems to recognize IoT assaults due to the development of heterogenous devices in the IoT ecosystem. Artificial Intelligence (AI) techniques can be a solution which enables the creation of an effective security model based on actual data from each device. In this work, IoT botnets are detected and classified using machine learning (ML) and deep learning (DL) based algorithms. Six ML models and three DL models are used to assess the system's performance. The best-performing model is also implemented as an API.","10.1109/ICMLANT56191.2022.9996464","IEEE Conferences","2022","","IEEE"
"AI-Based Localization and Classification of Visual Anomalies on Semiconductor Devices","This paper presents an AI-based system for automated visual inspection of semiconductor components, aimed at improving the Zero-Defect strategy in their manufacturing process. The system leverages unsupervised learning using Variational Autoencoder to learn and compare images of undamaged components to identify anomalies. An anomaly score is devised to enable detection of even minor flaws on the edges of components and decision rules are evaluated using appropriate metrics. The proposed system surpasses the current tape machine in detecting anomalies, hence contributing to achieving the Zero-Defect strategy in semiconductor manufacturing.","10.1109/eIT57321.2023.10187356","IEEE Conferences","2023","","IEEE"
"Hybrid Crowd-AI Learning for Human-Interpretable Symbolic Rules in Image Classification","Explainable AI is an indispensable goal for an AI-based society with trust, and deriving human-interpretable symbolic rules is one of the promising ways to verify whether the decision is appropriate. This paper explores a hybrid crowd-AI approach to develop white-box ML models associated with human-interpretable symbolic rules. The key idea of the proposed method is to discover human-interpretable latent features from trained neural networks by leveraging human abductive reasoning. The proposed method automatically generates crowdsourcing tasks that display subsets of images corresponding to each latent feature and ask crowd workers to provide the semantics of the features in natural language. The obtained semantics allow us to use the latent features as human-interpretable predicates that form symbolic rules to define target classes. We provide experimental results showing that the proposed approach can obtain interpretable symbolic rules and explanations.","10.1109/IIAI-AAI59060.2023.00060","IEEE Conferences","2023","","IEEE"
"Towards Productizing AI/ML Models: An Industry Perspective from Data Scientists","The transition from AI/ML models to production-ready AI-based systems is a challenge for both data scientists and software engineers. In this paper, we report the results of a workshop conducted in a consulting company to understand how this transition is perceived by practitioners. Starting from the need for making AI experiments reproducible, the main themes that emerged are related to the use of the Jupyter Notebook as the primary prototyping tool, and the lack of support for software engineering best practices as well as data science specific functionalities.","10.1109/WAIN52551.2021.00027","IEEE Conferences","2021","","IEEE"
"AIFIS: Artificial Intelligence (AI)-Based Forensic Investigative System","The scope of forensic investigations has recently expanded. Since most Internet of Things (IoT) devices are plug and play and do not have much memory or storage to pre-process data, it is a challenge for forensic investigators to identify and obtain relevant evidence to reconstruct attacks. As a solution, we propose using artificial intelligence (AI)-inspired techniques to automate the forensic analysis process by emulating attacks in the process of identifying and collecting forensic evidence. We used a differentiable inductive logic programming (∂ILP) system to obtain attack emulation information from different sources, such as device- and subsystem-level vulnerabilities gathered by assessing device components in an enterprise network, and to predict potential attacks from previous attacks on similar configurations. Our experimental results showed that the proposed methodology could successfully generate rules that can assist forensic examiners in identifying evidence to emulate attacks without execution.","10.1109/ISDFS55398.2022.9800801","IEEE Conferences","2022","","IEEE"
"Study of NMT: An Explainable AI based approach","Machine translation (MT) which translates source to the target language is a challenging task. It is one of the important area under Natural language Processing (NLP).These days we are having neural based translation system viz. Neural Machine Translation (NMT). In this study we have discussed some of the important architecture of NMT systems and their working in brief. NMT uses deep neural network frame work in its design. Deep neural network based machine learning (ML) approach is entirely black box for end user. NMT requires several hyper parameter tuning during training. We still don't get any satisfactory answer of why we are getting any specific result (output) with specific set of linguistic features and the hyper parameters that are tuned. We have tried to focus on this aspect with very recent concept in AI i.e. explainable AI (XAI). XAI, can interpret and explain the internal behavior of model's architecture which can provide us reasons (explanation) when we get any result (output) from our model. We have discussed some of the techniques such as LIME, SHAPELY, Seq-2-Seq-Vis, LSTM-Vis which are widely used by data scientists and incorporate them in ML pipeline to design an unbiased, robust and accurate model.","10.1109/ISCON52037.2021.9702396","IEEE Conferences","2021","","IEEE"
"Efficiency Improvement to Neural-Network-Driven Optimal Path Planning via Region and Guideline Prediction","Traditional sampling-based algorithms rely on random samples to explore a whole configuration space of robots for optimal path planning, while a uniform sampler impedes the exploration with randomly generated samples, leading to a long calculation time, especially in complex environments. Recently, neural-network-driven methods have attracted wide interest in developing non-uniform sampling to improve the sampling efficiency and reduce the calculation time. A region that contains an optimal path is predicted by neural networks and employed subsequently to biasedly generate samples. This work aims at enhancing the sampling efficiency and reducing the calculation time of the optimal path planning by a novel region and guideline prediction (denoted as RGP) model. We innovatively propose the RGP model with a guideline prediction module to estimate the guideline distributions, which are characterized by the central line of the predicted region. The predicted region and guideline are integrated into a sampling-based algorithm, namely RGP-RRT*, with an adaptively biased sampling strategy to select a proper domain for sampling. Simulations demonstrate the RGP model outperforms other region prediction models in accuracy and robustness. Besides, the RGP-RRT* reliably achieves a 7.2–80.1% reduction in calculation time and a 2.0–58.1% reduction in sample number compared with other neural-network-driven methods.","10.1109/LRA.2024.3350979","IEEE Journals","2024","","IEEE"
"Autonomous Decision-Making With Incomplete Information and Safety Rules Based on Non-Monotonic Reasoning","In this article we propose a decision process integrating Non-Monotonic Reasoning (NMR), embedded in a deliberative architecture. The NMR process uses Default Logic to implement goal reasoning, managing partially observable or incomplete information, allowing the design of default behaviours completed by the handling of specific situations, in order to manage the current mission objective as well as safety rules. We illustrate our approach through an application of an underwater robot performing a marine biology mission.","10.1109/LRA.2021.3103048","IEEE Journals","2021","","IEEE"
"Massive AI based cloud environment for smart online education with data mining","Under the background of the deep integration of Internet technology and artificial intelligence technology with the field of education, the traditional teacher centered teaching mode is facing a historic change. How to guide students to learn and communicate actively, and explore and improve the new student-centered teaching mode, has become the key problem to be solved. In the mixed cloud environment, the data stream is disturbed, and the error of mining association data is large. Aiming at the problem of poor anti-interference of scattered point cloud adaptive compression mining algorithm, this paper analyzes the data mining technology in cloud environment. Firstly, the time series analysis model of big data information flow in hybrid cloud environment is constructed to analyze the data structure, and then the high-dimensional phase space of data information flow in hybrid cloud environment is reconstructed. In the reconstructed phase space, the association rules are extracted, and the extracted features are used as pheromones to guide data location mining, so as to improve the data mining algorithm.","10.1109/ICICCS51141.2021.9432201","IEEE Conferences","2021","","IEEE"
"Knowledge-Intensive Language Understanding for Explainable AI","AI systems have seen significant adoption in various domains. At the same time, further adoption in some domains is hindered by the inability to fully trust an AI system that it will not harm a human. Besides, fairness, privacy, transparency, and explainability are vital to developing trust in AI systems. As stated in Describing Trustworthy AI,aa.https://www.ibm.com/watson/trustworthy-ai. “Trust comes through understanding. How AI-led decisions are made and what determining factors were included are crucial to understand.” The subarea of explaining AI systems has come to be known as XAI. Multiple aspects of an AI system can be explained; these include biases that the data might have, lack of data points in a particular region of the example space, fairness of gathering the data, feature importances, etc. However, besides these, it is critical to have human-centered explanations directly related to decision-making, similar to how a domain expert makes decisions based on “domain knowledge,” including well-established, peer-validated explicit guidelines. To understand and validate an AI system's outcomes (such as classification, recommendations, predictions) that lead to developing trust in the AI system, it is necessary to involve explicit domain knowledge that humans understand and use. Contemporary XAI methods are yet addressed explanations that enable decision-making similar to an expert. Figure 1 shows the stages of adoption of an AI system into the real world.","10.1109/MIC.2021.3101919","IEEE Magazines","2021","","IEEE"
"Performance and Endurance Training for Equine Racing (PETER)","Leveraging the Internet of Things (IoT) technologies into farming domains contribute significantly in more productive and sustainable farming activities. The concept of Smart stable depends on smart devices with the Internet connection to monitor and control the stable system and its animals. This paper proposes this method to provide the farmer and the horse trainer with an automated process to perform their daily activities to take better decisions or more efficient exploitation operations and management. In addition to that, the proposed system with being powered with artificial intelligence (AI) component able to absorb new horse health status updates then combines it with knowledge learned from historical records to predict the horse readiness for participating in training or real race sessions. The system equipped with sensors to detect physical data from the real world such as the speed of the horse, temperature, heartbeats, recovery time. Gathered data flows feed an advanced visualization dashboard based on Kibana, while another branch of data flow feeds the AI component.","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00234","IEEE Conferences","2019","","IEEE"
"AI Based Monitoring System for Social Engineering","Social media is one of the most predominantly used online platforms by individuals across the world. However, very few of these social media users are educated about the adverse effects of obliviously using social media. Therefore, this research project, is to develop an advisory system for the benefit of the general public who are victimized by the adverse impacts of their ignorant and oblivious behavior on social media. The system was implemented using a decision tree model with the use of customized datasets; and for the proceeding operational implementations, Python programming language, Pandas, Natural Language Processing and TensorFlow were used. This advisory system can monitor user behaviors and generate customized awareness reports for the users based on category and level of their behaviors on social media. Furthermore, the system is also capable of generating graph reports of the use behavior fluctuations for the reference of the user. With the help of these customized awareness reports and the graph reports, the users can identify their potential vulnerabilities and improve their social media habits.","10.1109/ICAC54203.2021.9671218","IEEE Conferences","2021","","IEEE"
"AI-Based convolute Neural Approach Management To Predict The RNA Structure","Let us begin with Machine learning (ML), which is a type of neural network (AI) that empowers software programmers to start increasing prediction without being done with full to do so. Because data is so valuable, improving strategies for intelligently having to manage the now-Ubiquitous content infrastructures is a necessary part of the process toward completely autonomous agents. In a nutshell, deep learning is a subset of machine learning that solves problems that machine learning alone cannot. Acquiring RNA secondary spatial relationships has been more significant in RNA and functional genomics studies in recent years. Although some RNA secondary sequences may be discovering approaches, most of the time, quick and accurate computational approaches are utilized to predict the structure of DNA strands. Current methods for determining RNA structure of proteins are generally based on the lowest power storage strategy, which seeks the optimal RNA folded form in vivo and employs an incremental process to satisfy the lowest source of critical energy and related aspects.","10.1109/ICACITE53722.2022.9823922","IEEE Conferences","2022","","IEEE"
"Safety Assurance of Artificial Intelligence-Based Systems: A Systematic Literature Review on the State of the Art and Guidelines for Future Work","The objective of this research is to present the state of the art of the safety assurance of Artificial Intelligence (AI)-based systems and guidelines on future correlated work. For this purpose, a Systematic Literature Review comprising 5090 peer-reviewed references relating safety to AI has been carried out, with focus on a 329-reference subset in which the safety assurance of AI-based systems is directly conveyed. From 2016 onwards, the safety assurance of AI-based systems has experienced significant effervescence and leaned towards five main approaches: performing black-box testing, using safety envelopes, designing fail-safe AI, combining white-box analyses with explainable AI, and establishing a safety assurance process throughout systems’ lifecycles. Each of these approaches has been discussed in this paper, along with their features, pros and cons. Finally, guidelines for future research topics have also been presented. They result from an analysis based on both the cross-fertilization among the reviewed references and the authors’ experience with safety and AI. Among 15 research themes, these guidelines reinforce the need for deepening guidelines for the safety assurance of AI-based systems by, e.g., analyzing datasets from a safety perspective, designing explainable AI, setting and justifying AI hyperparameters, and assuring the safety of hardware-implemented AI-based systems.","10.1109/ACCESS.2022.3229233","IEEE Journals","2022","","IEEE"
"An Adaptive Service-Oriented Business Management Pattern Based on Machine Learning Rule ML","The significance of artificial intelligence (AI) and machine learning (ML) for businesses is briefly and comprehensively discussed in this study. AI is a new trend and technology of the modern era that offers numerous advantages to businesses. AI and machine learning save the company money by lowering over- all business operations costs. In addition, it enables businesses to effectively solve business issues and helps them make better decisions about their processes. Customers can communicate with the AI-based chat bots at any time, day or night, and they can answer their questions about any business or product. Based on business operations, ML creates opportunities for businesses and automates the process completely. In addition, the ML effectively enhances cognitive engagement between employees and customers and offers solutions to customer issues like password issues and many others. In addition, the study contains the strategies and procedures utilized in its completion. In this study, the researcher has used secondary qualitative and quantitative methods to collect data. Companies must comprehend the augmentation and automation process in order to implement AI and ML in business operations. In addition, the type of business is used to describe the Al’s market size in percentage and dollars.","10.1109/ICACITE57410.2023.10183158","IEEE Conferences","2023","","IEEE"
"AI based MPPT methods for grid connected PV systems under non linear changing solar irradiation","This paper presents the artificial neural network (ANN), fuzzy logic controller (FLC) maximum power point tracking (MPPT) methods in grid connected photovoltaic (PV) systems for optimizing the solar energy efficiency. All the methods are simulated in MATLAB-Simulink, respectively together with SunPower-SPR305 PV module connected to single-ended primary inductor converter (SEPIC). Performance assessment covers efficiency, overshoot, settling time response, oscillations and stability.","10.1109/ICACEA.2015.7164752","IEEE Conferences","2015","","IEEE"
"Novel Four-Layered Software Defined 5G Architecture for AI-based Load Balancing and QoS Provisioning","Software defined 5G network (SD-5G) is an evolving networking technology. The integration of SDN and 5G brings scalability, and efficiency. However, Quality of Service (QoS) provision is still challenging in SD-5G due to improper load balancing, traffic unawareness and so on. To overwhelm these issues this paper designs a novel load balancing scheme using Artificial Intelligence (AI) techniques. Firstly, novel four-layered SD-5G network is designed with user plane, smart data plane, load balancing plane, and distributed control plane. In the context to 5G, the data transmission rate must satisfy the QoS constraints based on the traffic type such as text, audio, video etc. Thus, the data from the user plane is classified by Smart Traffic Analyzer in the data plane. For traffic analysis, Enriched Neuro-Fuzzy (ENF) classifier is proposed. In the load balancing plane, Primary Load balancer and Secondary Load Balancer are deployed. This plane is responsible for balancing the load among controllers. For controller load balancing, switch migration is presented. Overloaded controller is predicted by Entropy function. Then decision for migration is made by Fitness-based Reinforcement Learning (F-RL) algorithm. Finally, the four-layered SD-5G network is modeled in the NS-3.26. The observations shows that the proposed work improves the SD-5G network in terms of Loss Rate, Packet Delivery Rate, Delay, and round trip time.","10.1109/ICCCS49078.2020.9118463","IEEE Conferences","2020","","IEEE"
"Performance Analysis of AI-based Optical guiding Device for visually compromised person","To defeat the voyaging trouble for an outwardly impeded individual in chiefly outside climate, this paper presents a thought of savvy directing gadget dependent on CNN and fuzzy to distinguish snags like bicycle, vehicle, individual and give an appropriate sound criticism to the client in the wake of working out speed, distance and in the wake of applying fuzzy to exact the result. Work is to diminish the different sensors of distance and speed estimating and perform calculation on pictures to set exact outcomes up to make it financially savvy. It is a difficult situation for blind individual to stroll on themselves in free space or in street of snags. Different techniques have appeared for directing them to move like headlock strategies, multi-sensors combination Algorithm, yet among every one of them because of utilization of sensors its size turns out to be enormous and furthermore get high in cost. To lessen this, we have presented different calculations for exact speed and distance estimations in order to give appropriate sound criticism.","10.1109/ICSTSN53084.2022.9761308","IEEE Conferences","2022","","IEEE"
"Multiple AI Based Web Mining","Artificial intelligence (AI) refers to the computational process of finding, identifying, and evaluating patterns in huge data sets using techniques that lie at the confluence of machine learning, statistics, and database strategies. Its major purpose is to extract relevant information from raw data sets and reformat them into the desired format for analysis and application. Web Mining (WM), an expanding viewpoint of data mining, encompasses all data mining and associated processes. It is employed for automatically locating and extracting data from online records and services. So, the goal of WM is to glean useful information from the web. Given its significance, this research conducts a survey of DM methods for web mining.","10.1109/IIHC55949.2022.10059948","IEEE Conferences","2022","","IEEE"
"AI based Automated Essay Grading System using NLP","The goal of this proposed work is to develop an AI-powered system for automated essay grading. The system will utilize natural language processing and Graph based techniques to analyze, and grade written essays. It not only checks the syntax, semantics and grammar but also grades according to the similarity of sentences using a Graph based approach. The system will be trained on a dataset of labelled essays and will be able to accurately grade new essays based on their content and writing quality. The system can be able to integrate with existing learning management systems. The goal is to provide a more efficient and accurate essay grading process, so the teachers can provide valuable feedback to students. The proposed work aims to develop an automated essay grading system using AI technology. The system will be able to analyze, and grade written essays by using natural language processing and machine learning techniques. The system will be trained on a dataset of labelled essays, which will be used to teach the system to recognize patterns and characteristics of high-quality writing. This will enable the system to accurately grade new essays based on their content and writing quality.","10.1109/ICICCS56967.2023.10142822","IEEE Conferences","2023","","IEEE"
"Developing AI-based Fraud Detection Systems for Banking and Finance","Safeguarding financial institutions and their consumers against fraudulent activity makes fraud detection a top priority in the banking and finance business. There has been a rise in the development of artificial intelligence-based fraud detection systems in tandem with the popularity of machine learning methods. This study presents a comprehensive evaluation of modern machine learning approaches like neural networks in comparison to more conventional ones like logistic regression and decision trees. These techniques are tested using financial and banking data from the real world, and the findings indicate that neural networks are superior to more conventional approaches. In addition, our research emphasizes the significance of data gathering and administration in the evolution of fraud detection systems.","10.1109/ICIRCA57980.2023.10220838","IEEE Conferences","2023","","IEEE"
"A NLU-based method for a first level automatic categorization of AI-based security documents","Managing and organizing the information is a difficult subject. Especially in our time with the plethora of available sources accessible to the public, basically through the Internet, the volume of these pieces of information becomes larger and larger. The purpose of this dissertation is the creation of a model of documents' categorization. Our goal is to illustrate an as possible automated way of classification that takes into consideration the meaning of the documents. The way in which a human evaluates and classifies documents is followed in this proposed methodology. We also illustrate some empirical examples of the function of our classification method.","10.1109/IISA.2013.6623729","IEEE Conferences","2013","","IEEE"
"The Research and Construction of the AI-Based Knowledge Graph in Multi-Dimensional Data","With the development of deep learning and the knowledge graph, artificial intelligence has had a significant influence on the area of education as a result of the rapid growth of this age, which has profoundly altered human productivity and daily life. The university is undergoing a digital transformation. The essence of the knowledge graph is the knowledge base of the semantic network. Using natural language processing (NLP) technology, the university can construct a knowledge graph. Integrating knowledge graphs and deep learning has become one of the most important aspects of further improving the effect of deep learning. The solution to knowledge graph processing data is “algorithm, totalization, and implementation”. The key technologies of constructing knowledge graphs in multi-dimensional data mainly focus on knowledge ontology definition, knowledge representation, knowledge modeling, knowledge extraction, knowledge fusion, knowledge processing, knowledge computing, and other technologies. The research in this paper shows that the RDF model and algorithm of the knowledge graph have application prospects in multi-dimensional data.","10.1109/CEDL60560.2023.00008","IEEE Conferences","2023","","IEEE"
"AI Enabled IoT based Intelligent Waste Water Management System for Municipal Waste Water Treatment Plant","Water is considered to be an essential part of human life, it is our individual responsibility to utilize the water with utmost care. Agriculture is considered to be an important factor in the growth of the economy which also depends upon the availability of water. Rainfall in today's scenario is unpredictable and uncertain as the monsoon rainfalls are irregular in recent days, this causes serious water scarcity and agriculture failure in most places. To overcome these problems, various technologies are adopted in the field of agriculture to make the irrigation system more effective. This research study adopts a novel Artificial Intelligence (AI) based system to properly manage the usage of water in Municipal Wastewater Treatment Plants with the help of the Internet of Things (IoT). This system runs on a central Atmega 328p Microcontroller connected with an ESP 8266 Wi-Fi on the chip. Various parameters of the water such as pH, conductivity, color, smell, and temperature are recorded in the cloud server, which is analyzed with an AI-based system to decide whether the water can be reused or it can be passed to the garden for irrigation.","10.1109/ICICT57646.2023.10134075","IEEE Conferences","2023","","IEEE"
"RLOps: Development Life-Cycle of Reinforcement Learning Aided Open RAN","Radio access network (RAN) technologies continue to evolve, with Open RAN gaining the most recent momentum. In the O-RAN specifications, the RAN intelligent controllers (RICs) are software-defined orchestration and automation functions for the intelligent management of RAN. This article introduces principles for machine learning (ML), in particular, reinforcement learning (RL) applications in the O-RAN stack. Furthermore, we review the state-of-the-art research in wireless networks and cast it onto the RAN framework and the hierarchy of the O-RAN architecture. We provide a taxonomy for the challenges faced by ML/RL models throughout the development life-cycle: from the system specification to production deployment (data acquisition, model design, testing and management, etc.). To address the challenges, we integrate a set of existing MLOps principles with unique characteristics when RL agents are considered. This paper discusses a systematic model development, testing and validation life-cycle, termed: RLOps. We discuss fundamental parts of RLOps, which include: model specification, development, production environment serving, operations monitoring and safety/security. Based on these principles, we propose the best practices for RLOps to achieve an automated and reproducible model development process. At last, a holistic data analytics platform rooted in the O-RAN deployment is designed and implemented, aiming to embrace and fulfil the aforementioned principles and best practices of RLOps.","10.1109/ACCESS.2022.3217511","IEEE Journals","2022","","IEEE"
"Generative AI-Empowered Simulation for Autonomous Driving in Vehicular Mixed Reality Metaverses","In the vehicular mixed reality (MR) Metaverse, the discrepancy between physical and virtual entities can be overcome by fusing the physical and virtual environments with multi-dimensional communications in autonomous driving systems. Assisted by digital twin (DT) technologies, connected autonomous vehicles (AVs), roadside units (RSUs), and virtual simulators can maintain the vehicular MR Metaverse via simulations for sharing data and making driving decisions collaboratively. However, it is challenging and costly to enable large-scale traffic and driving simulation via realistic data collection and fusion from the physical world for online prediction and offline training in autonomous driving systems. In this paper, we propose an autonomous driving architecture, where generative AI is leveraged to synthesize unlimited conditioned traffic and driving data via simulations for improving driving safety and traffic control efficiency. First, we propose a multi-task DT offloading model for the reliable execution of heterogeneous DT tasks with different requirements at RSUs. Then, based on the preferences of AV's DTs and real-world data, virtual simulators can synthesize unlimited conditioned driving and traffic datasets for improved robustness. Finally, we propose a multi-task enhanced auction-based mechanism to provide fine-grained incentives for RSUs on providing resources for autonomous driving. The property analysis and experimental results demonstrate that the proposed mechanism and architecture are strategy-proof and effective.","10.1109/JSTSP.2023.3293650","IEEE Journals","2023","","IEEE"
"Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models","In this paper, we investigate the enhancement of Artificial Intelligence (AI) technologies in healthcare and the better understanding of medical literature with the use of Large Language Models (LLMs) and Natural Language Processing (NLP). Specifically, we introduce a rule-augmented AI-empowered system which incorporates a rule-based decision system, the ChatGPT application programming interface (API), and other external machine learning and analytical APIs to offer diagnostic suggestions to patients. The complexities of patient healthcare experiences, including doctor-patient interactions, understanding levels, treatment procedures, and preventive care, are considered. We illustrate how a diagnostic process typically integrates various strategies depending on various factors. To digitize the greatest portion of the process, we propose and illustrate the use of LLMs for humanizing the communication process and investigating ways to reduce burdens and costs in primary healthcare. We also outline a theoretical decision model for evaluating the use of technological components from external sources versus building them from scratch. The paper is structured into sections detailing background theories and context, our proposed and implemented rule-augmented AI-empowered system, as well as a system test in a corresponding use case. Finally, the paper key findings are presented, which contribute valuable insights for future work in this field.","10.1109/ICTAI59109.2023.00018","IEEE Conferences","2023","","IEEE"
"Overview of an AI-Based Methodology for Design: Case Study of a High Efficiency Electric Vehicle Chassis for the Shell Eco-Marathon","The design process of a chassis for a high-efficiency vehicle involves considering several unique parameters due to its distinct operational needs. The constraints specified in the official regulations for the Shell Eco-Marathon prototype battery electric class could ostensibly limit design innovations. However, this paper introduces a methodological approach employing Machine Learning, facilitated by Large Language Models, which substantially broadens the spectrum of conceptual design possibilities. Further, the widely recognized technique of Computer-Aided Design, coupled with Generative Design, is leveraged to optimize specific sections of the chassis structure. The final stage of this study involves rigorous testing of the designed chassis to assess its mechanical performance, guided by the stringent benchmarks set by the competition.","10.1109/ISEM59023.2023.10334852","IEEE Conferences","2023","","IEEE"
"Rough set based system for effective E-learning","To achieve intelligence over the web is underlying research topic and continuous efforts have been made in this direction. The results of these efforts in its practical form of applications have been achieved using modern tools & techniques. Artificial Intelligence (AI) has evolved as one of the promising technology for achieving intelligence over web. To facilitate quality education, the identification & selection of various factors that may influence a students' academic performance is very important. Knowing these factors is important for parents & teachers working positively on these factors may improve the performance of the student. . In this paper we propose an approach of decision rule induction to induce knowledge that can facilitate the proper decision making process. The approach for rule induction process is based on AI based rough set theory. The proposed system may be seen as a helping hand to creators of contents, educators and teachers of the course.","10.1109/IndiaCom.2014.6828126","IEEE Conferences","2014","","IEEE"
"Enhanced Defect Detection in After Develop Inspection with Machine Learning Disposition","A complementary Machine Learning disposition method was generated and tested for after develop inspections in lithography. For lithography coating defects, this new method showed twice the sensitivity and five times the specificity in a controlled experiment versus the baseline system. Applying the detection method along with process improvements, preventative measures and rework for splatter defects, reduced yield loss from splatters by over 30x. Herein we describe learnings on the use of image enhancement for training and disposition, an Explainable AI system to support understanding, and a process flow to train augmentation based on performance.","10.1109/ASMC51741.2021.9435721","IEEE Conferences","2021","","IEEE"
"The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement","Artificial Intelligence finds application at all stages of Software Engineering, and uses the Neural Networks, Machine Learning, Natural Language Processing concepts. This paper attempts to review the instance of such approach - neural network programmer’s assistant Copilot, based on Codex, the AI system developed by OpenAI. The differences between Codex language model’s versions and analogous systems were analyzed. The main problems and gaps of this innovation, such as correct commands formulation, copyrighting, safety issues, inefficient code, good practice examples and restrictions are also considered. Additionally, the opportunities for Copilot’s growth, development and possible features’ proposed recommendations were suggested.","10.1109/ElConRus54750.2022.9755659","IEEE Conferences","2022","","IEEE"
"Supporting the Incorporation of Individual Patient Preferences for Decision Support in Breast Cancer Therapy","With the rise of personalized medicine, the number of individualized treatment options and related decisions is increasing tremendously. Thereby, the acquisition, incorporation and representation of the patient’s individual preferences in upcoming, modern, AI-based medical decision support systems play a decisive role. E.g., for patients with advanced breast cancer, there are various therapeutic options associated with different outcomes to choose from. In our contribution we show a first approach to model Preference Elicitation (PE) via card sorting using a utility function. Based on this, we present further ideas for extending and improving the approach.","10.1109/CSCI54926.2021.00263","IEEE Conferences","2021","","IEEE"
"An expert system for automatic cyber risk assessment and its AI-based improvements","Evaluating risks against IT Systems is a complex yet crucial process that requires significant resources and competencies. This paper proposes RiskMan, an expert system for the automatic assessment of cyber risks that computes a risk score using information gathering and vulnerability assessment tools, public databases, and leaks from the dark web without involving cybersecurity experts. Moreover, RiskMan uses AI-driven techniques to determine risks also when only partial information is available.","10.1109/COMPSAC57700.2023.00220","IEEE Conferences","2023","","IEEE"
"Blockchain and AI Empowered Trust-Information-Centric Network for Beyond 5G","As the next-generation network, beyond fifth generation (B5G) provides transmission capability up to terabits and processes hundreds of exabytes of content data per day from the internet of Everything. From 5G to B5G, the information-centric network (iCN) is expected to play a vital role due to the strong capabilities of content distribution, caching, and processing. As security is a major concern in B5G, content trust of iCN is of critical importance. Lack of content trust leads to the untrustworthiness and maliciousness of services and applications in B5G, such as malicious accidents resulting from the untrusted content of vehicle navigation and autonomous system. To deal with this issue, we propose a blockchain and artificial intelligence (Ai) empowered trust-information- centric network architecture for B5G. First, we design a blockchain-based trust evaluation and circulation scheme for B5G nodes called TrustCoin, which quantifies the credibility of B5G nodes in a dynamic and fine-grained way, and manages trust quotas of B5G nodes as well as trust-coin circulation. Second, to obtain the content credibility, we devise a credibility decision method based on content status and B5G nodes' behaviors by exploiting the excellent properties of deep reinforcement learning, which provides the intelligent allocation criterion for TrustCoin. Third, we propose a smart incentive mechanism for the endogenous trust of B5G networks according to the allocation criterion, thereby establishing the trust-information-centric network. Experimental results have verified the effectiveness of our proposed mechanism.","10.1109/MNET.021.1900608","IEEE Magazines","2020","","IEEE"
"Secured IoT Malware Detection Framework using AI based Fuzzy Logic Systems","Internet of Things (IoT) system is emerged enormously today and it is utilized in all the applications of human lives. Security of IoT systems seem more challengeable in terms of malicious software’s which are referred as malwares. IoT malwares are also evolved with the employment of advanced obfuscation and evading techniques. It is a very challengeable job for the security analysts as well as security providers. In this paper, an enhanced IoT malware detection framework is proposed by making use of AI based Fuzzy Logic Systems (AIFLS) by considering the shortcomings of existing recent detection methods. Fuzzy rules are generated automatically without any human intervention. Further, Fuzzy Pattern Trees (FPT) are generated and utilized for fastening classification of IoT malwares and enhancing detection accuracy. Experimentation results provide better results.","10.1109/ICACRS55517.2022.10029032","IEEE Conferences","2022","","IEEE"
"Artificial Intelligence and Machine Learning Approaches For Aviation Cybersecurity: An Overview","Artificial Intelligence (AI) and Machine Learning (ML) applications are currently found across all engineering domains, including cybersecurity engineering. This paper presents an overview of the AI-systems and technologies that can greatly benefit the security domain and its potential solutions for the aviation industry: anomaly detection for avionics, securing data link communications, and security certification, among others.As showcased in the ""National Strategy for Aviation Security"" report in December 2018 and the U.S. Government Accountability Office report ""Aviation Cybersecurity"" in October 2020, there is a need for resilient cybersecurity practices and approaches to address the current issues that aviation faces today. Designing and implementing solutions to address these issues without exploring the feasibility of harnessing AI-powered cybersecurity tools would overlook the potential advantages these technologies can offer.Therefore, this paper aims to provide a roadmap to adapt well-known ML-cybersecurity approaches to aviation security engineering and airworthiness: (i) autonomous and semi-autonomous cybersecurity for autonomous flight operations security, (ii) game theory models for adversarial and uncertainty modeling, (iii) human-AI interfaces for airport security monitoring and decision-making assistance, (iv) predictive analytics for anomaly detection for avionics and e-enabled aircraft, and (v) AI-based reasoning trustworthiness for software reliability and security certification. This paper also presents the challenges of including AI-cybersecurity in the aviation ecosystem to ground the proposed solutions within an accepted set of industry regulations, such as design verification for AI/ML algorithms and certification specifications for AI/ML solutions for manufacturers and agencies.","10.1109/ICNS52807.2021.9441594","IEEE Conferences","2021","","IEEE"
"Prevention through Design in major construction projects – Case study from Tata Steel","The construction industry is a dynamic sector involving various kinds of activities, each having their own hazards. Most of these activities are of a constantly changing nature and their specific hazards are not very well known until much later into the construction process. Though the fundamental processes involved in construction remain the same, every construction project is unique & has its own specific jobs & hazards associated with them depending on the design specifications, materials, equipment & processes used & the safety culture followed by the working agency. Construction workers are especially vulnerable to injuries due to fall from height, electrocution, being caught in or between objects, being struck by moving machinery, falling objects, vehicles, etc. which can also lead to fatal incidents. Apart from these, they are also susceptible to irreversible health issues arising out of exposure to dust & other harmful substances.Project execution & construction activities have been one of the most challenging activities in Tata Steel because of a large diversity in geographical locations, types of operations & various process requirements. The organization has undertaken many greenfield as well as brownfield projects which both have different kinds of risks involved. Since the last few years, Tata Steel has taken many initiatives to mitigate the hazards & reduce the incidents in construction activities. One of the major steps taken in this direction was the implementation of Prevention through Design (PtD) in projects. This included adoption of practices like virtual design & construction, use of bolted & prefabricated structures, laser scanning & 3D modeling, powered access system, e-work permit, site access control and AI-based CCTV surveillance for monitoring of site activities among many others. Prevention through design is a transdisciplinary process which aims at reducing the hazards in the design & planning phase itself, making the construction activities inherently safer and their safety management cheaper. Risk identification & prioritization is done for each job according to a risk heat map based on the potential consequences of each hazardous event & its likelihood of occurrence. The top risks are identified & design interventions are proposed to eliminate or substitute them.Prevention through design, powered by automation & digitized safety management systems, is widely gaining use in several operations as well as construction projects due to its advantages and ease of implementation. The adoption of these safety technologies & automation has helped in proactively mitigating risks & significantly increased the effectiveness of health & safety management systems at construction sites. The construction companies should adopt these safety practices & policies, that combined with the implementation of digital health & safety tools & techniques could assist site managers ensure efficiency of their construction projects.This paper discusses the methodologies adopted at Tata Steel to implement prevention through design in construction projects and their effect on the health & safety performance of the organization.","10.1109/ICMIAM54662.2021.9715221","IEEE Conferences","2021","","IEEE"
"Agent-based Testing of Extended Reality Systems","Testing for quality assurance (QA) is a crucial step in the development of Extended Reality (XR) systems that typically follow iterative design and development cycles. Bringing automation to these testing procedures will increase the productivity of XR developers. However, given the complexity of the XR environments and the User Experience (UX) demands, achieving this is highly challenging. We propose to address this issue through the creation of autonomous cognitive test agents that will have the ability to cope with the complexity of the interaction space by intelligently explore the most prominent interactions given a test goal and support the assessment of affective properties of the UX by playing the role of users.","10.1109/ICST46399.2020.00051","IEEE Conferences","2020","","IEEE"
"The Drug-Like Molecule Pre-Training Strategy for Drug Discovery","Recent advances in artificial intelligence (AI) have led to the development of transformer-based models that have shown success in identifying potential drug molecules for therapeutic purposes. However, for a molecule to be considered a viable drug candidate, it must exhibit certain desirable properties such as low toxicity, high druggability, and synthesizability. To address this, we propose an approach that incorporates prior knowledge about these properties during the model training process. In this study, we utilized the PubChem database, which contains 100 million molecules, to filter drug-like molecules based on the quantity of drug-likeliness (QED) score and the Pfizer rule. We then used this filtered dataset of drug-like molecules to train both molecular representation (ChemBERTa) and molecular generation models (MolGPT). To assess the performance of the molecular representation model, we fine-tuned the results on the MoleculeNet benchmark datasets. Meanwhile, we evaluated the performance of the molecular generation model based on the generated samples comprising 10,000 molecules. Despite the limited diversity of the pre-training dataset, the models for molecular representation were able to retain at least 90% of their original performance on benchmark datasets, with an additional improvement of 6% in predicting clinical toxicology. In the domain of molecular generation, the model pre-trained on drug-like molecules exhibited a high rate of desirable molecule properties in the unconditionally generated outputs. Additionally, the diversity of generated structures demonstrated notable performance compared to the conditional generation approach. Moreover, the drug-like molecule pre-training strategy is not limited to a specific model or training method, making it a flexible approach that can be easily modified based on the research interests and criteria of interest.","10.1109/ACCESS.2023.3285811","IEEE Journals","2023","","IEEE"
"SignExplainer: An Explainable AI-Enabled Framework for Sign Language Recognition With Ensemble Learning","Deep learning has significantly aided current advancements in artificial intelligence. Deep learning techniques have significantly outperformed more than typical machine learning approaches, in various fields like Computer Vision, Natural Language Processing (NLP), Robotics Science, and Human-Computer Interaction (HCI). Deep learning models are ineffective in outlining their fundamental mechanism. That’s the reason the deep learning model mainly consider as Black-Box. To establish confidence and responsibility, deep learning applications need to explain the model’s decision in addition to the prediction of results. The explainable AI (XAI) research has created methods that offer these interpretations for already trained neural networks. It’s highly recommended for computer vision tasks relevant to medical science, defense system, and many more. The proposed study is associated with XAI for Sign Language Recognition. The methodology uses an attention-based ensemble learning approach to create a prediction model more accurate. The proposed methodology used ResNet50 with the Self Attention model to design ensemble learning architecture. The proposed ensemble learning approach has achieved remarkable accuracy at 98.20%. In interpreting ensemble learning prediction, the author has proposed SignExplainer to explain the relevancy (in percentage) of predicted results. SignExplainer has illustrated excellent results, compared to other conventional Explainable AI models reported in state of the art.","10.1109/ACCESS.2023.3274851","IEEE Journals","2023","","IEEE"
"Artificial Learning for Part Identification in Robotic Disassembly Through Automatic Rule Generation in an Ontology","With the increasing concern for sustainable treatment of waste electrical and electronic equipment (WEEE), methods of robotic disassembly of WEEE to address various challenges of handling end-of-life products has been a trend in research. The main challenge for robotic disassembly is the uncertainties of product structures, models, and conditions. The ability of a robotic disassembly system to learn new product structures and reason about existing knowledge of product structure is vital to addressing this challenge. This paper presents an effective learning framework and demonstrates the system’s ability to learn relevant information for the disassembly of LCD monitors. The learning algorithm uses a database of previous disassembly experience of the product family and analyses it to create rules and relations between the components and disassembly concepts before expanding the generic ontology for future disassembly runs. The results show a significant increase from 11% to 87% in successful part identification of LCD monitors after being trained on past disassembly experience. The proposed method can greatly aid robotic disassembly of any product family. Note to Practitioners—Robotic systems struggle to disassemble electronic waste due to the complexity and uncertainties in end-of-life products and variations in models and parts. An artificially intelligent method is proposed to enable a robotic disassembly system to address these uncertainties. The method uses a computing technique resembling the cognitive reasoning of a human mind in the form of a map of disassembly concepts connected by relationships. Artificial learning by the robotic system occurs by collecting data from previous disassembly runs of a product, analyzing the data, and expanding the map of knowledge with new concepts and relational rules found. The approach is tested on the robotic disassembly system’s ability to identify parts of LCD monitors which possess uncertainties. An improvement from 11% of successful part identification to 87% is found, which demonstrate that learning has taken place. This approach will be implemented in a larger robotic disassembly system and tested with real robotic disassembly runs in the near future.","10.1109/TASE.2022.3149242","IEEE Journals","2023","","IEEE"
"A Survey on Ethical Principles of AI and Implementations","AI has powerful capabilities in prediction, automation, planning, targeting, and personalisation. Generally, it is assumed that AI can enable machines to exhibit human-like intelligence, and is claimed to benefit to different areas of our lives. Since AI is fueled by data and is a distinct form of autonomous and self-learning agency, we are seeing increasing ethical concerns related to AI uses. In order to mitigate various ethical concerns, national and international organisations including governmental organisations, private sectors as well as research institutes have made extensive efforts by drafting ethical principles of AI, and having active discussions on ethics of AI within and beyond the AI community. This paper investigates these efforts with a focus on the identification of fundamental ethical principles of AI and their implementations. The review found that there is a convergence around limited principles and the most prevalent principles are transparency, justice and fairness, responsibility, non-maleficence, and privacy. The investigation suggests that ethical principles need to be combined with every stages of the AI lifecycle in the implementation to ensure that the AI system is designed, implemented and deployed in an ethical manner. Similar to ethical framework used in biomedical and clinical research, this paper suggests checklist-style questionnaires as benchmarks for the implementation of ethical principles of AI.","10.1109/SSCI47803.2020.9308437","IEEE Conferences","2020","","IEEE"
"AI-Based and Digital Mental Health Apps: Balancing Need and Risk","Mental health and well-being are increasingly important topics in discussions on public health [1]. The COVID-19 pandemic further revealed critical gaps in existing mental health services as factors such as job losses and corresponding financial issues, prolonged physical illness and death, and physical isolation led to a sharp rise in mental health conditions [2]. As such, there is increasing interest in the viability and desirability of digital mental health applications. While these dedicated applications vary widely, from platforms that connect users with healthcare professionals to diagnostic tools to self-assessments, this article specifically explores the implications of digital mental health applications in the form of chatbots [3]. Chatbots can be text based or voice enabled and may be rule based (i.e., linguistics based) or based on machine learning (ML). They can utilize the power of conversational agents well-suited to task-oriented interactions, like Apple’s Siri, Amazon’s Alexa, or Google Assistant. But increasingly, chatbot developers are leveraging conversational artificial intelligence (AI), which is the suite of tools and techniques that allow a computer program to seemingly carry out a conversational experience with a person or a group.","10.1109/MTS.2023.3241309","IEEE Magazines","2023","","IEEE"
"A Deep Learning Methodology to Detect Trojaned AI-based DDoS Defend Model","DDoS attack arranges bots to send low-speed traffic to backbone links and paralyze all servers in the target area. DDoS is difficultly defended due to the two research problems (1) indistinguishability of the changing DDoS characteristics and (2) the time series attack pattern, leading that the raising attention of developing varying DDoS defending methodologies. The conventional methods to defend DDoS apply a rules-based methodology that relies on the experience of algorithm designers and cannot reflect the changing attack characteristics of DDoS in a timely manner. Numerous artificial intelligence (AI) methodologies, therefore, are introduced to defend DDoS through end-to-end functionality (Input: network status; Output: defending action) without any manual intervention. However, the AI-based DDoS Defending model often outsources training to a machine-learning-as-a-service (MLaaS) provider because of the scarce training dataset and high hardware requirement. This may cause the model been trained maliciously, which is called the Artificial Intelligence Trojan attack (AI Trojan). AI Trojan means an AI model encounters a malicious training process and then have a good performance on normal data but behaves maliciously with certain data. This study proposes GAN based AI Robustness test algorithm, Deep Learning Attack Generator (DLAG), to verify that the artificial intelligence model has been fully trained to ensure the robustness of the model. DLAG can be divided into five steps: (1) DLAG randomly generates a sample, (2) generates noise that participates in the generation of a confrontation network (DLAG), (3) input the synthetic sample to the testing AI, (4) the test results will be recorded in the test report and fed back to GAN, and (5) a new synthetic sample will be generated again for the next test cycle. The simulation shows that our proposed DLAG can detect that the AI based DDoS/LFA detector is trained by imbalance data. The simulation results also demonstrate the potential and suggested development trait of AI Trojan detection methodology.","10.1109/ICARA55094.2022.9738571","IEEE Conferences","2022","","IEEE"
"AI based Diagnostic Service for IOT enabled Smart Refrigerators","High end refrigerators come with an ice dispensing unit that provides ice cubes and crushed ice. These refrigerators often face “Ice Maker Freeze” issue causing them to stop dispensing ice. As a user, this is highly undesirable who is often left wondering as to what caused this issue. Recent trends have seen an increase in consumers opting for IoT enabled devices. These devices log their device state at regular intervals and this data can be leveraged to help predict such issues in the refrigerator before they happen. Such predictive maintenance solutions would require Machine Learning and Big Data processing wherein trends are studied and behaviors learnt for future prediction. In this paper, we propose a cloud based AI (Artificial Intelligence) solution which uses refrigerator sensor data to figure out if the device is going to have an ice-dispensing problem in the near future. This information can be shared to end users with a set of preventive steps, which in turn results in lower maintenance costs and improved user experience. This solution is built by analyzing the data gathered from 300K refrigerator devices and we were able to achieve a 90% precision in predicting possible fault scenarios.","10.1109/FiCloud49777.2021.00031","IEEE Conferences","2021","","IEEE"
"Generative AI-empowered Effective Physical-Virtual Synchronization in the Vehicular Metaverse","Metaverse seamlessly blends the physical world and virtual spaces through ubiquitous communication and computing equipment and infrastructure. In intelligent transportation systems, the vehicular Metaverse can provide a fully immersive and hyperreal travel experience (e.g., via augmented reality head-up displays, AR-HUDs) to drivers and passengers in autonomous vehicles (AVs) through roadside units (RSUs). However, providing real-time and immersive services requires effective physical-virtual synchronization between AVs and virtual simulators. This paper proposes a generative AI-empowered physical-virtual synchronization framework for the vehicular Metaverse. In physical-to-virtual synchronization, digital twin (DT) tasks generated by AVs are offloaded for execution in RSUs with future route generation. In virtual-to-physical synchronization, virtual simulators customize diverse and personalized AR content via generative AI models based on user preferences. Furthermore, we propose a multi-task enhanced auction-based mechanism to match and price AVs and virtual simulators for RSUs to provide real-time and effective services. Finally, property analysis and experimental results demonstrate that the proposed mechanism is strategy-proof and adverse-selection free while increasing social surplus.","10.1109/MetaCom57706.2023.00106","IEEE Conferences","2023","","IEEE"
"An Efficient Vertical Handoff Choice in Subsequent Generation Wireless Networks","Next Generation (4G) wireless networks tend to be diverse, integrating unlike networks to provide constant admission for mobile users with multi mode access potential. The Next creation communications systems are about a worldwide wireless communications system and define a cost efficient, adapted according to the users' needs concept. Within this research paper an efficient vertical handoff conclusion is planned. A refined, intelligent Associative Rule Mining (ARM) and Artificial Intelligence (AI) based technique is mandatory to execute the vertical handoff system in subsequent generation wireless networks to create an valuable service which reduces handoff delay and convolution.","10.1109/ICICS.2018.00048","IEEE Conferences","2018","","IEEE"
"Potential Information Security Risks in The Implementation of AI - Based Systems","At present, technological solutions based on artificial intelligence (AI) are being accelerated in various sectors of the economy and social relations in the world. Practice shows that fast-developing information technologies, as a rule, carry new, previously unidentified threats to information security (IS). It is quite obvious that identification of vulnerabilities, threats and risks of AI technologies requires consideration of each technology separately or in some aggregate in cases of their joint use in application solutions. Of the wide range of AI technologies, data preparation, DevOps, Machine Learning (ML) algorithms, cloud technologies, microprocessors and public services (including Marketplaces) have received the most attention. Due to the high importance and impact on most AI solutions, this paper will focus on the key AI assets, the attacks and risks that arise when implementing AI-based systems, and the issue of building secure AI.","10.1109/Dynamics56256.2022.10014814","IEEE Conferences","2022","","IEEE"
"A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle","Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual’s privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.","10.1109/ACCESS.2023.3287195","IEEE Journals","2023","","IEEE"
"Space Applications of a Trusted AI Framework: Experiences and Lessons Learned","Artificial intelligence (AI), which encompasses machine learning (ML), has become a critical technology due to its well-established success in a wide array of applications. However, the proper application of AI remains a central topic of discussion in many safety-critical fields. This has limited its success in autonomous systems due to the difficulty of ensuring AI algorithms will perform as desired and that users will understand and trust how they operate. In response, there is growing demand for trustability in AI to address both the expectations and concerns regarding its use. The Aerospace Corporation (Aerospace) developed a Framework for Trusted AI (henceforth referred to as the framework) to encourage best practices for the implementation, assessment, and control of AI-based applications. It is generally applicable, being based on terms and definitions that cut across AI domains, and thus is a starting point for practitioners to tailor to their particular application. To help demonstrate how the framework can be tailored into mission assurance guidance for the space domain, Aerospace sought the involvement of the Jet Propulsion Laboratory (JPL) to engage with actual examples of AI-based space autonomy. We report here on the framework's application to two JPL projects. The first, Machine learning-based Analytics for Automated Rover Systems (MAARS), is a suite of algorithms that is intended to run onboard a rover to enhance its safety and productivity. The second, the Ocean Worlds Life Surveyor (OWLS), is comprised of an instrument suite and onboard software that is designed to search for life on an icy moon using microscopy and mass spectrometry while judiciously summarizing and prioritizing science data for downlink. Both MAARS and OWLS are intended to have minimal manual control while relying on complex autonomy software to operate within the unforgiving environment of deep space. Therefore, trusted AI for these systems is required for successful adoption of the autonomy software. To capture the needs for trust, interviews with a variety of JPL personnel responsible for developing autonomy solutions were conducted and are summarized here. Additionally, the application of the framework is presented as a means to lower the barrier for AI deployment. The intent of this document is to encourage researchers, engineers, and program managers to adopt new strategies when considering whether to leverage AI in autonomous systems.","10.1109/AERO53065.2022.9843322","IEEE Conferences","2022","","IEEE"
"Effects of Extended Stochastic Gradient Descent Algorithms on Improving Latent Factor-Based Recommender Systems","High-dimensional and sparse (HiDS) matrices from recommender systems contain various useful patterns. A latent factor (LF) analysis is highly efficient in grasping these patterns. Stochastic gradient descent (SGD) is a widely adopted algorithm to train an LF model. Can its extensions be capable of further improving an LF models' convergence rate and prediction accuracy for missing data? To answer this question, this work selects two of representative extended SGD algorithms to propose two novel LF models. Experimental results from two HiDS matrices generated by real recommender systems show that compared standard SGD, extended SGD algorithms enable an LF model to achieve a higher prediction accuracy for missing data of an HiDS matrix, a faster convergence rate, and a larger model diversity.","10.1109/LRA.2019.2891986","IEEE Journals","2019","","IEEE"
"Model-Driven Prompt Engineering","Generative artificial intelligence (AI) systems are capable of synthesizing complex content such as text, source code or images according to the instructions described in a natural language prompt. The quality of the output depends on crafting a suitable prompt. This has given rise to prompt engineering, the process of designing natural language prompts to best take advantage of the capabilities of generative AI systems.Through experimentation, the creative and research communities have created guidelines and strategies for creating good prompts. However, even for the same task, these best practices vary depending on the particular system receiving the prompt. Moreover, some systems offer additional features using a custom platform-specific syntax, e.g., assigning a degree of relevance to specific concepts within the prompt.In this paper, we propose applying model-driven engineering to support the prompt engineering process. Using a domain-specific language (DSL), we define platform-independent prompts that can later be adapted to provide good quality outputs in a target AI system. The DSL also facilitates managing prompts by providing mechanisms for prompt versioning and prompt chaining. Tool support is available thanks to a Langium-based Visual Studio Code plugin.","10.1109/MODELS58315.2023.00020","IEEE Conferences","2023","","IEEE"
"Ethical Chatbot Design for Reducing Negative Effects of Biased Data and Unethical Conversations","AI technology is being introduced into various public and private service domains, transforming existing computing systems or creating new ones. While AI technologies can provide benefits to humans and society, the unexpected consequences (e.g., malfunctions) of AI systems can cause social losses. For this reason, research on ethical design for the development of AI-based systems is becoming important. In this paper, from existing studies on AI ethics, general guidelines such as transparency, explainability, predictability, accountability, fairness, privacy, and control for the ethical design of AI systems are reviewed. And, based on the ethical design guidelines, we discuss ethical design to reduce the negative effects of biased data and unethical dialogues in AI-based conversational chatbots.","10.1109/PlatCon53246.2021.9680760","IEEE Conferences","2021","","IEEE"
"Applying a Trustworthy AI Framework to Mitigate Bias and Increase Workforce Gender Diversity","Organizations increasingly use artificial intelligence (AI) technologies in their screening and recruiting process. However, AI-enabled recruiting and talent management tools have also introduced risks of unfair bias that may compromise workforce diversity. This conceptual paper frames an ethical discussion regarding gender equity in AI-enabled workforce decision applications. The authors examined several real-world cases in which AI was used in talent acquisition. The ensuing question is whether the use of AI in the hiring process can be turned into an advantage to improve gender equity. To address the question, a multi-faceted trustworthy AI framework was reviewed and applied to the workforce decision context. A list of implementation guidelines is proposed to mitigate bias and increase diversity in the IT workforce. The authors aim to stimulate further discussions and investigation on this complex topic and to call for action to develop educational programs or awareness campaigns on trustworthy AI, so improving gender equity in technology hiring.","10.1109/ISTAS55053.2022.10227119","IEEE Conferences","2022","","IEEE"
"AI Based Chat-Bot Using Azure Cognitive Services","Letters ruled the earlier era in communication. Then with emergence of Telephones and subsequently mobile phones, voice conversations ruled the communication. However, currently, with the emergence of Internet and lots of social media, chat conversations are ruling the world. Think of your closest friend and ask yourself, have you talked more or chatted more? So, with popularity of chat in today's world, many technologists envisioned that chat couldn't just be a mode of communication between humans but also between a human and a computer. That's what chat-bot is. In some cases it is powered by machine learning (the more you interact with the chat-bot the smarter it gets). Or, more commonly, it is driven using intelligent rules (i.e. if a person says this, respond with that). A chat-bot can be useful in providing services in a variety of scenarios. These services include life-saving health messages, it may also include weather forecast or to purchase a new laptop, smartphone, and anything else in between. Many of the big companies like Google (Google Assistant), Amazon (Alexa), Microsoft (Cortana) and Oracle are spending good amount of energy and money for research on personal assistants. The following subjects would be touched upon for the development of chat-bot: · Using Azure Bot Architecture · Using NLP for Language Understanding from the user and for the Language Generation · Using Custom Vision services for the image recognition.","10.1109/ICCUBEA.2018.8697737","IEEE Conferences","2018","","IEEE"
"AI-Based Military Decision Support Using Natural Language","To mimic a realistic representation of military operations, serious combat simulations require sound tactical behavior from modeled entities. Therefore, one must define combat tactics, doctrines, rules of engagement, and concepts of operation. Reinforcement learning has been proven to generate a broad range of tactical actions within the behavioral boundaries of the involved entities. In a multi-agent ground combat scenario, this paper demonstrates how our artificial intelligence (AI) application develops strategies and provides orders to subsidiary units while conducting missions accordingly. We propose a combined approach where human knowledge and responsibility collaborate with an AI system. To communicate on a common level, the orders and actions imposed by AI are given in natural language. This empowers the human operator to act in a human-on-the-loop role in order to validate and evaluate the reasoning of AI. This paper showcases the successful integration of natural language into the reinforcement learning process.","10.1109/WSC57314.2022.10015234","IEEE Conferences","2022","","IEEE"
"Implementation of A Fuzzy Logic Progression For Alcohol Addicts Using Fuzzy Control System(FCS)","The use of the Reduced Alcohol Intake (RAI) logic model is to help monitor alcoholic addicts and help them reduce alcohol intake for a better life and improved academic performance. The purpose of this study is to use the Mamdani Fuzzy Inference System (MFIS) component, which includes the application of a T-S (Takagi-Sugeno) model-based Fuzzy Control System (FCS) and a Fuzzy Logic System (FLS) as a rule-based system (Fuzzy Control System - FCS) to assemble all inputs in the RAI model to achieve classified fuzzy outputs. As initiated in the theoretical logic model (the RAI logic model), there is a direct identification of breakpoints for a transition between phases in the model. Thus, it can be used as an AI system that is efficient to monitor and examine the progression of alcohol addicts (to know what percentage of improvement they have reached overtime). Using the T-S method, the core parameters (motivation and self-determined state) of the RAI model were analyzed to find a linear interaction between the existing variables. In this paper, the variables of motivation and self-determined state are scaled between 0 to 10 to predict the level of improvement in percentage (%).","10.1109/SISY50555.2020.9217079","IEEE Conferences","2020","","IEEE"
"AI Based Smart Remedial Observants in COVID-19 Crisis","Coronavirus disease (COVID-19) is a contagious [1] disease caused by becoming infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [2]. Numerous nations have acquainted social distancing measures to slow down the spread of the COVID-19 pandemic as people can spread the virus before they know they are sick. The solution focuses on a web-based solution to alert the residents and outsiders in case of any non-compliance of rules. In this work, an AI-powered solution is developed that leverages Machine learning based algorithm to guarantee that individuals are keeping up a safe distance from one another. A software-based approach is taken for providing a simple and engaging user experience to the user that will help the society and other authorities track and analyses the implications of such rules. The web application will be used to alert the users in case of any breaking of the law. Along with this, a system that detects if people are wearing a mask or not will also be verified by the algorithm. The model built can be deployed in the existing CCTV cameras to monitor each and every place of gathering without the need for any additional hardware systems.","10.1109/ICCICT50803.2021.9510051","IEEE Conferences","2021","","IEEE"
"AI-based speed control models for the autonomous train: a literature review","The railway industry recently showed interest in the potential use of AI to render trains autonomous in order to reduce cost and improve security and performance. This paper focuses on the integration of AI into Automatic Train Operation (ATO) systems to control train speed. The objective of this paper is to present and analyze a review of the literature made in that context. The review is done according to a typology based on three axis: the inputs and objectives of the model, the AI method used by authors and last, the validation process. Our review shows that AI based approaches outperform classical approaches and that learning based methods are superior to rule-based systems. Meanwhile, the contributions present incomplete validation processes, difficulties to generalize the proposed AI method and last, a lack of use of perceptual data during decision making. This analysis enables us to draw some prospects relevant to the solving of the listed limitations.","10.1109/TST52996.2021.00009","IEEE Conferences","2021","","IEEE"
"A Spectroscopy-Based Sensor for the AI-Based Classification of Lipemic and Hematic Parameters","Dyslipidemias are chronic conditions characterized by elevated levels of LDL cholesterol and/or triglycerides in the bloodstream. Guidelines from the European Society of Cardiology recommended lipoprotein apheresis (LA) as the last-resort therapy for severe cases of familial hypercholesterolemia. However, LA devices equipped with a blood leak detector (BLD) sensor often generate false alarms due to turbidity caused by serum lipoproteins. This letter presents a protocol for creating hyperlipemic plasma samples and proposes the use of a microspectrometer-based BLD sensor to collect the spectra. Furthermore, to address the false alarm problem (blood rate ≥0.7%), we developed a first approach using thresholding and linear support vector machine (SVM). In addition, to improve data classification performance, three artificial neural networks (ANNs) were developed with different classification tasks, then applied to four different databases. ANNs aim to solve the problem of false alarms and accurately classify samples based on blood and phospholipids concentration, achieving 99% accuracy for data classification based on the combination of phospholipids and blood percentage.","10.1109/LSENS.2023.3316878","IEEE Journals","2023","","IEEE"
"Software Engineering for Machine Learning: A Case Study","Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be ""entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.","10.1109/ICSE-SEIP.2019.00042","IEEE Conferences","2019","","IEEE"
"Using Knowledge Graphs to Unlock Practical Collection, Integration, and Audit of AI Accountability Information","To enhance trustworthiness of AI systems, a number of solutions have been proposed to document how such systems are built and used. A key facet of realizing trust in AI is how to make such systems accountable - a challenging task, not least due to the lack of an agreed definition of accountability and differing perspectives on what information should be recorded and how it should be used (e.g., to inform audit). Information originates across the life cycle stages of an AI system and from a variety of sources (individuals, organizations, systems), raising numerous challenges around collection, management, and audit. In our previous work, we argued that semantic Knowledge Graphs (KGs) are ideally suited to address those challenges and we presented an approach utilizing KGs to aid in the tasks of modelling, recording, viewing, and auditing accountability information related to the design stage of AI system development. Moreover, as KGs store data in a structured format understandable by both humans and machines, we argued that this approach provides new opportunities for building intelligent applications that facilitate and automate such tasks. In this paper, we expand our earlier work by reporting additional detailed requirements for knowledge representation and capture in the context of AI accountability; these extend the scope of our work beyond the design stage, to also include system implementation. Furthermore, we present the RAInS ontology which has been extended to satisfy these requirements. We evaluate our approach against three popular baseline frameworks, namely, Datasheets, Model Cards, and FactSheets, by comparing the range of information that can be captured by our KGs against these three frameworks. We demonstrate that our approach subsumes and extends the capabilities of the baseline frameworks and discuss how KGs can be used to integrate and enhance accountability information collection processes.","10.1109/ACCESS.2022.3188967","IEEE Journals","2022","","IEEE"
"A Study on Product Recommendation System based on Deep Learning and Collaborative Filtering","This essay analyses and contrasts the literature that has already been written about various product recommendation systems and the mechanisms that underlie them. Although there are many research contributions in the literature, in this article I have critically and thoroughly examined recent research and review papers that are relevant to AI-based product recommendation systems. The present techniques are divided into groups based on the fundamental ideas included into their processes. The idea put out by the concerned writers, the experimental technique, and the performance assessment criteria are highlighted. Also noted are the researchers' assertions. The flaws that have been found are highlighted together with our results from the thorough literature study. This work is crucial for the comparison of different AI-based product recommendation systems, which is a necessary step before dealing with related problems. Following a review of the literature, I have put up a system for recommending products to users, in which the tool suggests products that a particular user would want to buy. I have gathered information about items and users by using ML algorithms. The suggested system establishes a link between the people and the products.","10.1109/ICAECT57570.2023.10117628","IEEE Conferences","2023","","IEEE"
"State of AI-Based Monitoring in Smart Manufacturing and Introduction to Focused Section","Over the past few decades, intelligentization, supported by artificial intelligence (AI) technologies, has become an important trend for industrial manufacturing, accelerating the development of smart manufacturing. In modern industries, standard AI has been endowed with additional attributes, yielding the so-called industrial artificial intelligence (IAI) that has become the technical core of smart manufacturing. AI-powered manufacturing brings remarkable improvements in many aspects of closed-loop production chains from manufacturing processes to end product logistics. In particular, IAI incorporating domain knowledge has benefited the area of production monitoring considerably. Advanced AI methods such as deep neural networks, adversarial training, and transfer learning have been widely used to support both diagnostics and predictive maintenance of the entire production process. It is generally believed that IAI is the critical technologies needed to drive the future evolution of industrial manufacturing. This article offers a comprehensive overview of AI-powered manufacturing and its applications in monitoring. More specifically, it summarizes the key technologies of IAI and discusses their typical application scenarios with respect to three major aspects of production monitoring: fault diagnosis, remaining useful life prediction, and quality inspection. In addition, the existing problems and future research directions of IAI are also discussed. This article further introduces the papers in this focused section on AI-based monitoring in smart manufacturing by weaving them into the overview, highlighting how they contribute to and extend the body of literature in this area.","10.1109/TMECH.2020.3022983","IEEE Journals","2020","","IEEE"
"Intelligent Traffic Management System: AI-Enabled IoT Traffic Lights to Mitigate Accidents and Minimize Environmental Pollution","Reducing traffic and pollution is crucial for the well-being of both people and the planet. These issues mainly affect developing nations due to rapid urbanization and limited infrastructure. This paper emphasizes the development of smart traffic management systems that monitor and control traffic flow, lessen congestion, and shorten travel times using IoT and LoRa. Lowering the number of vehicles on the road can lower fuel use and emissions. IoT can also gather real-time data on air quality, which can help pollution reduction efforts and inform air quality policies.","10.1109/CONIT59222.2023.10205868","IEEE Conferences","2023","","IEEE"
"What is Software Quality for AI Engineers? Towards a Thinning of the Fog","It is often overseen that AI-enabled systems are also software systems and therefore rely on software quality assurance (SQA). Thus, the goal of this study is to investigate the software quality assurance strategies adopted during the development, integration, and maintenance of AI/ML components and code. We conducted semi-structured interviews with representatives of ten Austrian SMEs that develop AI-enabled systems. A qualitative analysis of the interview data identified 12 issues in the development of AI/ML components. Furthermore, we identified when quality issues arise in AI/ML components and how they are detected. The results of this study should guide future work on software quality assurance processes and techniques for AI/ML components.","10.1145/3522664.3528599","IEEE Conferences","2022","","IEEE"
"Neuro-Inspired Plasticity for Biologically Realistic Self-Adaptation of Neural Network Weights","The Prefrontal Cortex is the core of higher level learning and memory. It currently operates much like an AI system, in the sense that its actions are guided via a dopamine based reward function, however there is one critical difference, the PFC has the ability to rewire itself - plasticity. Here, we look to biological studies to find the governing rules of plasticity - competitiveness, memory, and correlation - to create a biologically plausible implementation of plasticity called Hybrid Plasticity. We implement it in continuous time recurrent neural networks (CTRNNS) completing simple working memory tasks. We show that the implementation of plasticity increases the adaptability of the working memory process within networks, while also resulting in a significant decrease in active neurons within the network indicating higher efficiency. We further demonstrate that plasticity results in an increased small world index, indicating high levels of efficiency, parallel processing, and cognitive integration as proposed by Global Workspace Theory. Plasticity CTRNNs are also shown to self organize into brain-like connectivity patterns including inhibitory clusters, excitatory clusters, and inhibitory autapses during their forward pass. Hence, Hybrid Plasticity represents a proof-of-concept solution for bringing forth biologically realistic phenomena within neural networks resulting in increased efficiency and generalizability.","10.1109/ICDL55364.2023.10364505","IEEE Conferences","2023","","IEEE"
"AI-Powered Ransomware Detection Framework","Ransomware attacks are taking advantage of the ongoing pandemics and attacking the vulnerable systems in business, health sector, education, insurance, bank, and government sectors. Various approaches have been proposed to combat ransomware, but the dynamic nature of malware writers often bypasses the security checkpoints. There are commercial tools available in the market for ransomware analysis and detection, but their performance is questionable. This paper aims at proposing an AI-based ransomware detection framework and designing a detection tool (AIRaD) using a combination of both static and dynamic malware analysis techniques. Dynamic binary instrumentation is done using PIN tool, function call trace is analyzed leveraging Cuckoo sandbox and Ghidra. Features extracted at DLL, function call, and assembly level are processed with NLP, association rule mining techniques and fed to different machine learning classifiers. Support vector machine and Adaboost with J48 algorithms achieved the highest accuracy of 99.54% with 0.005 false-positive rates for a multi-level combined term frequency approach.","10.1109/SSCI47803.2020.9308387","IEEE Conferences","2020","","IEEE"
"Analysis of Crypto-Ransomware Using ML-Based Multi-Level Profiling","Crypto-ransomware is the most prevalent form of modern malware, has affected various industries, demanding a significant amount of ransom. Mainly, small businesses, healthcare, education, and government sectors have been under continuous attacks by these adversaries. Various static and dynamic analysis techniques exist, but these methods become less efficient as the malware writers continuously trick the defenders. Numerous research of ransomware with AI techniques often lack the behavioral analysis and its correlation mapping. In this work, we developed an AI-powered hybrid approach overcoming the recent challenges to detect ransomware. Specifically, we proposed a deep inspection approach for multi-level profiling of crypto-ransomware, which captures the distinct features at Dynamic link library, function call, and assembly levels. We showed how the code segments correlate at these levels for studied samples. Our hybrid multi-level analysis approach includes advanced static and dynamic methods and a novel strategy of analyzing behavioral chains with AI techniques. Moreover, association rule mining, natural language processing techniques, and machine learning classifiers are integrated for building ransomware validation and detection model. We experimented with crypto-ransomware samples (collected from VirusTotal). One of the machine learning algorithms achieved the highest accuracy of 99.72% and a false positive rate of 0.003 with two class datasets. The result exhibited that multi-level profiling can better detect ransomware samples with higher accuracy. The multi-level feature sequence can be extracted from most of the applications running in the different operating systems; therefore, we believe that our method can detect ransomware for devices on multiple platforms. We designed a prototype, AIRaD (AI-based Ransomware Detection) tool, which will allow researchers and the defenders to visualize the analysis with proper interpretation.","10.1109/ACCESS.2021.3109260","IEEE Journals","2021","","IEEE"
"Predicting the Time Until a Vehicle Changes the Lane Using LSTM-Based Recurrent Neural Networks","To plan safe and comfortable trajectories for automated vehicles on highways, accurate predictions of traffic situations are needed. So far, a lot of research effort has been spent on detecting lane change maneuvers rather than on estimating the point in time a lane change actually happens. In practice, however, this temporal information might be even more useful. This letter deals with the development of a system that accurately predicts the time to the next lane change of surrounding vehicles on highways using long short-term memory-based recurrent neural networks. An extensive evaluation based on a large real-world data set shows that our approach is able to make reliable predictions, even in the most challenging situations, with a root mean squared error around 0.7 seconds. Already 3.5 seconds prior to lane changes the predictions become highly accurate, showing a median error of less than 0.25 seconds. In summary, this article forms a fundamental step towards downstreamed highly accurate position predictions.","10.1109/LRA.2021.3058930","IEEE Journals","2021","","IEEE"
"iART: Learning From Demonstration for Assisted Robotic Therapy Using LSTM","In this letter, we present an intelligent Assistant for Robotic Therapy (iART), that provides robotic assistance during 3D trajectory tracking tasks. We propose a novel LSTM-based robot learning from demonstration (LfD) paradigm to mimic a therapist's assistance behavior. iART presents a trajectory agnostic LfD routine that can generalize learned behavior from a single trajectory to any 3D shape. Once the therapist's behavior has been learned, iART enables the patient to modify this behavior as per their preference. The system requires only a single demonstration of 2 minutes and exhibits a mean accuracy of 91.41% in predicting, and hence mimicking a therapist's assistance behavior. The system delivers stable assistance in realtime and successfully reproduces different types of assistance behaviors.","10.1109/LRA.2019.2961845","IEEE Journals","2020","","IEEE"
"A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System","Today, many systems use artificial intelligence (AI) to solve complex problems. While this often increases system effectiveness, developing a production-ready AI-based system is a difficult task. Thus, solid AI engineering practices are required to ensure the quality of the resulting system and to improve the development process. While several practices have already been proposed for the development of AI-based systems, detailed practical experiences of applying these practices are rare.In this paper, we aim to address this gap by collecting such experiences during a case study, namely the development of an autonomous stock trading system that uses machine learning functionality to invest in stocks. We selected 10 AI engineering practices from the literature and systematically applied them during development, with the goal to collect evidence about their applicability and effectiveness. Using structured field notes, we documented our experiences. Furthermore, we also used field notes to document challenges that occurred during the development, and the solutions we applied to overcome them. Afterwards, we analyzed the collected field notes, and evaluated how each practice improved the development. Lastly, we compared our evidence with existing literature.Most applied practices improved our system, albeit to varying extent, and we were able to overcome all major challenges. The qualitative results provide detailed accounts about 10 AI engineering practices, as well as challenges and solutions associated with such a project. Our experiences therefore enrich the emerging body of evidence in this field, which may be especially helpful for practitioner teams new to AI engineering.","10.1109/CAIN58948.2023.00032","IEEE Conferences","2023","","IEEE"
"AI Augmentation for Trustworthy AI: Augmented Robot Teleoperation","Despite the performance of state-of-the-art Artificial Intelligence (AI) systems, some sectors hesitate to adopt AI because of a lack of trust in these systems. This attitude is prevalent among high-risk areas, where there is a reluctance to remove humans entirely from the loop. In these scenarios, Augmentation provides a preferred alternative over complete Automation. Instead of replacing humans, AI Augmentation uses AI to improve and support human operations, creating an environment where humans work side by side with AI systems. In this paper, we discuss how AI Augmentation can provide a path for building Trustworthy AI. We exemplify this approach using Robot Teleoperation. We lay out design guidelines and motivations for the development of AI Augmentation for Robot Teleoperation. Finally, we discuss the design of a Robot Teleoperation testbed for the development of AI Augmentation systems.","10.1109/HSI49210.2020.9142659","IEEE Conferences","2020","","IEEE"
"AI-Augmented Early Warning Models for Commercial and SME Segments: Leveraging Unstructured Data and Time-Series Analytics","The Early Warning System is a critical application that uses advanced AI algorithms to monitor large amounts of data to detect potential payment difficulties f or c lients. In this paper, we present a novel approach to generate time-series indicators from new data sources such as Trade Registry Gazette announcements and records of the number of days of delinquency. Our method leverages machine learning algorithms such as Extreme Gradient Boosting (XGBoost) to identify hidden patterns and trends in these data sources, thus overcoming the problems with the traditional rule-based models. By analyzing this data, we can identify time-series anomalies and predict the likelihood of 10 days of delinquency 6 months ahead for the clients in the SME (Small and medium-sized enterprises) and Commercial segments. Our analysis demonstrates that our approach can achieve high accuracy in delinquency prediction, enabling financial i nstitutions t o t ake p roactive m easures to prevent potential losses. Our proposed method can enrich credit monitoring systems and enhance the ability of financial institutions to mitigate financial risk.","10.1109/UBMK59864.2023.10286634","IEEE Conferences","2023","","IEEE"
"An approach to mental image based understanding of natural language: Focused on static and dynamic spatial relations","It must be rather difficult for ordinary people to communicate with robots using special technical languages. Therefore, it must be more desirable for them to use natural language (NL) for such a purpose because it is the most conventional among them. This work proposes a methodology for natural language understanding through an AI system named Conversation Management System (CMS) based on Mental Image Directed Semantic Theory proposed by M. Yokota. CMS is intended to enable a robot to understand NL in the same way as people do, and actually can reach the most plausible semantic interpretation of an input text and return desirable outcomes by employing word concepts, postulates, and inference rules. Recently, the authors have applied several spatial terms in English language, for example verbs, prepositions (e.g. between, along, left, right, and so on). We found that the methodology is outstanding from conventional approaches with the attempt to provide robots understand NL based on mental image model. This paper focuses on how CMS understands static spatial (3D) relations expressed in NL.","10.1109/ICAwST.2017.8256457","IEEE Conferences","2017","","IEEE"
"“Black Box Justice”: Robot Judges and AI-based Judgment Processes in China’s Court System","Artificial Intelligence (AI) has been widely adopted in China's court system to improve work efficiency to better serve the public. This paper evaluates the three stages of how AI is transforming China's court system: from being a simple auxiliary tool, performing basic tasks through reconciliation of case and trial information; to assisting judges in decision-making by providing recommendations via the AI's ability to learn from past precedent and standardized evidence review; and finally, to developing into autonomous agents able to take charge of the court and make judgments as robot judges. However, public skepticism around the credibility of the so-called “black box” of AI algorithms in ensuring fair judgment and achieving justice is escalating, with the concern that efficiency does not guarantee effectiveness or ensure public interest. This paper aims to analyze “black box” issues in each stage and demonstrates why China's effort to pursue AI as an innovative technical practice to realize judicial fairness should take complex social and ethical contexts into consideration. In order to serve for public good in China's court system, the new technology must ensure its representation of human values and include public participation.","10.1109/ISTAS50296.2020.9462216","IEEE Conferences","2020","","IEEE"
"Data-Driven AI-Based Parameters Tuning Using Grid Partition Algorithm for Predicting Climatic Effect on Epidemic Diseases","Adaptive Neuro-fuzzy Inference System (ANFIS) remains one of the promising AI techniques to handle data over-fitting and as well, improves generalization. Presently, many ANFIS optimization techniques have been synergized and found effective at some points through trial and error procedures. In this work, we tune ANFIS using Grid partition algorithm to handle unseen data effectively with fast convergence. This model is initialized using a careful selection of effective parameters that discriminate climate conditions; minimum temperature, maximum temperature, average temperature, wind speed and relative humidity. These parameters are used as inputs for ANFIS, whereas confirmed cases of COVID-19 is chosen as dependent values for two consecutive months and first ten days of December for new COVID-19 confirmed cases according to the Department of disease control (DDC) Thailand. The proposed ANFIS model provides outstanding achievement to predict confirmed cases of COVID-19 with R2 of 0.99. Furthermore, data set trend analysis is done to compare fluctuations of daily climatic parameters, to satisfy our proposition, and illustrates the serious effect of these parameters on COVID-19 epidemic virus spread.","10.1109/ACCESS.2021.3068215","IEEE Journals","2021","","IEEE"
"Procedure2Command: an AI-based Nuclear Power Plant Control Command Code Generation Prototype System","Nuclear power plant control systems are complex and require extremely high safety. Safety operation procedure flowcharts drawn by experts with many pages are often used as the guidebooks to help human operators avoid improper operations. To help operators better use these flowcharts and reduce their mental burden, here we propose a control command code generation prototype system, which involves artificial intelligence technologies, especially natural language processing, to automatically translate the nuclear power plant safety operation procedure flowcharts into executable codes. The proposed system includes three components: a flowchart decomposition tool, a text-code translation dataset, and a deep-learning based code generation model. Experimental results show that our proposed method can generate command codes with comparable accuracy as manual translation in a much higher inference speed.","10.1109/ICMCCE51767.2020.00144","IEEE Conferences","2020","","IEEE"
"An AI Based Automatic Translator for Ancient Hieroglyphic Language—From Scanned Images to English Text","Recent advancements in the fields of Machine Learning and Deep Learning made a huge transformation in other fields that are not related to Computer Science. In this work, a new framework is proposed to tackle the problem of translating the old Egyptian Hieroglyphic writings to English language through deploying both Image Processing and Natural Language Processing techniques combined with AI approaches. Our primary goal is to design an application that completely revolutionizes a tourist’s experience while navigating Egyptian Historical sites. This work utilize different AI techniques to automatically convert the scanned photos of hieroglyphic language to understandable and readable English language, through two main sub-tasks: The automatic detection and recognizing of the scanned glyphs images and the translation of them into English language. Different data sources of this low-resource language were explored and augmented to train and test our models. Results of different models and algorithms are assessed and analyzed to evaluate our work. State-of-the-art results are achieved compared to literature in both automatic glyphs recognition, and glyphs-to-English translation.","10.1109/ACCESS.2023.3267981","IEEE Journals","2023","","IEEE"
"Automatic Alert Generation against Pre-defined Rules-set for Perimetric Security of Sensitive Premises using YOLOv3","Adaptation of artificial intelligence (AI) based solutions at sensitive locations is growing rapidly. Use of these techniques along with surveillance cameras has become a primary requirement of smart cities to convert data into intelligible information. Consequently, these solutions are minimizing the effort of training and reliance on human resource. In this research paper, we have devised use cases of object detection with focus on human and luggage detection in real-time using a Convolutional Neural Network (CNN) technique YOLOv3. This technique, trained on MS-COCO dataset, has not been able to produce desirable results when tested on images from subcontinent region containing luggage, human or both. As a case study, we enhanced MS-COCO dataset by incorporating our own collection of realistic images. The study is carried out on a commodity hardware to strengthen our claim to use technology over humans. The proposed solution is developed for analysing video streams in real time against a predefined rules-set. Idea to automate the process of surveillance at strategic locations without human intervention opens a new window of research for literary community to develop cost effective solutions.","10.1109/ICET48972.2019.8994686","IEEE Conferences","2019","","IEEE"
"AI Based Periodic Forecasting Rate Prediction with Secured Optimized Cryptographic Method Sales Forecasting in Retail Business Sector","Artificial intelligence is the recent development in security and data analysis 8n business sector for maximize profits using data processing technology. Today's business is managing huge databases to store more information need to safety. The amount of data is expected to increase further based on the business needs to forecasting the developing trends. The retail business sectors need new data processing technologies and intelligent forecast models of sales trends with greater potential accuracy in security and reliability. This is an important prerequisite for planning and decision making of a company is a big issue. To resolve this problem, we propose a security surveillance and sales forecasting in the retail business sector based on periodic forecasting rate (PFR) and advanced encryption security (AES) to protect the data. This provides decision making based data forecasting based on the previous data detains which is applied beads n successive feature prediction rate. Then the prediction result processed in business sector in secure cryptography using advance verified authentication to protect the data. This proposed system produces higher prediction rate in forecasting rate and security in higher level as well than other methods.","10.1109/IIHC55949.2022.10059792","IEEE Conferences","2022","","IEEE"
"CoupHM: Task Scheduling Using Gradient Based Optimization for Human-Machine Computing Systems","We witnessed great advancement in Artificial Intelligence (AI) powered technologies in recent years, and yet, when applied to certain high-stake contexts, such as medical diagnosis, automatic driving and criminal justice, they are not qualified. This matter can be greatly settled by Human-Machine Computing (HMC), which is an effective computing paradigm that couples the expertise and demonstration abilities of humans with the high-performance computing power of machines. This work studies an optimal task scheduling problem for HMC systems, where various tasks are decomposed and dispatched to humans and AI-enabled machines to provide significantly better benefits compared to either type of computing resources in isolation. However, designing such optimal task scheduling is challenging because of the stochastic hybrid features of machines, as well as various human professional abilities. Considering the Quality of Service (QoS) and the heterogeneity of human-machine computing resources, we propose CoupHM, a feasible task scheduler using gradient based optimization for HMC systems. In particular, we firstly present the underlying architecture of HMC system and details of the task-driven workload model. On that basis, we then formulate the objective optimization problem to be solved and describe the composition of the CoupHM scheduler. Finally, the performance of our solution is evaluated by the simulation experiments, and the results indicate that the proposed scheduler has preferable performance both in balancing resources and guaranteeing QoS, which can serve as guidelines for future research on HMC systems.","10.1109/ICPADS56603.2022.00116","IEEE Conferences","2023","","IEEE"
"Leveraging Traditional Design for Reliability Techniques for Artificial Intelligence","Across academia, industry, and government there has been a resurgence of interest and development of Artificial Intelligence (AI) as it emerges from a second winter. With advances in microchips, networks, sensors, and data storage, AI and Machine Learning (ML) are becoming more accessible and feasible for utilization in fielded products to assist end Users with faster decision making and lightened cognitive load. However, with these advances in technology there is also concern of deploying products that may behave in unpredictable, erratic – or, in general, unreliable ways. These concerns, among others, have been voiced by boards, organizations, and government appointed commissions such as the Defense Innovation Board (DIB) and National Security Commission on AI (NSCAI). Even at the highest levels of leadership, the Secretary of Defense has stated that “Our development, deployment, and use of AI must always be responsible, equitable, traceable, reliable, and governable” [1]. All the voices and reports have a common theme and request: a push for means and methods to ensure assurance of AI enabled systems, and ultimately trust from evaluators and users.","10.1109/RAMS51457.2022.9893957","IEEE Conferences","2022","","IEEE"
"Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions","There is burgeoning interest in designing AI-based systems to assist humans in designing computing systems, including tools that automatically generate computer code. The most notable of these comes in the form of the first self-described ‘AI pair programmer’, GitHub Copilot, which is a language model trained over open-source GitHub code. However, code often contains bugs—and so, given the vast quantity of unvetted code that Copilot has processed, it is certain that the language model will have learned from exploitable, buggy code. This raises concerns on the security of Copilot’s code contributions. In this work, we systematically investigate the prevalence and conditions that can cause GitHub Copilot to recommend insecure code. To perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, e.g. those from MITRE’s “Top 25” Common Weakness Enumeration (CWE) list. We explore Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40% to be vulnerable.","10.1109/SP46214.2022.9833571","IEEE Conferences","2022","","IEEE"
"AI Toolbox Concept for the Arrowhead Framework","Artificial Intelligence (AI) has become a game-changer across numerous industrial areas, revolutionizing the way businesses operate and enhancing their competitiveness. The Arrowhead Framework, renowned for its service-oriented architecture and interconnectivity principles, presents an ideal platform for the development and deployment of AI-driven solutions for industrial Cyber-physical System of Systems (CPSoS). This paper delves into the formulation of an AI Toolbox that enhances the capabilities of the Arrowhead Framework, aiming to harness the synergies between AI and a robust architectural foundation. The paper presents the main objectives and requirements for the AI Toolbox, and also describes its concept, operation, and deployment principles. For a better understanding, the paper demonstrates how the AI Toolbox works through a generic industrial safety use case. In conclusion, this paper contributes a comprehensive perspective on the formulation of the Arrowhead AI Toolbox, demonstrating how the Arrowhead Framework can offer AI-based services for industrial use cases.","10.23919/CNSM59352.2023.10327821","IEEE Conferences","2023","","IEEE"
"Checklist for Validating Trustworthy AI","In the recent years AI technologies have been improved and utilized in the various real-world fields such as life, economy, finance, transportation, game, etc. Especially, the deep learning, one of the learning-based machine learning methods, has shown remarkable performance improvement in a broad variety of studies. As the widespread use of AI systems including the deep learning, however, the issue of reliability of AI-based systems has recently emerged. In the case of the many AI systems, they use a huge amount of data to train their models as well as the system is very complex for humans to comprehend. Hence, humans cannot be able to understand AI systems and have no confidence in the results they generate. Furthermore, it can cause various problems such as unexplained system error or uncontrollable system behavior when using AI systems in the real-world, and even can lead to very serious situations in sensitive services such as aviation, medical care, and security. In this paper, we examine a checklist to improve a reliability of AI system. Specifically, we introduce considerations with regard to the life cycle of an AI system.","10.1109/BigComp54360.2022.00088","IEEE Conferences","2022","","IEEE"
"From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where","Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications.","10.1109/TII.2022.3146552","IEEE Journals","2022","","IEEE"
"Realtime Safety Analysis System using Deep Learning for Fire Related Activities in Construction Sites","The era of digital transformation focuses on the integration of digital and AI based technology in construction industry for sustainable economic growth and high quality of life. This paper aims to provide a real-time detection and tracking of various construction activities and provide immediate practical safety guidelines and alert for probable accidental scenarios to ensure the safety of construction site and workers by using deep learning algorithms with vision-based edge devices and smartphone. Proposed paper develops a hybrid algorithm using scene classification first, and dependent object detection and tracking second to analyze vast category of fire related activities from video and images in real-time using computationally challenging devices. To cover the ever-changing construction location, easy to move smartphone-based applications were developed with AI as an API solution. The review of the results confirms superior real-time performance in successfully identifying and providing clear safety guidelines for indoor and outdoor fire related activities such as welding work and fire safety equipment and workers safety gear such as hardhat helmet. The study validated the practicality of IoT and deep learning-based solutions for construction jobsites with indoor and outdoor locations.","10.1109/ICECCME55909.2022.9987855","IEEE Conferences","2022","","IEEE"
"Unsupervised Hebbian Learning on Point Sets in StarCraft II","Learning the evolution of real-time strategy (RTS) game is a challenging problem in artificial intelligent (AI) system. In this paper, we present a novel Hebbian learning method to extract the global feature of a point set in StarCraft II game units, and its application to predict the movement of the points. Our model includes encoder, LSTM, and decoder, and we train the encoder with the unsupervised learning method. We introduce the concept of neuron activity aware learning combined with k-Winner-Takes-All. The optimal value of neuron activity is mathematically derived, and experiments support the effectiveness of the concept over the downstream task. Our Hebbian learning rule benefits the prediction with lower loss compared to self-supervised learning. Also, our model significantly saves the computational cost such as activations and FLOPs compared to a frame-based approach.","10.1109/IJCNN55064.2022.9892259","IEEE Conferences","2022","","IEEE"
"AI-Empowered Management and Orchestration of Vehicular Systems in the Beyond 5G Era","The complexity of orchestrating Beyond 5G services, such as vehicular, demands novel approaches to remove limitations of existing techniques, as these might cause a large delay in orchestration operations, and thus, negatively impact the service performance. For instance, the human-in-the-loop approach is slow and prone to errors, and closed loop control using rule-based algorithms is difficult to design, as an abundant number of parameters need to be configured. Applying Artificial Intelligence (Al)/Machine Learning (ML), in combination with Network Function Virtualization (NFV) and Software Defined Networking (SDN), seems a promising solution for enabling automation and intelligence that will optimize orchestration operations. In this article, we study the challenges in current ETSI NFV orchestration solutions for B5G C-V2X edge services; propose an Al/ML-based closed-loop orchestration framework; propose how and which Al/ML techniques can alleviate the identified challenges and what are the implications resulting from applying certain Al/ML techniques; and discuss A//ML-based system enablers for B5G C-V2X services.","10.1109/MNET.008.2300024","IEEE Magazines","2023","","IEEE"
"SRL-ORCA: A Socially Aware Multi-Agent Mapless Navigation Algorithm in Complex Dynamic Scenes","For real-world navigation, it is important to endow robots with the capabilities to navigate safely and efficiently in a complex environment with both dynamic and static obstacles. However, achieving path-finding in non-convex complex environments without maps as well as enabling multiple robots to follow social rules for obstacle avoidance remain challenging problems. In this letter, we propose a socially aware mapless navigation algorithm, namely Safe Reinforcement Learning-Optimal Reciprocal Collision Avoidance (SRL-ORCA). This is a multi-agent safe reinforcement learning algorithm by using ORCA as external knowledge to provide safety guarantees. This algorithm further introduces traffic norms of human society to improve social comfort and achieve cooperative avoidance by following human social customs. The result of experiments shows that SRL-ORCA learns strategies to obey specific traffic rules. Compared to RL, SRL-ORCA shows a significant improvement in navigation success rate in different complex scenarios. SRL-ORCA is able to cope with non-convex obstacle environments without falling into local minima and has a 14.5% improvement in average time to goal compared to ORCA.","10.1109/LRA.2023.3331621","IEEE Journals","2024","","IEEE"
"Role of Artificial Intelligence in Haematological Disorder","Artificial intelligence (AI) is a branch of computer science that uses a computational framework to replicate human brain functions. The primary non-natural neuron was created in 1943, and the primary non-natural neural system (ANN) was applied to hereditary procedures soon afterward. Researchers and scientists have already recognized the potential for a comparable technology in medicine. The capability of this technology to retain and analyses altogether medicinal information consumes it very alluring to complement or perhaps replace clinician in creation a designs. The routine of skilled or knowledge-based organizations in dull scientific use for analysis, healing management, and predictive assessment are examples of requests of artificial intelligence in medicine. New samples contain procedures practical to analysis in, psychiatry, heart illnesses etc. Biomedical applications include protein structure prediction, analysis and clustering of gene expression data, genome sequencing The first AI-based gadgets have been used in hematology to manage routine laboratory data. Created on neural systems expert by information since marginal plasma study, new methods for the differential diagnosis of certain diseases, such as anemias, thalassemia, and leukemia, are now available.","10.1109/CISCT57197.2023.10351237","IEEE Conferences","2023","","IEEE"
"Smart tourism chatbot system using Multi-domain Tourism Information DST","The smart tourism service provides tourists with travel planner services and tour guide services for easy and convenient travel throughout the entire travel process. In this paper, we develop the AI-based chatbot service using a pretrained language model (PLM) and provide tourism information so that tourists can make their travel plans. The proposed chatbot system consists of the DST server, the Neo4J graph DB and MySQL DB servers, and the natural language generation (NLG) server. The dialogue state tracking (DST) server understands the intention of tourists’ questions to overcome the shortcomings of the previous rule-based chatbot system [7]. We define the domains and slots of the tourism information DST model with the 4W1H method and develop the dataset [12] for transfer learning of the SOM DST model [14]. The Neo4J and MySQL web servers search tourism information from the tourism information knowledgebase and the smart tourism information system, respectively. The NLG server provides the searched tourism information to the smart tourism app.","10.1109/ICUFN57995.2023.10200288","IEEE Conferences","2023","","IEEE"
"Privacy-Preserving Gesture Recognition with Explainable Type-2 Fuzzy Logic Based Systems","Smart homes are a growing market in need of privacy preserving sensors paired with explainable, interpretable and reliable control systems. The recent boom in Artificial Intelligence (AI) has seen an ever-growing persistence to incorporate it in all spheres of human life including the household. This growth in AI has been met with reciprocal concern for the privacy impacts and reluctance to introduce sensors, such as cameras, into homes. This concern has led to research of sensors not traditionally found in households, mainly short range radar. There has been also increasing awareness of AI transparency and explainability. Traditional AI black box models are not trusted, despite boasting high accuracy scores, due to the inability to understand what the decisions were based on. Interval Type-2 Fuzzy Logic offers a powerful alternative, achieving close to black box levels of performance while remaining completely interpretable. This paper presents a privacy preserving short range radar sensor coupled with an Explainable AI system employing a Big Bang Big Crunch (BB-BC) Interval Type-2 Fuzzy Logic System (FLS) to classify gestures performed in an indoor environment.","10.1109/FUZZ48607.2020.9177768","IEEE Conferences","2020","","IEEE"
"Design & Development of Smart Electric Vehicle Safety Device by using IoT and AI","As the usage of electric vehicles grows in popularity, the risk of accidents caused by them is also drastically increased. High speed, drink-driving, distracting thoughts, overstress, and malfunctioning electronic gadgets, over the temperature in charging are the leading causes of accidents & fire. Also, in electric battery-operated cars, if the battery charging mechanism is not properly thermally stabilized, the battery may catch fire. As a result, the proposed system deals with accident detection systems that occur as a result of a driver's carelessness or system failure while operating an electric vehicle. Proposed Device created with a cardiac sensor in the seat belt and vehicle along with battery temperature, vibration & accelerometer sensors which can help to analyze the vehicle's yaw, roll, pitch, and slip motions. All of the data collected is a synced to ESP-32 controller through IoT-based cloud storage analysis to notify a neighboring helpline center about the accident. This data is also utilized in an AI-based model to detect one of the sovereign sources of death in growing countries i.e., cardiovascular disease, and it's cited by several throughout the globe. Cardiovascular disease, on the opposite hand, is called heart disease. This consolidates some dangerous factors of heart disease and the desire of the era of promoting correct, reliable and smart approaches that enable early identification to achieve quick treatment for the disease. This analysis paper also presents numerous attributes associated with a heart condition, and also the model is based on supervised algorithms of machine learning such as Support Vector Machines, Logistic Regression, Naïve Bayes, Decision tree, and random forest and algorithms of deep learning such as Artificial Neural Network, TabNet etc. It uses the prevailing dataset from V.A. Medical Center, Long Beach, and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D. It includes 303 occurrences and 76 attributes. Only 13 attributes are considered for testing out of 76 attributes. This is important to prove the performance of various algorithms. This analysis paper targets to visualize the likelihood of blooming heart conditions within the drivers with the comparison of traditional algorithms with deep learning techniques and will alert drivers by sending information via personal email, text message, or on the app.","10.1109/ICERECT56837.2022.10059784","IEEE Conferences","2022","","IEEE"
"AI-Based Media Coding Standards","Moving Picture, Audio and Data Coding by Artificial Intelligence (MPAI) is the first standards organization to develop data coding standards that have artificial intelligence (AI) as their core technology. MPAI believes that universally accessible standards for AI-based data coding can have the same positive effects on AI as standards had on digital media. Elementary components of MPAI standards–AI modules (AIMs)–expose standard interfaces for operation in a standard AI framework (AIF). As their performance may depend on the technologies used, MPAI expects that competing developers providing AIMs will promote horizontal markets of AI solutions that build on and further promote AI innovation. Finally, the MPAI framework licences (FWLs) provide guidelines to intellectual property right (IPR) holders facilitating the availability of compatible licenses to standard users.","10.5594/JMI.2022.3160793","SMPTE Journals","2022","","IEEE"
"Safety vs. Efficiency: AI-Based Risk Mitigation in Collaborative Robotics","The use of AI-based risk mitigation is increasing to provide safety in the areas of smart manufacturing, automated logistics etc, where the human-robot collaboration operations are in use. This paper presents our work on implementation of fuzzy logic system (FLS) and reinforcement learning (RL) to build risk mitigation modules for human-robot collaboration scenarios. Risk mitigation using FLS strategy is developed by manually defining the linguistic values, tuning the membership functions and generating the rules based on ISO/TS15066:2016. RL-based risk mitigation modules are developed using three different Qnetworks to estimate the Q-value function. Our purpose is twofold: to perform a comparative analysis of FLS and RL in terms of safety perspectives and further to evaluate the efficiency to accomplish the task. Our results present that all the proposed risk mitigation strategies improve the safety aspect by up to 26% as compared to a default setup where the robot is just relying on a navigation module without risk mitigation. The efficiency of using FLS model is maintained to the default setup, while the efficiency of using RL model is reduced by 26% from the default setup. We also compare the computation performance of risk mitigation between centralized and edge execution where the edge execution is 27.5 times faster than the centralized one.","10.1109/ICCAR49639.2020.9108037","IEEE Conferences","2020","","IEEE"
"A Novel Implementation of an AI-Based Smart Construction Safety Inspection Protocol in the UAE","The safety of workers at construction sites is one of the most important aspects that should be considered while performing their required tasks. Many rules and regulations have been implemented in the UAE to reduce injuries and fatalities in the jobsites. However, the number of accidents continues to increase. For instance, an accident category of fall-from-height is considered as the top cause of injuries and fatalities. Thus, this paper develops a novel technique that monitors the workers whether they are complying with a safety standard of the Personal Fall Arrest System (PFAS). This paper establishes a real time detection algorithm based on a Convolutional Neural Network (CNN) model in order to detect two main components of the PFAS that are, safety harness and life-line, in addition to a standard safety measure of using a safety helmet. The YOLOv3 algorithm is adopted for a deep learning network used to train the desired model. The model achieved an accuracy rate of 91.26% and around 99% precision. Moreover, the overall recall of the model was 90.2%. The obtained results verify the effectiveness of our proposed model in construction sites to control potential violations and to avoid unnecessary accidents. The main contribution of this paper is to provide an AI-based image detection framework to mitigate the likelihood of fall-from-height accidents.","10.1109/ACCESS.2021.3135662","IEEE Journals","2021","","IEEE"
"Stroke Medical Ontology for Supporting AI-based Stroke Prediction System using Bio-Signals","In this paper, we propose a stroke medical ontology that provides medical knowledge to accompany AI-based stroke disease prediction system's results that were arrived at based on EMG information. This system was developed as a result of the limitations mentioned above being encountered in previous studies. We approached the problem from a viewpoint of knowledge engineering with the aim of modeling medical knowledge related to strokes. Using web ontology language (OWL), a standard ontology language, we developed schema-level stroke ontologies with concepts and properties based on the brain's anatomical structures, lesions, and disease related to strokes. Also, we developed an instance-level medical terms ontology that can span standard medical terms such as those in the international classification diseases (ICD), systematized nomenclature of medicine - clinical terms (SNOMED-CT), and foundational model of anatomy (FMA). The above schema ontology and instance ontology are meaningfully mapped to each other to apply layered ontology modeling techniques that separate schemas from instances. Through semantic web rule language (SWRL)-based inference, we predict lesions, diseases, and anatomical brain structural ripple effects based on the patient's current lesions and diseases. The inferred knowledge information is provided via the SPARQL protocol and RDF query language (SPARQL), a standard ontology query language. To verify the stroke medical ontology proposed in this paper, we developed an ontology-based stroke disease prediction system. This system achieved knowledge augmentation performance of 67.82% by comparing the patients' current lesions and diseases with the lesions, diseases, and areas of disability found by SWRL-based inference using actual stroke emergency data from 37 patients.","10.1109/ICUFN49451.2021.9528529","IEEE Conferences","2021","","IEEE"
"Simulation-Based Deep Reinforcement Learning For Modular Production Systems","Modular production systems aim to supersede the traditional line production in the automobile industry. The idea here is that highly customized products can move dynamically and autonomously through a system of flexible workstations without fixed production cycles. This approach has challenging demands regarding planning and organization of such systems. Since each product can define its way through the system freely and individually, implementing rules and heuristics that leverage the flexibility in the system in order to increase performance can be difficult in this dynamic environment. Transport tasks are usually carried out by automated guided vehicles (AGVs). Therefore, integration of AI-based control logics offer a promising alternative to manually implemented decision rules for operating the AGVs. This paper presents an approach for using reinforcement learning (RL) in combination with simulation in order to control AGVs in modular production systems. We present a case study and compare our approach to heuristic rules.","10.1109/WSC48552.2020.9384089","IEEE Conferences","2020","","IEEE"
"Preventing and Controlling Epidemics Through Blockchain-Assisted AI-Enabled Networks","The COVID-19 pandemic, which spread rapidly in late 2019, has revealed that the use of computing and communication technologies provides significant aid in preventing, controlling, and combating infectious diseases. With the ongoing research in next-generation networking (NGN), the use of secure and reliable communication and networking is of utmost importance when dealing with users' health records and other sensitive information. Through the adaptation of artificial-intelligence-enabled NGN, the shape of healthcare systems can be altered to achieve smart and secure healthcare capable of coping with epidemics that may emerge at any given moment. In this article, we envision a cooperative and distributed healthcare framework that relies on state-of-the-art computing, communication, and intelligence capabilities, namely, federated learning, mobile edge computing, and blockchain, to enable epidemic (or suspicious infectious disease) discovery, remote monitoring, and fast health authority response. The introduced framework can also enable secure medical data exchange at the edge and between different health entities. This technique, coupled with the low latency and high bandwidth functionality of 5G and beyond networks, would enable mass surveillance, monitoring, and analysis to occur at the edge. Challenges, issues, and design guidelines are also discussed in this article with highlights on some trending solutions.","10.1109/MNET.011.2000628","IEEE Magazines","2021","","IEEE"
"What Would You do? An Ethical AI Quiz","The resurgence of Artificial Intelligence (AI) has been accompanied by a rise in ethical issues. AI practitioners either face challenges in making ethical choices when designing AI-based systems or are not aware of such challenges in the first place. Increasing the level of awareness and understanding of the perceptions of those who develop AI systems is a critical step toward mitigating ethical issues in AI development. Motivated by these challenges, needs, and the lack of engaging approaches to address these, we developed an interactive, scenario-based ethical AI quiz. It allows AI practitioners, including software engineers who develop AI systems, to self-assess their awareness and perceptions about AI ethics. The experience of taking the quiz, and the feedback it provides, will help AI practitioners understand the gap areas, and improve their overall ethical practice in everyday development scenarios. To demonstrate these expected outcomes and the relevance of our tool, we also share a preliminary user study. The video demo can be found at https://zenodo.org/record/7601169#.Y9xgA-xBxhF.","10.1109/ICSE-Companion58688.2023.00036","IEEE Conferences","2023","","IEEE"
"AI-based Load Forecasts - Research and Application","The climate targets require a transformation of the energy supply, which brings new challenges. The volatile generation of renewable energies and dynamic consumption due to the expansion of electricity-consuming systems such as e-mobility and heat pumps make a digitized and intelligent distribution network indispensable. To plan and optimize load distribution in a grid with volatile flexibilities and consumers, accurate load forecasts are needed. According to the current state of the art, these are carried out using Artificial Intelligence (AI) algorithms. An expert group appointed by the European Commission developed guidelines for trustworthy AI in 2019 and augmented them with a list for assessing AI in 2020. The requirements for trustworthy AI, identified in these guidelines, are crucial for the safe application of AI in practice, but they also bring challenges, as new AI methods are often very complex. The challenges, open research questions, and potential solutions are described and discussed in this article.","","VDE Conferences","2023","","IEEE"
"MOSAIC: Multiobjective Optimization Strategy for AI-Aided Internet of Things Communications","Future Internet of Things (IoT) communication trends toward heterogeneous services and diverse quality-of-service requirements pose fundamental challenges for network management strategies. In particular, multiobjective optimization (MOO) is necessary in resolving the competition among different nodes sharing limited wireless network resources. A unified coordination mechanism is essential such that individual nodes conduct the opportunistic maximization of heterogeneous local objectives for efficient distributed resource allocation. To such a problem, this article proposes an artificial intelligence (AI)-based framework, which is termed as MOO strategy for AI-aided IoT communications (MOSAIC). This framework enables to tackle numerous MOO tasks in IoT network management with simple reconfiguration of learning rules. In this strategy, a component unit associated with an individual network node includes a pair of deep neural networks (DNNs) to learn optimal local functions responsible for calculation and distributed coordination, respectively. The resultant AI module swarm called DNN tiles realizes the node cooperation that collectively seeks distributed MOO calculation rules. The advantage of MOSAIC is characterized by Pareto tradeoffs among conflicting performance metrics in diverse wireless networking configurations subject to severe interference and distinct criteria for multiple targets.","10.1109/JIOT.2022.3150747","IEEE Journals","2022","","IEEE"
"Requirements for Fuzzy Logic in Personalisation of Fire Emergency Alerts","During major natural disasters like extreme weather events and wildfires, it is very important to notify citizens when the danger level exceeds certain thresholds. However, defining these thresholds in an entirely discrete manner is challenging, despite their major importance. Conversely, triggering an alarm without sufficient justification can be costly for the state and unnecessarily disrupt the lives of citizens. In this regard, employing a more flexible approach, such as fuzzy logic, in the context of artificial intelligence empowerment of the whole process, can provide rules to mitigate the discreteness of alarm thresholds. Failing to raise an alarm, when necessary, can result in significant human and property losses. In this article, we present a new approach that utilises fuzzy logic to classify danger thresholds in a smoother and more effective manner for the civil protection. The paper offers valuable insights into the practical implementation of Fuzzy Logic and the entire life cycle of the proposed Fuzzy logic-based approach. This approach is designed to be iterative, involving key stakeholders to ensure the validity and reliability of the results.","10.1109/IISA59645.2023.10345861","IEEE Conferences","2023","","IEEE"
"FAILS: a tool for assessing risk in ML systems","Quality assurance of AI based systems presents a unique set of challenges to software engineers, making it difficult to assess the risks involved when deploying them. We present a risk assessment tool based on the widely used failure mode effect analysis (FMEA) methodology, as well as quality assurance guidelines released in recent years. The tool aims to support the search for potential risks in machine learning (ML) components used in the design and development of AI products. A preliminary evaluation showed its effectiveness and pointed toward areas for future improvement.","10.1109/APSECW53869.2021.00010","IEEE Conferences","2021","","IEEE"
"Modelling and analysis of artificial intelligence based MPPT techniques for PV applications","Solar Photovoltaic« plays a vital role in meeting the power requirements of the current generation. In fact it is the only mode of renewable energy that enables the decentralization of power. The output of an individual PV Module depends on the environmental conditions such as Temperature and Insolation level. For tracking down the maximum power available at a particular instant, we make use of Maximum Power Point Techniques. The heart of an MPPT system is a DC-DC Converter and for better performance any of the Buck-Boost converters are used. The Artificial Intelligence based methods have found to outperform the conventional methods in all the fields. In MPPT also, the AI based methods are found to be better than the conventional load line based methods. In this paper, a 1 kW PV Array is considered and three AI based MPPT techniques are analyzed with a Sepie converter. The loads connected to the converter are a Permanent Magnet DC Motor and a Grid tied Inverter. The temperature and Insolation levels are provided from historically available data for Thiruvananthapuram, Kerala, India.","10.1109/ICAGE.2014.7050144","IEEE Conferences","2014","","IEEE"
"Semantic Grasping Via a Knowledge Graph of Robotic Manipulation: A Graph Representation Learning Approach","Semantic grasping aims to make stable robotic grasps suitable for specific object manipulation tasks. While existing semantic grasping models focus only on the grasping regions of objects based on their affordances, reasoning about which gripper to use for grasping, e.g., a rigid parallel-jaw gripper or a soft gripper, and how strongly to grasp the target object allows more sophisticated robotic manipulation. In this letter, we create a knowledge graph of robotic manipulation named roboKG to represent information about objects (e.g., the material and the components of an object), tasks, and appropriate robotic manipulation such as which component of an object to grasp, which gripper to use, and how strongly to grasp. Using knowledge graph embedding, we generate semantic representations of the entities and relations in roboKG, enabling us to make predictions on robotic manipulation. Based on the predicted gripper type, grasping component, and grasping force, a real robot performs seven different real-world tasks on 42 household objects, achieving an accuracy of 95.21%.","10.1109/LRA.2022.3191194","IEEE Journals","2022","","IEEE"
"AI Ethics Impact Assessment based on Requirement Engineering","This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.","10.1109/REW56159.2022.00037","IEEE Conferences","2022","","IEEE"
"AI-Based Stroke Disease Prediction System Using ECG and PPG Bio-Signals","Since stroke disease often causes death or serious disability, active primary prevention and early detection of prognostic symptoms are very important. Stroke diseases can be divided into ischemic stroke and hemorrhagic stroke, and they should be minimized by emergency treatment such as thrombolytic or coagulant administration by type. First, it is essential to detect in real time the precursor symptoms of stroke, which occur differently for each individual, and to provide professional treatment by a medical institution within the proper treatment window. However, prior studies have focused on developing acute treatment or clinical treatment guidelines after the onset of stroke rather than detecting the prognostic symptoms of stroke. In particular, in recent studies, image analysis such as magnetic resonance imaging (MRI) or computed tomography (CT) has mostly been used to detect and predict prognostic symptoms in stroke patients. Not only are these methodologies difficult to diagnose early in real-time, but they also have limitations in terms of a long test time and a high cost of testing. In this paper, we propose a system that can predict and semantically interpret stroke prognostic symptoms based on machine learning using the multi-modal bio-signals of electrocardiogram (ECG) and photoplethysmography (PPG) measured in real-time for the elderly. To predict stroke disease in real-time while walking, we designed and implemented a stroke disease prediction system with an ensemble structure that combines CNN and LSTM. The proposed system considers the convenience of wearing the bio-signal sensors for the elderly, and the bio-signals were collected at a sampling rate of 1,000Hz per second from the three electrodes of the ECG and the index finger for PPG while walking. According to the experimental results, C4.5 decision tree showed a prediction accuracy of 91.56% while RandomForest showed a prediction accuracy of 97.51% during walking by the elderly. In addition, the CNN-LSTM model using raw data of ECG and PPG showed satisfactory prediction accuracy of 99.15%. As a result, the real-time prediction of the elderly stroke patients simultaneously showed high prediction accuracy and performance.","10.1109/ACCESS.2022.3169284","IEEE Journals","2022","","IEEE"
"Indian Traffic Sign Board Recognition and Driver Alert System Using CNN","Affirmation of traffic signs (TSR) is a popular bit of some ADA (ADAS) and vehicle drivers ' (ADS) schemes. As either the leading main technology of TSR, unveiling of traffic signs (TSD) is a worrying issue due to various styles, small size, complicated riding scenarios and obstacles. From late on various TSD figurations also relied on the view of the computer and even the pattern. A full description of the TSD structure is given in this article. We recommend splitting the field procedures under review into two rule groups: possibility-based, form-based systems. The proposed system is exhaustively apportioned into, data planning, data gathering, and getting ready and testing. System uses variety of picture planning strategies to improve the image quality and to oust non-illuminating pixel, and recognizing edges. Feature extractors are used to find the features of picture. Moved AI figuring Convolutional Neural Networks (CNN) is used to gather the differing traffic sign pictures reliant on their features by using the progressing camera.","10.1109/ICCCSP49186.2020.9315260","IEEE Conferences","2020","","IEEE"
"An AI-Based Medical Chatbot Model for Infectious Disease Prediction","The purpose of this paper is to show concisely how we can promote chatbots in the medical sector and cure infectious diseases. We can create awareness through the users and the users can get proper medical solutions to prevent disease. We created a preliminary training model and a study report to improve human interaction in databases in 2021. Through natural language processing, we describe the human behaviors and characteristics of the chatbot. In this paper, we propose an AI Chatbot interaction and prediction model using a deep feedforward multilayer perceptron. Our analysis discovered a gap in knowledge about theoretical guidelines and practical recommendations for creating AI chatbots for lifestyle improvement programs. A brief comparison of our proposed model concerning the time complexity and accuracy of testing is also discussed in this paper. In our work, the loss is a minimum of 0.1232 and the highest accuracy is 94.32%. This study describes the functionalities and possible applications of medical chatbots and explores the accompanying challenges posed by the use of these emerging technologies during such health crises mainly posed by pandemics. We believe that our findings will help researchers get a better understanding of the layout and applications of these revolutionary technologies, which will be required for continuous improvement in medical chatbot functionality and will be useful in avoiding COVID-19.","10.1109/ACCESS.2022.3227208","IEEE Journals","2022","","IEEE"
"Orchestrating Game Generation","The design process is often characterized by and realized through the iterative steps of evaluation and refinement. When the process is based on a single creative domain such as visual art or audio production, designers primarily take inspiration from work within their domain and refine it based on their own intuitions or feedback from an audience of experts from within the same domain. What happens, however, when the creative process involves more than one creative domain such as in a digital game? How should the different domains influence each other so that the final outcome achieves a harmonized and fruitful communication across domains? How can a computational process orchestrate the various computational creators of the corresponding domains so that the final game has the desired functional and aesthetic characteristics? To address these questions, this paper identifies game facet orchestration as the central challenge for artificial-intelligence-based game generation, discusses its dimensions, and reviews research in automated game generation that has aimed to tackle it. In particular, we identify the different creative facets of games, propose how orchestration can be facilitated in a top-down or bottom-up fashion, review indicative preliminary examples of orchestration, and conclude by discussing the open questions and challenges ahead.","10.1109/TG.2018.2870876","IEEE Journals","2019","","IEEE"
"Time-Optimized Online Planning For Parallel Parking With Nonlinear Optimization and Improved Monte Carlo Tree Search","Automatic parallel parking is critical to increase safety in urban narrow parking spots, maximize the traffic efficiency, and provide human drivers with mobility and convenience. Recent research integrates Monte Carlo tree search (MCTS) and artificial neural networks (ANNs) to calculate optimal lateral motions without considering the longitudinal aspect and narrow spots; advances in nonlinear programming-based (NPB) parking methods consider time-optimal parking motion in narrow spots using the time-consuming optimization calculation. To address the computational efficiency of the planning of time-optimal parking maneuvers, a complete framework relying on the two compositions was introduced. First, nonlinear optimization that formulates the minimum motion time and vehicle constraint was used to generate the data of parking motions offline. These motions were subsequently learned by ANNs. Second, the ANNs trained on the offline data were employed by an improved MCTS to generate approximate time-optimal parking motions online. The time-optimized performance and run-time performance of the proposed method were confirmed by comparing with that of NPB and other mainstream methods. A success rate of 100% for parking slots with merely 10% larger length than the vehicle was realized in simulations. Experiments were conducted on a full-sized pure electric vehicle to further confirm the effectiveness of the proposed method.","10.1109/LRA.2021.3139950","IEEE Journals","2022","","IEEE"
"Task and Motion Informed Trees (TMIT*): Almost-Surely Asymptotically Optimal Integrated Task and Motion Planning","High-level autonomy requires discrete and continuous reasoning to decide both what actions to take and how to execute them. Integrated Task and Motion Planning (TMP) algorithms solve these hybrid problems jointly to consider constraints between the discrete symbolic actions (i.e., the task plan) and their continuous geometric realization (i.e., motion plans). This joint approach solves more difficult problems than approaches that address the task and motion subproblems independently. TMP algorithms combine and extend results from both task and motion planning. TMP has mainly focused on computational performance and completeness and less on solution optimality. Optimal TMP is difficult because the independent optima of the subproblems may not be the optimal integrated solution, which can only be found by jointly optimizing both plans. This letter presents Task and Motion Informed Trees (TMIT*), an optimal TMP algorithm that combines results from makespan-optimal task planning and almost-surely asymptotically optimal motion planning. TMIT* interleaves asymmetric forward and reverse searches to delay computationally expensive operations until necessary and perform an efficient informed search directly in the problem's hybrid state space. This allows it to solve problems quickly and then converge towards the optimal solution with additional computational time, as demonstrated on the evaluated robotic-manipulation benchmark problems.","10.1109/LRA.2022.3199676","IEEE Journals","2022","","IEEE"
"GNGraph: Self-Organizing Maps for Autonomous Aerial Vehicle Planning","The present letter tackles the problem of planning a collision-free path in a known environment from a general point of view. We address the problem by using an unsupervised learning algorithm to generate a sparse graph representing the topological structure of the environment and use it for planning paths in 3D spaces. We propose GNGraph, an integrated solution combining the Growing Neural Gas algorithm to generate the sparse graph, a stop criterion to guarantee the graph's connectivity and a collision check to assess the edges and nodes validity. The proposed solution has been tested on simulated and real environment maps, and compared against a state-of-the-art graph planning algorithm among other global planning methods.","10.1109/LRA.2022.3195192","IEEE Journals","2022","","IEEE"
"Explainable Artificial Intelligence for Energy-Efficient Radio Resource Management","As wireless systems evolve, the problems of radio resource management (RRM) become harder to solve. Once the additional constraint of energy-efficient utilization of resources is factored in, these problems become even more challenging. Thus, experts started developing solutions based on complex artificial intelligence (AI) models that, unfortunately, suffer from a performance-explainability trade-off. In this work, we propose an explainable AI (XAI) methodology for addressing this tradeoff. Our methodology can be used to generate feature importance explanations of AI models through three XAI methods: (i) Kernel SHapley Additive exPlanations (SHAP), (ii) Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI), and (iii) Anchors. For Anchors, we formulate a new feature importance score based on the feature’s presence within the rules built by the method. We then use the generated explanations to improve the understanding of the model and reduce its complexity through a feature selection process. By applying our methodology to a reinforcement learning (RL) agent designed for energy-efficient RRM, we were able to reduce its complexity by approximately 27%−62% according to various metrics, without losing performance. Additionally, we show the possibility to replace the AI-based inference process with an Anchors-based inference process with similar performance and higher interpretability for humans.","10.1109/WCNC55385.2023.10119130","IEEE Conferences","2023","","IEEE"
"LoLTV: A Low Light Two-Wheeler Violation Dataset With Anomaly Detection Technique","Detecting traffic violations is essential for improving road safety, ensuring rule compliance, and maintaining smooth traffic flow. It also aids in holding violators accountable and supports data-driven decision-making for infrastructure enhancements. To address these challenges, the integration of AI-based methods for automated violation detection is increasingly vital, reducing the need for manual oversight. Low-light conditions pose additional difficulties, as violations become harder to detect. In this study, we created a novel dataset containing 1032 images with 1475 two-wheeler violations under low-light conditions. We propose a real-time deep learning system using YOLO-v8 for two-wheeler violation detection. Our system addresses the challenge of low-light conditions by incorporating a real-time low-light video enhancement module. Through comprehensive evaluations, our system has achieved an average precision of 98.2%, recall of 97.5%, and an accuracy of 97.05% when tested on our custom dataset. Notably, it successfully detected 172 out of 188 violations in the test dataset and exhibited 60% faster processing compared to other state-of-the-art methods. This suggests that our system not only outperforms existing methods on public datasets but also excels in terms of performance and accuracy when applied to the specifically constructed low-light traffic dataset. Furthermore, our system’s practical scalability is evident through its integration with multiple devices and CCTV systems.","10.1109/ACCESS.2023.3329737","IEEE Journals","2023","","IEEE"
"End-to-End From Human Hand Synergies to Robot Hand Tendon Routing","The human hand capabilities are paramount for highly dexterous manipulation interactions. Unfortunately, the limitations of current technologies make replicating such capabilities unfeasible. Although several works have focused on directly attempting to create robot hands able to mimic human ones closely, few of them have attempted to create generalizable platforms, where robotic hand mechanisms can be iteratively selected and customized to different tasks. In order to build highly dexterous robotic hands in the future, it is crucial to understand not only human manipulation, but also develop methods to leverage robotic mechanisms limitations to mimic human hand interactions accurately. In this letter, we propose an end-to-end framework capable of generating underactuated tendon routings that allow a generic robot hand model to reproduce desired observed human grasp motion synergies accurately. Our contributions are threefold: (1) an end to end framework to generate task-oriented robot hand tendon routings, with the potential to implement desired synergies, (2) a novel grammar based representation of robot hand tendon routings, and (3) a schematic visualization of robot hand tendon routings. The latter two contributions have the potential to embed and compare properties among robot hands. Our results in simulation show that the proposed method produces tendon routing mechanisms that are able to closely mimic the joint trajectories of human subjects performing the same experimental tasks, while achieving dynamically stable grasping postures.","10.1109/LRA.2022.3192649","IEEE Journals","2022","","IEEE"
"Standardization on Bias in Artificial Intelligence as Industry Support","Industry strives for trustworthy Artificial Intelligence (AI) systems through recognizing and implementing Responsible AI principles. Solutions supporting that goal are of the utmost interest in that context. Standardization is an essential element here, as it provides a platform for industry to discuss and facilitate not only the development of practical rules and requirements but also ways to implement AI based systems. One of Responsible AI principles is fairness, and bias is a serious obstacle against it. First, we explain the concept of Responsible AI and highlight results of our analysis on bias and fairness in ongoing international standardization works and AI Act (AIA). We identified a gap between the principles defined by high-level studies, including the AIA, and their practical implementations, and differences within standardization and research works. Second, we draw a standardization map for AI works. Finally, we state how international standardization bodies may fill this gap?","10.1109/BigData55660.2022.10020735","IEEE Conferences","2022","","IEEE"
"Intelligent Agents in Educational Institutions: NEdBOT - NLP-based Chatbot for Administrative Support Using DialogFlow","Artificial intelligence (AI)-based chatbot systems have seen increased adaption in the educational domain in recent years owing to increased sophistication in the AI domain. However, most of the communication between students and educational institutions is still performed physically and causes major administrative overhead, especially during the time of admission. Contemporary pattern-matching-based and generative-based chatbots underperform to queries outside a limited scope, grammatically and structurally ambiguous inputs, outliers to pre-defined rule-set, and longer response times for a huge knowledge base. We proposed a NEdBOT-An NLP-based Educational Bot, developed by Natural Language Processing models integrated within the DialogFlow platform utilizing a Retrieval-based approach. We evaluate the developed chatbot on a custom dataset generated for the admissions use case of a prominent university. We used an objective evaluation criterion with real-world users to achieve an intent classification accuracy of 76.8% at an average mean response time of 216.43ms per query and a user-friendliness score of 72% on the System Usability Scale (SUS). The results demonstrate the proposed approach's ability to create robust, reliable, responsive, and user-friendly web-based smart chatbots that are highly scalable with the capability to handle wider scopes and vague inputs with ease.","10.1109/ICA55837.2022.00012","IEEE Conferences","2022","","IEEE"
"When Smart Metaverse Meets Affective Computing: Opportunities and Design Guidelines","Metaverse and affective computing are two promising areas. We envision a new generation of smart metaverse that will consider affective computing to develop artificial intelligence (AI)-empowered avatars capable of expressing emotions and enhancing interactions on users' metaverse sessions. This article advocates for the symbiotic design of affective computing and metaverse. We discuss some of the unique challenges faced during the design of metaverse and affective computing and the current research trends to overcome them. We highlight how affective computing can tackle unique challenges in metaverse applications and how metaverse can be considered to deal with limitations faced in affective computing applications. Finally, we present some future research directions in need of attention.","10.1109/MCOM.004.2300009","IEEE Magazines","2023","","IEEE"
"AI-Based Technique to Enhance Transient Response and Resiliency of Power Electronic Dominated Grids via Grid-Following Inverters","This article presents a frequency restoration method to enhance power electronic dominated grid (PEDG) resiliency and transient response via redefining grid following inverters (GFLIs) role at the grid-edge. An artificial intelligence-based power reference correction (AI-PRC) module is developed for GFLIs to autonomously adjust their power setpoints during transient disturbances. A detailed analytical validation is provided that shows control rules in PEDG intrinsically follow the underlying dynamic of the swing-based machines to extend its stability boundary. Considering this fact, comprehensive transient and steady state-based mathematical models are used for constructing the learning database of the proposed AI-PRC. The proposed training approach can deal with grid's characteristics alterations and uncertainties. Thus, this approach incorporates PEDG's effective variables that shapes its dynamic response during transient disturbances. Subsequently, a neural network is trained by Bayesian regularization algorithm to realize the proposed AI-PRC scheme for frequency support via GFLIs. Several simulation and experimental case studies results validate the functionality of the proposed AI-PRC toward enhancing the PEDG's transient response and resiliency via GFLIs. The provided case studies demonstrate significant improvement in frequency restoration in response to transient disturbances.","10.1109/TIE.2023.3265067","IEEE Journals","2024","","IEEE"
"Development of AI-Based Optimum Energy Resource Management System for Prosumers with Solar Rooftops","Solar installations are becoming popular around the world and have emerged as a promising solution to address the increased energy needs while reducing carbon emissions. To harness the full potential of solar photovoltaic (PV) systems, efficient resource management systems play a vital role. This research paper proposes an efficient solar PV energy resource management system to optimize performance and increase the profits of the prosumers. Utility providers have introduced several tariff systems for the financial motivation of customers. In the proposed method, the load demand and Solar PV generation are forecasted for the next 48 hours using the Long Short-Term Memory (LSTM) model. Then, the cost function is optimized using the Sequential Least Squares Programming (SLSQP) algorithm, and an energy dispatch schedule is provided for the customer: The results of the study show that the electricity cost is reduced for the prosumer by the proposed method than the conventional rule-based energy management systems.","10.1109/MERCon60487.2023.10355519","IEEE Conferences","2023","","IEEE"
"TrueAdaptTM- AI Based Maskless Patterning to Compensate for Die-Shift in Fan-Out Wafer Level Packaging","TrueAdapt™ offers an attractive solution to fan-out-wafer-level-packaging (FOWLP) and fan-out-panel-level-packaging, which offers significant cost savings as compared to similar bridge connection technology or interposers. Due to die-placement error and shift during molding, die assemblies on FOWLP can have significant die-shift. Design rules must ensure the accommodation of die-shift and as a result fine-pitch patterning is limited. TrueAdapt™ aims to solve that by utilizing in-line characterization of the die shift, generation of a new layout using the measured offsets, and patterning with direct-write lithography for high throughput wafer-level and panel-level fabrication at fine-pitches. In this work we present the fabrication of an assembly of dies interconnected in a daisy chain network with 10 µm pitch wiring on the FlexTrate™, a bio-compatible polydimethylsiloxane (PDMS) based FOWLP architecture. We measure die shift using optical metrology techniques to generate a stitched image of the assembly. The image is then processed using artificial intelligence (AI) computer vision to identify critical features on the dies (which are used to generate die-offsets for each die). Furthermore, we generate a layout based on measured die-shift that adaptively routes the wiring in between dies. Via and metal layers are subsequently patterned using direct-write lithography using a 405 nm lase. Direct-write lithography enables fine-pitch patterning at the wafer/panel level without the need for mask fabrication, promising significant cost savings. We further demonstrate a novel exposure technique based on focal extension that can be utilized to pattern over 100 µm of topography, making this a truly adaptive patterning process.","10.1109/ECTC51909.2023.00388","IEEE Conferences","2023","","IEEE"
"A Review on Various Artificial Intelligence Techniques Used for Transmission Line Fault Location","Transmission line fault location has been estimated using various methods such as conventional distance relaying, differential relaying, artificial intelligent (AI) methods etc. Among all the methods AI based methods locates fault more accurately than others. In this work various AI methods used for transmission line fault location has been discussed with their advantages and limitations. Different AI methods that have been discussed are nearest neighbor algorithm, linear regression, logistic regression, artificial neural network, support vector machine, decision tree. With the various advantages of AI methods, it can be used effectively for locating faults in transmission lines.","10.1109/ICICT43934.2018.9034333","IEEE Conferences","2018","","IEEE"
"A Deployment Model to Extend Ethically Aligned AI Implementation Method ECCOLA","There is a struggle in Artificial intelligence (AI) ethics to gain ground in actionable methods and models to be utilized by practitioners while developing and implementing ethically sound AI systems. AI ethics is a vague concept without a consensus of definition or theoretical grounding and bearing little connection to practice. Practice involving primarily technical tasks like software development is not aptly equipped to process and decide upon ethical considerations. Efforts to create tools and guidelines to help people working with AI development have been concentrating almost solely on the technical aspects of AI. A few exceptions do apply, such as the ECCOIA method for creating ethically aligned AI -systems. ECCOIA has proven results in terms of increased ethical considerations in AI systems development. Yet, it is a novel innovation, and room for development still exists. This study aims to extend ECCOIA with a deployment model to drive the adoption of ECCOIA, as any method - no matter how good -is of no value without adoption and use. The model includes simple metrics to facilitate the communication of ethical gaps or outcomes of ethical AI development. It offers the opportunity to assess any AI system at any given life-cycle phase, e.g., opening possibilities like analyzing the ethicality of an AI system under acquisition.","10.1109/REW53955.2021.00043","IEEE Conferences","2021","","IEEE"
"Wearables as Part of Decision Support System in Parkinson's Disease Prediagnosis: A Case Study","Parkinson's disease (PD) is a progressive neurodegenerative disorder which affects 6.1million people worldwide and bears enormous financial implications. Trends to reduce the costs of PD management target early diagnosis and are oriented towards wearables and artificial intelligence support. This paper presents a case study which investigates the applicability of our previously developed small-size wearable physiograph with an AI-based assessment procedure to provide intelligent decision support in the diagnosis of PD. Our case study presents a 56-year-old female patient that undergone a three-task examination: writing, speaking, and walking. A discussion regarding contextual interpretation of the examination results is provided.","10.1109/EHB55594.2022.9991543","IEEE Conferences","2022","","IEEE"
"Beyond Industry 4.0: Leveraging AI-powered Anomalous Sound Detection for Smart Maintenance","The ongoing global changes, pushing the digital transformation to Industry 4.0, have been reflected in the launch of new services and process innovations tackling the existing pressure on costs and prices. In this context, AI is becoming an integral part of all future smart maintenance endeavors. The new generation of intelligent maintenance systems, driven by big data analysis and advanced diagnostics, are already guiding automated predictive innovation towards the idea of zero-failure activity. Automated detection of failures is crucial for smart maintenance, for building AI-based factory automation. In this context, the paper describes a solution for detecting failures based on sound obtained from the target machines. Abnormal sound data is difficult to collect, as it rarely occurs and is being hard to extract from a noisy environment and could have various patterns. The proposed solution detects anomalous sound after training the machine-learning model only with the normal operating sound of machines in a factory environment.","10.1109/ZINC52049.2021.9499309","IEEE Conferences","2021","","IEEE"
"A Evolutionary Behavior Tree AI for Neural MMO Challenge","The Neural MMO Challenge aims to study robustness and teamwork in large-scale multi-agent environments. AI needs to explore, search and fight in large-scale environments, and get higher scores than other competitors. Therefore, we developed AI based on evolutionary behavior tree, which has the advantages of strong interpretability, low coupling between modules and strong robustness. Specifically, the AI adopts the idea of divide and conquer, divides the decision-making into two levels: team and individual, divides the four task achievements into several subtasks, finds appropriate agents for each subtask according to the current advantages, and then completes specific actions such as attack, foraging, avoidance and collaboration, and optimizes the parameters with evolutionary strategy algorithm.AI won the silver medal in IJCAI 2022 Neural MMO Challenge.","10.1109/AIAM57466.2022.00069","IEEE Conferences","2022","","IEEE"
"Artificial intelligence in boiler control","Artificial Intelligence (AI) techniques are becoming useful as alternate approaches to conventional techniques. They have been used to solve complicated practical problems and now a day is very popular. They can learn from examples, fault tolerant in the sense they are able to handle noisy and incomplete data and once trained can perform faster prediction and generalization. AI based systems are used mainly because of their symbolic reasoning, flexibility and explanation capabilities. This paper briefly presents the main AI techniques and outlines an application in boiler control. Master controller is required for a steam generating system having multiple boilers operating in parallel. AI technique of Fuzzy logic controller is proposed as master controller. The optimum performance of individual boilers is achieved by the master controller meeting the varying load demands of the steam system.","10.1109/RACE.2015.7097268","IEEE Conferences","2015","","IEEE"
"An Intelligent Two-Phase Automated Architecture for Securing SDN-Based IoT Infrastructure","The Internet of Things (IoT) will bring many opportunities in the next years. However, IoT devices have processing and power limitation. Thus, security remains one of the main challenges. Software-defined networking (SDN) helps traditional IoT infrastructure become manageable and flexible in a centralized fashion. The SDN-IoT architecture tackles the security issue of IoT networks. The proposed architecture adds a new security engine to the controller. The security engine consists of the monitoring, intelligent sub-layer, analyzing/detection engine, reaction, and config engine to automatically monitor, analyze, classify, detect, and generate a proper reaction to the possible threads in two phases. The config engine automatically rearranges the security rules and applies the set of rules as a new configuration to the devices (switches) in the data layer. The intelligent sub-layer uses AI-based feature selection (Bat Algorithm) and classification (Random Forest) algorithms to reveal the possible threats and forward its output to the analyzing/detecting engine to examine it and make the alerts. The cooperation of the intelligent sub-layer and analyzing/detection engine in the two mentioned steps help the system improve the overall system performance and false positive alerts. The proposed architecture follows new security rules based on the network status such as bandwidth minimization and traffic. All the process automatically makes by the security engine and protects the entire network from different threats and attacks.","10.1109/ICEIB57887.2023.10170386","IEEE Conferences","2023","","IEEE"
"On STPA for Distributed Development of Safe Autonomous Driving: An Interview Study","Safety analysis is used to identify hazards and build knowledge during the design phase of safety-relevant functions. This is especially true for complex AI-enabled and software intensive systems such as Autonomous Drive (AD). System-Theoretic Process Analysis (STPA) is a novel method applied in safety-related fields like defense and aerospace, which is also becoming popular in the automotive industry. However, STPA assumes prerequisites that are not fully valid in the automotive system engineering with distributed system development and multi-abstraction design levels. This would inhibit software developers from using STPA to analyze their software as part of a bigger system, resulting in a lack of traceability. This can be seen as a maintainability challenge in continuous development and deployment (DevOps). In this paper, STPA’s different guidelines for the automotive industry, e.g. J31887/ISO21448/STPA handbook, are firstly compared to assess their applicability to the distributed development of complex AI-enabled systems like AD. Further, an approach to overcome the challenges of using STPA in a multilevel design context is proposed. By conducting an interview study with automotive industry experts for the development of AD, the challenges are validated and the effectiveness of the proposed approach is evaluated.","10.1109/SEAA60479.2023.00011","IEEE Conferences","2023","","IEEE"
"Neuromorphic Near-Sensor Computing: From Event-Based Sensing to Edge Learning","Neuromorphic near-sensor computing has recently emerged as a low-power and low-memory paradigm for the design of artificial intelligence (AI)-enabled IoT devices working at the extreme edge. Compared to conventional sensing and learning techniques, neuromorphic sampling, and processing reduces data bandwidth requirements, induces large savings on power and area consumption, and enables online learning and adaptation. In this article, we discuss recent studies made in the design of event-based sampling and learning circuits. We show that our event-based sampling methods outperform conventional techniques in terms of power consumption. We also show that our spiking neural network (SNN), learning through spike-timing-dependent plasticity (STDP), outperforms the state-of-the-art SNN-STDP systems in terms of inference accuracy while being orders of magnitude more power efficient than conventional deep-learning systems. We hope that the opportunities discussed in this summary article will inspire future research.","10.1109/MM.2022.3195634","IEEE Magazines","2022","","IEEE"
"Can Deep Learning Improve Technical Analysis of Forex Data to Predict Future Price Movements?","The foreign exchange market (Forex) is the world’s largest market for trading foreign money, with a trading volume of over 5.1 trillion dollars per day. It is known to be very complicated and volatile. Technical analysis is the observation of past market movements with the aim of predicting future prices and dealing with the effects of market movements. A trading system is based on technical indicators derived from technical analysis. In our work, a complete trading system with a combination of trading rules on Forex time series data is developed and made available to the scientific community. The system is implemented in two phases: In the first phase, each trading rule, both the AI-based rule and the trading rules from the technical indicators, is tested for selection; in the second phase, profitable rules are selected among the qualified rules and combined. Training data is used in the training phase of the trading system. The proposed trading system was extensively trained and tested on historical data from 2010 to 2021. To determine the effectiveness of the proposed method, we also conducted experiments with datasets and methodologies used in recent work by Hernandez-Aguila et al., 2021 and by Munkhdalai et al., 2019. Our method outperforms all other methodologies for almost all Forex markets, with an average percentage gain of 20.2%. A particular focus was on training our AI-based rule with two different architectures: the first is a widely used convolutional network for image classification, i.e. ResNet50; the second is an attention-based network Vision Transformer (ViT). The results provide a clear answer to the main question that guided our research and which is the title of this paper.","10.1109/ACCESS.2021.3127570","IEEE Journals","2021","","IEEE"
"An Explainable AI Model for Interpretable Lung Disease Classification","In this paper, we develop a framework for lung disease identification from chest X-ray images by differentiating the novel coronavirus disease (COVID-19) or other disease-induced lung opacity samples from normal cases. We perform image processing tasks, segmentation, and train a customized Convolutional Neural Network (CNN) that obtains reasonable performance in terms of classification accuracy. To address the black-box nature of this complex classification model, which emerged as a key barrier to applying such Artificial Intelligence (AI)-based methods for automating medical decisions raising skepticism among clinicians, we address the need to quantitatively interpret the performance of our adopted approach using a Layer-wise Relevance Propagation (LRP)-based method. We also used a pixel flipping-based, robust performance metric to evaluate the explainability of our adopted LRP method and compare its performance with other explainable methods, such as Local Interpretable Model Agnostic Explanation (LIME), Guided Backpropagation (GB), and Deep Taylor Decomposition (DTD).","10.1109/IoTaIS53735.2021.9628573","IEEE Conferences","2021","","IEEE"
"An Overview of Fuzzy Logic Approaches for Fault Diagnosis in Energy Conversion Devices","Any energy conversion devices, such as industrial motor-drives, propulsion drives of electric vehicles, pump systems, wind turbines, and others, are prone to failures. Usually, failures result in increased economic costs that come through additional energy losses, loss of production, or in a worst-case even environmental hazard. To prevent failures, energy conversion systems may be checked through particular routines developed and specified by the manufactures. However, it may be challenging due to the complex construction of energy conversion devices or devices' failure between the routine checks. Such schedule-based condition monitoring approaches provide minor information on the remaining lifetime (separate components and whole system) of the devices and do not allow proper prognostic or full exploitation. To overcome traditional two-level Boolean approaches with healthy/faulty states an Artificial Intelligence (AI)-based control techniques are used. The Fuzzy Logic approach is based on inspired by human perception processes and cognition that are often uncertain or empirical. However, Fuzzy Logic is already successfully applied in various control applications of energy conversion devices, even when the analytical models are unknown. This paper argues for developing new fault detection algorithms based on fuzzy logic methods to allow energy conversion systems designers to develop reliability factors for apparatus, which included electrical machines and power electronics subsystems.","10.1109/IWED52055.2021.9376389","IEEE Conferences","2021","","IEEE"
"Verification of Intelligent Transportation Systems: Challenges And Possibilities","Intelligent Transportation Systems (ITS) have been touted and proven to be an advanced-technology improvement in transport systems and commuters’ operational performance, efficiency, and safety. The nature of ITS as an integrated metasystem of information and data, operational management, safety, ICT infrastructure, and logistic systems permits their observation as a System of Systems (SoS). In addition, the prevalence of real-time information processing and the subsequent data explosion requires the utilization of Artificial Intelligence (AI) solutions. ITS characteristics depict them as AIbased SoS, which presents challenges to the verification and certification of these systems. This paper will frame ITS as Systems of Systems, considering their SoS classification from literature while outlining the role of AI applications in fostering effective and adequate mobility for these systems. With the understanding of the architecture and nature of ITS, it becomes easier to understand how the emergence and the complexity of modeling and evaluating these systems, among other challenges, contribute to the verification difficulty that will be encountered – key to certifying these systems. We propose some solutions from literature meant to serve as components of a holistic suite of solutions towards resolving the verification challenges posed by AI-based Systems of Systems like ITS.","10.1109/SOSE55472.2022.9812702","IEEE Conferences","2022","","IEEE"
"Sea-battlefield situation assessment based on a new method combining dynamic Bayesian network with pattern matching","Sea-battlefield situation is a dynamic, nonlinear and multi-dimensional system where Artificial Intelligence (AI) system has a good role to play. Bayesian Network has a strong knowledge skills and reasoning ability to solve the problem of sea-battlefield situation assessment. After constructing the network, giving the probability, considering the time factor and then combining with Pattern Matching using a rule set, sea-battlefield situation assessment can be achieved. The knowledge representation will be discussed and how to complete reasoning through Bayesian Network and Pattern Matching will be researched. In the end, a simulation will illustrate the combining method has a good performance in sea-battle-field situation assessment.","10.1109/CGNCC.2014.7007450","IEEE Conferences","2014","","IEEE"
"GitHub Considered Harmful? Analyzing Open-Source Projects for the Automatic Generation of Cryptographic API Call Sequences","GitHub is a popular data repository for code examples. It is being continuously used to train several AI-based tools to automatically generate code. However, the effectiveness of such tools in correctly demonstrating the usage of cryptographic APIs has not been thoroughly assessed. In this paper, we investigate the extent and severity of misuses, specifically caused by incorrect cryptographic API call sequences in GitHub. We also analyze the suitability of GitHub data to train a learning-based model to generate correct cryptographic API call sequences. For this, we manually extracted and analyzed the call sequences from GitHub. Using this data, we augmented an existing learning-based model called DeepAPI to create two security-specific models that generate cryptographic API call sequences for a given natural language (NL) description. Our results indicate that it is imperative to not neglect the misuses in API call sequences while using data sources like GitHub, to train models that generate code.","10.1109/QRS57517.2022.00094","IEEE Conferences","2022","","IEEE"
"A New Fracture Liaison Service Using the Mobile Application and IoT Sensor","While the clinical design of a Fracture Liaison Service(FLS) has been used as a localized healthcare service in a previous study, thus far there has not been an international mobile application, such as a FLS using smart phones. In addition, we developed a safety monitoring system using IoT sensor for a smart wheelchair. Our FLS is able to give patient various fall-related predictions with a safety monitoring system on this mobile application. The goal of our study is to improve the prevention of secondary fractures from our FLS application. We have developed a Fracture Liaison Service as an Android-OS application and released this service as a secondary fracture prevention program for osteoporotic fracture patients. We have released the final version of the FLS mobile application in Google's PlayStore. The new model of the FLS mobile application can be practically commercialized, and the effective second-order fracture prevention system is based on an open policy platform. We hope to contribute to the prevention and management of osteoporotic fractures and osteoporosis worldwide via this FLS mobile application. In the future, an intelligent personal FLS is definitely possible, by applying a Medical AI based on a huge DB.","10.1109/EMBC.2019.8857094","IEEE Conferences","2019","","IEEE"
"A Semantic Workbench for Editing, Querying, Navigating and Distributing Ontologies for Cognitive Manufacturing","Manufacturing-oriented enterprises are investing in novel solutions to adapt their cyber and physical resources to the fast and, yet, unexpected changes of global industrial environment. One of the important trends is to work towards development of cognitive systems which are capable to process and analyze complex data using Artificial Intelligence (AI)-based tools and techniques. Therefore, cognition can be already viewed as a requirement for hyper-connected environments e.g., the factories of the future or the Internet of Things (IoT). In this context, there is a need to represent and store the data collected from machines in a format that can be understood and manipulated by both humans and machines. This is feasible by designing and implementing semantic models i.e., ontologies which, in turn, enable inferring implicit data of explicit knowledge, leading to cognition. Moreover, there is a need of granting the access to such information remotely and at system runtime. Within this conceptual article, the authors present a semantic workbench that was developed during a European project aiming at utilization of ontologies for knowledge representation and reasoning in industrial automation systems. Further, this research work proposes the encapsulation of semantic workbench as a service in order to be deployed in cloud-based platforms, hence, enabling remote access of authorized clients at system runtime. The proposed functionalities are also of critical importance in highly complex and distributed environments, like the IoT or industrial ecosystems.","10.1109/IECON.2019.8927430","IEEE Conferences","2019","","IEEE"
"Driving style imitation in simulated car racing using style evaluators and multi-objective evolution of a fuzzy logic controller","This paper describes a new approach to driving style imitation in simulated car racing games. Our goal is to be able to create non-personal characters (NPCs) that both run competitively and exhibit some driving style traits of the player being imitated. We introduce a style evaluator function that can measure the style similarity between driving records even from different tracks. The effectiveness of such style evaluators are verified using driving records of both NPCs and human players. To build NPC drivers that can imitate particular human players, we use a base driver AI based on a fuzzy logic controller and optimizes its parameters using multi-objective evolution. This is the first work on driver imitation that actually allows several human players to drive in their only natural, not instructed, styles. Our results show evidences that the created imitator NPCs do possess traits of styles of the respective human players being modeled.","10.1109/NORBERT.2014.6893872","IEEE Conferences","2014","","IEEE"
"KIAAA: An AI Assistant for Teaching Programming in the Field of Automation","Especially in highly interdisciplinary fields such as automation engineering, contemporary programming education with tailored assignments and individual feedback is a major challenge for educational institutions due to the increasing number of students per teacher and the ever-increasing demand for computer science professionals. To address this gap, we present ”KIAAA” an AI Assistant for Automation Engineering Teaching, a work-in-progress approach for an integrated, customized, and AI-based learning support system for automation and programming courses based on instructor-defined course objectives. Thereby in the KIAAA system, the individual knowledge level of the students is determined and individually tailored virtual learning scenarios are generated based on the knowledge and learning profile of the students. These are iteratively adapted based on the answers given. To achieve this, KIAAA uses several AI components, a hybrid rule-based scenario generation component, a Help-DKT-based cognitive model, and a solution assessor that uses a combination of traditional code analysis methods and AI-based analyses methods for automated programming task assessment. These components are the main parts of KIAAA to generate customized programming scenarios as well as visualization and simulation based on a modern game and physics engine.","10.1109/INDIN51400.2023.10218157","IEEE Conferences","2023","","IEEE"
"Fuzzy Logic-based MPPT Control for Bifacial Photovoltaic Module","Solar Photovoltaics (PV) is crucial to meeting the energy needs of the current generation. Bifacial PV modules can generate high power density and higher energy yield with cost-effective operation due to their diffused and reflected irradiance-capturing capability. The power output of the PV system varies with varying temperatures and solar irradiance. The bifacial solar cell takes the independent value of irradiance for the front side and rear sides of the cell. Bifacial solar cells, like any other solar cell, are variable sources and their power output must be controlled, which is accomplished using the maximum power point tracking (MPPT) control techniques. Various Artificial Intelligence (AI) based algorithms are available for maximizing the power of the PV systems. AI-based methods have huge applications in PV systems to provide better responses. To get the Bifacial PV module's maximum operational power, this study proposes AI-based, fuzzy logic MPPT control with boost converter topology.","10.1109/ICEARS56392.2023.10085389","IEEE Conferences","2023","","IEEE"
"Comprehensive IoT SIM Card Anomaly Detection Algorithm Based on Big Data","The mobile Internet of Things (IoT) industry in China has developed rapidly and is expected to maintain rapid growth in the next decade. For the three mobile operators in China, IoT gradually becomes the new/key engine for profit growth. However, at the early stage of IoT development, due to the low cost of IoT SIM card, some illegal organizations and individuals take advantage of this loophole to earn illegal profits, which cause huge losses for mobile operators. In this paper, we explore comprehensive abnormal IoT SIM card detection algorithm based on IoT big data. For different IoT scenarios, this paper proposes two kinds of algorithms, including various rule-based detection algorithm (RDA) and AI-based detection algorithm (AIDA). The result of use case also shows that RDA and AIDA can greatly improve the anomaly detection accuracy and can benefit both of the telecommunication operators and enterprise customers.","10.1109/IUCC/DSCI/SmartCNS.2019.00126","IEEE Conferences","2019","","IEEE"
"Improving Circuit Miniaturization and Its Efficiency Using Rough Set Theory","High-speed, accuracy, meticulousness and quick responses are the notion of the vital necessities for modern digital world. An efficient electronic circuit unswervingly affects the maneuver of the whole system. Different tools are required to unravel different types of engineering tribulations. Improving the efficiency, accuracy and low power consumption in an electronic circuit is always been a bottle neck problem. So the need of circuit miniaturization is always there. It saves a lot of time and power while switching of gates and reduces the wiring-crises. Therefore to trounce with this problem we have proposed an artificial intelligence (AI) based approach that makes use of Rough Set Theory for its implementation. Theory of rough set has been proposed by Z Pawlak in the year 1982. Rough set theory is a new mathematical tool which deals with uncertainty and vagueness. Decisions can be generated using rough set theory by reducing the unwanted and superfluous data. We have condensed the number of gates without upsetting the productivity of the given circuit. This paper proposes an approach using artificial intelligence technique with the help of rough set theory which basically lessens the number of gates in the circuit, based on decision rules.","10.1109/ICMIRA.2013.79","IEEE Conferences","2013","","IEEE"
"GPT-K: A GPT-based model for generation of text in Kannada","Large AI-based language models are changing how we work with language. They are becoming increasingly popular because they allow us to create complex linguistic structures without requiring a lot of resources. A language model must have access to a large corpus of linguistic data (e.g., word frequencies) to learn and generate new words. GPT-2, a language model, can generate coherent paragraphs independently, without any input on what to write about or guidance on grammar rules. Although multiple pre-trained GPT-2 models exist for English and other high-resource languages, there are few to no such models for Indic languages like Kannada. In this study, we propose GPT-K, a GPT-2 based model for language modeling in Kannada. GPT-K has been trained on a large corpus of Kannada text and can effectively perform language modeling tasks in Kannada. The model generated syntactically correct text in most cases.","10.1109/ICCCMLA56841.2022.9989289","IEEE Conferences","2022","","IEEE"
"Integrated Multiple DEA Specifications and Visualization Technique for Advanced Management Analysis and Decision","In recent years, financial troubles (such as, financial crisis, credit risk, and default) have begun to appear and continue to grow rapidly, which has shocked the confidence of stack market participants as well as has frozen the circulation of valuable economic resource. Most previous works only laid much more emphasis on well-examined studies, such as financial crisis prediction and credit risk prediction, the work on forecasting corporate operating performance that has been widely deemed as the main trigger for financial troubles is quite rare. To fill this research gap, we introduces an artificial intelligence (AI)-based hybrid architecture that integrated dominance-based rough set theory (DBRST), support vector machine with particle swarm optimization (SVM-PSO) and rule generation. The introduced model, tested by real-cases, is a promising alternative for corporate operating performance forecasting and it can assist in both internal and external market participants.","10.1109/MDM.2019.00011","IEEE Conferences","2019","","IEEE"
"Comparison of ANN and ANFIS based MPPT Controller for grid connected PV systems","This paper presents comparison analysis of artificial neural network (ANN) and adaptive neuro fuzzy inference system (ANFIS) artificial intelligence (AI) based maximum power point tracking (MPPT) techniques for tracking maximum power from the Photovoltaic (PV) array. These algorithms are essential since PV arrays have non-linear characteristics with its firm dependence on changing solar irradiation and temperature. To increase the power extracted from solar panel, PV array must operate at a maximum power point (MPP) under given load conditions. Conventional algorithms such as Perturb and Observe (P&O) and Incremental-Conductance (Inc-Cond) suffers, with high oscillations during changing solar irradiation leading to low efficiency, therefore AI based techniques are designed and presented in this paper. ANFIS is more efficient in tracking MPP with less settling time, less overshoot, less oscillations and less time taken to track MPP than ANN based Controller.","10.1109/INDICON.2015.7443568","IEEE Conferences","2015","","IEEE"
"Intrusion Detection Systems Based on Machine Learning Using Feature Expansion Methods","With the development of computer networks, the amount of network traffic is explosively increasing. In addition, the importance of cyber security is being highlighted as cyber threats increase accordingly. In general, rule-based detection approaches have been used to detect cyber threats. The detection rules used in these are broadly set up to reliably detect cyber threats, resulting in too many unnecessary events. This leads to unanalyzed events, which can lead to severe security incidents. To solve this problem, recently, researches on AI-based cyber threat detection system that learns network traffic information and automatically generates detection rules are being conducted. Most of them have used complex model with sophisticated structures or feature engineering techniques so that AI models can learn as much information as possible. But, these are difficult to use in real-world security monitoring environment where quick decisions need to be made in real time, and are not suitable for that environments because they have been trained and verified through only open datasets. In this paper, we propose an AI-based cyber threat detection system that efficiently learns security event characteristics without any complicated process using tree-based model which efficient to learning tabular data. The proposed system detects cyber threats by learning security event characteristics using only information provided from security devices without complicated feature extraction process. In addition, rather than using the used information as a simple value, the value is transformed through a simple process so that the model can learn the event characteristics more effectively. Using the simplicity of the proposed method, it is expected that it can be applied to the real-world environments, and the possibility of this is demonstrated through real-world data.","10.1109/AsiaJCIS60284.2023.00016","IEEE Conferences","2023","","IEEE"
"How Artificial Intelligence and Mobile Crowd Sourcing are Inextricably Intertwined","Mobile Crowd Sourcing (MCS) has been an enabler in the development of artificial intelligence (AI) in general, and machine learning in particular. From collecting data to giving meaning to the data, there has been considerable work supporting the use of MCS in AI. While successful, current MCS solutions still suffer from limitations such as workers recruitment, data quality, trust, and so on, that can benefit a great deal from AI. However, the integration of AI in MCS is still at a nascent stage, thus opening various opportunities for further research. In this article, we review and discuss the integration of AI in MCS solutions, highlight its research challenges, and suggest means to address them. We also propose a novel architecture for AI-based MCS, where AI techniques are integrated and embedded in the different layers of MCS framework to provide efficient and trusted MCS applications. In particular, a machine learning (ML)-based selection using behaviors of individual workers is proposed, and its efficacy is gauged by analyzing a use-case study. The results show that by implementing a hybrid approach, the efficiency of selection was considerably improved. This article demonstrates a clear overview of AI-based MCS solutions and provide guidelines on applying AI to solve the current challenges and open issues.","10.1109/MNET.011.2000516","IEEE Magazines","2021","","IEEE"
"Trustworthiness of Artificial Intelligence","This paper discusses the need for a trustworthy AI, along with the ethics which are required to keep that trust intact. AI has a lot of benefits when it comes to societal, individual or cultural development. But any mistake in either the development or in the working phase of the AI system can be disastrous, especially when human lives are involved. The main goal of this paper is to understand what really makes an Artificial Intelligence system trustworthy.","10.1109/ICACCS48705.2020.9074237","IEEE Conferences","2020","","IEEE"
"Delivering Health Intelligence For Healthcare Services","The systems barrier for clinical information interoperability and standards has now evolved from a technology barrier to a semantic barrier. The processes to gather clinical data and to build clinical information and knowledge cannot be fully implemented, owing to semantic dissonances and limited data normalization. According to [1], “Just over a half of entered codes were appropriate for a given scenario and about a quarter were omitted.” This is a significant data and financial gap for healthcare provision. Huge amount of addition to the financial cost, lack of data integration and loss of information affects the ability to maintain standards in clinical care delivery and patient outcomes. This paper proposes that the solution to these issues is an augmented network of clinical note taking, where coding is automatically generated by an AI system as clinicians write their clinical notes. The system (AI-KEN) offers enhanced web support that is integrated to local clinical systems, whereby clinical notes are prompted by suggested predictive text options in real time. The anticipated benefits include reducing financial loss for acute services, support for clinical standard maintenance and enhanced advancements for clinical practice and research in real time.","10.1109/DDP.2019.00026","IEEE Conferences","2019","","IEEE"
"Mamdani fuzzy logic-based smart measuring device as quality determination for grain post-harvest technology","Agriculture is one sector that has a maj or role in the national economy, where agriculture has a contribution of 13.53 percent of GP A in Indonesia. The most widely produced agricultural products are types of grains such as corn, rice, and beans. However, the price of these commodities is often controlled by brokers, several aspects that become the benchmark for brokers to price these commodities are the quality of the seeds. The quality of rice or corn seeds is considered good if it meets a very small level of moisture content. Therefore, sometimes farmers dry their harvests for a long time without knowing the level of water content contained in their harvests so that it will hamper the distribution of crops. The solution to the problems experienced by the farmers is a device that can detect the moisture content in harvested seeds at low prices and an easy-to-use process, and is supported by an AI system that can assist farmers in making decisions about crop quality. This device works by reading the level of moisture in the grain using a humidity sensor that is plugged into the harvest container such as sacks and others. If it is felt that the moisture level is low, the device will provide suggestions to the user to support decision-making through the OLED screen installed on the device. The features make it easier for users to make decisions whether the harvest is worth selling or not.","10.1109/ICE3IS54102.2021.9649685","IEEE Conferences","2021","","IEEE"
"AI Engineering to Deploy Reliable AI in Industry","To bring competitive advantage to industry through a sound AI deployment, we need an end-to-end “AI systems engineering” process covering the overall lifecycle of an AI system, both at component level and at system level, regardless of whether the specifications come from regulation and reliability concerns.","10.1109/TransAI60598.2023.00015","IEEE Conferences","2023","","IEEE"
"SuperDriverAI: Towards Design and Implementation for End-to-End Learning-Based Autonomous Driving","Fully autonomous driving has been widely studied and is becoming increasingly feasible. However, such autonomous driving has yet to be achieved on public roads, because of various uncertainties due to surrounding human drivers and pedestrians. In this paper, we present an end-to-end learning-based autonomous driving system named SuperDriver AI, where Deep Neural Networks (DNNs) learn the driving actions and policies from the experienced human drivers and determine the driving maneuvers to take while guaranteeing road safety. In addition, to improve robustness and interpretability, we present a slit model and a visual attention module. We build a data-collection system and emulator with real-world hardware, and we also test the SuperDriver AI system with real-world driving scenarios. Finally, we have collected 150 runs for one driving scenario in Tokyo, Japan, and have shown the demonstration of SuperDriver AI with the real-world vehicle.","10.1109/VNC57357.2023.10136277","IEEE Conferences","2023","","IEEE"
"AI Augmentation to Remote Sensing Imagery in Forestry Conservation & Restoration for Increased Responsive Capabilities","Responsive forestry management is critical to carbon management and climate change mitigation. The United Nation’s Intergovernmental Panel on Climate Change (IPCC) Special Report stated that mitigation measures in forests from 2010-2019 have delivered approximately 80% of carbon mitigation from Land Use sectors. Advancements in Remote Sensing (RS) and Artificial Intelligence (AI) technologies hold significant potential to increase the necessary coverage and speed of forestry management; however, there is a delay in the current capability integration due to technical, cost, and human-factor constraints that prevent adoption and deployment. This research details the formation of the ART3MIS-AI (Augmented Real-Time 3D Mapping with Intelligent Sensing AI) system framework, an AI-augmentation framework design that minimizes these constraints. It is tailored for responsive deployment in forestry agencies and provides long-term robustness and extensibility for all four functions of forestry management. Our research analyzes AI capabilities in forestry RS from 75 research papers and assesses the potential integration pathways of these capabilities into the post-processing infrastructures of RS within forestry management for augmented-data transformation and critical metric extraction. The ART3MIS-AI system framework optimizes these observed capabilities for additional high levels of interpretability and extensibility given the technical and sensing platform constraints of forestry agencies. We generated a set of objectives and guidelines to facilitate the responsive deployment and integration of AI-augmentation frameworks within forestry agencies. The guidelines are based on established work in Human Machine Teaming, AI-Assurance, and prior research, in addition to consultation from our forestry professional partners in United States forestry agencies. The proposed ART3MIS-AI system framework is a detailed four-phase, automated and pipelined system implemented in Python and C++. It transforms RS imagery into ""Smart"" Point Clouds with augmented hyperspectral information, vegetation classification, and structural mission metrics to an individual tree scale (canopy height/width, timber volume/fuel loading, species identification, etc.). The ART3MIS-AI system framework accelerates structured tactical data delivery to forestry professionals and provides capabilities in tailored virtual planning. The system framework design, integration analysis, and additional guidelines within this paper provide the foundations for the large-scale and methodological integration of AI-augmentation into RS forestry conservation and restoration capabilities.","10.1109/AIPR57179.2022.10092215","IEEE Conferences","2022","","IEEE"
"MLoC: A Cloud Framework adopting Machine Learning for Industrial Automation","By leveraging the modern machine learning algorithms, we can build up more Artificial Intelligence (AI) systems, like self-driving cars, smart factories and financial analysis systems, to improve our daily life. In addition to building up an AI system, several prerequisites are required to drive the system, including data collection, data storage, machine learning models, training dataset, parameters tuning, and so on. To obtain the benefit of scalability and flexibility, most AI systems are built on a cloud platform, which shares resources with others in the same infrastructure. Though the above concept is trivial, the implementation faces big challenges when realizing it. In this paper, an easy-to-use cloud framework for machine learning as well as its implementation guideline is presented for building up a cloud-based development platform. We conduct several experiments on analyzing and monitoring the health condition of bearings of motors. We compare and analyze the feasibility of the proposed framework.","","IEEE Conferences","2019","","IEEE"
"Automated Brittle Fracture Rate Estimator for Steel Property Evaluation Using Deep Learning After Drop-Weight Tear Test","This study proposes an automated brittle fracture rate (BFR) estimator using deep learning. As the demand for line-pipes increases in various industries, the need for BFR estimation through drop-weight tear test (DWTT) increases to evaluate steel's property. Conventional BFR or ductile fracture rate (DFR) estimation methods require an expensive 3D scanner. Alternatively, a rule-based approach is used with a single charge-coupled device (CCD) camera. However, it is sensitive to the hyper-parameter. To solve these problems, we propose an approach based on deep learning that has recently been successful in the fields of computer vision and image processing. The method proposed in this study is the first to use deep learning approach for BFR estimation. The proposed method consists of a VGG-based U-Net (VU-Net) which is inspired by U-Net and fully convolutional network (FCN). VU-Net includes a deep encoder and a decoder. The encoder is adopted from VGG19 and transferred with a pre-trained model with ImageNet. In addition, the structure of the decoder is the same as that of the encoder, and the decoder uses the feature maps of the encoder through concatenation operation to compensate for the reduced spatial information. To analyze the proposed VU-Net, we experimented with different depths of networks and various transfer learning approaches. In terms of accuracy used in real industrial application, we compared the proposed VU-Net with U-Net and FCN to evaluate the performance. The experiments showed that VU-Net was the accuracy of approximately 94.9 %, and was better than the other two, which had the accuracies of about 91.8 % and 93.7 %, respectively.","10.1109/ACCESS.2019.2945563","IEEE Journals","2019","","IEEE"
"Clean Code and Design Educational Tool","Many different code snippets can implement the same software feature. However, a significant subset of these possible solutions contains difficult-to-understand code that harms the software's maintainability and evolution. Such low-quality code snippets directly harm profit, as frequent and fast code change enables businesses to seize new opportunities. Unfortunately, they are also prevalent in an industry that consists mostly of junior programmers. We developed a platform called Clean CaDET to tackle the prevalence of low-quality code from two angles. The Smell Detector module presents a framework for integrating AI-based code quality assessment algorithms to identify low-quality code as the programmer is writing it. The Smart Tutor module hosts a catalog of educational content that helps the programmer understand the identified issue and suggests possible solutions. By combining the quality assessment with the educational aspect, our integrated solution presents a novel approach for increasing the quality of code produced by our industry.","10.23919/MIPRO52101.2021.9597196","IEEE Conferences","2021","","IEEE"
"Interpreting AI for Networking: Where We Are and Where We Are Going","In recent years, artificial intelligence (AI) techniques have been increasingly adopted to tackle networking problems. Although AI algorithms can deliver high-quality solutions, most of them are inherently intricate and erratic for human cognition. This lack of interpretability tremendously hinders the commercial success of AI-based solutions in practice. To cope with this challenge, networking researchers are starting to explore explainable AI (XAI) techniques to make AI models interpretable, manageable, and trustworthy. In this article, we overview the application of AI in networking and discuss the necessity for interpretability. Next, we review the current research on interpreting AI-based networking solutions and systems. At last, we envision future challenges and directions. The ultimate goal of this article is to present a general guideline for AI and networking practitioners and motivate the continuous advancement of AI-based solutions in modern communication networks.","10.1109/MCOM.001.2100736","IEEE Magazines","2022","","IEEE"
"Prediction of MEMS-based INS Error Using Interval Type-2 Fuzzy Logic System in INS/GPS Integration","In recent years, for reliable, accurate, and robust navigation, Global Positioning System (GPS) and Inertial Navigation System (INS) has been integrated to use their complementary advantages and overcome their drawbacks. Kalman Filtering methods such as Extended Kalman Filter (EKF) have been used for INS/GPS integration widely. The EKF-based navigation systems are complex, and they might not have effective real-time performance, especially with the MicroElectro Mechanical System (MEMS)-based INS when GPS is blocked. To overcome these problems, Artificial Intelligence (AI) based integration was proposed over the Kalman filtering models. Due to the stochastic noise, bias, and drift of the low-cost MEMS-based inertial sensor outputs over time, in this study, we propose an Interval Type-2 Fuzzy Logic System (IT2FLS) to predict the MEMS-based sensor errors in GPS blockage. The IT2FLS can model uncertainty and stochastic noise of both input and training data in complex, noisy environments such as our application. Therefore, we use the IT2FLS to forecast the cumulative INS error during GPS outages to improve the accuracy of the navigation system. The experimental tests show that the IT2FLS has acceptable realtime performance and accuracy in predicting the INS error during the long-term GPS outages.","10.1109/CSICC49403.2020.9050081","IEEE Conferences","2020","","IEEE"
"Use of Expert System in Requirements Engineering Process A Systematic Literature Review","Requirements Engineering (RE) process deals with elicitation, analysis, negotiation, validation, management, and documentation of requirements. Several artificial intelligence (AI) based approaches have been proposed to automate RE activities. However, the requirements engineering community still lacks a comprehensive understanding on how expert system are used in RE process. The objectives of this study are (1) to explore the different AI approaches which are employed in requirements engineering, (2) to identify the main phases addressed by these approaches, (3) to identify AI tools that used in RE process, and (4) we tried to find the contributions and the benefits of applying expert system in RE. We found that expert system can partially facilitate the RE process, however no expert system can fully automate the RE process.","10.1109/UCET.2019.8881880","IEEE Conferences","2019","","IEEE"
"Adaptive Fuzzy-PI Control of Wind Energy Conversion System Based DFIG Under Voltage Dip","The Proportional-Integral (PI) and Fuzzy Logic Controllers (FLC) cannot deal accurately with the system variation. To overcome the drawbacks of PI and FLC regulators, the Adaptive Fuzzy-PI Controllers (AFPICs) are configured. This paper presents a comparison between three different controllers based control methodology for Variable Speed Wind Energy Conversion Systems (WECSs) by means of Doubly Fed Induction Generator (DFIG). Artificial Intelligence (AI) based FLCs is performed to improve the system efficiency and performance under Small Disturbance (SD) and Large Disturbance (LD) cases. To test the PI, FLC, and AFPIC robustness, simulations are done during abrupt wind speed variation (SD), and voltage dip fault (LD). The simulation results show that the proposed AFPIC delivers improved power control, better response rise time, reduced overshoot, undershoot, and settling time compared to classical PI and Fuzzy controllers. The proposed control is proved by simulation using Matlab/Simulink-R2016b.","10.1109/ICEIT48248.2020.9113215","IEEE Conferences","2020","","IEEE"
"Towards Training Reproducible Deep Learning Models","Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.","10.1145/3510003.3510163","IEEE Conferences","2022","","IEEE"
"Speed control of Induction Motor via Fuzzy Proportional Integral (FPI) controller","The Induction Motor (IM) control in industrial drives is widely acknowledged for robustness and low maintenance. The vector control technique is mostly used for the speed control of IM. The hybrid control e.g. Fuzzy with classic PI control provide adequate response with load variations of motor. Speed control is a challenging task as IM is characterized by its nonlinear dynamics. In case of complex systems, the traditional control theory fails. To address the aforesaid problem, artificial intelligence (AI) based control systems are proposed. Moreover Fuzzy control is one of such options to provide an alternative to past conventional control methodology for dealing with complex systems. This paper presents the Fuzzy Proportional Integral (FPI) control scheme designed for speed the control of IM.","10.1109/ICECUBE.2016.7495220","IEEE Conferences","2016","","IEEE"
"Detection of Malicious Domains in the Cyberspace using Machine Learning & Deep Learning: A Survey","People have daily access to a wide range of services through the World Wide Web, which serves as a platform for global information exchange. Businesses uses web as a low-cost communication channel for their business promotion and communications. As a result, millions of domains are created and registered every day. This immense development allows cyber criminals to play as well. Cybercriminals use a variety of methods to exploit the web security. Recent cyber security reports states that security breaches are 17% higher in 2021 than in 2020. Cybercriminals use URLs (domain name) as an easy tool to carry out malicious activities. Through email, SMS, and social media sites like Face book and Twitter, malicious URLs are disseminated. As soon as victims click on the URL, fraudsters will steal their personal data or place malware on their computer to get access to other systems. It is very important to detect such malicious domain names in advance using AI based techniques. Researchers have proposed several methods to classify malicious domain names and malicious domain names. Recently they preferred to use machine learning and deep learning techniques for automated classification. This paper presents a recent research work in this field and research issues. This will serve as source of new research in this domain.","10.1109/SMART55829.2022.10047254","IEEE Conferences","2022","","IEEE"
"Decision Making Algorithm for Blind Navigation Assistance using Deep Learning","Blind people face several obstacles in their daily lives and technological interventions can help overcome these obstacles. In this research, we provide an AI-based autonomous assisting device that recognizes many objects and it will provide acoustic input to the user to help visually blind people to understand the surrounding better to understand their environment better. Multiple photos of objects relevant to visually impaired people were used to build a deep-learning model. Training photos are enhanced and manually annotated to improve the trained model's resilience. A distance-measuring sensor is included which recognise the objects using computer vision. The gadget is made more inclusive by recognizing the obstacles coming out of one place to another. After stage segmentation and obstacle detection, the aural information sent to the user is adj usted to get a lot of details in minimum time and speed up video processing.","10.1109/ICCST55948.2022.10040269","IEEE Conferences","2022","","IEEE"
"Residential Energy Management System Using Fuzzy Logic","Electricity demand is a crucial indicator of a country's economic growth, but a change in environmental factors significantly impacts this factor. India has set a target of 500 GW of renewable energy by 2030 as part of its climate mitigation efforts at the COP-26 Summit in Glasgow to minimize electricity demand. In India, electrical energy is generated from thermal, hydro, nuclear, and renewable sources. There are various measures taken for energy conservation by industries. Due to technological development, advanced power generation technologies, and a rise in per capita income, there is a rise in residential energy consumption too. Energy conservation in the residential sector is a challenge. It needs social awareness. This paper contains an AI based fuzzy model that gives low, moderate, and high levels of residential energy consumption. That helps the consumer understand the level of energy they are using, and the cost of energy can be reduced by optimizing the energy consumption.","10.1109/I2CT57861.2023.10126420","IEEE Conferences","2023","","IEEE"
"Learning-Based Diagnostics for Fault Detection and Isolation in Linear Stochastic Systems","AI-enabled mechanisms are deployed to guard controlled systems against sensor anomalies. We explore a two-level architecture design in which a low-level feedback controller of a linear system uses measurements from one or more potentially unreliable sensors. These observations are prone both to sensor noise but unknown additive faults. Our proposed, high-level, guard mechanism consists of a Reinforcement Learning (RL) agent that monitors available vitals of the system. In the event of a fault on the sensor components, the RL agent automatically detects, estimates the fault, localizes and takes action to cancel the fault. In addition, we develop design methodologies for efficient training of the RL agent that take advantage of system dynamics and sensor fusion schemes. We show that the associated training cost functions can be designed so that their optimal policy achieves efficient of arbitrary constant or piece-wise constant sensor faults. To illustrate our theoretical results, we consider a linearized version of a chemical process with multiple sensors, controlled by a Linear Quadratic Gaussian (LQG) Servo-Controller with Integral Action. Our simulations show that the RL-agent is successful in localizing the faulty sensors and mitigating the effects of faults in an online fashion.","10.1109/MED54222.2022.9837165","IEEE Conferences","2022","","IEEE"
"Artificial Intelligence Based Early Diagnosis of Sepsis","Sepsis is a major killer of those who are already in a serious condition. The morbidity and death rates in this field remain high, despite the fact that medical technology has been advancing steadily over the last several years. This is due mostly to people not beginning therapy quickly enough and doctors not following best practices. Medical decision support solutions have advanced greatly with the help of artificial intelligence (AI), a rapidly developing sector in the medical industry. Great promise has been shown in its ability to anticipate patients' clinical conditions and aid clinical decision-making. Early prediction, prognosis evaluation, mortality prediction, and optimum treatment are just few of the areas where algorithms developed using artificial intelligence may be put to use. This article summarizes the most recent research on AI based clinical decision support in sepsis as well as explains how this cutting-edge technology might aid in sepsis prediction, identification, sub phenotyping, prognostic evaluation, and clinical treatment. We also spoke about the difficulties of using this non-conventional approach in clinical practice.","10.1109/ICACITE57410.2023.10182599","IEEE Conferences","2023","","IEEE"
"The impact of Artificial Intelligence, Blockchain, Big Data and evolving technologies in Coronavirus Disease - 2019 (COVID-19) curtailment","The pandemic of Coronavirus Disease 2019 (COVID-19) is proliferating across the globe obnoxiously and it is the most heard buzzword in recent times. Every person ranging from older people, persons with disabilities, youth, indigenous people have become a part of this chain and are most likely to suffer in the upcoming chronology. Social distancing is likely to become a new norm where “Work from Home”, Online Lectures” and “Meetings” ensue on social media applications. Technology has always lent a helping hand for mankind's problems. The idea focuses on highlighting the advancements in technology in the midst of a bizarre situation. Deep Learning applications to detect the symptoms of COVID-19, AI based robots to maintain social distancing, Blockchain technology to maintain patient records, Mathematical modeling to predict and assess the situation and Big Data to trace the spread of the virus and other technologies. These technologies have immensely contributed to curtailing this pandemic. Strong will power, patience and optimistic guidelines catered by the respective government are some of the altercations to COVID-19.","10.1109/ICOSEC49089.2020.9215294","IEEE Conferences","2020","","IEEE"
"ECCOLA - a Method for Implementing Ethically Aligned AI Systems","Various recent Artificial Intelligence (AI) system failures, some of which have made the global headlines, have highlighted issues in these systems. These failures have resulted in calls for more ethical AI systems that better take into account their effects on various stakeholders. However, implementing AI ethics into practice is still an on-going challenge. High-level guidelines for doing so exist, devised by governments and private organizations alike, but lack practicality for developers. To address this issue, in this paper, we present a method for implementing AI ethics. The method, ECCOLA, has been iteratively developed using a cyclical action design research approach. The method aims at making the high-level AI ethics principles more practical, making it possible for developers to more easily implement them in practice.","10.1109/SEAA51224.2020.00043","IEEE Conferences","2020","","IEEE"
"An Explainable Artificial Intelligence (xAI) Framework for Improving Trust in Automated ATM Tools","With the increased use of intelligent Decision Support Tools in Air Traffic Management (ATM) and inclusion of non-traditional entities, regulators and end users need assurance that new technologies such as Artificial Intelligence (AI) and Machine Learning (ML) are trustworthy and safe. Although there is a wide amount of research on the technologies themselves, there seem to be a gap between research projects and practical implementation due to different regulatory and practical challenges including the need for transparency and explainability of solutions. In order to help address these challenges, a novel framework to enable trust on AI-based automated solutions is presented based on current guidelines and end user feedback. Finally, recommendations are provided to bridge the gap between research and implementation of AI and ML-based solutions using our framework as a mechanism to aid advances of AI technology within ATM.","10.1109/DASC52595.2021.9594341","IEEE Conferences","2021","","IEEE"
"The Two Faces of AI in Green Mobile Computing: A Literature Review","Artificial intelligence is bringing ever new functionalities to the realm of mobile devices that are now considered essential (e.g., camera and voice assistants, recommender systems). Yet, operating artificial intelligence takes up a substantial amount of energy. However, artificial intelligence is also being used to enable more energy-efficient solutions for mobile systems. Hence, artificial intelligence has two faces in that regard, it is both a key enabler of desired (efficient) mobile functionalities and a major power draw on these devices, playing a part in both the solution and the problem. In this paper, we present a review of the literature of the past decade on the usage of artificial intelligence within the realm of green mobile computing. From the analysis of 34 papers, we highlight the emerging patterns and map the field into 13 main topics that are summarized in details.Our results showcase that the field is slowly increasing in the past years, more specifically, since 2019. Regarding the double impact AI has on the mobile energy consumption, the energy consumption of AI-based mobile systems is under-studied in comparison to the usage of AI for energy-efficient mobile computing, and we argue for more exploratory studies in that direction. We observe that although most studies are framed as solution papers (94%), the large majority do not make those solutions publicly available to the community. Moreover, we also show that most contributions are purely academic (28 out of 34 papers) and that we need to promote the involvement of the mobile software industry in this field.","10.1109/SEAA60479.2023.00053","IEEE Conferences","2023","","IEEE"
"AI Ethics in Smart Healthcare","This article reviews the landscape of ethical challenges of integrating artificial intelligence (AI) into smart healthcare products, including medical electronic devices. Differences between traditional ethics in the medical domain and emerging ethical challenges with AI-driven healthcare are presented, particularly as they relate to transparency, bias, privacy, safety, responsibility, justice, and autonomy. Open challenges and recommendations are outlined to enable the integration of ethical principles into the design, validation, clinical trials, deployment, monitoring, repair, and retirement of AI-based smart healthcare products.","10.1109/MCE.2022.3220001","IEEE Magazines","2023","","IEEE"
"Development of Artificial Intelligence for Variable Rate Application Based Oil Palm Fertilization Recommendation System","The need for fertilization knowledge that meets good cultivation principles is the background for the need for a platform that can help provide advice on fertilization implementation. The conventional method through leaf and soil analysis to determine the dose of fertilization has many obstacles in its implementation. The availability of experts to provide advice is also not available at all times. One way to transfer knowledge to non-experts is to use Artificial Intelligence (AI) in the form of a dynamic expert system. The purpose of this research is to create a dynamic expert system that can provide advice and apply fertilization quickly, cheaply, accurately, and available at all times. In building this AI system, a knowledge base, working memory, inference engine, and interface are needed. The implementation of dynamic expert system development consists of four stages, namely (1) literature study, (2) laboratory analysis, (3) construction of an inference engine, and (4) interface creation. Based on the literature study that has been carried out, it is known that there are three domains of knowledge of oil palm fertilization, namely the domain of soil, plants and climate. Each of these knowledge domains consists of attributes, sub-attributes, and facts of knowledge which are then arranged in the form of mathematical rules. The relationship between the three knowledge domains is used as the basis for making fertilization rules. The result of this research is an application with Artificial Intelligence to provide information on nutritional needs according to plant age, population, production, land area and location. The application provides recommendations for the type, frequency, amount of fertilizer, and time of application.","10.1109/ICIMTech53080.2021.9535082","IEEE Conferences","2021","","IEEE"
"AI Loyalty: A New Paradigm for Aligning Stakeholder Interests","When we consult a doctor, lawyer, or financial advisor, we assume that they are acting in our best interests. But what should we assume when we interact with an artificial intelligence (AI) system? AI-driven personal assistants, such as Alexa and Siri, already serve as interfaces between consumers and information on the Web, and users routinely rely upon these and similar systems to take automated actions or provide information. Superficially, they may appear to be acting according to user interests, but many are designed with embedded conflicts of interests. To address this problem, we introduce the concept of AI loyalty. AI systems are loyal to the degree that they minimize and make transparent, conflicts of interest, and act in ways that prioritize the interests of users. Loyal AI products hold obvious appeal for the end-user and could promote the alignment of the long-term interests of AI developers and customers. To this end, we suggest criteria for assessing whether an AI system is acting in a manner that is loyal to the user, and argue that AI loyalty should be deliberately considered during the technological design process alongside other important values in AI ethics, such as fairness, accountability privacy, and equity.","10.1109/TTS.2020.3013490","IEEE Journals","2020","","IEEE"
"Running Pace Adjustment and Training Distance Fitting with Fuzzy Logic and Machine Learning","A sedentary lifestyle and lack of sports favor the occurrence of many civilization diseases. To address the problem, the UN set 17 Sustainable Development Goals to be achieved glob-ally by 2030. They assume an enduring improvement in the life quality of present and future generations. One of the UN objects is “Goal 3: Good health and well-being”, focusing on ensuring a healthy life for all people and promoting well-being. An active lifestyle improves health by reducing the number and frequency of illnesses. This paper aims to develop an Artificial Intelligence (AI) system to provide training recommendations and evaluate decision-making algorithms for running pace adjustment and training distance fitting based on fuzzy logic. The data collected from running sessions enabled the construction of an AI system based on the data from the sports watch and personal feelings from the athlete regarding his emotions during each kilometer of the run. Comparing the system indications with information from the user due to fuzzy inference allowed a runner to increase endurance. Hence, using the provided recommendations, training can be intensified and training sensations - maintained.","10.1109/ISCIT55906.2022.9931228","IEEE Conferences","2022","","IEEE"
"Semi-Automatic Validation and Verification Framework for CV&AI-Enhanced Railway Signaling and Landmark Detector","The automation of railway operations is an activity in constant growth. Different railway stakeholders are already developing their research activities for the future driverless autonomous driving based on computer vision (CV) and artificial intelligence (AI)-enhanced perception technologies (e.g., obstacle detection). Unfortunately, the AI models are opaque in nature, and there are no certification accepted rules for CV&AI-enhanced functionality certification. Capturing and labeling camera image in real environment is expensive in terms of time and resources and it does not guarantee enough variation in edge visibility conditions, which makes the resulting database less valuable for the validation and verification (V&V) processes. To meet the increasing needs of trusted CV&AI-based solutions, numerous V&V approaches have been proposed in other sectors such as automotive, most of them based on virtual simulators. Unfortunately, there is currently no virtual perception simulator for railway scenario. This work aims to create a semi-automatic system based on virtual scenarios measuring the CV&AI-enhanced system performance facing different visibility conditions. It will be based on the global accuracy metrics and detected potential safety and operation rules’ violations. This work also demonstrates the quantitative and qualitative improvements while reducing current V&V cost.","10.1109/TIM.2023.3284928","IEEE Journals","2023","","IEEE"
"Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack","In autonomous driving (AD), accurate perception is indispensable to achieving safe and secure driving. Due to its safety-criticality, the security of AD perception has been widely studied. Among different attacks on AD perception, the physical adversarial object evasion attacks are especially severe. However, we find that all existing literature only evaluates their attack effect at the targeted AI component level but not at the system level, i.e., with the entire system semantics and context such as the full AD pipeline. Thereby, this raises a critical research question: can these existing researches effectively achieve system-level attack effects (e.g., traffic rule violations) in the real-world AD context? In this work, we conduct the first measurement study on whether and how effectively the existing designs can lead to system-level effects, especially for the STOP sign-evasion attacks due to their popularity and severity. Our evaluation results show that all the representative prior works cannot achieve any system-level effects. We observe two design limitations in the prior works: 1) physical model-inconsistent object size distribution in pixel sampling and 2) lack of vehicle plant model and AD system model consideration. Then, we propose SysAdv, a novel system-driven attack design in the AD context and our evaluation results show that the system-level effects can be significantly improved, i.e., the violation rate increases by around 70%.","10.1109/ICCV51070.2023.00407","IEEE Conferences","2023","","IEEE"
"Development of System for Detection and Prevention of Cyber Attacks Using Artifıcial Intelligence Methods","Artificial intelligence (AI) technologies have given the cyber security industry a huge leverage with the possibility of having significantly autonomous models that can detect and prevent cyberattacks – even though there still exist some degree of human interventions. AI technologies have been utilized in gathering data which can then be processed into information that are valuable in the prevention of cyberattacks. These AI-based cybersecurity frameworks have commendable scalability about them and are able to detect malicious activities within the cyberspace in a prompter and more efficient manner than conventional security architectures. However, our one or two completed studies did not provide a complete and clear analyses to apply different machine learning algorithms on different media systems. Because of the existing methods of attack and the dynamic nature of malware or other unwanted software (adware etc.) it is important to automatically and systematically create, update and approve malicious packages that can be available to the public. Some of Complex tests have shown that DNN performs maybe can better than conventional machine learning classification. Finally, we present a multiple, large and hybrid DNN torrent structure called Scale-Hybrid-IDS-AlertNet, which can be used to effectively monitor to detect and review the impact of network traffic and host-level events to warn directly or indirectly about cyber-attacks. Besides this, they are also highly adaptable and flexible, with commensurate efficiency and accuracy when it comes to the detection and prevention of cyberattacks.There has been a multiplicity of AI-based cyber security architectures in recent years, and each of these has been found to show varying degree of effectiveness. Deep Neural Networks, which tend to be more complex and even more efficient, have been the major focus of research studies in recent times. In light of the foregoing, the objective of this paper is to discuss the use of AI methods in fighting cyberattacks like malware and DDoS attacks, with attention on DNN-based models.","10.1109/GCAT52182.2021.9587584","IEEE Conferences","2021","","IEEE"
"We Are Not Pontius Pilate: Acknowledging Ethics and Policy","A new AI system is being developed to optimize vaccination strategies based on the structure and shape of a community's social contact network. The technology is minimally constrained and not bound by preconceived notions or human biases. With this come novel outside the box strategies; however, the system is only capable of optimizing what it is instructed to optimize, and does not consider any ethical or political concerns. With the growing concern for systematic discrimination as a result of artificial intelligence, we acknowledge a number of relevant issues that may arise as a consequence of our new technology and categorize them into three classes. We also introduce four normative ethical approaches that are used as a framework for decision-making. Despite the focus on vaccination strategies, our goal is to improve the discussions surrounding public concern and trust over artificial intelligence and demonstrate that artificial intelligence practitioners are addressing these concerns.","10.1109/SSCI47803.2020.9308312","IEEE Conferences","2020","","IEEE"
"AI-Powered Edge-Cloud Continuum for In-Flight Entertainment and Connectivity","The aviation industry is moving toward a greener, more sustainable, integrated, and digital ecosystem, with Artificial Intelligence (AI) and machine learning showing potential key roles in the transformation process. Travelers, who are now increasingly used to ubiquitous data access, are restarting their air travels with higher expectations and demands for connectivity services. This trend highlights the importance of the in-flight entertainment and connectivity system, which should adapt to such changes and be designed to focus on network security and privacy. In this article, we provide experimental demonstration of an AI-based edge-computing platform developed within the cloud-enabled Aircraft Network and ARtificial Intelligence-based data Analysis (CANARIA) project, which targets to deliver proof-of-concept of an in-flight edge network. The CANARIA edge-computing platform offers a set of AI-based and containerized applications to not only improve the in-flight experience for cabin crew and passengers, but also to underpin the cabin digital transformation while increasing the safety and security of the connectivity system.","10.1109/MAES.2023.3334686","IEEE Magazines","2023","","IEEE"
"A Multiple Linear Regression Model for Crop Production using Machine Learning and Neural Network","Wireless sensors and artificial intelligence (AI)-based monitoring systems are in great demand and provide precise data extraction and analysis. Finding the best plant development parameters is the main goal of this paper. In this essay, the idea of lowering agricultural risks and fostering intelligent farming is presented. Agriculture has always advanced, however the AI-based sensor devices will set a new standard for smart agriculture. This research objective is to use machine learning methods using image processing to enhance the prediction state. The detection and management of cotton leaf disease detection is the paper's major goal, as stated above. This study includes numerous components, such as soil sensing, remote monitoring based on a server, moisture and temperature sensing, and detection of leaf disease. Plant illnesses that decrease yield if not treated in a timely manner are often brought on by insects and pathogens. In this study, a technique for maintaining soil quality and preventing diseases of cotton leaves is presented. To recognize and categorise leaf diseases, the recommended method employs a regression approach of artificial intelligence. The neural network using linear regression algorithm in the proposed model exhibits the highest level of efficiency in the identification and control of various illnesses by enhancing farmer-friendly farming practises.","10.1109/MysuruCon55714.2022.9972651","IEEE Conferences","2022","","IEEE"
"Energy Storage Management for Microgrids Using n-Step Bootstrapping","Microgrids offer superiorities such as reducing energy costs and increasing the quality of energy, with the use of renewable energy sources and the effective use of energy storage unit created with innovative batteries. Furthermore, this structure, which helps to reduce the carbon footprint, will become undeniably critical to use in near future with the nanogrid and smart grid. As another development, an artificial intelligence (AI)-based control infrastructure brought to us by machine learning stands out as more beneficial than classical control methods. With this framework, which is called reinforcement learning (RL), it is promised that the system to be controlled can be more efficient. At this point, the thrifty use of energy storage unit, which is the most important tool that will increase the profitability of microgrids and enhance the proficiency of energy use, is associated with an RL-based energy control system. While this study focuses on an AI-based control infrastructure, it proposes a method utilizing an RL agent trained with a novel environmental model proposed specifically for the energy storage unit of microgrids. The advantages of this method demonstrated with the results are obtained, are shown and examined.","10.1109/ICJECE.2022.3232213","IEEE Journals","2023","","IEEE"
"Early Concept Evaluation of a Runtime Monitoring Approach for Safe Automated Driving","Being used in key features, such as sensing and intelligent path planning, Artificial Intelligence (AI) has become an inevitable part of automated vehicles (AVs). However, their usage in the automotive industry always comes with a “label” that questions their impact on the overall AV safety. This paper focuses on the safe deployment of AI-based AVs. Among the various ways for ensuring the safety of AI-based AVs is to monitor the safe execution of the system responsible for automated driving (i.e., Automated Driving System (ADS)) at runtime (i.e., runtime monitoring). Most of the research done in the past years focused on verifying whether the path or trajectory generated by the ADS does not immediately collide with objects on the road. However, as we will show in this paper, there are other unsafe situations that do not immediately result in a collision but the monitor should check for them. To build our case, we have looked into the National Highway Traffic Safety Administration (NHTSA) database of 5.9 million police-reported light-vehicle accidents and categorized these accidents into five main categories of unsafe vehicle operations. Furthermore, we have performed a high-level evaluation of the runtime monitoring approach proposed in [1], by estimating what percentage of the total population of 5.9 million of unsafe operations the approach would be able to detect. Lastly, we have performed the same evaluation on other existing runtime monitoring approaches to make a basic comparison of their diagnostic capabilities.","10.1109/ZINC55034.2022.9840649","IEEE Conferences","2022","","IEEE"
"Pros and Cons of Artificial Intelligence—Lessons From E-Government Services in the COVID-19 Pandemic","How to understand the role and impact of information technology and artificial intelligence has triggered a big debate. To explore the pros and cons of artificial intelligence and its applications, this article takes the face mask distribution programs in the COVID-19 pandemic as research objects, conducting a multi-case comparative study of three cities in China. By manual coding of a total of 4560 We Chat official account messages, and by analyzing information related to the distribution process, it was found that: (1) On the demand side, the task complexity, the demand diversity, and the unstructured decision-making process in the public health emergency have exposed some limitations of AI in data collecting and unstructured problem-solving. (2) On the supply side, the procedural and substantive rules designed, together with the reliability of an AI system, will shape the performance of the AI service channel. (3) Though AI and other new technologies are advancing drastically in the pandemic, there is still much room for improvement whether by the optimization of AI systems, or by political control and social participation, and by the supplement of alternative channels such as the community service delivery.","10.1109/ICAIE53562.2021.00042","IEEE Conferences","2021","","IEEE"
"The Deficiency of “Redline/Greenline” Approach to Risk Management in AI Applications","Expanding application of technologies classified as AI draws public attention to associated risks and effective measures for risk mitigation. Policy makers in most countries are currently looking for effective approaches to securing the public interest against AI-related risks and unforeseen consequences of widening AI use. In this connection, there is widespread talk of defining “red” and “green” areas for AI technologies, frequently leading to calls to draw “red lines” and “green lines” for technological innovation. The authors draw on the analysis of AI related risks in a number of international fora and question the efficacy of this “redline/greenline” approach in terms of making the benefits of AI available in the society, while not impeding innovation and technological progress. The authors propose that a more nuanced approach is required, which could involve certification of AI system in sensitive applications, or could apply codified ethical principles to derive specific rules for AI use dependent on the risks created by AI in a particular application.","10.1109/EnT52731.2021.00015","IEEE Conferences","2021","","IEEE"
"Artificial Intelligence in 5G Technology: A Survey","A fully operative and efficient 5G network cannot be complete without the inclusion of artificial intelligence (AI) routines. Existing 4G networks with all-IP (Internet Protocol) broadband connectivity are based on a reactive conception, leading to a poorly efficiency of the spectrum. AI and its subcategories like machine learning and deep learning have been evolving as a discipline, to the point that nowadays this mechanism allows fifth-generation (5G) wireless networks to be predictive and proactive, which is essential in making the 5G vision conceivable. This paper is motivated by the vision of intelligent base stations making decisions by themselves, mobile devices creating dynamically-adaptable clusters based on learned data rather than pre-established and fixed rules, that will take us to a improve in the efficiency, latency, and reliability of the current and real-time network applications in general. An exploration of the potential of AI-based solution approaches in the context of 5G mobile and wireless communications technology is presented, evaluating the different challenges and open issues for future research.","10.1109/ICTC.2018.8539642","IEEE Conferences","2018","","IEEE"
"Securing Data With Blockchain and AI","Data is the input for various artificial intelligence (AI) algorithms to mine valuable features, yet data in Internet is scattered everywhere and controlled by different stakeholders who cannot believe in each other, and usage of the data in complex cyberspace is difficult to authorize or to validate. As a result, it is very difficult to enable data sharing in cyberspace for the real big data, as well as a real powerful AI. In this paper, we propose the SecNet, an architecture that can enable secure data storing, computing, and sharing in the large-scale Internet environment, aiming at a more secure cyberspace with real big data and thus enhanced AI with plenty of data source, by integrating three key components: 1) blockchain-based data sharing with ownership guarantee, which enables trusted data sharing in the large-scale environment to form real big data; 2) AI-based secure computing platform to produce more intelligent security rules, which helps to construct a more trusted cyberspace; 3) trusted value-exchange mechanism for purchasing security service, providing a way for participants to gain economic rewards when giving out their data or service, which promotes the data sharing and thus achieves better performance of AI. Moreover, we discuss the typical use scenario of SecNet as well as its potentially alternative way to deploy, as well as analyze its effectiveness from the aspect of network security and economic revenue.","10.1109/ACCESS.2019.2921555","IEEE Journals","2019","","IEEE"
"AI IN PRODUCTION: VIDEO ANALYSIS AND MACHINE LEARNING FOR EXPANDED LIVE EVENTS COVERAGE","As with many industries, TV and video production is likely to be transformed by artificial intelligence (AI) and machine learning (ML), with software and algorithms assisting production tasks that, conventionally, could only be carried out by people. Expanded coverage of a diverse range of live events is particularly constrained by the relative scarcity of skilled people, and it is a strong use case for AI-based automation. This article describes the recent research conducted by the British Broadcasting Corporation (BBC) on the potential production benefits of AI algorithms, using visual analysis and other techniques. Rigging small, static ultrahigh-definition (UHD) cameras, we have enabled a one-person crew to crop UHD footage in multiple ways and cut between the resulting shots, effectively creating multicamera HD coverage of events that cannot accommodate a camera crew. By working with programmakers to develop simple deterministic rules and, increasingly, training systems using advanced video analysis, we are developing a system of algorithms to automatically frame, sequence, and select shots, and construct acceptable multicamera coverage of previously untelevised types of events.","10.5594/JMI.2020.2967204","SMPTE Journals","2020","","IEEE"
"An Assurance Case for the DoD Ethical Principles of Artificial Intelligence","SUMMARY & CONCLUSIONSThe Ethical Principles of Artificial Intelligence (AI) [1] laid out by the Defense Innovation Board were one of the first publications from the Department of Defense to outline the expectations for AI enabled systems and technologies. This document served as the first guidance for developing agencies and was reviewed to understand the requirements for these new systems. As engineers, the desire is to view the Ethical Principles as evaluation criteria and identify the means by which a system can be qualified against the language laid out by the Defense Innovation Board.One of the first parallels that was identified with this document was the concept of an assurance case. The Ethical Principles do not explicitly lay out any requirements but are more so suggestions or guidelines so the question was how to demonstrate adherence or fulfillment. To this extent the Materiel Release process [2], the process the U.S. Army follows to deploy and field a system, was reviewed as a means to demonstrate fulfillment through the requirements and documentation dictated by that process.This paper demonstrates how the processes and procedures followed by the U.S. Army, in pursuit of mitigating risks for fielding, also in turn fulfill the intent of the Ethical Principles. Upon further review of the principles, it can be observed as design best practices to ensure the development of trusted and assured products. The Materiel Release process is proposed as an assurance case for the adherence to the Ethical Principles of AI. The MR process and associated feeder processes are here compared to the language embodied in the Ethical Principles to the extent that the application of the same rigorous processes done for traditional systems may be applied to AI enabled systems – and in some cases adapted – to ensure justified confidence in the delivered product. Systems that have gone through a Materiel Release review can thus also be said to have demonstrated, as a byproduct, adherence to the Ethical Principles of AI.","10.1109/RAMS51473.2023.10088273","IEEE Conferences","2023","","IEEE"
"Hybrid Al Framework for Remote Patient Heart Failure Risk Prediction","Heart failure is a lethal disease with a high risk of death. Once it is diagnosed, it cannot be cured definitively. Continuous attention needs to be given to such patients in both hospital and home environment. Due to the lack of measurement and risk analysis at home, the chance of early intervention is dramatically reduced. This research aims to offer a hybrid AI-based approach for patients to monitor and assess their daily risk at home. Highly personalized AI models are trained with continuous data stream from wearable devices and demographic information. The personalized risk assessment is based on individual’s benchmark of the daily routine and bio pattern. Also, the rule-based algorithms are developed based on clinical well-established thresholds. This hybrid approach yields 87.5% accuracy. Our approach can provide a cost-efficient method for at-home patients’ heart failure prediction.","10.1109/PHM-Yantai55411.2022.9941764","IEEE Conferences","2022","","IEEE"
"Scalable and Secure Architecture for Distributed IoT Systems","Internet-of-things (IoT) is perpetually revolutionizing our daily life and rapidly transforming physical objects into an ubiquitous connected ecosystem. Due to their massive deployment and moderate security levels, those devices face a lot of security, management, and control challenges. Their classical centralized architecture is still cloaking vulnerabilities and anomalies that can be exploited by hackers for spying, eavesdropping, and taking control of the network. In this paper, we propose to improve the IoT architecture with additional security features using Artificial Intelligence (AI) and blockchain technology. We propose a novel architecture based on permissioned blockchain technology in order to build a scalable and decentralized end-to-end secure IoT system. Furthermore, we enhance the IoT system security with an AI-component at the gateway level to detect and classify suspected activities, malware, and cyber-attacks using machine learning techniques. Simulations and practical implementation show that the proposed architecture delivers high performance against cyber-attacks.","10.1109/TEMSCON47658.2020.9140108","IEEE Conferences","2020","","IEEE"
"Eat This, Not That! – a Personalised Restaurant Menu Decoder That Helps You Pick the Right Food","Picking the right food from a restaurant menu sometimes is not an easy thing for many people: visitors who are not familiar with local restaurants' meal names and their ingredients, people with religious diet constraints, patients with nutrition requirements, and people with special diet preferences. It is not easy for these diners to choose meals from restaurant menus as they do not provide enough information for the diners to make decisions in a brief period. In this paper, we propose an AI-empowered personalized restaurant menu decoder app that can help users make wise choices from any menu in any restaurant. With an easy-to-use interface, the app can quickly rank the restaurant's menu items based on the user’s preferences and concerns. Preliminary test results have demonstrated the good usability of the proposed system.","10.1109/HealthCom54947.2022.9982770","IEEE Conferences","2022","","IEEE"
"Design of Real-Time Multiplayer Word Game for the Android Platform Using Firebase and Fuzzy Logic","In this paper, a real-time, multi-player Android application is proposed, specifically a word game. The suggested application enables users to compete with other players in coming up with words using the same letters under time constraints. In certain scenarios, the system may match users with bots for gameplay. The user is given the impression that he is playing against a real opponent given the bot is adjusted to his skill level through an AI-empowered bot. Prefix tree (Trie) data structure and fuzzy logic have been utilized to develop the abovementioned system, which determines when to play and how many words to generate. The common AES method with a 128-bit key has been implemented for messaging encryption.","10.1109/IISA59645.2023.10345901","IEEE Conferences","2023","","IEEE"
"A Robust Methodology for Building an Artificial Intelligent (AI) Virtual Assistant for Payment Processing","The evolution of business interactions with customers has defined a new paradigm of human-machine interaction through AI enabled conversations. In such scenarios, the machine interacts with the human (also referred to as customers) by applying NLP, NLU and NLG techniques that are used to process, understand and generate. dynamic and rapidly changing course of conversations to keep it meaningful and within context. With the changing landscape, today's NLU and NLP components are supported by the latest deep learning algorithms, making them highly palatable of understanding customers intent, forming a cogent response, or taking an appropriate action than was possible in the recent past. But such sophisticated techniques require good quality of sample examples to learn. In this work, we discuss a step-by-step approach to enhance and enable the NLU behind the AI virtual assistant to robustly interpret customers utterances. As a system for interaction, we developed an AI virtual assistant for a payment process to help customer process the due amount in invoice, which is an integral part of several industries, like Banking, Utilities, Telcos, Retailers, etc. We tested our model by processing sample interactions of which a significant percentage of interactions (approximately 75%) went through finishing the intended task of completing the payment.","10.1109/TEMSCON.2019.8813584","IEEE Conferences","2019","","IEEE"
"Combining Human and Machine Intelligence to Foster Wider Adoption of e-Services","Hybrid Intelligence (HI) combines machine and human intelligence to overcome the shortcomings of existing AI systems, i.e. prevent the mistakes and failures that would be caused by an AI system working alone. This paper describes how the SIMPATICO project has used HI to contribute towards a further democratisation of e-services, i.e. making easier for citizens to complete the web-based services offered by public administrations (PAs). The Open Government solution proposed has been deployed and evaluated in three European pilots. This paper reflects on the results obtained applying the SIMPATICO solution to one of those PAs, i.e. regional government of Galicia in Spain. This reflection should help illustrating the ample potential of applying HI to give place to smarter more accessible humanfacing services.","10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00326","IEEE Conferences","2019","","IEEE"
"Towards Explainable Linguistic Summaries","As more AI solutions are implemented in every aspect of our lives, the need for Explainable Artificial Intelligence (XAI) rises. Explanations can have different forms, such as a number (or an equation), a figure, or a text. This paper investigates textual explanations to effectively communicate the reason for a decision made by an AI system. In previous works, linguistic summaries, as an example of a textual explanation, have already been tested and shown to have explanatory potential. In this paper, we explore this topic further and present a roadmap for linguistic summaries to become a proper XAI tool as Explainable Linguistic Summaries (XLSs). We discuss the challenges that an XLS has to overcome. We outline possible solutions and state their consequences. We consider different protoforms, the definition of the membership function, heuristics for the selection of XLS and personalizing the explanations as well as options to gain more insights into the explanations.","10.1109/FUZZ52849.2023.10309707","IEEE Conferences","2023","","IEEE"
"Neuro Intel: A System for Clinical Diagnosis of Attention Deficit Hyperactivity Disorder (ADHD) Using Artificial Intelligence","Attention-Deficit Hyperactivity Disorder (ADHD) is a mental condition characterised by a pattern of inattention, hyperactivity, and/or impulsivity that causes significant impairment across various domains. Delayed diagnosis and treatment for ADHD can be harmful to people, leading to broader mental health conditions. This paper presents a fully functional system for diagnosing ADHD using an Artificial Intelligence (AI) system called Neuro Intel. Positive results from our research has led to the development of Neuro Intel, which incorporates both expert clinician knowledge and historical clinical data using Machine Learning to assist clinicians in the diagnosis of ADHD in adults.","10.1109/ISCC58397.2023.10218313","IEEE Conferences","2023","","IEEE"
"Software-based bus dispatching system for Epifanio Delos Santos Avenue","In this study a Software-based Artificial Intelligence (AI) System and Neural Network (NN) System were combined to achieve a highly responsive and a self-learning machine capable in predicting the dispatch time and scheduling of buses in Epifanio Delos Santos Avenue (EDSA) which is a congested road in Metro Manila. The AI system is a software-based program that can learn through data gathering and use its pre-defined rules. The NN system used the learned data generated by the AI system to do a quick determination of bus schedule.","10.1109/HNICEM.2015.7393238","IEEE Conferences","2015","","IEEE"
"Survey on Quantum Circuit Compilation for Noisy Intermediate-Scale Quantum Computers: Artificial Intelligence to Heuristics","Computationally expensive applications, including machine learning, chemical simulations, and financial modeling, are promising candidates for noisy intermediate scale quantum (NISQ) computers. In these problems, one important challenge is mapping a quantum circuit onto NISQ hardware while satisfying physical constraints of an underlying quantum architecture. Quantum circuit compilation (QCC) aims to generate feasible mappings such that a quantum circuit can be executed in a given hardware platform with acceptable confidence in outcomes. Physical constraints of a NISQ computer change frequently, requiring QCC process to be repeated often. When a circuit cannot directly be executed on a quantum hardware due to its physical limitations, it is necessary to modify the circuit by adding new quantum gates and auxiliary qubits, increasing its space and time complexity. An inefficient QCC may significantly increase error rate and circuit latency for even the simplest algorithms. In this article, we present artificial intelligence (AI)-based and heuristic-based methods recently reported in the literature that attempt to address these QCC challenges. We group them based on underlying techniques that they implement, such as AI algorithms including genetic algorithms, genetic programming, ant colony optimization and AI planning, and heuristics methods employing greedy algorithms, satisfiability problem solvers, dynamic, and graph optimization techniques. We discuss performance of each QCC technique and evaluate its potential limitations.","10.1109/TQE.2021.3068355","IEEE Journals","2021","","IEEE"
"Pitako - Recommending Game Design Elements in Cicero","Recommender Systems are widely and successfully applied in e-commerce. Could they be used for designƒ In this paper, we introduce Pitako1, a tool that applies the Recommender System concept to assist humans in creative tasks. More specifically, Pitako provides suggestions by taking games designed by humans as inputs, and recommends mechanics and dynamics as outputs. Pitako is implemented as a new system within the mixed-initiative AI-based Game Design Assistant, Cicero. This paper discusses the motivation behind the implementation of Pitako as well as its technical details and presents usage examples. We believe that Pitako can influence the use of recommender systems to help humans in their daily tasks.","10.1109/CIG.2019.8848081","IEEE Conferences","2019","","IEEE"
"More knowledge on the table: Planning with space, time and resources for robots","AI-based solutions for robot planning have so far focused on very high-level abstractions of robot capabilities and of the environment in which they operate. However, to be useful in a robotic context, the model provided to an AI planner should afford both symbolic and metric constructs; its expressiveness should not hinder computational efficiency; and it should include causal, spatial, temporal and resource aspects of the domain. We propose a planner grounded on well-founded constraint-based calculi that adhere to these requirements. A proof of completeness is provided, and the flexibility and portability of the approach is validated through several experiments on real and simulated robot platforms.","10.1109/ICRA.2014.6906923","IEEE Conferences","2014","","IEEE"
"New Artificial Intelligence approaches for future UAV Ground Control Stations","The increasing interest in the use of Unmanned Aerial Vehicles (UAV) in the last years has opened up a new complex area of research applications. Many works have been focused on the applicability of new Artificial Intelligence techniques to facilitate the successfully execution of UAV operations from the Ground Control Stations (GCSs). Some of the most demanded applications in this field are the reduction of the workload of operators and the automation of training processes. This paper presents new algorithms focused on this field: a Multi-Objective Genetic Algorithm for solving Mission Planning and Replanning problems and a Procedure Following Evaluation methodology based on Petri Nets. This paper is based on a framework that simulates a GCS with support for multiple UAVs. The functionality of this framework has been extended in two different directions: on the one hand, to deal with Mission Designing, Automated Mission Planning and Replanning, and Alert Generation; and, on the other hand, to perform different analysis tasks of the UAV operators. Using this framework, a test mission has been executed and debriefed, focusing on the main AI-based issues described in this work.","10.1109/CEC.2017.7969645","IEEE Conferences","2017","","IEEE"
"Gaussian Processes for Personalized Interpretable Volatility Metrics in the Step-Down Ward","Patients in a hospital step-down unit require a level of care that is between that of the intensive care unit (ICU) and that of the general ward. While many patients remain physiologically stabilized, others will suffer clinical emergencies and be readmitted to the ICU, with a subsequent high risk of mortality. Had the associated physiological deterioration been detected early, the emergency may have been less severe or avoided entirely. Current clinical monitoring is largely heuristic, requiring manual calculation of risk scores and the use of heuristic decision criteria. Technical drawbacks include ignoring the time-series dynamics of physiological measurements, and lacking patient-specificity (i.e., personalization of models to the individual patient). In this paper, we demonstrate how Gaussian process regression models can supplement current monitoring practice by providing interpretable and intuitive illustrations of erratic vital-sign volatility. These personalized volatility metrics may provide significantly advanced warning of deterioration, while minimizing the false alarms that induce so-called alarm fatigue. While many AI-based approaches to healthcare are criticized for being uninterpretable “blackbox” methods, the cause of alarms generated from the proposed methods are explicitly interpretable and intuitive. We conclude that intelligent computational inference using methods such as those proposed can enhance current clinical decision making and potentially save lives.","10.1109/JBHI.2019.2890823","IEEE Journals","2019","","IEEE"
"Real-Time Decision Making for a Car Manufacturing Process Using Deep Reinforcement Learning","Computer simulations of manufacturing processes are in widespread use for optimizing production planning and order processing. If unforeseeable events are common, real-time decisions are necessary to maximize the performance of the manufacturing process. Pre-trained AI-based decision support offers promising opportunities for such time-critical production processes. Here, we explore the effectiveness of deep reinforcement learning for real-time decision making in a car manufacturing process. We combine a simulation model of a central production part, the line buffer, with deep reinforcement learning algorithms, in particular with deep Q-Learning and Monte Carlo tree search. We simulate two different versions of the buffer, a single-agent and a multi-agent one, to generate large amounts of data and train neural networks to represent near-optimal strategies. Our results show that deep reinforcement learning performs extremely well and the resulting strategies provide near-optimal decisions in real-time, while alternative approaches are either slow or give strategies of poor quality.","10.1109/WSC48552.2020.9383884","IEEE Conferences","2020","","IEEE"
"Optimization of Soft Mobility Localization with Sustainable Policies and Open Data","A quarter of global greenhouse emissions come from transport, with modern cities producing more than 60% of these emissions. To reduce carbon footprint, several solutions on soft mobility (e.g., optimizing electric vehicles locations) have been proposed using IoT resources and AI techniques. However, these solutions either lack replicability since they ignore city’s needs per area and economic restrictions or lack algorithmic fairness since they account no social criteria (e.g., disabled, age, gender). In this work, we developed AI-based methods to automatically detect the different areas (e.g., rural, urban) and propose two heuristics which incorporate social, environmental and economic criteria of the area in their decision making in the form of sustainability policy templates. Our heuristics solve the p-median problem; they minimize the distance of stations to important points constrained by the cost of new stations. We show that our proposed solution is able to disperse the new stations within the city while covering local neighbourhoods. This work is replicated in two big European cities adapted to different open data and demonstrated by a dedicated visual dashboard.","10.1109/IE54923.2022.9826779","IEEE Conferences","2022","","IEEE"
"Policy enabled caching for distributed AI","Web Caching has established itself as a key enabling technology within the Internet. It enables efficient browsing of websites and web-based services on networks that are bandwidth constrained. However, similar techniques are not available for AI based solutions. Many AI solutions are based on deep neural networks or similar approaches which require creation of machine learning models trained with huge amounts of data. Such models are best created in centralized locations with significant processing power. In many environments, sending the data to a centralized location is infeasible or undesirable. A judicious combination of ideas borrowed from web-caching paradigm, with ideas from AI and machine learning can provide an effective solution for exploitation of deep learning models in bandwidth constrained environments. Allowing such caches to generate their own policies using a generative policy approach can enable the creation of a generic edge caching system which can be used with a wide variety of backend AI systems.","10.1109/BigData.2017.8258273","IEEE Conferences","2017","","IEEE"
"Multi-Controller Architecture for Reliable Autonomous Vehicle Navigation: Combination of Model-Driven and Data-Driven Formalization","In this paper, a design of a multi-controller architecture (MCA) is presented. It effectively links model-based approaches and Artificial Intelligence (AI) developments for intelligent vehicles navigation in a highway. In this MCA, the model-based approach appears in the path planning (based on analytical target set-points definition) and the control law (based on a Lyapunov stability analysis). The AI-based approach appears in the proposed Two-Sequential Level Bayesian Decision Network (TSLBDN) for handling lane change maneuvers in uncertain environment and changing dynamic/behaviors of the surrounding vehicles. In addition, a combination of both trajectory prediction (based on dynamic target set-points and elliptic limit-cycles) and maneuver recognition based on Dynamic Bayesian Network (DBN) is proposed to infers surrounding vehicles actions. Several simulation results show the efficiency of the model-driven/data driven overall proposed control architecture.","10.1109/IVS.2019.8813830","IEEE Conferences","2019","","IEEE"
"Trust-aware Control for Intelligent Transportation Systems","Many intelligent transportation systems are multiagent systems, i.e., both the traffic participants and the subsystems within the transportation infrastructure can be modeled as interacting agents. The use of AI-based methods to achieve coordination among the different agents systems can provide greater safety over transportation systems containing only human-operated vehicles, and also improve the system efficiency in terms of traffic throughput, sensing range, and enabling collaborative tasks. However, increased autonomy makes the transportation infrastructure vulnerable to compromised vehicular agents or infrastructure. This paper proposes a new framework by embedding the trust authority into transportation infrastructure to systematically quantify the trustworthiness of agents using an epistemic logic known as subjective logic. In this paper, we make the following novel contributions: (i) We propose a framework for using the quantified trustworthiness of agents to enable trust-aware coordination and control. (ii) We demonstrate how to synthesize trust-aware controllers using an approach based on reinforcement learning. (iii) We comprehensively analyze an autonomous intersection management (AIM) case study and develop a trust-aware version called AIM-Trust that leads to lower accident rates in scenarios consisting of a mixture of trusted and untrusted agents.","10.1109/IV48863.2021.9576045","IEEE Conferences","2021","","IEEE"
"Considerations for Using Artificial Intelligence to Manage Authorized Push Payment (APP) Scams","Artificial Intelligence (AI)-based security intelligence modeling can be used to prevent, detect, and manage cyber threats. Data-driven AI solutions are currently undergoing rigorous research and design changes in their own field, but few scholars or practitioners frame authorized push payment (APP) scams as a unique cybersecurity concern, or tailor technical solutions based on local regulatory contexts. Drawing on a recent consultation publication by the UK Payment Systems Regulator on APP scams (November 2021), this article shows how AI can be leveraged to manage APP scams and explores some of the opportunities and risks one should consider when adopting such an approach. We highlight three scenarios: 1) Liability on payment service provider; 2) Liability on payor; and 3) Liability on payor with substantial public sector involvement. These examples illustrate how sociotechnical systems can play a design role, and consequently assist industry leaders and engineering management in prioritizing investment focus, strategic approaches, and technical solutions.","10.1109/EMR.2023.3288432","IEEE Journals","2023","","IEEE"
"Social lane-based cognitive model for simulating pedestrian flow in games","In computer game software, the implementation of simulated urban crowds is widespread. Representation of pedestrians in computer games has, to date, lagged behind what has been shown possible in academic studies and simulation software. Primary reasons for this are the strict CPU budgets that game AI has to function under, and algorithm implementation which is frequently complex for even a baseline approach (i.e. before performance optimisations). This paper presents a novel lane-based approach to pedestrian AI which combines the verisimilitude of AI based on behavioural studies, with the intuitive implementation and minimal computation cost required for games development. To achieve this, each agent filters its surroundings into virtual lanes, and then sidesteps or continues forward as dictated by social convention.","10.1109/CEC.2013.6557655","IEEE Conferences","2013","","IEEE"
"A Marketplace Solution for Distributed Network Management and Orchestration of Slices","The H2020 Distributed management of Network Slices in beyond 5G(MonB5G) project aims to provide zero-touch management and orchestration to support network slicing at scale to reduce the management burden on mobile operators by leveraging distribution of operations along with advanced data-driven Artificial Intelligence (AI)-based mechanisms. However, while this approach shows promise and large companies with abundant data and ML expertise are developing powerful MLdriven services, a critical aspect that remains to be analyzed is its business case. The vast majority of potentially valuable ML services, such as predictive maintenance, Quality of Service (QoS) optimization, network security enhancements, remain stuck at the idea or prototype stage. This paper delves into an analysis of how the MonB5G solutions in particular the tuples (Monitoring System (MS), Analytics Engine (AE), Decision Engine (DE) and Actuator (ACT) could be applied within the network management and orchestration market while investigating various business models and value chains. Numerical results based on experimental data have also been performed to evaluate the OpEX (Operational Expenditure) benefits associated with different network management techniques, for centralized and distributed systems.","10.23919/CNSM59352.2023.10327832","IEEE Conferences","2023","","IEEE"
"Data-driven Transient Stability Assessment Using Sparse PMU Sampling and Online Self-check Function","Artificial intelligence technologies provide a new approach for the real-time transient stability assessment (TSA) of large-scale power systems. In this paper, we propose a data-driven transient stability assessment model (DTSA) that combines different AI algorithms. A pre-AI based on the time-delay neural network is designed to locate the dominant buses for installing the phase measurement units (PMUs) and reducing the data dimension. A post-AI is designed based on the bidirectional long-short-term memory network to generate an accurate TSA with sparse PUM sampling. An online self-check function of the online TSA's validity when the power system changes is further added by comparing the results of the pre-AI and the post-AI. The IEEE 39-bus system and the 300-bus AC/DC hybrid system established by referring to China's existing power system are adopted to verify the proposed method. Results indicate that the proposed method can effectively reduce the computation costs with ensured TSA accuracy as well as provide feedback for its applicability. The DTSA provides new insights for properly integrating varied AI algorithms to solve practical problems in modern power systems.","10.17775/CSEEJPES.2021.05890","CSEE Journals","2023","","IEEE"
"Implication and Advantages of Machine Learning-based Chatbots in Diverse Disciplines","Artificial Intelligence (AI) and Machine Learning (ML) are the techniques, which helps in enacting system with the human beings. Now a days chatbots are playing a vital role in changing the mode of conversation between humans and computer systems. The implementation of these chatbots helps to improve the conversation between computers and humans. Chatbots are the software programmed virtual machines which are intended to make ready for building conversation with the humans and to deploy this system the Artificial Intelligence (AI) techniques are used in all the message plans, these virtual machines are not only bounded for only one area but can be used in many of the areas like education sector, medical, social media, banking and finance etc. Chatbots are essential in educational institutes for handling administrative activities. Chatbots acts as a platform for solving queries of individual with ease. Natural Language input and the deep neural networks are the major tools, which are used in the development of these chatbots. These tools use a LSTM mechanism to understand the related user query. By using these techniques, the chatbots are trained and that helps in giving instantaneous answers for the user queries. All the data from the user will be collected and stored in the specified database and that data will be used for further references. This study depicts the importance of chatbots in various fields with their working principle using Machine Learning(ML) and Artificial Intelligence (AI)-based algorithms.","10.1109/ICSCDS56580.2023.10104649","IEEE Conferences","2023","","IEEE"
"Platform and Model Design for Responsible AI: Design and build resilient, private, fair, and transparent machine learning models","Craft ethical AI projects with privacy, fairness, and risk assessment features for scalable and distributed systems while maintaining explainability and sustainability Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesLearn risk assessment for machine learning frameworks in a global landscapeDiscover patterns for next-generation AI ecosystems for successful product designMake explainable predictions for privacy and fairness-enabled ML trainingBook DescriptionAI algorithms are ubiquitous and used for tasks, from recruiting to deciding who will get a loan. With such widespread use of AI in the decision-making process, it’s necessary to build an explainable, responsible, transparent, and trustworthy AI-enabled system. With Platform and Model Design for Responsible AI, you’ll be able to make existing black box models transparent. You’ll be able to identify and eliminate bias in your models, deal with uncertainty arising from both data and model limitations, and provide a responsible AI solution. You’ll start by designing ethical models for traditional and deep learning ML models, as well as deploying them in a sustainable production setup. After that, you’ll learn how to set up data pipelines, validate datasets, and set up component microservices in a secure and private way in any cloud-agnostic framework. You’ll then build a fair and private ML model with proper constraints, tune the hyperparameters, and evaluate the model metrics. By the end of this book, you’ll know the best practices to comply with data privacy and ethics laws, in addition to the techniques needed for data anonymization. You’ll be able to develop models with explainability, store them in feature stores, and handle uncertainty in model predictions.What you will learnUnderstand the threats and risks involved in ML modelsDiscover varying levels of risk mitigation strategies and risk tiering toolsApply traditional and deep learning optimization techniques efficientlyBuild auditable and interpretable ML models and feature storesUnderstand the concept of uncertainty and explore model explainability toolsDevelop models for different clouds including AWS, Azure, and GCPExplore ML orchestration tools such as Kubeflow and Vertex AIIncorporate privacy and fairness in ML models from design to deploymentWho this book is forThis book is for experienced machine learning professionals looking to understand the risks and leakages of ML models and frameworks, and learn to develop and use reusable components to reduce effort and cost in setting up and maintaining the AI ecosystem.","","Packt Publishing eBooks","2023","","IEEE"
"Production Flow Analysis in the Era of Industry 4.0 : How Digital Technologies can Support Decision-Making in the Factory of the Future","In the context of Industry 4.0, manufacturing companies have been increasingly adopting digital technologies such as Internet of Things, data analytics and cyber-physical systems to seize opportunities for productivity improvements. At the same time, established manufacturing philosophies such as Group Technology have assisted companies in managing the complexity of production processes for decades. To support manufacturing management with more informed decision-making tools, the literature has been proposing new approaches that exploit the potential of digital technologies to enhance the effectiveness of traditional manufacturing techniques. This study focuses on Production Flow Analysis (PFA) as an established approach for Group Technology. Although the existing literature has been focusing on Artificial Intelligence (AI) based approaches to plan the change to Group Technology for decades, few studies rely on production data directly extracted from the factory floor. This is partly due to the fact that technologies such as sensors and data analytics have been increasingly adopted in recent years, and this has led to an increasing amount of data that can be exploited to develop models that can support decisions. In particular, in the context of Industry 4.0, process mining has gained increasing interest, as it provides a data-driven methodology to capture real production processes. The goal of this study is to explore how PFA has evolved in the last decade thanks to the adoption of digital technologies, and to investigate potential synergies between PFA and process mining. This study uses a structured literature review to map advances in industrial applications of PFA in relation to digital technologies, as well as process mining applications in manufacturing to present a future research agenda. This provides manufacturing managers with a structured overview of existing industrial applications and the digital technologies adopted to enhance decision-making tools.","10.23919/PICMET53225.2022.9882711","IEEE Conferences","2022","","IEEE"
"Deep Recurrent Learning versus Q-Learning for Energy Management Systems in Next Generation Network","An AI based energy management system (EMS) for microgrids is proposed. It is composed of three modules: a strategy based module, a deep learning (DL) and a reinforcement learning module (RL). This framework determines heuristically the optimal actions for the microgrid system under different time-dependent environmental conditions. In essence, a main innovation is applied to the EMS. Our deep learning algorithm uses recurrent neural networks (RNNs) instead of the habitual State Action Reward (SAR) approach (whether classical or deep). Learning is hence guided by successful actions rather than by blind exploration. A large improvement in learning rates is hence observed when compared to classical Q-learning on real datasets that present a large diversity in energy consumption profiles, acquired in French premises over a long period. It leads to question about the best appropriate reinforcement policies to adopt when solving large state environments.","10.1109/GLOBECOM46510.2021.9685620","IEEE Conferences","2021","","IEEE"
"Advancing Cybersecurity with Explainable Artificial Intelligence: A Review of the Latest Research","The use of artificial intelligence (AI) in cybersecurity has become increasingly common, but a key challenge is the lack of transparency and interpretability of AI models. Explainable Artificial Intelligence (XAI) can address this issue by providing a means of enhancing the transparency and interpretability of AI models, enabling cybersecurity professionals to better understand the decisions made by these models and to identify errors or biases. This review article provides a comprehensive overview of the latest research on the application of Explainable Artificial Intelligence (XAI) in the context of cybersecurity, with a focus on its benefits and challenges. Specifically, it analyses the most recent techniques and tools for implementing XAI in cybersecurity, while also highlighting several successful use cases. Furthermore, it delves into the ethical and regulatory considerations associated with XAI in cybersecurity and provides recommendations for future research in this area. The ultimate objective of this review article is to furnish cybersecurity professionals with a detailed understanding of the potential of XAI to enhance the efficacy of AI-based tools in cybersecurity, underscoring the significance of transparency and interpretability in assuring the security and dependability of AI systems.","10.1109/ICIRCA57980.2023.10220797","IEEE Conferences","2023","","IEEE"
"Agent Architecture for Adaptive Behaviors in Autonomous Driving","Evolution has endowed animals with outstanding adaptive behaviours which are grounded in the organization of their sensorimotor system. This paper uses inspiration from these principles of organization in the design of an artificial agent for autonomous driving. After distilling the relevant principles from biology, their functional role in the implementation of an artificial system are explained. The resulting Agent, developed in an EU H2020 Research and Innovation Action, is used to concretely demonstrate the emergence of adaptive behaviour with a significant level of autonomy. Guidelines to adapt the same principled organization of the sensorimotor system to other agents for driving are also obtained. The demonstration of the system abilities is given with example scenarios and open access simulation tools. Prospective developments concerning learning via mental imagery are finally discussed.","10.1109/ACCESS.2020.3007018","IEEE Journals","2020","","IEEE"
"Defining Quality Requirements for a Trustworthy AI Wildflower Monitoring Platform","For an AI solution to evolve from a trained machine learning model into a production-ready AI system, many more things need to be considered than just the performance of the machine learning model. A production-ready AI system needs to be trustworthy, i.e. of high quality. But how to determine this in practiceƒ For traditional software, ISO25000 and its predecessors have since long time been used to define and measure quality characteristics. Recently, quality models for AI systems, based on ISO25000, have been introduced. This paper applies one such quality model to a real-life case study: a deep learning platform for monitoring wildflowers. The paper presents three realistic scenarios sketching what it means to respectively use, extend and incrementally improve the deep learning platform for wildflower identification and counting. Next, it is shown how the quality model can be used as a structured dictionary to define quality requirements for data, model and software. Future work remains to extend the quality model with metrics, tools and best practices to aid AI engineering practitioners in implementing trustworthy AI systems.","10.1109/CAIN58948.2023.00029","IEEE Conferences","2023","","IEEE"
"A Customisable AI Deck for Pitch Reports and Automated III Umpire Decision Review System DRS","Nowadays giving fair verdict is a quite challenging task because of certain contentious aspects in modern cricket. So, in order to avoid making wrong decisions, we develop an automated AI-based solution. This project focus on a technology that helps both the main umpire and third umpire to makes critical determination for Leg Before the Wicket (LBW) regarding whether the batsman is out or not-out and also minimizes the waiting time for players until the third umpire go through the trajectory of the ball to make a correct decision. The main purpose of our AI-DRS is to remove the umpires call which plays a vital role in giving third umpires decision because whether any one of the cases shows umpires call the decision will be stick with on-field umpires call whether it may be out or not-out. The pitch report and comprehensive cricket laws are also included for the sake of the game. The pitch report will be examined with several key wicket characteristics, such as kind of soil, cracks, amount of grass cover, and wetness, etc. using drone we capture the video of the match day pitch. To determine the field crack, canny edge detection is performed and soil moisture sensor is used to determine the moisture content of the soil. This information help cricket team to make a decision about whether to bat or field after winning the toss and helps to choose the strongest 11 players through which can win the match on that pitch on that day. Utilizing support vector machine (SVM) and histograms of gradients (HOG), objects are classified and recognized. In order to monitor and forecast the velocity of the ball, linear regression and quadratic regression are applied. Finally, Tkinter is used for GUI development, imutils and OpenCV are used as implementation tools. Due to the controversy of rare wicket calls, boundary and penalty runs, we bring a voice recognized AI system which gave fans to easily understand why this decision is made by the umpire and sometime umpires found difficulty to remember some rules which is rarely used in cricket it will also give assist to on-field umpires to give a very clear idea why he made the decision, the on-field umpires can easily access the laws through voice recognition which use Alan-AI. The Voice recognition web app was developed using react-js.","10.1109/ICECAA58104.2023.10212245","IEEE Conferences","2023","","IEEE"
"Adapting a Trusted AI Framework to Space Mission Autonomy","As artificial intelligence (AI) is increasingly proposed for new and future capabilities in space missions, the question of how to trust AI-enabled space autonomy has been explored. Recently, a collaboration between The Aerospace Corporation (Aerospace) and NASA's Jet Propulsion Laboratory (JPL) investigated how Aerospace's Trusted AI Framework could be applied to two JPL projects that planned on leveraging AI for critical autonomous tasks. This combined effort led to many insights into the practical implementation of trust-ed AI along with considerable updates to the Trusted AI Framework that tailored its topic threads to space exploration. This document summarizes the enhanced framework as tailored to space missions as well as estimation of the level of trust required as a function of mission criticality and key stakeholders. The goal of this work is to provide a set of best practices to guide autonomy researchers, flight engineers, mission and proposal reviewers, and instrument and mission principal investigators (PIs) towards AI-based autonomy that maximizes trust and lowers the barriers to mission adoption for both science and engineering applications.","10.1109/AERO53065.2022.9843376","IEEE Conferences","2022","","IEEE"
"AI for CSI Feedback Enhancement in 5G-Advanced","The 3rd Generation Partnership Project started the study of Release 18 in 2021. Artificial intelligence (AI)-native air interface is one of the key features of Release 18, where AI for channel state information (CSI) feedback enhancement is selected as the representative use case. This article provides an overview of AI for CSI feedback enhancement in 5G-Advanced. Several representative non-AI and AI-enabled CSI feedback frameworks are first introduced and compared. Then, the standardization of AI for CSI feedback enhancement in 5G-advanced is presented in detail. First, the scope of the AI for CSI feedback enhancement in 5G-Advanced is presented and discussed. Then, the main challenges and open problems in the standardization of AI for CSI feedback enhancement, especially focusing on performance evaluation and the design of new protocols for AI-enabled CSI feedback, are identified and discussed. This article provides a guideline for the standardization study of AI-based CSI feedback enhancement.","10.1109/MWC.010.2200304","IEEE Early Access Articles","2022","","IEEE"
"Application of Artificial Intelligence in Project Planning to Solve Late and Over-Budgeted Construction Projects","Advance use of Artificial Intelligence (AI), has reduced the need of human intervention within several tasks that are repetitive and rule-based. AI can have a great impact on the workforce of a project within the construction industry. Use of Machine learning techniques within the project process can be beneficial for a project manager to manage financial aspects and time scheduling both. The major problem that construction project managers face is ineffective tracking process, cost management process. This is the main reason, the AI-based solution are needed within construction sites. The aim of this research is to identify the role of AI in time management as well as cost management of a construction project in India. Intelligence robotics is a major AI-based tool that is used within construction project for marinating cost. Some challenges are also found within construction project that might have a huge effect within its implementation process such as cultural barriers, high-cost of maintenance and unavailability of similar input parameters in all projects. As per the findings, ANN, SVM, Regression and many other AI-based are effective Ai-based machine learning tools that are used within construction project to replace various time consuming process by modern technologies. Construction delays are the major effective factor for cost overrun and time overrun within a project. As per this research article, it has been found that, use of AI, especially ANN model can reduce the tendency of delay in construction projects and mismanagement of costs.","10.1109/ICSCDS53736.2022.9761027","IEEE Conferences","2022","","IEEE"
"Ethics Aspects of Embedded and Cyber-Physical Systems","The growing complexity of software employed in the cyber-physical domain is calling for a thorough study of both its functional and extra-functional properties. Ethical aspects are among important extra-functional properties, that cover the whole life cycle with different stages from design, development, deployment/production to use of cyber physical systems. One of the ethical challenges involved is the question of identifying the responsibilities of each stakeholder associated with the development and use of a cyber-physical system. This challenge is made even more pressing by the introduction of autonomous increasingly intelligent systems that can perform functionalities without human intervention, because of the lack of experience, best practices and policies for such technology. In this article, we provide a framework for responsibility attribution based on the amount of autonomy and automation involved in AI based cyber-physical systems. Our approach enables traceability of anomalous behaviors back to the responsible agents, be they human or software, allowing us to identify and separate the ""responsibility"" of the decision-making software from human responsibility. This provides us with a framework to accommodate the ethical ""responsibility"" of the software for AI based cyber-physical systems that will be deployed in the future, underscoring the role of ethics as an important extra-functional property. Finally, this systematic approach makes apparent the need for rigorous communication protocols between different actors associated with the development and operation of cyber-physical systems that further identifies the ethical challenges involved in the form of group responsibilities.","10.1109/COMPSAC.2015.41","IEEE Conferences","2015","","IEEE"
"Development Of Methodology for Precise Diagnosis of Ecg By Artificial Intelligent","Implementation of Artificial Intelligence in medical diagnosis is a subject of intense study in nowadays. One of the current interests of developing an Artificial Intelligent is to develop an AI system for diagnosis of heart disease from Electrocardiogram (ECG). Few AI programs have also been developed for ECG diagnosis system, but most of them are based on pattern comparison algorithm which can never achieve the sufficient precision and accuracy for diagnosis task. To eliminate these deficiencies, this paper proposes a new methodology that makes AI system more capable for ECG diagnosis. The proposed methodology and design for AI diagnosis system is based on the statistical analysis of ECG and implementation of standard ECG Interpretation Principles for diagnosis of cardiac arrhythmias. This method is completely knowledge based and it applies the same methods and rules of cardiology which are implemented by a medical expert (cardiologist) to make a report of patient's ECG. The proposed methodology also provides an ability of self learning to AI system in order to utilize the experiences in further diagnosis service.","10.1109/ICECCT.2019.8869413","IEEE Conferences","2019","","IEEE"
"Efficient Automated Processing of the Unstructured Documents Using Artificial Intelligence: A Systematic Literature Review and Future Directions","The unstructured data impacts 95% of the organizations and costs them millions of dollars annually. If managed well, it can significantly improve business productivity. The traditional information extraction techniques are limited in their functionality, but AI-based techniques can provide a better solution. A thorough investigation of AI-based techniques for automatic information extraction from unstructured documents is missing in the literature. The purpose of this Systematic Literature Review (SLR) is to recognize, and analyze research on the techniques used for automatic information extraction from unstructured documents and to provide directions for future research. The SLR guidelines proposed by Kitchenham and Charters were adhered to conduct a literature search on various databases between 2010 and 2020. We found that: 1. The existing information extraction techniques are template-based or rule-based, 2. The existing methods lack the capability to tackle complex document layouts in real-time situations such as invoices and purchase orders, 3. The datasets available publicly are task-specific and of low quality. Hence, there is a need to develop a new dataset that reflects real-world problems. Our SLR discovered that AI-based approaches have a strong potential to extract useful information from unstructured documents automatically. However, they face certain challenges in processing multiple layouts of the unstructured documents. Our SLR brings out conceptualization of a framework for construction of high-quality unstructured documents dataset with strong data validation techniques for automated information extraction. Our SLR also reveals a need for a close association between the businesses and researchers to handle various challenges of the unstructured data analysis.","10.1109/ACCESS.2021.3072900","IEEE Journals","2021","","IEEE"
"Firewall Design and Implementation","The chapter introduces firewalls and their design as the first line of defense mechanism. This chapter's goal is twofold: (i) to cover major aspects of the firewall design and operation for security professional education and (ii) explain how artificial intelligence and machine learning techniques and technologies are employed for enhancing firewalls and the security they provide. For the first goal, it provides the firewall definition, discusses the functions, possible architectures, and operational models concentrating on the presentation of their advantages and drawbacks. It includes the step‐by‐step guide to the firewall design and implementation process ranging from planning to deployment and maintenance. For the second goal, the chapter moves the reader from basic rules design to sophisticated AI and ML employment algorithms that improve it. The major emphasis is placed on using rules to set up, configure, and modify the firewall's policy. Both generic and specific rules are discussed as well as their formulation and editing with firewall tools. Substantial rules design principles and conflict avoidance and resolution are presented. The modern AI‐based developments are presented at the end.","10.1002/9781119771579.ch2","Wiley-IEEE Press eBook Chapters","2022","","IEEE"
"Artificial Intelligence In Interferometric Synthetic Aperture Radar Phase Unwrapping: A Review","Interferometric synthetic aperture radar (InSAR) is a radar technique widely used in geodesy and remote sensing applications, e.g., topography reconstruction and subsidence estimation. Phase unwrapping (PU) is one of the key procedures of InSAR signal processing. Artificial intelligence (AI) techniques have proven to be potentially powerful in many fields and have been introduced into the PU domain, achieving superior performance. In this article, we provide a comprehensive overview of AI-based PU techniques in InSAR. We survey the AI-based single-baseline (SB) PU methods and then review the AI techniques related to multibaseline (MB) PU. In addition, we show several experimental examples of these methods, from both simulated and real InSAR data sets, which gives readers an overview of AI-based PU processing's potential and limitations. It is our hope that this article will provide researchers with guidelines and inspiration to further enhance the development of AI-based PU.","10.1109/MGRS.2021.3065811","IEEE Magazines","2021","","IEEE"
"Assessing Trustworthy AI in Times of COVID-19: Deep Learning for Predicting a Multiregional Score Conveying the Degree of Lung Compromise in COVID-19 Patients","This article’s main contributions are twofold: 1) to demonstrate how to apply the general European Union’s High-Level Expert Group’s (EU HLEG) guidelines for trustworthy AI in practice for the domain of healthcare and 2) to investigate the research question of what does “trustworthy AI” mean at the time of the COVID-19 pandemic. To this end, we present the results of a post-hoc self-assessment to evaluate the trustworthiness of an AI system for predicting a multiregional score conveying the degree of lung compromise in COVID-19 patients, developed and verified by an interdisciplinary team with members from academia, public hospitals, and industry in time of pandemic. The AI system aims to help radiologists to estimate and communicate the severity of damage in a patient’s lung from Chest X-rays. It has been experimentally deployed in the radiology department of the ASST Spedali Civili clinic in Brescia, Italy, since December 2020 during pandemic time. The methodology we have applied for our post-hoc assessment, called Z-Inspection®, uses sociotechnical scenarios to identify ethical, technical, and domain-specific issues in the use of the AI system in the context of the pandemic.","10.1109/TTS.2022.3195114","IEEE Journals","2022","","IEEE"
"A New Markov Decision Process Based Behavioral Prediction System for Airborne Crews","In order to ensure the normal and stable flights in the aircraft, a variety of sensors and corresponding instrumentation systems have been applied on the aircraft to monitor/control the current flight status, and the resulted data ensure the flight safety with a heavy burden on the pilot. In views of this, nowadays, the aircraft cockpit automation assistance system has become a hot topic. This paper is based on the pilot's future operational behavior which can be predicted through different stages of flight operations after the automated assistance system is triggered, thus providing the pilot with assistance in accordance with his operating habits. We have established a MDP (Markov Decision Process) model via analyzing and modeling of pilot operational behavior and mission requirements for flight processes, and we also use value iterative algorithm to find the optimal prediction sequence, lastly, we verify the operability of the algorithm by flight operation simulation experiment. It provides a new solution for the safety of pilot operations and the intrusiveness of the cockpit adaptive automation assistance system.","10.1109/ACCESS.2019.2961239","IEEE Journals","2020","","IEEE"
"Keynote: Algorithmic Targeting of Social Policies: Fairness, Accuracy, and Distributed Governance","Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and wide-spread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them - and who is not - are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.","10.1109/ICEDEG48599.2020.9096679","IEEE Conferences","2020","","IEEE"
"Traffic Analytics Development Kits (TADK): Enable Real-Time AI Inference in Networking Apps","Sophisticated traffic analytics, such as the encrypted traffic analytics and unknown malware detection, emphasizes the need for advanced methods to analyze the network traffic. Traditional methods of using fixed patterns, signature matching, and rules to detect known patterns in network traffic are being replaced with AI (Artificial Intelligence) driven algorithms. However, the absence of a high-performance AI networking-specific framework makes deploying real-time AI-based processing within networking workloads impossible. In this paper, we describe the design of Traffic Analytics Development Kits (TADK), an industry-standard framework specific for AI-based networking workloads processing. TADK can provide real-time AI-based networking workload processing in networking equipment from the data center out to the edge without the need for specialized hardware (e.g., GPUs, Neural Processing Unit, and so on). We have deployed TADK in commodity WAF and 5G UPF, and the evaluation result shows that TADK can achieve a throughput up to 35.3Gbps per core on traffic feature extraction, 6.5Gbps per core on traffic classification, and can decrease SQLi/XSS detection down to 4.5µs per request with higher accuracy than fixed pattern solution.","10.1109/ICUFN55119.2022.9829628","IEEE Conferences","2022","","IEEE"
"Optimization of Dominance Testing in Skyline Queries Using Decision Trees","Skyline queries identify skyline points, the minimal set of data points that dominate all other data points in a large dataset. The main challenge with skyline queries is executing the skyline query in the shortest possible time. To address and solve skyline query performance issues, we propose a decision tree-based method known as the decision tree-based comparator (DC). This method minimizes unnecessary dominance tests (i.e., pairwise comparisons) by constructing a decision tree based on the dominance testing. DC uses dominance relations that can be obtained from the decision rules of the decision tree to determine incomparability between data points. DC can also be easily applied to improve the performance of various existing skyline query methods. After describing the theoretical background of DC and applying it to existing skyline queries, we present the results of various experiments showing that DC can improve skyline query performance by up to 23.15 times.","10.1109/ACCESS.2021.3113697","IEEE Journals","2021","","IEEE"
"Security considerations for the procurement and acquisition of Artificial Intelligence (AI) systems","Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.","10.1109/FUZZ-IEEE55066.2022.9882675","IEEE Conferences","2022","","IEEE"
"Advancing Industrial Analytics Using Machine Learning (ML) and Mathematical Optimization","Machine Learning (ML) models offer a convenient framework to gather insights and deploy sustainable Artificial Intelligence (AI) enabled solutions to empower industrial analytics. Moreover, ML models have wide adoption across researchers from multiple disciplines. However, direct application of ML models may be restrictive in enforcing certain physics or operations-based rules. Augmenting ML models with model-based optimization tools, which can include constraints and rules through mathematical programming, can significantly improve the prescriptive nature and adaptability of such ML models .","10.23919/ACC53348.2022.9867615","IEEE Conferences","2022","","IEEE"
"Exploring customer behavior and enhanced revenue generation in e-commerce using interpretable and explainable artificial intelligence","We live in a world whose rules and procedures are governed by rich data and algorithms. For example, there are certain rules as who to qualify for credit and whose social media posts or account get censored. Black-Box algorithms make forecasting based on large volume of training data and these model often demonstrate higher accuracy compared to other ML/DL Model and bring low degree of confidence to the end user of AI System. Oftentimes, these Black-Box models are not capable of providing a justification or proper reasoning to the predicted output by the Model. For high stake decision for of e-commerce industry such as purchasing intention of end user, top management wants to know exactly why Black-Box system chose to show no purchasing intention for a particular customer based on training data. Unfortunately, it is difficult for e-commerce owner to fully understand black-box output based on skewed training data, input errors and unintended biases captured while building black-box system, even the developers of this black-box system does not have ideas of internal functionality of black-box model. Due to GDPR data regulation, there is a growing concern in the field of explainable artificial intelligence to explain the classification rules and procedures behind the final feature recommendations and final prediction.","10.1049/icp.2023.1511","IET Conferences","2023","","IEEE"
"Experimental Analysis of Trustworthy In-Vehicle Intrusion Detection System Using eXplainable Artificial Intelligence (XAI)","Anomaly-based In-Vehicle Intrusion Detection System (IV-IDS) is one of the protection mechanisms to detect cyber attacks on automotive vehicles. Using artificial intelligence (AI) for anomaly detection to thwart cyber attacks is promising but suffers from generating false alarms and making decisions that are hard to interpret. Consequently, this issue leads to uncertainty and distrust towards such IDS design unless it can explain its behavior, e.g., by using eXplainable AI (XAI). In this paper, we consider the XAI-powered design of such an IV-IDS using CAN bus data from a public dataset, named “Survival”. Novel features are engineered, and a Deep Neural Network (DNN) is trained over the dataset. A visualization-based explanation, “VisExp”, is created to explain the behavior of the AI-based IV-IDS, which is evaluated by experts in a survey, in relation to a rule-based explanation. Our results show that experts’ trust in the AI-based IV-IDS is significantly increased when they are provided with VisExp (more so than the rule-based explanation). These findings confirm the effect, and by extension the need, of explainability in automated systems, and VisExp, being a source of increased explainability, shows promise in helping involved parties gain trust in such systems.","10.1109/ACCESS.2022.3208573","IEEE Journals","2022","","IEEE"
"Artificial Intelligence-Based Techniques for Emerging Heterogeneous Network: State of the Arts, Opportunities, and Challenges","Recently, mobile networking systems have been designed with more complexity of infrastructure and higher diversity of associated devices and resources, as well as more dynamical formations of networks, due to the fast development of current Internet and mobile communication industry. In such emerging mobile heterogeneous networks (HetNets), there are a large number of technical challenges focusing on the efficient organization, management, maintenance, and optimization, over the complicated system resources. In particular, HetNets have attracted great interest from academia and industry in deploying more effective solutions based on artificial intelligence (AI) techniques, e.g., machine learning, bio-inspired algorithms, fuzzy neural network, and so on, because AI techniques can naturally handle the problems of large-scale complex systems, such as HetNets towards more intelligent and automatic-evolving ones. In this paper, we discuss the state-of-the-art AI-based techniques for evolving the smarter HetNets infrastructure and systems, focusing on the research issues of self-configuration, self-healing, and self-optimization, respectively. A detailed taxonomy of the related AI-based techniques of HetNets is also shown by discussing the pros and cons for various AI-based techniques for different problems in HetNets. Opening research issues and pending challenges are concluded as well, which can provide guidelines for future research work.","10.1109/ACCESS.2015.2467174","IEEE Journals","2015","","IEEE"
"Application of Artificial Intelligence in Predicting Earthquakes: State-of-the-Art and Future Challenges","Predicting the time, location and magnitude of an earthquake is a challenging job as an earthquake does not show specific patterns resulting in inaccurate predictions. Techniques based on Artificial Intelligence (AI) are well known for their capability to find hidden patterns in data. In the case of earthquake prediction, these models also produce a promising outcome. This work systematically explores the contributions made to date in earthquake prediction using AI-based techniques. A total of 84 scientific research papers, which reported the use of AI-based techniques in earthquake prediction, have been selected from different academic databases. These studies include a range of AI techniques including rule-based methods, shallow machine learning and deep learning algorithms. Covering all existing AI-based techniques in earthquake prediction, this article provides an account of the available methodologies and a comparative analysis of their performances. The performance comparison has been reported from the perspective of used datasets and evaluation metrics. Furthermore, using comparative analysis of performances the paper aims to facilitate the selection of appropriate techniques for earthquake prediction. Towards the end, it outlines some open challenges and potential research directions in the field.","10.1109/ACCESS.2020.3029859","IEEE Journals","2020","","IEEE"
"A comparison between PLSR, SVMR and NARX network for the mint treatment day prediction based on multisensor system","The ability to distinguish between edible aromatic plants treated with insecticides holds the attention of researchers in view of the toxicity of insecticides in human health. The malathion has a distinctive smell it an insecticide widely used to protect mint crops. In the present paper, three regression and artificial intelligence (AI)-based methods such as partial least squares (PLS) regression, support vector machine (SVM) regression, and the nonlinear autoregressive with exogenous input (NARX) were investigated to predict the mint treatment day with malathion. The data used in this work are collected using a multi-sensor system designed based on commercial gas sensors. In this case, the nonlinear autoregressive with exogenous input (NARX) was found the most effective achieving a correlation coefficient (R) of 0.99 with a very minimal mean squared error (MSE) of about 1.10288e-14. Thanks to the right choice of the appropriate algorithm, the mint treatment day could be predicted with a simple multisensor gas array.","10.1109/ICOA51614.2021.9442652","IEEE Conferences","2021","","IEEE"
"A User-Centered Design of Natural Language Processing for Maternal Monitoring Chatbot System","A self-monitoring device and remote counseling system for pregnant mothers using interactive chat is an effective method due to the reduction of maternal care visits caused during the pandemic. The employment of an artificial intelligence (AI) based system using natural language processing (NLP) for decision support has prospectively enhanced the conversational access of patient to improve health awareness and knowledge. This research was conducted to develop an AI-based system which focuses on education and monitoring with regard to danger signs during pregnancy using NLP. The Telegram chatbot was used to develop the system after investigating user needs based on the danger sign monitoring guideline from WHO and the Ministry of Health of the Republic of Indonesia. The inputs from users were recognized by NLP and forwarded to the testing data for decision system. Furthermore, the analysis result was sent to the user which provides educational information and a personalized monitoring result. System Usability Scale (SUS) was undertaken to assess the user ability to use the application. The SUS score average for the chatbot system was 62.3 which was classified as “OK” for the adjective ratings. The implication of the maternal monitoring using a chatbot system is the improvement of maternal care with regard to early detection of danger signs and relevant suggestions using an effective and interactive system which could be very promising especially in a limited healthcare resource environment.","10.1109/ICIMCIS56303.2022.10017517","IEEE Conferences","2022","","IEEE"
"Cooperative Traffic Control where Autonomous Cars Meet Human Drivers","Co-adaptive system is a close coupling between human and software system cooperating to achieve shared goals. This co-adaption requires adaptive actions to react to unpredictable circumstances. One of the challenges is to deal with uncertainties, and consequently, decision making under uncertainty, which may arise because of the change in the environment, the unpredictable resources, etc. Human behavior does contribute to large amounts of uncertainty. This paper presents an approach for using a simulator as a means of feedback to a human's decision under uncertainty that can assist human in automated planning to generate cooperative and symbiotic strategy of human and the system to achieve given tasks. To validate the approach, this paper presents a customizable traffic simulator to measure the delays associated with passing vehicles through intersections. The simulator contains AI-based self-adaptive vehicles which can evaluate the quality of traffic at an intersection and change their driving behavior. The human operator from the outside of the system can manipulate the signaling time, the number of predicates per driving rule, number of rules per rule set, learning factor (adaption) etc. to overcome any unexpected traffic. This research proves that our simulator is more efficient than the individual human-operated and automated traffic system and makes a true cooperative traffic example.","10.1109/SoutheastCon42311.2019.9020663","IEEE Conferences","2019","","IEEE"
"AI in Blockchain Towards Realizing Cyber Security","Blockchain and artificial intelligence are two technologies that, when combined, have the ability to help each other realize their full potential. Blockchains can guarantee the accessibility and consistent admittance to integrity safeguarded big data indexes from numerous areas, allowing AI systems to learn more effectively and thoroughly. Similarly, artificial intelligence (AI) can be used to offer new consensus processes, and hence new methods of engaging with Blockchains. When it comes to sensitive data, such as corporate, healthcare, and financial data, various security and privacy problems arise that must be properly evaluated. Interaction with Blockchains is vulnerable to data credibility checks, transactional data leakages, data protection rules compliance, on-chain data privacy, and malicious smart contracts. To solve these issues, new security and privacy-preserving technologies are being developed. AI-based blockchain data processing, either based on AI or used to defend AI-based blockchain data processing, is emerging to simplify the integration of these two cutting-edge technologies.","10.1109/AIE57029.2022.00096","IEEE Conferences","2022","","IEEE"
"Artificial Intelligence-Based Surveillance System for Railway Crossing Traffic","The application of Artificial Intelligence (AI) based techniques has strong potential to improve safety and efficiency in data-driven Intelligent Transportation Systems (ITS) as well as in the emerging Internet of Vehicles (IoV) services. This paper deals with the practical implementation of deep learning methods for increasing safety and security in a specific ITS scenario: railway crossings. This research work presents our proposed system called Artificial Intelligence-based Surveillance System for Railway Crossing Traffic (AISS4RCT) that is based on a combination of detection and classification methods focusing on various image processing inputs: vehicle presence, pedestrian presence, vehicle trajectory tracking, railway barriers at railway crossings, railway warnings, and light signaling systems. The designed system uses cameras that are suitably positioned to capture an entire crossing area at a given railway crossing. By employing GPU accelerated image processing techniques and deep neural networks, the system autonomously detects risky and dangerous situations at railway crossing in real-time. In addition, camera modules send data to a central server for further processing as well as notification to interested parties (police, emergency services, railway operators). Furthermore, the system architecture employs privacy-by-design and security-by-design best practices in order to secure all communication interfaces, protect personal data, and to increase personal privacy, i.e., pedestrians, drivers. Finally, we present field-based results of detection methods, and using the YOLO tiny model method we achieve average recall 89%. The results indicate that our system is efficient for evaluating the occurrence of objects and situations, and it's practicality for use in railway crossings.","10.1109/JSEN.2020.3031861","IEEE Journals","2021","","IEEE"
"SHAPES Project Pilots' Self-assessment for Trustworthy AI","The Assessment List for Trustworthy AI (ALTAI) was developed by the High-Level Expert Group on Artificial Intelligence (AI HLEG) set up by the European Commission to help assess whether the AI system that is being developed, deployed, procured, or used, complies with the seven requirements of Trustworthy AI, as specified in the AI HLEG's Ethics Guidelines for Trustworthy AI. This paper describes the self-evaluation process of the SHAPES pilot campaign and presents some individual case results applying the prototype of an interactive version of the Assessment List for Trustworthy AI. Finally, the available results of two individual cases are combined. The best results are obtained from the evaluation category ‘transparency’ and the worst from ‘technical robustness and safety’. Future work will be combining the missing self-assessment results and developing mitigation recommendations for AI-based risk reduction recommendations for new SHAPES services.","10.1109/DESSERT58054.2022.10018790","IEEE Conferences","2022","","IEEE"
"Introduction to AI Assurance for Policy Makers","The deployment of artificial intelligence (AI) applications has accelerated faster than most scientists, policymakers and business leaders could have predicted. AI enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risk either in the form of physical injury or unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective and requires oversight, therefore depending on experts opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations.While not comprehensive, this work provides an overview of AI legislation and directives at the international, U.S. state and federal levels. It also covers business standards, and technical society initiatives. This work can serve as a resource for policymakers and other key stakeholders and an entry point to their understanding of AI policy.","10.1109/STC55697.2022.00016","IEEE Conferences","2022","","IEEE"
"Comparative assessment of cyber-physical threats to megacities","By 2030, forecasts suggest that urban areas will house 60 percent of the world’s population and one in every three people will live in cities with at least half a million inhabitants. Within the same time frame, the number of global megacities is expected to jump from 33 today to 43 in 2030 [1]. Underpinning these large urban areas will be an interconnected network of critical physical infrastructures reliant on Internet-connected Industrial Control Systems and susceptible to increasingly sophisticated, e.g., AI-enabled, cyber threats. In hand, the cyber threat landscape is shifting rapidly. We are seeing a sharp rise in the number of cyberattacks on critical infrastructure [2] with significant impacts cascading across multiple sectors and causing disruption to the provisioning of essential goods and services. Security scholars suggest that these impacts are not always equitable and that disruption to critical infrastructure can affect vulnerable groups differently [3], which further emphasizes the need to improve cybersecurity between critical infrastructure sectors [4]. Through structured analysis of city statistics, demographic information, cyber incidents, and current cyber policy, our presentation will articulate potential social implications of megacity growth through the lens of cyber-physical infrastructure disruption. We investigate the largest 15 megacities in the world and find that megacities continue to grow in population but not in cyber policy. We highlight recent examples of cyber-physical disruption in Mumbai and New York City with focus on implications for vulnerable populations. Our work suggests the need for future research on social responsibility regarding security of these critical infrastructure sectors and on the need for technology-focused law, policy, and regulation guidelines.","10.1109/ISTAS52410.2021.9629170","IEEE Conferences","2021","","IEEE"
"A Behavioral Chatbot Using Encoder-Decoder Architecture : Humanizing conversations","Though there are so many ways of building conversational chatbots, they lack the human touch and sound very robotic. We don’t have any chatbots that aim to imitate even a speck of a personality or human-like traits, while we very well possess everything that we need in terms of data and computation. This project aims to make both efficient and human-like chatbot using the modern encoder-decoder architecture. There are many frameworks and libraries available to develop AI-based chatbots including program-based, rule-based and interface-based. But they lack the flexibility in developing real dialogues and understanding humans. The popular chatbot models don’t aim to hold conversations that imitate real human-like interactions. Current chatbots employ a rule-based approach, basic machine learning algorithms, or a retrieval-based strategy that does not provide humanized outputs, i.e., these chatbots are incapable of producing engaging dialogues. In this paper, we tried to develop a Behavioural chatbot, using modern deep learning techniques like Seq2Seq aiming to develop chatbots to understand humans and make some situation agnostic conversations that remind us of our desirable personalities. This chatbot model was trained on real human conversations extracted out of Hollywood movies, hence the dataset possesses around 2.3 lakh truly organic dialogues. The model was trained with ~4.2 million parameters, 250 epochs and attained an accuracy of 95%. This chatbot is capable of displaying subtle sarcasm and also tries to be funny at times, thanks to the dramatic Hollywood dialogue writers.","10.1109/ICPS55917.2022.00017","IEEE Conferences","2022","","IEEE"
"Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review","Despite the myriad peer-reviewed papers demonstrating novel Artificial Intelligence (AI)-based solutions to COVID-19 challenges during the pandemic, few have made a significant clinical impact, especially in diagnosis and disease precision staging. One major cause for such low impact is the lack of model transparency, significantly limiting the AI adoption in real clinical practice. To solve this problem, AI models need to be explained to users. Thus, we have conducted a comprehensive study of Explainable Artificial Intelligence (XAI) using PRISMA technology. Our findings suggest that XAI can improve model performance, instill trust in the users, and assist users in decision-making. In this systematic review, we introduce common XAI techniques and their utility with specific examples of their application. We discuss the evaluation of XAI results because it is an important step for maximizing the value of AI-based clinical decision support systems. Additionally, we present the traditional, modern, and advanced XAI models to demonstrate the evolution of novel techniques. Finally, we provide a best practice guideline that developers can refer to during the model experimentation. We also offer potential solutions with specific examples for common challenges in AI model experimentation. This comprehensive review, hopefully, can promote AI adoption in biomedicine and healthcare.","10.1109/RBME.2022.3185953","IEEE Journals","2023","","IEEE"
"Practical use of Artificial Intelligence for Clinical Staff Other than Physicians","Trials to introduce artificial intelligence (AI) in clinical settings have been done for several decades, but the movement toward such introduction remains slow. In the past, AI systems were mainly to support physicians. They were ”rule-based” and specifically designed to assist in diagnosis or to recommend drugs to be prescribed to patients. Current clinical medicine is not performed by a physician acting alone, but through cooperation between staff with various occupations. Kimura Information Technology Co., Ltd. (KIT, Japan) has built a system named ”AI-Q” that works on the Japanese version of IBM's Watson and with which it is possible to build arbitrary problem solving systems. AI-Q was made to serve a variety of purposes, and a system for pharmacists has been built for drug information. In this paper, we illustrate how practical applications of AI can be designed for use by medical staff other than physicians and discuss how the system can be extended to other fields. We converted an AI system previously used to support pharmacists into one for certified clinical engineers (CCE). The purpose of this paper is to give the background of the system for CCE and to evaluate it.","10.1109/ICCE-Berlin.2018.8576166","IEEE Conferences","2018","","IEEE"
"Curriculum and Training Development in the METIS project","To improve its competitiveness, the EU microelectronics area needs to overcome critical skills deficits. In this context, METIS (MicroElectronics Training, Industry and Skills) gives an individual European partnership establishing a sustainable structure to: analyze main global biases effecting on the area and offer strategic insights and foresights, predict rising skills demands, identify job rules/jobs of the future, determine important occupational profiles and observe progress in the domain of human capital for microelectronics, develop a Sector Skills Strategy to support the global leadership of the EU microelectronics industry, establishing operational linkages between skills and the future of the area, federate European synergies towards the needs of data-driven technologies such as artificial intelligence (AI) enabled by advanced microelectronics and its skills demands, establish an EU Microelectronics Observatory & Skills Council, plan and produce a modular and blended curriculum, integrating work-oriented learning that uses open education resources (OER), pave the way for the pan-European recognition of innovative Vocational Education and Training (VET), use innovative tools such as industry mentoring to facilitate inter-generational transfer of knowledge in the area, embed social (diversity & inclusion) and environmental sustainability (circular economy) subjects and EU policy aims in the development of workforce.","10.1109/SIITME53254.2021.9663582","IEEE Conferences","2021","","IEEE"
"Two-Wheeler Vehicle Traffic Violations Detection and Automated Ticketing for Indian Road Scenario","Traffic violation monitoring and control is a major concern in India due to excess crowd, increasing commuters, bad traffic signal management, and rider mentality. It is obvious that physical traffic police-based monitoring alone is insufficient to monitor such large traffic volumes and simultaneously track violations. This has led to many violators going unnoticed. The violators, in turn, cause more serious mishaps on the road resulting in danger to their own life as well as to other’s life. Thus, there is a need for incorporating Artificial Intelligence (AI)-based techniques to eliminate manual intervention for the detection and catching of violators. In this paper, we propose a system to automatically detect two-wheeler violations like not wearing a helmet, usage of a phone while riding, triple riding, wheeling, and illegal parking for Indian road scenarios and eventually automating the ticketing process by capturing the violations and corresponding vehicle number in a database. We propose using a custom trained Yolo-v4 + DeepSORT for violation detection and tracking and Yolo-v4 + Tesseract for number plate detection and extraction. This implementation obtained a mean average precision (mAP) of 98.09% for violation detection and an accuracy of 99.41% for number plate detection on the test data. Further, the system detected 77 out of 93 violations with zero false positives in real-life scenarios. Thus,showing that the traffic violation system developed can be used to automate traffic violation ticketing. The developed system would be particularly useful in deriving various safety-related policies and will help to enforce strong regulation of traffic rules and build towards a smart city ecosystem via the automated AI-based traffic violation and ticketing system.","10.1109/TITS.2022.3186679","IEEE Journals","2022","","IEEE"
"Towards a Data Engineering Process in Data-Driven Systems Engineering","Highly Automated Driving (HAD) has become one of the leading trends in the automotive industry. Mandatory tasks like environment perception and scene understanding challenge existing rule-based methods. Thus, data-driven technologies and Artificial Intelligence (AI) have been introduced to automotive software development. Utilizing data in the development process has become essential as these systems are no longer developed with classical systems engineering methods, but rather by deriving requirements from and training the algorithms with recorded real-world data. This entails the introduction of data-driven workflows and data-management as new aspects of Automotive Systems Engineering (ASE). Tasks related to the development of Artificial Intelligence (AI) software differ from their classical engineering and programming counterparts. Thus, engineers require new tools and methods for developing safe and accurate AI-based software and handling data efficiently during ASE. Another important aspect of data-driven development is ensuring data quality throughout the systems engineering process. Hence, this paper aims to take a step towards the introduction of a data engineering process in data-driven automotive systems engineering. Putting a spotlight on developing well-designed data sets as the central element for training and validating AI-based software. Besides determining the quality of data sets, we present steps towards improving data and data set quality.","10.1109/ISSE54508.2022.10005441","IEEE Conferences","2022","","IEEE"
"Dimmer: Self-Adaptive Network-Wide Flooding with Reinforcement Learning","The last decade saw an emergence of Synchronous Transmissions (ST) as an effective communication paradigm in low-power wireless networks. Numerous ST protocols provide high reliability and energy efficiency in normal wireless conditions, for a large variety of traffic requirements. Recently, with the EWSN dependability competitions, the community pushed ST to harsher and highly-interfered environments, improving upon classical ST protocols through the use of custom rules, hand-tailored parameters, and additional retransmissions. The results are sophisticated protocols, that require prior expert knowledge and extensive testing, often tuned for a specific deployment and envisioned scenario. In this paper, we explore how ST protocols can benefit from self-adaptivity; a self-adaptive ST protocol selects itself its best parameters to (1) tackle external environment dynamics and (2) adapt to its topology over time. We introduce Dimmer as a self-adaptive ST protocol. Dimmer builds on LWB and uses Reinforcement Learning to tune its parameters and match the current properties of the wireless medium. By learning how to behave from an unlabeled dataset, Dimmer adapts to different interference types and patterns, and is able to tackle previously unseen interference. With Dimmer, we explore how to efficiently design AI-based systems for constrained devices, and outline the benefits and downfalls of AI-based low-power networking. We evaluate our protocol on two deployments of resource-constrained nodes achieving 95.8 % reliability against strong, unknown WiFi interference. Our results outperform baselines such as non-adaptive ST protocols (~27%) and PID controllers, and show a performance close to hand-crafted and more sophisticated solutions, such as Crystal (~99 %).","10.1109/ICDCS51616.2021.00036","IEEE Conferences","2021","","IEEE"
"safe.trAIn – Engineering and Assurance of a Driverless Regional Train","Traditional automation technologies alone are not sufficient to enable the fully automated operation of trains. However, Artificial Intelligence (AI) and Machine Learning (ML) offers great potential to realize the mandatory novel functions to replace the tasks of a human train driver, such as obstacle detection on the tracks. The problem, which still remains unresolved, is to find a practical way to link AI/ML techniques with the requirements and approval processes that are applied in the railway domain. The safe.trAIn project aims to lay the foundation for the safe use of AI/ML to achieve the driverless operation of rail vehicles and thus addresses this key technological challenge hindering the adoption of unmanned rail transport. The project goals are to develop guidelines and methods for the reliable engineering and safety assurance of ML in the railway domain. Therefore, the project investigates methods to reliable design ML models and to prove the trustworthiness of AI-based functions taking robustness, uncertainty, and transparency aspects of the AI/ML model into account.","10.1109/CAIN58948.2023.00036","IEEE Conferences","2023","","IEEE"
"Practical Reinforcement Learning for Adaptive Photolithography Scheduler in Mass Production","This work introduces a practical reinforcement learning (RL) techniques to address the complex scheduling challenges in producing Active Matrix Organic Light Emitting Diode displays. Specifically, we focus on autonomous optimization of the photolithography process, a critical bottleneck in the fabrication. This provides an outperforming scheduling method compared with the existing rule-based approach which requires diverse rules and engineer experience on adapting dynamic environments. Our purposing RL network was designed to make effective schedules aligning with layered structures of the planning and scheduling modules for mass production. In the training phase, historical production data is utilized to create a representative discrete event simulation environment. The RL agent, based on the Deep Q-Network, undergoes episodic training to learn optimal scheduling policies. To ensure safe and reliable scheduling decisions, we further introduce action filters and parallel competing schedulers. The performance of RL-based Scheduler (RLS) is compared to the Rule-Based Scheduler (RBS) over actual fabrication in a year-long period. Based on Key performance indicators, we validate the RLS outperforms the RBS, with a remarkable improvement in step target matching, reduced setup times, and enhanced lot assignments. This work also paves a way for the gradual integration of AI-based algorithms into smart manufacturing practices.","10.1109/TSM.2023.3336909","IEEE Early Access Articles","2023","","IEEE"
"An Integrated Expert System with a Supervised Machine Learning based Probabilistic Approach to Play Tic-Tac-Toe","Tic-Tac-Toe, also known as Noughts and Crosses, is a widely popular game among people of all ages. In recent times, due to the rapid development of Artificial Intelligence (AI) based algorithms, AI in Games has become an interesting topic for research in both academia and industry. Due to the complicated yet competent nature of AI algorithms, the design and implementation of such AI-driven approaches in games are challenging and time intensive. In this regard, we propose a supervised Machine Learning (ML)-based approach that contributes in designing an innovative and less complex Tic-Tac-Toc expert system. Integrating AI and ML in the solution process will lead the concerned community toward a more lightweight and computationally efficient systems for playing games. In this study, we propose a novel algorithmic solution by combining an ensemble-based boosting approach and rule-based inference to build a probabilistic expert system that strategically chooses the best optimal move for next possible state of the game. A benchmark dataset containing 255,168 unique game states of Tic Tac Toe was utilized at training stage. The proposed strategy is able to successfully settle a draw against never-loosing MiniMax algorithm in 18 standard test cases.","10.1109/UEMCON53757.2021.9666728","IEEE Conferences","2021","","IEEE"
"An Energy Management Strategy in Hybrid Electric Vehicles: The Present and The Future Scenario","There has been a significant increase in interest towards ""The electrification of transportation"" in the past decade. The environmental crisis caused due to global warming and the depletion of oil supplies are factors that have made the automobile sector adopt strategies to produce eco-friendly, sustainable vehicles instead of their commercial fuel propelled vehicles. Most governments have expressed their interest in alleviating the environmental impact caused due to vehicle pollution by introducing various policies that eventually help people switch to Electric Vehicles (EV). Though there has been a surge of interest among people to adopt environmentally friendly, economically affordable electric vehicles, the major concern is the state of charge and range offered by these EVs. The global automobile sector has started to invest in research dedicated to the energy management system in EVs to overcome these issues. The emergence of artificial intelligence (AI) and the advancement of control systems are clear signs for developing smart-energy management systems in EV. This paper reviews the methods of energy storage and usage in EV following the various Energy Management Systems (EMS) present in EV such as Rule-based EMS and Optimization-based EMS and its types. Also, it gives an insight into the emergence of futuristic AI-based chips that would revolutionize the energy-management system in E-vehicles.","10.1109/ICAECA56562.2023.10200140","IEEE Conferences","2023","","IEEE"
"Melanoma Boundaries Detection Techniques using Artificial Intelligence","Melanoma is the 6th most successive disease in the United States, with more than 9000 individuals kicking the bucket every year. Fast acknowledgment of melanoma expands an individual's life expectancy, but further developed analytic advancements are as yet required. Skin injury limit anomaly, which addresses the ""B"" includes in the ""ABCD rule"", is viewed as a critical clinical component for the early discovery of melanoma. What's more, blue-white line structure evacuation additionally further develops the identification proficiency. In this paper, an AI based location method for distinguishing skin injury limit inconsistencies is presented. The technique involves extricating the skin injury from the dermoscopic images, recognizing the skin sore line, estimating line inconsistency, and prepared famous directed learning models called SVM, RF, DT, and gathering move learning calculations to distinguish line anomaly naturally, bringing about a true choice on whether the skin sore boundary is customary or unpredictable. The method produces excellent results, with 92.6 percent accuracy, 91.3 percent sensitivity, 92.5 percent specificity, and 95.1 percent F-Score, respectively.","10.1109/ICAIS56108.2023.10073936","IEEE Conferences","2023","","IEEE"
"A Multi-agent Simulation for the Research on the Market Equilibrium Phenomena Using Q-Network Algorithm","For the problems related to market equilibrium in complex market environments, analyses are conducted in the past, using some mathematical models and the game theory. These methods are based on the economic structural equations themselves, ignoring the interactions between economic subjects, and the hypothesis of subject homogeneity has no reference in the real world. On contrast, this paper proposes a multi-agent simulation model, from the microscopic point of view. In such simulation, agents interact with each other, and the decisions are made by agent-embedded AI systems, the Q-network. Therefore, there is no need to elaborate the behavioral rule for each agent, or manually set up too many assumptions. This paper assumes that the simulated market operates in a hypothetical way, in which there are two types of economic entities, namely, banks and enterprises. Banks and enterprises lending behaviors lead to a symbiotic relationship between the banks and the enterprises, while business-to-business transactions make the enterprises symbiotically compete with each other. In the experiment, the observed behavior of each agent can be reasonably explained. Agents endogenously generate intelligent behavioral patterns compatible with the environment. Therefore, this AI-based method can replace the artificially designated decision-making strategy in simulations of market, thus facilitating related economic researches.","10.1109/ICCT46805.2019.8947047","IEEE Conferences","2019","","IEEE"
"Experimental Investigation of Model Predictive Control for Thermal Energy Storage System Using Artificial Intelligence","A model predictive control (MPC) strategy was developed using artificial intelligence (AI) and investigated using an experimental setup. The experimental system for the cooling operation includes a chiller, thermal energy storage (TES), heat exchangers, and variable-speed pumps. The air-conditioning space was replaced with a water tank, and the cooling load was assigned by an electric immersion heater. Control variables included the flow rates of pumps in the water loop for the primary side. In the MPC framework, artificial neural networks (ANNs) were used as surrogate models, and a metaheuristics optimization solver was employed to minimize the total operating costs. The developed AI-based MPC strategy could save operating costs by 9.7-22.5% compared to the rule-based control strategies that prioritize TES operation.","10.1109/MED51440.2021.9480324","IEEE Conferences","2021","","IEEE"
"Manual Abstraction in the Wild: A Multiple-Case Study on OSS Systems’ Class Diagrams and Implementations","Models are a useful tool for software design, analysis, and to support the onboarding of new maintainers. However, these benefits are often lost over time, as the system implementation evolves and the original models are not updated. Reverse engineering methods and tools could help to keep models and implementation code in sync; however, automatically reverse-engineered models are typically not abstract and contain extensive information that prevents understanding. Recent advances in AI-based content generation make it likely that we will soon see reverse engineering tools with support for human-grade abstraction. To inform the design and validation of such tools, we need a principled understanding of what manual abstraction is, a question that has received little attention in the literature so far.Towards this goal, in this paper, we present a multiple-case study of model-to-code differences, investigating five substantial open-source software projects retrieved via repository mining. To explore characteristics of model-to-code differences, we, all in all, manually matched 466 classes, 1352 attributes, and 2634 operations from source code to 338 model elements (classes, attributes, operations, and relationships). These mappings precisely capture the differences between a provided class diagram design and implementation codebase. Studying all differences in detail allowed us to derive a taxonomy of difference types and to provide a sorted list of cases corresponding to the identified types of differences. As we discuss, our contributions pave the way for improved reverse engineering methods and tools, new mapping rules for model-to-code consistency checks, and guidelines for avoiding over-abstraction and over-specification during design.","10.1109/MODELS58315.2023.00017","IEEE Conferences","2023","","IEEE"
"IoTwins: Design and Implementation of a Platform for the Management of Digital Twins in Industrial Scenarios","With the increase of the volume of data produced by IoT devices, there is a growing demand of applications capable of elaborating data anywhere along the IoT-to-Cloud path (Edge/Fog). In industrial environments, strict real-time constraints require computation to run as close to the data origin as possible (e.g., IoT Gateway or Edge nodes), whilst batch-wise tasks such as Big Data analytics and Machine Learning model training are advised to run on the Cloud, where computing resources are abundant. The H2020 IoTwins project leverages the digital twin concept to implement virtual representation of physical assets (e.g., machine parts, machines, production/control processes) and deliver a software platform that will help enterprises, and in particular SMEs, to build highly innovative, AI-based services that exploit the potential of IoT/Edge/Cloud computing paradigms. In this paper, we discuss the design principles of the IoTwins reference architecture, delving into technical details of its components and offered functionalities, and propose an exemplary software implementation.","10.1109/CCGrid51090.2021.00075","IEEE Conferences","2021","","IEEE"
"How Do Manufacturing Firms Manage Artificial Intelligence to Drive Iterative Product Innovation?","In this article, we attempt to investigate how manufacturing firms can effectively manage artificial intelligence (AI) to deal with the tension posed by both the opportunities and risks associated with AI applications to drive iterative product innovation. We present empirical insights from three cases involving a typical Chinese manufacturing firm engaged in AI-driven iterative product innovation. We followed our sample firm for 12 months, relying on interviews, observations, and external archival data to collect rich data about its innovation process, and conducted text coding and text analytics to gain insights into the data. Our findings reveal that AI provides opportunities for broad, deep, and agile stakeholder interactions with the support of AI-enabled interactive digital platforms, intelligent manufacturing, and intelligent machines. During this process, risks emerge around data leakage, over-reliance on online intelligence decision-making, and unpredictable AI behaviors. Manufacturing firms need to manage AI by focusing on key principles relating to formulating guidelines for data management, integrating offline decision-makers’ experience into online intelligence analysis, and establishing management standards for intelligent devices. We combine these insights into a framework to illustrate how manufacturing firms manage AI to facilitate progress in iterative product innovation.","10.1109/TEM.2023.3259396","IEEE Early Access Articles","2023","","IEEE"
"Towards Domain-Specific Explainable AI: Model Interpretation of a Skin Image Classifier using a Human Approach","Machine Learning models have started to outperform medical experts in some classification tasks. Meanwhile, the question of how these classifiers produce certain results is attracting increasing research attention. Current interpretation methods provide a good starting point in investigating such questions, but they still massively lack the relation to the problem domain. In this work, we present how explanations of an AI system for skin image analysis can be made more domain-specific. We apply the synthesis of Local Interpretable Model-agnostic Explanations (LIME) with the ABCD-rule, a diagnostic approach of dermatologists, and present the results using a Deep Neural Network (DNN) based skin image classifier.","10.1109/CVPRW53098.2021.00199","IEEE Conferences","2021","","IEEE"
"Does Artificial Intelligence Help Reduce Audit Risks?","This article aims to discover how AI-powered systems facilitate auditing, what risks emerge for AI-assisted audits and how to deal with these new risks. The paper studies the impact of cognitive computing on audit risk. AI-powered software is capable of self-learn so that it can identify patterns in data and codify them in predictions, rules and decisions. This self-learning ability can become both a benefit and, at the same time, insecurity. Although AI-self-learning helps make the process more efficient and calculations more accurate by improving the algorithm, eliminating errors and reducing risks, it creates new previously unknown threats. We discovered inherent limitations of cognitive-based technologies and risks for the audit process associated with using AI systems. We also proposed a complex security model that can reduce the uncertainty of AI-enabled audit and provides insight into future research opportunities.","10.1109/ACIT58437.2023.10275661","IEEE Conferences","2023","","IEEE"
"A Survey on Artificial Intelligence-Based Modeling Techniques for High Speed Milling Processes","The process of high speed milling is regarded as one of the most sophisticated and complicated manufacturing operations. In the past four decades, many investigations have been conducted on this process, aiming to better understand its nature and improve the surface quality of the products as well as extending tool life. To achieve these goals, it is necessary to form a general descriptive reference model of the milling process using experimental data, thermomechanical analysis, statistical or artificial intelligence (AI) models. Moreover, increasing demands for more efficient milling processes, qualified surface finishing, and modeling techniques have propelled the development of more effective modeling methods and approaches. In this paper, an extensive literature survey of the state-of-the-art modeling techniques of milling processes will be carried out, more specifically of recent advances and applications of AI-based modeling techniques. The comparative study of the available methods as well as the suitability of each method for corresponding types of experiments will be presented. In addition, the weaknesses of each method as well as open research challenges will be presented. Therefore, a comprehensive comparison of recent developments in the field will be a guideline for choosing the most suitable modeling technique for this process regarding its goals, conditions, and specifications.","10.1109/JSYST.2013.2282479","IEEE Journals","2015","","IEEE"
"“The Robot-Arm Talks Back to Me” - Human Perception of Augmented Human-Robot Collaboration in Virtual Reality","The usage of AI enhanced robots in shared task environments is likely to become more and more common with the increase of digitalization in different industrial sectors. To take up this new challenge, research on the design of Human-Robot-Collaboration (HRC) involving AI-based systems has yet to establish common targets and guidelines. This paper presents results from an explorative qualitative study. Participants (N= 80) were either exposed to a virtual representation of an industrial robot-arm equipped with several augmentation channels for communication with the human operator (lights, textual statements about intentions, etc.) or one with no communicative functions at all. Across all conditions, participants recognized the benefit of collaborating with robots in industrial scenarios regarding work efficiency and alleviation of working conditions. However, a communication channel from the robot to the human is crucial for achieving these benefits. Participants interacting with the non-communicative robot expressed dissatisfaction about the workflow. In both conditions we found remarks about the insufficient speed of the robot-arm for an efficient collaborative process. Our results indicate a wider spectrum of questions to be further explored in the design of collaborative experiences with intelligent technological counterparts considering efficiency, safety, economic success and well-being.","10.1109/AIVR50618.2020.00062","IEEE Conferences","2020","","IEEE"
"Severe Analysis of Cardiac Disease Detection using the Wearable Device by Artificial Intelligence","In the current era of technology, Artificial Intelligence (AI) is playing a vital role in the health care sector especially cardiac disease detection which is a major cause of sudden death. Both the elderly and young are at the risk of sudden cardiac death at the ratio of 1-2% all around the world. Although AI technology with wearable technology is being used to detect heart diseases for quite some time now, sometimes it fails due to multiple reasons which include algorithm failure, high cost of treatment, limited battery time wearable device, data training issues, security and privacy issue in IoT, slow working of devices, poor internet or patients don't reach the hospital on time. Which gives rise to false results. Security and privacy issues in the old devices are the biggest flaws due to which old devices work slowly and the internet issues are common, it helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload, cost issues and to line onward. Meanwhile, these problems can be overcome by using modern models such as ECG assessment, AI-based guidelines, Visy's model which can recognize five critical diseases. A Wearable ECG patch is a very lightweight model that provides high accuracy and efficiency. These devices are trained by using a machine learning algorithm, and AI plays a prime role to detect the diseases. It helps us to check their heart parameters anytime and anywhere in the world which reduces the hospital's workload and cost issues, and the devices provide updated information as real-time data is stored online and secured with firebase authentication. It is concluded that all modern devices are more efficacious, cost-effective, user friendly, and more secure.","10.1109/INOCON50539.2020.9298388","IEEE Conferences","2020","","IEEE"
"Team Roles & Rhetorical Intelligence in Human-Machine Writing","This paper examines AI-based writing systems and how humans might partner with these systems to produce effective professional communication. We offer a taxonomy for examining roles in human-machine teaming for writing: Resource Tool, Assistant, Writer, and Executive Decision-Maker (whether at the beginning or end of the project). In particular, we focus on humanmachine teaming in relation to what we call rhetorical intelligence, the ability to invent and write for audience, purpose, and context. We examine human-machine writing by focusing on two cases: GameChanger and Phrazor by vPhrase. We conclude by proposing some guidelines for human-machine teaming for the production of professional communication.","10.1109/ProComm53155.2022.00078","IEEE Conferences","2022","","IEEE"
"Delay Root Cause Analysis and 3D Modeling of LTE Control Communication Using Machine Learning","This study investigates and evaluates delay root cause analysis and 3D modeling of LTE control communication utilizing sophisticated machine learning for network testing. The research studied LTE protocols for 5th-generation mobile telephony and provided guidelines for controlling LTE frequency for background knowledge, although it used an independent technique that did not employ LTE standards. 512 elements of input-output MIMO were employed for 100-GHz and 128 elements for mid-band sub-6-GHz. LOS is always 0.5. This paper is about LTE, not 3D modeling of LTE control path loss type communication using machine learning. This work’s route loss depends on cross-pol beam LTE polarization (±45o). The receiver (Rx) operations and transmitter (Tx) activities in the estimated distance of 0.5 km at an approximate altitude of 15.25 m. Distance, handover authentication, rain, atmosphere, and sub-6GHz vs 100GHz weather conditions affect path loss. The methodology has enhanced the spatial variety by boosting transmitting power and transmitting efficiency. Authorizing and sanctioning ANN-based LTE frequency for both mid-band sub-6-GHz and 100-GHz is possible due to its planning and development using open-source material and strategy with high transmission power and rate under doubtful handover confirmation using MIMO input/yield receiving wires. This theory examines LTE innovation dimensioning as unbiased for various handover verification and allows input boundary alterations for various organization arrangement setups for LTE recurrent data transmission from 6 GHz to 100 GHz for three climate sorts. This cycle should be seen as an undeniable level way to examine LTE networks under various air conditions. Using signal handling tool compartment and explicit AI-based ANN calculation from AI toolkit in MATLAB R2019a, it is possible to create a result answer for three climate types in a dataset with an LTE communication level of exactness of downpour assimilation and abundance foliage miss fort.","10.1109/ICAIoT57170.2022.10121830","IEEE Conferences","2022","","IEEE"
"Requirement analysis for an artificial intelligence model for the diagnosis of the COVID-19 from chest X-ray data","There are multiple papers published about different AI models for the COVID-19 diagnosis with promising results. Unfortunately according to the reviews many of the papers do not reach the level of sophistication needed for a clinically usable model. In this paper I go through multiple review papers, guidelines, and other relevant material in order to generate more comprehensive requirements for the future papers proposing a AI based diagnosis of the COVID-19 from chest X-ray data (CXR). Main findings are that a clinically usable AI needs to have an extremely good documentation, comprehensive statistical analysis of the possible biases and performance, and an explainability module.","10.1109/BIBM52615.2021.9669525","IEEE Conferences","2021","","IEEE"
"Markov Chain Based Explainable Pattern Forecasting","The explosive penetration of artificial intelligence (AI) and machine learning (ML) based technologies are dramatically transforming the traditional decision support systems. We consider the pattern recognition and forecasting for demand timeseries in a business-to-business supply chain where demand exhibits high volatilities, non-stationarities, and skewness. We develop a pattern forecasting system by developing a data driven, feature dependent Markov chain-based framework. This may include any arbitrary user defined pattern qualitative in nature, such as plummet or recovery from plummet. To increase adoption of AI based techniques among the various stakeholders (e.g., sales, marketing, procurement, production planning) the inherent modeling and forecasting of different patterns needs to be explained in terms of domain knowledge the user is more familiar with. We therefore define two metrices to evaluate explainability to enable cross scenario comparison as the notion of explainability lacks mathematical precision. These are, namely, relevance and informativeness. Relevance is measured by direct scoring from the user whereas informativeness is inspired by the fundamental concept of measuring differences or discrepancies between distributions and for the sake of simplicity in our case measured by the variance in the main attribute of explainability. Moreover, our dataset is high dimensional where number of columns are much higher than number of rows and therefore the method for selecting features for fitting the Markov chain is extremely critical. To provide guidelines on selecting different attributes of our pipeline, we compare between feature selection methods from two families, one advanced and one traditional. We perform extensive evaluation with real dataset obtained from a business division belonging to the Panasonic Industry Co. Ltd and observe a sparsity promoting feature selection method performs better in terms of accuracy and explainability.","10.1109/IECON51785.2023.10312192","IEEE Conferences","2023","","IEEE"
"BookMate: Leveraging Deep Learning to Empower Caregivers of People with ASD in Generation of Social Stories","People with Autism Spectrum Disorder (ASD) have difficulties in social communication and interaction. Their caregivers help them in overcoming these challenges. Social stories are tools largely adopted to improve the interaction and communication capabilities of people with ASD. The creation of a social story is not an easy task. Several guidelines have been defined to build them. In this paper, we propose an interactive mobile application aimed at empowering caregivers of people with ASD in generating social stories. The application integrates AI processing and AI-based audio transcription for story generation, effective audio data extraction, and data processing. The stories are presented in a slide-show format to the learner in different modalities according to the learner's capabilities. A preliminary usability study of the application has been performed and the first results are encouraging.","10.1109/IV60283.2023.00074","IEEE Conferences","2023","","IEEE"
"Exploring the Feasibility of the Meta-Analysis of Randomized Controlled Trials on Artificial Intelligence Chatbots for Use in Healthcare Based on a Published Systematic Review","Usage of artificial intelligence (AI) based chatbot systems has been increasing not only in many industrial fields but also in the health care system. The effectiveness of AI chatbot systems as therapeutic tools has to be confirmed by clinical trials. Meta-analysis, a statistical method that synthetizes results of multiple studies thus increases the power of the findings. In this paper, our focus is on randomized controlled trials (RCTs) for the purpose of studying the effectiveness of AI chatbots used for healthcare purposes and analyzing step by step their applicability for meta-analysis. This article is based on a systematic literature review that identified eight RCTs. Only two RCTs (in the field of mental health) were feasible for meta-analysis. Standardization of the RCTs, development of points to consider as guidelines for conducting clinical trials with AI chatbots in diverse clinical areas could efficiently increase the strength of the studies and enable meta-analyses.","10.1109/SISY56759.2022.10036294","IEEE Conferences","2022","","IEEE"
"IoT DoS and DDoS Attack Detection using ResNet","The network attacks are increasing both in frequency and intensity with the rapid growth of internet of things (IoT) devices. Recently, denial of service (DoS) and distributed denial of service (DDoS) attacks are reported as the most frequent attacks in IoT networks. The traditional security solutions like firewalls, intrusion detection systems, etc., are unable to detect the complex DoS and DDoS attacks since most of them filter the normal and attack traffic based upon the static predefined rules. However, these solutions can become reliable and effective when integrated with artificial intelligence (AI) based techniques. During the last few years, deep learning models especially convolutional neural networks achieved high significance due to their outstanding performance in the image processing field. The potential of these convolutional neural network (CNN) models can be used to efficiently detect the complex DoS and DDoS by converting the network traffic dataset into images. Therefore, in this work, we proposed a methodology to convert the network traffic data into image form and trained a state-of-the-art CNN model, i.e., ResNet over the converted data. The proposed methodology accomplished 99.99% accuracy for detecting the DoS and DDoS in case of binary classification. Furthermore, the proposed methodology achieved 87% average precision for recognizing eleven types of DoS and DDoS attack patterns which is 9% higher as compared to the state-of-the-art.","10.1109/INMIC50486.2020.9318216","IEEE Conferences","2020","","IEEE"
"Security Threats and Artificial Intelligence Based Countermeasures for Internet of Things Networks: A Comprehensive Survey","The Internet of Things (IoT) has emerged as a technology capable of connecting heterogeneous nodes/objects, such as people, devices, infrastructure, and makes our daily lives simpler, safer, and fruitful. Being part of a large network of heterogeneous devices, these nodes are typically resource-constrained and became the weakest link to the cyber attacker. Classical encryption techniques have been employed to ensure the data security of the IoT network. However, high-level encryption techniques cannot be employed in IoT devices due to the limitation of resources. In addition, node security is still a challenge for network engineers. Thus, we need to explore a complete solution for IoT networks that can ensure nodes and data security. The rule-based approaches and shallow and deep machine learning algorithms- branches of Artificial Intelligence (AI)- can be employed as countermeasures along with the existing network security protocols. This paper presented a comprehensive layer-wise survey on IoT security threats, and the AI-based security models to impede security threats. Finally, open challenges and future research directions are addressed for the safeguard of the IoT network.","10.1109/ACCESS.2021.3089681","IEEE Journals","2021","","IEEE"
"GRA_Net: A Deep Learning Model for Classification of Age and Gender From Facial Images","The problem of gender and age identification has been addressed by many researchers, however, the attention given to it compared to the other related problems of face recognition in particular is far less. The success achieved in this domain has not seen much improvement compared to the other face recognition problems. Any language in the world has a separate set of words and grammatical rules when addressing people of different ages. The decision associated with its usage, relies on our ability to demarcate these individual characteristics like gender and age from the facial appearances at one glance. With the rapid usage of Artificial Intelligence (AI) based systems in different fields, we expect that such decision making capability of these systems match as much as to the human capability. To this end, in this work, we have designed a deep learning based model, called GRA_Net (Gated Residual Attention Network), for the prediction of age and gender from the facial images. This is a modified and improved version of Residual Attention Network where we have included the concept of Gate in the architecture. Gender identification is a binary classification problem whereas prediction of age is a regression problem. We have decomposed this regression problem into a combination of classification and regression problems for achieving better accuracy. Experiments have been done on five publicly available standard datasets namely FG-Net, Wikipedia, AFAD, UTKFAce and AdienceDB. Obtained results have proven its effectiveness for both age and gender classification, thus making it a proper candidate for the same against any other state-of-the-art methods.","10.1109/ACCESS.2021.3085971","IEEE Journals","2021","","IEEE"
"Living with Artificial Intelligence: A Paradigm Shift toward Future Network Traffic Control","Future Internet is expected to meet explosive traffic growth and extremely complex architecture, which tend to make the traditional NTC strategies inefficient and even ineffective. Inspired by the latest breakthroughs of AI and its power to address large-scale and complex difficulties, the network community has begun to consider shifting the NTC paradigm from legacy rule-based to novel AI-based. As an applied inter-discipline, design and implementation are important. Although there have been some preliminary explorations along this frontier, they are either limited by only envisioning the prospects, or too scattered to provide high-level insight into a general methodology. To this end, we start with the domain knowledge relationships of AI and NTC, summarizing a baseline workflow toward deep reinforcement learning, which will be the dominant method for the AI-NTC paradigm. On top of that, we argue that AI-NTC training and running must be carried out in online environments in closed-loop fashion for the purpose of putting ti into practice. A series of challenges and opportunities are discussed from a realistic viewpoint, and a set of new architecture and mechanism to enable the online and closed-loop AI-NTC paradigm are proposed. Hopefully, this work can help the AI community to better understand NTC and the NTC community to better live with AI.","10.1109/MNET.2018.1800119","IEEE Magazines","2018","","IEEE"
"Intelligent Automatic Door System based on Supervised Learning","The widespread adoption of automatic sliding doors in both commercial and non-commercial environments globally has necessitated the need to improve their efficiency, safety, and mode of operation. The automatic door gives access to go into or outside a building by sensing the approaching individual using sensors. However, it does not have the intuition to understand when a person is not authorized to go outside based on their age limit, for example, children. To address this problem, researchers have proposed solutions ranging from the use of fuzzy logic to rule-based approaches to make automatic doors better than the previous ones. In this study, an AI-based automatic door system is proposed, which uses a supervised machine learning approach to train classifiers using human body measurement. Our evaluation of different classifiers indicates that SVM is capable of classifying the instances correctly while achieving about 88.9% F-score. Thus, the proposed approach is expected to improve the safety of automatic doors, thereby making them smarter and more intelligent.","10.1109/ICOS50156.2020.9293673","IEEE Conferences","2020","","IEEE"
"Experimental Study on Generating Multi-modal Explanations of Black-box Classifiers in terms of Gray-box Classifiers","Artificial Intelligence (AI) is a first class citizen in the cities of the 21st century. In addition, trust, fairness, accountability, transparency and ethical issues are considered as hot topics regarding AI-based systems under the umbrella of Explainable AI (XAI). In this paper we have conducted an experimental study with 15 datasets to validate the feasibility of using a pool of gray-box classifiers (i.e., decision trees and fuzzy rule-based classifiers) to automatically explain a black-box classifier (i.e., Random Forest). Reported results validate our approach. They confirm the complementarity and diversity among the gray-box classifiers under study, which are able to provide users with plausible multi-modal explanations of the considered black-box classifier for all given datasets.","10.1109/FUZZ48607.2020.9177770","IEEE Conferences","2020","","IEEE"
"A Hybrid Approach of Web Based Heart Disease Diagnosis with Neural Networks","The prescient displaying approach for assessing cardiovascular gamble in medical services informatics is extremely challenging. Consequently, utilizing delicate figuring innovations to clinically assess clinical data sets and prescient displaying is viewed as a beneficial and practical decision for clinical specialists. Accordingly, delicate registering advances are essential in the present medical services applications since they can perform information examination and demonstrating and assist specialists with making ideal, precise clinical decisions. Information mining is the most common way of finding designs in a data set of wellbeing science factors that connect indicator factors. The displaying of convoluted, powerful frameworks is OK for existing information mining approaches. In this review, we propose a group model system for coordinating the prescient force of various classifiers' models for further developed expectation precision. To foresee and analyze the repeat of cardiovascular disease, this review utilizes group figuring out how to consolidate the demonstrating approaches of five classifiers, including support vector machines, fake neural networks, Credulous Bayesian, relapse examination, and arbitrary woods. Cleveland and Hungarian cardiovascular information records were taken from the UCI archive. The two most significant elements in myocardial localized necrosis determination are timing and exactness. Minor demonstrative slip-ups can essentially affect the length and cost of treatment as well as seriously jeopardized the patient. This study portrays a choice emotionally supportive network (DSS) for myocardial localized necrosis (MI) finding and the board, along with persistent pulse checking of the patient, based on neural networks and factual interaction control diagrams. In the whole world, heart disease is viewed as one of the main sources of death. Clinical experts find it challenging to foresee on the grounds that a complicated undertaking calls for experience and high level information. Presently, information mining and AI based clinical strong advances assume a huge part in the forecast of cardiovascular diseases. In this review, we propose a clever hybrid strategy for the expectation of cardiovascular disease utilizing an assortment of AI techniques, including Calculated Relapse (LR), Versatile Helping (AdaBoostM1), Multi-Objective Developmental Fluffy Classifier (MOEFC), Fluffy Unordered Rule Enlistment (FURIA), Hereditary Fluffy Framework LogitBoost (GFS-LB), and Fluffy Hybrid Hereditary Based AI.","10.1109/ICATIECE56365.2022.10047363","IEEE Conferences","2022","","IEEE"
"Usage of AI and Wearable IoT Devices for Healthcare Data: A Study","In this present situation, the importance of drawing the efficient learning footsteps should be necessary for describing mortal performances with the help of wearable‐internet of things (W‐IoT) sensors for analyzing body parameters, such as average‐accuracy analysis, tracking performance, work‐offloading wage and possibility analysis, power‐consumption analysis, and reliability‐ratio analysis. In the healthcare department, data storing/collection are done by using artificial intelligence (AI) based cognitive factor tools use wearing sensors for control where cloud support internet of things (IoT) are introduced. In spite of the fact that several current set of rules with deep‐learning patterns shows hopeful outcomes in sensor facts and statistics resolution for identification of mortal attitudes, appreciation of uncertainty in cognitive factor is yet harder and few common processes are more complicated. On account of the reserved computing ability, W‐IoT devices want most effective use of network to handle the maintenance and improvement of physical‐ and mental‐health information practically and effectively for feasible interpretation. Therefore, a modern ethical mobility determination is introduced that fully worked on improved Bayesian convolution network (IBCN), which permits to deliver everyone and every knowledgeable process to copy information via either basic telecommunications technique or lower ability back diffraction informing with cloud facilitation. IBCN consists of an adjustment of the pattern's dormant fickle is planned and the shape are uprooted using fold layers, the achievement of the W‐IoT has been uplifted by assembling a volatile auto‐encoder with a grade sound genuine classifier. In addition, the IBCN provides assistance to locate the privacy consignment where EDL is developed with a useful offloading AI technique. These explorative outcomes display the collection of information from the W‐IoT sensors side is impressionable to various productions of doubtfulness, such as noise and reliability. In addition, lab‐scale explorative solution on sick person's hygiene info grouping appropriateness has been displayed with the help of IBCN, which is a usual designed with the help of cognitive radio (CR) learning, DL‐SAR and cloud‐assisted agent‐based smart environment (CASE).","10.1002/9781119861850.ch18","Wiley-IEEE Press eBook Chapters","2023","","IEEE"
"AEPRS-EF: Advanaced Eelectricity Plan Recommendation System utilizing Efficient Fuzzy Logic","this paper was to propose novel advanced electricity plan recommendation utilizing Efficient Fuzzy logic algorithms (AEPRS-EF). To solve the problems related to sparsity, recommendation accuracy, & computation efficiency. For sparsity, we introduced the advanced Efficient Fuzzy logic under which we applied the set of fuzzy rules to optimize the recommendation process. For the accuracy & computation efficiency, we propose the advanced relevance feedback approach which may automatically recommends the advanced electricity planes based on end user feedbacks on previous recommendation results for the same user. The main goal & objectives is to propose & evaluate a unique data mining-based advanced electricity plan extraction framework. This research investigates the use of an advanced recommender system as compare to existing method, an AI-based rapid creation technique, to the task regards recommending power plans for a single private customer. Five basic advanced measures, including Normalized Discontinued Cumulative Gain (NDCG), Precision, Recall, Area under Precision & Recall Curve (AUPR), & Average Recommendation Time, have been utilized to evaluate the performance regards method under this study (ART). We computed the following performance metrics for the top K suggestion outcomes.","10.1109/ASIANCON55314.2022.9908936","IEEE Conferences","2022","","IEEE"
"Beyond 160 applications of an expert system: key to a better usability","The most influential relevant thinkers have complained of the “poverty” of Expert Systems (ES) both in the past (Dreyfus and Dreyfus, 1986) and in recently studies as well (Müller and Bostrom, 2016). We developed our own AI-Based Expert System shell for rule-based and case-based reasoning three decades ago and now there are 160 Knowledge Engineering (KE) process behind us with this system. We hope that this experience give us the right to formulate an opinion about that what is the key to a better usability and user experience in understanding of the result of the decision making process. While we do not think that ES is an omnipotent panacea, we also do not think that its applicability is determined only by the shell capabilities. However, one ability is essential; namely, presenting the result as simply as possible in order to that the decision-maker also can understand it. Our finding is that ES shells are only able to be transparent if they are designed by people who have an understanding of the human thinking process instead of a strong math-based software development approach.","10.1109/CogInfoCom50765.2020.9237822","IEEE Conferences","2020","","IEEE"
"Influence-Based Nano Fuzzy Swarm Oxygen Deficiency Detection and Therapy","Oxygen deficiency is a serious health problem that may occur as a result of many diseases. In this article, we present an influence-based nano fuzzy swarm (INFS) for oxygen deficiency detection and therapy using a swarm of oxygen carrier nanomachines operating in three cognitive fields of control, influence, and interest. In particular, we propose a long short-term memory (LSTM) deep neural network for detecting apnea by analyzing the irregular peripheral oxygen saturation (SpO2) signal. Using the proposed sleep-in-the-loop strategy and the desaturated blood biomarkers, including oxygen and hydrogen ion concentrations, an in-silico multithreshold nano fuzzy swarm noninvasive therapeutic method is then performed. We also analytically prove the stability of the INFS using swarm control theory. We apply our strategy to sleep apnea, as one of the most common instances of oxygen deficiency. Furthermore, we compare the accuracy of INSF by using LSTM, bidirectional LSTM (BiLSTM), multilayer perceptron (MLP), convolutional neural network (CNN), and support vector machines (SVM). The detection and therapy results are then compared with other apnea detection methods. The input variables and structure of INSF, i.e., the number of rules and width of membership functions, are studied in terms of robustness to noise. As the results show, the proposed artificial intelligence (AI)-based noninvasive nano detection and therapy method could outperform the competing approaches in treating oxygen deficiency emergencies such as apnea.","10.1109/TSMC.2023.3252899","IEEE Journals","2023","","IEEE"
"A Bus Arrival Time Prediction Method Based on Position Calibration and LSTM","Bus arrival time prediction not only provides convenience for passengers, but also helps to improve the efficiency of intelligent transportation system. Unfortunately, the low precision of bus-mounted GPS system, lack of real-time traffic information and poor performance of prediction model lead to low estimation accuracy - greatly influence bus service performance. Hence, in this paper, a GPS calibration method is put forward, while projection rules of specific road shapes are discussed. Moreover, two traffic factors, travel factor and dwelling factor, are defined to express real-time traffic state. Then, considering both historic data and real-time traffic condition, a hybrid dynamic BAT prediction factor, which achieves accuracy enhancement by taking into account traffic flow evaluation results and GPS position calibration, is defined. A LSTM training model is construct to realize BAT prediction. Experiment results demonstrate that our technique can provide a higher level of accuracy compared to methods based on traditional time-of-arrival techniques, especially in the accuracy of multi-stops BAT prediction.","10.1109/ACCESS.2020.2976574","IEEE Journals","2020","","IEEE"
"Title","Abstract","DOI","Document Type","Year","Index Keywords","Scopus"
"ARTIFICIAL INTELLIGENCE-ENABLED KNOWLEDGE MANAGEMENT USING A MULTIDIMENSIONAL ANALYTICAL FRAMEWORK OF VISUALIZATIONS","To better manage human resources (HR), companies are increasingly incorporating artificial intelligence (AI) and other AI-based tools into their HR management (HRM) strategies, at a universal scale. Companies on a global scale, highlight the employment prospects and use of resources, business judgment, and make predictions using machine learning approaches. This work aims at the situation that the human resource department faces high employee turnover in the company especially some experienced employees leave. The termination of an employee is predicted by using an enhanced ID3 decision tree with ABC rule miner. The best-classifying attributes are chosen by ID3 and association rules are mined to generate an enhanced decision tree to perform classification. It is then passed to the regressor model to make prediction. Gradient descent optimizer is used for optimizing the proposed machine learning model. Predictive analysis is done in HR dataset v-14 by visualizing and analyzing and exploiting the behavioral relationship among the attributes. The variables of employee termination are predicted by a data-driven predictive analysis from the performance measure metrics. © 2023","10.1016/j.ijcce.2023.06.003","Article","2023","Decision trees; Gradient methods; Knowledge management; Machine learning; Optimization; Predictive analytics; ABC rule miner; Employee turnover; Global scale; Gradient-descent; Human resources management; Iterative decision tree; Machine learning approaches; Machine learning models; Management strategies; Random forests; Human resource management","Scopus"
"A scoping review of artificial intelligence-based methods for diabetes risk prediction","The increasing prevalence of type 2 diabetes mellitus (T2DM) and its associated health complications highlight the need to develop predictive models for early diagnosis and intervention. While many artificial intelligence (AI) models for T2DM risk prediction have emerged, a comprehensive review of their advancements and challenges is currently lacking. This scoping review maps out the existing literature on AI-based models for T2DM prediction, adhering to the PRISMA extension for Scoping Reviews guidelines. A systematic search of longitudinal studies was conducted across four databases, including PubMed, Scopus, IEEE-Xplore, and Google Scholar. Forty studies that met our inclusion criteria were reviewed. Classical machine learning (ML) models dominated these studies, with electronic health records (EHR) being the predominant data modality, followed by multi-omics, while medical imaging was the least utilized. Most studies employed unimodal AI models, with only ten adopting multimodal approaches. Both unimodal and multimodal models showed promising results, with the latter being superior. Almost all studies performed internal validation, but only five conducted external validation. Most studies utilized the area under the curve (AUC) for discrimination measures. Notably, only five studies provided insights into the calibration of their models. Half of the studies used interpretability methods to identify key risk predictors revealed by their models. Although a minority highlighted novel risk predictors, the majority reported commonly known ones. Our review provides valuable insights into the current state and limitations of AI-based models for T2DM prediction and highlights the challenges associated with their development and clinical integration. © 2023, Springer Nature Limited.","10.1038/s41746-023-00933-5","Review","2023","Diagnosis; Forecasting; Medical imaging; Search engines; Early diagnosis; Early intervention; Health complications; Intelligence models; Predictive models; Risk predictions; Scoping review; Systematic searches; Type 2 diabetes mellitus; Unimodal; artificial intelligence; data base; diabetes mellitus; diagnostic imaging; electronic health record; human; machine learning; multiomics; non insulin dependent diabetes mellitus; prediction; Review; risk assessment; search engine; Artificial intelligence","Scopus"
"Impact of AI assistance on student agency","AI-powered learning technologies are increasingly being used to automate and scaffold learning activities (e.g., personalised reminders for completing tasks, automated real-time feedback for improving writing, or recommendations for when and what to study). While the prevailing view is that these technologies generally have a positive effect on student learning, their impact on students’ agency and ability to self-regulate their learning is under-explored. Do students learn from the regular, detailed and personalised feedback provided by AI systems, and will they continue to exhibit similar behaviour in the absence of assistance? Or do they instead continue to rely on AI assistance without learning from it? To contribute to filling this research gap, we conducted a randomised controlled experiment that explored the impact of AI assistance on student agency in the context of peer feedback. With 1625 students across 10 courses, an experiment was conducted using peer review. During the initial four-week period, students were guided by AI features that utilised techniques such as rule-based suggestion detection, semantic similarity, and comparison with previous comments made by the reviewer to enhance their submissions if the feedback provided was deemed insufficiently detailed or general in nature. Over the following four weeks, students were divided into four different groups: control (AI) received prompts, (NR) received no prompts, (SR) received self-monitoring checklists in place of AI prompts, and (SAI) had access to both AI prompts and self-monitoring checklists. Results of the experiment suggest that students tended to rely on rather than learn from AI assistance. If AI assistance was removed, self-regulated strategies could help fill the gap but were not as effective as AI assistance. Results also showed that hybrid human-AI approaches that complement AI assistance with self-regulated strategies (SAI) were not more effective than AI assistance on its own. We conclude by discussing the broader benefits, challenges and implications of relying on AI assistance in relation to student agency in a world where we learn, live and work with AI. © 2023 The Author(s)","10.1016/j.compedu.2023.104967","Article","2024","Educational technology; Feedback; Scaffolds; Semantics; AI in education; Detailed feedbacks; Learn+; Learning Activity; Learning technology; Peer feedback; Real-time feedback; Self-monitoring; Student agency; Student learning; Students","Scopus"
"A Systematic Survey of Data Augmentation of ECG Signals for AI Applications","AI techniques have recently been put under the spotlight for analyzing electrocardiograms (ECGs). However, the performance of AI-based models relies on the accumulation of large-scale labeled datasets, which is challenging. To increase the performance of AI-based models, data augmentation (DA) strategies have been developed recently. The study presented a comprehensive systematic literature review of DA for ECG signals. We conducted a systematic search and categorized the selected documents by AI application, number of leads involved, DA method, classifier, performance improvements after DA, and datasets employed. With such information, this study provided a better understanding of the potential of ECG augmentation in enhancing the performance of AI-based ECG applications. This study adhered to the rigorous PRISMA guidelines for systematic reviews. To ensure comprehensive coverage, publications between 2013 and 2023 were searched across multiple databases, including IEEE Explore, PubMed, and Web of Science. The records were meticulously reviewed to determine their relevance to the study’s objective, and those that met the inclusion criteria were selected for further analysis. Consequently, 119 papers were deemed relevant for further review. Overall, this study shed light on the potential of DA to advance the field of ECG diagnosis and monitoring. © 2023 by the authors.","10.3390/s23115237","Article","2023","Artificial Intelligence; Databases, Factual; Electrocardiography; PubMed; Classification (of information); Large dataset; Search engines; AI applications; AI in cardiology; AI techniques; Data augmentation; Electrocardiogram augmentation; Electrocardiogram signal; Labeled dataset; Large-scales; Modeling data; Performance; artificial intelligence; electrocardiography; factual database; Medline; Electrocardiograms","Scopus"
"An ontology-based approach to engineering ethicality requirements","In a world where Artificial Intelligence (AI) is pervasive, humans may feel threatened or at risk by giving up control to machines. In this context, ethicality becomes a major concern to prevent AI systems from being biased, making mistakes, or going rogue. Requirements Engineering (RE) is the research area that can exert a great impact in the development of ethical systems by design. However, proposing concepts, tools and techniques that support the incorporation of ethicality into the software development processes as explicit requirements remains a great challenge in the RE field. In this paper, we rely on Ontology-based Requirements Engineering (ObRE) as a method to elicit and analyze ethicality requirements (‘Ethicality requirements’ is adopted as a name for the class of requirements studied in this paper by analogy to other quality requirements studied in software engineering, such as usability, reliability, and portability, etc. The use of this term (as opposed to ‘ethical requirements’) highlights that they represent requirements for ethical systems, analogous to how ‘trustworthiness requirements’ represent requirements for trustworthy systems. To put simply: the predicates ‘ethical’ or ‘trustworthy’ are not meant to be predicated over the requirements themselves). ObRE applies ontological analysis to ontologically unpack terms and notions that are referred to in requirements elicitation. Moreover, this method instantiates the adopted ontology and uses it to guide the requirements analysis activity. In a previous paper, we presented a solution concerning two ethical principles, namely Beneficence and Non-maleficence. The present paper extends the previous work by targeting two other important ethicality principles, those of Explicability and Autonomy. For each of these new principles, we do ontological unpacking of the relevant concepts, and we present requirements elicitation and analysis guidelines, as well as examples in the context of a driverless car case. Furthermore, we validate our approach by analysing the requirements elicitation made for the driverless car case in contrast with a similar case, and by assessing our method’s coverage w.r.t European Union guidelines for Trustworthy AI. © 2023, The Author(s).","10.1007/s10270-023-01115-3","Article","2023","Computer software portability; Ethical technology; Ontology; Software design; Software reliability; Artificial intelligence systems; Driverless cars; Ethical system; Ethicality requirement; Foundational ontologies; Ontological analysis; Ontology-based; Requirement analysis; Requirement engineering; Requirements elicitation; Requirements engineering","Scopus"
"Mitigating Adversarial Norm Training with Moral Axioms","This paper addresses the issue of adversarial attacks on ethical AI systems. We investigate using moral axioms and rules of deontic logic in a norm learning framework to mitigate adversarial norm training. This model of moral intuition and construction provides AI systems with moral guard rails yet still allows for learning conventions. We evaluate our approach by drawing inspiration from a study commonly used in moral development research. This questionnaire aims to test an agent's ability to reason to moral conclusions despite opposed testimony. Our findings suggest that our model can still correctly evaluate moral situations and learn conventions in an adversarial training environment. We conclude that adding axiomatic moral prohibitions and deontic inference rules to a norm learning model makes it less vulnerable to adversarial attacks. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2023","Artificial intelligence; Ethical technology; AI systems; Axiomatics; Deontic; Deontic Logic; Guard-rails; Inference rules; Learn+; Learning frameworks; Learning models; Moral development; Learning systems","Scopus"
"AI-Enabled Electrocardiogram Analysis for Disease Diagnosis","Contemporary methods used to interpret the electrocardiogram (ECG) signal for diagnosis or monitoring are based on expert knowledge and rule-centered algorithms. In recent years, with the advancement of artificial intelligence, more and more researchers are using deep learning (ML) and deep learning (DL) with ECG data to detect different types of cardiac issues as well as other health problems such as respiration rate, sleep apnea, and blood pressure, etc. This study presents an extensive literature review based on research performed in the last few years where ML and DL have been applied with ECG data for many diagnoses. However, the review found that, in published work, the results showed promise. However, some significant limitations kept that technique from implementation in reality and being used for medical decisions; examples of such limitations are imbalanced and the absence of standardized dataset for evaluation, lack of interpretability of the model, inconsistency of performance while using a new dataset, security, and privacy of health data and lack of collaboration with physicians, etc. AI using ECG data accompanied by modern wearable biosensor technologies has the potential to allow for health monitoring and early diagnosis within reach of larger populations. However, researchers should focus on resolving the limitations. © 2023 by the authors.","10.3390/asi6050095","Review","2023","","Scopus"
"An Overview of Artificial Intelligence Ethics","Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.  © 2020 IEEE.","10.1109/TAI.2022.3194503","Article","2023","Ethical technology; Artificial intelligence ethic; Autonomous driving; Ethical issues; Ethical principles; Ethical theories; Government; Guideline; Privacy; Security; Systematic; Industrial robots","Scopus"
"A deep learning anomaly detection framework with explainability and robustness","The prevalence of encrypted Internet traffic has resulted in a pressing need for advanced analysis techniques for traffic analysis and classification. Traditional rule-based and signature-based approaches have been hindered by the introduction of network encryption methods. With the emergence of machine learning (ML) and deep learning (DL), several preliminary works have been developed for anomaly detection in encrypted network traffic. However, complex Artificial Intelligence (AI) models like neural networks lack explainability, limiting the understanding of their predictions. To address this limitation, eXplainable Artificial Intelligence (XAI) has emerged, aiming to provide users with a rationale for understanding AI system outputs and fostering trust. However, existing explainable frameworks still lack comprehensive support for adversarial attacks and defenses. In this paper, we present Montimage AI Platform (MAIP), a new GUI-based deep learning framework for malicious traffic detection and classification combined with its ability of explaining the decision of the model. We employ popular XAI methods to interpret the prediction of the developed deep learning model. Furthermore, we perform adversarial attacks to assess the accountability and robustness of our model via different quantifiable metrics. We perform extensive experiments with both public and private network traffic. The experimental results demonstrate that our model achieves high performance and robustness, and its outcomes align closely with the domain knowledge. © 2023 Owner/Author.","10.1145/3600160.3605052","Conference paper","2023","Anomaly detection; Cryptography; Deep learning; Domain Knowledge; Learning systems; Malware; Adversarial attack; Deep learning; Encrypted traffic; Encrypted traffic analyse; Explainable artificial intelligence; Malware detection; Network traffic; Networks security; Traffic analysis; Traffic classification; Network security","Scopus"
"The Building Blocks of a Responsible Artificial Intelligence Practice: An Outlook on the Current Landscape","For artificial intelligence (AI)-driven companies, awareness of the urgency of the responsible application of AI became essential with increased interest from different stakeholders. Responsible AI (RAI) has emerged as a practice to guide the design, development, deployment, and use of AI systems to ensure a benefit to users and those impacted by the systems' outcomes. This benefit is achieved through trustworthy models and strategies that assimilate ethical principles to ensure compliance with regulations and standards for long-term trust. However, RAI comes with the challenge of lack of standardization when it comes to which principles to adopt, what they mean, and how they can be operationalized. This article aims to bridge the gap between principles and practice through a study of different approaches taken in the literature and the proposition of a foundational framework.  © 2001-2011 IEEE.","10.1109/MIS.2023.3320438","Article","2023","Ethical technology; Regulatory compliance; 'current; AI systems; Applications of AI; Building blockes; Design development; Design use; Guideline; Privacy; Research and development; Special issue and section; Intelligent systems","Scopus"
"RE-centric Recommendations for the Development of Trustworthy(er) Autonomous Systems","Complying with the EU AI Act (AIA) guidelines while developing and implementing AI systems will soon be mandatory within the EU. However, practitioners lack actionable instructions to operationalise ethics during AI systems development. A literature review of different ethical guidelines revealed inconsistencies in the principles addressed and the terminology used to describe them. Furthermore, requirements engineering (RE), which is identified to foster trustworthiness in the AI development process from the early stages was observed to be absent in a lot of frameworks that support the development of ethical and trustworthy AI. This incongruous phrasing combined with a lack of concrete development practices makes trustworthy AI development harder. To address these concerns, we formulated a comparison table for the terminology used and the coverage of the ethical AI principles in major ethical AI guidelines. We then examined the applicability of ethical AI development frameworks for performing effective RE during the development of trustworthy AI systems. A tertiary review and meta-analysis of literature discussing ethical AI frameworks revealed their limitations when developing trustworthy AI. Based on our findings, we propose recommendations to address such limitations during the development of trustworthy AI.  © 2023 Owner/Author.","10.1145/3597512.3599697","Conference paper","2023","Ethical technology; Terminology; AI systems; Autonomous system; Ethical AI; EU AI act; Framework; Guideline; Limitation; Recommendation; Requirement engineering; Trustworthy AI; Requirements engineering","Scopus"
"Morphological analysis of historical lanscapes based on cultural DNA approach","Recent trends in landscape architecture investigate new approaches, methods, and technologies to understand, monitor, manage, continuity, and sustainably develop heritage landscapes. Cultural DNA (CD) represents designs' transferable geometric, behavioural and functional properties. The morphological structure of Persian historical gardens possesses discoverable hidden patterns, computable through the CD's mathematical and computational models. This study aims to investigate and discover effective parameters in the spatial structure of historical Persian gardens using Space Syntax. Six Persian Gardens were surveyed, and spatial structures were analysed using DepthMap10 software. The results show that these spaces follow meaningful mathematical patterns and rules that can be formulated in the context of generative processes and generalized for the evolutionary continuity of gardens. However, further research is proposed to develop more advanced computational methods, such as artificial intelligence (AI) algorithms and AI-based decision support tools, to help to generate design scenarios and to transmit culture through the design process. © 2023","10.1016/j.daach.2023.e00277","Article","2023","","Scopus"
"Trustworthy Recommender Systems: Technical, Ethical, Legal, and Regulatory Perspectives","This tutorial provides an interdisciplinary overview about the topics of fairness, non-discrimination, transparency, privacy, and security in the context of recommender systems. These are important dimensions of trustworthy AI systems according to European policies, but also extend to the global debate on regulating AI technology. Since we strongly believe that the aforementioned aspects require more than merely technical considerations, we discuss these topics also from ethical, legal, and regulatory points of views, intertwining different perspectives. The main focus of the tutorial is still on presenting technical solutions that aim at addressing the mentioned topics of trustworthiness. In addition, the tutorial equips the mostly technical audience of RecSys with the necessary understanding of the social and ethical implications of their research and development, and of recent ethical guidelines and regulatory frameworks. © 2023 Owner/Author.","10.1145/3604915.3609497","Conference paper","2023","Ethical technology; Network security; AI systems; AI Technologies; Ethical implications; Privacy and security; Regulatory frameworks; Research and development; Social implication; Technical solutions; Recommender systems","Scopus"
"Optimizing flexural strength of fused deposition modelling using supervised machine learning algorithms","Due to its distinct production paradigm, additive manufacturing (AM) is positioned to bring about a revolution. It presents the possibility of on-demand, decentralized, and mass-customizable manufacturing. However, several issues related to design principles, standardization, and quality control arise from not only the complexity of production systems but also the need for increasingly complicated and high-quality goods. Artificial Intelligence (AI)-based algorithms, which can effectively monitor quality, optimize processes, model complex systems, and manage energy, is essential in addressing the difficulties. In the present work, we have used three supervised machine learning regression-based algorithms, i.e., XG Boost, Random Forest, and Decision Trees, to determine the Flexural Strength of the Fused Deposition Modeling specimen. The results showed that the XG Boost algorithm resulted in the highest coefficient of determination value of 0.77. Supervised machine learning classification-based algorithms such as the Stochastic Gradient Descent (SGD) algorithm, Decision Tree, and Random Forest algorithm is used to determine good and bad flexural strength specimens. The result showed that the SGD algorithm achieved the highest F1 score of 0.85. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.","10.1007/s41870-023-01329-0","Article","2023","","Scopus"
"Using AI to measure Parkinson’s disease severity at home","We present an artificial intelligence (AI) system to remotely assess the motor performance of individuals with Parkinson’s disease (PD). In our study, 250 global participants performed a standardized motor task involving finger-tapping in front of a webcam. To establish the severity of Parkinsonian symptoms based on the finger-tapping task, three expert neurologists independently rated the recorded videos on a scale of 0–4, following the Movement Disorder Society Unified Parkinson’s Disease Rating Scale (MDS-UPDRS). The inter-rater reliability was excellent, with an intra-class correlation coefficient (ICC) of 0.88. We developed computer algorithms to obtain objective measurements that align with the MDS-UPDRS guideline and are strongly correlated with the neurologists’ ratings. Our machine learning model trained on these measures outperformed two MDS-UPDRS certified raters, with a mean absolute error (MAE) of 0.58 points compared to the raters’ average MAE of 0.83 points. However, the model performed slightly worse than the expert neurologists (0.53 MAE). The methodology can be replicated for similar motor tasks, providing the possibility of evaluating individuals with PD and other movement disorders remotely, objectively, and in areas with limited access to neurological care. © 2023, Springer Nature Limited.","10.1038/s41746-023-00905-9","Article","2023","Artificial intelligence; Artificial intelligence systems; Disease ratings; Disease severity; Finger tapping; Mean absolute error; Motor performance; Motor tasks; Movement disorders; Rating scale; WebCams; adult; aged; Article; artificial intelligence; controlled study; disease severity assessment; feature extraction; female; finger tapping test; home care; human; image quality; information processing; interrater reliability; major clinical study; male; MDS-Unified Parkinson Disease Rating Scale; mean absolute error; middle aged; motor performance; neurologist; Parkinson disease; very elderly; videorecording; Diseases","Scopus"
"Telehealth interventions during COVID-19 pandemic: A scoping review of applications, challenges, privacy and security issues","Background The COVID-19, caused by the SARS-CoV-2 virus, proliferated worldwide, leading to a pandemic. Many governmental and non-governmental organisations and research institutes are contributing to the COVID-19 fight to control the pandemic. Motivation Numerous telehealth applications have been proposed and adopted during the pandemic to combat the spread of the disease. To this end, powerful tools such as artificial intelligence (AI)/robotic technologies, tracking, monitoring, consultation apps and other telehealth interventions have been extensively used. However, there are several issues and challenges that are currently facing this technology. Objective The purpose of this scoping review is to analyse the primary goal of these techniques; document their contribution to tackling COVID-19; identify and categorise their main challenges and future direction in fighting against the COVID-19 or future pandemic outbreaks. Methods Four digital libraries (ACM, IEEE, Scopus and Google Scholar) were searched to identify relevant sources. Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) was used as a guideline procedure to develop a comprehensive scoping review. General telehealth features were extracted from the studies reviewed and analysed in the context of the intervention type, technology used, contributions, challenges, issues and limitations. Results A collection of 27 studies were analysed. The reported telehealth interventions were classified into two main categories: AI-based and non-AI-based interventions; their main contributions to tackling COVID-19 are in the aspects of disease detection and diagnosis, pathogenesis and virology, vaccine and drug development, transmission and epidemic predictions, online patient consultation, tracing, and observation; 28 telehealth intervention challenges/issues have been reported and categorised into technical (14), non-technical (10), and privacy, and policy issues (4). The most critical technical challenges are: network issues, system reliability issues, performance, accuracy and compatibility issues. Moreover, the most critical non-technical issues are: the skills required, hardware/software cost, inability to entirely replace physical treatment and people's uncertainty about using the technology. Stringent laws/regulations, ethical issues are some of the policy and privacy issues affecting the development of the telehealth interventions reported in the literature. Conclusion This study provides medical and scientific scholars with a comprehensive overview of telehealth technologies' current and future applications in the fight against COVID-19 to motivate researchers to continue to maximise the benefits of these techniques in the fight against pandemics. Lastly, we recommend that the identified challenges, privacy, and security issues and solutions be considered when designing and developing future telehealth applications.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","10.1136/bmjhci-2022-100676","Review","2023","Artificial Intelligence; COVID-19; Humans; Pandemics; Privacy; Reproducibility of Results; SARS-CoV-2; Telemedicine; SARS-CoV-2 vaccine; accuracy; adult; artificial intelligence; confusion (uncertainty); coronavirus disease 2019; disease transmission; drug development; health care cost; health care policy; health legislation; human; information security; library; medical ethics; pathogenesis; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; privacy; reliability; Review; Scopus; search engine; skill; systematic review; teleconsultation; telehealth; virology; coronavirus disease 2019; pandemic; procedures; reproducibility; Severe acute respiratory syndrome coronavirus 2; telemedicine","Scopus"
"The European AI liability directives – Critique of a half-hearted approach and lessons for the future","The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a “Brussels effect” in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI). © 2023 Philipp Hacker","10.1016/j.clsr.2023.105871","Article","2023","Artificial intelligence; Crime; Defects; Personal computing; Risk assessment; Sustainable development; AI act; AI systems; ChatGPT; EU law; Generative model; Innovation; Large generative AI model; Products liabilities; Strict liability; Unsolved problems; Product liability","Scopus"
"GDPR-compliant AI-based automated decision-making in the world of work","Artificial Intelligence is spreading fast in our everyday life and the world of work is no exception. AI is increasingly shaping the employment context: such emerging areas are augmented and automated decision-making. As AI-based decision-making is fuelled by personal data, compliance with data protection frameworks is inevitable. Even though automated decision-making is already addressed by the European norms on data protection – especially the GDPR –, their application in the world of work raises specific questions. The paper examines, in the light of the ‘general’ data protection background, what specific data protection challenges are raised in the field of AI-based automated decision-making in the context of employment. As a result of the research, the paper provides a detailed overview on the European legal framework on the data protection aspects of AI-based automated decision-making in the employment context. It identifies the main challenges, such as the applicability of the existing legal framework to the current use-cases and the specific questions relating to the lawful bases in the world of work, and provides guidelines on how to address these challenges. © 2023 Adrienn Lukács and Szilvia Váradi","10.1016/j.clsr.2023.105848","Article","2023","Automation; Data privacy; Decision making; Employment; Laws and legislation; 'current; Automated decision making; Decisions makings; GDPR; IT Identify; Labor laws; Legal frameworks; Artificial intelligence","Scopus"
"Identifying presence of cybersickness symptoms using AI-based predictive learning algorithms","Cybersickness (CS) affects a large proportion of virtual reality (VR) users causing a combination of nausea, headaches and dizziness which would create barriers to the users, VR designers/developers and the stakeholders in the production industry. Although design principles suggest methods to avoid CS, challenges remain as new demands and systems continue to penetrate the competitive market. The dilemma is whether to use VR technology by experiencing the ultimate virtual world using a head-mounted display (HMD) with possible CS triggers or to avoid the triggers by avoiding using VR. With the huge success and potential in the entertainment industry, it is very important to focus on the solutions to handling CS dilemmas. Therefore, the main observation for the developers is to have a guide around the set of established design principles aiming to broadly reduce CS. In this paper, we provide a method to apply artificial intelligence (AI) techniques and use machine learning (ML) algorithms including support vector machines (SVMs), decision trees (DTs) and K-nearest neighbours (KNNs) to predict CS outcomes. Based on our findings, we have observed that DT and SVM surpassed KNN in test accuracy. Additionally, DT exhibited better results than both SVM and KNN in train accuracy. By exploiting the power of ML, developers will be able to predict the potential occurrence of CS while developing VR projects to find ways to alleviate CS more effectively. © 2023, The Author(s).","10.1007/s10055-023-00813-z","Article","2023","Helmet mounted displays; Learning algorithms; Learning systems; Nearest neighbor search; Support vector machines; Virtual reality; Artificial intelligence; Cybersickness; Decision tree; Head-mounted display; Head-mounted-displays; K-near neighbor; Machine learning; Machine-learning; Nearest-neighbour; Support vector machine; Support vectors machine; Virtual reality; Decision trees","Scopus"
"Diagnostic Test Accuracy of artificial intelligence-assisted detection of acute coronary syndrome: A systematic review and meta-analysis","Background: Artificial intelligence (AI) has potential uses in healthcare including the detection of health conditions and prediction of health outcomes. Past systematic reviews had reviewed the accuracy of artificial neural networks (ANN) on Electrocardiogram (ECG) readings but that of other AI models on other Acute Coronary Syndrome (ACS) detection tools remains unclear. Methods: Nine electronic databases were searched from 2012 to 31 August 2022 including grey literature search and hand searching of references of included articles. Risk of bias was assessed by two independent reviewers using the Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2). Test characteristics namely true positives, false positives, true negatives, and false negatives were extracted from all included articles into a 2x2 table. Study-specific estimates of sensitivity and specificity were pooled using hierarchical summary receiver operating characteristic (HSROC) model and displayed using a forest plot and HSROC curve. Results: 66 studies were included in the review. A total of 518,931 patients were included whose mean ages varied from 32.62 to 70 years old. In 66 studies, the sensitivity and specificity of AI-based detection for ACS screening ranged from 64 % to 100 % and 65 %–100 %, respectively. The overall quality of evidence was low due to the inclusion of case-control studies. Conclusion: Results of the study inform the potential of using AI-assisted ACS detection for accurate diagnosis and prompt treatment for ACS. Adherence to the Standards for Reporting of Diagnostic Accuracy (STARD) guideline and having more cohort studies for future Diagnostic Test Accuracy (DTA) studies are necessary to improve the quality of evidence of AI-based detection of ACS. © 2023 Elsevier Ltd","10.1016/j.compbiomed.2023.107636","Review","2023","Acute Coronary Syndrome; Adult; Aged; Artificial Intelligence; Diagnostic Tests, Routine; Humans; Middle Aged; ROC Curve; Sensitivity and Specificity; Electrocardiography; Forestry; Neural networks; Quality control; Risk assessment; Accuracy study; Acute coronary syndrome; Coronary syndromes; Diagnostic accuracy; Diagnostic tests; Machine-learning; Meta-analysis; Sensitivity and specificity; Systematic Review; Test accuracy; acute coronary syndrome; artificial intelligence; cardiac patient; diagnostic accuracy; diagnostic test accuracy study; electrocardiogram; human; major clinical study; meta analysis; practice guideline; predictive value; Quality Assessment of Diagnostic Accuracy Studies; Review; risk assessment; sensitivity and specificity; systematic review; adult; aged; artificial intelligence; diagnostic test; middle aged; receiver operating characteristic; Machine learning","Scopus"
"The smart and secured AI-powered strategies for optimizing processes in multi-vendor business applications","The development of artificial intelligence (AI)-powered processes in multivendor business applications has created significant opportunities to optimize resources, streamline operations, and reduce costs. However, deploying AI in multi-vendor business applications presents a unique set of challenges, including the potential for data privacy and security issues. To ensure the success of AI-enabled processes, organizations should implement best practices for proper data protection and secure AI-powered strategies. With the proper implementation of data security protocols and usage strategies, organizations can harness the potential of AI-powered processes in multivendor business applications to drive greater efficiency and cost savings. This includes creating greater process efficiency, reducing manual labor costs, and improving customer experiences. This will also enable organizations to remain competitive in the rapidly changing business landscape. © 2024 Walter de Gruyter GmbH, Berlin/Boston.","10.1515/9783111323749-014","Book chapter","2023","","Scopus"
"Configurable Intelligent Design Based on Hierarchical Imitation Models","The deterministic AI system under review is an alternative to neural-network-based machine learning. In its application fields, which are science, technology, engineering, and business, the implementation of rule-based AI systems leads to benefits such as accuracy and correctness of design, and personalization of the process itself and the results. An algorithmic AI suite is based on design and logical imitation models alone, without creating and/or using Big Data and knowledge bases. Excessive complexity of configuration and high design resource capacity, which are inherent in deterministic systems, are balanced by a special methodology. A hierarchical modeling approach gives a quasi-dynamic network effect, symmetric to the analogous effect in neural networks. System performance is improved by deterministic reference training capable of modifying imitation models in online interaction with users. Such training, which serves as an alternative to neural machine learning, can be implemented by means of experimental partially empirical algorithms and system–user dialogues to build reference model libraries (portfolios). Partially empirical algorithms based on experimental design methods and system user dialogues are used to create reference model libraries (portfolios) that form a deterministic training system, which can be an alternative to neural machine learning. Estimated resources can be saved by using modified optimization techniques and by controlling the computational complexity of the algorithms. Since the proposed system in the considered layout has no analogues, and the relevant research and practical knowledge are extremely limited, special methods are required to implement this project. A gradual, phased implementation process involves the step-by-step formation of sets of algorithms with verification tests at each stage. Each test is performed using an iteration method, and each test includes test, tweak, and modification cycles. Final testing should lead to the development of an AI algorithm package, including related methodological and working papers. © 2023 by the authors.","10.3390/app13137602","Review","2023","","Scopus"
"Anticipatory regulatory instruments for AI systems: A comparative study of regulatory sandbox schemes","Anticipatory regulatory instruments are pre-emptive approaches to identify and anticipate risks arising from new technologies. They can also act as indicators of 'pro-innovation' economic support for digital technologies. The extent to which regulatory agencies can fulfil their regulatory remit, aimed at the protection of the public good, and signal support for innovative and disruptive technologies is an open policy question. Regulatory sandbox schemes are comparatively new anticipatory tools, operating within a small number of regulators, and their potential to assess contextual or cross-sectoral risk is unclear. However, emerging proposals for the regulation of AI increasing feature various models of regulatory sandboxes often aligned to the need to reduce access barriers for SMEs and innovators. Examples include the European Commission's Proposal for a regulation concerning AI [3] and the recent United Kingdom AI White Paper, AI Regulation: A Pro-Innovation Approach [8]. Disentangling the causal dimensions of why regulatory sandboxes are proposed to regulate AI, and their utility as tools of pre-emptive risk assessment are my core research questions. The regulation of emerging digital technologies present challenges for regulators and governments in monitoring rapid global developments and in anticipating novel forms of risk [9]. Nesta introduced the term anticipatory regulation, and such approaches potentially provide 'a set of behaviours and tools - i.e., a way of working - that is intended to help regulators identify, build and test solutions to emerging challenges' [4]. Regulatory sandboxes are a prominent, and arguably the most widespread, example of such an anticipatory regulatory tool. Whilst there are varied definitions of regulatory sandbox schemes, existing schemes allow small-scale, live testing of innovations in a controlled environment under the supervision of a regulatory authority [6]. A small number of regulatory sandbox schemes are in operation within the UK operating within sectoral and cross-sectoral regulatory remits. However, empirical data and academic literature regarding the methodologies and operation of these current schemes, and literature exploring regulatory sandboxes more broadly, is scarce [7, 10]. The ontological focus of my work is critical realist, which accepts the external reality of the design and instrumental aims of sandbox schemes, whilst seeking to understand the underlying causes and drivers for their use and rapid promotion. To locate such causes and explanations it is necessary to examine existing schemes within the 'rules and norms' of their institutional context and structures [1, 2]. Institutional analysis will isolate the key dimensions of each scheme, consider the influence of the regulatory structures, and then test such analysis through empirical research with regulatory and policy actors. The core hypothesis of my research is that regulatory contexts, path dependencies and conceptions of risk are significant causal elements within existing sandbox schemes and, as such, may present a challenge when designing and deploying cross-sectoral sandbox schemes for AI systems. I have already undertaken analysis of the two regulatory sandbox schemes applying the Institutional Analysis and Development framework of Elinor Ostrom [5]. This analysis has highlighted significant dimensions of sandbox schemes including the role and forms of sectoral incentives for participants, how knowledge and conceptions of risk are shared and the potential role of participatory processes and stakeholders. I am drafting a forthcoming paper outlining a typology of incentives for existing regulatory sandbox schemes. I have included policy and wider sectoral stakeholders within my data collection to obtain perspectives regarding perceived utility, understandings, and conceptions of sandbox schemes. Incorporating collaborative processes and inclusive engagement with affected stakeholders is a key principle of anticipatory regulation [4]. The role and extent of such engagement within proposed sandbox schemes for AI is a further dimension of my research to consider how such processes may be developed and operationalised. This work is undertaken at a time of rapid progression within AI systems and in the development of proposed AI regulation and varied forms of decentralised AI governance. I hope that my research will provide understanding of the utility, and potential limitations, of sandboxes as a regulatory tool drawing upon data from existing practices. My work may also impact existing policy discussions around the role of sandbox schemes as risk assessment and information monitoring tools for regulators.  © 2023 Owner/Author.","10.1145/3600211.3604732","Conference paper","2023","Public policy; AI governance and regulation; AI systems; Anticipatory regulation; Comparatives studies; Digital technologies; Economic supports; Regulatory agencies; Regulatory sandbox; Risks assessments; Trustworthy AI; Risk assessment","Scopus"
"AI + Ethics Curricula for Middle School Youth: Lessons Learned from Three Project-Based Curricula","Artificial Intelligence (AI) is revolutionizing many industries and becoming increasingly ubiquitous in everyday life. To empower children growing up with AI to navigate society’s evolving sociotechnical context, we developed three middle school AI literacy curricula: Creative AI, Dancing with AI, and How to Train Your Robot. In this paper we discuss how we leveraged three design principles—active learning, embedded ethics, and low barriers to access – to effectively engage students in learning to create and critique AI artifacts. During the summer of 2020, we recruited and trained in-service, middle school teachers from across the United States to co-instruct online workshops with students from their schools. In the workshops, a combination of hands-on unplugged and programming activities facilitated students’ understanding of AI. As students explored technical concepts in tandem with ethical ones, they developed a critical lens to better grasp how AI systems work and how they impact society. We sought to meet the specified needs of students from a range of backgrounds by minimizing the prerequisite knowledge and technology resources students needed to participate. Finally, we conclude with lessons learned and design recommendations for future AI curricula, especially for K-12 in-person and virtual learning. © 2022, The Author(s).","10.1007/s40593-022-00298-y","Article","2023","Artificial intelligence; E-learning; Philosophical aspects; Students; Active Learning; Artificial intelligence; Artificial intelligence literacy; Constructionism; Creatives; Design Principles; Middle school; Online learning; Project-based curriculum; Sociotechnical; Curricula","Scopus"
"Explainable AI for DBA: Bridging the DBA's experience and machine learning in tuning database systems","Recently artificial intelligence techniques in the database community have become a driver for many database applications. The proposed solution adopting AI in the core database shows that incorporating AI improves the query processing and the self-tuning of database systems. In traditional systems, self-tuning database systems are commonly addressed with heuristics to suggest the physical structures (e.g., creation of indexes and materialized views) that enable the fastest execution of queries. However, existing designer tools do not explain/justify how the system behaves and the reasoning behind tuning activities. Moreover, these tools do not keep the database administrator (DBA) in the loop of the optimization process to trust some of the automatic tuning decisions. To address this problem, we introduce a framework called Explain-Tun that enables to predict and explain self-tuning actions with transparent strategy from historical data using two explicit models, that is, decision tree and random forests. First, we propose AI-based DBMS to explain how to select physical structures and provide decision rules extracted by machine learning (ML) as a designed plug-gable component. Second, a goal-oriented model to keep DBA in the loop of the optimization process in order to manipulate ML models as CRUD entities. Finally, we evaluate our approach on three use cases, results show that bridging the DBA's experience and ML make sense in tuning database systems. © 2023 John Wiley & Sons, Ltd.","10.1002/cpe.7698","Article","2023","Decision trees; Optimization; Query languages; Query processing; AI for DBMS; Artificial intelligence techniques; Database administrators; Explainability; Machine-learning; Physical structures; Self drivings; Self-driving DBMS; Selftuning; Transparency of self-tuning database; Machine learning","Scopus"
"Implementing AI Ethics: Making Sense of the Ethical Requirements","Society's increasing dependence on Artificial Intelligence (AI) and AI-enabled systems require a more practical approach from software engineering (SE) executives in middle and higher-level management to improve their involvement in implementing AI ethics by making ethical requirements part of their management practices. However, research indicates that most work on implementing ethical requirements in SE management primarily focuses on technical development, with scarce findings for middle and higher-level management. We investigate this by interviewing ten Finnish SE executives in middle and higher-level management to examine how they consider and implement ethical requirements. We use ethical requirements from the European Union (EU) Trustworthy Ethics guidelines for Trustworthy AI as our reference for ethical requirements and an Agile portfolio management framework to analyze implementation. Our findings reveal a general consideration of privacy and data governance ethical requirements as legal requirements with no other consideration for ethical requirements identified. The findings also show practicable consideration of ethical requirements as technical robustness and safety for implementation as risk requirements and societal and environmental well-being for implementation as sustainability requirements. We examine a practical approach to implementing ethical requirements using the ethical risk requirements stack employing the Agile portfolio management framework.  © 2023 Owner/Author.","10.1145/3593434.3593453","Conference paper","2023","Engineering research; Financial data processing; Philosophical aspects; Software engineering; Sustainable development; Agile portfolio management; Artificial intelligence ethic; Artificial intelligence ethic principle; Engineering executives; Ethical requirement; Ethical requirement stack; Level management; Management frameworks; Management practises; Portfolio managements; Investments","Scopus"
"Systematic review of data-centric approaches in artificial intelligence and machine learning","Artificial intelligence (AI) relies on data and algorithms. State-of-the-art (SOTA) AI smart algorithms have been developed to improve the performance of AI-oriented structures. However, model-centric approaches are limited by the absence of high-quality data. Data-centric AI is an emerging approach for solving machine learning (ML) problems. It is a collection of various data manipulation techniques that allow ML practitioners to systematically improve the quality of the data used in an ML pipeline. However, data-centric AI approaches are not well documented. Researchers have conducted various experiments without a clear set of guidelines. This survey highlights six major data-centric AI aspects that researchers are already using to intentionally or unintentionally improve the quality of AI systems. These include big data quality assessment, data preprocessing, transfer learning, semi-supervised learning, machine ​learning ​operations (MLOps), and the effect of adding more data. In addition, it highlights recent data-centric techniques adopted by ML practitioners. We addressed how adding data might harm datasets and how HoloClean can be used to restore and clean them. Finally, we discuss the causes of technical debt in AI. Technical debt builds up when software design and implementation decisions run into “or outright collide with” business goals and timelines. This survey lays the groundwork for future data-centric AI discussions by summarizing various data-centric approaches. © 2023 Xi'an Jiaotong University","10.1016/j.dsm.2023.06.001","Article","2023","","Scopus"
"Towards AI-assisted digital twins for smart railways: preliminary guideline and reference architecture","In the last years, there has been a growing interest in the emerging concept of digital twins (DTs) among software engineers and researchers. DTs not only represent a promising paradigm to improve product quality and optimize production processes, but they also may help enhance the predictability and resilience of cyber-physical systems operating in critical contexts. In this work, we investigate the adoption of DTs in the railway sector, focusing in particular on the role of artificial intelligence (AI) technologies as key enablers for building added-value services and applications related to smart decision-making. In this paper, in particular, we address predictive maintenance which represents one of the most promising services benefiting from the combination of DT and AI. To cope with the lack of mature DT development methodologies and standardized frameworks, we detail a workflow for DT design and development specifically tailored to a predictive maintenance scenario and propose a high-level architecture for AI-enabled DTs supporting such workflow. © 2023, The Author(s).","10.1007/s40860-023-00208-6","Article","2023","Decision making; E-learning; Embedded systems; Internet of things; Machine learning; Railroad transportation; Railroads; Artificial intelligence technologies; Cybe-physical systems; Cyber-physical systems; Machine-learning; Predictive maintenance; Production process; Products quality; Railway; Reference architecture; Work-flows; Cyber Physical System","Scopus"
"Why We Need to Know More: Exploring the State of AI Incident Documentation Practices","To enable the development and use of safe and equitable artificial intelligence (AI) systems, AI engineers must monitor deployed AI systems and learn from past AI incidents where failures have occurred. Around the world, public databases for cataloging AI systems and resulting harms are instrumental in promoting awareness of potential AI harms among policymakers, researchers, and the public. However, despite growing recognition of the potential of AI systems to produce harms, causes of AI systems failure remain elusive and AI incidents continue to occur. For example, incidents of AI bias are frequently reported and discussed, yet biased systems continue to be developed and deployed. This raises the question - how are we learning from documented incidents? What information do we need to analyze AI incidents and develop new AI engineering best practices? This paper examines reporting techniques from a variety of AI stakeholders and across different industries, identifies requirements towards the design of effective AI incident documentation, and proposes policy recommendations for augmenting current practice.  © 2023 Owner/Author.","10.1145/3600211.3604700","Conference paper","2023","Artificial intelligence systems; Current practices; Engineering best practice; Explainable artificial intelligence; Learn+; Policy makers; Policy recommendations; Public database; System failures; Artificial intelligence","Scopus"
"Performance analysis of conventional and AI-based variant callers using short and long reads","Background: The accurate detection of variants is essential for genomics-based studies. Currently, there are various tools designed to detect genomic variants, however, it has always been a challenge to decide which tool to use, especially when various major genome projects have chosen to use different tools. Thus far, most of the existing tools were mainly developed to work on short-read data (i.e., Illumina); however, other sequencing technologies (e.g. PacBio, and Oxford Nanopore) have recently shown that they can also be used for variant calling. In addition, with the emergence of artificial intelligence (AI)-based variant calling tools, there is a pressing need to compare these tools in terms of efficiency, accuracy, computational power, and ease of use. Results: In this study, we evaluated five of the most widely used conventional and AI-based variant calling tools (BCFTools, GATK4, Platypus, DNAscope, and DeepVariant) in terms of accuracy and computational cost using both short-read and long-read data derived from three different sequencing technologies (Illumina, PacBio HiFi, and ONT) for the same set of samples from the Genome In A Bottle project. The analysis showed that AI-based variant calling tools supersede conventional ones for calling SNVs and INDELs using both long and short reads in most aspects. In addition, we demonstrate the advantages and drawbacks of each tool while ranking them in each aspect of these comparisons. Conclusion: This study provides best practices for variant calling using AI-based and conventional variant callers with different types of sequencing data. © 2023, The Author(s).","10.1186/s12859-023-05596-3","Article","2023","Artificial Intelligence; Genomics; High-Throughput Nucleotide Sequencing; Sequence Analysis, DNA; Software; Artificial intelligence; Bottles; Computational efficiency; Gene encoding; Computational power; Genome projects; Genomics; Illumina; NGS; Performances analysis; Pressung; Sequencing; Short reads; Variant calling; artificial intelligence; DNA sequencing; genomics; high throughput sequencing; procedures; software; Genome","Scopus"
"Developing Team Design Patterns for Hybrid Intelligence Systems","With artificial intelligence (AI) systems entering our working and leisure environments with increasing adaptation and learning capabilities, new opportunities arise for developing hybrid (human-AI) intelligence (HI) systems, comprising new ways of collaboration. However, there is not yet a structured way of specifying design solutions of collaboration for hybrid intelligence (HI) systems and there is a lack of best practices shared across application domains. We address this gap by investigating the generalization of specific design solutions into design patterns that can be shared and applied in different contexts. We present a human-centered bottom-up approach for the specification of design solutions and their abstraction into team design patterns. We apply the proposed approach for 4 concrete HI use cases and show the successful extraction of team design patterns that are generalizable, providing re-usable design components across various domains. This work advances previous research on team design patterns and designing applications of HI systems. © 2023 The Authors.","10.3233/FAIA230071","Conference paper","2023","Artificial intelligence; Case-based researches; Co-evolution; Design Patterns; Human-centered artificial intelligence; Hybrid intelligence; Intelligence systems; Interdependence; Team design pattern; Team designs; Use-case based research; Leisure","Scopus"
"Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey","Advancements in wearable medical devices using the IoT technology are shaping the modern healthcare system. With the emergence of the Internet of Healthcare Things (IoHT), efficient healthcare services can be provided to patients. Healthcare professionals have effectively used AI-based models to analyze the data collected from IoHT devices to treat various diseases. Data must be processed and analyzed while avoiding privacy breaches, in compliance with legal rules and regulations, such as the HIPAA and GDPR. Federated learning (FL) is a machine learning-based approach allowing multiple entities to train an ML model collaboratively without sharing their data. It is particularly beneficial in healthcare, where data privacy and security are substantial concerns. Even though FL addresses some privacy concerns, there is still no formal proof of privacy guarantees for IoHT data. Privacy-enhancing technologies (PETs) are tools and techniques designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users’ personal information and sensitive data from unauthorized access and tracking. This paper comprehensively reviews PETs concerning FL in the IoHT scenario and identifies several key challenges for future research. © 2023 by the authors.","10.3390/electronics12122703","Article","2023","","Scopus"
"Chat GPT in Diagnostic Human Pathology: Will It Be Useful to Pathologists? A Preliminary Review with ‘Query Session’ and Future Perspectives","The advent of Artificial Intelligence (AI) has in just a few years supplied multiple areas of knowledge, including in the medical and scientific fields. An increasing number of AI-based applications have been developed, among which conversational AI has emerged. Regarding the latter, ChatGPT has risen to the headlines, scientific and otherwise, for its distinct propensity to simulate a ‘real’ discussion with its interlocutor, based on appropriate prompts. Although several clinical studies using ChatGPT have already been published in the literature, very little has yet been written about its potential application in human pathology. We conduct a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, using PubMed, Scopus and the Web of Science (WoS) as databases, with the following keywords: ChatGPT OR Chat GPT, in combination with each of the following: pathology, diagnostic pathology, anatomic pathology, before 31 July 2023. A total of 103 records were initially identified in the literature search, of which 19 were duplicates. After screening for eligibility and inclusion criteria, only five publications were ultimately included. The majority of publications were original articles (n = 2), followed by a case report (n = 1), letter to the editor (n = 1) and review (n = 1). Furthermore, we performed a ‘query session’ with ChatGPT regarding pathologies such as pigmented skin lesions, malignant melanoma and variants, Gleason’s score of prostate adenocarcinoma, differential diagnosis between germ cell tumors and high grade serous carcinoma of the ovary, pleural mesothelioma and pediatric diffuse midline glioma. Although the premises are exciting and ChatGPT is able to co-advise the pathologist in providing large amounts of scientific data for use in routine microscopic diagnostic practice, there are many limitations (such as data of training, amount of data available, ‘hallucination’ phenomena) that need to be addressed and resolved, with the caveat that an AI-driven system should always provide support and never a decision-making motive during the histopathological diagnostic process. © 2023 by the authors.","10.3390/ai4040051","Review","2023","","Scopus"
"Improving the Reliability of Medical Diagnostic Models through Rule-Based Decision Deferral","Pancreatic ductal adenocarcinoma (PDAC) is a highly lethal cancer, and accurate assessment of tumor resectability is crucial for determining appropriate treatment. AI-based models have shown promise in classifying tumor resectability, but reliability concerns have impeded clinical implementation. We propose extending the AI-based VasQNet model for classifying tumor resectability on AI-generated segmentations of computed tomography scans (CTs) to improve the models’ reliability. This extension allows VasQNet to defer decisions when the AI-generated segmentations violate pre-established rules on vascular anatomy, tumor location, and tumor size. We conducted experiments using CTs of (borderline) resectable and non-resectable PDAC patients. We evaluated the performance of the baseline VasQNet and the extended VasQNet with rule-based decision deferral (RBDD) by comparing their classifications to a ground-truth provided by a radiologist, employing agreement as a metric. Our results demonstrate that the extended VasQNet achieved a significantly higher agreement (90%) with the radiologist’s classification than the baseline VasQNet (67%). Notably, 17/31 (54%) deferred decisions would have been incorrect had they not been deferred. Our study demonstrates the effectiveness of RBDD in improving the reliability of clinical diagnostic models through the exemplification of VasQNet. In conclusion, RBDD can enhance the reliability of clinical diagnostics models, facilitating integration into clinical practice. The documented code is available on GitHub (https://github.com/PHAIR-Consortium/Vessel- Involvement-Quantifier). © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2023","Artificial intelligence; Computerized tomography; Diagnosis; Reliability; Clinical diagnostics; Computed tomography scan; Diagnostic model; Ductal adenocarcinomas; Medical diagnostics; Model reliability; Rule based; Tumor location; Tumor size; Vascular anatomy; Tumors","Scopus"
"Investigating Usability of Conversational User Interfaces for Integrated System-Physical Interactions: A Medical Device Perspective","The use of Conversational User Interfaces (CUIs) as human-machine interfaces in AI-infused systems has become increasingly popular. However, the existing design guidelines for CUIs are inadequate for meeting the complex interaction requirements of applications involving integrated System-Physical Interaction. In this study, the real-life context of using CUIs as the front-end of AI-enabled medical devices is examined, investigating interaction and usability issues in clinical task operations. Voice- and text-based CUIs were tested with 40 participants to perform clinical tasks. Based on user testing results, a team of seven experts identified 116 unique usability issues and synthesized 16 heuristics using a multilevel thematic coding process. These heuristics were compared to past guidelines to assess their alignment and novelty. Further, 12 usability experts evaluated the heuristics across various clinical systems. The study established that the proposed 16 heuristics provide comprehensive guidance for designing and evaluating CUIs, addressing a wide range of usability requirements. © 2024 Taylor & Francis Group, LLC.","10.1080/10447318.2023.2298534","Article","2024","Cyber Physical System; Embedded systems; Integrated control; User interfaces; AI agent; Clinical tasks; Conversational-AI; Cybe-physical systems; Cyber-physical systems; Heuristic evaluation; Integrated systems; Intelligent User Interfaces; Medical Devices; Physical interactions; Usability engineering","Scopus"
"OpenFL-XAI: Federated learning of explainable artificial intelligence models in Python","Artificial Intelligence (AI) systems play a significant role in manifold decision-making processes in our daily lives, making trustworthiness of AI more and more crucial for its widespread acceptance. Among others, privacy and explainability are considered key requirements for enabling trust in AI. Building on these needs, we propose a software for Federated Learning (FL) of Rule-Based Systems (RBSs): on one hand FL prioritizes user data privacy during collaborative model training. On the other hand, RBSs are deemed as interpretable-by-design models and ensure high transparency in the decision-making process. The proposed software, developed as an extension to the Intel® OpenFL open-source framework, offers a viable solution for developing AI applications balancing accuracy, privacy, and interpretability. © 2023 The Author(s)","10.1016/j.softx.2023.101505","Article","2023","Application programs; Artificial intelligence; Data privacy; Learning systems; Open source software; Open systems; Artificial intelligence systems; Collaborative modeling; Daily lives; Decision-making process; Explainable artificial intelligence; Federated learning; Intelligence models; Linguistic fuzzy models; Rules based systems; User data; Decision making","Scopus"
"Autonomous AI systems in the face of liability, regulations and costs","Autonomous AI systems in medicine promise improved outcomes but raise concerns about liability, regulation, and costs. With the advent of large-language models, which can understand and generate medical text, the urgency for addressing these concerns increases as they create opportunities for more sophisticated autonomous AI systems. This perspective explores the liability implications for physicians, hospitals, and creators of AI technology, as well as the evolving regulatory landscape and payment models. Physicians may be favored in malpractice cases if they follow rigorously validated AI recommendations. However, AI developers may face liability for failing to adhere to industry-standard best practices during development and implementation. The evolving regulatory landscape, led by the FDA, seeks to ensure transparency, evaluation, and real-world monitoring of AI systems, while payment models such as MPFS, NTAP, and commercial payers adapt to accommodate them. The widespread adoption of autonomous AI systems can potentially streamline workflows and allow doctors to concentrate on the human aspects of healthcare. © 2023, Springer Nature Limited.","10.1038/s41746-023-00929-1","Article","2023","AI systems; AI Technologies; Best practices; Human aspects; Industry standards; Language model; Real-world; Work-flows","Scopus"
"Ethical considerations in the early detection of Alzheimer's disease using speech and AI","While recent studies indicate that AI could play an important role in detecting early signs of Alzheimer's disease in speech, this use of data from individuals with cognitive decline raises numerous ethical concerns. In this paper, we identify and explain concerns related to autonomy (including consent, depersonalization and disclosure), privacy and data protection (including the handling of personal content and medical information), welfare (including distress, discrimination and reliability), transparency (including the interpretability of language features and AI-based decision-making for developers and clinicians), and fairness (including bias and the distribution of benefits). Our aim is to not only raise awareness of the ethical concerns posed by the use of AI in speech-based Alzheimer's detection, but also identify ways in which these concerns might be addressed. To this end, we conclude with a list of suggestions that could be incorporated into ethical guidelines for researchers and clinicians working in this area. © 2023 Owner/Author.","10.1145/3593013.3594063","Conference paper","2023","Data privacy; Decision making; Ethical technology; Neurodegenerative diseases; Speech recognition; Alzheimers disease; Autonomy; Cognitive decline; Digital biomarker; Ethical concerns; Ethical considerations; Fairness; Language; Privacy; Welfare; Transparency","Scopus"
"Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training","The success of Transformer models has pushed the deep learning model scale to billions of parameters, but the memory limitation of a single GPU has led to an urgent need for training on multi-GPU clusters. However, the best practice for choosing the optimal parallel strategy is still lacking, as it requires domain expertise in both deep learning and parallel computing. The Colossal-AI system addressed the above challenge by introducing a unified interface to scale your sequential code of model training to distributed environments. It supports parallel training methods such as data, pipeline, tensor, and sequence parallelism and is integrated with heterogeneous training and zero redundancy optimizer. Compared to the baseline system, Colossal-AI can achieve up to 2.76 times training speedup on large-scale models. © 2023 Association for Computing Machinery. All rights reserved.","10.1145/3605573.3605613","Conference paper","2023","Deep learning; Learning systems; Best practices; Dataset; Gaze detection; Large-scales; Learning models; Model scale; Neural-networks; Parallel training; Text tagging; Transformer modeling; Large dataset","Scopus"
"An AI-based Approach for Grading Students' Collaboration","Soft skills (such as communication and collaboration) are rarely addressed in programming courses, mostly because they are difficult to teach, assess, and grade. A quantitative, modular, AI-based approach for assessing and grading students' collaboration has been examined in this article. The pedagogical underpinning of the approach includes a pedagogical framework and a quantitative soft skill assessment rubric, which have been adapted and used in an extracurricular Java programming course. The objective was to identify pros and cons of using different AI methods within this approach when it comes to assessing and grading collaboration in group programming projects. More specifically, fuzzy rules and several machine learning methods (ML onward) have been examined to see which one would yield the best results regarding performance, interpretability/explainability of recommendations, and feasibility/practicality. The data used for training and testing span four academic years, and the results suggest that almost all of the examined AI methods, when used within the proposed AI-based approach, can provide adequate grading recommendations as long as teachers cover other aspects of the assessment not covered by the rubrics: code quality, plagiarism, and project completion. The fuzzy-rule-based method requires time and effort to be spent on (manual) creation and tuning of fuzzy rules and sets, whereas the examined ML methods require lesser initial investments but do need historical data for training. On the other hand, the fuzzy-rule-based method can provide the best explanations on how the assessment/grading was made - something that proved to be very important to teachers.  © 2008-2011 IEEE.","10.1109/TLT.2022.3225432","Article","2023","Computer programming; Education computing; Engineering education; Fuzzy rules; Grading; Learning systems; Personnel training; Students; Teaching; Assessment tool; Automatic assessment; Automatic assessment tool; Collaboration; Computer Science Education; Fuzzy rule based; Machine-learning; Programming course; Soft skills; Teachers'; Fuzzy inference","Scopus"
"Requirements analysis for an AI-based clinical decision support system for general practitioners: a user-centered design process","Background: As the first point of contact for patients with health issues, general practitioners (GPs) are frequently confronted with patients presenting with non-specific symptoms of unclear origin. This can result in delayed, prolonged or false diagnoses. To accelerate and improve the diagnosis of diseases, clinical decision support systems would appear to be an appropriate tool. The objective of the project ‘Smart physician portal for patients with unclear disease’ (SATURN) is to employ a user-centered design process based on the requirements analysis presented in this paper to develop an artificial Intelligence (AI)-based diagnosis support system that specifically addresses the needs of German GPs. Methods: Requirements analysis for a GP-specific diagnosis support system was conducted in an iterative process with five GPs. First, interviews were conducted to analyze current workflows and the use of digital applications in cases of diagnostic uncertainty (as-is situation). Second, we focused on collecting and prioritizing tasks to be performed by an ideal smart physician portal (to-be situation) in a workshop. We then developed a task model with corresponding user requirements. Results: Numerous GP-specific user requirements were identified concerning the tasks and subtasks: performing data entry (open system, enter patient data), reviewing results (receiving and evaluating results), discussing results (with patients and colleagues), scheduling further diagnostic procedures, referring to specialists (select, contact, make appointments), and case closure. Suggested features particularly concerned the process of screening and assessing results: e.g., the system should focus more on atypical patterns of common diseases than on rare diseases only, display probabilities of differential diagnoses, ensure sources and results are transparent, and mark diagnoses that have already been ruled out. Moreover, establishing a means of using the platform to communicate with colleagues and transferring patient data directly from electronic patient records to the system was strongly recommended. Conclusions: Essential user requirements to be considered in the development and design of a diagnosis system for primary care could be derived from the analysis. They form the basis for mockup-development and system engineering. © 2023, The Author(s).","10.1186/s12911-023-02245-w","Article","2023","Artificial Intelligence; Decision Support Systems, Clinical; Electronic Health Records; General Practitioners; Humans; User-Centered Design; artificial intelligence; clinical decision support system; electronic health record; general practitioner; human; user-centered design","Scopus"
"Assessing Teamwork Skills: Can a Computer Algorithm Match Human Experts?","Teamwork skills are commonly evaluated by human assessors, which can be logistically challenging and resource intensive. Technological advancements provide an opportunity for a new assessment method – virtual behavioural simulations with self-scoring algorithms. This study explores whether a rule-based algorithm can match human assessors at evaluating teamwork skills. 206 undergraduate students completed a virtual simulation assessment, where they interacted with “teammates” (represented by chatbots) using natural language. In this study, students’ teamwork skills were assessed independently by a computer algorithm and two human experts based on the transcripts of their conversations with “teammates” (chatbots). The relative accuracy of these assessments was evaluated against peer- and self-evaluations of teamwork. The assessment scores generated by the algorithm and human experts were highly correlated with each other and were comparable in their ability to predict teamwork. The scores generated by the algorithm were slightly more correlated with peer-evaluations than those generated by human experts (r =.25 and r =.17, respectively; p =.21). The results indicate that AI-based techniques offer a promising method of skill assessment to support learning and acquisition teamwork skills. © 2022, International Artificial Intelligence in Education Society.","10.1007/s40593-022-00318-x","Article","2023","Computer simulation languages; Virtual reality; Assessment; Behavioural simulations; Chatbots; Human assessors; Human expert; Peer evaluations; Scoring algorithms; Simulation; Teamwork skills; Technological advancement; Students","Scopus"
"Explainable artificial intelligence: A taxonomy and guidelines for its application to drug discovery","Artificial intelligence (AI) is having a growing impact in many areas related to drug discovery. However, it is still critical for their adoption by the medicinal chemistry community to achieve models that, in addition to achieving high performance in their predictions, can be trusty explained to the end users in terms of their knowledge and background. Therefore, the investigation and development of explainable artificial intelligence (XAI) methods have become a key topic to address this challenge. For this reason, a comprehensive literature review about explanation methodologies for AI based models, focused in the field of drug discovery, is provided. In particular, an intuitive overview about each family of XAI approaches, such as those based on feature attribution, graph topologies, or counterfactual reasoning, oriented to a wide audience without a strong background in the AI discipline is introduced. As the main contribution, we propose a new taxonomy of the current XAI methods, which take into account specific issues related with the typical representations and computational problems study in the design of molecules. Additionally, we also present the main visualization strategies designed for supporting XAI approaches in the chemical domain. We conclude with key ideas about each method category, thoroughly providing insightful analysis about the guidelines and potential benefits of their adoption in medical chemistry. This article is categorized under: Data Science > Artificial Intelligence/Machine Learning. © 2023 Wiley Periodicals LLC.","10.1002/wcms.1681","Article","2023","Deep learning; Taxonomies; Topology; Chemistry community; Deep learning; Drug discovery; End-users; Explainable artificial intelligence; ITS applications; Key topics; Literature reviews; Medicinal chemistry; Performance; Visualization","Scopus"
"AI Regulation Is (not) All You Need","The development of processes and tools for ethical, trustworthy, and legal AI is only beginning. At the same time, legal requirements are emerging in various jurisdictions, following a deluge of ethical guidelines. It is therefore key to explore the necessary practices that must be adopted to ensure the quality of AI systems, mitigate their potential risks and enable legal compliance. Ensuring that the potential negative impacts of AI on individuals, society, and the environment are mitigated will depend on many factors, including the capacity to properly regulate its deployment and to mandate necessary internal best practices along lifecycles. Regulatory frameworks must evolve from abstract requirements to providing concrete operational mandates that enable better oversight mechanisms in the way AI systems operate, how they are developed, and how they are deployed. In view of the above, this paper explores the necessary practices that can be adopted throughout a comprehensive lifecycle audit as a key practice to ensure the quality of AI systems and enable the development of compliance mechanisms. It also discusses novel governance tools that enable bridging the current operational gaps. Such gaps were identified by interviewing experts, analysing adaptable tools and methodologies from the software engineering domain, and by exploring the state of the art of auditing. The results present recommendations for novel tools and oversight mechanisms for governing AI systems. © 2023 ACM.","10.1145/3593013.3594079","Conference paper","2023","Life cycle; Philosophical aspects; Software engineering; AI regulation; AI systems; Algorithmic auditing; Algorithmics; Best practices; Ethical AI; Legal compliance; Legal requirements; Machine-learning; Potential risks; Machine learning","Scopus"
"Cnosso, a novel method for business document automation based on open information extraction","The state-of-the-art in automated processing of unstructured business documents has evolved from manual labor to advanced AI systems in the span of mere decades. Such systems involve learning techniques, rule or clause sets, neural models – either used alone or in combination – for the extraction to work. As an example, rule-based processes operate on a perceived layout or positioning of the information, whereas model-based frameworks adopt a semantic, and often uninspectable, approach. Verb-Based Semantic Role Labeling (VBSRL) is a novel system presented in a former paper that uses a hybrid foundation to inform the extraction phase via a set of rules modeling natural language. We propose a new VBSRL-based document processing method, aided by valuable and innovative architectural choices, which has been implemented for the Italian language and experimented upon with promising results. Even in its infancy, in fact, the first implementation of this system shows better results than comparable IE solutions, obtaining an aggregate, average F-measure of nearly 79%. © 2023 Elsevier Ltd","10.1016/j.eswa.2023.123038","Article","2024","Automation; Information retrieval; Learning systems; Modeling languages; Natural language processing systems; Automated processing; Business documents; Document automation; Information extraction; Natural language analysis; NER; Novel methods; Semantic role labeling; State of the art; Verb-based semantic role labeling; Semantics","Scopus"
"Pre-planning for Plastic Surgery Using Machine Learning: A Proof of Concept","This paper presents a proof-of-concept study on AI-based pre-surgery planning in plastic surgery. The study addresses the challenge of technique selection by developing an AI-driven system that utilises machine learning algorithms to analyse patient-specific data and historical outcomes. By comparing and evaluating diverse inputs, the system generates detailed results for each technique, providing surgeons with valuable insights into expected outcomes. This enhances decision-making during pre-surgery planning and improves surgical precision. The system’s development involved addressing challenges related to data availability, algorithm selection, and interpretability. Preoperative images will be processed using advanced computer vision algorithms to extract relevant features. A Convolutional Neural Network (CNN) architecture predicted technique-specific outcomes based on the extracted features. The validation included comparing predictions against ground truth data and expert evaluations. Feedback from plastic surgery practitioners will be collected to assess usability and practicality. Ethical guidelines will be strictly followed to ensure patient data protection and address potential biases. The successful implementation of the proof of concept demonstrates the potential of AI integration in pre-surgery planning for plastic surgery. By empowering surgeons with technique-specific insights, the system enhances decision-making, ultimately improving patient care and treatment outcomes. Future work involves expanding the dataset, considering additional variables, and conducting prospective clinical trials to validate the system’s real-world impact. © 2024, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","10.1007/978-3-031-50215-6_4","Conference paper","2024","Decision making; Hospital data processing; Learning algorithms; Surgery; Machine learning for pre-planning; Machine learning in surgery; Machine-learning; Plastic surgery; Pre-panning plastic surgery; Pre-planning; Pre-planning surgery; Proof of concept; Machine learning","Scopus"
"What's Missing in Requirements Engineering for Responsible AI?","The rapid evolution of artificial intelligence (AI) has catalyzed a multifaceted discourse in the software engineering (SE) community. The crux of this dialogue is to pinpoint the distinct attributes of AI systems that necessitate tailored SE methodologies. While classical SE techniques have proved effective across a spectrum of systems, there's an emerging consensus: AI introduces distinct challenges, compelling us to rethink some foundational principles of traditional SE.1 Central to AI systems is the imperative to design models, curate training datasets, govern system autonomy, and embed ethical guidelines. Two salient features of AI operations include continuous learning from evolving datasets and human feedback while dealing with the increased uncertainties and risks due to system autonomy.  © 1984-2012 IEEE.","10.1109/MS.2023.3302934","Article","2023","Artificial intelligence systems; Design models; Engineering community; Engineering techniques; Intelligence operations; Requirement engineering; Salient features; Software engineering methodologies; Spectra's; Training dataset; Software engineering","Scopus"
"Characterizing Manipulation from AI Systems","Manipulation is a concern in many domains, such as social media, advertising, and chatbots. As AI systems mediate more of our digital interactions, it is important to understand the degree to which AI systems might manipulate humans without the intent of the system designers. Our work clarifies challenges in defining and measuring this kind of manipulation from AI systems. Firstly, we build upon prior literature on manipulation and characterize the space of possible notions of manipulation, which we find to depend upon the concepts of incentives, intent, covertness, and harm. We review proposals on how to operationalize each concept and we outline challenges in including each concept in a definition of manipulation. Second, we discuss the connections between manipulation and related concepts, such as deception and coercion. We then analyze how our characterization of manipulation applies to recommender systems and language models, and give a brief overview of the regulation of manipulation in other domains. While some progress has been made in defining and measuring manipulation from AI systems, many gaps remain. In the absence of a consensus definition and reliable tools for measurement, we cannot rule out the possibility that AI systems learn to manipulate humans without the intent of the system designers. Manipulation could pose a significant threat to human autonomy and precautionary actions to mitigate it are likely warranted. © 2023 Owner/Author.","10.1145/3617694.3623226","Conference paper","2023","Social networking (online); Systems analysis; Advertizing; AI systems; Chatbots; Coercion; Deception; Digital interactions; Manipulation; Persuasion; Social media; System designers; Recommender systems","Scopus"
"Adherence of randomised controlled trials using artificial intelligence in ophthalmology to CONSORT-AI guidelines: a systematic review and critical appraisal","Purpose Many efforts have been made to explore the potential of deep learning and artificial intelligence (AI) in disciplines such as medicine, including ophthalmology. This systematic review aims to evaluate the reporting quality of randomised controlled trials (RCTs) that evaluate AI technologies applied to ophthalmology. Methods A comprehensive search of three relevant databases (EMBASE, Medline, Cochrane) from 1 January 2010 to 5 February 2022 was conducted. The reporting quality of these papers was scored using the Consolidated Standards of Reporting Trials-Artificial Intelligence (CONSORT-AI) checklist and further risk of bias was assessed using the RoB-2 tool. Results The initial search yielded 2973 citations from which 5 articles satisfied the inclusion/exclusion criteria. These articles featured AI technologies applied to diabetic retinopathy screening, ophthalmologic education, fungal keratitis detection and paediatric cataract diagnosis. None of the articles reported all items in the CONSORT-AI checklist. The overall mean CONSORT-AI score of the included RCTs was 53% (range 37%-78%). The individual scores of the articles were 37% (19/51), 39% (20), 49% (25), 61% (31) and 78% (40). All articles were scored as being moderate risk, or 'some concerns present', regarding potential risk of bias according to the RoB-2 tool. Conclusion A small number of RCTs have been published to date on the applications of AI in ophthalmology and vision science. Adherence to the 2020 CONSORT-AI reporting guidelines is suboptimal with notable reporting items often missed. Greater adherence will help facilitate reproducibility of AI research which can be a stimulus for more AI-based RCTs and clinical applications in ophthalmology.  © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","10.1136/bmjhci-2023-100757","Article","2023","Artificial Intelligence; Child; Humans; Ophthalmology; Randomized Controlled Trials as Topic; Research Design; Article; artificial intelligence; cataract; checklist; clinical trial protocol; diabetic retinopathy; fungal detection; keratomycosis; randomized controlled trial (topic); Standards of Reporting Trials Artificial Intelligence; systematic review; artificial intelligence; child; human; methodology; ophthalmology","Scopus"
"Ethical Challenges of Artificial Intelligence in Medicine and the Triple Semantic Dimensions of Algorithmic Opacity with Its Repercussions to Patient Consent and Medical Liability","Artificial intelligence algorithms have the potential to diagnose some types of skin cancer or to identify specific heart-rhythm abnormalities as well as (or even better) than board-certified dermatologists and cardiologists. However, one of the biggest fears in the healthcare sector in the Era of AI in Medicine is the so-called black box medicine, given the obscurity in the way information is processed by algorithms. More broadly, it is observed that there are three different semantic dimensions of algorithmic opacity relevant to Medicine: (1) epistemic opacity for the insufficient physicians understanding of the rules an AI system is applying to make predictions and decisions; (2) opacity for the lack of medical disclosure about the AI systems to support clinical decisions and patient’s unawareness that automated decision-making are being carried out with their personal data; (3) explanatory opacity for the unsatisfactory explanation to patients about the technology used to support professional decision-making. Therefore, the aim of this study is to analyze each type of opacity, considering hypothetical scenarios and its repercussions in terms of medical malpractice and patient’s informed consent. From this, it will be defined ethical challenges of using AI in the healthcare sector and the importance of medical education. © 2024, The Author(s).","10.1007/978-3-031-41264-6_12","Book chapter","2024","","Scopus"
"A Zipf's law-based text generation approach for addressing imbalance in entity extraction","Entity extraction is critical in the intelligent advancement across diverse domains. Nevertheless, a challenge to its effectiveness arises from the data imbalance, where certain entities are common while others are scarce. To address this issue, this study proposes a novel text generation approach that harnesses Zipf's law, which is a powerful tool from informetrics for studying human language. By employing characteristics of Zipf's law, words within the documents are classified as common and rare ones. Subsequently, sentences are classified into common and rare ones, and are further processed by text generation models accordingly. Rare entities within the generated sentences are then labeled using human-designed rules, serving as a supplement to the raw dataset, thereby mitigating the imbalance problem. The study presents a case of extracting entities from technical documents, and the extensive experimental results on two datasets prove the effectiveness of the proposed method. Furthermore, the significance and potential of Zipf's law in driving the progress of artificial intelligence (AI) is discussed, broadening the scope and coverage of informetrics. By incorporating the foundational principles of informetrics into text generation, this study showcases the pivotal role of informetrics in shaping the design and developmental of AI systems. © 2023","10.1016/j.joi.2023.101453","Article","2023","Computational linguistics; Data mining; Classifieds; Data imbalance; Diverse domains; Entity extractions; Human language; Imbalance problem; Informetrics; Technical documents; Text generations; Zipf Law; Extraction","Scopus"
"AI systems and the issue of liability in the European and national regulatory strategies","This chapter focuses on the regulatory strategies undertaken at the European and national level with regard to the issue of liability for damages caused by cyber-physical systems. Attention will be devoted to the most recent attempts of identifying the appropriate target for regulation. This target seems to have shifted from the narrower field of robotics to the wider domain of AI. In the most recent documents the regulatory effort addresses the design and architecture of autonomous systems based on AI. An overview of the legislative endeavour in this field aims at evaluating its main policy goals, along with analysing the operational rules suggested by these policy goals to address the problem of liability. These are examined against the backdrop of the flaws within current liability regimes which are challenged by the special nature of autonomous systems, and questions the actual need for introducing new regulatory schemes. © Edward Elgar Publishing 2023.","10.4337/9781802203844.00007","Book chapter","2023","","Scopus"
"Ethical Challenges in the Development of Virtual Assistants Powered by Large Language Models †","Virtual assistants (VAs) have gained widespread popularity across a wide range of applications, and the integration of Large Language Models (LLMs), such as ChatGPT, has opened up new possibilities for developing even more sophisticated VAs. However, this integration poses new ethical issues and challenges that must be carefully considered, particularly as these systems are increasingly used in public services: transfer of personal data, decision-making transparency, potential biases, and privacy risks. This paper, an extension of the work presented at IberSPEECH 2022, analyzes the current regulatory framework for AI-based VAs in Europe and delves into ethical issues in depth, examining potential benefits and drawbacks of integrating LLMs with VAs. Based on the analysis, this paper argues that the development and use of VAs powered by LLMs should be guided by a set of ethical principles that prioritize transparency, fairness, and harm prevention. The paper presents specific guidelines for the ethical use and development of this technology, including recommendations for data privacy, bias mitigation, and user control. By implementing these guidelines, the potential benefits of VAs powered by LLMs can be fully realized while minimizing the risks of harm and ensuring that ethical considerations are at the forefront of the development process. © 2023 by the authors.","10.3390/electronics12143170","Article","2023","","Scopus"
"Understanding the factors influencing acceptability of AI in medical imaging domains among healthcare professionals: A scoping review","BACKGROUND: Artificial intelligence (AI) technology has the potential to transform medical practice within the medical imaging industry and materially improve productivity and patient outcomes. However, low acceptability of AI as a digital healthcare intervention among medical professionals threatens to undermine user uptake levels, hinder meaningful and optimal value-added engagement, and ultimately prevent these promising benefits from being realised. Understanding the factors underpinning AI acceptability will be vital for medical institutions to pinpoint areas of deficiency and improvement within their AI implementation strategies. This scoping review aims to survey the literature to provide a comprehensive summary of the key factors influencing AI acceptability among healthcare professionals in medical imaging domains and the different approaches which have been taken to investigate them. METHODS: A systematic literature search was performed across five academic databases including Medline, Cochrane Library, Web of Science, Compendex, and Scopus from January 2013 to September 2023. This was done in adherence to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines. Overall, 31 articles were deemed appropriate for inclusion in the scoping review. RESULTS: The literature has converged towards three overarching categories of factors underpinning AI acceptability including: user factors involving trust, system understanding, AI literacy, and technology receptiveness; system usage factors entailing value proposition, self-efficacy, burden, and workflow integration; and socio-organisational-cultural factors encompassing social influence, organisational readiness, ethicality, and perceived threat to professional identity. Yet, numerous studies have overlooked a meaningful subset of these factors that are integral to the use of medical AI systems such as the impact on clinical workflow practices, trust based on perceived risk and safety, and compatibility with the norms of medical professions. This is attributable to reliance on theoretical frameworks or ad-hoc approaches which do not explicitly account for healthcare-specific factors, the novelties of AI as software as a medical device (SaMD), and the nuances of human-AI interaction from the perspective of medical professionals rather than lay consumer or business end users. CONCLUSION: This is the first scoping review to survey the health informatics literature around the key factors influencing the acceptability of AI as a digital healthcare intervention in medical imaging contexts. The factors identified in this review suggest that existing theoretical frameworks used to study AI acceptability need to be modified to better capture the nuances of AI deployment in healthcare contexts where the user is a healthcare professional influenced by expert knowledge and disciplinary norms. Increasing AI acceptability among medical professionals will critically require designing human-centred AI systems which go beyond high algorithmic performance to consider accessibility to users with varying degrees of AI literacy, clinical workflow practices, the institutional and deployment context, and the cultural, ethical, and safety norms of healthcare professions. As investment into AI for healthcare increases, it would be valuable to conduct a systematic review and meta-analysis of the causal contribution of these factors to achieving high levels of AI acceptability among medical professionals. Copyright © 2023 The Author(s). Published by Elsevier B.V. All rights reserved.","10.1016/j.artmed.2023.102698","Article","2024","Artificial Intelligence; Databases, Factual; Health Personnel; Humans; MEDLINE; artificial intelligence; factual database; health care personnel; human; Medline; meta analysis","Scopus"
"The European Commission's approach to extra-contractual liability and AI – An evaluation of the AI liability directive and the revised product liability directive","The European Commission published two proposals that aim to adapt (tort) liability rules to the digital age, the circular economy and the impact of the global value chain. The ‘AI Liability Directive’ contains rules on the disclosure of information and the alleviation of the burden of proof in relation to damage caused by AI systems. The ‘revised Product Liability Directive’ substantially modifies the current product liability regime by broadening the scope, integrating new circumstances to assess the product's defectiveness and introducing provisions regarding presumptions of defectiveness and causation. In this article, we evaluate how both proposals provide some answers to major technological developments – in particular AI – in view of the issues they raise as identified in the legal literature. To do so, we also provide a clear understanding of the major provisions in both proposals, supported by visuals. Although we welcome both proposals for several reasons outlined in the article, different unclarities and inconsistencies need to be resolved. These inter alia relate to the unclarity of terms, the position of claimants, the uncertain interaction with other supranational initiatives and the many interpretation issues with regard to the fault-based liability regime. A more fundamental objection relates to the choice of the revised Product Liability Directive to capture all liability issues with AI systems, which comes at the cost of losing the connection to ‘product’ as a grounding concept. Our findings can be used by policymakers in further adapting and refining both proposals to the digital reality. © 2023 Elsevier Ltd","10.1016/j.clsr.2023.105894","Article","2023","Internet of things; AI liability directive; Digital product passport; Digital products; Disclosure; Fault; Internet of thing; Liability; Presumption; Products liabilities; Revised product liability directive; Product liability","Scopus"
"Impact of Artificial Intelligence and Cyber Security as Advanced Technologies on Bitcoin Industries","This review article investigates the relationship between Bitcoin and artificial intelligence (AI), as well as any potential consequences on the Bitcoin market. Also included are any implications for the future of the cryptocurrency. The literature review focuses on the existing research on the relationships between artificial intelligence technology and Bitcoin, and it provides an overview of both of these businesses. This research investigates the potential impacts that AI might have on the Bitcoin industry, including improved user experiences, better levels of transactional security, and enhanced operational efficiencies. The paper also analyses the challenges that occur from applying AI to the Bitcoin industry in terms of the rules and regulations, data security and privacy, and trust that exist in the sector. In recent years, cryptocurrencies have emerged as a dominant form of digital money, and the financial system itself has evolved into an increasingly important component in this space. In order to reduce the amount of risk that is associated with investing, certain approaches that are based on artificial intelligence are required to predict price and trend, as well as to design portfolios and identify fraudulent activity. Along with recent research on AI-based strategies for cryptocurrencies, the most well-known cryptocurrency, Bitcoin, is explored in this article. The articles that were determined to be the most relevant were assessed, and this page addresses the bulk of those publications. This contains research on Bitcoin and other cryptocurrencies, as well as techniques of machine learning such as SVM, ANN, LSTM, and GRU. © 2024, Ismail Saritas. All rights reserved.","","Article","2024","","Scopus"
"Packet Losses in SAGIN with Artificial Intelligence","Modern solutions based on Artificial Intelligence (AI) play an important role in the management of drone’s resources in Space-Air-Ground-Integrated-Network (SAGIN). AI can use information collected by drone sensors to develop routing protocols, optimize communication networks, improve energy efficiency, and predict user behavior. In this regard, the analysis of data loss in SAGIN with AI is relevant. This work is devoted to the calculation of packet losses in SAGIN, containing additional hardware of AI system. Based on the original model containing a Base Station (BS), a stratospheric Remotely Piloted Air System (RPAS) with an AI system, a low-orbit satellite, a low-altitude RPAS and a user of a terrestrial cellular network, data traffic was simulated using NetCracker Professional 4.1 software. The AI system was simulated by a cloud structure with the ability to change the delay and the probability of packet losses. Quantitative characteristics of traffic in SAGIN channels with such a model of the AI hardware system are obtained. The dependences of packets losses on the size of messages and the data transfer rate are calculated. The dependences of BS uplink Average Load and the packets travel time on the TS, as well as the dependences of the Bit Error Rate (BER) on the Average Load, are obtained. The results are valuable in terms of practical guidelines for choosing data transfer modes and the necessary hardware parameters for an AI system. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s10776-022-00579-2","Article","2023","Artificial intelligence; Behavioral research; Data communication systems; Data transfer; Drones; Energy efficiency; Orbits; Packet loss; Travel time; Air grounds; Air Systems; Artificial intelligence systems; Bit-error rate; Dropped packets; Integrated networks; Packets loss; Remotely piloted air system; Space-air-ground-integrated-network; Transaction size; Bit error rate","Scopus"
"Empowering Deaf-Hearing Communication: Exploring Synergies between Predictive and Generative AI-Based Strategies towards (Portuguese) Sign Language Interpretation","Communication between Deaf and hearing individuals remains a persistent challenge requiring attention to foster inclusivity. Despite notable efforts in the development of digital solutions for sign language recognition (SLR), several issues persist, such as cross-platform interoperability and strategies for tokenizing signs to enable continuous conversations and coherent sentence construction. To address such issues, this paper proposes a non-invasive Portuguese Sign Language (Língua Gestual Portuguesa or LGP) interpretation system-as-a-service, leveraging skeletal posture sequence inference powered by long-short term memory (LSTM) architectures. To address the scarcity of examples during machine learning (ML) model training, dataset augmentation strategies are explored. Additionally, a buffer-based interaction technique is introduced to facilitate LGP terms tokenization. This technique provides real-time feedback to users, allowing them to gauge the time remaining to complete a sign, which aids in the construction of grammatically coherent sentences based on inferred terms/words. To support human-like conditioning rules for interpretation, a large language model (LLM) service is integrated. Experiments reveal that LSTM-based neural networks, trained with 50 LGP terms and subjected to data augmentation, achieved accuracy levels ranging from 80% to 95.6%. Users unanimously reported a high level of intuition when using the buffer-based interaction strategy for terms/words tokenization. Furthermore, tests with an LLM—specifically ChatGPT—demonstrated promising semantic correlation rates in generated sentences, comparable to expected sentences. © 2023 by the authors.","10.3390/jimaging9110235","Article","2023","Audition; Brain; Computational linguistics; Embeddings; Natural language processing systems; Predictive analytics; Semantics; Deaf-hearing communication; Generative pre-trained transformer; Language model; Large language model; Long-short term memory; Machine learning; Machine-learning; Portuguese sign language; Sign language; Sign language recognition; Video-based motion analytic; Long short-term memory","Scopus"
"Explainable deep learning for attack intelligence and combating cyber–physical attacks","Cyber–physical control loops comprising sensors, actuators and controllers pose the most valued and critical part of the industrial Internet of Things (IIoT) as it regulates the state of the physical process, such as water treatment or gas flow. Thus, any malicious activities could lead to physical damage, affecting human safety. Cyber–physical attacks against the physical process are difficult to detect using existing threats and attack intelligence due to the (1) lack of such intelligence for the physical process and operational technology systems and (2) such attacks affect the process parameters and states. Artificial Intelligence (AI)-based attack intelligence is required. This study proposes an attack intelligence framework for identifying cyber–physical attacks and extracting attack intelligence. We propose an attribution module for attack identification using various machine and deep learning algorithms. We also utilize Explainable AI (XAI) to improve the explainability of the attack attribution module and extract attack intelligence. Our proposed framework is evaluated and tested using a gas pipeline dataset as a use case. We demonstrate that the proposed framework improves the understanding of attacks and provides attack rules, assisting security analysts in securing critical physical processes. © 2023 The Author(s)","10.1016/j.adhoc.2023.103329","Article","2024","Computer crime; Cybersecurity; Deep learning; Flow of gases; Internet of things; Learning algorithms; Learning systems; Attack intelligence; Cyber physicals; Deep learning; Detection; Industrial IoT; Industrial processs; Physical attacks; Physical control; Physical process; XAI; Water treatment","Scopus"
"Assessing Human-AI Interaction Early through Factorial Surveys: A Study on the Guidelines for Human-AI Interaction","This work contributes a research protocol for evaluating human-AI interaction in the context of specific AI products. The research protocol enables UX and HCI researchers to assess different human-AI interaction solutions and validate design decisions before investing in engineering. We present a detailed account of the research protocol and demonstrate its use by employing it to study an existing set of human-AI interaction guidelines. We used factorial surveys with a 2 × 2 mixed design to compare user perceptions when a guideline is applied versus violated, under conditions of optimal versus sub-optimal AI performance. The results provided both qualitative and quantitative insights into the UX impact of each guideline. These insights can support creators of user-facing AI systems in their nuanced prioritization and application of the guidelines. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","10.1145/3511605","Article","2023","Engineering research; AI systems; Condition; Design decisions; Design guideline; Evaluation; Factorial survey; Human-AI interaction; Performance; Research protocol; User perceptions; Design","Scopus"
"Automated Test Generation for Medical Rules Web Services: A Case Study at the Cancer Registry of Norway","The Cancer Registry of Norway (CRN) collects, curates, and manages data related to cancer patients in Norway, supported by an interactive, human-in-the-loop, socio-technical decision support software system. Automated software testing of this software system is inevitable; however, currently, it is limited in CRN's practice. To this end, we present an industrial case study to evaluate an AI-based system-level testing tool, i.e., EvoMaster, in terms of its effectiveness in testing CRN's software system. In particular, we focus on GURI, CRN's medical rule engine, which is a key component at the CRN. We test GURI with EvoMaster's black-box and white-box tools and study their test effectiveness regarding code coverage, errors found, and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage; i.e., around 19% line, 13% branch, and 20% method; and find a similar number of errors; i.e., 1 in GURI's code. Concerning domain-specific coverage, EvoMaster's black-box tool is the most effective in generating tests that lead to applied rules; i.e., 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules; and to diverse rule execution results; i.e., 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass, and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results, we recommend using EvoMaster's black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless, EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally, we conclude with lessons learned and potential research directions, which we believe are applicable in a general context. © 2023 ACM.","10.1145/3611643.3613882","Conference paper","2023","Automation; Decision support systems; Diseases; Engines; Software testing; Automated software testing; Black boxes; Cancer registries; Electronic health; Electronic health record; Health records; REST API; Rule engine; Software-systems; Test generations; Web services","Scopus"
"What does it mean to be a responsible AI practitioner: An ontology of roles and skills","With the growing need to regulate AI systems across a wide variety of application domains, a new set of occupations has emerged in the industry. The so-called responsible Artificial Intelligence (AI) practitioners or AI ethicists are generally tasked with interpreting and operationalizing best practices for ethical and safe design of AI systems. Due to the nascent nature of these roles, however, it is unclear to future employers and aspiring AI ethicists what specific function these roles serve and what skills are necessary to serve the functions. Without clarity on these, we cannot train future AI ethicists with meaningful learning objectives. In this work, we examine what responsible AI practitioners do in the industry and what skills they employ on the job. We propose an ontology of existing roles alongside skills and competencies that serve each role. We created this ontology by examining the job postings for such roles over a two-year period (2020-2022) and conducting expert interviews with fourteen individuals who currently hold such a role in the industry. Our ontology contributes to business leaders looking to build responsible AI teams and provides educators with a set of competencies that an AI ethics curriculum can prioritize.  © 2023 Owner/Author.","10.1145/3600211.3604702","Conference paper","2023","Curricula; Ethical technology; Applications domains; Artificial intelligence systems; Best practices; Competency framework; Ethical designs; Job postings; Learning objectives; Ontology's; Responsible artificial intelligence practitioner; Safe designs; Ontology","Scopus"
"Facial recognition technology, democracy and human rights","On 4 July 2023, the Third Section of the European Court of Human Rights (ECtHR) delivered the first judgment on the compatibility of facial recognition technology with human rights in Glukhin v. Russia. The case concerned the use of facial recognition technology (FRT) against Mr Glukhin following his solo demonstration in the Moscow underground. The Court unanimously found a violation of Article 8 (right to respect for private life) and Article 10 (freedom of expression) of the European Convention of Human Rights (ECHR). Regarding FRT, the Court concluded that the use of highly intrusive technology is incompatible with the ideals and values of a democratic society governed by the rule of law. This case note analyses the judgment and shows its relevance in the current regulatory debate on Artificial Intelligence (AI) systems in Europe. Notwithstanding the importance of this decision, we argue that the Court has left crucial questions unanswered. © 2023 Francesca Palmiotto and Natalia Menéndez González","10.1016/j.clsr.2023.105857","Article","2023","Laws and legislation; Social aspects; 'current; Artificial intelligence systems; European convention of human right; Facial recognition; Facial recognition technology; Freedom of expression; Human rights; Privacy; Face recognition","Scopus"
"Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT","ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT’s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes. © 2023 by the authors.","10.3390/educsci13090856","Article","2023","","Scopus"
"A Temporal Type-2 Fuzzy System for Time-Dependent Explainable Artificial Intelligence","Explainable artificial intelligence (XAI) focuses on transparent AI models and decisions, which are easy to understand, analyze, and augment by a nontechnical audience. Fuzzy logic systems (FLS)-based XAI provides an explainable framework while also modeling uncertainties in real-world environments. However, most real-life processes are not characterized by high uncertainty alone; they are also inherently time dependent, i.e., the processes are time variant. In this work, we present a novel temporal type-2 FLS-based approach for time-dependent XAI (TXAI) systems, which can account for the likelihood of a sample occurrence in the time domain by its the frequency. In the proposed temporal type-2 fuzzy sets (TT2FSs), a 4-D time-dependent membership function integrates the universe of discourse, its membership, and its frequency of occurrence across time. The TXAI system manifested better classification prowess in cross-validation tests, with a mean recall of 95.40% than a standard XAI system (based on nontemporal general type-2 fuzzy sets) that had a mean recall of 87.04%. TXAI also performed significantly better than most nonexplainable AI systems, with between 3.95% and 19.04% improvement gain in mean recall. In addition, TXAI can also outline the most likely time-dependent trajectories using the frequency and time dimensions embedded in the TXAI model; viz. given a rule at a determined time interval, what will be the next most likely rule at a subsequent time interval. In this regard, the proposed TXAI system can have profound implications for delineating the evolution of real-life time-dependent processes, such as behavioral or biological processes.  © 2020 IEEE.","10.1109/TAI.2022.3210895","Article","2023","Artificial intelligence; Classification (of information); Computer circuits; Fuzzy sets; Membership functions; Temperature measurement; Time domain analysis; Uncertainty analysis; Computational modelling; Fuzzy logic system; Fuzzy-Logic; Modeling uncertainties; Most likely; Time dependent; Time interval; Type-2 fuzzy set; Type-2 fuzzy systems; Uncertainty; Fuzzy logic","Scopus"
"An AI knowledge-based system for police assistance in crime investigation","The fight against crime is often an arduous task overall when huge amounts of data have to be inspected, as is currently the case when it comes for example in the detection of criminal activity on the dark web. This work presents and describes an artificial intelligence (AI) based system that combines various tools to assist police or law enforcement agencies during their investigations, or at least mitigate the hard process of data collection, processing and analysis. The system is an early warning/early action system for crime investigation that supports law enforcement with different processes to collect and process data as well as having knowledge extraction tools. It helps to extract information during the investigation of a criminal case or even to detect possible criminal hotspots that may lead to further investigation or analysis of a criminal case Abu Al-Haija et al. (2022, Electronics, 11, 556). The functionality of the proposed system is illustrated through several examples using data collected from the dark web, which includes advertisements offering firearms-related products. © 2024 The Authors. Expert Systems published by John Wiley & Sons Ltd.","10.1111/exsy.13524","Article","2024","Data acquisition; Data handling; Data mining; Expert systems; Crime detection; Crime investigation; Criminal activities; Criminal case; Dark web; Data collection; Early warning; Knowledge repository; Knowledge-based systems; Law-enforcement agencies; Crime","Scopus"
"Innovative Robotic Technologies and Artificial Intelligence in Pharmacy and Medicine: Paving the Way for the Future of Health Care—A Review","The future of innovative robotic technologies and artificial intelligence (AI) in pharmacy and medicine is promising, with the potential to revolutionize various aspects of health care. These advances aim to increase efficiency, improve patient outcomes, and reduce costs while addressing pressing challenges such as personalized medicine and the need for more effective therapies. This review examines the major advances in robotics and AI in the pharmaceutical and medical fields, analyzing the advantages, obstacles, and potential implications for future health care. In addition, prominent organizations and research institutions leading the way in these technological advancements are highlighted, showcasing their pioneering efforts in creating and utilizing state-of-the-art robotic solutions in pharmacy and medicine. By thoroughly analyzing the current state of robotic technologies in health care and exploring the possibilities for further progress, this work aims to provide readers with a comprehensive understanding of the transformative power of robotics and AI in the evolution of the healthcare sector. Striking a balance between embracing technology and preserving the human touch, investing in R&D, and establishing regulatory frameworks within ethical guidelines will shape a future for robotics and AI systems. The future of pharmacy and medicine is in the seamless integration of robotics and AI systems to benefit patients and healthcare providers. © 2023 by the authors.","10.3390/bdcc7030147","Review","2023","Ethical technology; Health care; Intelligent robots; Artificial intelligence systems; Effective therapy; Innovative robotic technology; Medical fields; Personalized medicines; Pharmaceutical fields; Pharmacy; Pressung; Reduce costs; Robotic technologies; Medicine","Scopus"
"From Preference Elicitation to Participatory ML: A Critical Survey & Guidelines for Future Research","The AI Ethics community faces an imperative to empower stakeholders and impacted community members so that they can scrutinize and influence the design, development, and use of AI systems in high-stakes domains. While a growing chorus of recent papers has kindled interest in so-called ""participatory ML""methods, precisely what form participation ought to take and how to operationalize these ambitions are seldom addressed. Our survey of the relevant literature shows that in many papers, participation is reduced to highly structured, computational mechanisms designed to elicit mathematically tractable approximations of narrowly-defined moral values. Of papers that actually engage with real people, these engagements typically consist of one-time interactions with individuals that are often unrepresentative of the relevant stakeholders. Motivated by these clear limitations, we introduce a consolidated set of axes to evaluate and improve participatory approaches. We use these axes to analyze contemporary work in this space and outline future AI research directions that could meaningfully contribute to operationalizing the ideal of participation.  © 2023 Owner/Author.","10.1145/3600211.3604661","Conference paper","2023","Artificial intelligence; Ethical technology; AI systems; Critical surveys; Design development; Design use; Elicitation; Participation; Participatory approach; Preference elicitation; Value-alignment; Economic and social effects","Scopus"
"Automatic literature screening using the PAJO deep-learning model for clinical practice guidelines","Background: Clinical practice guidelines (CPGs) are designed to assist doctors in clinical decision making. High-quality research articles are important for the development of good CPGs. Commonly used manual screening processes are time-consuming and labor-intensive. Artificial intelligence (AI)-based techniques have been widely used to analyze unstructured data, including texts and images. Currently, there are no effective/efficient AI-based systems for screening literature. Therefore, developing an effective method for automatic literature screening can provide significant advantages. Methods: Using advanced AI techniques, we propose the Paper title, Abstract, and Journal (PAJO) model, which treats article screening as a classification problem. For training, articles appearing in the current CPGs are treated as positive samples. The others are treated as negative samples. Then, the features of the texts (e.g., titles and abstracts) and journal characteristics are fully utilized by the PAJO model using the pretrained bidirectional-encoder-representations-from-transformers (BERT) model. The resulting text and journal encoders, along with the attention mechanism, are integrated in the PAJO model to complete the task. Results: We collected 89,940 articles from PubMed to construct a dataset related to neck pain. Extensive experiments show that the PAJO model surpasses the state-of-the-art baseline by 1.91% (F1 score) and 2.25% (area under the receiver operating characteristic curve). Its prediction performance was also evaluated with respect to subject-matter experts, proving that PAJO can successfully screen high-quality articles. Conclusions: The PAJO model provides an effective solution for automatic literature screening. It can screen high-quality articles on neck pain and significantly improve the efficiency of CPG development. The methodology of PAJO can also be easily extended to other diseases for literature screening. © 2023, The Author(s).","10.1186/s12911-023-02328-8","Article","2023","Artificial Intelligence; Clinical Decision-Making; Deep Learning; Female; Humans; Labor, Obstetric; Neck Pain; Pregnancy; artificial intelligence; clinical decision making; deep learning; female; human; labor; neck pain; pregnancy","Scopus"
"Detection of left ventricular systolic dysfunction from single-lead electrocardiography adapted for portable and wearable devices","Artificial intelligence (AI) can detect left ventricular systolic dysfunction (LVSD) from electrocardiograms (ECGs). Wearable devices could allow for broad AI-based screening but frequently obtain noisy ECGs. We report a novel strategy that automates the detection of hidden cardiovascular diseases, such as LVSD, adapted for noisy single-lead ECGs obtained on wearable and portable devices. We use 385,601 ECGs for development of a standard and noise-adapted model. For the noise-adapted model, ECGs are augmented during training with random gaussian noise within four distinct frequency ranges, each emulating real-world noise sources. Both models perform comparably on standard ECGs with an AUROC of 0.90. The noise-adapted model performs significantly better on the same test set augmented with four distinct real-world noise recordings at multiple signal-to-noise ratios (SNRs), including noise isolated from a portable device ECG. The standard and noise-adapted models have an AUROC of 0.72 and 0.87, respectively, when evaluated on ECGs augmented with portable ECG device noise at an SNR of 0.5. This approach represents a novel strategy for the development of wearable-adapted tools from clinical ECG repositories. © 2023, The Author(s).","10.1038/s41746-023-00869-w","Article","2023","Chemical detection; Gaussian noise (electronic); Portable equipment; Signal to noise ratio; Wearable technology; Cardiovascular disease; Frequency ranges; Left ventricular; Noise source; Novel strategies; Portable device; Random Gaussian noise; Real-world noise; Systolic dysfunction; Wearable devices; Article; cardiovascular disease; electrocardiogram; electrocardiography; heart failure; human; left ventricular systolic dysfunction; noise; performance; practice guideline; receiver operating characteristic; signal noise ratio; systolic dysfunction; Electrocardiograms","Scopus"
"AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers","Artificial intelligence (AI) solutions and technologies are being increasingly adopted in smart systems contexts; however, such technologies are concerned with ethical uncertainties. Various guidelines, principles, and regulatory frameworks are designed to ensure that AI technologies adhere to ethical well-being. However, the implications of AI ethics principles and guidelines are still being debated. To further explore the significance of AI ethics principles and relevant challenges, we conducted a survey of 99 randomly selected representative AI practitioners and lawmakers (e.g., AI engineers and lawyers) from 20 countries across five continents. To the best of our knowledge, this is the first empirical study that unveils the perceptions of two different types of population (AI practitioners and lawmakers) and the study findings confirm that transparency, accountability, and privacy are the most critical AI ethics principles. On the other hand, lack of ethical knowledge, no legal frameworks, and lacking monitoring bodies are found to be the most common AI ethics challenges. The impact analysis of the challenges across principles reveals that conflict in practice is a highly severe challenge. Moreover, the perceptions of practitioners and lawmakers are statistically correlated with significant differences for particular principles (e.g. fairness and freedom) and challenges (e.g. lacking monitoring bodies and machine distortion). Our findings stimulate further research, particularly empowering existing capability maturity models to support ethics-aware AI systems' development and quality assessment.  © 2014 IEEE.","10.1109/TCSS.2023.3251729","Article","2023","Ethical technology; Accountable artificial intelligence; Artificial intelligence; Artificial intelligence ethic; Artificial intelligence ethic principle; Challenge; Empirical studies; Machine ethic; Regulatory frameworks; Smart System; Uncertainty; Artificial intelligence","Scopus"
"The proposed EU Directives for AI liability leave worrying gaps likely to impact medical AI","Two newly proposed Directives impact liability for artificial intelligence in the EU: a Product Liability Directive (PLD) and an AI Liability Directive (AILD). While these proposed Directives provide some uniform liability rules for AI-caused harm, they fail to fully accomplish the EU’s goal of providing clarity and uniformity for liability for injuries caused by AI-driven goods and services. Instead, the Directives leave potential liability gaps for injuries caused by some black-box medical AI systems, which use opaque and complex reasoning to provide medical decisions and/or recommendations. Patients may not be able to successfully sue manufacturers or healthcare providers for some injuries caused by these black-box medical AI systems under either EU Member States’ strict or fault-based liability laws. Since the proposed Directives fail to address these potential liability gaps, manufacturers and healthcare providers may have difficulty predicting liability risks associated with creating and/or using some potentially beneficial black-box medical AI systems. © 2023, The Author(s).","10.1038/s41746-023-00823-w","Article","2023","Health care; AI systems; Black boxes; EU directives; Fault-based; Good and services; Health care providers; Medical decision making; Potential liability; Products liabilities; Article; artificial intelligence; European Union; health care personnel; human; injury; law; legal liability; medical decision making; medical liability; reasoning; Product liability","Scopus"
"Automating Business Process Compliance for the EU AI Act","The EU AI Act is the first step toward a comprehensive legal framework for AI. It introduces provisions for AI systems based on their risk levels in relation to fundamental rights. Providers of AI systems must conduct Conformity Assessments before market placement. Recent amendments added Fundamental Rights Impact Assessments for high-risk AI system users, focusing on compliance with EU and national laws, fundamental rights, and potential impacts on EU values. The paper suggests that automating business process compliance can help standardize these assessments and outlines some methodological guidelines.  © 2023 The Authors.","10.3233/FAIA230955","Conference paper","2023","AI act; AI systems; Business process compliances; Conformity assessment; Impact assessments; Legal frameworks; National laws; Potential impacts; Risk levels; Risks assessments; Risk assessment","Scopus"
"Machine learning and power relations","There has been an increased focus within the AI ethics literature on questions of power, reflected in the ideal of accountability supported by many Responsible AI guidelines. While this recent debate points towards the power asymmetry between those who shape AI systems and those affected by them, the literature lacks normative grounding and misses conceptual clarity on how these power dynamics take shape. In this paper, I develop a workable conceptualization of said power dynamics according to Cristiano Castelfranchi’s conceptual framework of power and argue that end-users depend on a system’s developers and users, because end-users rely on these systems to satisfy their goals, constituting a power asymmetry between developers, users and end-users. I ground my analysis in the neo-republican moral wrong of domination, drawing attention to legitimacy concerns of the power-dependence relation following from the current lack of accountability mechanisms. I illustrate my claims on the basis of a risk-prediction machine learning system, and propose institutional (external auditing) and project-specific solutions (increase contestability through design-for-values approaches) to mitigate domination. © 2022, The Author(s).","10.1007/s00146-022-01400-7","Article","2023","Ethical technology; AI design; Design for values; Domination; End-users; Learning relations; Machine-learning; Power; Power dynamics; Power relations; Responsible AI; Machine learning","Scopus"
"Augmented Humans: Provocations for collaborative AI system design","This workshop is designed to facilitate an exploration of collaborative methodologies from both academia and industry practice to advance insight into the emergent problem space of designing AI-enabled information systems. The recent developments and implementations of AI-enabled technologies have seen a parallel proliferation of practical approaches to ensure human-centred and ethical design principles are imbedded into AI development which has largely been in response to widespread industry criticism of unethical practices and unintended negative consequences of black box' algorithmic decision making. Our prototype design cards and collaborative design process are targeted at current problems and limitations with intelligent human-machine systems that can be averted with more inclusive collaboration with users as stakeholders in system design. Our intention is to refine our AI design methodology and design cards over several international workshops and to provide them to the public as a free open-source tool for AI researchers and practitioners.  © 2023 Owner/Author.","10.1145/3616961.3616969","Conference paper","2023","Design; Ethical technology; Systems analysis; AI systems; Collaborative design; Collaborative methodologies; Design card; Design method; Ethical designs; Human-centred designs; Industry practices; Problem space; Stakeholder collaborative design method; Decision making","Scopus"
"Embedding artificial intelligence in society: looking beyond the EU AI master plan using the culture cycle","The European Union (EU) Commission’s whitepaper on Artificial Intelligence (AI) proposes shaping the emerging AI market so that it better reflects common European values. It is a master plan that builds upon the EU AI High-Level Expert Group guidelines. This article reviews the masterplan, from a culture cycle perspective, to reflect on its potential clashes with current societal, technical, and methodological constraints. We identify two main obstacles in the implementation of this plan: (i) the lack of a coherent EU vision to drive future decision-making processes at state and local levels and (ii) the lack of methods to support a sustainable diffusion of AI in our society. The lack of a coherent vision stems from not considering societal differences across the EU member states. We suggest that these differences may lead to a fractured market and an AI crisis in which different members of the EU will adopt nation-centric strategies to exploit AI, thus preventing the development of a frictionless market as envisaged by the EU. Moreover, the Commission aims at changing the AI development culture proposing a human-centred and safety-first perspective that is not supported by methodological advancements, thus taking the risks of unforeseen social and societal impacts of AI. We discuss potential societal, technical, and methodological gaps that should be filled to avoid the risks of developing AI systems at the expense of society. Our analysis results in the recommendation that the EU regulators and policymakers consider how to complement the EC programme with rules and compensatory mechanisms to avoid market fragmentation due to local and global ambitions. Moreover, regulators should go beyond the human-centred approach establishing a research agenda seeking answers to the technical and methodological open questions regarding the development and assessment of human-AI co-action aiming for a sustainable AI diffusion in the society. © 2022, The Author(s).","10.1007/s00146-021-01383-x","Article","2023","Commerce; Decision making; Economic and social effects; 'current; Artificial intelligence policy; Embeddings; European union; European union commissions; Human artificial intelligence interaction; Master plan; Societal impacts; Symbiosis of artificial intelligence and human; Trust; Artificial intelligence","Scopus"
"Best Practices of Using AI-Based Models in Crystallography and Their Impact in Structural Biology","The recent breakthrough made in the field of three-dimensional (3D) structure prediction by artificial intelligence softwares, such as initially AlphaFold2 (AF2) and RosettaFold (RF) and more recently large Language Models (LLM), has revolutionized the field of structural biology in particular and also biology as a whole. These models have clearly generated great enthusiasm within the scientific community, and different applications of these 3D predictions are regularly described in scientific articles, demonstrating the impact of these high-quality models. Despite the acknowledged high accuracy of these models in general, it seems important to make users of these models aware of the wealth of information they offer and to encourage them to make the best use of them. Here, we focus on the impact of these models in a specific application by structural biologists using X-ray crystallography. We propose guidelines to prepare models to be used for molecular replacement trials to solve the phase problem. We also encourage colleagues to share as much detail as possible about how they use these models in their research, where the models did not yield correct molecular replacement solutions, and how these predictions fit with their experimental 3D structure. We feel this is important to improve the pipelines using these models and also to get feedback on their overall quality. © 2023 American Chemical Society.","10.1021/acs.jcim.3c00381","Review","2023","Artificial Intelligence; Biology; Crystallography, X-Ray; Software; Three dimensional computer graphics; X ray crystallography; Best practices; High quality; Intelligence software; Language model; Molecular replacements; Scientific articles; Scientific community; Structural biology; Structure prediction; Three dimensional (3D) structures; artificial intelligence; biology; software; X ray crystallography; Forecasting","Scopus"
"A methodological and theoretical framework for implementing explainable artificial intelligence (XAI) in business applications","Artificial Intelligence (AI) is becoming fundamental in almost all activity sectors in our society. However, most of the modern AI techniques (e.g., Machine Learning – ML) have a black box nature, which hinder their adoption by practitioners in many application fields. This issue raises a recent emergence of a new research area in AI called Explainable artificial intelligence (XAI), aiming at providing AI-based decision-making processes and outcomes to be easily understood, interpreted, and justified by humans. Since 2018, there has been an exponential growth of research studies on XAI, which has justified some review studies. However, these reviews currently focus on proposing taxonomies of XAI methods. Yet, XAI is by nature a highly applicative research field, and beyond XAI methods, it is also very important to investigate how XAI is concretely used in industries, and consequently derive the best practices to follow for better implementations and adoptions. There is a lack of studies on this latter point. To fill this research gap, we first propose a holistic review of business applications of XAI, by following the Theory, Context, Characteristics, and Methodology (TCCM) protocol. Based on the findings of this review, we secondly propose a methodological and theoretical framework in six steps that can be followed by all practitioners or stakeholders for improving the implementation and adoption of XAI in their business applications. We particularly highlight the need to rely on domain field and analytical theories to explain the whole analytical process, from the relevance of the business question to the robustness checking and the validation of explanations provided by XAI methods. Finally, we propose seven important future research avenues. © 2023 Elsevier B.V.","10.1016/j.compind.2023.104044","Article","2024","Deep learning; Learning systems; Business applications; Deep learning; Explainable artificial intelligence; Framework; Interpretable artificial intelligence; Interpretable machine learning; Machine-learning; Methodological frameworks; Theory, context, characteristic, and methodology; XAI; Decision making","Scopus"
"Tensor-Based Baum-Welch Algorithms in Coupled Hidden Markov Model for Responsible Activity Prediction","The development and applications of artificial intelligence (AI) have brought unprecedented opportunities to humans, but also brought many challenges and concerns such as unfairness, immorality, distrust, illegality, and discrimination. Responsible AI provides a new solution to effectively address these AI potential threats by integrating social/physical rules into AI systems. However, these rules are high-level regulations and ethical principles, which are difficult to be formalized. To this end, we attempt to use the data generated in various AI systems such as cyber-physical-social systems (CPSS) to discover and reflect these rules to provide more responsible services for humans. In this article, we first propose a data-driven responsible CPSS framework. Its core idea is to mine valuable rules through perception, fusion, processing, and analysis of CPSS data, and then use these rules to adaptively optimize CPSS. Based on this framework, three tensor-based couple hidden Markov models (T-CHMMs) are constructed to integrate three responsible features (i.e., timing, periodicity, and correlation) for mining potential and valuable rules. Then, the corresponding tensor-based Baum-Welch (TBW) algorithms are designed to solve their learning problems. Finally, the predictive accuracy and computational efficiency of the proposed models and algorithms are verified on three open datasets. The experimental results show that proposed methods have the best performances for various scenarios, which reflects that our methods are more promising and responsible than existing methods.  © 2014 IEEE.","10.1109/TCSS.2022.3227458","Article","2023","Artificial intelligence; Computational efficiency; Forecasting; Learning algorithms; Learning systems; Tensors; Activity predictions; Artificial intelligence systems; Baum-Welch algorithms; Hidden-Markov models; Learning problem; Learning problem of tensor-based couple hidden markov model; Prediction algorithms; Responsible artificial intelligence; Tensor algebra; Hidden Markov models","Scopus"
"From Principles to Practice: Comparative Analysis of European and United States Ethical AI Frameworks for Assessment and Methodological Application","The Z-Inspection® Process is a form of applied research for the ethical assessment of AI systems. It is quickly establishing itself as a robust method to ethically assess AI in Europe. The process is predicated on the European Union's Ethics Guidelines for Trustworthy AI, outlining ethical principles intended to guide European AI development. In contrast, the United States has only recently released its holistic version of such guidelines, the Blueprint for an AI Bill of Rights. The aim of this paper is to assess the suitability of the Blueprint for an AI Bill of Rights as an ethical framework underpinning the use of the Z-Inspection® Process in the United States. This paper provides preliminary findings of comparative analysis of European and United States ethical frameworks for responsible AI development. Findings outline primary ethical concepts that are shared between respective frameworks. Findings suggest the US Blueprint is suitable as an ethical framework for the Z-Inspection® Process. There are notable omissions within the US framework which would require further development for Z-Inspection® use. Discussion will consider opportunities for adapting Z-Inspection® to the United States context, including contributions from the information professions and research.  Annual Meeting of the Association for Information Science & Technology | Oct. 27 – 31, 2023 | London, United Kingdom. Author(s) retain copyright, but ASIS&T receives an exclusive publication license.","10.1002/pra2.792","Article","2023","Artificial intelligence; Blueprints; Ethical technology; Inspection; AI ethic; AI systems; Applied research; Comparative analyzes; European union; Inspection process; International information issue; Legislation and regulation; Robust methods; Value-sensitive AI design; Laws and legislation","Scopus"
"Artificial Intelligence Enabled Network Intrusion Detection Model (AI-NIDM) for Smart Grid Cyber-Physical Systems","The increasing complexity and interconnectivity of Smart Grid Cyber-Physical Systems (SG-CPS) have raised significant concerns regarding the security and integrity of these systems. Network Intrusion Detection Model (NIDM) is an essential component of SG-CPS security infrastructure. However, the conventional rule-based and signature-based NIDM are becoming less effective in detecting advanced and sophisticated cyber-attacks. Artificial Intelligence (AI) technologies, named machine learning, deep learning, and neural networks, have shown great potential in enhancing the accuracy and efficiency of NIDM. This paper proposes an AI-Enabled Network Intrusion Detection Model (AI-NIDM) called GWA-ANN for SG-CPS, which integrates AI techniques with traditional NIDS for improved detection and response to cyber-attacks. The proposed system is evaluated on a public SG-CPS dataset, and the results establish that AI-NIDM can effectively detect and classify various types of cyber-attacks with high accuracy and low false-positive rates. The proposed AI-NIDM can significantly improve the security and resilience of SG-CPS against emerging cyber threats. © 2024, Ismail Saritas. All rights reserved.","","Article","2024","","Scopus"
"Assessing security concerns for ai-based drones in smart cities","This chapter investigates security concerns involving AI-powered drones in smart cities, emphasising the importance of secure deployment. It discusses topics like data privacy, cybersecurity risks, physical security, and ethical repercussions. Security precautions such encrypted communication channels, intrusion detection systems, collision avoidance systems, and observance of moral and legal norms are discussed. The chapter offers case studies of successful AI-based drone deployments as well as recommendations for best practises for upcoming operations. The chapter addresses challenges and embraces ethical concerns in an effort to support the moral integration of AI-based drones in smart city scenarios. © 2023, IGI Global. All rights reserved.","10.4018/978-1-6684-9151-5.ch002","Book chapter","2023","","Scopus"
"Official International Mahjong: A New Playground for AI Research","Games have long been benchmarks and testbeds for AI research. In recent years, with the development of new algorithms and the boost in computational power, many popular games played by humans have been solved by AI systems. Mahjong is one of the most popular games played in China and has been spread worldwide, which presents challenges for AI research due to its multi-agent nature, rich hidden information, and complex scoring rules, but it has been somehow overlooked in the community of game AI research. In 2020 and 2022, we held two AI competitions of Official International Mahjong, the standard variant of Mahjong rules, in conjunction with a top-tier AI conference called IJCAI. We are the first to adopt the duplicate format in evaluating Mahjong AI agents to mitigate the high variance in this game. By comparing the algorithms and performance of AI agents in the competitions, we conclude that supervised learning and reinforcement learning are the current state-of-the-art methods in this game and perform much better than heuristic methods based on human knowledge. We also held a human-versus-AI competition and found that the top AI agent still could not beat professional human players. We claim that this game can be a new benchmark for AI research due to its complexity and popularity among people. © 2023 by the authors.","10.3390/a16050235","Article","2023","Heuristic methods; Multi agent systems; Supervised learning; AI competition; AI systems; Algorithms and performance; Computational power; Game AI; Hidden information; Mahjong; Multi agent; Reinforcement learnings; Scoring rules; Reinforcement learning","Scopus"
"The Role of the Autonomous Machines at the Conclusion of a Contract: Contractual Responsibility According to Current Rules of Private Law and Prospects","Nowadays, one of the most important applications of autonomous AI systems is the conclusion of contracts. Nonetheless, concerns are raised about the validity of the contracts concluded by autonomous machines and, subsequently, about the contractual responsibility in case of non-performance. Various theories have already been expounded in legal doctrine, with the view to tackling thereon. Some of them suggest that autonomous AI systems are mere communication tools or agents that render their user liable, whilst other legal scholars suggest that autonomous AI systems themselves—not their user—should be held liable. After presenting the arguments of these theories, the chapter concludes that the legal community should absolutely accept the validity of the contracts concluded by intelligent agents, considering their users legally bound to their performance. Users’ liability could be based on the theory of de facto contracts (faktische Verträge) or, alternatively, on the doctrine of reliance liability (Vertrauenshaftung). In both cases, users’ right to invalidate the contract in case of mistake must be guaranteed and the mistake shall be assigned to the intelligent agent. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","10.1007/978-3-031-41081-9_5","Book chapter","2023","","Scopus"
"DAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children's Why and How Questions","Children acquire an understanding of the world by asking ""why""and ""how""questions. Conversational agents (CAs) like smart speakers or voice assistants can be promising respondents to children's questions as they are more readily available than parents or teachers. However, CAs' answers to ""why""and ""how""questions are not designed for children, as they can be difficult to understand and provide little interactivity to engage the child. In this work, we propose design guidelines for creating interactive dialogues that promote children's engagement and help them understand explanations. Applying these guidelines, we propose DAPIE, a system that answers children's questions through interactive dialogue by employing an AI-based pipeline that automatically transforms existing long-form answers from online sources into such dialogues. A user study (N=16) showed that, with DAPIE, children performed better in an immediate understanding assessment while also reporting higher enjoyment than when explanations were presented sentence-by-sentence. © 2023 ACM.","10.1145/3544548.3581369","Conference paper","2023","Natural language processing systems; Child; Conversational agents; Dialog; Interactive dialogs; Interactivity; Natural languages; Online sources; Question Answering; Teachers'; User study; User interfaces","Scopus"
"Towards secure private and trustworthy human-centric embedded machine learning: An emotion-aware facial recognition case study","The use of artificial intelligence (AI) at the edge is transforming every aspect of the lives of human beings from scheduling daily activities to personalized shopping recommendations. Since the success of AI is to be measured ultimately in terms of how it benefits human beings, and that the data driving the deep learning-based edge AI algorithms are intricately and intimately tied to humans, it is important to look at these AI technologies through a human-centric lens. However, despite the significant impact of AI design on human interests, the security and trustworthiness of edge AI applications are not foolproof and ethicalneither foolproof nor ethical; Moreover, social norms are often ignored duringin the design, implementation, and deployment of edge AI systems. In this paper, we make the following two contributions: Firstly, we analyze the application of edge AI through a human-centric perspective. More specifically, we present a pipeline to develop human-centric embedded machine learning (HC-EML) applications leveraging a generic human-centric AI (HCAI) framework. Alongside, we also analyzediscuss the privacy, trustworthiness, robustness, and security aspects of HC-EML applications with an insider look at their challenges and possible solutions along the way. Secondly, to illustrate the gravity of these issues, we present a case study on the task of human facial emotion recognition (FER) based on AffectNet dataset, where we analyze the effects of widely used input quantization on the security, robustness, fairness, and trustworthiness of an EML model. We find that input quantization partially degrades the efficacy of adversarial and backdoor attacks at the cost of a slight decrease in accuracy over clean inputs. By analyzing the explanations generated by SHAP, we identify that the decision of a FER model is largely influenced by features such as eyes, alar crease, lips, and jaws. Additionally, we note that input quantization is notably biased against the dark skin faces, and hypothesize that low-contrast features of dark skin faces may be responsible for the observed trends. We conclude with precautionary remarks and guidelines for future researchers. © 2022 The Author(s)","10.1016/j.cose.2022.103058","Article","2023","Deep learning; Ethical technology; Face recognition; Learning systems; Network security; Speech recognition; Adversarial machine learning; Embedded machine learning; Embedded machines; Human-centered artificial intelligence; Machine-learning; Privacy awareness; Robustness; Security; Tiny machine learning; Trustworthiness; Emotion Recognition","Scopus"
"Human-Computer Interaction and AI: What practitioners need to know to design and build effective AI system from a human perspective","AI and ML are now essential parts of many systems that are currently being built. What should CHI practitioners know about the possibilities and potential drawbacks of building AI systems? Understanding the human side of AI/ML based systems requires understanding both how the system-side AI works, but also how people think about, understand, and use AI tools and systems. This course will cover what AI components and systems currently exist, how to design and build usable systems with AI components, along with how the mental models of AI/ML tools operate. These models lead to user expectations of how AI systems function, and ultimately, to design guidelines that avoid disappointing end-users by accidentally creating unintelligible AI tools. We'll also cover the ethics of AI, including data collection, algorithmic and data fairness considerations, along with other risks of AI. © 2023 Owner/Author.","10.1145/3544549.3574170","Conference paper","2023","Curricula; Ethical technology; Human engineering; AI fairness; AI systems; AI trust; Design and build; HAI; Human perspectives; Human-in-the-loop; Mental model; UI design for AI system; UI designs; Human computer interaction","Scopus"
"Ethics in AI Governance: Comparative Analysis, Implication, and Policy Recommendations for the Philippines","This study provides a comparative analysis of Artificial Intelligence (AI) ethical guidelines by looking at six different sources from the USA, European Union, India, Philippines, UNESCO, and CAIDP. The researchers extracted key terms from these guidelines and categorized them based on their frequency across the six sources to get a deeper understanding of their content and identify central themes and topics across each guideline. In doing so, the paper was able to identify ethical considerations and challenges of implementing AI in the Philippine context, including data collection, use and sharing, and AI development. The insights from the literature and document reviews and the analysis of the extracted key terms were used to craft considerations in formulating AI policy for the Philippines. These include (1) defining ethical principles and values in developing and implementing AI, (2) establishing mechanisms for ensuring fairness and preventing bias, (3) implementing mechanisms to ensure security and mitigating risks in AI systems, and (4) assessing potential impacts on AI technologies. Overall, the study uncovered that existing guidelines and legal frameworks on AI ethics seem to have put less emphasis on ethics and fairness. This underpins the need for the PH to ensure that its localized AI ethics policy is clear about its definition of what is ethical and fair use of AI across sectors, industries., demographics, and contexts.  © 2023 IEEE.","10.1109/ICSEC59635.2023.10329756","Conference paper","2023","Data mining; Ethical technology; Public policy; Risk assessment; Artificial intelligence; Artificial intelligence ethic; Artificial intelligence governance; Comparative analyzes; Data policy; Ethical considerations; European union; Guideline; Philippines; Policy recommendations; Artificial intelligence","Scopus"
"Designing an evaluation framework for eXplainable AI in the Healthcare domain","The rapid adoption of Artificial Intelligence (AI) has brought automation and problem-solving capabilities in various fields, including healthcare. However, a significant challenge lies in the lack of explanation for AI predictions, particularly in healthcare, where transparency is crucial. This issue has led to eXplainable AI (XAI) development, focusing on constructing explanations for AI systems. However, the evaluation of these explanations lacks a standardized user-centric approach. This research proposes an evaluation framework for XAI methods to address this gap. The project involves four stages: conducting a systematic review of current evaluation methods, assessing the appropriateness of automatic evaluation of explanations, and conducting user studies to gauge the framework's effectiveness in capturing the user experience complexity. The desired outcome is a user-centric evaluation framework and guidelines, enhancing the scalability of XAI research and fostering confidence in adopting AI systems in the healthcare domain. © 2023 CEUR-WS. All rights reserved.","","Conference paper","2023","Problem solving; 'current; Artificial intelligence systems; Evaluation framework; Explainable artificial intelligence; Healthcare domains; Human-centered artificial intelligence; Problem-solving; Systematic Review; User-centric; User-centric evaluations; Health care","Scopus"
"Using sensitive data to prevent discrimination by artificial intelligence: Does the GDPR need a new exception?","Organisations can use artificial intelligence to make decisions about people for a variety of reasons, for instance, to select the best candidates from many job applications. However, AI systems can have discriminatory effects when used for decision-making. To illustrate, an AI system could reject applications of people with a certain ethnicity, while the organisation did not plan such ethnicity discrimination. But in Europe, an organisation runs into a problem when it wants to assess whether its AI system accidentally discriminates based on ethnicity: the organisation may not know the applicants’ ethnicity. In principle, the GDPR bans the use of certain ‘special categories of data’ (sometimes called ‘sensitive data’), which include data on ethnicity, religion, and sexual preference. The proposal for an AI Act of the European Commission includes a provision that would enable organisations to use special categories of data for auditing their AI systems. This paper asks whether the GDPR's rules on special categories of personal data hinder the prevention of AI-driven discrimination. We argue that the GDPR does prohibit such use of special category data in many circumstances. We also map out the arguments for and against creating an exception to the GDPR's ban on using special categories of personal data, to enable preventing discrimination by AI systems. The paper discusses European law, but the paper can be relevant outside Europe too, as many policymakers in the world grapple with the tension between privacy and non-discrimination policy. © 2022","10.1016/j.clsr.2022.105770","Article","2023","Behavioral research; Decision making; Sensitive data; AI auditing; AI fairness testing; AI systems; Automated decision making; Decisions makings; Job application; Non-discrimination; Sensitive datas; Special category of data; Testing an AI system for discrimination; Artificial intelligence","Scopus"
"AI-Based Planning of Business Management","Artificial intelligence (AI)-based planning is a powerful tool for enhancing business management, offering accurate insights and informed decision-making. However, challenges like data privacy, bias, and job impact must be addressed. Best practices, human oversight, and ethical policies are crucial for responsible implementation. Understanding objectives, selecting appropriate tools, and ensuring technical readiness are key to successful integration. AI-based planning has transformative potential, but a critical and responsible approach is essential for sustainable systems. © 2024 selection and editorial matter, Kiran Chaudhary and Mansaf Alam; individual chapters, the contributors.","10.1201/9781032614083-10","Book chapter","2023","","Scopus"
"Black is the new orange: how to determine AI liability","Autonomous artificial intelligence (AI) systems can lead to unpredictable behavior causing loss or damage to individuals. Intricate questions must be resolved to establish how courts determine liability. Until recently, understanding the inner workings of “black boxes” has been exceedingly difficult; however, the use of Explainable Artificial Intelligence (XAI) would help simplify the complex problems that can occur with autonomous AI systems. In this context, this article seeks to provide technical explanations that can be given by XAI, and to show how suitable explanations for liability can be reached in court. It provides an analysis of whether existing liability frameworks, in both civil and common law tort systems, with the support of XAI, can address legal concerns related to AI. Lastly, it claims their further development and adoption should allow AI liability cases to be decided under current legal and regulatory rules until new liability regimes for AI are enacted. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","10.1007/s10506-022-09308-9","Article","2023","Product liability; Artificial intelligence systems; Black boxes; Civil laws; Common law; Complex problems; Explainability; Explainable artificial intelligence (XAI); Further development; Legal concern; Liability; Artificial intelligence","Scopus"
"AI in Healthcare: Impacts, Risks and Regulation to Mitigate Adverse Impacts","The rapid advancements in artificial intelligence (AI) have revolutionised various industries, including healthcare. AI systems in healthcare hold immense potential for improving patient outcomes, accelerating diagnosis, and enhancing overall healthcare delivery. However, the introduction of AI in healthcare also brings forth significant ethical, legal, and societal implications that necessitate a robust regulatory framework. This position paper aims to discuss the use and the risk of AI in healthcare, and also how the regulations or guidelines aiming to mitigate their potential adverse impact on individuals and societies corresponds to it. © 2023 CEUR-WS. All rights reserved.","","Conference paper","2023","Artificial intelligence; Ethical technology; Laws and legislation; Artificial intelligence harm; Artificial intelligence healthcare; Artificial intelligence regulation; Artificial intelligence systems; Ethic of artificial intelligence; Ethical implications; Healthcare delivery; Impact risk; Legal implications; Societal implications; Health care","Scopus"
"Challenges of Testing Cognitive EW Systems","This paper describes some of the test infrastructure requirements for testing the performance of artificial intelligence (AI) systems that can learn from novel experiences in the field. As a test community, we must validate the learning process, rather than validating the learned model. Cognitive capabilities will force multiple paradigm shifts from legacy test and evaluation (T&E) approaches. Notably, the system may never be the same twice. Testing must therefore become a continuous process, rather than a final exam, where we develop tests to understand system limitations and range of effectiveness. These paradigm shifts highlight some of the improvements needed in the current test infrastructure. The paper describes some of the requirements that should be placed on cognitive systems for data collection, transparency, and rules for how to interact with legacy systems. We use Cognitive Electronic Warfare (CogEW) as the motivating scenario, where AI enables EW systems to respond more quickly and effectively to real-world conditions with complex and novel emitters.  © 2023 IEEE.","10.1109/AUTOTESTCON47464.2023.10296319","Conference paper","2023","Cognitive systems; E-learning; Electronic warfare; Learning systems; Legacy systems; Machine learning; Military applications; Artificial intelligence systems; Assurance; Cognitive electronic warfare; Learn+; Learning process; Machine-learning; Paradigm shifts; Performance; Test and evaluation; Test infrastructures; Information management","Scopus"
"Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes","Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by ‘contextual explanations’ that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients’ clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) - a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians’ usage of AI models. © 2023","10.1016/j.artmed.2023.102498","Article","2023","Artificial Intelligence; Diabetes Mellitus, Type 2; Humans; Trust; Epidemiology; Forecasting; Modeling languages; Risk perception; Clinical explainability; Comorbidities; Contextual explanation; Question Answering; Question-answering approach; Risk prediction models; Risk predictions; Type-2 diabetes; Type-2 diabetes comorbidity risk prediction; User driven; adult; Article; artificial intelligence; chronic kidney failure; clinical assessment; clinical indicator; clinician; comorbidity; disease simulation; female; human; male; non insulin dependent diabetes mellitus; post hoc analysis; practice guideline; predictive model; qualitative analysis; quantitative analysis; risk assessment; artificial intelligence; trust; Risk assessment","Scopus"
"AI-based ICD coding and classification approaches using discharge summaries: A systematic literature review","The assignment of codes to free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning clinical codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related machine learning and deep learning methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. The main objective of this systematic literature review is to provide a comprehensive overview of automated clinical coding systems that utilise appropriate NLP, machine learning and deep learning methods and techniques to assign the International Classification of Diseases (ICD) codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2021 in four high quality academic databases: PubMed, ScienceDirect, Association for Computing Machinery (ACM) Digital Library, and the Association for Computational Linguistics (ACL) Anthology. We reviewed 6128 publications; 42 met the inclusion criteria. This review identified: 6 datasets having discharge summaries (2 publicly available, 4 acquired from hospitals); 14 NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. The review also shows that there is a significant increase in the use of deep learning models compared to machine learning. To measure the performance of classification methods, different evaluation metrics are used. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers. © 2022 Elsevier Ltd","10.1016/j.eswa.2022.118997","Review","2023","Classification (of information); Clinical research; Codes (symbols); Data mining; Digital libraries; Extraction; Learning algorithms; Learning systems; Linguistics; Machinery; Natural language processing systems; Text processing; Classification and coding; Clinical classification; Clinical classification and coding; Computer assisted; Computer assisted clinical coding; Deep learning; Discharge summary; Language processing; Machine-learning; Natural language processing; Natural languages; Deep learning","Scopus"
"The Human Factors of AI-Empowered Knowledge Sharing","Many industries are facing the challenge of how to capture workers' knowledge such that it can be shared, in particular tacit knowledge. The operation of complex systems such as a manufacturing line is knowledge-intensive, especially if the operator must frequently reconfigure it for different products. Considering the breadth and dynamic nature of this knowledge, existing solutions for sharing knowledge (e.g., word-of-mouth, issue reports, document creation, and decision support systems) are inefficient and/or resource-intensive. Conversational user interfaces are an efficient way to convey information that mimics the way humans share knowledge; however, we know little about how to design them specifically for this purpose, especially regarding tacit knowledge. In this work, my main goal is to investigate how a cognitive assistant can be designed to facilitate (tacit) knowledge transfer between users of dynamic complex systems. I aim to achieve this by outlining the design requirements, challenges, and opportunities in factories; by collaboratively designing, implementing, and evaluating a cognitive assistant for sharing knowledge; studying the effects of design characteristics on aspects such as user experience; and finally, creating a set of design guidelines. © 2023 Owner/Author.","10.1145/3544549.3577044","Conference paper","2023","Artificial intelligence; Cognitive systems; Industry 4.0; Knowledge management; User interfaces; Chatbots; Cognitive assistant; Dynamic nature; Human-centered AI; Industry 5.0; Knowledge-sharing; Manufacturing lines; Sharing knowledge; Tacit knowledge; Workers'; Decision support systems","Scopus"
"A Design Science Research Approach Towards Knowledge Discovery and Predictive Maintenance of MEMS Inertial Sensors Using Machine Learning","Knowledge discovery is the process of extracting relevant and practical information from a collection of structured or unstructured data. In numerous applications, such as marketing, fraud detection, telecommunication, and manufacturing, it is an unavoidable step. The complexity of the discovery process has risen along with the volume of data during the past few decades. In this situation, artificial intelligence (AI)-based solutions have emerged as the most advantageous. However, there is a lack of a rigorous strategy in the knowledge extraction and reuse processes. A qualitative research paradigm known as Design Science Research (DSR), provides systematic recommendations for the generalization and transferability of newly produced knowledge utilizing artifacts. In this research, we present an artifact for the early prediction of impacted micro-electromechanical systems (MEMS)-based inertial sensors. MEMS-based inertial sensor manufacturing is complex and time-consuming. Moreover, there is a persistent need for more precise products, streamlined production stages, and quicker solutions. One way of achieving this is through optimized manufacturing processes using AI-based solutions. However, many difficulties are encountered, including problems with data collection, data analysis, computational power availability, platform compatibility, etc. Thorough and systemic guidelines can ensure the avoidance of all these issues. The proposed artifact is created using a DSR approach utilizing various machine learning algorithms for predictive maintenance of MEMS-based inertial sensors along with providing optimal feature selection methods. A thorough demonstration of the artifact designing and evaluation process is provided using a real use case. The manufacturing process has been improved by further investigation of the results to help with knowledge discovery and re-usability. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","10.1007/978-3-031-41774-0_25","Conference paper","2023","Data acquisition; Design; Inertial navigation systems; Learning algorithms; Machine learning; Maintenance; MEMS; Design-science researches; Fraud detection; Inertial sensor; Machine-learning; Manufacturing process; Micro electromechanical system inertial sensors; Predictive maintenance; Research approach; Structured data; Unstructured data; Data mining","Scopus"
"A Comprehensive Review of Conversational AI-Based Chatbots: Types, Applications, and Future Trends","It is an evident fact that almost every application area in the present-day world is driven by technology and a core reason for this disruption is Artificial Intelligence (AI) and Machine learning (ML). Among them, chatbot research is one of the core areas that is driven by AI. The shift from simple rule-based chatbots to AI-based conversational agents was all possible because of advancements in conversational AI research. This paper provides an in-depth review of the evolution of chatbot technology on an AI front, its applications in real-world scenarios, and hence the future trends associated with it. Additionally, a critical comparison of state-of-the-art conversational AI frameworks is also incorporated into the study. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-19-9719-8_24","Conference paper","2023","Artificial intelligence; Learning algorithms; Application area; Artificial intelligence learning; Chatbots; Conversational artificial intelligence; Future trends; Language processing; Natural language processing; Natural language understanding; Natural languages; Natural language processing systems","Scopus"
"A Comprehensive Review on AI-Enabled Models for Parkinson’s Disease Diagnosis","Parkinson’s disease (PD) is a devastating neurological disease that cannot be identified with traditional plasma experiments, necessitating the development of a faster, less expensive diagnostic instrument. Due to the difficulty of quantifying PD in the past, doctors have tended to focus on some signs while ignoring others, primarily relying on an intuitive assessment scale because of the disease’s characteristics, which include loss of motor control and speech that can be utilized to detect and diagnose this disease. It is an illness that impacts both motion and non-motion functions. It takes years to develop and has a wide range of clinical symptoms and prognoses. Parkinson’s patients commonly display non-motor symptoms such as sleep problems, neurocognitive ailments, and cognitive impairment long before the diagnosis, even though scientists have been working to develop designs for diagnosing and categorizing the disease, only noticeable defects such as movement patterns, speech, or writing skills are offered in this paper. This article provides a thorough analysis of several AI-based ML and DL techniques used to diagnose PD and their influence on developing additional research directions. It follows the guidelines of Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR). This review also examines the current state of PD diagnosis and the potential applications of data-driven AI technology. It ends with a discussion of future developments, which aids in filling critical gaps in the current Parkinson’s study. © 2023 by the authors.","10.3390/electronics12040783","Review","2023","","Scopus"
"Distributed Tracing for Troubleshooting of Native Cloud Applications via Rule-Induction Systems","Diagnosing IT issues is a challenging problem for large-scale distributed cloud environments due to complex and non-deterministic interrelations between the system components. Modern monitoring tools rely on AI-empowered data analytics for detection, root cause analysis, and rapid resolution of performance degradation. However, the successful adoption of AI solutions is anchored on trust. System administrators will not unthinkingly follow the recommendations without sufficient interpretability of solutions. Explainable AI is gaining popularity by enabling improved confidence and trust in intelligent solutions. For many industrial applications, explainable models with moderate accuracy are preferable to highly precise black-box ones. This paper shows the benefits of rule-induction classification methods, particularly RIPPER, for the root cause analysis of performance degradations. RIPPER reveals the causes of problems in a set of rules system administrators can use in remediation processes. Native cloud applications are based on the microservices architecture to consume the benefits of distributed computing. Monitoring such applications can be accomplished via distributed tracing, which inspects the passage of requests through different microservices. We discuss the application of rule-learning approaches to trace traffic passing through a malfunctioning microservice for the explanations of the problem. Experiments performed on datasets from cloud environments proved the applicability of such approaches and unveiled the benefits. © 2023, IICM. All rights reserved.","10.3897/jucs.112513","Article","2023","","Scopus"
"Automating Data Quality Monitoring with Reference Data Profiles","Data quality is of central importance for the qualitative evaluation of decisions taken by AI-based applications. In practice, data from several heterogeneous data sources is integrated, but complete, global domain knowledge is often not available. In such heterogeneous scenarios, it is particularly difficult to monitor data quality (e.g., completeness, accuracy, timeliness) over time. In this paper, we formally introduce a new data-centric method for automated data quality monitoring, which is based on reference data profiles. A reference data profile is a set of data profiling statistics that is learned automatically to model the target quality of the data. In contrast to most existing data quality approaches that require domain experts to define rules, our method can be fully automated from initialization to continuous monitoring. This data-centric method has been implemented in our data quality tool DQ-MeeRKat and evaluated with six real-world telematic device data streams. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-37890-4_2","Conference paper","2023","Automation; Data reduction; Domain Knowledge; Knowledge graph; Quality control; Automated quality check; Data centric; Data profiles; Data quality; Data quality monitoring; Knowledge graphs; Quality checks; Quality monitoring; Reference data; Reference data profile; Telematics","Scopus"
"An AI-Based Newly Developed Analytical Formulation for Discharging Behavior of Supercapacitors with the Integration of a Review of Supercapacitor Challenges and Advancement Using Quantum Dots","A supercapacitor is a type of electrical component that has larger capacitance, due to asymmetric behavior with better power density, and lower ESR (effective series resistance) than conventional energy-storage components. Supercapacitors can be used with battery technology to create an effective energy storage system due to their qualities and precise characterization. Studies have shown that the use of quantum dots as electrodes in supercapacitors can significantly increase their effectiveness. In this research article, we have used a Drude model based on free electrons (asymmetric nature) to describe the supercapacitor’s discharging characteristics. Commercially available Nippon DLA and Green-cap supercapacitors were used to verify the Drude model by discharging them through a constant current source using a simple current mirror circuit. The parameters of both the fractional-order models and our suggested method were estimated using the least-squares regression fitting approach. An intriguing finding from the Drude model is the current-dependent behavior of the leakage-parallel resistance in the constant current discharge process. Instead of using the traditional exponential rule, supercapacitors discharge according to a power law. This work reflects the strong symmetry of different aspects of designing a hybrid supercapacitor with high efficiency and reliability. © 2023 by the authors.","10.3390/sym15040844","Article","2023","","Scopus"
"Explainable AI for Intrusion Prevention: A Review of Techniques and Applications","Intrusion prevention has become a critical concern in today's increasingly complex and interconnected digital systems. Traditional intrusion prevention methods often rely on rule-based approaches that can be inflexible and prone to false positives and false negatives. The emergence of explainable artificial intelligence (AI) techniques has the potential to provide more accurate and interpretable solutions for intrusion prevention. This review paper surveys the current state of the art in explainable AI techniques for intrusion prevention, including their strengths and limitations. We begin by providing an overview of intrusion prevention and the challenges faced by traditional methods. We then explore the different types of explainable AI techniques, such as Local Interpretable Model-Agnostic Explanations (LIME), Shapley Additive Explanations (SHAP), and Integrated Gradients, and their application to intrusion prevention. We also discuss the different types of datasets and evaluation metrics used in explainable AI-based intrusion prevention, including public datasets such as NSL-KDD and UNSW-NB15. Finally, we highlight the future research directions in explainable AI-based intrusion prevention, including the need for larger and more diverse datasets, better evaluation metrics, and more comprehensive explainable AI models. Overall, this review paper provides a comprehensive overview of the state of the art in explainable AI for intrusion prevention, and serves as a valuable resource for researchers and practitioners in the field. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.","10.1007/978-981-99-3758-5_31","Conference paper","2023","Artificial intelligence; Lime; Artificial intelligence techniques; Digital system; Evaluation metrics; Explainable artificial intelligence; Intrusion prevention; Local interpretable model-agnostic explanation; Review papers; Shapley; Shapley additive explanation; State of the art; Additives","Scopus"
"The law and economics of AI liability","The employment of AI systems presents challenges for liability rules. This paper identifies these challenges and evaluates how liability rules should be adapted in response. The paper discusses the gaps in liability that arise when AI systems are unpredictable or act (semi)-autonomously. It considers the problems in proving fault and causality when errors in AI systems are difficult to foresee for producers, and monitoring duties of users are difficult to define. From an economic perspective, the paper considers what liability rules would minimise costs of harm related to AI. Based on the analysis of risks and optimal liability rules, the paper evaluates the recently published EU proposals for a Product Liability Directive and for an AI Liability Directive. © 2023","10.1016/j.clsr.2023.105794","Article","2023","Product liability; Risk analysis; AI systems; Economic perspective; EU law; Liability; Products liabilities; Risk assessment","Scopus"
"Co-design of a Social Robot for Distraction in the Paediatric Emergency Department","We are developing a social robot to help children cope with painful and distressing medical procedures in the hospital emergency department. This is a domain where a range of interventions have proven effective at reducing pain and distress, including social robots; however, until now, the robots have been designed with limited stakeholder involvement and have shown limited autonomy. For our system, we have defined and validated the necessary robot behaviour together with children, parents/caregivers, and healthcare professionals, taking into account the ethical and social implications of robotics and AI in the paediatric healthcare context. The result of the co-design process has been captured in a flowchart, which has been converted into a set of concrete design guidelines for the AI-based autonomous robot system. © 2023 IEEE Computer Society. All rights reserved.","10.1145/3568294.3580127","Conference paper","2023","Economic and social effects; Emergency rooms; Health care; Machine design; Child-robot interactions; Co-designs; Emergency departments; Health care professionals; Hospital emergency departments; Medical procedures; Robot behavior; Social robots; Socially assistive robots; Stakeholder involvement; Pediatrics","Scopus"
"SAT: a methodology to assess the social acceptance of innovative AI-based technologies","Purpose: The purpose of this paper is to present the conceptual model of an innovative methodology (SAT) to assess the social acceptance of technology, especially focusing on artificial intelligence (AI)-based technology. Design/methodology/approach: After a review of the literature, this paper presents the main lines by which SAT stands out from current methods, namely, a four-bubble approach and a mix of qualitative and quantitative techniques that offer assessments that look at technology as a socio-technical system. Each bubble determines the social variability of a cluster of values: User-Experience Acceptance, Social Disruptiveness, Value Impact and Trust. Findings: The methodology is still in development, requiring further developments, specifications and validation. Accordingly, the findings of this paper refer to the realm of the research discussion, that is, highlighting the importance of preventively assessing and forecasting the acceptance of technology and building the best design strategies to boost sustainable and ethical technology adoption. Social implications: Once SAT method will be validated, it could constitute a useful tool, with societal implications, for helping users, markets and institutions to appraise and determine the co-implications of technology and socio-cultural contexts. Originality/value: New AI applications flood today’s users and markets, often without a clear understanding of risks and impacts. In the European context, regulations (EU AI Act) and rules (EU Ethics Guidelines for Trustworthy) try to fill this normative gap. The SAT method seeks to integrate the risk-based assessment of AI with an assessment of the perceptive-psychological and socio-behavioural aspects of its social acceptability. © 2022, Emerald Publishing Limited.","10.1108/JICES-09-2021-0095","Article","2023","","Scopus"
"Harnessing Artificial Intelligence Technologies for Sustainable Space Missions: Legal Perspectives","Artificial Intelligence (AI) represents an opportunity, but also a challenge, for the future of space activities and its legal framework. Expanding connectivity and symbiotic interaction between humans and intelligent machines raises significant questions for the rule of law, including the liability regime in case of damage arising from actions undertaken through the utilization of increasingly advanced AI in space missions. Artificial Intelligence technologies also encompass a series of possibilities for space sustainability. We describe the legal issues brought by this technology, and then focus specifically on AI systems for space operations, which entail questions about how these interact with existing legal concepts and technical standards. We address the role of AI for space sustainability, especially in relation to how it can support the implementation of the 2019 UNCOPUOS Guidelines for the Long-term Sustainability of Space Activities. We also discuss how space law is relevant and applicable to AI use in the context of sustainable space operations, including autonomous action to avoid collisions in orbit and space traffic management to limit orbital congestion. © 2024 selection and editorial matter, Matteo Madi and Olga Sokolova; individual chapters, the contributors.","10.1201/9781003366386-8","Book chapter","2023","","Scopus"
"Sentiment Analysis of Social Media with AI","Sentiment analysis, a crucial aspect of social media analysis, plays a significant role in understanding public opinions and attitudes towards products, services, and events. This chapter provides an overview of the use of artificial intelligence (AI) to conduct sentiment analysis for social media platforms. Various approaches to sentiment analysis, including rule-based, automated, and hybrid methods, are discussed, highlighting their respective strengths and limitations. The chapter further explores different types of sentiment analysis, such as fine-grained sentiment analysis, emotion detection, intent-based sentiment analysis, and aspect-based sentiment analysis, each serving specific analytical purposes. The advantages and disadvantages of employing AI-based sentiment analysis for social media are examined, emphasising its potential for providing valuable insights for businesses, economics, and finance. The chapter outlines popular software tools utilised for conducting sentiment analysis on social media data using AI techniques. It also addresses the cautionary measures, limitations, and challenges associated with sentiment analysis, including issues related to accuracy, context, language nuances, and bias. Overall, this chapter serves as a comprehensive guide to the application of sentiment analysis for social media analysis using AI, offering researchers, practitioners, and decision-makers valuable insights into harnessing the power of public sentiment for informed decision-making. © 2024 selection and editorial matter, Kiran Chaudhary and Mansaf Alam; individual chapters, the contributors.","10.1201/9781032614083-2","Book chapter","2023","","Scopus"
"Human-Centered Explainable AI (HCXAI): Coming of Age","Explainability is an essential pillar of Responsible AI that calls for equitable and ethical Human-AI interaction. Explanations are essential to hold AI systems and their producers accountable, and can serve as a means to ensure humans' right to understand and contest AI decisions. Human-centered XAI (HCXAI) argues that there is more to making AI explainable than algorithmic transparency. Explainability of AI is more than just ""opening""the black box - who opens it matters just as much, if not more, as the ways of opening it. In this third CHI workshop on Human-centered XAI (HCXAI), we build on the maturation through the first two installments to craft the coming-of-age story of HCXAI, which embodies a deeper discourse around operationalizing human-centered perspectives in XAI. We aim towards actionable interventions that recognize both affordances and potential pitfalls of XAI. The goal of the third installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we emphasize ""operationalizing.""Within our research agenda for XAI, we seek actionable analysis frameworks, concrete design guidelines, transferable evaluation methods, and principles for accountability. © 2023 Owner/Author.","10.1145/3544549.3573832","Conference paper","2023","Affordances; AI systems; Algorithmics; Analysis frameworks; Black boxes; Conceptual levels; Concrete design; Human rights; Research agenda; Technical levels","Scopus"
"Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages","Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.  © 2023 ACM.","10.1145/3579592","Article","2023","Computational linguistics; Diseases; Natural language processing systems; Text messaging; Vaccines; Artificial intelligence-mediated communication; Language model; Language processing; Large language model; Mediated Communication; Message factor; Natural language processing; Natural languages; Persuasion; Public health messaging; Disease control","Scopus"
"Trustworthy Algorithmic Ranking Systems","This tutorial aims at providing its audience an interdisciplinary overview about the topics of fairness and non-discrimination, diversity, and transparency as relevant dimensions of trustworthy AI systems, tailored to algorithmic ranking systems such as search engines and recommender systems. We will equip the mostly technical audience of WSDM with the necessary understanding of the social and ethical implications of their research and development on the one hand, and of recent ethical guidelines and regulatory frameworks addressing the aforementioned dimensions on the other hand. While the tutorial foremost takes a European perspective, starting from the concept of trustworthy AI and discussing EU regulation in this area currently in the implementation stages, we also consider related initiatives worldwide. Since ensuring non-discrimination, diversity, and transparency in retrieval and recommendation systems is an endeavor in which academic institutions and companies in different parts of the world should collaborate, this tutorial is relevant for researchers and practitioners interested in the ethical, social, and legal impact of their work. The tutorial, therefore, targets both academic scholars and practitioners around the globe, by reviewing recent research and providing practical examples addressing these particular trustworthiness aspects, and showcasing how new regulations affect the audience's daily work. © 2023 Owner/Author.","10.1145/3539597.3572723","Conference paper","2023","Ethical technology; Laws and legislation; Recommender systems; Search engines; AI systems; Algorithmics; Diversity; Explainability; Fairness; Non-discrimination; Ranking; Ranking system; Regulation; Web searches; Transparency","Scopus"
"Boosting Methods for Federated Learning","Federated Learning (FL) has been proposed to develop better AI systems without compromising the privacy of final users and the legitimate interests of private companies. Initially deployed by Google to predict text input on mobile devices, FL has been deployed in many other industries. Since its introduction, Federated Learning mainly exploited the inner working of neural networks and other gradient descent-based algorithms by either exchanging the weights of the model or the gradients computed during learning. While this approach has been very successful, it rules out applying FL in contexts where other models are preferred, e.g., easier to interpret or known to work better. This paper proposes to leverage distributed versions of the AdaBoost algorithm to acquire strong federated models. In contrast with previous approaches, our proposal does not put any constraint on the client-side learning models and does not rely on inner workings of the learning algorithms used in the clients. We perform a large set of experiments on ten UCI datasets, comparing the algorithms in six non-iidness settings. Results show that the approach is effective, in the case of an IID setting, results are often near to the theoretical optimum (i.e., the performances of AdaBoost on the complete dataset). In case of non-IID settings, results very much depend on the severity of the non-IIDness. © 2023 CEUR-WS. All rights reserved.","","Conference paper","2023","Adaptive boosting; Gradient methods; Large dataset; AI systems; Boosting; Boosting method; Cross-silo; Ensemble learning; Federated learning; Google+; Neural-networks; Private companies; Text input; Learning systems","Scopus"
"Feature Selection via Minimal Covering Sets for Industrial Internet of Things Applications","High stakes decision making requires that any decision support systems must be able to come up with plausible explanations about the decisions they propose to the user. Several popular approaches to explaining black-box AI systems, such as neural networks, focus either on highlighting the features that matter the most in one particular decision as in the SHAP models, or on developing a local to the particular instance data model that is explainable by nature, such as a decision tree. ML systems that are by default explainable and/or interpretable, such as decision trees, or rule-based systems do not require such third-party approaches, as they are themselves explainable. Nevertheless, presenting a consistent (small) set of features to the users as explanations for any given proposed decision can increase the confidence of the users towards the reliability of the system. For this reason, we have developed a system that given a set of rules that hold on a training dataset, finds a minimal cardinality set of features that are used in a set of rules that together cover the entire training dataset. We develop a parallel heuristic algorithm for finding such a minimal variables set, and we show it outperforms all state-of-the-art optimization solvers for finding the solution to a MIP formulation of the problem. Experiments with data from use cases applying AI in public policy decision making as well as in medical use cases show that the proposed small set of features is sufficient to explain all the cases in the test dataset via rules containing only variables from the proposed set of features.  © 2023 IEEE.","10.1109/DCOSS-IoT58021.2023.00092","Conference paper","2023","Decision support systems; Decision trees; Heuristic algorithms; Industry 4.0; Machine learning; Statistical tests; AI systems; Black boxes; Decisions makings; Explainable artificial intelligence; Features selection; Industrial internet of thing; Machine-learning; Set of rules; Sets of features; Training dataset; Internet of things","Scopus"
"Using Artificial Intelligence Assistant Technology to Develop Animation Games on IoT","This research proposes an XNA animation game system with AI technology for action animation games in mobile devices, based on an object-oriented modular concept. The animation game function with AI technology is encapsulated into independent objects, through the combination of objects to build repetition. It adds AI technology to the finite state machine, fuzzy state machine and neural network and attempts to combine the traditional rule-base system and learning adaptation system to increase the learning ability of traditional AI roles. The main contributions are compared with traditional methods and the AI animation game system is shown to have more reusability, design flexibility and expansibility of its AI system through the object composition approach. It adds AI technology to combine the traditional rule-base system and learning adaptation system to increase the learning ability of traditional AI roles. Therefore, AI animation game producers can accelerate their processes of developing animation games and reducing costs. © 2023, ComSIS Consortium. All rights reserved.","10.2298/CSIS220719021Z","Article","2023","","Scopus"
"Investigating Semi-Automatic Assessment of Data Sets Fairness by Means of Fuzzy Logic","Research has shown how data sets convey social bias in AI systems, especially those based on machine learning. A biased data set is not representative of reality and might contribute to perpetuate societal biases within the model. To tackle this problem, it is important to understand how to avoid biases, errors, and unethical practices while creating the data sets. In this work we offer a preliminary framework for the semi-Automated evaluation of fairness in data sets, by combining statistical information about data with qualitative consideration. We address the issue of how much (un)fairness can be included in a data set used for machine learning research, focusing on classification issues. In order to provide guidance for the use of data sets in contexts of critical decision-making, such as health decisions, we identify six fundamental features (balance, numerosity, unevenness, compliance, quality, incompleteness) that could affect model fairness. We developed a rule-based approach based on fuzzy logic that combines these characteristics into a single score and enables a semi-Automatic evaluation of a data set in algorithmic fairness research.  © 2023 IEEE.","10.1109/CIBCB56990.2023.10264913","Conference paper","2023","Automation; Classification (of information); Computer circuits; Decision making; Machine learning; AI systems; Bias error; Data bias; Data set; Fairness; Fuzzy-Logic; Machine-learning; On-machines; Semi-automatic assessment; Trustworthy artificial intelligence; Fuzzy logic","Scopus"
"A Multi-Layer Intrusion Detection System for SOME/IP-Based In-Vehicle Network","The automotive Ethernet is gradually replacing the traditional controller area network (CAN) as the backbone network of the vehicle. As an essential protocol to solve service-based communication, Scalable service-Oriented MiddlewarE over IP (SOME/IP) is expected to be applied to an in-vehicle network (IVN). The increasing number of external attack interfaces and the protocol’s vulnerability makes SOME/IP in-vehicle networks vulnerable to intrusion. This paper proposes a multi-layer intrusion detection system (IDS) architecture, including rule-based and artificial intelligence (AI)-based modules. The rule-based module is used to detect the SOME/IP header, SOME/IP-SD message, message interval, and communication process. The AI-based module acts on the payload. We propose a SOME/IP dataset establishment method to evaluate the performance of the proposed multi-layer IDS. Experiments are carried out on a Jetson Xavier NX, showing that the accuracy of AI-based detection reached 99.7761% and that of rule-based detection was 100%. The average detection time per packet is 0.3958 ms with graphics processing unit (GPU) acceleration and 0.6669 ms with only a central processing unit (CPU). After vehicle-level real-time analyses, the proposed IDS can be deployed for distributed or select critical advanced driving assistance system (ADAS) traffic for detection in a centralized layout. © 2023 by the authors.","10.3390/s23094376","Article","2023","Computer crime; Computer graphics; Computer graphics equipment; Control system synthesis; Deep learning; Graphics processing unit; Internet protocols; Intrusion detection; Middleware; Network security; Program processors; Vehicle to vehicle communications; Automotives; Back-bone network; Controller-area network; Deep learning; In-vehicle networks; Intrusion Detection Systems; Multi-layers; Rule based; Service-oriented middleware; Service-oriented middleware over IP; acceleration; article; artificial intelligence; deep learning; Vehicles","Scopus"
"Trustworthy AI: A Fuzzy-Multiple Method for Evaluating Ethical Principles in AI Regulations","In this study, we investigated the ethical principles of trustworthy AI and differentiated five prime factors essential for developing trust in AI and most widely presented in regulatory guidelines worldwide. By utilizing Fuzzy Logic Toolbox in MATLAB 9.4, we evaluated the impact of primary ethical principles on trustworthy AI systems in a systematic and structured manner. We discovered that the principle of Fairness and Non-discrimination is the most influential for the development of trustworthy AI, as it is the most represented in the regulatory guidelines. The proposed model offers two main benefits for developers and deployers of AI systems, including predicting the potential public trust in AI systems and assessment compliance with the regulatory frameworks. To ensure the continued trustworthiness of AI systems, the model should be used at all stages of the software life circle, including during development, before placing the system on the market, and at the stage of use to monitor compliance with the safeguards declared to users. © 2023 IEEE.","10.1109/ACIT58437.2023.10275505","Conference paper","2023","Fuzzy logic; Philosophical aspects; Regulatory compliance; AI systems; Ethical principle of AI; Ethical principles; Fuzzy Logic Toolbox; Multiple methods; Prime factors; Regulation; Regulatory guidelines; Trust; Trustworthy AI; MATLAB","Scopus"
"DERIVING TRUST-SUPPORTING DESIGN KNOWLEDGE FOR AI-BASED CHATBOTS IN CUSTOMER SERVICE: A USE CASE FROM THE AUTOMOTIVE INDUSTRY","In the automotive industry, companies are increasingly implementing Artificial Intelligence (AI)-based chatbots to support various processes, especially in the context of customer service. However, there currently is a lack of knowledge, especially systematically derived design knowledge, regarding customer trust in interacting with AI-based chatbots. In this context, a lack of security and transparency, limited social features, and the communication style and quality-related issues of AI-based chatbots are just a few aspects that inhibit customer trust in interacting with this innovative technology, thereby hindering the adoption of chatbots. To address this knowledge gap, we adopted a design theory-based approach and developed a design concept for trust-supporting design knowledge regarding customer interaction with an AI-based chatbot. Design science provides a structured development and evaluation process to support, for example, the adoption of AI-based chatbots. Drawing on trust-based literature, a use case in customer service in the automotive industry, and seven semi-structured expert interviews, we propose 10 meta/user requirements and four design principles for trust-supporting design elements as (e.g. social) signals (stimuli) regarding the interaction with AI-based chatbots. We developed two click prototypes over two evaluation cycles. Each evaluation included an online survey with 180 participants. The findings that were obtained make a valuable contribution to solving the described lack of design knowledge by developing and evaluating different design approaches in the form of prototypical user interfaces. Moreover, the results show that visible design elements such as transparent and factual security signals (stimuli) and trust seals have a significant impact on customer trust. © 2023 Taylor & Francis Group, LLC.","10.1080/10919392.2023.2276631","Article","2023","","Scopus"
"The configurational effects of artificial intelligence-based hiring decisions on applicants' justice perception and organisational commitment","Purpose: This study aims to investigate the configurational effects of five rules – artificial intelligence (AI)-based hiring decision transparency, consistency, voice, explainability and human involvement – on applicants' procedural justice perception (APJP) and applicants' interactional justice perception (AIJP). In addition, this study examines whether the identified configurations could further enhance applicants' organisational commitment (OC). Design/methodology/approach: Drawing on the justice model of applicants' reactions, the authors conducted a longitudinal survey of 254 newly recruited employees from 36 Chinese companies that utilise AI in their hiring. The authors employed fuzzy-set qualitative comparative analysis (fsQCA) to determine which configurations could improve APJP and AIJP, and the authors used propensity score matching (PSM) to analyse the effects of these configurations on OC. Findings: The fsQCA generates three patterns involving five configurations that could improve APJP and AIJP. For pattern 1, when AI-based recruitment with high interpersonal rule (AI human involvement) aims for applicants' justice perception (AJP) through the combination of high informational rule (AI explainability) and high procedural rule (AI voice), there must be high levels of AI consistency and AI voice to complement AI explainability, and only this pattern of configurations can further enhance OC. In pattern 2, for the combination of high informational rule (AI explainability) and low procedural rule (absent AI voice), AI recruitment with high interpersonal rule (AI human involvement) should focus on AI transparency and AI explainability rather than the implementation of AI voice. In pattern 3, a mere combination of procedural rules could sufficiently improve AIJP. Originality/value: This study, which involved real applicants, is one of the few empirical studies to explore the mechanisms behind the impact of AI hiring decisions on AJP and OC, and the findings may inform researchers and managers on how to best utilise AI to make hiring decisions. © 2023, Emerald Publishing Limited.","10.1108/ITP-04-2022-0271","Article","2023","","Scopus"
"Three lines of defense against risks from AI","Organizations that develop and deploy artificial intelligence (AI) systems need to manage the associated risks—for economic, legal, and ethical reasons. However, it is not always clear who is responsible for AI risk management. The three lines of defense (3LoD) model, which is considered best practice in many industries, might offer a solution. It is a risk management framework that helps organizations to assign and coordinate risk management roles and responsibilities. In this article, I suggest ways in which AI companies could implement the model. I also discuss how the model could help reduce risks from AI: it could identify and close gaps in risk coverage, increase the effectiveness of risk management practices, and enable the board of directors to oversee management more effectively. The article is intended to inform decision-makers at leading AI companies, regulators, and standard-setting bodies. © 2023, The Author(s).","10.1007/s00146-023-01811-0","Article","2023","Artificial intelligence; Decision making; Network security; Artificial intelligence systems; Best practices; Boards of directors; Decision makers; Internal audit; Risk coverage; Risk management framework; Risk management practices; Risks management; Three line of defense; Risk management","Scopus"
"Anonymisation of Judicial Rulings for Legal Analytics Purposes: Ethics, Law, and Compliance","Legal Analytics (LA) techniques are a useful tool in the process of digitisation of judicial systems. However, they may imply processing of personal data contained in judicial rulings. This requires an assessment of the impact generated on the rights and freedoms of individuals. What happens if personal data are processed, with LA and AI systems, for research purposes, such as prediction? Should be taken additional technical and organisational measures for the protection of individuals, such as anonymisation or pseudonymisation? The EU legal framework does not interfere with data processing of courts acting in their judicial capacity, in order to safeguard the independence of the judiciary. Therefore, the decision to anonymise judgments is normally taken by the Court’s rules or procedures. The paper provides an overview of the different policies adopted by the different EU countries, investigating whether they should apply to researchers performing LA of judicial rulings. The paper also illustrates how such issues have been dealt within the Legal Analytics for Italian LAw (LAILA) project, funded by the Italian Ministry of Education and Research within the “PRIN programme”. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-49011-8_9","Conference paper","2023","Artificial intelligence; Ethical technology; Laws and legislation; Analytic technique; Analytics systems; Anonymization; Digitisation; Judicial ruling; Judicial systems; Legal analytic; Legal information; Legitimate interest; Proportionality; Data privacy","Scopus"
"MolTaut: A Tool for the Rapid Generation of Favorable Tautomer in Aqueous Solution","Fast and proper treatment of the tautomeric states for drug-like molecules is critical in computer-aided drug discovery since the major tautomer of a molecule determines its pharmacophore features and physical properties. We present MolTaut, a tool for the rapid generation of favorable states of drug-like molecules in water. MolTaut works by enumerating possible tautomeric states with tautomeric transformation rules, ranking tautomers with their relative internal energies and solvation energies calculated by AI-based models, and generating preferred ionization states according to predicted microscopic pKa. Our test shows that the ranking ability of the AI-based tautomer scoring approach is comparable to the DFT method (wB97X/6-31G*//M062X/6-31G*/SMD) from which the AI models try to learn. We find that the substitution effect on tautomeric equilibrium is well predicted by MolTaut, which is helpful in computer-aided ligand design. The source code of MolTaut is freely available to researchers and can be accessed at https://github.com/xundrug/moltaut. To facilitate the usage of MolTaut by medicinal chemists, we made a free web server, which is available at http://moltaut.xundrug.cn. MolTaut is a handy tool for investigating the tautomerization issue in drug discovery. © 2023 American Chemical Society","10.1021/acs.jcim.2c01393","Article","2023","Isomerism; Water; Design for testability; HTTP; water; Computer-aided drug discovery; Internal energies; Ionization state; Microscopic pK; Pharmacophores; Rapid generations; Solvation energy; Tautomeric transformation; Tautomerics; Transformation rules; isomerism; Molecules","Scopus"
"Towards Audit Requirements for AI-Based Systems in Mobility Applications","Various mobility applications like advanced driver assistance systems increasingly utilize artificial intelligence (AI) based functionalities. Typically, deep neural networks (DNNs) are used as these provide the best performance on the challenging perception, prediction or planning tasks that occur in real driving environments. However, current regulations like UNECE R 155 or ISO 26262 do not consider AI-related aspects and are only applied to traditional algorithm-based systems. The non-existence of AI-specific standards or norms prevents the practical application and can harm the trust level of users. Hence, it is important to extend existing standardization for security and safety to consider AI-specific challenges and requirements. To take a step towards a suitable regulation we propose 50 technical requirements or best practices that extend existing regulations and address the concrete needs for DNN-based systems. We show the applicability, usefulness and meaningfulness of the p roposed requirements by performing an exemplary audit of a DNN-based traffic sign recognition system using three of the proposed requirements. © 2023 by SCITEPRESS – Science and Technology Publications, Lda.","10.5220/0011619500003405","Conference paper","2023","","Scopus"
"Can legitimate interest be an appropriate lawful basis for processing Artificial Intelligence training datasets?","Precision and effectiveness of Artificial Intelligence (AI) models are highly dependent on the availability of genuine, relevant, and representative training data. AI systems tested and validated on poor-quality datasets can produce inaccurate, erroneous, skewed, or harmful outcomes (actions, behaviors, or decisions), with far-reaching effects on individuals' rights and freedoms. Appropriate data governance for AI development poses manifold regulatory challenges, especially regarding personal data protection. An area of concern is compliance with rules for lawful collection and processing of personal data, which implies, inter alia, that using databases for AI design and development should be based on a clear and precise legal ground: the prior consent of the data subject or another specific valid legal basis. Faced with this challenge, the European Union's personal data protection legal framework does not provide a preferred, one-size-fits-all answer, and the best option will depend on the circumstances of each case. Although there is no hierarchy among the different legal bases for data processing, in doubtful cases, consent is generally understood by data controllers as a preferred or default choice for lawful data processing. Notwithstanding this perception, obtaining data subjects' consent is not without drawbacks for AI developers or AI-data controllers, as they must meet (and demonstrate) various requirements for the validity of consent. As a result, data subjects' consent could not be a suitable and realistic option to serve AI development purposes. In view of this, it is necessary to explore the possibility of basing this type of personal data processing on lawful grounds other than the data subject's consent, specifically, the legitimate interest of the data controller or third parties. Given its features, legitimate interests could help to meet the challenge of quality, quantity, and relevance of data curation for AI training. The aim of this article is to provide an initial conceptual approach to support the debate about data governance for AI development in the European Union (EU), as well as in non-EU jurisdictions with European-like data protection laws. Based on the rules set by the EU General Data Protection Regulation (GDPR), this paper starts by referring to the relevance of adequate data curation and processing for designing trustworthy AI systems, followed by a legal analysis and conceptualization of some difficulties data controllers face for lawful processing of personal data. After reflecting on the legal standards for obtaining data subject's valid consent, the paper argues that legitimate interests (if certain criteria are met) may better match the purpose of building AI training datasets. © 2022 Pablo Trigo Kramcsák","10.1016/j.clsr.2022.105765","Article","2023","Controllers; Data privacy; Laws and legislation; Artificial intelligence systems; Data controllers; Data governances; Data subjects; European union; Legal ground for personal data processing; Legitimate interest; Personal data protection regulation; Personal data protections; Training dataset; Artificial intelligence","Scopus"
"Accurate and Explainable Retinal Disease Recognition via DCNFIS","The accuracy-interpretability tradeoff is a significant challenge for Explainable AI systems; if too much accuracy is lost, an explainable system might be of no actual value. We report on the ongoing development of the Deep Convolutional Neuro-Fuzzy Inference System, an XAI algorithm that has to this point demonstrated accuracy on par with existing convolutional neural networks. Our system is evaluated on the Retinal OCT dataset, in which it achieves state-of-the-art performance. Explanations for the system’s classifications based on saliency analysis of medoid elements from the fuzzy rules in the classifier component are analyzed. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-46778-3_1","Conference paper","2023","Convolution; Deep learning; Fuzzy neural networks; Fuzzy systems; Ophthalmology; AI systems; Convolutional neural network; Deep learning; Interpretability; Neuro-fuzzy inference systems; Neurofuzzy system; Retinal disease; Saliency analysis; State-of-the-art performance; XAI; Fuzzy inference","Scopus"
"Exploring the ethical considerations of using Chat GPT in university education","This study investigates the moral dilemmas that arise with incorporating Chat GPT into higher education, with a focus on the situation in Latinoamerican institutions of higher learning. The study surveyed 220 people via online questionnaire to learn more about their experiences with and motivations for using AI-powered conversational agents. An overview of the demographics of the participants was provided through descriptive statistics. This investigation of the subject at hand lays the groundwork for further research. It also reveals the hidden meanings of the observed phenomena, and it suggests possible solutions to the problems that have been uncovered. This research looks at how AI systems and chatbots can supplement human knowledge and judgment, as well as their potential drawbacks. The results showed that participants thought Chat GPT integration was moderately accessible and had moderately positive social attitudes. They understood the value and responsibility of Chat GPT in creating individualized educational opportunities. Participants stressed the necessity for explicit institutional standards regarding privacy and data security. Gender, age, sense of accessibility, social attitude, opinions, and personal experience, privacy and data security, institutional guidelines, and individualized learning were also found to affect participants' reliance on AI through regression analysis. The findings shed light on how the integration of Chat GPT into Latinoamerican higher education is complicated by factors such as individual beliefs, cultural norms, and ethical problems. The busy schedules of students may be accommodated and the resources they need to succeed can be made available thanks to this adaptability. In addition, natural language processing models can offer students instantaneous help via text chat, voice, or video. To fully grasp the ethical consequences and lead the creation of responsible implementation techniques, the research proposes that additional qualitative investigations, longitudinal studies, and comparative research across diverse contexts is required. Closing these knowledge gaps will help move the conversational AI field forward in ways that are ethical and beneficial to the classroom. © The Author 2023. This work is licensed under a Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/) that allows others to share and adapt the material for any purpose (even commercially), in any medium with an acknowledgement of the work's authorship and initial publication in this journal. All Rights Reserved.","10.21533/pen.v11i4.3770","Article","2023","","Scopus"
"Investigating How Practitioners Use Human-AI Guidelines: A Case Study on the People + AI Guidebook","Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitioner-facing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI's design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products. © 2023 Owner/Author.","10.1145/3544548.3580900","Conference paper","2023","Case-studies; Cross-functional; Design challenges; Human-artificial intelligence guideline; Human-artificial intelligence interaction; Intelligence products; People artificial intelligence guidebook; Product and services; Product manager; Users' experiences; Product design","Scopus"
"Global Explanations for Multivariate time series models","Several explainable AI algorithms have been proposed to help make machine learning models more interpretable and trustworthy. However in spite of numerous methodological advancements, there is still a persistent gap between what researchers develop and what business users seek. In this work, we aim to bridge this gap for an AI system that predicts the remaining useful life of an aircraft's engine using time series data collected from multiple sensors. We propose a novel approach to compute easily understandable explanations by fusing two explainers in sequence wherein explanations of the first explainer are explained by the second. We use this approach to build a global post-hoc model-agnostic explainer for AI models that ingest multivariate time series data. Our approach fuses a local explainer that yields feature importance weights, with a directly interpretable model that outputs global rules. Our experimental results based on the C-MAPSS open-source dataset demonstrate that the proposed two-stage explainer computes global explanations that are amenable to business users and sheds light on how the behavior of an individual and a group of sensors impacts the remaining useful life of an aircraft's engine.  © 2023 ACM.","10.1145/3570991.3570998","Conference paper","2023","Aircraft engines; Engines; Machine learning; AI algorithms; AI explainability; AI systems; Business-users; Global explanation; Machine learning models; Multiple sensors; Multivariate time series models; Remaining useful lives; Time-series data; Time series","Scopus"
"Enhancing Trust in Machine Learning Systems by Formal Methods: With an Application to a Meteorological Problem","With the deployment of applications based on machine learning techniques the need for understandable explanations of these systems’ results becomes evident. This paper clarifies the concept of an “explanation”: the main goal of an explanation is to build trust in the recipient of the explanation. This can only be achieved by creating an understanding of the results of the AI systems in terms of the users’ domain knowledge. In contrast to most of the approaches found in the literature, which base the explanation of the AI system’s results on the model provided by the machine learning algorithm, this paper tries to find an explanation in the specific expert knowledge of the system’s users. The domain knowledge is defined as a formal model derived from a set of if-then-rules provided by experts. The result from the AI system is represented as a proposition in a temporal logic. Now we attempt to formally prove this proposition within the domain model. We use model checking algorithms and tools for this purpose. If the proof is successful, the result of the AI system is consistent with the model of the domain knowledge. The model contains the rules it is based on and hence the path representing the proof can be translated back to the rules: this explains, why the proposition is consistent with the domain knowledge. The paper describes the application of this approach to a real world example from meteorology, the short-term forecasting of cloud coverage for particular locations. © 2023, IFIP International Federation for Information Processing.","10.1007/978-3-031-40837-3_11","Conference paper","2023","Formal methods; Learning algorithms; Machine learning; Meteorology; Model checking; AI systems; Domain knowledge; Explainable AI; Machine learning systems; Machine learning techniques; Machine-learning; Models checking; On-machines; Solar radiation forecast; User domains; Domain Knowledge","Scopus"
"Collaborative Appropriation of AI in the Context of Interacting with AI","In the context of maintaining technical equipment, AI is used to detect possible problems. Human specialists check whether a real problem is addressed, and, in this case, try to solve it. Furthermore, they go on trying to translate the problem notification into an improvement of other software components into which the AI system is embedded. Thus, every AI result is not only the cause of immediate action but is also a trigger within the process of continuous appropriation of the technical infrastructure that includes AI. The whole socio-technical system is a subject of AI-related improvement as a collaborative task that requires continuous advancement of human competences and skills. This has to be supported by a type of explainable AI by which the process of understanding the reasons driving AI output is not a task for a single end-user but rather the result of combining different specialists’ viewpoints and competences. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-35894-4_18","Conference paper","2023","AI systems; Appropriation; Human-centered artificial intelligence; Keeping the organization in the loop; Organizational practices; Real problems; Rules extraction; Socio-technical designs; Software-component; Technical equipments; Artificial intelligence","Scopus"
"Intelligent service robots for elderly or disabled people and human dignity: legal point of view","This article aims to present the problem of the impact of artificial intelligence on respect for human dignity in the sphere of care for people who, for various reasons, are described as particularly vulnerable, especially seniors and people with various disabilities. In recent years, various initiatives and works have been undertaken on the European scene to define the directions in which the development and use of artificial intelligence should go. According to the human-centric approach, artificial intelligence should be developed, used and monitored with people in mind, their needs and rights. It is artificial intelligence that should adapt to the rules set by people, not the other way around. The source of all human rights and freedoms is respect for human dignity. This is evidenced by numerous European, international, national regulations and documents. Respecting this value is also one of the works on the AI development. One of the areas of our life into which AI enters more and more boldly and which in the near future, due to demographic reasons and aging population, may be almost dominated by modern technologies, is the medical and care system. The usefulness of industrial co-robots made us think about the possibility of using similar devices in the non-industrial sphere, including in the sphere of care, nursing and therapy. Actually, despite the impressive development of technology and AI, intelligent robots/devices used for care, nursing or therapy (so-called care/nursing or therapy robots) perform rather simple activities. They provide information, navigate, bring something and give it (e.g. medicines, food), help to get up. They are an important support for medical staff in this respect. Performing tasks that are more complex in terms of technology and movement, such as feeding, washing, intimate hygiene, dressing or undressing, is still beyond the reach of the currently used robots. The question we must ask ourselves is whether, in the future, care robots will be able to perform such tasks, and should they do so? Will this lead to the replacement of human medical personnel in the performance of the above-mentioned activities with such robots. Would anyone want to be ""looked after"" by a soulless machine? Should potential wards/patients, in other words all of us in fact, have the right to object to being taken into the care of an intelligent robot? There is no doubt that intelligent robots have great potential, especially when it comes to ensuring or maintaining the independence or mobility of people with various health limitations. However, we must not forget about the risks and dangers they may generate. Even a simple robot generates serious legal and ethical problems. Who should be liable for damage caused in connection with improper care performed with the participation of a robot? Robots based on AI systems are able to collect a significant amount of sensitive data, for example through the face and speech recognition function. There is considerable scope for abuse in this area, not only in terms of personal data protection but also in terms of informational self-determination, privacy and dignity. Bearing in mind the above risks, the creation of a new right to object to being looked after by a robot should be considered. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00146-022-01477-0","Article","2023","Intelligent robots; Laws and legislation; Mobile robots; Spheres; Care robot; Disabled people; Elderly people; Human dignity; Human-centric; Intelligent Service robots; Robots for elderlies; Service robots; Simple++; Vulnerable people; Nursing","Scopus"
"How Do AI Ethics Principles Work? From Process to Product Point of View","Discussing the potential negative impacts of AI systems and how to address them has been the core idea of AI ethics more recently. Based on this discussion, various principles summarizing and categorizing ethical issues have been proposed. To bring these principles into practice, it has been common to repackage them into guidelines for AI ethics. The impact of these guidelines seems to remain small, however, and is considered to be a result of a lack of interest in them. To remedy this issue, other ways of implementing these principles have also been proposed. In this paper, we wish to motivate more discussion on the role of the product in AI ethics. While the lack of adoption of these guidelines and their principles is an issue, we argue that there are also issues with the principles themselves. The principles overlap and conflict and commonly include discussion on issues that seem distant from practice. Given the lack of empirical studies in AI ethics, we wish to motivate further empirical studies by highlighting current gaps in the research area. © 2023 Copyright for this paper by its authors.","","Conference paper","2023","Ethical technology; AI ethic; AI systems; Current gap; Empirical studies; Ethical issues; Machine-learning; Principle; Product; Research areas; Machine learning","Scopus"
"Technical Trends in Public Healthcare and Medical Engineering","Healthcare is a sizable sector of the economy with outdated systems, which can result in inefficiencies. For healthcare and associated purposes, use computing platforms, networking, software, and sensors as digital health technologies. When new technologies develop and rules change as a result of pooled expertise, this has led to a significant movement in the areas of interest within the field of digital health. Technology can help with trainings, supervision, and the delivery of healthcare in remote areas through telemedicine, m-health, and digital platforms or apps. For unbreakable and infinite connection between medical personnel and patients, present hospitals require online healthcare management and control using different types of sensors, and recent tools and technology that can be used in the medical domain. This chapter discusses health system-related difficulties and looks for appropriate solutions using technologies from the Internet of Things (IoT), clouds, sensors, and soft computing. It also elaborates how several AI-based technologies are creating effective decision assistance for medical applications. © 2024 Scrivener Publishing LLC.","","Book chapter","2023","","Scopus"
"Automatic Generation of Training Data for AI Object Detection in Terms of Technical Drawings in Engineering","This paper deals with the development of a program code which is able to produce a huge synthetic data training set automatically and quickly. Since technical drawings vary a lot depending on the application, it is difficult to gather a large amount of high quality data for AI-based image classification. To overcome this problem, firstly, engineering standard design proceedings and rules including calculations are collected, and the important objects to classify are defined. This information is then implemented into an algorithm that generates the training data. Finally, a parameter analysis is performed evaluating both the influences of the input into the program to generate training data, and the input of the training data on the object detection quality. The approach will be standardized so that it is scalable for other applications. In addition, an outlook on how this methodology could be integrated into teaching practice is given for a particular example. The easy and fast production of large training data sets for object detection puts forward the use of AI especially in engineering education. This concept is an ex-ample for teachers and researchers to reproduce for their own purpose. In this manner, they are capable of using AI for new challenges. Moreover, the paper investigates the impact of the parameters of the training data program and the significance on the object detection of YOLOv4. The influence of the resizing of the image resolution on the object detection quality is analyzed. Some limitations imposed will be discussed as well. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-42467-0_60","Conference paper","2023","Artificial intelligence; Engineering education; Image resolution; Object recognition; Artificial intelligence; Automatic Generation; Large amounts; Objects detection; Program code; Synthetic data; Technical drawing; Technical drawing in engineering; Training data; Training sets; Object detection","Scopus"
"Artificial Intelligence & AGILE Based Business Development Review","In this essay, I want to look at how to provide products to customers as rapidly as possible without sacrificing product quality. We will examine how the six consistent design principles may assist us in ensuring that the finished product has the highest attainable quality in the shortest amount of time imaginable throughout the improvement interaction. Giving wonderful items quickly for what it's worth to accomplish as such successfully is equally important. There are several strategies we may employ to achieve this, such availability techniques, which enable us to retain the highest level of quality we are capable of as a software development team. Along with a few strategies for expediting product delivery and including a better driver software architecture in the driver software, he explains these strategies. A sizable portion of India's economy is focused on the food industry. The great majority of individuals in this area rely mostly on agricultural produce for their income, which benefits the whole community. The development of food, which is fundamental for human food, is heavily influenced by ranchers. The sales reps are attempting to decide the right selling cost for the offers they are giving. The misfortunes of this organization outperform its benefits. As indicated by the financial exchange hypothesis referenced above, ranchers are allowed to sell their wares at the most elevated offer cost. Ranchers that sign up in this manner will approach different administrations, including assessments, distributer correspondence, market warnings, and different elements and benefits of a comparable kind. Predictive analytics may be used in many other industries, such as expert device manufacture (which might include voice recognition and artificial vision), judicial assessment, and a number of others. Precision agriculture, automated weapons systems (such as drones), and judicial precedent analysis are a few examples. The adoption of artificial intelligence agricultural methods will help alleviate the challenge of the rising global food demand. Artificial intelligence would make it simple to identify and target weeds, and decisions on the use of pesticides and the appropriate buffer zone could be made quickly. It was chosen to include certain artificial intelligence (AI) components in this paper. © 2023 IEEE.","10.1109/ICACITE57410.2023.10182756","Conference paper","2023","Agile manufacturing systems; Artificial intelligence; Predictive analytics; Product design; Sales; Software design; Agile softwares; Artificial intelligence in business development; Business development; Design Principles; Finished products; Food industries; Precision Agriculture; Product delivery; Products quality; Software development teams; Agriculture","Scopus"
"PaTAT: Human-AI Collaborative Qualitative Coding with Explainable Interactive Rule Synthesis","Over the years, the task of AI-assisted data annotation has seen remarkable advancements. However, a specific type of annotation task, the qualitative coding performed during thematic analysis, has characteristics that make effective human-AI collaboration difficult. Informed by a formative study, we designed PaTAT, a new AI-enabled tool that uses an interactive program synthesis approach to learn flexible and expressive patterns over user-annotated codes in real-time as users annotate data. To accommodate the ambiguous, uncertain, and iterative nature of thematic analysis, the use of user-interpretable patterns allows users to understand and validate what the system has learned, make direct fixes, and easily revise, split, or merge previously annotated codes. This new approach also helps human users to learn data characteristics and form new theories in addition to facilitating the ""learning""of the AI model. PaTAT's usefulness and effectiveness were evaluated in a lab user study. © 2023 ACM.","10.1145/3544548.3581352","Conference paper","2023","Data annotation; Human users; Human-AI collaboration; Interactive programs; Learn+; New approaches; Program synthesis; Qualitative analysis; Real- time; Thematic analysis","Scopus"
"JECC: Commonsense Reasoning Tasks Derived from Interactive Fictions","Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an essential cornerstone in building general AI systems. We propose a new commonsense reasoning dataset based on human's Interactive Fiction (IF) gameplay walkthroughs as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset provides a natural mixture of various reasoning types and requires multi-hop reasoning. Moreover, the IF game-based construction procedure requires much less human interventions than previous ones. Different from existing benchmarks, our dataset focuses on the assessment of functional commonsense knowledge rules rather than factual knowledge. Hence, in order to achieve higher performance on our tasks, models need to effectively utilize such functional knowledge to infer the outcomes of actions, rather than relying solely on memorizing facts. Experiments show that the introduced dataset is challenging to previous machine reading models as well as the new large language models with a significant 20% performance gap compared to human experts. © 2023 Association for Computational Linguistics.","","Conference paper","2023","Computational linguistics; AI systems; Commonsense reasoning; Gameplay; Human abilities; Human players; In-buildings; Interactive fiction; Physical world; Reasoning tasks; Walkthroughs; Large dataset","Scopus"
"Steganalysis of Neural Networks Based on Symmetric Histogram Distribution","Deep neural networks have achieved remarkable success in various fields of artificial intelligence. However, these models, which contain a large number of parameters, are widely distributed and disseminated by researchers, engineers, and even unauthorized users. Except for intelligent tasks, typically overparameterized deep neural networks have become new digital covers for data hiding, which may pose significant security challenges to AI systems. To address this issue, this paper proposes a symmetric steganalysis scheme specifically designed for neural networks trained for image classification tasks. The proposed method focuses on detecting the presence of additional data without access to the internal structure or parameters of the host network. It employs a well-designed method based on histogram distribution to find the optimal decision threshold, with a symmetric determining rule where the original networks and stego networks undergo two highly symmetrical flows to generate the classification labels; the method has been shown to be practical and effective. SVM and ensemble classifiers were chosen as the binary classifier for their applicability to feature vectors output from neural networks based on different datasets and network structures. This scheme is the first of its kind, focusing on steganalysis for neural networks based on the distribution of network output, compared to conventional digital media such as images, audio, and video. Overall, the proposed scheme offers a promising approach to enhancing the security of deep neural networks against data hiding attacks. © 2023 by the authors.","10.3390/sym15051079","Article","2023","","Scopus"
"Under the Hood of Social Media Advertising: How Do We use AI Responsibly for Advertising Targeting and Creative Evaluation","Digital Advertising is historically one of the most developed areas where Machine Learning and AI have been applied since its origination. From smart bidding to creative content generation and DCO, AI is well-demanded in the modern digital marketing industry and partially serves as a backbone of most of the state-of-the-art computational advertising systems, making them impossible for the AI tech and the programmatic systems to exist apart from one another. At the same time, given the drastic growth of the available AI technology nowadays, the issue of responsible AI utilization as well as the balance between the opportunity of deploying AI systems and the possible borderline etic and privacy-related consequences are still yet to be discussed comprehensively in both business and research communities. Particularly, an important issue of automatic User Profiling use in modern Programmatic systems like Meta Ads as well as the need for responsible application of the creative assessment models to fit into the business etic guidelines is yet to be described well. Therefore, in this talk, we are going to discuss the technology behind modern programmatic bidding and content scoring systems and the responsible application of AI by SoMin.ai to manage the Advertising targeting and Creative Validation process. © 2023 Owner/Author.","10.1145/3539597.3575791","Conference paper","2023","Artificial intelligence; Social networking (online); User profile; Ads performance prediction; Advertizing; Creatives; Digital advertizing; Digital marketing; Machine-learning; Performance prediction; Programmatics; Smart bidding; Social media; Marketing","Scopus"
"Analyzing the students' views, concerns, and perceived ethics about chat GPT usage","Artificial Intelligence has greatly revolutionized education in many aspects. Today, AI-enabled language models, such as ChatGPT, are gaining popularity due to their characteristics and benefits. However, users also consider them a threat to educational integrity and purposes. This research examined ChatGPT usage among students in the United Arab Emirates (UAE), their views, concerns, and perceived ethics. The data was gathered from 388 students from two universities in Al Ain city using Yamane's formula. Findings showed that students consider ChatGPT a revolutionary technology that helps students in many ways. The gathered data showed that the effect of ChatGPT Usage remained significant on students' views. The path analysis also supported the second hypothesis, proposing the significant effect of ChatGPT on Students' Concerns. Finally, the findings also indicated the validation of the final hypothesis, showing the significant effect of ChatGPT Usage on the Perceived Ethics among the students in the UAE. Therefore, this study concluded that using ChatGPT in education has useful and concerning effects on educational integrity. However, implementing practical guidelines can assist in making informed decisions and shaping policies within educational institutions. Recognizing the complexities and importance of ChatGPT usage, teachers and policymakers can keep a balance by leveraging Artificial Intelligence technology to improve education while upholding ethical practices that promote critical thinking, originality, and integrity among students. © 2023 The Authors","10.1016/j.caeai.2023.100180","Review","2023","Artificial intelligence; Education computing; Ethical technology; Regression analysis; ChatGPT; Informed decision; Language model; Path analysis; Perceived ethic; Practical guidelines; Revolutionary technology; Students' views; Technology in educations; United Arab Emirates; Students","Scopus"
"An adaptive heuristic algorithm to solve the network slicing resource management problem","Artificial intelligence-based (AI-based) network slicing bandwidth allocation enables the 5G/6G service providers to create multiple virtual networks atop a shared physical infrastructure while fulfilling varying end-user demands. Some researchers argue that AI-enable network may run the danger of having private information compromised. We still need a backup rule-based methodology to allocate bandwidth resource to each slice, if the AI-based method suddenly encounters security issues. To design such a rule-based methodology, this study attempts to answer two questions: (1) Is the network slicing bandwidth allocation problem the nondeterministic polynomial-time completeness (NP-completeness)? (2) Is there a heuristic methodology without any training process, which has equivalent performance compared to the AI-based methodology? This study first proves the classical network slicing bandwidth allocation problems is NP-completeness. This shows that the designed heuristic method is inescapably suboptimal to the network slicing bandwidth allocation problem. Secondly, this study proposes the Adaptive Hungarian Algorithm (AHA), which outperforms previous AI-empowered method and does not need any training process. The experiments demonstrate that AHA reached 93%–97% of the maximal system throughput by brute-and-force algorithm, compared to other methodologies only having at most 93% of the maximal system throughput. This also indicates that AHA is capable to solve the network slicing bandwidth allocation problem, if the telecommunication operators do not have sufficient sample complexity to train an AI model. © 2023 John Wiley & Sons Ltd.","10.1002/dac.5463","Article","2023","5G mobile communication systems; Complex networks; Heuristic algorithms; Heuristic methods; Polynomial approximation; Allocation problems; Channel allocation; Complexity; Hungarian algorithm; Network slicing; Nondeterministic polynomial; Nondeterministic polynomial-time completeness; Polynomial-time; Rule based; Training process; Bandwidth","Scopus"
"A Proof-of-Concept Implementation Based on the Framework of AI-Enabled Proactive mHealth: Health Promotion with Motivation","Digital health with mHealth contributes to health promotion by empowering the user with a holistic view of their health. Proactive mHealth is to predict and prevent a situation beforehand, promptly. Most health decisions are taken by the user pervasively. They have a short or long-term impact. Being proactive requires support as ubiquitous decision-making is prone to sudden changes. Changes in users’ internal and contextual states require adaptive systems with timeliness. Personalized health information needs analysis to support user-level decision-making. The goal is to automate processes and augment healthy behaviour. Data from wearables, together with the context, requires automated decision-making with AI modelling, for predicting intervention values. Prediction and prevention mechanism in implementation requires timely interventions, triggered with a supportive action. The health information (wearables + context) can provide information about the states (current, future, and goal). AI-enabled proactive mHealth framework accentuates abstraction by presenting modules with rules of user-level decision-making, tools for automated decision-making, design with P5 principles, and the architecture of Just-in-time adaptive interventions. In this paper, a proof-of-concept (POC) for health promotion with physical activity is implemented based on the framework. The goal is to promote health with motivation. The paper also categorizes intervention with type, properties, and principles. Components of intervention and behaviour change are also listed. POC includes parameters of context and user profile. The paper provides a step-by-step approach to implementing the system on the framework, from input/output mapping to modelling. The outcome is a POC that alters and augments behaviour change for health promotion with physical activity. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-38854-5_14","Conference paper","2023","Automation; Decision making; Forecasting; Learning algorithms; Machine learning; mHealth; Motivation; Wearable technology; Automated decision making; Digital health; Health interventions; Just-in-time; Just-in-time adaptive intervention; Machine-learning; Physical activity; Proactive health; Proof of concept; Wearables; E-learning","Scopus"
"Inclusion of XAI in artificial intelligence and deep learning technologies","As technology has advanced over the past few decades, the complexity of artificial intelligence (AI) systems has increased rapidly. While these systems can provide impressive results, they can also be difficult to understand, even for experts in the field. Explainable AI (XAI) is an emerging field of research focused on making AI systems more transparent and interpretable. In this article, we will explore what XAI is, why it matters, and how it works. XAI is an emerging field of research that aims to make AI systems more transparent, interpretable, and accountable. In recent years, AI has made significant advances in fields such as natural language processing, image recognition, and game playing. However, as AI systems become more complex and ubiquitous, it becomes increasingly important to ensure that they are used ethically and responsibly. One of the main challenges with AI is that it can be difficult for humans to understand how the system arrived at a particular decision. For example, a deep learning algorithm might be able to identify objects in an image with incredible accuracy, but it may not be clear how the system arrived at its conclusion. This can lead to a lack of trust in the system, particularly in high-stakes domains such as healthcare, finance, and criminal justice. Technically, XAI refers to a set of methods and techniques that enable AI systems to provide human-understandable explanations of their decisions, predictions, and actions. XAI utilizes various approaches such as rule-based systems, decision trees, and model-based techniques to produce explanations that can be interpreted and verified by humans. XAI aims to address the lack of transparency and accountability in traditional black-box AI systems referred in Figure 4.1, which can make it difficult for developers and users to understand and trust these systems. By providing interpretable explanations, XAI can increase the effectiveness, reliability, and trustworthiness of AI systems in a variety of applications. © The Institution of Engineering and Technology 2023.","","Book chapter","2023","","Scopus"
"Toward AI Governance: Identifying Best Practices and Potential Barriers and Outcomes","In recent years artificial intelligence (AI) has been seen as a technology with tremendous potential for enabling companies to gain an operational and competitive advantage. However, despite the use of AI, businesses continue to face challenges and are unable to immediately realize performance gains. Furthermore, firms need to introduce robust AI systems and mitigate AI risks, which emphasizes the importance of creating suitable AI governance practices. This study, explores how AI governance is applied to promote the development of robust AI applications that do not introduce negative effects, based on a comparative case analysis of three firms in the energy sector. The study illustrates which practices are placed to produce knowledge that assists with decision making while at the same time overcoming barriers with recommended actions leading to desired outcomes. The study contributes by exploring the main dimensions relevant to AI’s governance in organizations and by uncovering the practices that underpin them. © 2022, The Author(s).","10.1007/s10796-022-10251-y","Article","2023","Artificial intelligence; Decision making; Artificial intelligence challenge and outcome; Artificial intelligence data governance; Artificial intelligence governance; Artificial intelligence systems; Best practices; Competitive advantage; Data governances; Performance Gain; Potential barriers; Potential outcomes; Competition","Scopus"
"Color Tracking Application Using AI-Based Docker Container Scheduling in Fog Computing","This paper presents the real implementation of a fog computing environment for the execution of color tracking applications by using FogBus2 framework and an artificial intelligence based docker container scheduling. To be precise, an edge computing network has been developed by using a personal computer and several small computing devices such as Raspberry Pi and Nvidia Jetson Nano. Related to the scheduling policy, besides the existing policies in Fogbus2 framework, another one based on fuzzy rules-based system has been designed. Results demonstrate the proposed policy outperforms classical approaches, even when using, pavin the way to the use of knowledge acquisition techniques in order to improve the scheduling performance in terms of makespan and flowtime. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-41630-9_17","Conference paper","2023","Fog computing; Fuzzy inference; Personal computers; Classical approach; Color tracking; Computing devices; Computing environments; Container scheduling; Edge computing; Fuzzy rule based systems; Knowledge acquisition techniques; Scheduling policies; Tracking application; Containers","Scopus"
"iSee: Intelligent Sharing of Explanation Experience by Users for Users","The right to obtain an explanation of the decision reached by an Artificial Intelligence (AI) model is now an EU regulation. Different stakeholders of an AI system (e.g. managers, developers, auditors, etc.) may have different background knowledge, competencies and goals, thus requiring different kinds of interpretations and explanations. Fortunately, there is a growing armoury of tools to interpret ML models and explain their predictions, recommendations and diagnoses which we will refer to collectively as explanation strategies. As these explanation strategies mature, practitioners will gain experience that helps them know which strategies to deploy in different circumstances. What is lacking, and is addressed by iSee, is capturing, sharing and re-using explanation strategies based on past positive experiences. The goal of the iSee platform is to improve every user's experience of AI, by harnessing experiences and best practices in Explainable AI.  © 2023 Owner/Author.","10.1145/3581754.3584137","Conference paper","2023","Artificial intelligence systems; Background knowledge; Best practices; Conversation artificial intelligence; EU regulations; Explainable artificial intelligence; Intelligence models; Interactive explanation; Positive experiences; Users' experiences","Scopus"
"AI-Based Platform Design for Complex Thinking Assessment: A Case Study of an Ideathon Using the Transition Design Approach","Emerging Artificial Intelligence-enhanced technology platforms in education warrant attention to exploring new learning strategies and dynamics. Keeping up with the accelerating momentum to bring classic traditional learning activities to Artificial Intelligence-supported platforms may unbalance the interest in developing the participants’ higher-order thinking. This article presents case study research of an Artificial Intelligence-based technological platform to measure complex thinking traits of higher education participants in an Ideathon learning scenario. The didactical strategy was grounded in the Transition Design approach, with Sharing Economy as the challenge. An overview of the process for developing Artificial Intelligence-supported activities, the challenges and risks identified in the development, and a classification model and enhancements for future implementation in a subsequent pilot are presented. The findings set a guideline for balancing Artificial Intelligence-powered educational activities and the development of the participants’ complex thinking. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","10.1080/07380569.2023.2256711","Review","2023","Case-studies; Classification models; Complex thinking; Design approaches; Educational innovations; High educations; Ideathon; Platform design; Technological platform; Transition design; Artificial intelligence","Scopus"
"Ethical Challenges for Human–Agent Interaction in Virtual Collaboration at Work","In virtual collaboration at the workplace, a growing number of teams apply supportive conversational agents (CAs). They take on different work-related tasks for teams and single users such as scheduling meetings or stimulating creativity. Previous research merely focused on these positive aspects of introducing CAs at the workplace, omitting ethical challenges faced by teams using these often artificial intelligence (AI)-enabled technologies. Thus, on the one hand, CAs can present themselves as benevolent teammates, but on the other hand, they can collect user data, reduce worker autonomy, or foster social isolation by their service. In this work, we conducted 15 expert interviews with senior researchers from the fields of ethics, collaboration, and computer science in order to derive ethical guidelines for introducing CAs in virtual team collaboration. We derived 14 guidelines and seven research questions to pave the way for future research on the dark sides of human–agent interaction in organizations. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","10.1080/10447318.2023.2279400","Article","2023","Ethical technology; Virtual reality; Conversational agents; Human-agent interaction; Single users; Social isolation; Trust; User data; Virtual collaboration; Virtual team; Work-related; Workers'; Human computer interaction","Scopus"
"Artificial intelligence in adverse drug events","The Institute of Medicine defined adverse drug events as injuries “resulting from medical intervention related to a drug”. These events are common in healthcare and there is substantial opportunity for improvement. This chapter describes artificial intelligence (AI)-based algorithms and tools that can be used to inform clinical decision-making for the prevention or mitigation of adverse drug events at the point of care. It covers three types of AI: rule-based models that are currently in use, and the next generation of more complex, modern machine learning and natural language processing-based tools that are under development and in testing. The application of modern AI is an emerging area and has the potential to substantially improve medication-related decision-making compared with rule-based tools. There are several challenges to address before widespread use and impact in real-world clinical settings can be realized. © 2024 Elsevier Inc. All rights reserved.","10.1016/B978-0-443-15688-5.00014-0","Book chapter","2023","","Scopus"
"Features, key challenges, and applications of open-source data fabric platforms: Is open-source tools for data fabric - dawn or dusk?","In recent years, ""Data Fabric"" has become new analytic buzzword in Data Management agility where it has become a high priority in booming industries where they have an environment that is more complicated, scattered, and diversified. Data analytics experts began exploring beyond conventional data management techniques and shifted toward contemporary solutions like AI-enabled data integration in order to decrease human errors and total costs. Data fabric is a weave where it stretches spanning a wide area that connects numerous sites, various data source kinds, and accessing techniques. As it progresses through the various stages of the data fabric, the data collected from the source can be handled, processed, and stored. For a wide range of applications, the data can also be accessible by or shared with both internal and external apps. Data fabric applications' main objectives are to optimize supply chains for end-to-end products, complywith data rules, and enhance consumer engagement through more sophisticated mobile apps and interactions. Always Companies can gain a competitive edge with data, but to meet customer demands, they must supply data rapidly. Most of the enterprises implemented cloud migration and IoT, with increased cost-effective data storage and processing. Because of this data is no longer tied to local centers, and most of the data are located in different places and it is very difficult to manage [1]. A Data Fabric is a strategic solution to the enterprise to incur storage operations and leverages the best version of cloud migration. This architecture can support centrally managed, public and private clouds, IoT and other devices. This reduces management tasks through automation, accelerates the development and deployment process, and protects assets without interruption. It enables changes to be made quickly, resolving problems, managing risk, reducing IT operations and complying with regulations. In this chapter, the best open source data fabric tools that meet the enterprise requirements are listed and highlighted with its benefits and challenges. The greatest data fabric tools are profiled in one location, which makes it easy for researchers to choose the tool throughout their search. Data categorization and discovery, data quality and profiling, data lineage and governance, and data exploration and integration are the four main functions offered by the data fabric technologies. These data collaboration platforms combine data integration with business applications. Atlan, Cinchy, Data.world, Denodo, IBM, K2 View are few open source tools that are used by enterprise to manage their data and its integration. There are wide ranges of Open Source Data fabric tools that are quick to list its benefits. Instead of using proprietary systems, the majority of firms are interested in open source solutions due to lower costs. The capacity to modify and offer creative solutions on the code to satisfy business objectives is another crucial advantage of working with open source proponents. However, in this chapter we discuss about the Key features, benefits and technical challenges of different open source data integration tools in detail. The primary challenges in the utilizing open source data tool in enterprise is they lack in community support. In general The IT departments of many businesses rely on vendor support to enhance their internal capabilities [2]. Having open source tools, make the enterprise to face and resolve the issues by their own, which is very hard. When developing a data management environment, technology teams frequently underestimate the amount of time and expertise required to properly employ open source software. Most of the organizations they frequently underestimate the amount of work necessary to integrate open source with other subsystems and, as a result, incorrectly evaluate the total cost of ownership of employing open source systems. Most businesses meet few significant obstacles when working on open source pilot projects, but they may run into problems when attempting to manage and maintain those deployments on a wide scale. © 2023 Walter de Gruyter GmbH, Berlin/Boston. All rights reserved.","10.1515/9783111000886-006","Book chapter","2023","","Scopus"
"Molecular MRI-Based Monitoring of Cancer Immunotherapy Treatment Response","Immunotherapy constitutes a paradigm shift in cancer treatment. Its FDA approval for several indications has yielded improved prognosis for cases where traditional therapy has shown limited efficiency. However, many patients still fail to benefit from this treatment modality, and the exact mechanisms responsible for tumor response are unknown. Noninvasive treatment monitoring is crucial for longitudinal tumor characterization and the early detection of non-responders. While various medical imaging techniques can provide a morphological picture of the lesion and its surrounding tissue, a molecular-oriented imaging approach holds the key to unraveling biological effects that occur much earlier in the immunotherapy timeline. Magnetic resonance imaging (MRI) is a highly versatile imaging modality, where the image contrast can be tailored to emphasize a particular biophysical property of interest using advanced engineering of the imaging pipeline. In this review, recent advances in molecular-MRI based cancer immunotherapy monitoring are described. Next, the presentation of the underlying physics, computational, and biological features are complemented by a critical analysis of the results obtained in preclinical and clinical studies. Finally, emerging artificial intelligence (AI)-based strategies to further distill, quantify, and interpret the image-based molecular MRI information are discussed in terms of perspectives for the future. © 2023 by the authors.","10.3390/ijms24043151","Review","2023","Artificial Intelligence; Humans; Immunotherapy; Magnetic Resonance Imaging; Molecular Imaging; Neoplasms; immune checkpoint inhibitor; apoptosis; apparent diffusion coefficient; artificial intelligence; blood vessel permeability; cancer immunotherapy; carbon nuclear magnetic resonance; chemical composition; chemical exchange saturation transfer; contrast enhancement; diagnostic imaging; diffusion weighted imaging; fluid-attenuated inversion recovery imaging; fluorine magnetic resonance imaging; human; immune response; inflammatory cell; molecular imaging; non invasive procedure; nonhuman; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; oncolytic virotherapy; practice guideline; Review; T1 weighted imaging; T2 weighted imaging; treatment response; tumor microenvironment; artificial intelligence; immunotherapy; molecular imaging; neoplasm; nuclear magnetic resonance imaging; procedures","Scopus"
"Healthcare AI Treatment Decision Support: Design Principles to Enhance Clinician Adoption and Trust","Artificial intelligence (AI) supported clinical decision support (CDS) technologies can parse vast quantities of patient data into meaningful insights for healthcare providers. Much work is underway to determine the technical feasibility and the accuracy of AI-driven insights. Much less is known about what insights are considered useful and actionable by healthcare providers, their trust in the insights, and clinical workflow integration challenges. Our research team used a conceptual prototype based on AI-generated treatment insights for type 2 diabetes medications to elicit feedback from 41 U.S.-based clinicians, including primary care and internal medicine physicians, endocrinologists, nurse practitioners, physician assistants, and pharmacists. We contribute to the human-computer interaction (HCI) community by describing decision optimization and design objective tensions between population-level and personalized insights, and patterns of use and trust of AI systems. We also contribute a set of 6 design principles for AI-supported CDS. © 2023 Owner/Author.","10.1145/3544548.3581251","Conference paper","2023","Decision support systems; Health care; Human computer interaction; Machine learning; Medical computing; Medicine; Design objectives; Design Principles; Knowledge creations; Machine-learning; Medication prescribing; Provider workflow; Sociotechnical; Sociotechnical complexity; Type two diabetes; Work-flows; Hospital data processing","Scopus"
"Conversational AI for Web Inclusivity: Technologies, Design Patterns and Development Toolkits","Digital services can represent an important channel for granting access to knowledge, education, and work. Expecially to the citizens living with disabilities. However, as of now, the Web is conceived essentially for visual fruition and is inadequate for all those users living with permanent or situational impairments. Conversational AI is emerging as a technology apt for the development of inclusive and accessible applications, but there is still a lack of guidance specific to the design of inclusive Conversational AI systems. This research proposes to identify guidelines, interaction patterns, and enabling technology for a new paradigm for accessible conversational web browsing. © 2023 Copyright for this paper by its authors.","","Conference paper","2023","Card tool; Conversational interface; Design development; Design Patterns; Development toolkit; Digital services; Evaluation methods; HCI design; Software accessibility; Technology designs","Scopus"
"Data-driven mathematical modeling for AI-based security applications","Artificial intelligence (A.I.) is defined as the ability of a machine to perform cognitive functions that we associate with human minds, such as perceiving, reasoning, learning, interacting with the environment, problem solving, decision-making, and even demonstrating creativity. This field of artificial intelligence finds itself indispensable across various domains like shopping, fraud prevention, personalized learning, autonomous vehicles, voice assistants, etc. It is widely used in the field of cyber security. There are numerous AI based security models to delay security threats. Such algorithms could be classified under three heads - rule-based, shallow machine learning and deep learning algorithms. Fuzzy logic and fuzzy neural networks fall under rule-based algorithm. support vector machine (SVM), naïve bayes, decision tree, random forest, k-nearest neighbour and ensemble learning are some shallow ML algorithms that could be employed for cyber security. © 2023, IGI Global.","10.4018/978-1-6684-6408-3.ch010","Book chapter","2023","","Scopus"
"The Current State of Art-Indian Unleavened Flat Bread Cooking","New methods of food production and technical food processing are now possible. Thanks to contemporary advancements in the food sector. Studies on the standardization of conditions for making dough with wheat flour, wheat flour size of particle, and wheat flour variations were conducted with the goal of producing a consistent procedure for baking the unleavened flat bread known as chapati, a traditional Indian dish. Water needed to make chapati dough, dough thickness, rolling qualities, chapati thickness, baking time and temperature, and chapati puffing conditions were all factors taken into account. This paper summarizes current research on the aforementioned chapati making parameters. It provides guidelines for future work on computer vision and AI based chapati production. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-99-3761-5_1","Conference paper","2023","Cooking; Food products; 'current; Condition; Consistent procedures; Flat bread; Food production; Food sector; ML; Wheat flours; Computer vision","Scopus"
"Experiencing Ethics and Values in the Design Process of AI-Enabled Medical Devices and Software","The interaction design of medical devices has to engage and cater to the needs of a wide range of stakeholders, from patients to physicians. The present paper aims to show by example the methodological integration of critical reflection on ethics and values during the design process of AI-enabled tools. The question of how to promote awareness of ethical responsibilities in the context of AI in medical devices is raised, and the use of core frameworks for ethical and value-based design as well as reflexive practice are being evaluated. To this end we conducted multiple empirical studies based on multiple university research projects, including joint research with healthcare industry partners, connecting the fields of medicine, engineering psychology, media informatics, and design research. We present a questionnaire-based self-reflection tool—VaPeMeT—designed to encourage ethical reflection and use of frameworks across project phases and team members. Our studies combine qualitative and quantitative research in order to 1) connect reported participant actions with theoretical considerations from value-based design and 2) evaluate the completeness and usefulness of the VaPeMeT questionnaire. By conceptualizing process design implications and suggesting a questionnaire-based self-reflection tool, our research aims to contribute to integrated, actionable and responsible transdisciplinary cooperation in this sensitive context. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-48057-7_15","Conference paper","2023","Design; Ethical technology; Human computer interaction; Process design; Artificial intelligence and lot; Design method; Design process managements; Design technique; Ethical issues; Heuristic and guideline for design; Medical Devices; Method and technique; Philosophical and ethical issue of HCI; Transdisciplinarity; Heuristic methods","Scopus"
"Artificial intelligence and global health","The use of modern machine learning and natural language processing is an emerging area in the prevention and detection of adverse drug events at the point of care, which has the potential to substantially improve medication-related decision-making compared with rule-based tools. This chapter focuses on AI-based algorithms and tools that can be used to inform clinical decision-making for prevention or early detection of adverse drug events at the point of care. This overview addresses three types of AI: rule-based models which are currently used in practice; the next generation of more complex, modern machine learning; and natural language processing-based tools that are under development and in testing. Examples are given of the current rules-based systems that are widely used to support medication-related decision-making are summarized; these use clinical guidelines, patient-specific information such as comorbidities or genomic profiles, and known contraindications from pharmacological databases. The next generation of AI tools that use Machine Learning and Natural Language Processing (NLP) to inform medication-related decision-making are reviewed and there is a brief introduction of the currently limited scope of NLP being applied to extract information from free-text clinical notes in the electronic health record. The current challenges that are limiting the implementation of AI within this field are identified and suggestions for the future direction of AI that will affect clinical decision-making and patient outcomes are given. © 2024 Elsevier Inc. All rights reserved.","10.1016/B978-0-443-15688-5.00034-6","Book chapter","2023","","Scopus"
"Assuring Safe and Efficient Operation of UAV Using Explainable Machine Learning","The accurate estimation of airspace capacity in unmanned traffic management (UTM) operations is critical for a safe, efficient, and equitable allocation of airspace system resources. While conventional approaches for assessing airspace complexity certainly exist, these methods fail to capture true airspace capacity, since they fail to address several important variables (such as weather). Meanwhile, existing AI-based decision-support systems evince opacity and inexplicability, and this restricts their practical application. With these challenges in mind, the authors propose a tailored solution to the needs of demand and capacity management (DCM) services. This solution, by deploying a synthesized fuzzy rule-based model and deep learning will address the trade-off between explicability and performance. In doing so, it will generate an intelligent system that will be explicable and reasonably comprehensible. The results show that this advisory system will be able to indicate the most appropriate regions for unmanned aerial vehicle (UAVs) operation, and it will also increase UTM airspace availability by more than 23%. Moreover, the proposed system demonstrates a maximum capacity gain of 65% and a minimum safety gain of 35%, while possessing an explainability attribute of 70%. This will assist UTM authorities through more effective airspace capacity estimation and the formulation of new operational regulations and performance requirements. © 2023 by the authors.","10.3390/drones7050327","Article","2023","","Scopus"
"Towards Explainable AI Validation in Industry 4.0: A Fuzzy Cognitive Map-based Evaluation Framework for Assessing Business Value","The development of Artificial Intelligence (AI) systems in Industry 4.0 has gained momentum due to their potential for increasing efficiency and productivity. However, AI systems can be just as complex and opaque, leading to concerns about their reliability, trustworthiness, and accountability. To address these issues, this paper proposes a validation framework for Explainable AI (XAI) in Industry 4.0 based on Fuzzy Cognitive Maps (FCMs). The proposed framework aims to evaluate Key Performance Indicators (KPIs) based on a set of AI metrics and XAI metrics. The FCM-based approach enables the representation of causal-effect relationships between the different concepts of the system using expert knowledge. The presented validation framework provides a theoretical background for evaluating and optimizing the business values of AI systems based on multiple criteria in the manufacturing industry, demonstrating its effectiveness. The main contributions of this paper are: i) the development of an FCM-based validation framework for XAI in Industry 4.0; ii) the identification of relevant AI and XAI metrics for the evaluation of the KPIs of the theoretical graph model; and iii) the demonstration of the effectiveness of the proposed framework through a case study. The results of this study provide valuable insights into the importance of considering not only accuracy but also efficiency and transparency when developing AI pipelines that generate higher business value. Overall, this paper offers a theoretical foundation and practical insights for organizations seeking to evaluate the business values of their AI systems in Industry 4.0. It emphasizes the importance of explainability and the integration of AI and XAI metrics in achieving transparent and accountable AI solutions that deliver optimal results for the manufacturing industry and beyond.  © 2023 IEEE.","10.1109/ICE/ITMC58018.2023.10332301","Conference paper","2023","Artificial intelligence; Benchmarking; Efficiency; Fuzzy rules; Industry 4.0; Artificial intelligence systems; Business perspective; Business value; Evaluation framework; Expert knowledge; Explainability; Explainable artificial intelligence; Key performance indicators; Manufacturing industries; Map-based approach; Fuzzy Cognitive Maps","Scopus"
"Research Libraries Approaching Trustworthy Artificial Intelligence","Recent advances in artificial intelligence (AI) applications have raised concerns about the consequences of the uncontrolled development of AI technology for society and humans. Information and knowledge professionals working in research libraries are in professions that have long existed and have globally applied ethical codes that serve as self-regulatory ethical norms. New AI technologies that penetrate throughout libraries’ operations cause confusion among librarians and challenge the existing ethics. In this paper, we examine these challenges and present a qualitative study that reveals the ethical considerations that research librarians face when they approach new AI technologies. As there are no established AI ethics norms for research librarians, we compared the international code of conduct for libraries against the European AI guidelines to identify relevant themes for our study. We analyzed the data from two Scandinavian workshops for librarians. Our findings highlight the central role of research libraries in making AI-powered research ethical. Our study also indicates a need to update international codes of conduct for libraries for the AI age by including aspects of AI agency and the interests of future generations. This helps librarians better orient themselves and their patrons towards a trustworthy and existentially sustainable future with AI systems. © 2023 Copyright for this paper by its authors.","","Conference paper","2023","Ethical technology; Libraries; Academic libraries; Artificial intelligence technologies; Code of conduct; Ethical considerations; Future generations; Intelligence agencies; International codes; Qualitative study; Research libraries; Scandinavian workshop; Artificial intelligence","Scopus"
"Regulation and Ethics of Facial Recognition Systems: An Analysis of Cases in the Court of Appeal in the State of São Paulo","Context: The use of Artificial Intelligence (AI) in various sectors of the economy is already a reality in Brazil. Consequently, since 2019, the number of cases in the Judiciary involving AI has increased. Cases involving facial recognition systems (FRS) for contracting bank credit are increasing annually, so it is necessary to analyze how the Judiciary handles the issues. Problem: Why is the São Paulo Court of Appeal ruling in favor of banks in all cases involving taking out credit through facial recognition technology? Methodology and Methods: Data were collected and processed using automated computer programs. The qualitative analysis used the analytical, comparative and monographic methods. Results: The Court of Appeal of São Paulo considers it difficult to deceive an AI system, therefore, the burden of proof is on the author, even if there is a consumer relationship. That is, the decisions are contrary to the general rule of the Code of Consumer Protection in Brazil, which consists of reversing the burden of proof in consumer relations when one of the parties is underprivileged. Contributions and Solutions: The research points to the path of jurisprudence in cases involving the contracting of credit through FRS, and the Judiciary is deciding against the bank’s customers, dispensing with the production of evidence by the banking sector. Therefore, it is necessary to alert the National Council of Justice and the Central Bank regarding this situation so that it is disciplined adequately since the FRS is fallible and does not guarantee the absence of fraud. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.","10.1007/978-3-031-45368-7_2","Conference paper","2023","Consumer protection; Face recognition; Artificial intelligence and jurisprudence; Artificial intelligence and laws; Bank credit; Burden of proof; Facial recognition; Facial recognition system and legal case; Facial recognition systems; Legal case; Qualitative analysis; Sao Paulo; Artificial intelligence","Scopus"
"A System for answering simple questions in multiple languages","Our research focuses on the most prevalent type of queries-simple questions-exemplified by questions like ""What is the capital of France-"". These questions reference an entity such as ""France"", which is directly connected (one hop) to the answer entity ""Paris"" in the underlying knowledge graph (KG). We propose a multilingual Knowledge Graph Question Answering (KGQA) technique that orders potential responses based on the distance between the question s text embeddings and the answer s graph embeddings. A system incorporating this novel method is also described in our work. Through comprehensive experimentation using various English and multilingual datasets and two KGs-Freebase andWikidata-we illustrate the comparative advantage of the proposed method across diverse KG embeddings and languages. This edge is apparent even against robust baseline systems, including seq2seq QA models, search-based solutions and intricate rule-based pipelines. Interestingly, our research underscores that even advanced AI systems like ChatGPT encounter difficulties when tasked with answering simple questions. This finding emphasizes the relevance and effectiveness of our approach, which consistently outperforms such systems. We are making the source code and trained models from our study publicly accessible to promote further advancements in multilingual KGQA. © ACL-DEMO 2023. All rights reserved.","","Conference paper","2023","Graph embeddings; Natural language processing systems; Embeddings; Graph embeddings; Knowledge graphs; Multiple languages; Novel methods; Potential response; Question Answering; Research focus; S-graph; Simple++; Knowledge graph","Scopus"
"Fuzzy Failure Modes Effect and Criticality Analysis of the Procurement Process of Artificial Intelligent Systems/Services","This study focuses on the ranking of risks associated with the procurement of Artificial Intelligent (AI) systems/services for UAE public Sectors. Considering the involvement of human-based reasoning, this study proposes to use Fuzzy Failure Mode Effect and Criticality Analysis (FMECA). The risks were identified from the literature and subsequently, using 40 interviews with practitioners, the final list is developed on the basis of the presence of risks in the AI procurement process. For Fuzzy FMECA, the input data is collected from fifteen experts. The values of Severity (S), and Detection (D) for each risk element are averaged to use as input. If-Then rule-based fuzzy inference system is employed to obtain the Fuzzy Risk Priority Numbers of risk elements. The traditional RPN and Fuzzy RPN numbers are compared and it is found that fuzzy RPN gives a realistic picture of the ranking of risks. Privacy and security risks, Integration Risks, Risk of Malfunction of systems/services, and Ethical risks are found to be high priorities. This study provides valuable insight to policymakers to develop strategies to mitigate these risks for smooth procurement and implementation of AI-related Projects. © (2023), (Science and Information Organization). All Rights Reserved.","10.14569/IJACSA.2023.0141060","Article","2023","Criticality (nuclear fission); Failure modes; Fuzzy inference; Artificial intelligent; Artificial intelligent  system; Failure modes effects and criticality analysis; Fuzzy failure mode effect and criticality analyse; Procurement; Procurement process; Public sector; System services; United arab emirate (UAE; United Arab Emirates; Intelligent systems","Scopus"
"Understanding developer practices and code smells diffusion in ai-enabled software: A preliminary study","To deal with continuous change requests and the strict time-To-market, practitioners and big companies constantly update their software systems to meet users requirements. This practice force developers to release immature products, neglecting best practices to reduce delivery times. As a possible result, technical debt can arise, i.e., potential design issues that can negatively impact software maintenance and evolution and, in turn, increase both the time-To-market and costs. Code smells-sub-optimal design decisions identifiable by computing software metrics and providing a general overview of code quality-Are common symptoms of technical debt. While previous research focused on code smells primarily considering them in the context of Java, the growing popularity of Python, particularly for developing artificial intelligence (AI)-Enabled systems, calls for additional investigations. This preliminary analysis addresses this gap by exploring the diffusion of Python-specific code smells, and the activities performed by developers that induce the introduction of code smells in their systems. To perform our preliminary investigation, we selected 200 AI-Enabled systems available in the Niche dataset; We extracted 10,611 information on the releases using PyDriller, and PySmell to extract information about code smells. The results reveal several insights: 1) Code smells related to object-oriented principles are rarely detected in Python; 2) Complex List Comprehension is the most prevalent and the most long-Alive smell; 3) The main activities that can induce code smells are evolutionary. This study fills a critical gap in the literature by providing empirical evidence on the evolution of code smells in Python-based AI-enabled systems. © 2021 Copyright for this paper by its authors.","","Conference paper","2023","Codes (symbols); Commerce; Computer software maintenance; Continuous time systems; Object detection; Object oriented programming; Odors; Optimal systems; Best practices; Code smell; Delivery time; Design issues; Software Evolution; Software refactoring; Software-systems; Technical debts; Time to market; User requirements; Python","Scopus"
"Dialogue Explanations for Rule-Based AI Systems","The need for AI systems to explain themselves is increasingly recognised as a priority, particularly in domains where incorrect decisions can result in harm and, in the worst cases, death. Explainable Artificial Intelligence (XAI) tries to produce human-understandable explanations for AI decisions. However, most XAI systems prioritize factors such as technical complexities and research-oriented goals over end-user needs, risking information overload. This research attempts to bridge a gap in current understanding and provide insights for assisting users in comprehending the rule-based system’s reasoning through dialogue. The hypothesis is that employing dialogue as a mechanism can be effective in constructing explanations. A dialogue framework for rule-based AI systems is presented, allowing the system to explain its decisions by engaging in “Why?” and “Why not?” questions and answers. We establish formal properties of this framework and present a small user study with encouraging results that compares dialogue-based explanations with proof trees produced by the AI System. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-40878-6_4","Conference paper","2023","'current; AI systems; End-users; Formal properties; Information overloads; Rule based; Rules based systems; Technical complexity; Technical research; User need; Artificial intelligence","Scopus"
"Recent advances in deep learning for retrosynthesis","Retrosynthesis is the cornerstone of organic chemistry, providing chemists in material and drug manufacturing access to poorly available and brand-new molecules. Conventional rule-based or expert-based computer-aided synthesis has obvious limitations, such as high labor costs and limited search space. In recent years, dramatic breakthroughs driven by deep learning have revolutionized retrosynthesis. Here we aim to present a comprehensive review of recent advances in AI-based retrosynthesis. For single-step and multi-step retrosynthesis both, we first introduce their goal and provide a thorough taxonomy of existing methods. Afterwards, we analyze these methods in terms of their mechanism and performance, and introduce popular evaluation metrics for them, in which we also provide a detailed comparison among representative methods on several public datasets. In the next part, we introduce popular databases and established platforms for retrosynthesis. Finally, this review concludes with a discussion about promising research directions in this field. This article is categorized under: Data Science > Artificial Intelligence/Machine Learning Data Science > Computer Algorithms and Programming Data Science > Chemoinformatics. © 2023 Wiley Periodicals LLC.","10.1002/wcms.1694","Article","2023","Computer programming; Data Science; Wages; Computer-aided synthesis; Deep learning; Drug manufacturing; Labor costs; Materials manufacturing; Organic Chemistry; Retrosynthesis; Rule based; Search spaces; Single-step; Deep learning","Scopus"
"Create Effective and Responsible AI User Experiences with The Human-AI Experience (HAX) Toolkit","The HAX Toolkit (https://aka.ms/haxtoolkit) is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. The Toolkit is grounded in a set of Guidelines for Human-AI Interaction [1] that prescribe how AI systems should behave when interacting with people. Course attendees will explore the nuances of each guideline and learn how to use the AI patterns and examples in the HAX Design Library to apply the Guidelines. Course attendees will also learn how to guide cross-disciplinary teams in planning user-facing AI systems by using the HAX Workbook. For NLP systems, course attendees will learn to use the HAX Playbook [2] to anticipate and design for failures. The HAX Toolkit is a set of collaborative tools that helps teams working on user-facing AI plan, create, and evaluate human-AI user experiences. This course will help AI practitioners, human-AI interaction researchers, teachers, and students learn how to use the HAX Toolkit themselves and how to introduce it to others. Course attendees will learn the nuances of the Guidelines for Human-AI Interaction, how to lead cross-disciplinary teams in planning human-AI interaction using the HAX Workbook, and how to use the HAX Workbook to plan for failures of NLP systems. © 2023 Owner/Author.","10.1145/3544549.3574191","Conference paper","2023","Curricula; Facings; HTTP; Natural language processing systems; Students; AI systems; Collaborative tools; Cross-disciplinary teams; Human-AI interaction; Learn+; NLP systems; Responsible AI; Teachers'; Team working; Users' experiences; Teaching","Scopus"
"Application of explainable artificial intelligence for healthcare: A systematic review of the last decade (2011–2022)","Background and objectives: Artificial intelligence (AI) has branched out to various applications in healthcare, such as health services management, predictive medicine, clinical decision-making, and patient data and diagnostics. Although AI models have achieved human-like performance, their use is still limited because they are seen as a black box. This lack of trust remains the main reason for their low use in practice, especially in healthcare. Hence, explainable artificial intelligence (XAI) has been introduced as a technique that can provide confidence in the model's prediction by explaining how the prediction is derived, thereby encouraging the use of AI systems in healthcare. The primary goal of this review is to provide areas of healthcare that require more attention from the XAI research community. Methods: Multiple journal databases were thoroughly searched using PRISMA guidelines 2020. Studies that do not appear in Q1 journals, which are highly credible, were excluded. Results: In this review, we surveyed 99 Q1 articles covering the following XAI techniques: SHAP, LIME, GradCAM, LRP, Fuzzy classifier, EBM, CBR, rule-based systems, and others. Conclusion: We discovered that detecting abnormalities in 1D biosignals and identifying key text in clinical notes are areas that require more attention from the XAI research community. We hope this is review will encourage the development of a holistic cloud system for a smart city. © 2022 Elsevier B.V.","10.1016/j.cmpb.2022.107161","Review","2022","Artificial Intelligence; Delivery of Health Care; Humans; Clinical research; Decision making; Diagnosis; Expert systems; Fuzzy sets; Health care; Hospital data processing; Learning systems; Attention mechanisms; CBr; Deep learning; EBM; Explainable artificial intelligence (XAI); GradCAM; Healthcare; LRP; Machine-learning; PRISMA; Rule based; Saliency map; SHAP; artificial intelligence; attention; deep learning; expert system; fuzzy system; human; machine learning; prediction; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; review; systematic review; health care delivery; Lime","Scopus"
"An object-oriented neural representation and its implication towards explainable AI","Rapid dissemination of Artificial Intelligence (AI) and machine learning in real-world problems has raised a concern about the reliability aspects of the model. A separate sub-branch of AI solicitudes on reliability is known as Explainable AI (XAI). XAI analyses the cause and impact of the decision made by AI systems. The neural network plays a significant part in AI's ability to upgrade with more recent data. However, the learning capability left the model obscure for most of its decisions. Breaking the black-box nature of the neural network model and giving understanding and insight into the functionality of the model will mitigate the uncertainty. Here, in this research, we have designed Object oriented neural representation to devise a “Feature importance” technique from the correlation between Loss and Weight distribution devised method is effective in interpreting the decision to the end user and AI practitioners with optimal time complexity (TC = (L-1) × (E × C)). The proposed neural representation also extended to incorporate domain/business rules from which we introduced a new Loss, known as business loss. From getting the impact of business loss, we obtained an earlier decline in the overall Loss and improved performance from the ablation study. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.","10.1007/s41870-023-01432-2","Article","2023","","Scopus"
"Linking Team-level and Organization-level Governance in Machine Learning Operations through Explainable AI and Responsible AI Connector","The adoption of AI systems has been widely used across multiple industry domains at an alerting rate without focusing on its ethical concerns. In order to address those concerns, an increasing number of AI ethics frameworks have been suggested recently, which focus on the algorithmic level rather than the systems level. Nonetheless, some system-level approaches mostly cover a single-level governance pattern of the system components in the entire software design life cycle. However, the need to go beyond the single-level system design AI ethics frameworks to allow not only a better responsible-AI-by-design but also a trustworthy process pattern that abstracts and links the underlying layers of responsible AI on every level. This paper illustrates a principal-to-practice guide of the multi-level governance within organizations across the globe for AI ethics frameworks. We outline the main gap areas in organizations for AI ethics frameworks. Consecutively, we propose a multi-level governance pattern for responsible AI systems within organizations which is participatory, iterative, flexible and operable that targets those main gap areas. Finally, to assist practitioners in applying the multi-level governance AI in organizations and its impact on the industry level, we will translate it into effective and responsible AI practices using a case study. © 2023 IEEE.","10.1109/COMPSAC57700.2023.00185","Conference paper","2023","Iterative methods; Life cycle; Machine learning; Philosophical aspects; Software design; AI ethic; AI systems; AIMLOp; AIOp; Best practices; Multi-level governance; Pattern; Single level; Trustworthy AI; XAI; Software architecture","Scopus"
"Operationalising AI ethics: how are companies bridging the gap between practice and principles? An exploratory study","Despite the increase in the research field of ethics in artificial intelligence, most efforts have focused on the debate about principles and guidelines for responsible AI, but not enough attention has been given to the “how” of applied ethics. This paper aims to advance the research exploring the gap between practice and principles in AI ethics by identifying how companies are applying those guidelines and principles in practice. Through a qualitative methodology based on 22 semi-structured interviews and two focus groups, the goal of the current study is to understand how companies approach ethical issues related to AI systems. A structured analysis of the transcripts brought out many actual practices and findings, which are presented around the following main research topics: ethics and principles, privacy, explainability, and fairness. The interviewees also raised issues of accountability and governance. Finally, some recommendations are suggested such as developing specific sector regulations, fostering a data-driven organisational culture, considering the algorithm’s complete life cycle, developing and using a specific code of ethics, and providing specific training on ethical issues. Despite some obvious limitations, such as the type and number of companies interviewed, this work identifies real examples and direct priorities to advance the research exploring the gap between practice and principles in AI ethics, with a specific focus on Spanish companies. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00146-021-01267-0","Article","2022","Ethical technology; Life cycle; Ethical issues; Explainability; Exploratory studies; Fairness; Guidelines and Principles; Principle; Privacy; Qualitative methodologies; Research fields; Semi structured interviews; Artificial intelligence","Scopus"
"Poster: On the System-Level Effectiveness of Physical Object-Hiding Adversarial Attack in Autonomous Driving","In Autonomous Driving (AD) systems, perception is both security and safety-critical. Among different attacks on AD perception, object-hiding adversarial attack is one of the most critical ones due to the direct impact on safety-critical driving decisions such as collision avoidance. However, all of the prior works on physical object-hiding adversarial attacks only study the security of the AI component alone rather than with the entire AD system pipeline with closed-loop control. This thus inevitably raises a critical research question: can these prior works actually achieve system-level effects (e.g., vehicle collisions, traffic rule violation) under real-world AD settings with closed-loop control? To answer this critical question, in this work we take the necessary first step by performing the first measurement study on whether and how effective the existing designs can lead to system-level effects. Our early results find that RP2 and FTE, as two representative examples of prior works, cannot achieve any system-level effect in a representative closed-loop AD setup in common STOP sign-controlled road speeds. In the future, we plan to 1) perform a more comprehensive measurement study using both simulated environments and a real vehicle-sized AD R&D chassis; and 2) analyze the measurement study results and explore new attack designs that can better achieve the system-level effect in AD systems. © 2022 Owner/Author.","10.1145/3548606.3563539","Conference paper","2022","Closed loop control systems; Safety engineering; Autonomous driving; Autonomous driving  system security; Closed-loop control; Driving systems; Measurement study; Object hiding attack; Physical objects; System levels; System security; System-level effect; Autonomous vehicles","Scopus"
"AI and public contests: a model to improve the evaluation and selection of public contest candidates in the Police Force","Purpose: The number of candidates applying to public contests (PC) is increasing compared to the number of human resources employees required for selecting them for the Police Force (PF). This work intends to perceive how those public institutions can evaluate and select their candidates efficiently during the different phases of the recruitment process. To achieve this purpose, artificial intelligence (AI) was studied. This paper aims to focus on analysing the AI technologies most used and appropriate to the PF as a complementary recruitment strategy of the National Criminal Investigation police agency of Portugal – Polícia Judiciária. Design/methodology/approach: Using design science research as a methodological approach, the authors suggest a theoretical framework in pair with the segmentation of the candidates and comprehend the most important facts facing public institutions regarding the usage of AI technologies to make decisions about evaluating and selecting candidates. Following the preferred reporting items for systematic reviews and meta-analyses methodology guidelines, a systematic literature review and meta-analyses method was adopted to identify how the usage and exploitation of transparent AI positively impact the recruitment process of a public institution, resulting in an analysis of 34 papers between 2017 and 2021. Findings: Results suggest that the conceptual pairing of evaluation and selection problems of candidates who apply to PC with applicable AI technology such as K-means, hierarchical clustering, artificial neural network and convolutional neural network algorithms can support the recruitment process and could help reduce the workload in the entire process while maintaining the standard of responsibility. The combination of AI and human decision-making is a fair, objective and unbiased process emphasising a decision-making process free of nepotism and favouritism when carefully developed. Innovative and modern as a category, group the statements that emphasise the innovative and contemporary nature of the process. Research limitations/implications: There are two main limitations in this study that should be considered. Firstly, the difficulty regarding the timetable, privacy and legal issues associated with public institutions. Secondly, a small group of experts served as the validation group for the new framework. Individual semi-structured interviews were conducted to alleviate this constraint. They provide additional insights into an interviewee’s opinions and beliefs. Social implications: Ensure that the system is fair, transparent and facilitates their application process. Originality/value: The main contribution is the AI-based theoretical framework, applicable within the analysis of literature papers, focusing on the problem of how the institutions can gain insights about their candidates while profiling them, how to obtain more accurate information from the interview phase and how to reach a more rigorous assessment of their emotional intelligence providing a better alignment of moral values. This work aims to improve the decision-making process of a PF institution recruiter by turning it into a more automated and evidence-based decision when recruiting an adequate candidate for the job vacancy. © 2022, Emerald Publishing Limited.","10.1108/TG-05-2022-0078","Article","2022","","Scopus"
"Improving Trustworthiness of AI Solutions: A Qualitative Approach to Support Ethically-Grounded AI Design","Despite recent efforts to make AI systems more transparent, a general lack of trust in such systems still discourages people and organizations from using or adopting them. In this article, we first present our approach for evaluating the trustworthiness of AI solutions from the perspectives of end-user explainability and normative ethics. Then, we illustrate its adoption through a case study involving an AI recommendation system used in a real business setting. The results show that our proposed approach allows for the identification of a wide range of practical issues related to AI systems and further supports the formulation of improvement opportunities and generalized design principles. By linking these identified opportunities to ethical considerations, the overall results show that our approach can support the design and development of trustworthy AI solutions and ethically-aligned business improvement. © 2022 The Author(s). Published with license by Taylor & Francis Group, LLC.","10.1080/10447318.2022.2095478","Article","2023","Ethical technology; AI systems; Business improvements; Case-studies; Design and Development; Design Principles; End-users; Ethical considerations; Normative ethics; Practical issues; Qualitative approach; Artificial intelligence","Scopus"
"A European Approach to Excellence and Trust: The 2020 White Paper on Artificial Intelligence","This chapter demonstrates that, although a soft-law approach was initially adopted with the publication of the non-binding 2019 Ethics Guidelines, the EU decided to shift towards a legislative approach and called for the adoption of a new EU regulatory framework on artificial intelligence. It underlines that the ethical guidelines and the existing laws which are applicable to AI systems were not considered by the Commission to be sufficient to address the risks posed by the development and deployment of AI. Therefore, the legislative framework should be improved by adjusting or clarifying existing legislation. Alongside the possible adjustments to and clarifications of existing legislation, the Commission considered that a new legislation specifically on artificial intelligence was needed to make the EU legal framework fit for the current and forthcoming technological and commercial developments. The White Paper on AI reaffirmed that “AI should work for people and be a force for good in society”, set out the Commission’s vision of advancing as well as regulating AI, confirmed that a new regulatory framework on AI will be adopted, and offered specific insights about the core elements of the forthcoming new AI regime. The guiding principles of the White Paper are the creation of ecosystems of excellence (“the Policy Framework”) and of trust (“the Regulatory Framework”). Although the White Paper on AI did not set out a concrete framework for new AI legislation, it did set out the Commission’s key priorities in that regard. A new regulatory framework specifically for AI (“effective” and “not excessively prescriptive”) was considered to be necessary, following a risk-based approach, ensuring that the regulatory intervention is proportionate and sufficiently flexible to accommodate technological progress while also precise enough to provide legal certainty. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27953-9_5","Book chapter","2023","","Scopus"
"Analytical Engines With Context-Rich Processing: Towards Efficient Next-Generation Analytics","As modern data pipelines continue to collect, produce, and store a variety of data formats, extracting and combining value from traditional and context-rich sources such as strings, text, video, audio, and logs becomes a manual process where such formats are unsuitable for RDBMS. To tap into the dark data, domain experts analyze and extract insights and integrate them into the data repositories. This process can involve out-of-DBMS, ad-hoc analysis, and processing resulting in ETL, engineering effort, and suboptimal performance. While AI systems based on ML models can automate the analysis process, they often further generate context-rich answers. Using multiple sources of truth, for either training the models or in the form of knowledge bases, further exacerbates the problem of consolidating the data of interest.We envision an analytical engine co-optimized with components that enable context-rich analysis. Firstly, as the data from different sources or resulting from model answering cannot be cleaned ahead of time, we propose using online data integration via model-assisted similarity operations. Secondly, we aim for a holistic pipeline cost- and rule-based optimization across relational and model-based operators. Thirdly, with increasingly heterogeneous hardware and equally heterogeneous workloads ranging from traditional relational analytics to generative model inference, we envision a system that just-in-time adapts to the complex analytical query requirements. To solve increasingly complex analytical problems, ML offers attractive solutions that must be combined with traditional analytical processing and benefit from decades of database community research to achieve scalability and performance effortless for the end user.  © 2023 IEEE.","10.1109/ICDE55515.2023.00298","Conference paper","2023","Data integration; Data mining; Database systems; Machine learning; Pipeline processing systems; Pipelines; Query processing; Taps; Analytic; Data domains; Data pipelines; Domain experts; Expert analysis; Hardware-conscious processing; Machine-learning; Manual process; Queries optimization; RDBMS's; Engines","Scopus"
"Strengthening the AI Operating Environment","In the rapidly evolving discourse on artificial intelligence (AI), the familiar refrain of “maximizing potential while mitigating risks” has become somewhat of a ubiquitous mantra, emphasizing the need for an effective risk mitigation framework. This paper briefly examines the current state of AI-enabled applications and discusses the various risk containment strategies being implemented. Initial efforts focused on establishing high-level principles for responsible AI use. More recent strategies have sought to operationalize these principles through normative instruments, such as industry best practices and legal statutes, that govern AI applications and their creators. While valuable, such a top-down approach is not sufficiently effective; a complementary, bottom-up approach focused on strengthening the environment in which AI is deployed is also necessary. The paper analyzes two specific initiatives aimed at enhancing the human component of AI deployment (creating a better-informed public through AI benchmarks, creating a better-equipped public with resources for local validation) and offers insights on how this environment-focused track can contribute to risk containment. Furthermore, we suggest additional steps for leveraging this approach in tandem with top-down strategies to cultivate a more robust risk mitigation framework. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2023","Artificial intelligence education; Artificial intelligence governance; Artificial intelligence risk; Competence; Effectiveness; Evaluation; Operating environment; Risk mitigation; Trust; Validation; Artificial intelligence","Scopus"
"AI ethics and learning: EdTech companies’ challenges and solutions","The aim of this study is to identify the ethical challenges, solutions and needs of educational technology (EdTech) companies. Qualitative data was collected in interviews with seven experts from four companies, and the data was analysed using inductive content analysis. The four main areas of challenges were ambiguous regulations, inequalities in human learning, ethical dilemmas in machine learning (ML) and lack of ability to assess consequences in society. According to the studied companies, AI regulations are difficult to understand and implement. There is also much to be done in terms of reliability, transparency, and safety. Consequently, companies suggested that AI-based products should be more preventive, safe, explicable, and equally accessible. Sufficient information, multi-professional support also within company, global collaboration, sharing best practices, and general discussion were emphasised. The results show that EdTech companies are aware of their ethical challenges, and their responsibility as disseminators of information. However, translating information into practice is challenging because it is often very fragmented and difficult to understand. Companies hoped that everyone: themselves, consumers, educational institutions, researchers, funders, and decision-makers would do more together to overcome the ethical challenges of AI. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","10.1080/10494820.2022.2043908","Article","2023","","Scopus"
"Explainable Artificial Intelligence for Autonomous Surface Vessels by Fuzzy-Based Collision Avoidance System","Autonomy at sea relies on algorithms (often local) to make the decisions. One approach to create these algorithms are through the use of artificial intelligence. Numerous black-box machine learning-based algorithms are proposed for autonomous surface vessels (ASV) to make decisions like changing the speed or changing the route in order to reach the operational goal in an optimal way with respect to cost (fuel, time, etc.) and safety (avoid collisions or dangerous situations). Hence, the algorithms must take into account many constraints and are influenced by several varying factors such as other vessels, weather, etc. The objective of this paper is to propose a model that provides the reason behind the ASV’s decision when it is on a predefined path and changes speed or route. Fuzzy logic is used to record the expert knowledge based on COLREGs to steer the vessel and take the decision during the collision course. Data has been captured based on expert knowledge and used to train an explainable model. The explainable model predicts the reason behind the decision. The focus of the paper is on local explainability instead of global decisions. The structured abstracts of the paper are (1) Background: Several AI-enabled algorithms have been proposed for implementing autonomy to avoid the collision. These black-box techniques provide good predictions at the same time, they fail to explain the reason behind the decision, which makes the model less trustworthy; (2) Methods: Expert knowledge (COLREGs) has been captured using fuzzy rules and applied when ASV progresses, the decision has been recorded. (3) Results: The explainable model provides the reason behind the action taken by the collision avoidance system; (4) Conclusion: A model has been proposed that explains the collision avoidance system to make it transparent and trustworthy. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-99-0838-7_12","Conference paper","2023","Collision avoidance; Computer circuits; Machine learning; Safety devices; ANFIS; Autonomous surface vessels; Black boxes; Collision avoidance systems; Collision risks; COLREG; Expert knowledge; Explainable artificial intelligence; Fuzzy-Logic; Machine-learning; Fuzzy inference","Scopus"
"Human-Centered AI for Manufacturing – Design Principles for Industrial AI-Based Services","AI-based services are becoming more and more common in manufacturing; however, the development, implementation, and operation of these services are associated with challenges. The design of Human-Centered AI (HCAI) is one approach to address these challenges. Design guidelines and principles are provided to assist AI developers in the design of HCAI. However, these principles are currently defined for AI in general and not for specific application contexts. The aim of this work is to analyze whether existing design principles for HCAI are transferable to IAI-based services in manufacturing and how they can be integrated into the development process. In an explorative-qualitative research design, the design pattern of the People + AI Guidebook by the PAIR from Google were analyzed regarding their applicability in manufacturing environments. The finding show that a transfer of the design principles is generally possible. According to the experts, 15 of the design patterns have a direct influence on the perception of Industrial AI-based services by end-users or management and can thus increase the acceptance of them. Finally, the design patterns were assessed in terms of their application relevance and complexity in manufacturing. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-35891-3_8","Conference paper","2023","Application contexts; Design Patterns; Design Principles; Development process; Guidelines and Principles; Human-centered AI; Industrial AI; Manufacturing design; Qualitative research; Research designs; Industrial research","Scopus"
"Distributed Raman Spectrum Data Augmentation System Using Federated Learning with Deep Generative Models","Chemical agents are one of the major threats to soldiers in modern warfare, so it is so important to detect chemical agents rapidly and accurately on battlefields. Raman spectroscopy-based detectors are widely used but have many limitations. The Raman spectrum changes unpredictably due to various environmental factors, and it is hard for detectors to make appropriate judgments about new chemical substances without prior information. Thus, the existing detectors with inflexible techniques based on determined rules cannot deal with such problems flexibly and reactively. Artificial intelligence (AI)-based detection techniques can be good alternatives to the existing techniques for chemical agent detection. To build AI-based detection systems, sufficient amounts of data for training are required, but it is not easy to produce and handle fatal chemical agents, which causes difficulty in securing data in advance. To overcome the limitations, in this paper, we propose the distributed Raman spectrum data augmentation system that leverages federated learning (FL) with deep generative models, such as generative adversarial network (GAN) and autoencoder. Furthermore, the proposed system utilizes various additional techniques in combination to generate a large number of Raman spectrum data with reality along with diversity. We implemented the proposed system and conducted diverse experiments to evaluate the system. The evaluation results validated that the proposed system can train the models more quickly through cooperation among decentralized troops without exchanging raw data and generate realistic Raman spectrum data well. Moreover, we confirmed that the classification model on the proposed system performed learning much faster and outperformed the existing systems. © 2022 by the authors.","10.3390/s22249900","Article","2022","Artificial Intelligence; Computer Communication Networks; Health Status; Judgment; Learning; Chemical detection; Deep learning; Generative adversarial networks; Petroleum reservoir evaluation; Raman scattering; Augmentation systems; Chemical agent; Data augmentation; Deep generative model; Distributed systems; Environmental factors; Federated learning; Generative model; Modern warfare; Spectra datum; artificial intelligence; computer network; decision making; health status; learning; Learning systems","Scopus"
"Challenges and best practices in corporate AI governance: Lessons from the biopharmaceutical industry","While the use of artificial intelligence (AI) systems promises to bring significant economic and social benefits, it is also coupled with ethical, legal, and technical challenges. Business leaders thus face the question of how to best reap the benefits of automation whilst managing the associated risks. As a first step, many companies have committed themselves to various sets of ethics principles aimed at guiding the design and use of AI systems. So far so good. But how can well-intentioned ethical principles be translated into effective practice? And what challenges await companies that attempt to operationalize AI governance? In this article, we address these questions by drawing on our first-hand experience of shaping and driving the roll-out of AI governance within AstraZeneca, a biopharmaceutical company. The examples we discuss highlight challenges that any organization attempting to operationalize AI governance will have to face. These include questions concerning how to define the material scope of AI governance, how to harmonize standards across decentralized organizations, and how to measure the impact of specific AI governance initiatives. By showcasing how AstraZeneca managed these operational questions, we hope to provide project managers, CIOs, AI practitioners, and data privacy officers responsible for designing and implementing AI governance frameworks within other organizations with generalizable best practices. In essence, companies seeking to operationalize AI governance are encouraged to build on existing policies and governance structures, use pragmatic and action-oriented terminology, focus on risk management in development and procurement, and empower employees through continuous education and change management. Copyright © 2022 Mökander, Sheth, Gersbro-Sundler, Blomgren and Floridi.","10.3389/fcomp.2022.1068361","Article","2022","","Scopus"
"Explainable for Trustworthy AI","Black-box Artificial Intelligence (AI) systems for automated decision making are often based on over (big) human data, map a user’s features into a class or a score without exposing why. This is problematic for the lack of transparency and possible biases inherited by the algorithms from human prejudices and collection artefacts hidden in the training data, leading to unfair or wrong decisions. The future of AI lies in enabling people to collaborate with machines to solve complex problems. This requires good communication, trust, clarity, and understanding, like any efficient collaboration. Explainable AI (XAI) addresses such challenges, and for years different AI communities have studied such topics, leading to different definitions, evaluation protocols, motivations, and results. This chapter provides a reasoned introduction to the work of Explainable AI to date and surveys the literature focusing on symbolic AI-related approaches. We motivate the needs of XAI in real-world and large-scale applications while presenting state-of-the-art techniques and best practices and discussing the many open challenges. © 2023, Springer Nature Switzerland AG.","10.1007/978-3-031-24349-3_10","Conference paper","2023","Artificial intelligence; Decision making; Artificial intelligence systems; Automated decision making; Black boxes; Complex problems; Data maps; Explainable artificial intelligence; Human data; Training data; Transparent by design; Trustworthy artificial intelligence; Behavioral research","Scopus"
"Guidelines and quality criteria for artificial intelligence-based prediction models in healthcare: a scoping review","While the opportunities of ML and AI in healthcare are promising, the growth of complex data-driven prediction models requires careful quality and applicability assessment before they are applied and disseminated in daily practice. This scoping review aimed to identify actionable guidance for those closely involved in AI-based prediction model (AIPM) development, evaluation and implementation including software engineers, data scientists, and healthcare professionals and to identify potential gaps in this guidance. We performed a scoping review of the relevant literature providing guidance or quality criteria regarding the development, evaluation, and implementation of AIPMs using a comprehensive multi-stage screening strategy. PubMed, Web of Science, and the ACM Digital Library were searched, and AI experts were consulted. Topics were extracted from the identified literature and summarized across the six phases at the core of this review: (1) data preparation, (2) AIPM development, (3) AIPM validation, (4) software development, (5) AIPM impact assessment, and (6) AIPM implementation into daily healthcare practice. From 2683 unique hits, 72 relevant guidance documents were identified. Substantial guidance was found for data preparation, AIPM development and AIPM validation (phases 1–3), while later phases clearly have received less attention (software development, impact assessment and implementation) in the scientific literature. The six phases of the AIPM development, evaluation and implementation cycle provide a framework for responsible introduction of AI-based prediction models in healthcare. Additional domain and technology specific research may be necessary and more practical experience with implementing AIPMs is needed to support further guidance. © 2022, The Author(s).","10.1038/s41746-021-00549-7","Review","2022","Digital libraries; Forecasting; Health care; Quality control; Data preparation; Impact assessments; Model development; Model evaluation; Model implementation; Model validation; Prediction modelling; Quality criteria; Scoping review; Six-phase; artificial intelligence; attention; health care practice; human; library; Medline; practice guideline; prediction; review; scientific literature; software; Web of Science; Software design","Scopus"
"Towards Effective Paraphrasing for Information Disguise","Information Disguise (ID), a part of computational ethics in Natural Language Processing (NLP), is concerned with best practices of textual paraphrasing to prevent the non-consensual use of authors’ posts on the Internet. Research on ID becomes important when authors’ written online communication pertains to sensitive domains, e.g., mental health. Over time, researchers have utilized AI-based automated word spinners (e.g., SpinRewriter, WordAI) for paraphrasing content. However, these tools fail to satisfy the purpose of ID as their paraphrased content still leads to the source when queried on search engines. There is limited prior work on judging the effectiveness of paraphrasing methods for ID on search engines or their proxies, neural retriever (NeurIR) models. We propose a framework where, for a given sentence from an author’s post, we perform iterative perturbation on the sentence in the direction of paraphrasing with an attempt to confuse the search mechanism of a NeurIR system when the sentence is queried on it. Our experiments involve the subreddit “r/AmItheAsshole” as the source of public content and Dense Passage Retriever as a NeurIR system-based proxy for search engines. Our work introduces a novel method of phrase-importance rankings using perplexity scores and involves multi-level phrase substitutions via beam search. Our multi-phrase substitution scheme succeeds in disguising sentences 82% of the time and hence takes an essential step towards enabling researchers to disguise sensitive content effectively before making it public. We also release the code of our approach. (https://github.com/idecir/idecir-Towards-Effective-Paraphrasing-for-Information-Disguise ) © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-28238-6_22","Conference paper","2023","HTTP; Information retrieval; Iterative methods; Natural language processing systems; Philosophical aspects; Adversarial retrieval; Best practices; Computational ethic; Information disguise; Language processing; Natural languages; Neural information; Neural information retrieval; On-line communication; Paraphrasing; Search engines","Scopus"
"Are physicians and medical students ready for artificial intelligence applications in healthcare?","Background: Artificial intelligence (AI) Healthcare applications are listed in the national visions of some Gulf Cooperation Council countries. A successful use of AI depends on the attitude and perception of medical experts of its applications. Objective: To evaluate physicians and medical students’ attitude and perception on AI applications in healthcare. Method: A web-based survey was disseminated by email to physicians and medical students. Results: A total of 293 (82 physicians and 211 medical students) individuals have participated (response rate is 27%). Seven participants (9%) reported knowing nothing about AI, while 208 (69%) were aware that it is an emerging field and would like to learn about it. Concerns about AI impact on physicians’ employability were not prominent. Instead, the majority (n=159) agreed that new positions will be created and the job market for those who embrace AI will increase. They reported willingness to adapt AI in practice if it was incorporated in international guidelines (30.5%), published in respected scientific journals (17.1%), or included in formal training (12.2%). Almost two of the three participants agreed that dedicated courses will help them to implement AI. The most commonly reported problem of AI is its inability to provide opinions in unexpected scenarios. Half of the participants think that both the manufacturer and physicians should be legally liable for medical errors occur due to AI-based decision support tools while more than one-third (36.77%) think that physicians who make the final decision should be legally liable. Senior physicians were found to be less familiar with AI and more concerned about physicians’ legal liability in case of a medical error. Conclusion: Physicians and medical students showed positive attitudes and willingness to learn about AI applications in healthcare. Introducing AI learning objectives or short courses in medical curriculum would help to equip physicians with the needed skills for AI-augmented healthcare system. © The Author(s) 2023.","10.1177/20552076231152167","Article","2023","adult; article; artificial intelligence; curriculum; decision support system; e-mail; employability; female; health care system; human; human experiment; job market; learning; legal liability; major clinical study; male; medical error; medical student; perception; physician; practice guideline; skill","Scopus"
"Diversity, Equity, and Inclusion in Artificial Intelligence: An Evaluation of Guidelines","Artificial intelligence (AI) is present everywhere in the lives of individuals. Unfortunately, several cases of discrimination by AI systems have already been reported. Scholars have warned on risks of AI reproducing existing inequalities or even amplifying them. To tackle these risks and promote responsible AI, many ethics guidelines for AI have emerged recently, including diversity, equity, and inclusion (DEI) principles and practices. However, little is known about the DEI content of these guidelines, and to what extent they meet the most relevant accumulated knowledge from DEI literature. We performed a semi-systematic literature review of the AI guidelines regarding DEI stakes and analyzed 46 guidelines published from 2015 to today. We fleshed out the 14 DEI principles and the 18 DEI practices recommended underlying these 46 guidelines. We found that the guidelines mostly encourage one of the DEI management paradigms, namely fairness, justice, and nondiscrimination, in a limited compliance approach. We found that narrow technical practices are favored over holistic ones. Finally, we conclude that recommended practices for implementing DEI principles in AI should include actions aimed at directly influencing AI actors’ behaviors and awareness of DEI risks, rather than just stating intentions and programs. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.","10.1080/08839514.2023.2176618","Article","2023","Ethical technology; Artificial intelligence systems; Compliance approach; Inclusion content; Inclusion principles; Principles and practices; Recommended practice; Systematic literature review; Artificial intelligence","Scopus"
"Factors Influencing Trust and Use of Recommendation AI: A Case Study of Diet Improvement AI in Japan","To use AI systems that are trustworthy, it is necessary to consider not only AI technologies, but also a model that takes into account factors such as guidelines, assurance through audits and standards and user interface design. In this paper, we conducted a questionnaire survey focusing on (1) AI intervention, (2) data management, and (3) purpose of use. The survey was conducted on a case study of an AI service for dietary habit improvement recommendations among Japanese people. The results suggest that how the form of communication between humans and AI is designed may affect whether users trust and use AI. © 2023, The Author(s).","10.1007/978-3-031-34804-4_10","Book chapter","2023","","Scopus"
"Balancing Technological Advances with User Needs: User-centered Principles for AI-Driven Smart City Healthcare Monitoring","In recent years, the integration of artificial intelligence (AI) technologies has greatly benefited smart city healthcare, meeting the growing demand for affordable, efficient, and real-time healthcare services. Patient monitoring is one area where artificial intelligence has shown great promise. Improved health outcomes have been made possible by the advancement of AI-based monitoring systems, which enable more personalized and continuous patient monitoring. However, to fully maximize the benefits of these systems, a user-centered approach is essential, which prioritizes patients' needs and experiences while ensuring their privacy and autonomy are respected. This study focuses on the application of user-centered design principles in the development and deployment of AI-driven monitoring systems in smart city healthcare. Addressing the challenges and opportunities of AI-driven monitoring systems, the article considers issues such as privacy and security concerns, data accuracy, and user acceptance. Finally, some possible future directions to the challenges are suggested. A user-centered approach to AI monitoring systems is recommended for healthcare providers to enhance patient experience in smart city healthcare. © 2022,International Journal of Advanced Computer Science and Applications. All Rights Reserved.","10.14569/IJACSA.2023.0140341","Article","2023","Artificial intelligence; Continuous time systems; Health care; Patient monitoring; User centered design; Artificial intelligence technologies; Efficient time; Growing demand; Healthcare monitoring; Monitoring system; Smart healthcare; Technological advances; User need; User-centered approach; User-centred; Smart city","Scopus"
"AI-based adaptive personalized content presentation and exercises navigation for an effective and engaging E-learning platform","Effective and engaging E-learning becomes necessary in unusual conditions such as COVID-19 pandemic, especially for the early stages of K-12 education. This paper proposes an adaptive personalized E-learning platform with a novel combination of Visual/Aural/Read, Write/Kinesthetic (VARK) presentation or gamification and exercises difficulty scaffolding through skipping/hiding/ reattempting. Cognitive, behavior and affective adaptation means are included in developing a dynamic learner model, which detects and corrects each student’s learning style and cognitive level. As adaptation targets, the platform provides adaptive content presentation in two groups (VARK and gamification), adaptive exercises navigation and adaptive feedback. To achieve its goal, the platform utilizes a Deep Q-Network Reinforcement Learning (DQN-RL) and an online rule-based decision making implementation. The platform interfaces front-end dedicated website and back-end adaptation algorithms. An improvement in learning effectiveness is achieved comparing the post-test to the pre-test in a pilot experiment for grade 3 mathematics curriculum. Both groups witnessed academic performance and satisfaction level improvements, most importantly, for the students who started the experiment with a relatively low performance. VARK group witnessed a slightly more improvement and higher satisfaction level, since interactive activities and games in the kinesthetic presentation can provide engagement, while keeping other presentation styles available, when needed. © 2022, The Author(s).","10.1007/s11042-022-13076-8","Article","2023","Behavioral research; Decision making; E-learning; Education computing; Learning systems; Scaffolds; Students; Content presentation; Dynamic learner model; Gamification; Kinesthetics; Learner modeling; Learningstyles; Primary school mathematic; Primary schools; Reinforcement learnings; School mathematics; Reinforcement learning","Scopus"
"Causality Prediction with Neural-Symbolic Systems: A Case Study in Smart Grids","In complex systems, such as smart grids, explanations of system events benefit both system operators and users. Deriving causality knowledge as a basis for explanations has been addressed with rule-based, symbolic AI systems. However, these systems are limited in their scope to discovering causalities that can be inferred by their rule base. To address this gap, we propose a neural-symbolic architecture that augments symbolic approaches with sub-symbolic components, in order to broaden the scope of the identified causalities. Concretely, we use Knowledge Graph Embeddings (KGE) to solve causality knowledge derivation as a link prediction problem. Experimental results show that the neural-symbolic approach can predict causality knowledge with a good performance and has the potential to predict causalities that were not present in the symbolic system, thus broadening the causality knowledge scope of symbolic approaches. © 2023 Copyright for this paper by its authors.","","Conference paper","2023","Forecasting; Graph embeddings; Knowledge graph; Case-studies; Causality; Explainability; Graph embeddings; Knowledge graph embedding; Knowledge graphs; Neural-symbolic systems; Smart grid; System operator; Smart power grids","Scopus"
"Artificial intelligence assisted acute patient journey","Artificial intelligence is taking the world by storm and soon will be aiding patients in their journey at the hospital. The trials and tribulations of the healthcare system during the COVID-19 pandemic have set the stage for shifting healthcare from a physical to a cyber-physical space. A physician can now remotely monitor a patient, admitting them only if they meet certain thresholds, thereby reducing the total number of admissions at the hospital. Coordination, communication, and resource management have been core issues for any industry. However, it is most accurate in healthcare. Both systems and providers are exhausted under the burden of increasing data and complexity of care delivery, increasing costs, and financial burden. Simultaneously, there is a digital transformation of healthcare in the making. This transformation provides an opportunity to create systems of care that are artificial intelligence-enabled. Healthcare resources can be utilized more justly. The wastage of financial and intellectual resources in an overcrowded healthcare system can be avoided by implementing IoT, telehealth, and AI/ML-based algorithms. It is imperative to consider the design principles of the patient's journey while simultaneously prioritizing a better user experience to alleviate physician concerns. This paper discusses the entire blueprint of the AI/ML-assisted patient journey and its impact on healthcare provision. Copyright © 2022 Nazir, Mushhood Ur Rehman, Asghar and Kalia.","10.3389/frai.2022.962165","Review","2022","","Scopus"
"The Proposed Artificial Intelligence Act and Subsequent ‘Compromise’ Proposals: Commission, Council, Parliament","This chapter provides a thorough and systematic analysis of the Commission’s proposed AI Act which set harmonised rules for the development, placement on the market and use of AI systems in the EU following a proportionate risk-based approach. The proposed AI Act must be reviewed and adopted by the European Parliament and Member States before it comes into effect and, to this end, the Commission’s proposed AI Act is being discussed by the co-legislators (the main decision-making bodies of the EU), i.e., the European Parliament (“the Parliament”) and the Council of the European Union (“the Council”). This chapter compares the Commission’s proposed AI Act with the Council’s numerous “compromise” proposals (from November 2021 to December 2022) which attempted to find a common position between Member States. The Council’s AI Act final version (general approach) of 11 November 2022 received unanimous approval from the Committee of Permanent Representatives on 18 November 2022, and its formal adoption by EU ministers took place at the Telecom Council meeting on 6 December 2022. This chapter also takes into account the European Parliament’s views on all major and controversial issues, revealing the position the European Parliament is likely to adopt in the forthcoming negotiations with the Commission and the Council on the text of the AI Act. It covers the process of preparing the Parliament’s compromise proposal, taking account of the comments/amendments which were submitted by political groups represented in the European Parliament and which set the tone for future discussions and political negotiations in order to reach a majority via compromises. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27953-9_8","Book chapter","2023","","Scopus"
"A Logical Agent Approach to Solving the Wumpus World Problem: An Analysis of Game Trees","The Wumpus World problem is a classic AI challenge in which an agent must navigate a maze-like environment to find and retrieve gold while avoiding obstacles such as pits and a monster called the Wumpus. This project aims to implement a logical agent to solve the Wumpus World problem using a combination of first-order logic and the Minimax algorithm. The environment is represented as a set of logical propositions. The agent's knowledge base is expressed as a set of first-order logic rules describing the relationships between the propositions. The Minimax algorithm is used to generate a game tree and compute the minimax values of the nodes in the tree, allowing the agent to make informed decisions about which actions to take. The implementation demonstrates the versatility and expressiveness of logical agents for solving complex AI problems and highlights the potential benefits of using first-order logic in AI systems. © 2023 IEEE.","10.1109/ICACCS57279.2023.10113041","Conference paper","2023","Computer circuits; Formal logic; Knowledge based systems; Software agents; Agent approach; Avoiding obstacle; First order logic; Game trees; Logical agents; Maze-like environment; Min-max; Minimax algorithm; Minmax algorithm; Wumpus world; Trees (mathematics)","Scopus"
"Analysis of the Classification of Medical Device Software in the AI Act Proposal","The Artificial Intelligence Act (AIA) proposal by the European Commission (EC) is considered the first legal attempt to harmonize rules for AI systems. The proposal is designed to regulate AI systems in different European economic sectors, including Medical Devices (MD). This paper aims to examine the classification of AI systems in the AIA and their alignment with the Medical Device Regulation (MDR). The analysis focuses on Software as a Medical Device (SaMD) and Software in a Medical Device (SiMD), excluding general-purpose AI systems and machinery products (i.e., driven systems and safety components), as investigation in the Machinery Directive legislation is required. The strategy is to identify the classification conditions for AI systems by mapping key terms and definitions related to Article 6 in the AIA. Then, these conditions are translated into propositions suitable for the MD domain and presented in a flow chart for discussion. The primary source of information for the analysis is the MDR and the AIA, considering the latest revisited version of the proposal (Presidency compromise text, document 11124/22). We conclude this paper by discussing the classification pathway for SaMD and SiMD according to the AIA and additional discussion on terminology-related concerns and suggestions. © 2023 Copyright for this paper by its authors.","","Conference paper","2023","Computer software; Laws and legislation; AI system classification; AI systems; Artificial intelligence act proposal; Condition; European Commission; Medical device software; Medical Devices; Medical devices regulations; Medical software; System classification; Artificial intelligence","Scopus"
"Improved Reinforcement Learning in Asymmetric Real-time Strategy Games via Strategy Diversity","We investigate the use of artificial intelligence (AI)-based techniques in learning to play a 2-player, real-time strategy (RTS) game called Hunting-of-the-Plark. The game is challenging to play for both humans and AI-based techniques because players cannot observe each other’s moves while playing the game and one player is at a disadvantage due to the asymmetric nature of the game rules. We analyze the performance of different deep reinforcement learning algorithms to train software agents that can play the game. Existing reinforcement learning techniques for RTS games enable players to converge towards an equilibrium outcome of the game but usually do not facilitate further exploration of techniques to exploit and defeat the opponent. To address this shortcoming, we investigate techniques including self-play and strategy diversity that can be used by players to improve their performance beyond the equilibrium outcome. We observe that when players use self-play, their number of wins begins to cycle around an equilibrium value as each player quickly learns to outwit and defeat its opponent and vice-versa. Finally, we show that strategy diversity could be used as an effective means to alleviate the performance of the disadvantaged player caused by the asymmetric nature of the game. © 2023, Serious Games Society. All rights reserved.","10.17083/ijsg.v10i1.548","Article","2023","","Scopus"
"The PSyKE Technology for Trustworthy Artificial Intelligence","Transparency is one of the “Ethical Principles in the Context of AI Systems” as described in the Ethics Guidelines for Trustworthy Artificial Intelligence (TAI). It is closely linked to four other principles – respect for human autonomy, prevention of harm, traceability and explainability – and involves numerous ways in which opaqueness can have undesirable impacts, such as discrimination, inequality, segregation, marginalisation, and manipulation. The opaqueness of many AI tools and the inability to understand the underpinning black boxes contradicts these principles as well as prevents people from fully trusting them. In this paper we discuss the PSyKE technology, a platform providing general-purpose support to symbolic knowledge extraction from different sorts of black-box predictors via many extraction algorithms. The extracted knowledge results are easily injectable into existing AI assets making them meet the transparency TAI requirement. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27181-6_1","Conference paper","2023","Artificial intelligence; Data mining; Ethical technology; Extraction; AI systems; Black boxes; Ethical principles; Explainability; Knowledge extraction; Marginalization; PSyKE; Symbolic knowledge; Symbolic knowledge extraction; Trustworthy artificial intelligence; Transparency","Scopus"
"Bag-of-Words Similarity in eXplainable AI","eXplainable AI (XAI) does not only lie in the interpretation of the rules generated by AI systems, but also in the evaluation and selection, among many rules automatically generated by large datasets, of those that are more relevant and meaningful for domain experts. With this work, we propose a method for evaluation of similarity between rules, which identifies similar rules, or very different ones, by exploiting techniques developed for Natural Language Processing (NLP). We evaluate the similarity of if-then rules by interpreting them as sentences and generating a similarity matrix acting as an enabler for domain experts to analyse the generated rules and thus discover new knowledge. Rule similarity may be applied to rule analysis and manipulation in different scenarios: the first one deals with rule analysis and interpretation, while the second scenario refers to pruning unnecessary rules within a single ruleset. Rule similarity allows also the automatic comparison and evaluation of rulesets. Two different examples are provided to evaluate the effectiveness of the proposed method for rules analysis for knowledge extraction and rule pruning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-16078-3_58","Conference paper","2023","","Scopus"
"Designing a feature selection method based on explainable artificial intelligence","Nowadays, artificial intelligence (AI) systems make predictions in numerous high stakes domains, including credit-risk assessment and medical diagnostics. Consequently, AI systems increasingly affect humans, yet many state-of-the-art systems lack transparency and thus, deny the individual’s “right to explanation”. As a remedy, researchers and practitioners have developed explainable AI, which provides reasoning on how AI systems infer individual predictions. However, with recent legal initiatives demanding comprehensive explainability throughout the (development of an) AI system, we argue that the pre-processing stage has been unjustifiably neglected and should receive greater attention in current efforts to establish explainability. In this paper, we focus on introducing explainability to an integral part of the pre-processing stage: feature selection. Specifically, we build upon design science research to develop a design framework for explainable feature selection. We instantiate the design framework in a running software artifact and evaluate it in two focus group sessions. Our artifact helps organizations to persuasively justify feature selection to stakeholders and, thus, comply with upcoming AI legislation. We further provide researchers and practitioners with a design framework consisting of meta-requirements and design principles for explainable feature selection. © 2022, The Author(s).","10.1007/s12525-022-00608-1","Article","2022","","Scopus"
"The future of endoscopy–what are the thoughts on artificial intelligence?","There is an emerging role of artificial intelligence (AI) in endoscopy with studies on early systems showing promising results. However, various limitations inhibit widespread use. The aim of this study was to ascertain the sentiments of endoscopists and understand the benefits and barriers towards adoption of AI systems into healthcare. An anonymous online 18-question survey was disseminated to gastroenterology and surgical departments across UK. A total of 75 endoscopists completed the questionnaire. The majority felt that AI would increase adenoma detection rate (ADR) (72.8%) and aid lesion characterisation (78.6%). However, only a quarter of respondents were either moderately or very familiar with AI, and there was no consensus on necessity of AI in endoscopy. The key barriers identified were cost, accessibility and lack of guidelines. Endoscopists believe AI systems will have a positive impact on endoscopy; however, these systems must provide quality assurance through large clinical trials before adoption. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","10.1080/0952813X.2023.2178516","Article","2023","Artificial intelligence; Quality assurance; Tumors; Adenoma detection rate; Artificial intelligence systems; Clinical trial; Colonoscopy; Computer aided detection; Detection rates; IS costs; Endoscopy","Scopus"
"Human-centered design and evaluation of AI-empowered clinical decision support systems: a systematic review","Introduction: Artificial intelligence (AI) technologies are increasingly applied to empower clinical decision support systems (CDSS), providing patient-specific recommendations to improve clinical work. Equally important to technical advancement is human, social, and contextual factors that impact the successful implementation and user adoption of AI-empowered CDSS (AI-CDSS). With the growing interest in human-centered design and evaluation of such tools, it is critical to synthesize the knowledge and experiences reported in prior work and shed light on future work. Methods: Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we conducted a systematic review to gain an in-depth understanding of how AI-empowered CDSS was used, designed, and evaluated, and how clinician users perceived such systems. We performed literature search in five databases for articles published between the years 2011 and 2022. A total of 19874 articles were retrieved and screened, with 20 articles included for in-depth analysis. Results: The reviewed studies assessed different aspects of AI-CDSS, including effectiveness (e.g., improved patient evaluation and work efficiency), user needs (e.g., informational and technological needs), user experience (e.g., satisfaction, trust, usability, workload, and understandability), and other dimensions (e.g., the impact of AI-CDSS on workflow and patient-provider relationship). Despite the promising nature of AI-CDSS, our findings highlighted six major challenges of implementing such systems, including technical limitation, workflow misalignment, attitudinal barriers, informational barriers, usability issues, and environmental barriers. These sociotechnical challenges prevent the effective use of AI-based CDSS interventions in clinical settings. Discussion: Our study highlights the paucity of studies examining the user needs, perceptions, and experiences of AI-CDSS. Based on the findings, we discuss design implications and future research directions. Copyright © 2023 Wang, Zhang, Wang, Cao, Zhou, Zhang, Liu, Fan and Tian.","10.3389/fcomp.2023.1187299","Review","2023","","Scopus"
"Awareness among teaching on AI and ML applications based on fuzzy in education sector at USA","This paper summarises the level of knowledge held by educators in the United States on the use of artificial intelligence and machine learning in the classroom. The education industry seems to have reaped little benefits from the AI & ML industry's growth thus far. In any event, the creation of new ML & AI-based systems is mostly aimed towards areas with higher societal needs, such as medical diagnostics and individual transportation, rather than institutions of higher education. With this analysis, we want to shed some light on the mysterious state of application development in the US education industry. The report was written using a triangulation of research approaches to achieve this objective. First, we surveyed the current state-of-the-art reports from other countries and reviewed the relevant literature on AI & ML applications in the field of education. In the second phase, we analysed, to the extent possible, official documents from the United States education sector that dealt with AI and ML based on fuzzy digitalization initiatives. Third, in order to corroborate and expand upon the impressions received from the relevant literature and the document analysis, 15 guideline-based expert interviews were undertaken. Based on this data, we provide a selection of the AI & ML systems in use in universities and colleges now, analyse the benefits and drawbacks of implementing them, and speculate on their potential future evolution. While it would be a stretch to say that this paper presents a comprehensive overview of the subject, it does provide light on key areas of application and potential future research directions for AI and ML. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s00500-023-08329-z","Article","2023","Diagnosis; Fuzzy sets; Artificial intelligence learning; Education industry; Education sectors; Educational sectors; Fuzzy classifiers; Industry growth; Institutions of higher educations; Learning analytic; Machine-learning; Medical diagnostics; Machine learning","Scopus"
"Good for tech: Disability expertise and labor in China’s artificial intelligence sector","People with disabilities are often perceived as being “given” the opportunity to work, rather than “providing” valuable labor. Centering on disabled data workers as experts involved in the quotidian construction of artificial intelligence (AI) systems in China, this article shows that disability expertise and labor can afford a technical edge to AI systems in a certain political economy. In the case examined, the work of consistently synchronizing interpretations of the ambiguous data and elusive rules of smart home systems prefers a stable annotation workforce with coordinated cognition and trained judgment. This technical demand has come to be met by a committed team of skilled disabled workers, who are pushed out from mainstream job market by systemic ableism, and pulled in by disability-informed expertise that reconfigures space, time, and political economy to meet non-normative bodyminds. Through this exceptional case run by a disabled people led organization, I draw attention to disabled people’s underexamined role as system-builders of information technologies as opposed to users, victims, or inspirations, and highlight the transformative potential of disability expertise © This paper is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License","10.5210/fm.v28i1.12887","Article","2023","","Scopus"
"Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations","Human-Centered Artificial Intelligence (AI) focuses on AI systems prioritizing user empowerment and ethical considerations. We explore the importance of usercentric design principles and ethical guidelines in creating AI technologies that enhance user experiences and align with human values. It emphasizes user empowerment through personalized experiences and explainable AI, fostering trust and user agency. Ethical considerations, including fairness, transparency, accountability, and privacy protection, are addressed to ensure AI systems respect human rights and avoid biases. Effective human AI collaboration is emphasized, promoting shared decision-making and user control. By involving interdisciplinary collaboration, this research contributes to advancing human-centered AI, providing practical recommendations for designing AI systems that enhance user experiences, promote user empowerment, and adhere to ethical standards. It emphasizes the harmonious coexistence between humans and AI, enhancing well-being and autonomy and creating a future where AI technologies benefit humanity. Overall, this research highlights the significance of human-centered AI in creating a positive impact. By centering on users' needs and values, AI systems can be designed to empower individuals and enhance their experiences. Ethical considerations are crucial to ensure fairness and transparency. With effective collaboration between humans and AI, we can harness the potential of AI to create a future that aligns with human aspirations and promotes societal well-being. © 2023 IEEE.","10.1109/HORA58378.2023.10156761","Conference paper","2023","Artificial intelligence; Decision making; Ethical technology; Technology transfer; Artificial intelligence systems; Artificial intelligence technologies; Digitalization; Empowerment; Ethical considerations; Ethicality; Human-centered; Society 2.0; User empowerments; Users' experiences; Transparency","Scopus"
"Multi-objective search for gender-fair and semantically correct word embeddings","Fairness is a crucial non-functional requirement of modern software systems that rely on the use of Artificial Intelligence (AI) to make decisions regarding our daily lives in application domains such as justice, healthcare and education. In fact, these algorithms can exhibit unwanted discriminatory behaviours that create unfair outcomes when the software is used, such as giving privilege to one group of users over another (e.g., males vs. females). Mitigating algorithmic bias during the development life cycle of AI-enabled software is crucial given that any bias in these algorithms is inherited by the software systems using them. However, previous work has shown that mitigating bias can impact the performance of such systems. Therefore, we propose herein a novel use of soft computing for improving AI-enabled software fairness. Specifically, we exploit multi-objective search, as opposed to previous work optimising fairness only, to strike an optimal balance between reducing gender bias and improving semantic correctness of word embedding models, which are at the core of many AI-enabled systems. To assess the effectiveness of our proposal, we carry out a thorough empirical study based on the most recent best practice for the evaluation of search-based approaches and AI-enabled software. We explore seven different search-based approaches, and benchmark them against both baseline and state-of-the-art approaches applied to a popular and widely used word embedding model, namely WORD2VEC. Our results show that multi-objective search outperforms single-objective search, and generates word embeddings that are strictly better than the original ones in both objectives, bias and semantic correctness, for all investigated cases. Additionally, our approach generates word embeddings of higher semantic correctness than those generated by using state-of-the-art techniques in all cases, while also achieving a higher degree of fairness in 67% of the cases. These findings show the feasibility and effectiveness of multi-objective search as a tool for engineers to incorporate fair and accurate word embedding models in their AI-enabled systems. © 2022 The Author(s)","10.1016/j.asoc.2022.109916","Article","2023","Application programs; Life cycle; Semantics; Soft computing; Daily lives; Embeddings; Gender bias; Multi objective; Non-functional requirements; Search-based; Search-based software engineering; Software fairness; Software-systems; Word embedding; Embeddings","Scopus"
"Ethical Principles for Trustworthy AI","This chapter covers the guiding ethical principles which should be based on the EU’s ‘human-centric’ approach to AI that is respectful of European values and principles. The chapter discusses five ethical principles (“ethical imperatives”) and their correlated values that must be respected in the development, deployment and use of AI systems. These ethical principles are: (i) respect for human autonomy; (ii) prevention of harm (non-maleficence); (iii) fairness/justice; (iv) explicability; (v) the principle of beneficence (‘do only good’), i.e., the principle of creating AI technology that is beneficial to humanity. It is explained that EU policy-makers have chosen to remain faithful to the EU’s cultural preferences and higher standard of protection against the risks posed by AI, building on the existing regulatory framework and ensuring that European values are at the heart of creating the right environment of trust for the successful development and use of AI. The overall aim of the ethics guidelines is—apart from establishing an ethical level playing field across all Member States as well as offering guidance on how to foster and secure the development of ethical AI systems—to bring a European ethical approach to the global stage, i.e. to stimulate discussion of ethical frameworks for AI “at a global level” and, therefore, to build an international consensus on AI ethics guidelines. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27953-9_3","Book chapter","2023","","Scopus"
"Artificial intelligence governance: Ethical considerations and implications for social responsibility","A number of articles are increasingly raising awareness on the different uses of artificial intelligence (AI) technologies for customers and businesses. Many authors discuss about their benefits and possible challenges. However, for the time being, there is still limited research focused on AI principles and regulatory guidelines for the developers of expert systems like machine learning (ML) and/or deep learning (DL) technologies. This research addresses this knowledge gap in the academic literature. The objectives of this contribution are threefold: (i) It describes AI governance frameworks that were put forward by technology conglomerates, policy makers and by intergovernmental organizations, (ii) It sheds light on the extant literature on ‘AI governance’ as well as on the intersection of ‘AI’ and ‘corporate social responsibility’ (CSR), (iii) It identifies key dimensions of AI governance, and elaborates about the promotion of accountability and transparency; explainability, interpretability and reproducibility; fairness and inclusiveness; privacy and safety of end users, as well as on the prevention of risks and of cyber security issues from AI systems. This research implies that all those who are involved in the research, development and maintenance of AI systems, have social and ethical responsibilities to bear toward their consumers as well as to other stakeholders in society. © 2023 The Author. Expert Systems published by John Wiley & Sons Ltd.","10.1111/exsy.13406","Article","2023","Deep learning; Economic and social effects; Engineering education; Ethical technology; Expert systems; Learning systems; Artificial intelligence accountability; Artificial intelligence explainability; Artificial intelligence fairness; Artificial intelligence governance; Artificial intelligence risk; Artificial intelligence systems; Artificial intelligence transparency; Ethical considerations; Ethical implications; Social responsibilities; Transparency","Scopus"
"What does the public think about artificial intelligence?—A criticality map to understand bias in the public perception of AI","Introduction: Artificial Intelligence (AI) has become ubiquitous in medicine, business, manufacturing and transportation, and is entering our personal lives. Public perceptions of AI are often shaped either by admiration for its benefits and possibilities, or by uncertainties, potential threats and fears about this opaque and perceived as mysterious technology. Understanding the public perception of AI, as well as its requirements and attributions, is essential for responsible research and innovation and enables aligning the development and governance of future AI systems with individual and societal needs. Methods: To contribute to this understanding, we asked 122 participants in Germany how they perceived 38 statements about artificial intelligence in different contexts (personal, economic, industrial, social, cultural, health). We assessed their personal evaluation and the perceived likelihood of these aspects becoming reality. Results: We visualized the responses in a criticality map that allows the identification of issues that require particular attention from research and policy-making. The results show that the perceived evaluation and the perceived expectations differ considerably between the domains. The aspect perceived as most critical is the fear of cybersecurity threats, which is seen as highly likely and least liked. Discussion: The diversity of users influenced the evaluation: People with lower trust rated the impact of AI as more positive but less likely. Compared to people with higher trust, they consider certain features and consequences of AI to be more desirable, but they think the impact of AI will be smaller. We conclude that AI is still a “black box” for many. Neither the opportunities nor the risks can yet be adequately assessed, which can lead to biased and irrational control beliefs in the public perception of AI. The article concludes with guidelines for promoting AI literacy to facilitate informed decision-making. Copyright © 2023 Brauner, Hick, Philipsen and Ziefle.","10.3389/fcomp.2023.1113903","Article","2023","","Scopus"
"The assessment list for trustworthy artificial intelligence: A review and recommendations","In July 2020, the European Commission's High-Level Expert Group on AI (HLEG-AI) published the Assessment List for Trustworthy Artificial Intelligence (ALTAI) tool, enabling organizations to perform self-assessments of the fit of their AI systems and surrounding governance to the “7 Principles for Trustworthy AI.” Prior research on ALTAI has focused primarily on specific application areas, but there has yet to be a comprehensive analysis and broader recommendations aimed at proto-regulators and industry practitioners. This paper therefore starts with an overview of this tool, including an assessment of its strengths and limitations. The authors then consider the success by which the ALTAI tool is likely to be of utility to industry in improving understanding of the risks inherent in AI systems and best practices to mitigate such risks. It is highlighted how research and practices from fields such as Environmental Sustainability, Social Justice, and Corporate Governance (ESG) can be of benefit for addressing similar challenges in ethical AI development and deployment. Also explored is the extent to which the tool is likely to be successful in being taken up by industry, considering various factors pertaining to its likely adoption. Finally, the authors also propose recommendations applicable internationally to similar bodies to the HLEG-AI regarding the gaps needing to be addressed between high-level principles and practical support for those on the front-line developing or commercializing AI tools. In all, this work provides a comprehensive analysis of the ALTAI tool, as well as recommendations to relevant stakeholders, with the broader aim of promoting more widespread adoption of such a tool in industry. Copyright © 2023 Radclyffe, Ribeiro and Wortham.","10.3389/frai.2023.1020592","Article","2023","","Scopus"
"An omni-channel, outcomes-focused approach to scale digital health interventions in resource-limited populations: a case study","Populations in resource-limited communities have low health awareness, low financial literacy levels, and inadequate access to primary healthcare, leading to low adoption of preventive health behaviours, low healthcare-seeking behaviours, and poor health outcomes. Healthcare providers have limited reach and insights, limiting their ability to design relevant products for resource limited settings. Our primary preventive health intervention, called the Saathealth family health interventions, is a scaled digital offering that aims to improve knowledge levels on various health topics, nudge positive behaviour changes, and drive improved health outcomes. This case study presents our learnings and best practices in scaling these digital health interventions in resource-limited settings and maximising their impact. We scaled the Saathealth interventions to cumulatively reach >10 million users across India using a multi-pronged approach: (1) ensuring localization and cultural relevance of the health content delivered through user research; (2) disseminating content using omni-channel approaches, which involved using diverse content types and multiple digital platforms; (3) using iterative product features such as gamification and artificial intelligence-based (AI-based) predictive models; (4) using real-time analytics to adapt the user's digital experience by using interactive content to drive them towards products and services and (5) experiments with sustainability models to yield some early successes. The Saathealth family health mobile app had >25,000 downloads and the intervention reached >873,000 users in India every month through the mobile app, Facebook, and Instagram combined, from the time period of February 2022 to January 2023. We repeatedly observed videos and quizzes to be the most popular content types across all digital channels being used. Our AI-based predictive models helped improve user retention and content consumption, contributing to the sustainability of the mobile apps. In addition to reaching a high number of users across India, our scaling strategies contributed to deepened engagement and improved health-seeking behaviour. We hope these strategies help guide the sustainable and impactful scaling of mobile health interventions in other resource-limited settings. 2023 Hazra-Ganju, Dlima, Menezes, Ganju and Mer.","10.3389/fdgth.2023.1007687","Article","2023","Article; artificial intelligence; awareness; behavior change; cardiovascular disease; digital health intervention; family health; feedback system; gamification; gastrointestinal disease; health behavior; health education; health insurance; hospitalization; human; India; intervention study; malignant neoplasm; mental disease; mhealth assessment and planning for scale tool kit; physical activity; predictive model; primary health care; quality of life assessment; resource limited setting; social media; social support; tuberculosis; typhoid fever; vector borne disease; videorecording","Scopus"
"Communication, sensing, computing and energy harvesting in smart cities","A smart city provides diverse services based on real-time data obtained from different devices deployed in urban areas. These devices are largely battery-powered and widely placed. Therefore, providing continuous energy to these devices and ensuring their efficient sensing and communications are critical for the wide deployment of smart cities. To achieve frequent and effective data exchange, advanced enabling information and communication technology (ICT) infrastructure is in urgent demand. An ideal network in future smart cities should be capable of sensing the physical environment and intelligently mapping the digital world. Therefore, in this paper, we propose design guidelines on how to integrate communications with sensing, computing and/or energy harvesting in the context of smart cities, aiming to offer research insights on developing integrated communications, sensing, computing and energy harvesting (ICSCE) for promoting the development ICT infrastructure in smart cities. To put these four pillars of smart cities together and to take advantage of ever-increasing artificial intelligence (AI) technologies, the authors propose a promising AI-enabled ICSCE architecture by leveraging the digital twin network. The proposed architecture models the physical deep neural network-aided ICSCE system in a virtual space, where offline training is performed by using the collected real-time data from the environment and physical devices. © 2022 The Authors. IET Smart Cities published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology.","10.1049/smc2.12041","Review","2022","Deep neural networks; Electronic data interchange; Energy harvesting; Internet of things; Network architecture; Smart city; Battery powered; Information and Communication Technologies; IoT and mobile communication; Mobile communications; Network and telematic; Real-time data; Service-based; Technology infrastructure; Telematics; Urban areas; Telematics","Scopus"
"Biomedical data analysis and processing using explainable artificial intelligence and responsive artificial intelligence","Medicine and biomedical sciences ensure developed data-intensive arenas, at the same time, allowing the application of data-driven methods and necessitating refined data processing and data analysis methods. Biomedical informatics affords an appropriate interdisciplinary circumstance to assimilate information and data when dispensation accessible information, with the intention of generous operative decision-making maintenance in translational and clinic research. Potential applications in the biomedical field comprise the instinctive identification of entrant biomarkers on behalf of a disease or analytic of a treatment reaction, and the edifice of prognostic or diagnostic rules manipulating these biomarkers. These procedures being generic, they could be pragmatic to numerous causes of data and biomedical/biological requests. Nowadays, in medical applications, the growth of procedures for explaining, visualizing, and interpreting deep learning replicas has freshly appealed to cumulative attention. Interpretable Machine Learning (IML) or Explainable Machine Learning (XAI) programs are intended to generate a complement of machine learning procedures that yield additional explainable models while upholding a high level of accurateness. It moreover empowers users to comprehend, applicably trust, and effectively achieve the evolving cohort of artificially intelligent associates. The XAI befits more and more decisive for deep learning-powered applications, exclusively for healthcare and medical studies. A pace elsewhere XAI is Responsive AI (RAI), which symbolizes a set of moralities to have happened when arranging AI-based classifications in practical circumstances: Fairmindedness, Human-Centric, Explainability Accountability, Privacy Awareness, Security and Safety. Owed to the flora of amenities and the liability of an enormous segment of patrons, the theme of accountable AI is necessary to convert the focus of prevalent learning and conversation. The main idea underlying the concept of Biomedical Data Analysis and Processing is extracting knowledge from the very large amount of medical data which is available in the form of signals and images, with a very large amount of variables. © 2022 Nova Science Publishers, Inc.","","Book chapter","2022","","Scopus"
"Towards an AI-centric Requirements Engineering Framework for Trustworthy AI","Ethical guidelines are an asset for artificial intel-ligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level. © 2023 IEEE.","10.1109/ICSE-Companion58688.2023.00075","Conference paper","2023","Cognitive systems; Engineering research; Ethical technology; Artificial intel-ligence co-worker; Engineering frameworks; Ethical artificial intel-ligence; EU artificial intel-ligence act; Framework; Guideline; Requirement engineering; Requirement engineering process; Trustworthy artificial intel-ligence; Workers'; Requirements engineering","Scopus"
"Machine Learning and Deep Learning Methods for Enhancing Building Energy Efficiency and Indoor Environmental Quality – A Review","The built environment sector is responsible for almost one-third of the world's final energy consumption. Hence, seeking plausible solutions to minimise building energy demands and mitigate adverse environmental impacts is necessary. Artificial intelligence (AI) techniques such as machine and deep learning have been increasingly and successfully applied to develop solutions for the built environment. This review provided a critical summary of the existing literature on the machine and deep learning methods for the built environment over the past decade, with special reference to holistic approaches. Different AI-based techniques employed to resolve interconnected problems related to heating, ventilation and air conditioning (HVAC) systems and enhance building performances were reviewed, including energy forecasting and management, indoor air quality and occupancy comfort/satisfaction prediction, occupancy detection and recognition, and fault detection and diagnosis. The present study explored existing AI-based techniques focusing on the framework, methodology, and performance. The literature highlighted that selecting the most suitable machine learning and deep learning model for solving a problem could be challenging. The recent explosive growth experienced by the research area has led to hundreds of machine learning algorithms being applied to building performance-related studies. The literature showed that existing research studies considered a wide range of scope/scales (from an HVAC component to urban areas) and time scales (minute to year). This makes it difficult to find an optimal algorithm for a specific task or case. The studies also employed a wide range of evaluation metrics, adding to the challenge. Further developments and more specific guidelines are required for the built environment field to encourage best practices in evaluating and selecting models. The literature also showed that while machine and deep learning had been successfully applied in building energy efficiency research, most of the studies are still at the experimental or testing stage, and there are limited studies which implemented machine and deep learning strategies in actual buildings and conducted the post-occupancy evaluation. © 2022","10.1016/j.egyai.2022.100198","Review","2022","Air quality; Buildings; Deep learning; Energy utilization; Fault detection; HVAC; Indoor air pollution; Learning algorithms; Learning systems; Building energy managements; Built environment; Deep learning; Heating ventilation and air conditioning; Heating, ventilation and air conditioning; Indoor environmental quality; Learning methods; Machine-learning; Occupancy detections; Energy efficiency","Scopus"
"Rethinking Interaction with Conversational Agents: How to Create a Positive User Experience Utilizing Dialog Patterns","Conversational agents (CAs) are increasingly used as an additional convenient and innovative customer service channel to relieve service employees, as in the studied organization. In the process of analyzing and maintaining the present AI-based agent, however, user satisfaction is low as the CA lacks understanding and offers unsatisfactory solutions to users. Nonetheless, solving the requests and providing a positive user experience is crucial to relieve the service employees’ workload permanently. For CAs’ improvement, this study followed action design research (ADR) and used design thinking. We identified the central interaction problems (findability, welcome message, dialog control and fallback issues) with a monitoring process and analysis. Afterward, we interviewed users about their expectations and requirements and addressed these problems by creating user-centric mock-ups. Through a quantitative survey, the most popular solutions were implemented in a prototype. Finally, the resulting CA prototype was evaluated, showing a significantly improved user experience afterward, and design guidelines were discovered. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-35708-4_22","Conference paper","2023","Artificial intelligence; Chatbot user experience (UX); Chatbots; Conversational agents; Customer-service; Fallback strategies; Interaction design; Service channels; Service employees; Users' experiences; Personnel","Scopus"
"The Utilization of Artificial Intelligence for Developing Autonomous Social Robots within Health Information Systems","This study focuses on using AI systems, specifically conversational agents (CAs), to improve information flow during peak hours in healthcare emergency departments (EDs). We customized a Cross Industry Standard Process for Data Mining CRISP-DM approach to a CRISP-Knowledge graph (CRISP-KG) for overall design research. We use a knowledge graph approach to create an intelligent knowledge base (KBs) for CAs, which can enhance their reasoning, knowledge management, and context awareness abilities. We employ a collaborative methodology and ontology design patterns to develop a formal ontological model. Our goal is to build intelligent KBs for CAs that can interact with end-users and improve care quality in EDs, using Semantic Web Rule Language (SWRL) for inference. The KG approach can assist healthcare practitioners and patients in managing information flow more efficiently in EDs, ultimately improving care outcomes. © 2023 CEUR-WS. All rights reserved.","","Conference paper","2023","Data mining; Health care; Intelligent robots; Knowledge graph; Ontology; Conversational agent; Conversational agents; CRISP-knowledge graph; Emergency departments; Information flows; Knowledge graphs; Knowledge management; Rules languages; Semantic web rule language; Semantic Web rules; Knowledge management","Scopus"
"Age-Related Macular Degeneration Biomarker Segmentation from OCT images","The image classification task is considered solved from the technical perspective: given enough data - in terms of quantity, quality and distribution - machine learning technology is able to classify various medical conditions with high performance metrics. Yet, one disadvantage is that the large majority of approaches directly target to signal the disease without considering at all the running protocols or medical guidelines used by clinicians. We address here the gap between running clinical protocols and solutions provided by computer scientists. Instead of directly target the disease, we aim the identify only the biomarkers that the physicians are looking for. We apply this approach to the age-related macular degeneration (AMD). The task is to identify biomarkers for the AMD condition by segmenting retinal optical coherence tomography (OCT) images. One relevant question regards the choice between feature based techniques versus deep learning methods. We address this question by providing a hybrid original solution that combines deep learning based retinal layer segmentation with feature based image classification used to distinguish between a particular fluid area and its neighbouring retinal areas. In this context we perform a comparative analysis of various semantic segmentation techniques which provide noticeable results for retinal layer segmentation. On the other hand, due to the low representation of some fluids in the considered benchmark dataset, we address and enhance their recognition by texture based region of interest classification. The proposed approach is a step towards developing AI systems in line with running medical protocols. © 2023 IEEE.","10.1109/CSCS59211.2023.00076","Conference paper","2023","Biomarkers; Classification (of information); Deep learning; Learning systems; Medical imaging; Ophthalmology; Optical tomography; Semantic Segmentation; Semantics; Textures; Age-related macular degeneration; Classification tasks; Deep learning; Feature-based; Feature-based image classification; Images classification; Layer segmentation; Medical image segmentation; Optical coherence tomography image; Retinal layers; Image classification","Scopus"
"Artificial Intelligence, Machine Learning, and Deep Learning in Structural Engineering: A Scientometrics Review of Trends and Best Practices","Artificial Intelligence (AI), machine learning (ML), and deep learning (DL) are emerging techniques capable of delivering elegant and affordable solutions which can surpass those obtained through traditional methods. Despite the recent and rapid advancements in developing next-gen AI-based techniques, we continue to lack a systemic understanding of how AI, ML, and DL can fundamentally be integrated into the structural engineering domain. To advocate for a smooth and expedite the adoption of AI techniques into our field, we present a state-of-the-art review that is specifically tailored to structural engineers. This review aims to serve three purposes: (1) introduce the art and science of AI, ML, and DL in terms of its commonly used algorithms and techniques with particular attention to those of high value to this domain, (2) map the current knowledge within this domain through a scientometrics analysis of more than 4000 scholarly works with a focus on those published in the last decade to identify best practices in terms of procedures, performance metrics, and dataset size etc., and (3) review past and recent efforts that applied AI derivatives into the various subfields within structural engineering. Special attention is given to the application of AI, ML, and DL in earthquake, wind, and fire engineering, as well as structural health monitoring, damage detection, and prediction of properties of structural materials as collected from over 200 sources. Finally, a discussion on trends, recommendations, best practices, and advanced topics towards the end of this review. © 2022, The Author(s) under exclusive licence to International Center for Numerical Methods in Engineering (CIMNE).","10.1007/s11831-022-09793-w","Review","2023","Damage detection; Deep learning; Learning systems; Structures (built objects); 'current; Art and science; Artificial intelligence techniques; Best practices; Engineering domains; Machine-learning; Scientometric analysis; Scientometrics; State-of-the art reviews; Structural engineer; Structural health monitoring","Scopus"
"Building Safe and Reliable AI Systems for Safety Critical Tasks with Vision-Language Processing","Although AI systems have been applied in various fields and achieved impressive performance, their safety and reliability are still a big concern. This is especially important for safety-critical tasks. One shared characteristic of these critical tasks is their risk sensitivity, where small mistakes can cause big consequences and even endanger life. There are several factors that could be guidelines for the successful deployment of AI systems in sensitive tasks: (i) failure detection and out-of-distribution (OOD) detection; (ii) overfitting identification; (iii) uncertainty quantification for predictions; (iv) robustness to data perturbations. These factors are also challenges of current AI systems, which are major blocks for building safe and reliable AI. Specifically, the current AI algorithms are unable to identify common causes for failure detection. Furthermore, additional techniques are required to quantify the quality of predictions. All these contribute to inaccurate uncertainty quantification, which lowers trust in predictions. Hence obtaining accurate model uncertainty quantification and its further improvement are challenging. To address these issues, many techniques have been proposed, such as regularization methods and learning strategies. As vision and language are the most typical data type and have many open source benchmark datasets, this thesis will focus on vision-language data processing for tasks like classification, image captioning, and vision question answering. In this thesis, we aim to build a safeguard by further developing current techniques to ensure the accurate model uncertainty for safety-critical tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-28241-6_47","Conference paper","2023","Classification (of information); Data handling; Deep learning; Learning systems; Safety engineering; Uncertainty analysis; 'current; Accurate modeling; AI systems; Critical tasks; Deep learning; Failure detection; Model calibration; Modeling uncertainties; Uncertainty; Uncertainty quantifications; Forecasting","Scopus"
"Enhancing Artificial Intelligence Control Mechanisms: Current Practices, Real Life Applications and Future Views","The popularity of Artificial Intelligence has grown lately with the potential it promises for revolutionizing a wide range of different sectors. To achieve the change, whole community must overcome the Machine Learning (ML) related explainability barrier, an inherent obstacle of current sub symbolism-based approaches, e.g. in Deep Neural Networks, which was not existing during the last AI hype time including some expert and rule-based systems. Due to lack of transparency, privacy, biased systems, lack of governance and accountability, our society demands toolsets to create responsible AI solutions for enabling of unbiased AI systems. These solutions will help business owners to create AI applications which are trust enhancing, open and transparent and also explainable. Properly made systems will enhance trust among employees, business leaders, customers and other stakeholders. The process of overseeing artificial intelligence usage and its influence on related stakeholders belongs to the context of AI Governance. Our work gives a detailed overview of a governance model for Responsible AI, emphasizing fairness, model explainability, and responsibility in large-scale AI technology deployment in real-world organizations. Our goal is to provide the model developers in an organization to understand the Responsible AI with a comprehensive governance framework that outlines the details of the different roles and the key responsibilities. The results work as reference for future research is aimed to encourage area experts from other disciplines towards embracement of AI in their own business sectors, without interpretability shortcoming biases. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-18461-1_19","Conference paper","2023","","Scopus"
"Face Mask Detection: An Application of Artificial Intelligence","COVID-19 has been announced as a new pandemic which has affected almost all the countries of the world. Millions of people have become sick and thousands have died due to the respiratory illness caused by the virus. The virus is known to spread when small droplets from nose or mouth of an infected person gets dissolved in air when he or she coughs or exhales or when a person touches a surface infected with virus. The governments all over the world are working on ways to curb the spread of this virus. Multidisciplinary researchers are working to find the best solutions in their own way. Out of the many solutions wearing surgical facemasks is being one of the best preventive measures to limit the spread of corona virus. These masks support filtration of air and adequate breathability. But the problem is that few people don’t use the masks regularly or occasionally due to various reasons like negligence and discomfort etc. This is one of the main causes of high spread of COVID. So, there is a strong need to detect people without mask at public places and to aware them. There are so many initiatives taken by government in this direction, but all have their limitation in one or the other way. So, there is a strong need of a digital solution to ensure that people comply with the government rules of wearing masks in public place sand to recognize unmasked faces on existing monitoring systems to maintain safety and security. Facial recognition systems were being used to identify faces using technology that includes hardware like video cameras. These systems work by combining AI based pattern recognition system along with biometrics to map facial features from an image and compare it with a database of known faces. This research content is also an initiative in this direction to optimize the results. © 2023, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","10.1007/978-3-031-35081-8_16","Conference paper","2023","Deep learning; Face recognition; Video cameras; Viruses; Breathability; Deep learning; Detection methods; Digital solutions; Face masks; Images processing; Preventive measures; Public places; Respiratory illness; Small droplets; COVID-19","Scopus"
"Safe.trAIn - Engineering and Assurance of a Driverless Regional Train","Traditional automation technologies alone are not sufficient to enable the fully automated operation of trains. However, Artificial Intelligence (AI) and Machine Learning (ML) offers great potential to realize the mandatory novel functions to replace the tasks of a human train driver, such as obstacle detection on the tracks. The problem, which still remains unresolved, is to find a practical way to link AI/ML techniques with the requirements and approval processes that are applied in the railway domain. The safe.trAIn project aims to lay the foundation for the safe use of AI/ML to achieve the driverless operation of rail vehicles and thus addresses this key technological challenge hindering the adoption of unmanned rail transport. The project goals are to develop guidelines and methods for the reliable engineering and safety assurance of ML in the railway domain. Therefore, the project investigates methods to reliable design ML models and to prove the trustworthiness of AI-based functions taking robustness, uncertainty, and transparency aspects of the AI/ML model into account. © 2023 IEEE.","10.1109/CAIN58948.2023.00036","Conference paper","2023","Autonomous vehicles; Driver training; Obstacle detectors; Railroad transportation; Railroads; Safety engineering; Artificial intelligence/machine learning engineering process; Automation technology; Autonomous driving; Driverless; Driverless regional train; Engineering process; Machine learning models; Machine-learning; Regional train; Safety approval; Rails","Scopus"
"Loose Ends: A Mixed-Initiative Creative Interface for Playful Storytelling","We present Loose Ends, a mixed-initiative co-creative storytelling play experience in which a human player and an AI system work together to compose a story. Loose Ends specifically aims to provide computational support for managing multiple parallel plot threads and bringing these threads to satisfying conclusions—something that has proven difficult in past attempts to facilitate playful mixed-initiative storytelling. We describe the overall human-AI interaction loop in Loose Ends, including the implementation of the rules-based AI system that enables this interaction loop; discuss four examples of desirable mixed-initiative interactions that are possible in Loose Ends, but not in similar systems; and present results from a preliminary expert evaluation of Loose Ends. Altogether, we find that Loose Ends shows promise for creating a sense of coauthorship in the player while also mitigating the directionlessness reported by players of earlier systems. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","10.1609/aiide.v18i1.21955","Conference paper","2022","AI systems; Co-authorships; Creatives; Expert evaluation; Human players; Mixed-initiative; Mixed-initiative interactions; Rule based; Artificial intelligence","Scopus"
"Determinants for scalable adoption of autonomous AI in the detection of diabetic eye disease in diverse practice types: key best practices learned through collection of real-world data","Autonomous Artificial Intelligence (AI) has the potential to reduce disparities, improve quality of care, and reduce cost by improving access to specialty diagnoses at the point-of-care. Diabetes and related complications represent a significant source of health disparities. Vision loss is a complication of diabetes, and there is extensive evidence supporting annual eye exams for prevention. Prior to the use of autonomous AI, store-and-forward imaging approaches using remote reading centers (asynchronous telemedicine) attempted to increase diabetes related eye exams with limited success. In 2018, after rigorous clinical validation, the first fully autonomous AI system [LumineticsCore™ (formerly IDx-DR), Digital Diagnostics Inc., Coralville, IA, United States] received U.S. Food and Drug Administration (FDA) De Novo authorization. The system diagnoses diabetic retinopathy (including macular edema) without specialist physician overread at the point-of-care. In addition to regulatory clearance, reimbursement, and quality measure updates, successful adoption requires local optimization of the clinical workflow. The general challenges of frontline care clinical workflow have been well documented in the literature. Because healthcare AI is so new, there remains a gap in the literature about challenges and opportunities to embed diagnostic AI into the clinical workflow. The goal of this review is to identify common workflow themes leading to successful adoption, measured as attainment number of exams per month using the autonomous AI system against targets set for each health center. We characterized the workflow in four different US health centers over a 12-month period. Health centers were geographically dispersed across the Midwest, Southwest, Northeast, and West Coast and varied distinctly in terms of size, staffing, resources, financing and demographics of patient populations. After 1 year, the aggregated number of diabetes-related exams per month increased from 89 after the first month of initial deployment to 174 across all sites. Across the diverse practice types, three primary determinants underscored sustainable adoption: (1) Inclusion of Executive and Clinical Champions; (2) Underlining Health Center Resources; and (3) Clinical workflows that contemplate patient identification (pre-visit), LumineticsCore Exam Capture and Provider Consult (patient visit), and Timely Referral Triage (post-visit). In addition to regulatory clearance, reimbursement and quality measures, our review shows that addressing the core determinants for workflow optimization is an essential part of large-scale adoption of innovation. These best practices can be generalizable to other autonomous AI systems in front-line care settings, thereby increasing patient access, improving quality of care, and addressing health disparities. 2023 Goldstein, Weitzman, Lemerond and Jones.","10.3389/fdgth.2023.1004130","Review","2023","artificial intelligence; autonomous artificial intelligence; clinical practice; consultation; demography; diabetes mellitus; diabetic eye disease; diabetic retinopathy; eye examination; Food and Drug Administration; geography; health care; health care access; health care quality; health care system; health disparity; human; information processing; macular edema; medical specialist; patient; patient referral; patient triage; quality control; reimbursement; Review; United States; workflow","Scopus"
"Best-of-Breed: Service-Oriented Integration of Artificial Intelligence in Interoperable Educational Ecosystems","Artificial Intelligence (AI) offers great potential for optimizing learning processes, teaching methods, learning content, or organizational procedures. However, the success of AI components in educational environments is by no means guaranteed and depends on several conditions in their respective learning settings. In this article, we analyze requirements that are often addressed prior to introducing AI features. We address organizational, methodological, didactical, content-related, and technical challenges. The research question of this work is how AI features can best be incorporated into modern educational system landscapes to create sustainable system architectures that are accepted and perceived as added value by users. Thereby, the article discusses two approaches to software architecture: Best-of-Suite (for monolithic architectures) and Best-of-Breed (for service-oriented architectures). Monolithic systems offer a wide range of functions, can be offered by a single provider but can become difficult to manage and create dependencies. Specialized and service-oriented systems, in turn, consist of modular functions handled by specialized services, are more flexible and scalable, and can be integrated with a wide range of tools and services, but require more effort to set up and manage. We explain why the Best-of-Breed strategy is a sensible approach to the use of AI components, how this can be implemented sustainably with the help of a middleware component, and we report on the user experiences from a field test. While in this work we evaluate the implemented system with a cybersecurity training as an on-the-job course, the middleware has been successfully used in other educational contexts, as well. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-34754-2_22","Conference paper","2023","Artificial intelligence; Computer architecture; Ecosystems; Information services; Learning systems; Middleware; Service oriented architecture (SOA); Teaching; Best practices; Best-of-breed; Didactic; Educational environment; Learning analytic; Learning contents; Learning process; Organisational; Service oriented integrations; Teaching methods; Interoperability","Scopus"
"Giving DIAnA More TIME – Guidance for the Design of XAI-Based Medical Decision Support Systems","Future healthcare ecosystems integrating human-centered artificial intelligence (AI) will be indispensable. AI-based healthcare technologies can support diagnosis processes and make healthcare more accessible globally. In this context, we conducted a design science research project intending to introduce design principles for user interfaces (UIs) of explainable AI-based (XAI) medical decision support systems (XAI-based MDSS). We used an archaeological approach to analyze the UI of an existing web-based system in the context of skin lesion classification called DIAnA (Dermatological Images – Analysis and Archiving). One of DIAnA’s unique characteristics is that it should be usable for the stakeholder groups of physicians and patients. We conducted the in-situ analysis with these stakeholders using the think-aloud method and semi-structured interviews. We anchored our interview guide in concepts of the Theory of Interactive Media Effects (TIME), which formulates UI features as causes and user psychology as effects. Based on the results, we derived 20 design requirements and developed nine design principles grounded in TIME for this class of XAI-based MDSS, either associated with the needs of physicians, patients, or both. Regarding evaluation, we first conducted semi-structured interviews with software developers to assess the reusability of our design principles. Afterward, we conducted a survey with user experience/interface designers. The evaluation uncovered that 77% of the participants would adopt the design principles, and 82% would recommend them to colleagues for a suitable project. The findings prove the reusability of the design principles and highlight a positive perception by potential implementers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-32808-4_7","Conference paper","2023","Decision support systems; Design; Diagnosis; Health care; Reusability; User interfaces; Dermatological images; Design Principles; Design-science researches; Explainable artificial intelligence; Healthcare; Image-analysis; Interactive media; Medical decision support system; Medium effect; Semi structured interviews; Artificial intelligence","Scopus"
"The European Parliament’s 2020 Resolution: Proposal for a Regulation on Ethical Principles for the Development, Deployment and Use of Artificial Intelligence, Robotics and Related Technologies","This chapter examines the European Parliaments’ 2020 Resolution on a framework of ethical principles and legal obligations for the development, deployment and use of artificial intelligence, robotics and related technologies. With this legislative initiative, the Parliament urged the Commission to present a new legal framework (the AI Regulation/Act) outlining the ethical principles and legal obligations to be followed when developing, deploying and using artificial intelligence, robotics and related technologies in the EU. In line with the White Paper on AI and the Ethics Guidelines for Trustworthy AI, the Parliament’s proposal for a Regulation on AI was premised on several guiding principles and obligations to be imposed in relation to “high-risk” sectors and high-risk uses and purposes that entail a risk of breach of fundamental rights and safety rules. Those guiding principles and obligations included a human-centric, human-made and human-controlled AI (guaranteeing full human oversight); an impartial, regulated and external ex-ante risk assessment based on concrete and pre-defined criteria; features to ensure safety, transparency and accountability; safeguards against bias and discrimination; the right to challenge the introduction or ongoing use of a AI system and to seek remedies for a violation of rights; social responsibility and environmental sustainability; respect for privacy and fundamental rights. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27953-9_6","Book chapter","2023","","Scopus"
"Artificial Intelligence in COVID-19 Management: A Systematic Review","With the development of modern technologies in the field of healthcare, the use of Artificial Intelligence (AI) in disease management is increasing. AI methods may assist healthcare providers in the COVID-19 era. The current study aimed to observe the efficacy and importance of AI for managing the COVID-19 pandemic. An organized search was conducted, utilizing PubMed, Web of Science, Scopus, Embase, and Cochrane up to September 2022. Studies were considered qualified for inclusion if they met the inclusion criterion. We conducted review according to the Preferred Reporting Items for Systematic reviews and Meta Analyses (PRISMA) guidelines. There were 52 documents that met the eligibility criteria to be included in the review. The most common item using AI during the COVID-19 era was predictive models to foretell pneumonia and mortality risks in people with COVID-19 based on medical and experimental parameters. COVID-19 mortality was related to being male and elderly based on the Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) logistic regression analysis of demographics, clinical data, and laboratory tests of hospitalized COVID-19 patients. AI can predict, diagnose and model COVID-19 by using techniques such as support vector machines, decision trees, and neural networks. It is suggested that future research should deal with the design and development of AI-based tools for the management of chronic diseases such as COVID-19. © 2023 Samaneh Mohammadi, SeyedAhmad SeyedAlinaghi, Mohammad Heydari, Zahra Pashaei, Pegah Mirzapour, Amirali Karimi, Amir Masoud Afsahi, Peyman Mirghaderi, Parsa Mohammadi, Ghazal Arjmand, Yasna Soleimani, Ayein Azarnoush, Hengameh Mojdeganlou, Mohsen Dashti, Hadiseh Azadi Cheshmekabodi, Sanaz Varshochi, Mohammad Mehrtak, Ahmadreza Shamsabadi, Esmaeil Mehraeen, and Daniel Hackett. This open-access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.","10.3844/jcssp.2023.554.568","Article","2023","","Scopus"
"The Use of Responsible Artificial Intelligence Techniques in the Context of Loan Approval Processes","Despite the existing skepticism about the use of automatic systems in contexts where human knowledge and experience are considered indispensable (e.g., the granting of a mortgage, the prediction of stock prices, or the detection of cancers), our work aims to show how the use of explainability and fairness techniques can lead to the growth of a domain expert’s trust and reliance on an artificial intelligence (AI) system. This article presents a system, applied to the context of loan approval processes, focusing on the two aforementioned ethical principles out of the four defined by the High-Level Expert Group on AI in the document “Ethics Guidelines for Trustworthy AI,” published in April 2019, in which the key requirements that AI systems should meet to be considered trustworthy are identified. The presented case study is realized within a proprietary framework composed of several components for supporting the user throughout the management of the whole life cycle of a machine learning model. The main approaches, consisting of providing an interpretation of the model’s outputs and monitoring the model’s decisions to detect and react to unfair behaviors, are described in more detail to compare our system within state-of-the-art related frameworks. Finally, a novel Trust & Reliance Scale is proposed for evaluating the system, and a usability test is performed to measure the user satisfaction with the effectiveness of the developed user interface; results are obtained, respectively, by the submission of the mentioned novel scale to bank domain experts and the usability questionnaire to a heterogeneous group composed of loan officers, data scientists, and researchers. © 2022 Taylor & Francis Group, LLC.","10.1080/10447318.2022.2081284","Article","2023","Artificial intelligence; Chemical detection; Ethical technology; Life cycle; Machine components; Artificial intelligence systems; Artificial intelligence techniques; Automatic systems; Case-studies; Domain experts; Ethical principles; Human knowledge; In contexts; Knowledge and experience; Stock price; User interfaces","Scopus"
"Rule-based NLP vs ChatGPT in Ambiguity Detection, a Preliminary Study","With the rapid advances of AI-based tools, the question of whether to use such tools or conventional rule-based tools often arises in many application domains. In this paper, we address this question when considering the issue of ambiguity in requirements documents. For this purpose, we consider GPT-3 that is the third-generation of the Generative Pretrained Transformer language model, developed by OpenAI and we compare its ambiguity detection capability with that of a publicly available rule-based NLP tool on a few example requirements documents. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2023","Ambiguity detection in requirement; Applications domains; Chatgpt; Detection capability; Language model; NLP tools; Requirements document; Rule based; Rule-based NLP tool; Third generation; Natural language processing systems","Scopus"
"Specification and Validation of Normative Rules for Autonomous Agents","A growing range of applications use autonomous agents such as AI and robotic systems to perform tasks deemed dangerous, tedious or costly for humans. To truly succeed with these tasks, the autonomous agents must perform them without violating the social, legal, ethical, empathetic, and cultural (SLEEC) norms of their users and operators. We introduce SLEECVAL, a tool for specification and validation of rules that reflect these SLEEC norms. Our tool supports the specification of SLEEC rules in a DSL [1] we co-defined with the help of ethicists, lawyers and stakeholders from health and social care, and uses the CSP refinement checker FDR4 to identify redundant and conflicting rules in a SLEEC specification. We illustrate the use of SLEECVAL for two case studies: an assistive dressing robot, and a firefighting drone. © 2023, The Author(s).","10.1007/978-3-031-30826-0_13","Conference paper","2023","Specifications; AI systems; Assistive; Case-studies; Cultural norms; Health and social care; Robotic systems; Tool support; Autonomous agents","Scopus"
"Ethics by Design for Intelligent and Sustainable Adaptive Systems","AI systems are increasingly dependent on the data and information sources they are developed with. In particular, learning machines are highly exposed to undesirable problems due to biased and incomplete coverage of training data. The autonomy exhibited by machines trained on low-quality data raises an ethical concern, as it may infringe on social rules and security constraints. In this paper, we extensively experiment with a learning framework, called Ethics by Design, which aims to ensure a supervised learning policy that can pursue both the satisfaction of ethical constraints and the optimization of task (i.e., business) accuracy. The results obtained on tasks and datasets confirm the positive impact of the method in ensuring ethical compliance. This paves the way for a large set of industrial applications, whose ethical dimension is critical to increasing the trustworthiness with respect to this technology. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27181-6_11","Conference paper","2023","Deep learning; Ethical technology; Learning systems; AI systems; Bias in deep learning; Data and information; Data-source; Empirical evaluation of ethical AI system; Empirical evaluations; Ethic by design in machine learning; Ethical issue of AI; Ethical issues; Machine-learning; Network security","Scopus"
"Towards Transparent Cheat Detection in Online Chess: An Application of Human and Computer Decision-Making Preferences","Online game providers face the challenge of preventing malicious users (cheaters) from breaking the rules and winning games through illegal means. This issue in particular plagues the online chess scene, where the strongest algorithms have long surpassed the world’s best players [4] – any cheater can beat the best human players through computer assistance. Moreover, recent developments in AI-based chess engines have opened the door to even more human-like engines [33], which are increasingly able to mimic legitimate human players. Unfortunately, because major chess websites do not discuss their cheat detection mechanisms publicly, there is limited scientific literature on how to tackle the pervasive problem of cheating in online chess. Certainly, there is no way to validate whether these mechanisms actually work. We take a first step towards formalizing a proper cheat detection framework for online chess by leveraging a large-scale statistical examination of human and computer decision-making tendencies over millions of chess games played online. Although cheaters are not engines (computer players) but centaurs (computer-assisted human players), the insights into computer play serve as a useful guideline for finding the strongest indicators of cheating. We then demonstrate how these findings may distinguish legitimate human players from cheaters in an automated, rules-based manner. Additionally, we argue that the status quo of hiding cheat detection mechanisms from the public eye is dangerous to the integrity of the game, and that cheat detection is foremost a service to society instead of a competitive advantage for chess websites to attract more users. Consistent with Kerckhoffs’ paradigm [24], we believe that the benefits of an open discussion on cheat detection far outweigh the potential drawbacks of cheaters learning about these methods. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-34017-8_14","Conference paper","2023","Competition; Computer games; Engines; Websites; Breakings; Cheat detection; Chess; Decisions makings; Detection framework; Detection mechanism; Human like; Human players; On-line games; Scientific literature; Decision making","Scopus"
"A Collision Avoidance Method for Autonomous Underwater Vehicles Based on Long Short-Term Memories","Over the past decades, underwater robotics has enjoyed growing popularity and relevance. While performing a mission, one crucial task for Autonomous Underwater Vehicles (AUVs) is bottom tracking, which should keep a constant distance from the seabed. Since static obstacles like walls, rocks, or shipwrecks can lie on the sea bottom, bottom tracking needs to be extended with obstacle avoidance. As AUVs face a wide range of uncertainties, implementing these essential operations is still challenging. A simple rule-based control method has been proposed in [7] to realize obstacle avoidance. In this work, we propose an alternative AI-based control method using a Long Short-Term Memory network. We compare the performance of both methods using real-world data as well as via a simulator. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-27499-2_42","Conference paper","2023","Autonomous vehicles; Brain; AI-based control; Autonomous underwater vehicles]; Collisions avoidance; Control methods; Obstacles avoidance; Rule-based control; Sea bottom; Static obstacles; Uncertainty; Underwater robotics; Autonomous underwater vehicles","Scopus"
"Application of Artificial Intelligence in the Food Industry: AI-Based Automatic Pruning of Dormant Apple Trees","Automatic pruning is one of the most essential as well as expensive and labor-intensive procedure in specialty crop production. During winter, expert pruners are employed to remove certain primary branches of dormant trees based on a set of predefined rules. The end goal of the automatic pruning applications is to reduce dependence on this huge labor and associated humongous costs by automating the pruning decisions, which in turn would facilitate easy interface with intelligent robotic pruners. In this chapter, we have developed a robust 3D reconstruction scheme that utilizes color information in addition to the time-of-flight depth data from Kinect2 sensor for accurately modeling the trunk and primary branches of a dormant apple tree. The motivation behind incorporating color in our framework is to acquire accurate 3D tree reconstruction even in absence of quality depth data. Quantitative and qualitative comparisons of our proposed approach with a depth based reconstruction technique depicts the usefulness of using color information in our automatic pruning system. On average, the proposed scheme provides a performance of 93.94% accuracy for correctly identifying the branches, and 71.13 and 89.26% for correctly estimating the diameters of the primary branches within error margins of 3 mm and 5 mm respectively. Moreover, the time complexity of our proposed algorithm shows an improvement in order of magnitude over the complexity of the baseline approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-13702-0_1","Book chapter","2023","","Scopus"
"Data-driven based four examinations in TCM: a survey","Traditional Chinese medicine (TCM) diagnosis is a unique disease diagnosis method with thousands of years of TCM theory and effective experience. Its thinking mode in the process is different from that of modern medicine, which includes the essence of TCM theory. From the perspective of clinical application, the four diagnostic methods of TCM, including inspection, auscultation and olfaction, inquiry, and palpation, have been widely accepted by TCM practitioners worldwide. With the rise of artificial intelligence (AI) over the past decades, AI based TCM diagnosis has also grown rapidly, marked by the emerging of a large number of data-driven deep learning models. In this paper, our aim is to simply but systematically review the development of the data-driven technologies applied to the four diagnostic approaches, i.e. the four examinations, in TCM, including data sets, digital signal acquisition devices, and learning based computational algorithms, to better analyze the development of AI-based TCM diagnosis, and provide references for new research and its applications in TCM settings in the future. © 2023 Digital Chinese Medicine","10.1016/j.dcmed.2022.12.004","Review","2022","artificial intelligence; auscultation; big data; cardiovascular disease; Chinese medicine; chronic kidney failure; clinical observation; data processing; data warehouse; deep learning; diabetes mellitus; diagnostic accuracy; differential diagnosis; feature extraction; feature selection; heart auscultation; human; image processing; image segmentation; impaired glucose tolerance; information technology; inspection; intermethod comparison; interview; ischemic heart disease; lung auscultation; lung cancer; machine learning; palpation; Parkinson disease; radial basis function neural network; Review; smelling; tongue; yin deficiency","Scopus"
"Deep ANFIS for Understanding Emotions in Movie Clips","Significant success of Deep learning (DL) in extracting features from big data which led to an explosion of Artificial Intelligence (AI) applications. However, most of those AI systems lack transparency and interpretability due to the black-box nature of DL architecture, which causes major trust-related problems in AI applications where validation is essential. This necessitates the need for interpretable AI systems that can explain their decisions. In this view, this paper proposes a deep adaptive neuro-fuzzy inference system (Deep ANFIS), that combines fuzzy inference with DL architecture to provide a more comprehensible explanation of the decision processes. Deep ANFIS uses ANFIS based convolution units in convolutional neural networks (CNNs) architecture that allows approximating the complex non-linear problems using fuzzy if-then rules. To verify the performance of the proposed Deep ANFIS and analyze the essential features for classification, we perform experiments with COGNIMUSE dataset for emotion recognition. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-22200-9_35","Conference paper","2023","","Scopus"
"The rise of AI in telehealth","Since its introduction in 1955, artificial intelligence (AI) has continued its growth and expansion across all industries and societal sectors. It took the COVID-19 pandemic for AI and its subsets to take the center stage in medicine and health care. AI is a broad discipline and encompasses machine learning (ML), deep learning (DL), and other techniques. Advancements in AI enabled, facilitated, and accelerated the expansion of telehealth. Telehealth describes the wide array of digital information and communication technologies and systems that allow the delivery of health and health-related services. There are three distinct subtypes of telehealth: synchronous, asynchronous, and remote (tele) monitoring. The overarching goal of telehealth is to break down barriers in delivery of high value care by overcoming challenges resulting from time or location constraints. The end goal is not to replace in-person care, rather to commoditize and democratize high quality, high value care. On the other hand, there remain significant limitations and pitfalls, particularly regulatory and technological. Examples include best practice guidelines on the adaptation of standards regulating data exchange, expansion of reimbursement and importantly ethical challenges. The latter include critical issues such as data privacy, security, and governance, AI-introduced bias, the black box nature of some AI/ML algorithms and the impact of AI technologies/algorithms on health disparities and inequities. Disparities in access to and use of tele-health were already known but highlighted during the COVID-19 pandemic. Recognition of this hurdle led to the emerging and rapidly growing field of digital determinants of health, which comprise factors like digital literacy, access to AI/technology, and community infrastructure like access to WiFi/broadband internet. © 2023 Elsevier Inc. All rights reserved.","10.1016/B978-0-443-15980-0.00011-9","Book chapter","2023","","Scopus"
"Smart Process Observer for Crane Automation","A method of automated, noncontact analysis is presented, which scans a process crane’s work area fully extrinsically with special 3D LiDAR sensors and analyzes its motion dynamics in real time. Rule- and AI-based algorithms that interpret high-quality point cloud scans have been developed, thus making it possible to evaluate a process crane’s specific handling operations reliably. Existing CAD models of the crane assemblies are automatically fitted into the point cloud for the central process of fused data analysis. The workflow starts with the localization of the loading beam’s cables to estimate its initial orientation and position. The CAD models of the lifting beam and all other lifting system components are successively fitted into the point cloud exactly with the aid of local registration. Swivel joint design constraints are factored into the assessment. The lifting operation is displayed in a VR model automatically receiving all component orientations and positions and the load every second. The crane operator can view the current situation from defined perspectives and additionally receives information on crane component position, spacing and the load, which is needed to control the crane. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-26655-3_16","Conference paper","2023","Automation; Computer aided design; Optical radar; Quality control; Assistance system; CAD models; Crane automation; Functional Safety; LiDAR; Motion dynamics; Noncontact analysis; Point-clouds; Rule based algorithms; Smart process; Cranes","Scopus"
"Artificial Intelligence and User Experience in reciprocity: Contributions and state of the art","Among the primary aims of Artificial Intelligence (AI) is the enhancement of User Experience (UX) by providing deep understanding, profound empathy, tailored assistance, useful recommendations, and natural communication with human interactants while they are achieving their goals through computer use. To this end, AI is used in varying techniques to automate sophisticated functions in UX and thereby changing what UX is apprehended by the users. This is achieved through the development of intelligent interactive systems such as virtual assistants, recommender systems, and intelligent tutoring systems. The changes are well received, as technological achievements but create new challenges of trust, explainability and usability to humans, which in turn need to be amended by further advancements of AI in reciprocity. AI can be utilised to enhance the UX of a system while the quality of the UX can influence the effectiveness of AI. The state of the art in AI for UX is constantly evolving, with a growing focus on designing transparent, explainable, and fair AI systems that prioritise user control and autonomy, protect user data privacy and security, and promote diversity and inclusivity in the design process. Staying up to date with the latest advancements and best practices in this field is crucial. This paper conducts a critical analysis of published academic works and research studies related to AI and UX, exploring their interrelationship and the cause-effect cycle between the two. Ultimately, best practices for achieving a successful interrelationship of AI in UX are identified and listed based on established methods or techniques that have been proven to be effective in previous research reviewed.  © 2023 - The authors. Published by IOS Press.","10.3233/IDT-230092","Article","2023","Artificial intelligence; Computer aided instruction; Data privacy; E-learning; Education computing; Learning systems; User interfaces; Virtual reality; E - learning; Help systems; Human-ai interaction; Human-centered artificial intelligence; Intelligent help; Intelligent help system; Intelligent tutoring; Intelligent tutoring system; Intelligent User Interfaces; Tutoring system; User Modelling; Users' experiences; Virtual assistants; Web searches; Recommender systems","Scopus"
"The Ethical Impact Assessment of Selling Life Insurance to Titanic Passengers","The Artificial Intelligence Act (AIA) is a uniform legal framework to ensure that AI systems within the European Union (EU) are safe and comply with existing law on fundamental rights and constitutional values. The AIA adopts a risk-based approach with the aim of intending to regulate AI systems, especially categorised as high-risk, which have significant harmful impacts on the health, safety and fundamental rights of persons in the Union. The AIA is founded on the Ethics Guidelines of the High-Level Expert Group for Trustworthy AI, which are grounded in fundamental rights and reflect four ethical imperatives in order to ensure ethical and robust AI. While we acknowledge that ethics is not law, we advocate that the analysis of ethical risks can assist us in complying with laws, thereby facilitating the implementation of the AIA requirements. Thus, we first design an AI-driven Decision Support System for individual risk prediction in the insurance domain (categorised as high-risk by the AIA) based on the Titanic case, which is a popular benchmark dataset in machine learning. We then fulfill an ethical impact assessment of the Titanic case study, relying on the four ethical imperatives of respect for human autonomy, prevention of harm, fairness, and explicability, declared by the High-Level Expert Group for Trustworthy AI. In the context of this ethical impact assessment, we also refer to the questions in the ALTAI checklist. Our discussions regarding the ethical impact assessment in the insurance domain demonstrate that ethical principles can intersect but also create tensions (intriguingly, only in this particular context), for which there is no definitive solution. When tensions arise, which may result in unavoidable trade-offs, these trade-offs should be addressed in a rational and methodical manner, paying special attention to the context of the current case study being evaluated. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2023","Commerce; Decision support systems; Economic and social effects; Ethical technology; Health risks; Insurance; Laws and legislation; Risk assessment; AI systems; Case-studies; European union; First designs; Health safety; Impact assessments; Legal frameworks; Life insurance; Risk-based approach; Trade off; Artificial intelligence","Scopus"
"Do Explainable AI techniques effectively explain their rationale? A case study from the domain expert's perspective","Artificial Intelligence (AI) systems are technologies impacting our lives. The systems learn from existing datasets that record past human decisions. Their performance is measured in terms of accuracy, precision, and recall for reproducing already-known results. Understanding the system's rationale is crucial to check for bias and accept such technology. Explainable AI (XAI) is the area devoted to opening the AI black box, and designing guidelines to build explainable AI systems. Nevertheless, it is important to understand the user's needs for these explanations. This paper presents an investigation of the usefulness of XAI systems in the field of cancer diagnosis from the domain expert's (oncologist) perspective. The main findings suggest domain experts (1) understood the outcomes of the XAI systems; (2) considered XAI outcomes as informative, rather than explanatory; (3) would like to go beyond the fixed presented perspective; and (4) missed the causal relation that would reveal the system's rationale.  © 2023 IEEE.","10.1109/CSCWD57460.2023.10152722","Conference paper","2023","Machine learning; Artificial intelligence systems; Artificial intelligence techniques; Case-studies; Domain experts; Explainable artificial intelligence; Health informatics; Human decisions; IS technologies; Learn+; Machine-learning; Medical informatics","Scopus"
"Setting the Grounds for the Transition from Business Analytics to Artificial Intelligence in Solving Supply Chain Risk","As supply chains (SCs) become more complex globally, businesses are looking for efficient business analytics (BA), business intelligence (BI), and artificial intelligence (AI) tools for managing supply-chain risk. The tools and methodologies proposed by the supply-chain risk management (SCRM) literature are mostly based on experts’ judgments, their knowledge, and past data. The expert evaluation-based approach could be partly or fully replaced by AI solutions, increasing objectivity, impartiality, and impersonality, reducing sources of human mistakes, biases, and inefficiencies in SCRM. However, the transition from BA to AI in SCRM is not a self-contained process; though attractive as a vision, it is not straightforward as a management or implementation process. The purpose of this research is to explore and define the conceptual grounds for transitioning from BA to AI in SCRM. The conceptual SCRM structure, its AI suitability, and implementation terms are defined theoretically based on a literature review. A single, in-depth business case study is employed to explore the theoretically defined terms of AI-based SCRM implementation. The proposed conceptual AI-suitable SCRM structure is defined by five principal building blocks: risk events, risk-event indicators, data-processing rules and algorithms, analytical techniques, and risk event probability forecasts. The study concludes that the business environment meets AI-based SCRM-implementation terms of data existence and access. Since data on risk events and negative outcomes are limited for machine learning, experts’ experience and knowledge might be utilised to build initial rules and data-processing algorithms for AI. © 2022 by the authors.","10.3390/su141911827","Article","2022","artificial intelligence; supply chain management","Scopus"
"Designing User-Centric Explanations for Medical Imaging with Informed Machine Learning","A flawed algorithm released in clinical practice can cause unintended harm to patient health. Risks, regulation, responsibility, and ethics shape the demand of clinical users to understand and rely on the outputs made by artificial intelligence. Explainable artificial intelligence (XAI) offers methods to render a model’s behavior understandable from different perspectives. Extant XAI, however, is mainly data-driven and designed to meet developers’ demands to correct models rather than clinical users’ expectations to reflect clinically relevant information. To this end, informed machine learning (IML) utilizes prior knowledge jointly with data to generate predictions, a promising paradigm to enrich XAI with medical knowledge. To explore how IML can be used to generate explanations that are congruent to clinical users’ demands and useful to medical decision-making, we conduct Action Design Research (ADR) in collaboration with a team of radiologists. We propose an IML-based XAI system for clinically relevant explanations of diagnostic imaging predictions. With the help of ADR, we reduce the gap between implementation and user evaluation and demonstrate the effectiveness of the system in a real-world application with clinicians. While we develop design principles of using IML for user-centric XAI in diagnostic imaging, the study demonstrates that an IML-based design adequately reflects clinicians’ conceptions. In this way, IML inspires greater understandability and trustworthiness of AI-enabled diagnostic imaging. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-32808-4_29","Conference paper","2023","Clinical research; Decision making; Diagnosis; Medical imaging; Action design research; Clinical users; Design research; Diagnostic imaging; Explainable artificial intelligence; Informed machine learning; Machine-learning; Medical image analysis; User-centric; User-centric designs; Machine learning","Scopus"
"Industrielle herausforderungen für KI systems engineering Entwicklungen hin zu autonomen Systemen in der Industrie; [Industrial challenges for AI systems engineering Towards autonomous industrial systems]","Integration of Artificial Intelligence (AI) methods into industrial systems engineering processes is challenging. Despite an increasing body of knowledge on AI techniques and impressive state-of-the-art reports, the application of AI in industrial contexts is only at an early stage. This paper summarizes challenges for AI Systems Engineering. Two examples of AI systems engineering are provided: the TRUMPF Sorting Guide and ABB BatchInsight. Summaries of the projects give insights into the project executions and related challenges. The learnings from these projects also show that increased maturity of AI systems engineering can be expected from increased method competence and adjusted project setups. Here guidelines and best practices for AI systems engineering can support.  © 2022 Walter de Gruyter GmbH, Berlin/Boston.","10.1515/auto-2022-0015","Article","2022","","Scopus"
"Recommendation for Continuous Ethical Analysis of AI Algorithms","Artificial Intelligence (AI) algorithms and applications have become more prevalent in our information society. Organizations that build AI applications incorporate various ethical evaluation frameworks, policies, and guidelines-and yet the outcome of many AI systems are producing questionable, biased, unfair, opaque, unjustified, and/or unexplained results. In this research project we determine the necessity for not just an initial ethical review of such algorithms, but suggest the ongoing ethical evaluation of AI algorithms as applications are updated and enhanced-a Continuous Ethical Analysis process.  © 2022 Owner/Author.","10.1145/3528580.3532996","Conference paper","2022","Analysis process; Artificial intelligence algorithms; Artificial intelligence systems; Continuous ethical analyse; Evaluation framework; Evaluation guidelines; Evaluation policy; Information society; Ethical technology","Scopus"
"When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment","AI systems are becoming increasingly intertwined with human life. In order to effectively collaborate with humans and ensure safety, AI systems need to be able to understand, interpret and predict human moral judgments and decisions. Human moral judgments are often guided by rules, but not always. A central challenge for AI safety is capturing the flexibility of the human moral mind - the ability to determine when a rule should be broken, especially in novel or unusual situations. In this paper, we present a novel challenge set consisting of moral exception question answering (MoralExceptQA) of cases that involve potentially permissible moral exceptions - inspired by recent moral psychology studies. Using a state-of-the-art large language model (LLM) as a basis, we propose a novel moral chain of thought (MORALCOT) prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments. MORALCOT outperforms seven existing LLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to capture the flexibility of the human moral mind. We also conduct a detailed error analysis to suggest directions for future work to improve AI safety using MoralExceptQA. © 2022 Neural information processing systems foundation. All rights reserved.","","Conference paper","2022","AI systems; Cognitive science; Human lives; Human reasoning; Language model; Moral judgment; Moral reasoning; Question Answering; State of the art; Computational linguistics","Scopus"
"SmartValidator: A framework for automatic identification and classification of cyber threat data","A wide variety of Cyber Threat Information (CTI) is used by Security Operation Centres (SOCs) to perform validation of security incidents and alerts. Security experts manually define different types of rules and scripts based on CTI to perform validation tasks. These rules and scripts need to be updated continuously due to evolving threats, changing SOCs’ requirements and dynamic nature of CTI. The manual process of updating rules and scripts delays the response to attacks. To reduce the burden of human experts and accelerate response, we propose a novel Artificial Intelligence (AI) based framework, SmartValidator. SmartValidator leverages Machine Learning (ML) techniques to enable automated validation of alerts. It consists of three layers to perform the tasks of data collection, model building and alert validation. It projects the validation task as a classification problem. Instead of building and saving models for all possible requirements, we propose to automatically construct the validation models based on SOC's requirements and CTI. We built a Proof of Concept (PoC) system with eight ML algorithms, two feature engineering techniques and 18 requirements to investigate the effectiveness and efficiency of SmartValidator. The evaluation results showed that when prediction models were built automatically for classifying cyber threat data, the F1-score of 75% of the models were above 0.8, which indicates adequate performance of the PoC for use in a real-world organization. The results further showed that dynamic construction of prediction models required 99% less models to be built than pre-building models for all possible requirements. Thus, SmartValidator is much more efficient to use when SOCs’ requirements and threat behaviour are constantly evolving. The framework can be followed by various industries to accelerate and automate the validation of alerts and incidents based on their CTI and SOC's preferences. © 2022 Elsevier Ltd","10.1016/j.jnca.2022.103370","Article","2022","Automation; Classification (of information); Learning algorithms; Machine learning; Natural language processing systems; Alert validator; Cybe threat information; Cyber security; Cyber threats; Machine-learning; Proof of concept; Security automation; Security operation center; Threat data; Threat intelligence; Cybersecurity","Scopus"
"How Can I Help You? A chatbot’s answers to citizens’ information needs","AI-based chatbots are becoming an increasingly common part of the front-line of public services. Through natural language, users can write simple queries to a chatbot which answers with appropriate information. We have investigated how a public chatbot operates in actual practice and how it answers the citizens’ questions about the rules and regulations for welfare benefits. We use the concept of citizens’ information needs to determine the quality of the chatbot’s answers. Information needs are often not formulated from the start as answerable questions. We analyse logs from chat sessions between the chatbot and the citizens, and focus on problems that arise, e.g., that the chatbot gives irrelevant answers or omits important information. The paper shows how the inner workings of the chatbot shapes the answerable questions. We conclude that responsible use of AI (such as chatbots) is a matter of design of the overall service and includes acknowledging that the AI itself can never be responsible. © Scandinavian Journal of Information Systems.","","Article","2022","","Scopus"
"How AI can Help us Understand and Mitigate Error Propagation in Radiation Oncology","The treatment workflow in Radiation Oncology involves a long chain of clinical and technical steps involving numerous subsystems, multiple vendors, and a variety of medical professionals. This complex workflow must be further customized for individual patients whose tumor size and locations can change during treatment. Therefore, medical errors can occur, and, crucially, such errors can propagate to future steps unless detected and addressed immediately. Understanding this error propagation is key to proactive error management. This chapter aims to discuss these issues and to provide guidelines toward an artificial intelligence (AI)-based analytical framework to analyze structured and unstructured incident reports. Such an analytical framework can be used to model error propagation and proactively identify points of weakness in Radiation Oncology pathways. Incorporating statistical learning and AI tools in this model may preemptively identify errors or trends in errors and suggest actions to prevent their recurrence. © 2023 by World Scientific Publishing Co. Pte. Ltd.","10.1142/9789811263545_0014","Book chapter","2022","","Scopus"
"Supply chain risk identification: a real-time data-mining approach","Purpose: The global pandemic COVID-19 unveils transforming the supply chain (SC) to be more resilient against unprecedented events. Identifying and assessing these risk factors is the most significant phase in supply chain risk management (SCRM). The earlier risk quantification methods make timely decision-making more complex due to their inability to provide early warning. The paper aims to propose a model for analyzing the social media data to understand the potential SC risk factors in real-time. Design/methodology/approach: In this paper, the potential of text-mining, one of the most popular Artificial Intelligence (AI)-based data analytics approaches for extracting information from social media is exploited. The model retrieves the information using Twitter streaming API from online SC forums. Findings: The potential risk factors that disrupt SC performance are obtained from the recent data by text-mining analyses. The outcomes carry valuable insights about some contemporary SC issues due to the pandemic during the year 2021. The most frequent risk factors using rule mining techniques are also analyzed. Originality/value: This study presents the significant role of Twitter in real-time risk identification from online SC platforms like “Supply Chain Dive”, “Supply Chain Brain” and “Supply Chain Digest”. The results indicate the significant role of data analytics in achieving accurate decision-making. Future research will extend to represent a digital twin for identifying potential risks through social media analytics, assessing risk propagation and obtaining mitigation strategies. © 2022, Emerald Publishing Limited.","10.1108/IMDS-11-2021-0719","Article","2022","Data Analytics; Data mining; Decision making; Risk assessment; Risk management; Social networking (online); Supply chains; Data analytics; Decisions makings; Online supplies; Real- time; Risk factors; Risk Identification; Sentiment analysis; Social media; Supply chain risk identification; Supply-chain risks; Sentiment analysis","Scopus"
"Explainable AI for Constraint-Based Expert Systems","The need to derive explanations from machine learning (ML)-based AI systems has been addressed in recent research due to the opaqueness of their processing. However, a significant amount of productive AI systems are not based on ML but are expert systems including strong opaqueness. A resulting lack of understanding causes massive inefficiencies in business processes that involve opaque expert systems. This work uses recent research interest in explainable AI (XAI) to generate knowledge for the design of explanations in constraint-based expert systems. Following the Design Science Research paradigm, we develop design requirements and design principles. Subsequently, we design an artifact and evaluate the artifact in two experiments. We observe the following phenomena. First, global explanations in a textual format were well-received. Second, abstract local explanations improved comprehensibility. Third, contrastive explanations successfully assisted in the resolution of contradictions. Finally, a local tree-based explanation was perceived as challenging to understand. © 2022 17th International Conference on Wirtschaftsinformatik, WI 2022. All rights reserved.","","Conference paper","2022","AI systems; Business Process; Configuration; Constraint; Constraint-based; Explainable artificial intelligence; Machine-learning; On-machines; Recent researches; Research interests; Expert systems","Scopus"
"Perspectives of Using Artificial Intelligence in Building Fire Safety","Over the past decade, big data and artificial intelligence (AI) enable new smart techniques in the building and construction area. The applications of AI in fire detection, risk assessment, and fire forecast are emerging. This chapter provides a roadmap for AI-based building fire safety engineering application by comparing it with the history of CFD fire modelling. Guidelines for constructing a reliable fire database with both experimental and numerical data are introduced. The AI algorithms having a great potential to detect and forecast fire scenarios are discussed, and the latest research on exploring and developing intelligent firefighting systems are reviewed. Finally, three new concepts of applying AI in building fire safety are proposed, (1) the AI-based fire engineering design to improve the structure fire safety, (2) the building fire Digital Twin to monitoring the fire risk and development in real time, and (3) the Super Real-time Forecast (SuRF) of the fire evolution. © Springer Nature Switzerland AG 2022.","10.1007/978-3-030-98685-8_6","Book chapter","2022","","Scopus"
"Towards Understanding and Improving Handwriting with AI","What makes a handwriting good? If the aesthetic judgment of handwriting follows implicit rules, can those rules be recovered by observing good and bad examples? To answer these questions, we apply explainability techniques to the classification of good and bad handwriting. We show that it is indeed possible to recover these inherent rules. We develop an AI system that uses a modified version of LIME Image Explainer and generates images containing suggestions for improvement. We use single-character and word-level datasets labelled with binary labels generated via accepted rules for handwriting classification. We discuss the possible improvements to the current system as well as where this research could be applied, such as user-specific auto-suggestions. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-21648-0_23","Conference paper","2022","Image enhancement; Lime; Aesthetic judgments; AI systems; Binary labels; Character level; Current system; Explainability; Feature attribution; Handwriting analysis; Word level; Classification (of information)","Scopus"
"Open questions and research gaps for monitoring and updating AI-enabled tools in clinical settings","As the implementation of artificial intelligence (AI)-enabled tools is realized across diverse clinical environments, there is a growing understanding of the need for ongoing monitoring and updating of prediction models. Dataset shift—temporal changes in clinical practice, patient populations, and information systems—is now well-documented as a source of deteriorating model accuracy and a challenge to the sustainability of AI-enabled tools in clinical care. While best practices are well-established for training and validating new models, there has been limited work developing best practices for prospective validation and model maintenance. In this paper, we highlight the need for updating clinical prediction models and discuss open questions regarding this critical aspect of the AI modeling lifecycle in three focus areas: model maintenance policies, performance monitoring perspectives, and model updating strategies. With the increasing adoption of AI-enabled tools, the need for such best practices must be addressed and incorporated into new and existing implementations. This commentary aims to encourage conversation and motivate additional research across clinical and data science stakeholders. 2022 Davis, Walsh and Matheny.","10.3389/fdgth.2022.958284","Article","2022","accuracy; Article; artificial intelligence; clinical practice; clinical prediction model; dataset shift; human; information system; life cycle; machine learning; medical research; monitoring; patient; patient care; policy; prediction; prospective study; risk model surveillance; statistical model; temporal analysis; training; validation study","Scopus"
"Institutional Strategies for Cybersecurity in Higher Education Institutions","Cybersecurity threats have grown exponentially, posing a heavy burden on organisations. Higher Education Institutions (HEIs) are particularly vulnerable, and their cybersecurity issues are receiving greater attention. However, existing research on cybersecurity has limited referencing value for HEI leaders and policy-makers because they are usually technology-focused. Publications that showcase best practices often lack system-wide perspectives towards cybersecurity in HEIs. Our paper, therefore, aims to bridge this literature gap and generate institutional cybersecurity strategies for HEI leaders and policy-makers from a system perspective. We first review how the cybersecurity landscape has evolved over the last few decades and its latest trends and projections for the next decade. By analysing these historical developments and new changes, we further illuminate the importance of strengthening HEI cybersecurity capacities. As we explore why HEIs face severe challenges to tackle the ever-escalating cyberattacks, we propose a system-wide approach to safeguard HEI cybersecurity and highlight the necessity to reassess prioritised areas. By taking an extensive literature review and desk research of methods that could respond to the cybersecurity vulnerabilities of the next decade, we synthesise our findings with a set of institutional strategies, with takeaways designed to equip HEIs better to address cybersecurity threats into the future. The strategies include: (1) Strengthening Institutional Governance for Cybersecurity; (2) Revisiting Cybersecurity KPIs; (3) Explicating Cybersecurity Policies, Guidelines and Mechanisms; (4) Training and Cybersecurity Awareness Campaigns to Build Cybersecurity Culture; (5) Responding to AI-based Cyber-threats and Harnessing AI to Enhance Cybersecurity; (6) Introduction of New and More Sophisticated Security Measures; (7) Paying Attention to Mobile Devices Use, Using Encryption as a Daily Practice; and (8) Risk Management. We believe that cybersecurity can be safeguarded throughout the new decade when these strategies are considered thoroughly and with the concerted effort of relevant HEI stakeholders. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/info13040192","Article","2022","Cryptography; Decision making; Risk assessment; Risk management; Best practices; Cyber security; Cyber threats; Cyber-attacks; High educations; Higher education institutions; Historical development; Institutional strategy; Management strategies; Policy makers; Cybersecurity","Scopus"
"Reliable data exchange in vehicular delay tolerant networks using AI-based hybrid trust management","Vehicular delay-tolerant networks (VDTNs) play prominent part in smart transportation and smart city paradigm to diminish the drivers' risk to meet accidents and offer many infotainment and entertainment services. All the operations are carried out by exchanging data among nodes. However, due to open communication nature of VDTN, the data broadcasted by mobile nodes are quiet susceptible to security attacks. Recently, a number of protocols are proposed for open communication. However, securing such communications and establishing trust value among vehicles are major addressable issues. This is because the existing fraudulent peers can lead to catastrophic circumstances on roads. Along with securing the data carriers, the authenticity and reliability of data is also equally important. In order to identify reliable nodes and maintaining the authenticity of data being communicated, a new artificial intelligence (AI)-based hybrid trust management framework is proposed in this article. The study particularly exploits the proximity-based k-nearest neighbour (kNN) classification model for selecting controlling nodes. Further, decision stump is employed to accomplish trust estimation rules, and backpropagation is used to self-train the mobile nodes, whenever anticipated trust value is not attained. The proposed scheme maintains the integrity of vehicular nodes and efficiently handles the specified. The trust framework uses a multifaceted direct and recommended trust estimation approach to calculate the global trust values. For comparison, the performance of the proposed method was compared with other trust management approaches. © 2022 John Wiley & Sons Ltd.","10.1002/dac.5197","Article","2022","Authentication; Delay tolerant networks; Electronic data interchange; Nearest neighbor search; Vehicle to vehicle communications; Wireless networks; Decision stumps; Entertainment services; Global trust; Hybrid trust management; Infotainment; Mobile nodes; Open communication; Trust management; Trust values; Vehicular delay-tolerant networks; Backpropagation","Scopus"
"EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case","The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols – such as knowledge graphs – are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: (1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and (2) SHAP-Backprop, an explainable AI-informed training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that with our approach, it is possible to improve explainability at the same time as performance. © 2021 The Authors","10.1016/j.inffus.2021.09.022","Article","2022","Classification (of information); Deep learning; Economic and social effects; Graphic methods; Image enhancement; Knowledge management; Learning algorithms; Network architecture; Object detection; Compositionality; Deep learning; Expert knowledge; Expert knowledge graph; Explainable artificial intelligence; Knowledge graphs; Neural-symbolic learning; Part based; Part-based object detection and classification; Symbolic learning; Knowledge graph","Scopus"
"Designing for Continuous Interaction with Artificial Intelligence Systems","The increasing capabilities of Artificial Intelligence enable the support of users in a continuously growing number of applications. Current systems typically dictate that interaction between user input and AI output unfolds in discrete steps, as is the case with, for example, conversational agents. Novel scenarios require AI systems to adapt and respond to continuous user input, e.g., image-guided surgery and AI-supported text entry. In and across these applications, AI systems need to support more varied and dynamic interactions in which users and AI interact continuously and in parallel. Current methods and guidelines are often inadequate and sometimes even detrimental to user needs when considering continuous usage scenarios. Realizing a continuous interaction between users and AI requires a substantial change in perspective when designing Human-AI systems. In this SIG, we support the exchange of cutting-edge research contributing to a better understanding and improved methods and tools to design continuous Human-AI interaction. © 2022 Owner/Author.","10.1145/3491101.3516409","Conference paper","2022","Cutting tools; User interfaces; AI systems; Artificial intelligence systems; Continuous interactions; Current system; Design guideline; Discrete step; Explainability; Human-AI interaction; ML; User input; Artificial intelligence","Scopus"
"A Neo-Republican Critique of AI ethics","The AI Ethics literature, aimed to responsibly develop AI systems, widely agrees on the fact that society is in dire need for effective accountability mechanisms with regards to AI systems. Particularly, machine learning (ML) systems cause reason for concern due to their opaque and self-learning characteristics. Nevertheless, what such accountability mechanisms should look like remains either largely unspecified (e.g., ‘stakeholder input’) or ineffective (e.g., ‘ethical guidelines’). In this paper, I argue that the difficulty to formulate and develop effective accountability mechanisms lies partly in the predominant focus on Mill's harm's principle, rooted in the conception of freedom as non-interference. A strong focus on harm overcasts other moral wrongs, such as potentially problematic power dynamics between those who shape the system and those affected by it. I propose that the neo-republican conception of freedom as non-domination provides a suitable framework to inform responsible ML development. Domination, understood by neo-republicans, is a moral wrong as it undermines the potential for human flourishing. In order to mitigate domination, neo-republicans plead for accountability mechanisms that minimize arbitrary relations of power. Neo-republicanism should hence inform responsible ML development as it provides substantive and concrete grounds when accountability mechanisms are effective (i.e. when they are non-dominating). © 2021","10.1016/j.jrt.2021.100022","Article","2022","","Scopus"
"Human-Centered Explainable AI (HCXAI): Beyond Opening the Black-Box of AI","Explainability of AI systems is crucial to hold them accountable because they are increasingly becoming consequential in our lives by powering high-stakes decisions in domains like healthcare and law. When it comes to Explainable AI (XAI), understanding who interacts with the black-box of AI is just as important as ""opening""it, if not more. Yet the discourse of XAI has been predominantly centered around the black-box, suffering from deficiencies in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. In this second CHI workshop on Human-centered XAI (HCXAI), we build on the success of the first installment from CHI 2021 to expand the conversation around XAI. We chart the domain and shape the HCXAI discourse with reflective discussions from diverse stakeholders. The goal of the second installment is to go beyond the black box and examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on ""operationalizing"", aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI. © 2022 Owner/Author.","10.1145/3491101.3503727","Conference paper","2022","AI systems; Algorithmic fairness; Algorithmics; Black boxes; Explainable artificial intelligence; Interpretability; Interpretable machine learning; Machine-learning; Responsible AI; Trust in automation; Machine learning","Scopus"
"Governance of Responsible AI: From Ethical Guidelines to Cooperative Policies","The increasingly pervasive role of Artificial Intelligence (AI) in our societies is radically changing the way that social interaction takes place within all fields of knowledge. The obvious opportunities in terms of accuracy, speed and originality of research are accompanied by questions about the possible risks and the consequent responsibilities involved in such a disruptive technology. In recent years, this twofold aspect has led to an increase in analyses of the ethical and political implications of AI. As a result, there has been a proliferation of documents that seek to define the strategic objectives of AI together with the ethical precautions required for its acceptable development and deployment. Although the number of documents is certainly significant, doubts remain as to whether they can effectively play a role in safeguarding democratic decision-making processes. Indeed, a common feature of the national strategies and ethical guidelines published in recent years is that they only timidly address how to integrate civil society into the selection of AI objectives. Although scholars are increasingly advocating the necessity to include civil society, it remains unclear which modalities should be selected. If both national strategies and ethics guidelines appear to be neglecting the necessary role of a democratic scrutiny for identifying challenges, objectives, strategies and the appropriate regulatory measures that such a disruptive technology should undergo, the question is then, what measures can we advocate that are able to overcome such limitations? Considering the necessity to operate holistically with AI as a social object, what theoretical framework can we adopt in order to implement a model of governance? What conceptual methodology shall we develop that is able to offer fruitful insights to governance of AI? Drawing on the insights of classical pragmatist scholars, we propose a framework of democratic experimentation based on the method of social inquiry. In this article, we first summarize some of the main points of discussion around the potential societal, ethical and political issues of AI systems. We then identify the main answers and solutions by analyzing current national strategies and ethics guidelines. After showing the theoretical and practical limits of these approaches, we outline an alternative proposal that can help strengthening the active role of society in the discussion about the role and extent of AI systems. Copyright © 2022 Gianni, Lehtinen and Nieminen.","10.3389/fcomp.2022.873437","Article","2022","","Scopus"
"A Systematic Review of Artificial Intelligence Techniques in Cancer Prediction and Diagnosis","Artificial intelligence has aided in the advancement of healthcare research. The availability of open-source healthcare statistics has prompted researchers to create applications that aid cancer detection and prognosis. Deep learning and machine learning models provide a reliable, rapid, and effective solution to deal with such challenging diseases in these circumstances. PRISMA guidelines had been used to select the articles published on the web of science, EBSCO, and EMBASE between 2009 and 2021. In this study, we performed an efficient search and included the research articles that employed AI-based learning approaches for cancer prediction. A total of 185 papers are considered impactful for cancer prediction using conventional machine and deep learning-based classifications. In addition, the survey also deliberated the work done by the different researchers and highlighted the limitations of the existing literature, and performed the comparison using various parameters such as prediction rate, accuracy, sensitivity, specificity, dice score, detection rate, area undercover, precision, recall, and F1-score. Five investigations have been designed, and solutions to those were explored. Although multiple techniques recommended in the literature have achieved great prediction results, still cancer mortality has not been reduced. Thus, more extensive research to deal with the challenges in the area of cancer prediction is required. © 2021, CIMNE, Barcelona, Spain.","10.1007/s11831-021-09648-w","Review","2022","Deep learning; Diagnosis; Diseases; Forecasting; Artificial intelligence techniques; Cancer detection; Cancer diagnosis; Cancer prediction; Cancer prognosis; Effective solution; Machine learning models; Open-source; Systematic Review; Web of Science; Health care","Scopus"
"The Impact of Artificial Intelligence on Sustainable Development in Electronic Markets","With the emergence of artificial intelligence (AI), the technological revolution has transformed human lives and processes, empowering the products and services in today’s marketplaces. AI introduces new ways of doing jobs and business, and of exploring new global market opportuni-ties. However, on the other hand, it provides many challenges to comprehend. Therefore, our study’s main objective was to examine the behavioral, cultural, ethical, social, and economic challenges of AI-enabled products and services in consumer markets and discuss how businesses might shape their approaches to address AI-related ethical issues. AI offers numerous social, ethical, and behavioral difficulties for people, organizations, and societies that endanger the sustainable development of economies. These fundamental challenges due to AI technologies have raised serious questions for the sustainable development of electronic markets. Based on this, the current study presents a framework highlighting these issues. Systematic reviewing was our research method; we looked for explicit information and methods that indicate the credibility of research or reduce biases. This paper is of great importance, as it highlights several behavioral, societal, ethical, and cultural aspects in electronic markets which were not presented in previous studies. Some key issues are the security and privacy of consumers, AI biases, individual autonomy, wellbeing, and issues of unemployment. Therefore, companies that use AI systems need to be socially responsible and make AI systems as secure as possible to promote the sustainable development of countries. The results suggest that AI has undoubtedly transformed life and has both positive and negative effects. However, the main aim regarding AI should be to use it for the overall goals of humanity. Moreover, authorities operating in e-business environments need to create proper rules and regulations and make the systems as secure as possible for people. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/su14063568","Article","2022","artificial intelligence; business; electronics industry; market conditions; sustainable development","Scopus"
"A Unified Framework to Collect and Document AI-Infused Project Exemplars","Advancements in AI and ML approaches are the reason for the current hype of this technology. A lot of products and services, either in consumer-facing solutions, as well as in the industrial context, embrace the advancement of smart algorithms. Designing such systems entails several challenges, including designing for black-box decision-making with a potentially infinite and unknown set of UI manifestations, delivering easy-to-understand explanations, involving end-users in requirements specification and product evaluation, and communication with software engineers and data scientists among others. Although designers are today equipped with several UX tools for capturing and presenting users’ experience with the products they are designing, the question that arises in the AI context is whether and how existing contemporary tools can adapt and scale to support the design of AI-enabled interactive systems. Therefore, AI and ML are perceived as a new design material. This work aims to assist researchers and practitioners involved in AI-infused projects by proposing a framework to collect and document these. The framework was designed following a workshop with representative stakeholders, through which different use cases were presented and elaborated. Evaluation of the framework highlighted that it is an easy to use and useful tool for documenting use cases and communicating them to a wide audience. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-21707-4_29","Conference paper","2022","Human computer interaction; Product design; 'current; Best practices; Black boxes; Exemplar; Industrial context; ML; Product and services; Smart algorithms; Unified framework; Use case; Decision making","Scopus"
"A Human Being Must Obey the Commands of a Robot! CAVs, Asimov’s Second Law and the New Ground-Breaking Ethics","In 2020, the Independent Expert Group published the “Ethics of Connected and Automated Vehicles: recommendations on road safety, privacy, fairness, explainability and responsibility” report. This document represents a significant step towards systematizing the ongoing debate on ethical issues related to autonomic AI systems, especially Connected Automated Vehicles (CAVs). However, the report does not address the conflict between the values of human autonomy and safety, which becomes apparent when considering who should have control over CAVs, and who is responsible for the results of human autonomy. This problem and these questions have therefore become the subject of this paper. The analysis implied the following: either the human driver will be forbidden from driving, which is tantamount to admitting Asimov’s Second Law à rebours, i.e. a human being must obey the commands of a robot, or the human driver should be held fully responsible for overriding the decisions of the AI controlling the CAV. The choice between these two options must be made by the law maker according to the ethical rules within a culture. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-20316-9_29","Conference paper","2022","Ethical technology; Motor transportation; Automated vehicles; Autonomous Vehicles; Breakings; Connected and automated vehicle; Ethical issues; European laws; Human being; Human drivers; Road safety; Second law; Autonomous vehicles","Scopus"
"Process-Driven Modelling of Media Forensic Investigations-Considerations on the Example of DeepFake Detection","Academic research in media forensics mainly focuses on methods for the detection of the traces or artefacts left by media manipulations in media objects. While the resulting detectors often achieve quite impressive detection performances, when tested under lab conditions, hardly any of those have yet come close to the ultimate benchmark for any forensic method, which would be courtroom readiness. This paper tries first to facilitate the different stakeholder perspectives in this field and then to partly address the apparent gap between the academic research community and the requirements imposed onto forensic practitioners. The intention is to facilitate the mutual understanding of these two classes of stakeholders and assist with first steps intended at closing this gap. To do so, first a concept for modelling media forensic investigation pipelines is derived from established guidelines. Then, the applicability of such modelling is illustrated on the example of a fusion-based media forensic investigation pipeline aimed at the detection of DeepFake videos using five exemplary detectors (hand-crafted, in one case neural network supported) and testing two different fusion operators. At the end of the paper, the benefits of such a planned realisation of AI-based investigation methods are discussed and generalising effects are mapped out. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s22093137","Article","2022","Forensic Medicine; Intention; Neural Networks, Computer; Social Media; Videotape Recording; Digital forensics; Academic research; Certifiable investigation method; Deepfake detection; Detection performance; Forensic investigation; Forensic process models; Investigation methods; Media objects; Medium forensic; Process-driven; behavior; forensic medicine; social media; videorecording; Pipelines","Scopus"
"Towards a DSL for AI Engineering Process Modeling","Many modern software products embed AI components. As a result, their development requires multidisciplinary teams with diverse skill sets. Diversity may lead to communication issues or misapplication of best practices. Process models, which prescribe how software should be developed within an organization, can alleviate this problem. In this paper, we introduce a domain-specific language for modeling AI engineering processes. The DSL concepts stem from our analysis of scientific and gray literature that describes how teams are developing AI-based software. This DSL contributes a structured framework and a common ground for designing, enacting and automating AI engineering processes. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-21388-5_4","Conference paper","2022","Digital subscriber lines; Modeling languages; Process engineering; AI engineering; Best practices; Domains specific languages; Engineering process; Grey literature; Multidisciplinary teams; Process-models; Scientific literature; Skill sets; Software products; Problem oriented languages","Scopus"
"Searching for explanations of black-box classifiers in the space of semantic queries","Deep learning models have achieved impressive performance in various tasks, but they are usually opaque with regards to their inner complex operation, obfuscating the reasons for which they make decisions. This opacity raises ethical and legal concerns regarding the real-life use of such models, especially in critical domains such as in medicine, and has led to the emergence of the eXplainable Artificial Intelligence (XAI) field of research, which aims to make the operation of opaque AI systems more comprehensible to humans. The problem of explaining a black-box classifier is often approached by feeding it data and observing its behaviour. In this work, we feed the classifier with data that are part of a knowledge graph, and describe the behaviour with rules that are expressed in the terminology of the knowledge graph, that is understandable by humans. We first theoretically investigate the problem to provide guarantees for the extracted rules and then we investigate the relation of “explanation rules for a specific class” with “semantic queries collecting from the knowledge graph the instances classified by the black-box classifier to this specific class”. Thus we approach the problem of extracting explanation rules as a semantic query reverse engineering problem. We develop algorithms for solving this inverse problem as a heuristic search in the space of semantic queries and we evaluate the proposed algorithms on four simulated use-cases and discuss the results. © 2023 – The authors.","10.3233/SW-233469","Article","2022","","Scopus"
"Voice assistants in hospitality: using artificial intelligence for customer service","Purpose: Voice assistants (VAs) empower human–computer interactions by recognising human speech and implementing commands pronounced by users. This paper aims to investigate VA-enabled interactions between hotels and guests in the hospitality context. The research positions VAs within the artificial intelligence (AI)-enabled Internet of Things (IoT) context, disrupting old practices and processes. Smart hospitality uses VAs to support effortless value cocreation for guests cost-effectively. The research examines consumer perceptions and expectations of hospitality VAs and explores VA capabilities through expert technology providers. Design/methodology/approach: This empirical paper investigates the current use and future implications of VAs for hotel environments. It uses qualitative, semi-structured in-depth interviews with 7 expert hospitality VA technology providers and 21 hotel guests who have VA experience. The research adopts a demand and supply approach, addressing the VAs in hospitality holistically. Findings: The findings illustrate the requirements from both end-users’ sides, hotels and guests, exploring VA advantages and challenges. The analysis demonstrates that VAs increasingly become digital assistants. VA technology helps hotels to improve customer service, expand operational capability and reduce costs. Although in its infancy, VA technology has made progress towards optimising hotel operations and upgrading customer service. The study proposes a speech-enabled interactions model. Research limitations/implications: This research stimulates the transformation of hospitality services by using VAs and the development of smart hospitality and tourism ecosystems. The study can benefit from further research with hotel managers, to reflect hoteliers’ points of view and investigate their perception of VAs. Further research can also explore different aspects of consumer–VA interaction in different contexts. Practical implications: The paper makes a significant contribution to hospitality management and human–computer interaction best practices. It supports technology providers to reconsider how to develop suitable technology solutions towards improving their strategic competitiveness. It also explains how to use VAs cost-effectively and profitably while adding value to travellers’ experience. Originality/value: VA studies are often focussed on the technology in private households, rather than in commercial or hotel spaces. This paper contributes to the emerging literature on AI and IoT in smart hospitality and explores the acceptance and operationalisation of VAs. The research contributes to the conceptualisation of VA-enabled hotel services and explores positive and negative features, as well as future prospects. © 2021, Emerald Publishing Limited.","10.1108/JHTT-03-2021-0104","Article","2022","","Scopus"
"FINS auditing framework: Group fairness for subset selections","Subset selection is an integral component of AI systems that is increasingly affecting people's livelihoods in applications ranging from hiring, healthcare, education, to financial decisions. Subset selections powered by AI-based methods include top-k analytics, data summarization, clustering, and multi-winner voting. While group fairness auditing tools have been proposed for classification systems, these state-of-The-Art tools are not directly applicable to measuring and conceptualizing fairness in selected subsets. In this work, we introduce the first comprehensive auditing framework, FINS, to support stakeholders in interpretably quantifying group fairness across a diverse range of subset-specific fairness concerns. FINS offers a family of novel measures that provide a flexible means to audit group fairness for fairness goals ranging from item-based, score-based, and a combination thereof. FINS provides one unified easy-To-understand interpretation across these different fairness problems. Further, we develop guidelines through the FINS Fair Subset Chart, that supports auditors in determining which measures are relevant to their problem context and fairness objectives. We provide a comprehensive mapping between each fairness measure and the belief system (i.e., worldview) that is encoded within its measurement of fairness. Lastly, we demonstrate the interpretability and efficacy of FINS in supporting the identification of real bias with case studies using AirBnB listings and voter records.  © 2022 ACM.","10.1145/3514094.3534160","Conference paper","2022","Feature Selection; Set theory; AI systems; Algorithmic fairness; Algorithmics; Data summarizations; Financial decisions; Health care education; Integral components; Machine learning fairness; Machine-learning; Subset selection; Fins (heat exchange)","Scopus"
"INN: An Interpretable Neural Network for AI Incubation in Manufacturing","Both artificial intelligence (AI) and domain knowledge from human experts play an important role in manufacturing decision making. Smart manufacturing emphasizes a fully automated data-driven decision-making; however, the AI incubation process involves human experts to enhance AI systems by integrating domain knowledge for modeling, data collection and annotation, and feature extraction. Such an AI incubation process not only enhances the domain knowledge discovery but also improves the interpretability and trustworthiness of AI methods. In this article, we focus on the knowledge transfer from human experts to a supervised learning problem by learning domain knowledge as interpretable features and rules, which can be used to construct rule-based systems to support manufacturing decision making, such as process modeling and quality inspection. Although many advanced statistical and machine learning methods have shown promising modeling accuracy and efficiency, rule-based systems are still highly preferred and widely adopted due to their interpretability for human experts to comprehend. However, most of the existing rule-based systems are constructed based on deterministic human-crafted rules, whose parameters, such as thresholds of decision rules, are suboptimal. Yet the machine learning methods, such as tree models or neural networks, can learn a decision rule based structure without much interpretation or agreement with domain knowledge. Therefore, the traditional machine learning models and human experts' domain knowledge cannot be directly improved by learning from data. In this research, we propose an interpretable neural network (INN) model with a center-adjustable sigmoid activation function to efficiently optimize the rule-based systems. Using the rule-based system from domain knowledge to regulate the INN architecture not only improves the prediction accuracy with optimized parameters but also ensures the interpretability by adopting the interpretable rule-based systems from domain knowledge. The proposed INN will be effective for supervised learning problems when rule-based systems are available. The merits of the INN model are demonstrated via a simulation study and a real case study in the quality modeling of a semiconductor manufacturing process. © 2022 Association for Computing Machinery.","10.1145/3519313","Article","2022","Domain Knowledge; III-V semiconductors; Knowledge management; Learning systems; Multilayer neural networks; Network layers; Semiconductor device manufacture; Artificial intelligence incubation; Decisions makings; Domain knowledge; Human expert; Interpretability; Interpretable neural network; Multilayers perceptrons; Neural-networks; Rules based systems; Semiconductor manufacturing; Decision making","Scopus"
"Bridging the Gap Between UX Practitioners' Work Practices and AI-Enabled Design Support Tools","User interface (UI) and user experience (UX) design have become an indispensable part of today's tech industry. Recently, much progress has been made in machine-learning-enabled design support tools for UX designers. However, few of these tools have been adopted by practitioners. To learn the underlying reasons and understand user needs for bridging this gap, we conducted a retrospective analysis with 8 UX professionals to understand their practice and identify opportunities for future research. We found that the current AI-enabled systems to support UX work mainly work on graphical interface elements, while design activities that involve more ""design thinking""such as user interviews and user testings are more helpful for designers. Many current systems were also designed for overly-simplistic and generic use scenarios. We identified 4 areas in the UX workflow that can benefit from additional AI-enabled assistance: design inspiration search, design alternative exploration, design system customization, and design guideline violation check. © 2022 ACM.","10.1145/3491101.3519809","Conference paper","2022","User experience; 'current; Data-driven design; Design support tools; Human-AI collaboration; Learn+; Retrospective analysis; User experience (UX); User need; Users' experiences; Work practices; User interfaces","Scopus"
"Leveraging IoT-Aware Technologies and AI Techniques for Real-Time Critical Healthcare Applications","Personalised healthcare has seen significant improvements due to the introduction of health monitoring technologies that allow wearable devices to unintrusively monitor physiological parameters such as heart health, blood pressure, sleep patterns, and blood glucose levels, among others. Additionally, utilising advanced sensing technologies based on flexible and innovative biocompatible materials in wearable devices allows high accuracy and precision measurement of biological signals. Furthermore, applying real-time Machine Learning algorithms to highly accurate physiological parameters allows precise identification of unusual patterns in the data to provide health event predictions and warnings for timely intervention. However, in the predominantly adopted architectures, health event predictions based on Machine Learning are typically obtained by leveraging Cloud infrastructures characterised by shortcomings such as delayed response times and privacy issues. Fortunately, recent works highlight that a new paradigm based on Edge Computing technologies and on-device Artificial Intelligence significantly improve the latency and privacy issues. Applying this new paradigm to personalised healthcare architectures can significantly improve their efficiency and efficacy. Therefore, this paper reviews existing IoT healthcare architectures that utilise wearable devices and subsequently presents a scalable and modular system architecture to leverage emerging technologies to solve identified shortcomings. The defined architecture includes ultrathin, skin-compatible, flexible, high precision piezoelectric sensors, low-cost communication technologies, on-device intelligence, Edge Intelligence, and Edge Computing technologies. To provide development guidelines and define a consistent reference architecture for improved scalable wearable IoT-based critical healthcare architectures, this manuscript outlines the essential functional and non-functional requirements based on deductions from existing architectures and emerging technology trends. The presented system architecture can be applied to many scenarios, including ambient assisted living, where continuous surveillance and issuance of timely warnings can afford independence to the elderly and chronically ill. We conclude that the distribution and modularity of architecture layers, local AI-based elaboration, and data packaging consistency are the more essential functional requirements for critical healthcare application use cases. We also identify fast response time, utility, comfort, and low cost as the essential non-functional requirements for the defined system architecture. © 2022 by the authors.","10.3390/s22197675","Article","2022","Aged; Artificial Intelligence; Biocompatible Materials; Blood Glucose; Delivery of Health Care; Humans; Technology; Anomaly detection; Biocompatibility; Blood; Blood pressure; Computer architecture; Costs; Edge computing; Fall detection; Internet of things; Learning algorithms; Wearable sensors; biomaterial; Anomaly detection; Edge intelligence; Health care application; Healthcare and wellness; Multi sensor; Personalized healthcare; Piezoelectric sensors; Real- time; Systems architecture; Wearable devices; aged; artificial intelligence; glucose blood level; health care delivery; human; technology; Piezoelectricity","Scopus"
"Adversarial training for high-stakes reliability","In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high-stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance. In this work, we used a safe language generation task (“avoid injuries”) as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques-including a tool that assists human adversaries-to find and eliminate failures in a classifier that filters text completions suggested by a generator. In our task, we determined that we can set very conservative classifier thresholds without significantly impacting the quality of the filtered outputs. We found that adversarial training increased robustness to the adversarial attacks that we trained on-doubling the time for our contractors to find adversarial examples both with our tool (from 13 to 26 minutes) and without (from 20 to 44 minutes)-without affecting in-distribution performance. We hope to see further work in the high-stakes reliability setting, including more powerful tools for enhancing human adversaries and better ways to measure high levels of reliability, until we can confidently rule out the possibility of catastrophic deployment-time failures of powerful models. © 2022 Neural information processing systems foundation. All rights reserved.","","Conference paper","2022","AI systems; Doublings; Filtered output; Further works; High reliability; Language generation; Performance; Safe languages; Training techniques; Worst-case performance","Scopus"
"An empirical study of algorithmic bias","In all goal-oriented selection activities, the existence of a certain level of bias is unavoidable and may be desired for efficient AI-based decision support systems. However, a fair, independent comparison of all eligible entities is essential to alleviate explicit biasness in a competitive marketplace. For example, searching online for a good or a service, it is expected that the underlying algorithm will provide fair results by searching all available entities in the search category mentioned. However, a biased search can make a narrow or collaborative query, ignoring competitive outcomes, resulting in it costing the customers more or getting lower-quality products or services for the resources (money) they spend. This chapter describes algorithmic biases in different contexts with real-life case studies, examples, and scenarios; it provides best practices to detect and remove algorithmic bias. © 2022 World Scientific Publishing Company.","10.1142/9789811247323_0023","Book chapter","2022","","Scopus"
"Artificial Intelligence Robot Safety: A Conceptual Framework and Research Agenda Based on New Institutional Economics and Social Media","According to “Huang’s law”, Artificial intelligence (AI)-related hardware increases in power 4–10 times per year. AI can benefit various stages of real estate development, from planning and construction to occupation and demolition. However, Hong Kong’s legal system is currently behind when it comes to technological abilities, while the field of AI safety in built environments is still in its infancy. Negligent design and production processes, irresponsible data management, questionable deployment, algorithm training, sensor design and/or manufacture, unforeseen consequences from multiple data inputs, and erroneous AI operation based on sensor or remote data can all lead to accidents. Yet, determining how legal rules should apply to liability for losses caused by AI systems takes time. Traditional product liability laws can apply for some systems, meaning that the manufacturer will bear responsibility for a malfunctioning part. That said, more complex cases will undoubtedly have to come before the courts to determine whether something unsafe should be the manufacturer’s fault or the individual’s fault, as well as who should receive the subsequent financial and/or non-financial compensation, etc. Since AI adoption has an inevitable relationship with safety concerns, this project intends to shed light on responsible AI development and usage, with a specific focus on AI safety laws, policies, and people’s perceptions. We will conduct a systematic literature review via the PRISMA approach to study the academic perspectives of AI safety policies and laws and data-mining publicly available content on social media platforms such as Twitter, YouTube, and Reddit to study societal concerns about AI safety in built environments. We will then research court cases and laws related to AI safety in 61 jurisdictions, in addition to policies that have been implemented globally. Two case studies on AI suppliers that sell AI hardware and software to users of built environment will also be included. Another two case studies will be conducted on built environment companies (a contractor and Hong Kong International Airport) that use AI safety tools. The results obtained from social media, court cases, legislation, and policies will be discussed with local and international experts via a workshop, then released to the public to provide the international community and Hong Kong with unique policy and legal orientations. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.","10.1007/978-981-19-0737-1_3","Book chapter","2022","","Scopus"
"Exploiting Distance-Based Structures in Data Using an Explainable AI for Stock Picking","In principle, the fundamental data of companies may be used to select stocks with a high probability of either increasing or decreasing price. Many of the commonly known rules or used explanations for such a stock-picking process are too vague to be applied in concrete cases, and at the same time, it is challenging to analyze high-dimensional data with a low number of cases in order to derive data-driven and usable explanations. This work proposes an explainable AI (XAI) approach on the quarterly available fundamental data of companies traded on the German stock market. In the XAI, distance-based structures in data (DSD) that guide decision tree induction are identified. The leaves of the appropriately selected decision tree contain subsets of stocks and provide viable explanations that can be rated by a human. The prediction of the future price trends of specific stocks is made possible using the explanations and a rating. In each quarter, stock picking by DSD-XAI is based on understanding the explanations and has a higher success rate than arbitrary stock picking, a hybrid AI system, and a recent unsupervised decision tree called eUD3.5. © 2022 by the author. Licensee MDPI, Basel, Switzerland.","10.3390/info13020051","Article","2022","Clustering algorithms; Commerce; Data mining; Data visualization; AI systems; Data driven; Decision tree induction; Distance-based; Explainable AI; Fundamental analysis; High dimensional data; High probability; Information visualization; Price trends; Decision trees","Scopus"
"Leveraging Digital Twins to Enhance Green Public Procurement in AECO Industry","The digital transition of process management and Digital Twins (DTs) are promising to bridge the gap towards Product Lifecycle Management (PLM) and revolutionize decision-making processes in AECO (Architectural, Engineering, Construction and Operation) industry. Public procurement particularly suffers of poor digitalization with ineffective processes and low adoption of Green Public Procurement (GPP) mainly due to the lack of digital and automated data-driven tools for tender evaluation. Leveraging DTs as virtual Prototypes (DTPs) could help to overcome the current discrete project performances evaluation and enable a systemic one, exploitable for bids evaluation besides performance and sustainability optimization. The research adopts a PLM view to define a methodology aimed at developing DTPs starting from the bidding BIM models. The main objective is to integrate several DTPs and an Artificial Intelligence (AI) system in the aim automatizing MEAT (Most Economic Advantageous Tender) procedure and promote GPP adoption, providing an optimal and more objective data-driven awarding system and criteria weighting. Three crucial objectives should be accomplished: (i) the definition of a replicable methodology to develop the DTPs, (ii) the definition of their informative structure and (iii) the re-engineering of tender processes to bring full digitalization and automation. This could enable more effective decisions and performance optimization, bids objective evaluation, tendering procedure streamlining, transparency and sustainability enhancement. The awarded DTP, as a truthful “As-built” developed accordingly to defined information guidelines, must be exploited as the basis for valuable DTIs to manage the whole lifecycle, optimizing DTs development costs together with operational and maintenance costs. © 2022 Copyright for this paper by its authors.","","Conference paper","2022","Architectural design; Bridges; Decision making; Information management; Life cycle; Sustainable development; Architectural engineering constructions; Data driven; Decision-making process; Digital twin prototype; Engineering operation; Green public procurement; Process management; Product life cycle management; Public procurement; Tender evaluation; Waste management","Scopus"
"Smartphone apps for tracking food consumption and recommendations: Evaluating artificial intelligence-based functionalities, features and quality of current apps","The advancement of artificial intelligence (AI) and the significant growth in the use of food consumption tracking and recommendation-related apps in the app stores have created a need for an evaluation system, as minimal information is available about the evidence-based quality and technological advancement of these apps. Electronic searches were conducted across three major app stores and the selected apps were evaluated by three independent raters. A total of 473 apps were found and 80 of them were selected for review based on inclusion and exclusion criteria. An app rating tool is devised to evaluate the selected apps. Our rating tool assesses the apps essential features, AI based advanced functionalities and software quality characteristics required for food consumption tracking and recommendations, as well as their usefulness to general users. The rating tool's internal consistency, as well as inter- and intra-rater reliability among raters, are also calculated. Users’ comments from the app stores are collected and evaluated to better understand their expectations and perspectives. Following an evaluation of the assessed applications, design considerations that emphasize automation-based approaches using artificial intelligence are proposed. According to our assessment, most mobile apps in the app stores do not satisfy the overall requirements for tracking food consumption and recommendations. “Foodvisor” is the only app that can automatically recognise food items, and compute the recommended volume and nutritional information of that food item. However, these features need to be improvised in the food consumption tracking and recommendation apps. This study provides both researchers and developers with an insight into current state-of-the-art apps and design guidelines with necessary information on essential features and software quality characteristics for designing and developing a better app. © 2022 The Author(s)","10.1016/j.iswa.2022.200103","Review","2022","Application programs; Artificial intelligence; Computer software selection and evaluation; Food supply; Nutrition; Quality control; Smartphones; 'current; App evaluation; App stores; Design guideline; Essential features; Food consumption; Food nutrition; Food recommendation; Smartphone apps; Software quality characteristics; Design","Scopus"
"Woubot®: A personalized predictive AI system for hard to heal wounds","Management of chronic wounds in healthcare disciplines is a huge financial burden on healthcare systems around the world. An estimated 1.5-2 million patients in Europe alone suffer from acute or chronic wounds at a given time. The mental and societal burden of living with a chronic wound is immense. Many studies have shown that treatment of these wounds conservatively (without surgery) is one of the major contributing factors to the cost, with wound dressings being a significant impactr. Data from the NHS shows that managing wounds properly such as choosing the appropriate dressing for the right wound and continuous appropriate treatment can significantly increase healing and reduce healthcare spending. Funded by the National Institute of Health Research and NHS England the AI in Health and Care Award Accelerated Access Collaborative (AAC) and NHS AI Lab supported AI technologies across the spectrum of development, from initial feasibility to evaluation within clinical pathways in the NHS and social care settings, to the point that they could be nationally commissioned. In this paper, the findings of a phase 1, project a feasibility study are introduced for discussion and shared learning about an artificial intelligence-based technology which aims in phase 2 to predict the development of hard to heal wounds and their rates of healing and produce recommendations for clinicians dealing with wound care. Woubot® will evaluate the risks of different wound treatments and predict and monitor the progression of wounds. Considering national guidelines on treatment as well as data available, improvements in practice will be recommended, and tailored treatment plans will be suggested for individual patients. Early analysis of patient data (combined electronic clinical records containing demographic, historical, laboratory tests, intervention details etc.) was completed over a 12-month period. The impact of biological factors affecting wound healing suggested that changes in clinical practice such as carrying out a blood test to detect for example vitamin B12 levels and other circulatory factors could significantly improve wound healing rates. The findings suggest that once detected either simple lifestyle changes (diet) or a clinical intervention e.g., B12 injections may result in improved healing. Initial assessments show the monetized benefits of using Woubot® have been predicted to be around £35 million over a period of 10 years, which is a substantial development in the future of wound management. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2022","Blood; Clinical research; Hospital data processing; Patient treatment; AI systems; Chronic wounds; Contributing factor; England; Health research; Healthcare systems; National institute of healths; Woubot®; Wound dressings; Wound healing; Artificial intelligence","Scopus"
"Dialogue Explanation with Reasoning for AI","Explainable Artificial Intelligence is increasingly gaining attention in domains, such as self-driving cars and medical treatment. One of the most prevalent issues with these explainable models is that they are difficult to comprehend and have not been tested in real-world scenarios. In this research, I propose a dialogue-based explanation with reasoning for a rule-based system with the intention of utilising it in the future with a Neuro Symbolic AI system, to give machines the capacity to explain their actions or decisions using logic. We hypothesize that when a system makes a deduction that was, in some way, unexpected by the user then locating the source of the disagreement or misunderstanding is best achieved through a collaborative dialogue process that allows the participants to gradually isolate the cause. I also conduct a user evaluation for this hypothesis.  © 2022 Owner/Author.","10.1145/3514094.3539522","Conference paper","2022","Computation theory; AI systems; Artificial intelligence; Dialog for explanation; Explainable artificial intelligence (XAI); Machine reasoning; Medical treatment; Neuro symbolic; Real-world scenario; Rules based systems; User evaluations; Artificial intelligence","Scopus"
"An Occupational Safety and Health Perspective on Human in Control and AI","The continuous and rapid development of AI-based systems comes along with an increase in automation of tasks and, therewith, a qualitative shift in opportunities and challenges for occupational safety and health. A fundamental aspect of humane working conditions is the ability to exert influence over different aspects of one's own work. Consequently, stakeholders contribute to the prospect of maintaining the workers' autonomy albeit increasing automation and summarize this aspiration with the human in control principle. Job control has been part of multiple theories and models within the field of occupational psychology. However, most of the models do not include specific technical considerations nor focus on task but rather on job level. That is, they are possibly not able to fully explain specific changes regarding the digitalization of tasks. According to the results of a large-scale study on German workers (DiWaBe), this seems to be the case to some extend: the influence of varying degrees of automation, moderated by perceived autonomy, on workers' wellbeing was not consistent. However, automation is a double-edged sword: on a high level, it can be reversely related to the workers' job control while highly autonomous and reliable systems can also create opportunities for more flexible, impactful and diverse working tasks. Consequently, automation can foster and decrease the factor of job control. Models about the optimal level of automation aim to give guidelines on how the former can be achieved. The results of the DiWaBe study indicate that automation in occupational practice does not always happen in line with these models. Instead, a substantial part of automation happens at the decision-making level, while executive actions remain with the human. From an occupational safety and health perspective, it is therefore crucial to closely monitor and anticipate the implementation of AI in working systems. Constellations where employees are too controlled by technology and are left with a high degree of demands and very limited resources should be avoided. Instead, it would be favorable to use AI as an assistance tool for the employees, helping them to gather and process information and assisting them in decision-making. Copyright © 2022 Niehaus, Hartwig, Rosen and Wischniewski.","10.3389/frai.2022.868382","Article","2022","","Scopus"
"Ethical FRAPPE - an adapted draft framework for ethical AIED","Artificial Intelligence (AI) is pervading our lives in numerous ways today. It is important to apply ethical principles to guide the development and usage of AI systems to prevent harms or discrimination through AI algorithms. This has led to various ethical regulations and guidelines being formed at the corporate, national and supra-national level. The EU AI Act classifies the usage of AI in education as 'high-risk' as “such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination” [1, p. 26]. However, there has been little attention paid to ethics in AI in Education (AIED) in literature and there is only one existing framework to ethically guide AIED. AIED ethics is complex as it has to combine both general AI ethics and the ethics of educational technology. We aim to create a theoretical framework for AIED, comprising implementation guidelines for developers and organizational users of AI in education. In this paper, an existing draft framework by Holmes et al. is adapted by using insights from literature in the ethics of AI, ethics of educational technology and ethics of AIED. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2022","Educational technology; Ethical technology; Laws and legislation; Artificial intelligence algorithms; Artificial intelligence in education; Artificial intelligence systems; Corporates; Education and training; Ethical principles; National level; Organisational; Theoretical framework; Artificial intelligence","Scopus"
"Contractor’s Risk Analysis of Engineering Procurement and Construction (EPC) Contracts Using Ontological Semantic Model and Bi-Long Short-Term Memory (LSTM) Technology","The development of intelligent information technology in the era of the fourth industrial revolution requires the EPC (engineering, procurement, and construction) industry to increase productivity through a digital transformation. This study aims to automatically analyze the critical risk clauses in the invitation to bid (ITB) at the bidding stage to strengthen their competitiveness for the EPC contractors. To this end, we developed an automated analysis technology that effectively analyzes a large amount of ITB documents in a short time by applying natural language processing (NLP) and bi-directional long short-term memory (bi-LSTM) algorithms. This study proposes two models. First, the semantic analysis (SA) model is a rule-based approach that applies NLP to extract key risk clauses. Second, the risk level ranking (RLR) model is a train-based approach that ranks the risk impact for each clause by applying bi-LSTM. After developing and training an artificial intelligent (AI)-based ITB analysis model, its performance was evaluated through the actual project data. As a result of validation, the SA model showed an F1 score of 86.4 percent, and the RLR model showed an accuracy of 46.8 percent. The RLR model displayed relatively low performance because the ITB used in the evaluation test included the contract clauses that did not exist in the training dataset. Therefore, this study illustrated that the rule-based approach performed superior to the training-based method. The authors suggest that EPC contractors should apply both the SA and RLR modes in the ITB analysis, as one supplements the other. The two models were embedded in the Engineering Machine-learning Automation Platform (EMAP), a cloud-based platform developed by the authors. Rapid analysis through applying both the rule-based and AI-based automatic ITB analysis technology can contribute to securing timeliness for risk response and supplement possible human mistakes in the bidding stage. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/su14116938","Article","2022","competitiveness; information technology; language; model; training","Scopus"
"Responsible AI Systems: Who are the Stakeholders?","As of 2021, there were more than 170 guidelines on AI ethics and responsible, trustworthy AI in circulation according to the AI Ethics Guidelines Global Inventory maintained by AlgorithmWatch, an organisation which tracks the effects of increased digitalisation on everyday lives. However, from the perspective of day-To-day work, for those engaged in designing, developing, and maintaining AI systems identifying relevant guidelines and translating them into practice presents a challenge. The aim of this paper is to help anyone engaged in building a responsible AI system by identifying an indicative long-list of potential stakeholders. This list of impacted stakeholders is intended to enable such AI system builders to decide which guidelines are most suited to their practice. The paper draws on a literature review of articles short-listed based on searches conducted in the ACM Digital Library and Google Scholar. The findings are based on content analysis of the short-listed literature guided by probes which draw on the ISO 26000:2010 Guidance on social responsibility. The paper identifies three levels of potentially relevant stakeholders when responsible AI systems are considered: individual stakeholders (including users, developers, and researchers), organisational stakeholders, and national / international stakeholders engaged in making laws, rules, and regulations. The main intended audience for this paper is software, requirements, and product engineers engaged in building AI systems. In addition, business executives, policy makers, legal/regulatory experts, AI researchers, public, private, and third sector organisations developing responsible AI guidelines, and anyone interested in seeing functional responsible AI systems are the other intended audience for this paper.  © 2022 ACM.","10.1145/3514094.3534187","Conference paper","2022","Economic and social effects; Ethical technology; Laws and legislation; Social aspects; AI ethic; AI system builder; AI systems; Corporate social responsibility; ISO 26000:2010 guidance on social responsibility; Responsible AI system; Social responsibilities; Stakeholders identifications; System builders; Digital libraries","Scopus"
"Who Audits the Auditors? Recommendations from a field scan of the algorithmic auditing ecosystem","Algorithmic audits (or g AI audits') are an increasingly popular mechanism for algorithmic accountability; however, they remain poorly defined. Without a clear understanding of audit practices, let alone widely used standards or regulatory guidance, claims that an AI product or system has been audited, whether by first-, second-, or third-party auditors, are difficult to verify and may potentially exacerbate, rather than mitigate, bias and harm. To address this knowledge gap, we provide the first comprehensive field scan of the AI audit ecosystem. We share a catalog of individuals (N=438) and organizations (N=189) who engage in algorithmic audits or whose work is directly relevant to algorithmic audits; conduct an anonymous survey of the group (N=152); and interview industry leaders (N=10). We identify emerging best practices as well as methods and tools that are becoming commonplace, and enumerate common barriers to leveraging algorithmic audits as effective accountability mechanisms. We outline policy recommendations to improve the quality and impact of these audits, and highlight proposals with wide support from algorithmic auditors as well as areas of debate. Our recommendations have implications for lawmakers, regulators, internal company policymakers, and standards-setting bodies, as well as for auditors. They are: 1) require the owners and operators of AI systems to engage in independent algorithmic audits against clearly defined standards; 2) notify individuals when they are subject to algorithmic decision-making systems; 3) mandate disclosure of key components of audit findings for peer review; 4) consider real-world harm in the audit process, including through standardized harm incident reporting and response mechanisms; 5) directly involve the stakeholders most likely to be harmed by AI systems in the algorithmic audit process; and 6) formalize evaluation and, potentially, accreditation of algorithmic auditors. © 2022 ACM.","10.1145/3531146.3533213","Conference paper","2022","Artificial intelligence; Decision making; Ethical technology; AI audit; AI bias; AI harm; AI policy; AI systems; Algorithm audit; Algorithmic accountability; Algorithmics; Audit; Ethical AI; Ecosystems","Scopus"
"Evolving explainable rule sets","Most AI systems work like black boxes tasked with generating reasonable outputs for given inputs. Many domains, however, have explainablity and trustworthiness requirements not fulfilled by these approaches. Various methods exist to analyze or interpret black-box models post training. When it comes down to sensitive domains in which there is a mandate for white-box models, a better choice would be to use transparent models. In this work, we present a method which evolves explainable rule-sets using inherently transparent ordinary logic to make models. We showcase some sample domains we tackled and discuss their major desirable properties like bias detection, knowledge discovery, and modifiablity, to name a few. © 2022 ACM.","10.1145/3520304.3534023","Conference paper","2022","AI systems; Black box modelling; Black boxes; Explainable AI; Property; Rule set; Rule-set evolution; White-box models; XAI; Genetic algorithms","Scopus"
"Examining the technology-mediated cycles of injustice that contribute to digital ageism: Advancing the conceptualization of digital ageism: evidence and implications","Our work draws attention to digital ageism referring to the nexus of ageism (discrimination or bias related to age) that is mediated and perpetuated by artificial intelligent (AI) systems and technologies. Building on the World Health Organization's recently published policy brief entitled ""Ageism in AI for Health""and our previous work about digital ageism, this paper aims to advance our current understanding and conceptualization of digital ageism in technology and AI systems broadly and beyond health alone. To do this, we will 1) elaborate on our conceptual model and the ageist technology-mediated cycles of injustice that can produce and reinforce digital ageism; 2) present empirical evidence of our descriptive analysis of seven commonly used facial image datasets to highlight data disparities for older adults which will provide real-world evidence that substantiates one of the elements in our ageist cycles of injustice; and 3) summarize results from our grey literature search of various grey literature databases including the AI ethics guidelines Global Inventory to identify guidance documents that address ageism in AI in research or technology development. This paper uniquely contributes conceptual and empirical evidence of digital ageism which will advance knowledge in the field and deepen our understanding of how ageism in AI is fostered by broader ageist cycles of injustice. Lastly, we will briefly provide future considerations to address digital ageism.  © 2022 ACM.","10.1145/3529190.3534765","Conference paper","2022","Ethical technology; Ageism; Algorithmic bias; Algorithmics; Artificial intelligent; Bias; Discrimination; Grey literature; Inequity; Policy briefs; World Health Organization; Health","Scopus"
"Explainable Model Fusion for Customer Journey Mapping","Due to advances in computing power and internet technology, various industrial sectors are adopting IT infrastructure and artificial intelligence (AI) technologies. Recently, data-driven predictions have attracted interest in high-stakes decision-making. Despite this, advanced AI methods are less often used for such tasks. This is because AI technology is a black box for the social systems it is meant to support; trustworthiness and fairness have not yet been established. Meanwhile in the field of marketing, strategic decision-making is a high-stakes problem that has a significant impact on business trends. For global marketing, with its diverse cultures and market environments, future decision-making is likely to focus on building consensus on the formulation of the problem itself rather than on solutions for achieving the goal. There are two important and conflicting facts: the fact that the core of domestic strategic decision-making comes down to the formulation of the problem itself, and the fact that it is difficult to realize AI technology that can achieve problem formulation. How can we resolve this difficulty with current technology? This is the main challenge for the realization of high-level human-AI systems in the marketing field. Thus, we propose customer journey mapping (CJM) automation through model-level data fusion, a process for the practical problem formulation known as explainable alignment. Using domain-specific requirements and observations as inputs, the system automatically outputs a CJM. Explainable alignment corresponds with both human and AI perspectives and in formulating the problem, thereby improving strategic decision-making in marketing. Following preprocessing to make latent variables and their dynamics transparent with latent Dirichlet allocation and a variational autoencoder, a post-hoc explanation is implemented in which a hidden Markov model and learning from an interpretation transition are combined with a long short-term memory architecture that learns sequential data between touchpoints for extracting attitude rules for CJM. Finally, we realize the application of human-AI systems to strategic decision-making in marketing with actual logs in over-the-top media services, in which the dynamic behavior of customers for CJM can be automatically extracted. Copyright © 2022 Okazaki and Inoue.","10.3389/frai.2022.824197","Article","2022","","Scopus"
"Model Monitoring in Practice: Lessons Learned and Open Challenges","Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges. In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.  © 2022 Owner/Author.","10.1145/3534678.3542617","Conference paper","2022","Employment; Ethical technology; Health care; Learning systems; Monitoring; Recommender systems; Risk management; Sales; Case study from industry; Case-studies; Ethic in ai; Machine learning models; Model monitoring; Model monitoring and model risk management; Model risk management; Monitoring risks; Monitoring tools; Responsible ai; Artificial intelligence","Scopus"
"Explanations in AI as Claims of Tacit Knowledge","As AI systems become increasingly complex it may become unclear, even to the designer of a system, why exactly a system does what it does. This leads to a lack of trust in AI systems. To solve this, the field of explainable AI has been working on ways to produce explanations of these systems’ behaviors. Many methods in explainable AI, such as LIME (Ribeiro et al. in Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016), offer only a statistical argument for the validity of their explanations. However, some methods instead study the internal structure of the system and try to find components which can be assigned an interpretation. I believe that these methods provide more valuable explanations than those statistical in nature. I will try to identify which explanations can be considered internal to the system using the Chomskyan notion of tacit knowledge. I argue that each explanation expresses a rule, and through the localization of this rule in the system internals, we can take a system to have tacit knowledge of the rule. I conclude that the only methods which are able to sufficiently establish this tacit knowledge are those along the lines of Olah (Distill 2(11): 4901–4911, 2017), and therefore they provide explanations with unique strengths. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","10.1007/s11023-021-09588-1","Article","2022","Data mining; Lime; AI systems; Explainable artificial intelligence; Explanation; Internal structure; Interpretability; Knowledge discovery and data minings; Localisation; Philosophy of language; System behaviors; Tacit knowledge; Machine learning","Scopus"
"An overview of artificial intelligence techniques for diagnosis of Schizophrenia based on magnetic resonance imaging modalities: Methods, challenges, and future works","Schizophrenia (SZ) is a mental disorder that typically emerges in late adolescence or early adulthood. It reduces the life expectancy of patients by 15 years. Abnormal behavior, perception of emotions, social relationships, and reality perception are among its most significant symptoms. Past studies have revealed that SZ affects the temporal and anterior lobes of hippocampus regions of the brain. Also, increased volume of cerebrospinal fluid (CSF) and decreased volume of white and gray matter can be observed due to this disease. Magnetic resonance imaging (MRI) is the popular neuroimaging technique used to explore structural/functional brain abnormalities in SZ disorder, owing to its high spatial resolution. Various artificial intelligence (AI) techniques have been employed with advanced image/signal processing methods to accurately diagnose SZ. This paper presents a comprehensive overview of studies conducted on the automated diagnosis of SZ using MRI modalities. First, an AI-based computer aided-diagnosis system (CADS) for SZ diagnosis and its relevant sections are presented. Then, this section introduces the most important conventional machine learning (ML) and deep learning (DL) techniques in the diagnosis of diagnosing SZ. A comprehensive comparison is also made between ML and DL studies in the discussion section. In the following, the most important challenges in diagnosing SZ are addressed. Future works in diagnosing SZ using AI techniques and MRI modalities are recommended in another section. Results, conclusion, and research findings are also presented at the end. © 2022 Elsevier Ltd","10.1016/j.compbiomed.2022.105554","Review","2022","Adolescent; Adult; Artificial Intelligence; Brain; Gray Matter; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Schizophrenia; Behavioral research; Brain; Cerebrospinal fluid; Computer aided diagnosis; Computer aided instruction; Deep learning; Diseases; Learning algorithms; Learning systems; Neuroimaging; Artificial intelligence techniques; Conventional machine learning; Conventional machines; Deep learning; Imaging modality; Life expectancies; Machine-learning; Mental disorders; Neuroscience; Schizophrenia; abnormal behavior; ant colony optimization; applied research; artificial intelligence; autoencoder; bipolar disorder; blood oxygenation; classification; cognitive flexibility; connectome; convolutional neural network; cost effectiveness analysis; decision support system; deep belief network; deep learning; diffusion weighted imaging; DSM-5; electric activity; electroencephalogram; electroencephalography; environmental factor; feature extraction; feature learning (machine learning); feature selection; functional connectivity; functional magnetic resonance imaging; functional near-infrared spectroscopy; functional neuroimaging; gray matter; hemodynamics; hippocampus; human; image processing; International Classification of Diseases; machine learning; magnetoencephalography; medical research; mental disease; neuroimaging; non invasive procedure; nuclear magnetic resonance imaging; particle swarm optimization; personality disorder; phenotype; practice guideline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; recurrent neural network; Review; Scale for the Assessment of Positive Symptoms; schizoaffective psychosis; schizophrenia; short term memory; signal processing; social interaction; support vector machine; transfer of learning; United States; virtual reality; adolescent; adult; brain; diagnostic imaging; nuclear magnetic resonance imaging; pathology; procedures; schizophrenia; Magnetic resonance imaging","Scopus"
"How Do Software Companies Deal with Artificial Intelligence Ethics? A Gap Analysis","The public and academic discussion on Artificial Intelligence (AI) ethics is accelerating and the general public is becoming more aware AI ethics issues such as data privacy in these systems. To guide ethical development of AI systems, governmental and institutional actors, as well as companies, have drafted various guidelines for ethical AI. Though these guidelines are becoming increasingly common, they have been criticized for a lack of impact on industrial practice. There seems to be a gap between research and practice in the area, though its exact nature remains unknown. In this paper, we present a gap analysis of the current state of the art by comparing practices of 39 companies that work with AI systems to the seven key requirements for trustworthy AI presented in the ""The Ethics Guidelines for Trustworthy Artificial Intelligence"". The key finding of this paper is that there is indeed notable gap between AI ethics guidelines and practice. Especially practices considering the novel requirements for software development, requirements of societal and environmental well-being and diversity, nondiscrimination and fairness were not tackled by companies. © 2022 ACM.","10.1145/3530019.3530030","Conference paper","2022","Data privacy; Ethical technology; Software design; 'current; Artificial intelligence ethic; Artificial intelligence systems; Ethics issues; Gap analysis; General publics; Industrial practices; Public IS; Responsible artificial intelligence; Software company; Artificial intelligence","Scopus"
"Explore AI and Machine Learning for Future ISR Collection Planning and Management","The current airborne ISR (Intelligence, Surveillance, and Reconnaissance) collection planning and management is designed for the employment of a limited number of large ISR platforms with respect to a set of collection requirements created through an assembly line-like process. This process is often very cumbersome and mentally exhaustive for intelligence analysts when dealing with a large volume of dynamic all-source intelligence. Consequently, more human time and resources are spent on processing and digesting raw data, instead of strategizing and designing the most effective ISR collection plans. These problems could be amplified significantly in potential future conflicts with a near-peer adversary because the complexity, scale, and intensity of an airborne ISR operation could be several orders higher. This paper discusses our new research concepts and preliminary results in applying artificial intelligence (AI) and machine learning (ML) as proof-of-concepts for facilitating future ISR collection planning and management. We explored a dynamic knowledge graph to represent historical and current all-source intelligence data as well as the corresponding contextual relationships and temporal states. Such an accumulative knowledge base allows us to apply machine learning and other analytical methods to infer and visualize multi-layered intelligence on an adversary’s capabilities and operations. These analytical results could assist human ISR analysts in understanding adversary’s operational tactics, techniques, and procedures. We further look into AI-enabled virtual agents in assisting mission planners to best manage a group of ISR assets for fulfillment of collection requirements. Applying deep reinforcement learning to Intellection, a new cooperative multi-player ISR collection board game, we train the virtual agents into AI players who can follow the game rules and estimate the desirable flight paths for potentially maximizing successful collections over prioritized targets. Together, these explorations may potentially create decision advantages and relieve possible manpower bottlenecks in future fast-paced ISR collection planning and management. © 2022 SPIE.","10.1117/12.2619117","Conference paper","2022","Deep learning; Learning systems; Reinforcement learning; Collections management; Combat operation model; Combat operations; Intelligence surveillance and reconnaissances; Intelligence, surveillance, and reconnaissance collection management; Knowledge graphs; Machine-learning; Operations Modeling; Reinforcement learnings; Route planning; Knowledge graph","Scopus"
"Identify diabetic retinopathy-related clinical concepts and their attributes using transformer-based natural language processing methods","Background: Diabetic retinopathy (DR) is a leading cause of blindness in American adults. If detected, DR can be treated to prevent further damage causing blindness. There is an increasing interest in developing artificial intelligence (AI) technologies to help detect DR using electronic health records. The lesion-related information documented in fundus image reports is a valuable resource that could help diagnoses of DR in clinical decision support systems. However, most studies for AI-based DR diagnoses are mainly based on medical images; there is limited studies to explore the lesion-related information captured in the free text image reports. Methods: In this study, we examined two state-of-the-art transformer-based natural language processing (NLP) models, including BERT and RoBERTa, compared them with a recurrent neural network implemented using Long short-term memory (LSTM) to extract DR-related concepts from clinical narratives. We identified four different categories of DR-related clinical concepts including lesions, eye parts, laterality, and severity, developed annotation guidelines, annotated a DR-corpus of 536 image reports, and developed transformer-based NLP models for clinical concept extraction and relation extraction. We also examined the relation extraction under two settings including ‘gold-standard’ setting—where gold-standard concepts were used–and end-to-end setting. Results: For concept extraction, the BERT model pretrained with the MIMIC III dataset achieve the best performance (0.9503 and 0.9645 for strict/lenient evaluation). For relation extraction, BERT model pretrained using general English text achieved the best strict/lenient F1-score of 0.9316. The end-to-end system, BERT_general_e2e, achieved the best strict/lenient F1-score of 0.8578 and 0.8881, respectively. Another end-to-end system based on the RoBERTa architecture, RoBERTa_general_e2e, also achieved the same performance as BERT_general_e2e in strict scores. Conclusions: This study demonstrated the efficiency of transformer-based NLP models for clinical concept extraction and relation extraction. Our results show that it’s necessary to pretrain transformer models using clinical text to optimize the performance for clinical concept extraction. Whereas, for relation extraction, transformers pretrained using general English text perform better. © 2022, The Author(s).","10.1186/s12911-022-01996-2","Article","2022","Artificial Intelligence; Blindness; Diabetes Mellitus; Diabetic Retinopathy; Electronic Health Records; Humans; Natural Language Processing; artificial intelligence; blindness; diabetes mellitus; diabetic retinopathy; electronic health record; human; natural language processing","Scopus"
"The Development of an Information Technology Architecture for Automated, Agile and Versatile Companies with Ecological and Ethical Guidelines","Based on many years of experience as a management consultant in different industries and corporate structures and cultures, the motivation to use digital transformation in connection with variable corporate goals—such as fluctuating workloads, agile response to customer inquiries, and ecological and economic sustainability—results in a process or a product to be developed that intelligently adapts to market requirements and requires forward-looking leadership. Using an AI-based methodical analysis and synthesis approach, the high consumption of economic and human resources is to be continuously monitored and optimization measures initiated at an early stage. The necessary information technology with its infrastructure and architecture is the starting point to accompany the agility and changeability of corporate goals. Researching the relevant documents begins with writing the panorama or the state of knowledge on the topic. This article is about the IT infrastructure based on the requirements for an architecture and behavior that a versatile, agile company needs to accompany the constantly changing framework conditions of the market. The technology used and the available resources, including the human resources, need to be adapted as early as possible. Data now represent the most valuable asset on Earth and future industrial manufacturing systems must maximize the opportunity of data usage. Low-level data must be transformed to make them useful in supporting intelligent decision-making, for example. Furthermore, future manufacturing systems must be highly productive, adaptable, absent of error, and kind to the environment and to local communities. The all-important design should minimize the waste of material, capital, energy, and media. Herein, we discuss the fulfilling of agile customer requirements involving adaptable and modulated production processes (related to the ‘agile manufacturing’ and ‘digital transformation’ perspectives). © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/informatics9020037","Article","2022","","Scopus"
"Attentive Hierarchical ANFIS with interpretability for cancer diagnostic","Prediction of clinical outcomes using the patient's medical data enhances clinical decision making and improves prognostic accuracy. Deep learning (DL) for medical decision support systems has particularly shown expert-level accuracy in predicting clinical outcomes. However, most of these machine learning and Artificial Intelligent (AI) models lack interpretability which causes major trust-related problems in healthcare. This necessitates the need for interpretable AI systems that can explain their decisions. This paper is designed to address the problem of how clinical decision support systems can be designed to be transparent, interpretable and therefore comprehensible for humans. In this view, this paper proposes an attentive hierarchical adaptive neuro-fuzzy inference system (AH-ANFIS), that combines fuzzy inference in a hierarchical architecture with attention for selecting the important rules. The proposed model benefits from the rule-based structure of ANFIS that enables the user to interpret the abstractions of hidden layers. The hierarchical structure in fuzzy modeling helps to overcome the rule explosion problem that arises with large medical data and improve interpretability. To ensure the improvement of interpretability with hierarchical architecture, an evolutionary algorithm (EA) is used to decompose the input space into an optimal permutation of input subsets which results in subsystems with independent meaning. The attention-based rule selector identifies the most activated rule to select important patient-specific features for predicting the clinical outcome. To verify the performance of the proposed AH-ANFIS and analyze the important features for classification, we perform experiments with two cancer diagnostic datasets. By pruning fuzzy if-then rules using recursive rule elimination (RRE), the complexity of the model is largely reduced while maintaining the performance of the system making it more interpretable. © 2022 Elsevier Ltd","10.1016/j.eswa.2022.117099","Article","2022","Classification (of information); Decision making; Decision support systems; Deep learning; Diagnosis; Diseases; Forecasting; Fuzzy neural networks; Fuzzy systems; Network architecture; Adaptive neuro-fuzzy inference; Artificial intelligent; Attention; Cancer diagnostics; Clinical outcome; Hierarchical architectures; Interpretability; Interpretable artificial intelligent; Medical data; Neuro-fuzzy network; Fuzzy inference","Scopus"
"Human-Centred AI in the Age of Industry 5.0: A Systematic Review Protocol","Research within AI-based Industry 4.0 (I4.0) work systems has predominantly focused on technical and process performance, while human and psychosocial factors are rarely examined. These factors must be considered to design human-centred systems that cultivate sustainable human-AI interaction, i.e., human-AI interaction that promotes long-term well-being, engagement, and performance. The European Commission has brought forward a new vision of I4.0 called Industry 5.0, where well-being and technological advancement are jointly considered, thus overcoming the weaknesses of I4.0. To move forward with Industry 5.0, it is necessary to consolidate our knowledge of human-technology interaction within I4.0. This systematic review aims to uncover the antecedents and consequences of human and psychosocial factors within AI-based I4.0 systems, with an end goal of providing guidelines for the sustainable design, implementation, and use of these systems. This protocol presents the background and the methodology behind our review, as well as preliminary results and expected contributions. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-21707-4_34","Conference paper","2022","Human engineering; Sustainable development; Human centered systems; Human-centered AI; Industry 5.0; Process performance; Psychosocial factors; Systematic Review; Technical performance; Well being; Well performance; Work system; Industry 4.0","Scopus"
"Human-Centered Efficient Explanation on Intrusion Detection Prediction","The methodology for constructing intrusion detection systems and improving existing systems is being actively studied in order to detect harmful data within large-capacity network data. The most common approach is to use AI systems to adapt to unanticipated threats and improve system performance. However, most studies aim to improve performance, and performance-oriented systems tend to be composed of black box models, whose internal working is complex. In the field of security control, analysts strive for interpretation and response based on information from given data, system prediction results, and knowledge. Consequently, performance-oriented systems suffer from a lack of interpretability owing to the lack of system prediction results and internal process information. The recent social climate also demands a responsible system rather than a performance-focused one. This research aims to ensure understanding and interpretation by providing interpretability for AI systems in multiple classification environments that can detect various attacks. In particular, the better the performance, the more complex and less transparent the model and the more limited the area that the analyst can understand, the lower the processing efficiency accordingly. The approach provided in this research is an intrusion detection methodology that uses FOS based on SHAP values to evaluate if the prediction result is suspicious and selects the optimal rule from the transparent model to improve the explanation. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/electronics11132082","Article","2022","","Scopus"
"Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work","Calls for “ethical Artificial Intelligence” are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing “ethical AI” remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work. Copyright © 2022 Cole, Cant, Ustek Spilda and Graham.","10.3389/frai.2022.869114","Article","2022","","Scopus"
"Morality, Machines, and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents","We present what we call the Interpretation Problem, whereby any rule in symbolic form is open to infinite interpretation in ways that we might disapprove of and argue that any attempt to build morality into machines is subject to it. We show how the Interpretation Problem in Artificial Intelligence is an illustration of Wittgenstein’s general claim that no rule can contain the criteria for its own application, and that the risks created by this problem escalates in proportion to the degree to which a machine is causally connected to the world, in what we call the Law of Interpretative Exposure. Using games as an illustration, we attempt to define the structure of normative spaces and argue that any rule-following within a normative space is guided by values that are external to that space and which cannot themselves be represented as rules. In light of this, we categorise the types of mistakes an artificial moral agent could make into Mistakes of Intention and Instrumental Mistakes, and we propose ways of building morality into machines by getting them to interpret the rules we give in accordance with these external values, through explicit moral reasoning, the “Show, not Tell” paradigm, the adjustment of causal power and structure of the agent, and relational values, with the ultimate aim that the machine develop a virtuous character and that the impact of the Interpretation Problem is minimised. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-21441-7_9","Conference paper","2022","Decision support systems; Ethical technology; AI ethic; AI systems; Evaluation of AI system; Intelligent decision-support systems; Interpretation problem; Moral value; Practical reasoning; Rule; Value alignment; Virtue theory; Wittgenstein; Artificial intelligence","Scopus"
"The Legal Basis of the Right to Explanation for Artificial Intelligence Decisions in UAE Law","Artificial intelligence (AI) systems have a major role in making decisions affecting humans in the present era, however, they still suffer from several shortcomings, the most important of which is the inability of the human element to understand the mechanism of action of these systems and the foundations upon the decision basis. Ambiguity also makes it impossible to assign responsibility and control potential AI biases. Thus, international and national standards were set to counteract the negative consequences, among the most important international standards are the recommendations set by UNESCO for the ethics of artificial intelligence. While on the United Arab Emirates Level, this study addresses the basis of this explanation right in its Constitution, in the Civil Procedures Law and Smart Dubai Department Law No. (1) of 2020, which was enacted in order to enhance the status of the Emirate of Dubai and support its efforts towards transformation into smart cities. The authors relied on an analytical and descriptive approach to the various legislative provisions related to the right to explain. The study concluded that there is no explicit legal provision at the UAE level that establishes the right of people to have AI decisions explained. However, this right has been recognized at the international level in the nonbinding UNESCO guidelines. The study reached a recommendation that lawmakers at the international and national levels should pay more attention to the right to explanation of AI decisions, and they should recognize this right with explicit and binding legal texts.  © 2022 IEEE.","10.1109/ACIT57182.2022.9994088","Conference paper","2022","Ethical technology; Laws and legislation; Artificial intelligence; Artificial intelligence systems; Assign responsibilities; Control potential; Explainability; Intelligence decision; International standards; Making decision; Mechanism of action; The right to explanation; Artificial intelligence","Scopus"
"Design Knowledge for the Lifecycle Management of Conversational Agents","Organizations spend extensive resources on artificial intelligence (AI) solutions in customer service in order to remain customer-focused and competitive. A rising language-based application of AI emerges in the context of conversational agents (CAs), such as chatbots, which represent increasingly intelligent, autonomous, scalable, and cost-effective service platforms. However, AI-based CAs bring new organizational challenges. They are underrepresented in current research, leading to many unanswered questions and research potential regarding the management of their introduction, operation, and improvement. To address this issue, we provide design knowledge that considers the organizational perspective of CAs. Therefore, we conducted a systematic literature review (SLR) and qualitative interview study to reveal and analyze individual issues and challenges, develop meta-requirements, and finally, use them to create design principles. We contribute to the emerging field of CAs that has previously focused mainly on the individual, behavioral, interactional, or technical design. © 2022 17th International Conference on Wirtschaftsinformatik, WI 2022. All rights reserved.","","Conference paper","2022","Autonomous agents; Life cycle; Artificial intelligence-based assistant; Chatbots; Conversational agents; Customer-service; Design knowledge; Design Principles; Extensive resources; Interview study; Language-based applications; Lifecycle management; Cost effectiveness","Scopus"
"A Hybrid and Hierarchical Approach for Spatial Exploration in Dynamic Environments","Exploration in unknown dynamic environments is a challenging problem in an AI system, and current techniques tend to produce irrational exploratory behaviours and fail in obstacle avoidance. To this end, we present a three-tiered hierarchical and modular spatial exploration model that combines the intrinsic motivation integrated deep reinforcement learning (DRL) and rule-based real-time obstacle avoidance approach. We address the spatial exploration problem in two levels on the whole. On the higher level, a DRL based global module learns to determine a distant but easily reachable target that maximizes the current exploration progress. On the lower level, another two-level hierarchical movement controller is used to produce locally smooth and safe movements between targets based on the information of known areas and free space assumption. Experimental results on diverse and challenging 2D dynamic maps show that the proposed model achieves almost 90% coverage and generates smoother trajectories compared with a state-of-the-art IM based DRL and some other heuristic methods on the basis of avoiding obstacles in real time. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/electronics11040574","Article","2022","","Scopus"
"Ethics of AI: A Systematic Literature Review of Principles and Challenges","Ethics in AI becomes a global topic of interest for both policymakers and academic researchers. In the last few years, various research organizations, lawyers, think tankers, and regulatory bodies get involved in developing AI ethics guidelines and principles. However, there is still debate about the implications of these principles. We conducted a systematic literature review (SLR) study to investigate the agreement on the significance of AI principles and identify the challenging factors that could negatively impact the adoption of AI ethics principles. The results reveal that the global convergence set consists of 22 ethical principles and 15 challenges. Transparency, privacy, accountability and fairness are identified as the most common AI ethics principles. Similarly, lack of ethical knowledge and vague principles are reported as the significant challenges for considering ethics in AI. The findings of this study are the preliminary inputs for proposing a maturity model that assesses the ethical capabilities of AI systems and provides best practices for further improvements. © 2022 ACM.","10.1145/3530019.3531329","Conference paper","2022","Ethical technology; AI ethic; Challenge; Global conver-gence; Guidelines and Principles; Machine ethic; Policy makers; Principle; Regulatory bodies; Research organization; Systematic literature review; Artificial intelligence","Scopus"
"Effects on Co-Presence of a Virtual Human: A Comparison of Display and Interaction Types","Recently, artificial intelligence (AI)-enabled virtual humans have been widely used in various fields in our everyday lives, such as for museum exhibitions and as information guides. Given the continued technological innovations in extended reality (XR), immersive display devices and interaction methods are evolving to provide a feeling of togetherness with a virtual human, termed co-presence. With regard to such technical developments, one main concern is how to improve the experience through the sense of co-presence as felt by participants. However, virtual human systems still have limited guidelines on effective methods, and there is a lack of research on how to visualize and interact with virtual humans. In this paper, we report a novel method to support a strong sense of co-presence with a virtual human, and we investigated the effects on co-presence with a comparison of display and interaction types. We conducted the experiment according to a specified scenario between the participant and the virtual human, and our experimental study showed that subjects who participated in an immersive 3D display with non-verbal interaction felt the greatest co-presence. Our results are expected to provide guidelines on how to focus on constructing AI-based interactive virtual humans. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/electronics11030367","Article","2022","","Scopus"
"Suggestions for a Revision of the European Smart Robot Liability Regime","In recent years, the need for regulation of robots and Artificial Intelligence, together with the urgency of reshaping the civil liability framework, has become apparent in Europe. Although the matter of civil liability has been the subject of many studies and resolutions, multiple attempts to harmonize EU tort law have been unsuccessful so far, and only the liability of producers for defective products has been harmonized so far. In 2021, by publishing the AI Act proposal, the European Commission reached the goal to regulate AI at the European level, classifying smart robots as”high-risk systems”. This new piece of legislation, albeit tackling important issues, does not focus on liability rules. However, regulating the responsibility of developers and manufacturers of robots and AI systems, in order to avoid a fragmented legal framework across the EU and an uneven application of liability rules in each Member State, is still an important issue that raises many concerns in the industry sector. In particular, deep learning techniques need to be carefully regulated, as they challenge the traditional liability paradigm: it is often not possible to know the reason behind the output given by those models, and neither the programmer nor the manufacturer is able to predict the AI behavior. For this reason, some authors have argued that we need to take liability away from producers and programmers when robots are capable of acting autonomously from their original design, while others have proposed a strict liability regime. This article explores liability issues about AI and robots with regards to users, producers, and programmers, especially when the use of machine learning techniques is involved, and suggests some regulatory solutions for European lawmakers. © 2022 Impact of Artificial Intelligence and Robotics, ECIAIR 2022","","Conference paper","2022","Deep learning; Intelligent robots; Learning algorithms; Learning systems; Product liability; AI systems; Civil liability; Defective products; European Commission; European levels; High-risk systems; Liability; Robot law; Robots system; Smart robots; Machine design","Scopus"
"Deployment and validation of an AI system for detecting abnormal chest radiographs in clinical settings","Background: The purpose of this paper is to demonstrate a mechanism for deploying and validating an AI-based system for detecting abnormalities on chest X-ray scans at the Phu Tho General Hospital, Vietnam. We aim to investigate the performance of the system in real-world clinical settings and compare its effectiveness to the in-lab performance. Method: The AI system was directly integrated into the Hospital's Picture Archiving and Communication System (PACS) after being trained on a fixed annotated dataset from other sources. The system's performance was prospectively measured by matching and comparing the AI results with the radiology reports of 6,285 chest X-ray examinations extracted from the Hospital Information System (HIS) over the last 2 months of 2020. The normal/abnormal status of a radiology report was determined by a set of rules and served as the ground truth. Results: Our system achieves an F1 score—the harmonic average of the recall and the precision—of 0.653 (95% CI 0.635, 0.671) for detecting any abnormalities on chest X-rays. This corresponds to an accuracy of 79.6%, a sensitivity of 68.6%, and a specificity of 83.9%. Conclusions: Computer-Aided Diagnosis (CAD) systems for chest radiographs using artificial intelligence (AI) have recently shown great potential as a second opinion for radiologists. However, the performances of such systems were mostly evaluated on a fixed dataset in a retrospective manner and, thus, far from the real performances in clinical practice. Despite a significant drop from the in-lab performance, our result establishes a reasonable level of confidence in applying such a system in real-life situations. Copyright © 2022 Nguyen, Nguyen, Nguyen, Nguyen, Pham and Nguyen.","10.3389/fdgth.2022.890759","Article","2022","Article; atelectasis; bootstrapping; cardiomegaly; classifier; clavicle fracture; computer assisted diagnosis; controlled study; data extraction; false negative result; false positive result; hospital information system; human; instrument validation; intermethod comparison; interstitial lung disease; lung consolidation; lung emphysema; lung fibrosis; lung nodule; major clinical study; measurement accuracy; measurement precision; pleura effusion; pleura thickening; pneumothorax; prospective study; radiologist; retrospective study; rib fracture; sensitivity and specificity; thorax radiography; Viet Nam","Scopus"
"Towards a Balanced Natural Language Processing: A Systematic Literature Review for the Contact Centre: Balancing the AI Triple Challenge of Opportunity, Ethics, and Opportunity Cost!","Artificial Intelligence (AI), which is the design, development, and utilisation of iterative and complex algorithmic systems that complete tasks which normally required human intelligence, is rapidly gaining momentum throughout the world. Through Machine Learning these AI systems automatically learn and adapt themselves so that they can offer an even more accurate outcome than humans and this offers many exciting benefits to most businesses and economies. But their introduction has raised ethical questions after some unethical conduct on their part like racism, biasness against women, unemployment (through intelligent automation), and inequality. After these incidents of unethical behaviour by some AI technologies around the globe most public, private, and even non-profit organisations embarked on initiatives to address the unethical conduct of AI systems. They produced a range of ethical AI frameworks, guidelines, and principles, but a properly balanced AI, where opportunity, ethics, and opportunity costs intersect, is still to be achieved or realised. Most AI Practitioners are pressured by their shareholders to prioritise commercial interests over ethical considerations. The findings from this Systematic Literature Review study, which used meta-analyses for qualitative synthesis, demonstrate that a Balanced Natural Language Processing (NLP) is possible. © 2022, IFIP International Federation for Information Processing.","10.1007/978-3-031-19429-0_24","Conference paper","2022","Balancing; Ethical technology; Iterative methods; Learning algorithms; Natural language processing systems; Artificial intelligence systems; Balanced artificial intelligence; Ethical artificial intelligence; Language processing; Machine-learning; Natural language processing; Natural languages; Opportunity costs; Systematic literature review; Unethical conduct; Machine learning","Scopus"
"A Benchmark for Compositional Visual Reasoning","A fundamental component of human vision is our ability to parse complex visual scenes and judge the relations between their constituent objects. AI benchmarks for visual reasoning have driven rapid progress in recent years with state-of-the-art systems now reaching human accuracy on some of these benchmarks. Yet, there remains a major gap between humans and AI systems in terms of the sample efficiency with which they learn new visual reasoning tasks. Humans' remarkable efficiency at learning has been at least partially attributed to their ability to harness compositionality - allowing them to efficiently take advantage of previously gained knowledge when learning new tasks. Here, we introduce a novel visual reasoning benchmark, Compositional Visual Relations (CVR), to drive progress towards the development of more data-efficient learning algorithms. We take inspiration from fluid intelligence and non-verbal reasoning tests and describe a novel method for creating compositions of abstract rules and generating image datasets corresponding to these rules at scale. Our proposed benchmark includes measures of sample efficiency, generalization, compositionality, and transfer across task rules. We systematically evaluate modern neural architectures and find that convolutional architectures surpass transformer-based architectures across all performance measures in most data regimes. However, all computational models are much less data efficient than humans, even after learning informative visual representations using self-supervision. Overall, we hope our challenge will spur interest in developing neural architectures that can learn to harness compositionality for more efficient learning. © 2022 Neural information processing systems foundation. All rights reserved.","","Conference paper","2022","Digital storage; Learning algorithms; Learning systems; Compositionality; Efficient learning; Fundamental component; Human vision; Human-systems; Learn+; Neural architectures; State-of-the-art system; Visual reasoning; Visual scene; Efficiency","Scopus"
"An AI-Based Automatic Risks Detection Solution for Plant Owner’s Technical Requirements in Equipment Purchase Order","Maintenance activities to replace, repair, and revamp equipment in the industrial plant sector are gradually needed for sustainability during the plant’s life cycle. In order to carry out these revamping activities, the plant owners exchange many purchase orders (POs) with equipment suppliers, including technical and specification documents and commercial procurement content. As POs are written in various formats with large volumes and complexities, it is often time-consuming for the owner’s engineer to review them and it may lead to errors and omissions. This study proposed the purchase order recognition and analysis system (PORAS), which automatically detects and compares risk clauses between plant owners’ and suppliers’ POs by utilizing artificial intelligence (AI). The PORAS is a comprehensive framework consisting of two independent modules and four model components that accurately reflect on the added value of the PORAS. The table recognition and comparison (TRC) module is utilized for risk clauses in POs written in tables with its two components, the table comparison (TRC-C) and table recognition (TRC-R) models. The critical terms in general conditions (CTGC) module analyzes the patterns of risk clauses in general texts, then extracts them with a rule-based algorithm and compares them through entity matching. In the TRC-C model using machine learning (Ditto model), a few errors occurred due to insufficient training data, resulting in an accuracy of 87.8%, whereas in the TRC-R model, a rule-based algorithm, errors occurred in only some exceptional cases; thus, its F1 score was evaluated to be 96.9%. The CTGC module’s F2 score for automatic extraction performance was evaluated as 79.1% due to some data’s bias. Overall, the validation study shows that while a human review of the risk clauses in a PO manually took hours, it took only an average of 10 min with the PORAS. Therefore, this time saving can significantly reduce the owner engineer’s PO workload. In essence, this study contributes to achieving sustainable engineering processes through the intelligence and automation of document and risk management in the plant industry. © 2022 by the authors.","10.3390/su141610010","Article","2022","algorithm; artificial intelligence; engineering; machine learning; sustainability","Scopus"
"Using human-in-the-loop and explainable AI to envisage new future work practices","In this paper, we discuss the trends and challenges of the integration of Artificial Intelligence (AI) methods in the workplace. An important aspect towards creating positive AI futures in the workplace is the design of fair, reliable and trustworthy AI systems which aim to augment human performance and perception, instead of replacing them by acting in an automatic and non-transparent way. Research in Human-AI Interaction has proposed frameworks and guidelines to design transparent and trustworthy human-AI interactions. Considering such frameworks, we discuss the potential benefits of applying human-in-the-loop (HITL) and explainable AI (XAI) methods to define a new design space for the future of work. We illustrate how such methods can create new interactions and dynamics between human users and AI in future work practices.  © 2022 Owner/Author.","10.1145/3529190.3534779","Conference paper","2022","Artificial intelligence methods; Artificial intelligence systems; Explainable artificial intelligence; Future of works; Human perception; Human performance; Human-artificial intelligence interaction; Human-in-the-loop; Potential benefits; Work practices","Scopus"
"The Human in the Infinite Loop: A Case Study on Revealing and Explaining Human-AI Interaction Loop Failures","Interactive AI systems increasingly employ a human-in-the-loop strategy. This creates new challenges for the HCI community when designing such systems. We reveal and investigate some of these challenges in a case study with an industry partner, and developed a prototype human-in-the-loop system for preference-guided 3D model processing. Two 3D artists used it in their daily work for 3 months. We found that the human-AI loop often did not converge towards a satisfactory result and designed a lab study (N=20) to investigate this further. We analyze interaction data and user feedback through the lens of theories of human judgment to explain the observed human-in-the-loop failures with two key insights: 1) optimization using preferential choices lacks mechanisms to deal with inconsistent and contradictory human judgments; 2) machine outcomes, in turn, influence future user inputs via heuristic biases and loss aversion. To mitigate these problems, we propose descriptive UI design guidelines. Our case study draws attention to challenging and practically relevant imperfections in human-AI loops that need to be considered when designing human-in-the-loop systems.  © 2022 ACM.","10.1145/3543758.3543761","Conference paper","2022","3D modeling; Failure (mechanical); Human computer interaction; Human engineering; User interfaces; 3d-modeling; Adaptive human-computer interaction; AI systems; Case-studies; Human errors; Human judgments; Human-in-the-loop; Human-in-the-loop machine learning; Loop systems; Machine-learning; Machine learning","Scopus"
"Hidden Information General Game Playing with Deep Learning and Search","General Game Playing agents are capable of learning to play games they have never seen before, merely by looking at a formal description of the rules of a game. Recent developments in deep learning have influenced the way state-of-the-art AI systems can learn to play games with perfect information like Chess and Go. This development is popularised by the success of AlphaZero and was subsequently generalised to arbitrary games describable in the general Game Description Language, GDL. Many real-world problems, however, are non-deterministic and involve actors with concealed information, or events with probabilistic outcomes. We describe a framework and system for General Game Playing with self-play reinforcement learning and search for hidden-information games, which can be applied to any game describable in the extended Game Description Language for imperfect-information games, GDL-II. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-20868-3_12","Conference paper","2022","Deep learning; Game theory; Learning systems; Search engines; AI systems; Description languages; Formal Description; Game playing; General game playing; Hidden information; Imperfect information; Learning to play; Reinforcement learnings; State of the art; Reinforcement learning","Scopus"
"BLOCKCHAIN AND ARTIFICIAL INTELLIGENCE: CONNECTING TWO DISTINCT TECHNOLOGIES TO COMPLY WITH GDPR’S DATA PROTECTION BY DESIGN PRINCIPLE","The aim of the paper is to present some of the general principles of data protection law that can be applied to automated decision-making applications embedded into blockchain technology in order to comply with the provision of the European Union’s General Data Protection Regulation (GDPR). The analysis focuses on the applicability of the ‘data protection by design’ principle during the development of such systems. Because blockchain-based networks are built on distributed data processing operations, therefore data controlling or processing of participating nodes should comply some abstract data protection patterns predetermined and collectively built-in during the system’s development phase. On the other hand, the imprint of AI’s automated data processing could be also observed and tracked back in the blockchain due to its historically retroactive nature. In the end, the study presents the human mind and its ‘uploading’ with conscious and unconscious contents as an analogy to blockchain-based AI systems. My goal is to highlight that the synergy of blockchain and machine learning-based AI can be hypothetically suitable to develop robust yet transparent automated decision-making systems. The compliance of these distributed AI systems with data protection law’s principles is a key issue regarding the high risks posed by them to data subjects rights and freedoms. © 2022 Masaryk University Journal of Law and Technology. All rights reserved.","10.5817/MUJLT2022-1-3","Article","2022","","Scopus"
"The use of artificial intelligence systems in diagnosis of pneumonia via signs and symptoms: A systematic review","Artificial Intelligence (AI) systems using symptoms/signs to detect respiratory diseases may improve diagnosis especially in limited resource settings. Heterogeneity in such AI systems creates an ongoing need to analyse performance to inform future research. This systematic literature review aimed to investigate performance and reporting of diagnostic AI systems using machine learning (ML) for pneumonia detection based on symptoms and signs, and to provide recommendations on best practices for designing and implementing predictive ML algorithms. This article was conducted following the PRISMA protocol, 876 articles were identified by searching PubMed, Scopus, and OvidSP databases (last search 5th May 2021). For inclusion, studies must have differentiated clinically diagnosed pneumonia from controls or other diseases using AI. Risk of Bias was evaluated using The STARD 2015 tool. Information was extracted from 16 included studies regarding study characteristics, ML-model features, reference tests, study population, accuracy measures and ethical aspects. All included studies were highly heterogenous concerning the study design, setting of diagnosis, study population and ML algorithm. Study reporting quality in methodology and results was low. Ethical issues surrounding design and implementation of the AI algorithms were not well explored. Although no single performance measure was used in all studies, most reported an accuracy measure over 90%. There is strong evidence to support further investigations of ML to automatically detect pneumonia based on easily recognisable symptoms and signs. To help improve the efficacy of future research, recommendations for designing and implementing AI tools based on the findings of this study are provided. © 2021","10.1016/j.bspc.2021.103325","Review","2022","Machine learning; Philosophical aspects; Accuracy measures; Artificial intelligence systems; Best practices; Machine learning algorithms; Performance; Pneumonia; Predictive models; Symptoms (signs); Systematic literature review; Systematic Review; area under the curve; artificial intelligence; diagnostic accuracy; diagnostic test accuracy study; human; machine learning; physical disease by body function; pneumonia; Review; sensitivity and specificity; study design; systematic review; Diagnosis","Scopus"
"AI Tools for Media Data Governance in the Post-Truth Era: from Abnormal Data Recognition to Intelligent Opinion Monitoring Algorithm","AI tools for media data governance in the post-truth era from abnormal data recognition to intelligent opinion monitoring algorithm is studied in the paper. The decisions and rules made by artificial intelligence are not necessarily superior to human beings. In terms of fairness, machine learning identifies patterns from past data and makes new decisions based on these patterns. Therefore, AI systems may consolidate or amplify historical bias. In the analysis of network public opinion, the first thing is to then grab the network text, and analyze the behavior characteristics, classify different behavior characteristics, so as to detect network public opinion according to some different behavior types and with this inspiration. In our designed model, the data mining algorithm is designed for the modelling. Through the comparison analysis, the performance is then validated.  © 2022 IEEE.","10.1109/ICICT54344.2022.9850591","Conference paper","2022","Data mining; Monitoring; Social aspects; Abnormal data; AI tool; Behavior characteristic; Data governances; Data recognition; Intelligent opinion; Medium data governance; Monitoring algorithms; Network public opinions; Post-truth era; Artificial intelligence","Scopus"
"The Construction and Validation of an Automatic Crisis Balance Analysis Model","Background: With the development of Internet, many people with suicide risk tend to express their thoughts on social media platforms. AI-based model can early identify social media users with suicide risk and analyze their cognitive and interpersonal characteristics. Then we can do early intervention to help them. Objective: To build an automatic crisis balance analysis model based on artificial intelligence which can perform automatic early suicide identification, suicide risk classification and analyze cognitive distortion and interpersonal relationship of users. Then to validate the predictive efficiency of model. Method: Firstly, based on the suicide knowledge graph, free annotation data set was generated and then Bert-based model was built. Secondly, the data set was refined by psychology students and experts to build fine-tuning model and Psychology+ model. The Psychology+ model was used as final suicide risk assessment model. We enriched and quantified the variables of cognitive and interpersonal characteristics and built the cognitive distortion and interpersonal relationship analysis model. Using F1 score, precision, recall and accuracy to evaluate the model performance and the consistence of model results with expert judgment and scales results to evaluate the model prediction ability. Results: For the suicide risk assessment model, the F1 score, precision, recall rate and accuracy rate of the model are 77.98%, 80.75%, 75.41% and 78.68% respectively. For the cognitive distortion and interpersonal relationship analysis model, the F1 score, accuracy and recall rate of the model are 77.26%, 78.22% and 76.33% respectively. Comparing the results with the results of the scale by chi square test, there was no significant difference in cognitive distortion(P = 0.521) and interpersonal relationship(P = 0.189) aspect. Conclusion: The model showed good performance and can be used as a guideline and evaluation tool for intervention. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-20627-6_17","Conference paper","2022","Knowledge graph; Risk assessment; Social networking (online); Analysis models; Balance analysis; Data set; F1 scores; Interpersonal relationship; Model validation; Psychology Model; Risk assessment - modelling; Social media; Suicide; Statistical tests","Scopus"
"Interaction Design for AI Systems: An oriented state-of-the-art","In recent years, new web-based technologies have emerged, and mobile devices and applications access have become widespread, resulting in new paradigms in Human-Computer Interaction (HCI). These paradigms created several challenges in interaction design regarding customization, adaptability, and accessibility. Over the lifetime of a digital product, the user must adapt to updates, changes in the interface, and new functions, while having to provide attention to customization and configuration tasks in interfaces created for millions of individuals worldwide. Simultaneously, users' conditions change, and the system must adjust to new requirements, preferences, and needs in a fast-paced digital environment. And new functions, interfaces, and technologies that meet current market directions, such as Artificial Intelligence, Augmented Reality, Virtual Reality, and even Design without physical interfaces must be developed and implemented. This research work explores the importance of Interaction Design (IxD) in the present and future Artificial Intelligence (AI) systems, highlighting the prominent authors of User-Centered Design and usability principles, guidelines, and heuristics. Moreover, researching appropriate design principles for developing a positive, effective, and safe interaction between humans and computers. This study will also deepen and orient the study of the state-of-the-art to promote the exploration of HCI in a period of enormous challenges and opportunities in AI. As a result of this research work, a table summarizes, compares, and classifies the state of the art according to Usability & Design Principles. Outputting a matrix that aggregates the fundamental principles for designing interfaces in artificial intelligence systems, regardless of their interface. This matrix serves as a base for a framework to create a prototype, in future work, based on the guidelines suggested. © 2022 IEEE.","10.1109/HORA55278.2022.9800084","Conference paper","2022","Artificial intelligence; Augmented reality; Human computer interaction; Interface states; Software design; User centered design; Virtual reality; Artificial intelligence systems; Customisation; Human-artificial intelligence interaction; Human-centred designs; Human-computer interaction; Interaction design; State of the art; User experience (UX); User interface; Users' experiences; User interfaces","Scopus"
"Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications","The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from 'connected things' to 'connected intelligence'. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.  © 1983-2012 IEEE.","10.1109/JSAC.2021.3126076","Article","2022","5G mobile communication systems; Application programs; Computer architecture; Data Analytics; Deep learning; Energy utilization; Job analysis; Network architecture; Quality of service; Wireless networks; 6g; 6g mobile communication; Communication system security; Edge artificial intelligence; Edge inference; Edge training; End to end; End-to-end architecture; Federated learning; Large-scale optimization; Mobile communications; Over the airs; Over-the-air computation; Resources allocation; Service-driven resource allocation; Task analysis; Task-oriented; Task-oriented communication; Resource allocation","Scopus"
"Challenges of Enforcing Regulations in Artificial Intelligence Act - Analyzing Quantity Requirement in Data and Data Governance","To make Artificial Intelligence (AI) systems and services accountable and regulated in the European Union market, in April 2021, the European Union Parliament published a proposal 'Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act)', widely known as Artificial Intelligence Act (AI Act). Since then, many concerns have been raised in terms of compliance and whether the regulations are enforceable. However, to the best of our knowledge, none of them provided an explicit technical analysis of the challenges in enforcing the regulation. Among 85 Articles in the AI Act, we emphasize on the Article 10, the central regulatory requirement for data and data governance. In this paper, we have analyzed a specific requirement, the data quantity, to show the challenges of enforcing this requirement in a principled way. In our analysis, we have used deep learning modeling and machine learning generalization theory. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)","","Conference paper","2022","Laws and legislation; Learning systems; Artificial intelligence act; Artificial intelligence systems; Creative Commons; Data governances; Deep learning modeling; European union; Future technologies; Generalisation; Generalization theory; Learning models; Deep learning","Scopus"
"Onto4MAT: A Swarm Shepherding Ontology for Generalized Multiagent Teaming","Research in multi-agent teaming has increased substantially over recent years. Underneath these attempts sits a suite of communication functions to enable effective teaming. The Artificial Intelligence (AI) systems supporting the teaming arrangement have primarily relied on knowledge-based systems, with rules triggered based on the mode of interaction. Enabling humans to join the team of AI agents effectively calls for both the humans and AI agents to share their understanding and representation of their shared worlds. Such shared understanding requires formal representations of concepts to support transparency during bi-directional communications between team members. Little research has been done in this space, especially when humans need to team with a swarm of agents. We present an ontology designed specifically for human-agent teaming to address this research gap. The ontology is general, but we then contextualise it into a particular swarm-shepherding scenario to illustrate its use in a particular context. The proposed Ontology for Generalised Multi-Agent Teaming Onto4MAT offers the underlying building blocks for effective communication and shared understanding between humans and multi-agent teams.  © 2013 IEEE.","10.1109/ACCESS.2022.3180032","Article","2022","Autonomous agents; Intelligent agents; Intelligent robots; Job analysis; Knowledge based systems; Multi agent systems; Swarm intelligence; Human-swarm teaming; Multi agent; Multi-agent teaming; Ontology's; Robot kinematics; Shepherding; Situational understanding; Task analysis; Teamwork; Ontology","Scopus"
"Boosting the Federation: Cross-Silo Federated Learning without Gradient Descent","Federated Learning has been proposed to develop better AI systems without compromising the privacy of final users and the legitimate interests of private companies. Initially deployed by Google to predict text input on mobile devices, FL has been deployed in many other industries. Since its introduction, Federated Learning mainly exploited the inner working of neural networks and other gradient descent-based algorithms by either exchanging the weights of the model or the gradients computed during learning. While this approach has been very successful, it rules out applying FL in contexts where other models are preferred, e.g., easier to interpret or known to work better. This paper proposes FL algorithms that build federated models without relying on gradient descent-based methods. Specifically, we leverage distributed versions of the AdaBoost algorithm to acquire strong federated models. In contrast with previous approaches, our proposal does not put any constraint on the client-side learning models. We perform a large set of experiments on ten UCI datasets, comparing the algorithms in six non-iidness settings. © 2022 IEEE.","10.1109/IJCNN55064.2022.9892284","Conference paper","2022","Gradient methods; Large dataset; Learning systems; AI systems; Boosting; Cross-silo; Ensemble learning; Federated learning; Google+; Gradient-descent; Neural-networks; Private companies; Text input; Adaptive boosting","Scopus"
"Deriving Design Principles for AI-Adaptive Learning Systems: Findings from Interviews with Experts","AI applications are increasing in the field of education, from laboratory set-ups to contemporary and complex learning systems. A great example of such systems is AI-enabled adaptive learning systems (AI-ALS) that promote adaptive learning. Despite its promised potential, there are challenges such as design issues, highly complex models, and lack of evidence-based guidelines and design principles that hinder the large-scale adoption and implementation of AI-ALS. The goal of this paper thus is to establish a set of empirically grounded design principles (DPs) of AI-ALS, that would serve well in a university context. 22 interviews were con-ducted with experts knowledgeable about the design and development of AI-ALS. Several rounds of coding and deep analysis of the expert interviews revealed features and functionalities of AI-ALS; purposes for designing and using AI-ALS; and recommended improvements for AI-ALS as requirements. These requirements were translated to 13 preliminary DPs. The findings of this study serve as a guide on how to better design AI-ALS, that will improve the learning experiences of students. © 2022, IFIP International Federation for Information Processing.","10.1007/978-3-031-15342-6_7","Conference paper","2022","Artificial intelligence; Education computing; Adaptive learning; Adaptive learning systems; AI applications; AIEd; Complex learning; Complex model; Design issues; Design Principles; Evidence-based; Set-ups; Learning systems","Scopus"
"Research and development of the clinical thinking mining and discovery system based on artificial intelligence","An AI-based clinical thinking mining discovery system that can be used on PCs and mobile terminals (cell phones, pads, etc.). The system utilizes artificial intelligence technology to obtain massive medical case data and case discussions from the Internet for data extraction and organization, and intelligently classifies them by disease type and clinical presentation. Using natural language processing technology and intelligent mapping mechanism of medical terms, it mines the information of clinical features, tests, inspections, disposal measures and reasons (drugs, surgeries, etc.) of the extracted cases, abstracts and visualizes the diagnostic rules and clinical treatment channels of the cases. The medical case data processed on the Internet will be combined with the typical case data in the HIS system to form a clinical knowledge repository of diseases, guide junior doctors and students to conduct clinical thinking training and consolidate medical knowledge.  © The Authors.","10.1117/12.2637407","Conference paper","2022","Clinical research; Diagnosis; Natural language processing systems; Artificial intelligence technologies; Cell phone; Clinical thinking; Data extraction; Data organization; Discovery systems; Medical case; Mining systems; Mobile terminal; Research and development; Artificial intelligence","Scopus"
"Software engineering for Responsible AI: An empirical study and operationalised patterns","AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.  © 2022 IEEE.","10.1109/ICSE-SEIP55303.2022.9793864","Conference paper","2022","Ethical technology; Learning systems; Machine learning; Risk assessment; AI systems; Continual learning; Cross-cutting; Current practices; Empirical studies; Machine-learning; Responsible AI; Risks assessments; Scientists and engineers; System output; Software architecture","Scopus"
"AI Models and Methods in Automotive Manufacturing: A Systematic Literature Review","While artificial intelligence (AI) experienced an increasing interest in industry during the past decade, the true potential and applicability of AI for automotive original equipment manufacturers (OEMs) and suppliers in real-world scenarios have not been clearly understood. Most applications of AI focus on the development of connected and autonomous cars, rather than the optimisation of automotive operations and manufacturing processes. This work, therefore, bridged this gap and shed light on the topic of AI in the context of automotive manufacturing and Industry 4.0. It aimed to promote understanding and provide up-to-date insights on specific models and methods of AI, applications that have been achieved with best practices as well as the problems that were encountered, underpinned with possible future prospects. A systematic literature review approach was adopted to ensure broad and thorough coverage of current knowledge and the identification of relevant literature on the topic. The literature search was confined to papers that were published from 2015 onwards using the databases of IEEE and ScienceDirect as primary sources, with a three-keyword search phrase to narrow down the results and increase specificity. A total of 359 papers were identified and subsequently screened for eligibility, of which 84 papers were selected for quantitative and 79 papers for qualitative analysis. The results of the quantitative analysis confirmed that the topic has markedly increased in significance, with a mere 3 papers published in 2015 and 33 papers in 2021. The majority of papers dealt with solving problems in production (39.29%), quality (35.71%) and assembly (16.67%), whereas supply chain (5.95%) and business intelligence (2.38%) were inadequately represented. The results of the qualitative analysis revealed that machine learning methods dominate current research and automotive applications, with neural networks as the most used out of more than 70 identified models. The industrial applicability was confirmed by many use cases including quality inspection, robot assembly, human–robot collaboration, material demand prediction or AI-enabled manufacturing decision making. The problems of such applications were mainly attributed to data availability and quality, model development and gaps in simulation, system integration, the complexity of automotive processes, the physical conditions of the system environment and dynamic change. For industrial applications it is thus recommended to further optimise AI methods and models, enabling a wider system integration by harvesting the potential of big data and both edge and cloud computing. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-14748-7_1","Book chapter","2022","","Scopus"
"Social sustainability in the e-health domain via personalized and self-adaptive mobile apps","Within software engineering, social sustainability is the dimension of sustainability that focuses on the ""support of current and future generations to have the same or greater access to social resources by pursuing social equity."" An important domain that strives to achieve social sustainability is e-Health, and more recently e-Health mobile apps.A wealth of e-Health mobile apps is available for many purposes, such as lifestyle improvement and mental coaching. The interventions, prompts, and encouragements of e-Health apps sometimes take context into account (e.g., previous interactions or geographical location of the user), but they still tend to be rigid, e.g., apps use fixed sets of rules or they are not sufficiently tailored toward individuals' needs. Personalization to the different users' characteristics and run-time adaptation to their changing needs and context provide a great opportunity for getting users continuously engaged and active, eventually leading to better physical and mental conditions. This chapter presents a reference architecture for enabling AI-based personalization and self-adaptation of mobile apps for e-Health. The reference architecture makes use of a dedicated goal model and multiple MAPE loops operating at different levels of granularity and for different purposes. The proposed reference architecture is instantiated in the context of a fitness-based mobile application and exemplified through a series of typical usage scenarios extracted from our industrial collaborations. © Springer Nature Switzerland AG 2021. All rights reserved.","10.1007/978-3-030-69970-3_13","Book chapter","2021","","Scopus"
"Educating AI Software Engineers: Challenges and Opportunities","To properly develop, test und use Artificial Intelligence (AI) applications, students and professionals need a well-defined AI software engineering (AISE) process and the appropriate tools. However, AISE, which is today mainly based on the use of deep learning (DL) neural networks, is still under development. This makes the education of AI software engineers particularly challenging, since there are no well-established methodologies, tools and practices, like in traditional Software Engineering (SE) education drawing on decades of experience and methods in all phases of software development, from requirements analysis over design and implementation to integration and testing. We analyze the main differences between traditional SE and AISE education and address challenges in AISE education. Our methodology is based on literature survey, analysis of own industry experience and statistical analysis of students works on AI applications. Our goal is to provide guidelines for an AISE process and propose a curriculum path for AISE education, which can be used to update a traditional SE curriculum. According to results of our analysis, the main challenges for the students are: Dealing with data and taking into account that algorithms change (learn) by data, selection and re-use of AI algorithms, model test, maintenance and automatizing the AISE process. We propose to address these challenges in SE curricula by teaching more statistical thinking with connections to software development, developing re-engineering capabilities, teaching a model-based AI approach and combining AI with virtual reality simulations. In the whole process, we consider an optimal division of work between humans and AI systems by explicitly including humans in the AISE loop. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-93907-6_26","Conference paper","2022","","Scopus"
"Autoencoder-based semantic novelty detection: Towards dependable ai-based systems","Many autonomous systems, such as driverless taxis, perform safety-critical functions. Autonomous systems employ artificial intelligence (AI) techniques, specifically for environmental per-ception. Engineers cannot completely test or formally verify AI-based autonomous systems. The accuracy of AI-based systems depends on the quality of training data. Thus, novelty detection, that is, identifying data that differ in some respect from the data used for training, becomes a safety measure for system development and operation. In this study, we propose a new architecture for autoencoder-based semantic novelty detection with two innovations: architectural guidelines for a semantic autoencoder topology and a semantic error calculation as novelty criteria. We demonstrate that such a semantic novelty detection outperforms autoencoder-based novelty detection approaches known from the literature by minimizing false negatives. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11219881","Article","2021","","Scopus"
"A pluralist hybrid model for moral AIs","With the increasing degrees AIs and machines, the need for implementing ethics in AIs is pressing. In this paper, we first survey current approaches to moral AIs and their inherent limitations. Then we propose the pluralist hybrid approach and show how these limitations of moral AIs can be partly alleviated by the pluralist hybrid approach. The core ethical decision-making capacity of an AI based on the pluralist hybrid approach consists of two systems. The first is a deterministic algorithm system that embraces different moral rules for making explicit moral decisions. The second is a machine learning system that accounts for calculating the value of the variables required by the application of moral principles. The pluralist hybrid system is better than the existing proposals as it better addresses the moral disagreement problem of the top-down approach by including distinct moral principles. Besides, the pluralist hybrid system reduces the opacity of ethical decision-making by implementing explicit moral principles for moral decision-making. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00146-022-01601-0","Article","2022","Decision making; Learning systems; Opacity; Philosophical aspects; Transparency; 'current; Deterministic algorithms; Ethical decision making; Hybrid approach; Hybrid model; Inherent limitations; Moral AI; Moral disagreement problem; Opacity problem; Pressung; Hybrid systems","Scopus"
"Actionable Recommendations for Small Businesses With Hybrid AI","We present a business use case for computing actionable recommendations for SMBs to prevent near-future or existing critical situations for which a Hybrid AI solution seems more promising than a pure Machine Learning or a pure Symbolic AI solution. For one of the most common of such critical situations, namely, insufficient operating funds, we provide details on the complexity of the problem as well as the requirements on actionable recommendations. We argue why the requirements cannot be satisfied by an end-to-end Machine Learning or Symbolic AI system. We show a breakdown of the monolith into sub-problems, and justify the selection of the most appropriate AI technique for each component, in particular, Machine Learning, Symbolic Rules, and Mathematical Optimization. We also discuss some of the challenges industry would face when adopting Hybrid AI solutions. © 2022 Copyright for this paper by its authors","","Conference paper","2022","Machine learning; AI systems; AI techniques; End to end; Machine-learning; Mathematical optimizations; Rule optimization; Small business; Sub-problems; Optimization","Scopus"
"User Experience Design for Defense Systems with AI","As artificial intelligence (AI) is applied at an increasing frequency in various fields, the number of studies on the user experience (UX) design of human-AI interaction is also increasing. However, the results of these studies on AI UX design principles are insufficient for actual AI systems. In light of this fact, the purpose of this study was to upgrade the UX design of a defense system that uses AI technology to detect land changes and targets. In order to upgrade the UX design of this AI system, a three-step procedure was executed. First, AI UX principles were derived by analyzing literature related to human-AI interaction. Second, ideation was performed to improve the interface. Finally, the results of the ideation were utilized to construct the UX prototype of the AI system with Adobe XD. The results of this study are expected to be used as fundamental data for future research that will develop UX principles and advanced methods for AI systems. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-030-98404-5_23","Conference paper","2022","Artificial intelligence; Design; Network security; Artificial intelligence system design; Artificial intelligence system design process; Artificial intelligence systems; Artificial intelligence usability; Artificial intelligence UX; Defence systems; System design process; User experience design; Users' experiences; Systems analysis","Scopus"
"Data Mining Methods for Modeling in Water Science","One of the most useful research fields with many real-life applications, such as in water science, is the subject of data mining. Data mining (DM) is considered a process to extract valuable data from a wide range of information stored in various databases. The data is categorized into the form of patterns, associations, changes, anomalies and significant structures. In water recourses management and environmental engineering, predicting and modelling parameters play an integral role in decision making. The most critical freshwater water resource for millions of people worldwide are rivers with a dynamic nature (floods/droughts), in terms of available freshwater quantity and quality. With various basin characteristics, river flow and sediment regime may be influenced by natural processes such as erosion and sediment transport as well as anthropogenic factors such as urban stormwater runoff and semi-treated sanitary/industrial sewage discharge. Therefore, artificial intelligence (AI) techniques are used to decrease model development costs and improve prediction errors, achieving more efficient models. In this chapter, some well-known techniques and AI-based methods are introduced, and their applications are elaborated. The models are comprised of extreme learning machine (ELM), least square support vector machine (LSSVM), genetic programming (GP), adaptive neural-fuzzy inference system (ANFIS), and multivariate adaptive regression spline (MARS). Each technique, then, is illustrated with a brief literature review. Having being evaluated in terms of the basic concept, the methods are addressed based on a mathematical statement. In the last part, the pseudocode of the ways, an acceptable guideline for coding the methods, is pointed out. This chapter is collected for graduate students, researchers, educators, and practitioners interested in engineering optimization. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-19-2519-1_8","Book chapter","2022","","Scopus"
"Multimodal Conversational AI A Survey of Datasets and Approaches","As humans, we experience the world with all our senses or modalities (sound, sight, touch, smell, and taste). We use these modalities, particularly sight and touch, to convey and interpret specific meanings. Multimodal expressions are central to conversations; a rich set of modalities amplify and often compensate for each other. A multimodal conversational AI system answers questions, fulfills tasks, and emulates human conversations by understanding and expressing itself via multiple modalities. This paper motivates, defines, and mathematically formulates the multimodal conversational research objective. We provide a taxonomy of research required to solve the objective: multimodal representation, fusion, alignment, translation, and co-learning. We survey state-of-the-art datasets and approaches for each research area and highlight their limiting assumptions. Finally, we identify multimodal co-learning as a promising direction for multimodal conversational AI research. © 2022 Association for Computational Linguistics.","","Conference paper","2022","Computational linguistics; AI systems; Co-learning; Multi-modal; Multimodal expressions; Multiple modalities; Research areas; Research objectives; State of the art; Surveys","Scopus"
"EXPLAINABLE AI AND RESPONSIBLE AI","Chapter 29 relating to Explainable AI and Responsible AI 'sets out' the 'black box'problem. This is so often discussed in the mainstream media now that it has become a cliché. The book, and this chapter in particular, unpicks the cliché. Part of this involves education on how AI systems operate, how XAI works, how rules and standards operate in the context of AI, and how to apply ethical considerations to AI. The chapter includes explanations of explainability (!) and points the way towards toolkits to be used in practice. © The Editor and Contributors Severally 2022. All rights reserved.","10.4337/9781800371729.00043","Book chapter","2022","","Scopus"
"Legal evaluation of the attacks caused by artificial intelligence-based lethal weapon systems within the context of Rome statute","Artificial intelligence (AI) as of the level of development reached today has become a scientific reality that is subject to study in the fields of law, political science, and other social sciences besides computer and software engineering. AI systems which perform relatively simple tasks in the early stages of the development period are expected to become fully or largely autonomous in the near future. Thanks to this, AI which includes the concepts of machine learning, deep learning, and autonomy, has begun to play an important role in producing and using smart arms. However, questions about AI-Based Lethal Weapon Systems (AILWS) and attacks that can be carried out by such systems have not been fully answered under legal aspect. More particularly, it is a controversial issue who will be responsible for the actions that an AILWS has committed. In this article, we discussed whether AILWS can commit offense in the context of the Rome Statute, examined the applicable law regarding the responsibility of AILWS, and tried to assess whether these systems can be held responsible in the context of international law, crime of aggression, and individual responsibility. It is our finding that international legal rules including the Rome Statute can be applied regarding the responsibility for the act/crime of aggression caused by AILWS. However, no matter how advanced the cognitive capacity of an AI software, it will not be possible to resort to the personal responsibility of this kind of system since it has no legal personality at all. In such a case, responsibility will remain with the actors who design, produce, and use the system. Last but not least, since no AILWS software does have specific codes of conduct that can make legal and ethical reasonings for today, at the end of the study it was recommended that states and non-governmental organizations together with manifacturers should constitute the necessary ethical rules written in software programs to prevent these systems from unlawful acts and to develop mechanisms that would restrain AI from working outside human control. © 2021 The Authors","10.1016/j.clsr.2021.105564","Article","2021","Deep learning; Philosophical aspects; Software engineering; Cognitive capacity; Legal aspects; Legal personality; Nongovernmental organizations; Personal responsibility; Political science; Scientific reality; Software program; Social sciences computing","Scopus"
"Smart Electrically Assisted Bicycles as Health Monitoring Systems: A Review","This paper aims to provide a review of the electrically assisted bicycles (also known as e-bikes) used for recovery of the rider’s physical and physiological information, monitoring of their health state, and adjusting the “medical” assistance accordingly. E-bikes have proven to be an excellent way to do physical activity while commuting, thus improving the user’s health and reducing air pollutant emissions. Such devices can also be seen as the first step to help unhealthy sedentary people to start exercising with reduced strain. Based on this analysis, the need to have e-bikes with artificial intelligence (AI) systems that recover and processe a large amount of data is discussed in depth. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines were used to complete the relevant papers’ search and selection in this systematic review. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s22020468","Review","2022","Accidents, Traffic; Artificial Intelligence; Bicycling; Electricity; Humans; Transportation; Air pollution; Bicycles; Health; Physiology; E-bike; Health monitoring system; Health state; Information monitoring; Intelligent sensors; Monitoring system; Physical activity; Physical information; Physiological informations; Systematic Review; artificial intelligence; cycling; electricity; human; traffic accident; traffic and transport; Monitoring","Scopus"
"Investigating Trust in Human-Machine Learning Collaboration: A Pilot Study on Estimating Public Anxiety from Speech","Trust is a key element in the development of effective collaborative relationships between humans and increasingly complex artificial intelligence (AI) systems. Here, we examine trust in AI in the context of a human-AI partnership that involves a joint decision making task for estimating levels of public speaking anxiety based on speech signals. The AI system is comprised of an explainable machine learning (ML) algorithm, that takes acoustic characteristics as input and outputs the estimate of public speaking anxiety levels, a local explanation about the most important features that contributed to the decision of each speech sample, and a global explanation about the most important features for the data overall. We analyze interactions between AI and human annotators with background in psychological sciences, and measure trust over time via the annotators' agreement with the AI model and the annotators' self-reports. We further examine factors of trust that are related to the characteristics of the human annotator and the ML algorithm. Results indicate that trust in AI depends on the openness level of the annotator and the importance level of input features. Findings from this study can provide guidelines to designing solutions that properly calibrate human trust in AI in collaborative human-AI tasks. © 2021 ACM.","10.1145/3462244.3479926","Conference paper","2021","Decision making; Speech; Artificial intelligence systems; Human-artificial intelligence interaction; Human-machine; Important features; Machine learning algorithms; Machine-learning; Pilot studies; Public speaking; Public speaking anxiety; Trustworthy artificial intelligence; Machine learning","Scopus"
"Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation","Increasing a ML model accuracy is not enough, we must also increase its trustworthiness. This is an important step for building resilient AI systems for safety-critical applications such as automotive, finance, and healthcare. For that purpose, we propose a multi-agent system that combines both machine and human agents. In this system, a checker agent calculates a trust score of each instance (which penalizes overconfidence in predictions) using an agreement-based method and ranks it; then an improver agent filters the anomalous instances based on a human rule-based procedure (which is considered safe), gets the human labels, applies geometric data augmentation, and retrains with the augmented data using transfer learning. We evaluate the system on corrupted versions of the MNIST and FashionMNIST datasets. We get an improvement in accuracy and trust score with just few additional labels compared to a baseline approach. © 2022 IEEE.","10.1109/COMPSAC54236.2022.00014","Conference paper","2022","Safety engineering; AI systems; Data augmentation; Data centric; Human-in-the-loop; Modeling accuracy; Multi agent; Multi-agent approach; Robust AI; Trust; Trust scores; Multi agent systems","Scopus"
"An Introduction to the Principle of Transparency in Automated Decision-Making Systems","Under current European data protection law and the approach of the European Commission regarding artificial intelligence (AI) development, the principle of transparency and explainability by design are essential to protect the data subject's rights and generate confidence in AI systems. However, a closer look reveals that the legal approach ignores limitations of the transparency principle in the practical application of automated-decision making systems. Current transparency rules also require a high standard of transparency in automated decisions due to its potential risks.This paper seeks to analyze the scope of the principle of transparency and its limitations in the practical field, suggesting a division of data subjects to provide automated decision-making explanations according to their level of expertise to reach the transparency principle's goal: user understanding. The paper will address the semantic discussion of whether this objective is achieved through interpretability, explainability, accountability or, transparency in the broad sense. It also maps out the analysis about guidance to address transparency through a certification mechanism, contestability by design, or supplementary post hoc explanations in AI systems. © 2022 Croatian Society MIPRO.","10.23919/MIPRO55190.2022.9803417","Conference paper","2022","Artificial intelligence; Automation; Decision making; Microelectronics; Semantics; 'current; Artificial intelligence systems; Automated decision making; Automated decision making systems; Data protection laws; Data subjects; European Commission; Explicability; GDPR; High standards; Transparency","Scopus"
"Design Principles for (X)AI-based Patient Education Systems","Recently, the management of chronic diseases has advanced to a prime topic for Information Systems (IS) research and practice. With increasing capability of Information Technology, patients are empowered to engage in self-management of chronic diseases connected to promises of health benefits for the individual as well as an unburdening of clinics and economic advantages for health care systems. Nevertheless, patients must be adequately educated about risks, screening and examination options to make patient self-management effective, sustainable and profitable. In this regard, Explainable Artificial Intelligence ((X)AI)-based Patient Education Systems (PES) may be an opportunity to provide patient education in an interactive, intelligible and intelligent manner. By establishing Design Principles (DP) for the engineering of effective (X)AIbased PES, instantiating them in a system prototype and evaluating the DP with the help of general practitioners, this paper contributes to the body of knowledge in designing health IS. © 2022 Gesellschaft fur Informatik (GI). All rights reserved.","","Conference paper","2022","Design; Diagnosis; Diseases; Information management; Chronic disease; Design Principles; Design science; Education systems; Explainable artificial intelligence; Information system research; Information systems practices; Patient adherence; Patient education; Self management; Artificial intelligence","Scopus"
"A Multidisciplinary Survey and Framework for Design and Evaluation of Explainable AI Systems","The need for interpretable and accountable intelligent systems grows along with the prevalence of artificial intelligence (AI) applications used in everyday life. Explainable AI (XAI) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.  © 2021 Association for Computing Machinery.","10.1145/3387166","Article","2021","Design; Human computer interaction; Intelligent systems; Iterative methods; Surveys; Appropriate designs; Artificial intelligence systems; Design and evaluations; Design evaluation; Design goal; Evaluation methods; Explainable artificial intelligence (XAI); Explanation; Human-computer interaction; Machine-learning; Machine learning","Scopus"
"Enhancing Cluster Analysis With Explainable AI and Multidimensional Cluster Prototypes","Explainable Artificial Intelligence (XAI) aims to introduce transparency and intelligibility into the decision-making process of AI systems. Most often, its application concentrates on supervised machine learning problems such as classification and regression. Nevertheless, in the case of unsupervised algorithms like clustering, XAI can also bring satisfactory results. In most cases, such application is based on the transformation of an unsupervised clustering task into a supervised one and providing generalised global explanations or local explanations based on cluster centroids. However, in many cases, the global explanations are too coarse, while the centroid-based local explanations lose information about cluster shape and distribution. In this paper, we present a novel approach called ClAMP (Cluster Analysis with Multidimensional Prototypes) that aids experts in cluster analysis with human-readable rule-based explanations. The developed state-of-the-art explanation mechanism is based on cluster prototypes represented by multidimensional bounding boxes. This allows representing of arbitrary shaped clusters and combines the strengths of local explanations with the generality of global ones. We demonstrate and evaluate the use of our approach in a real-life industrial case study from the domain of steel manufacturing as well as on the benchmark datasets. The explanations generated with ClAMP were more precise than either centroid-based or global ones.  © 2013 IEEE.","10.1109/ACCESS.2022.3208957","Article","2022","Cluster analysis; Data mining; Decision making; Job analysis; Learning algorithms; Learning systems; Supervised learning; Cluster prototype; Clusterings; Decision-making process; Expert’s knowledge; Explainable AI; Features extraction; Machine learning algorithms; Prototype; Shape; Task analysis; Clustering algorithms","Scopus"
"Towards Access Control Models for Conversational User Interfaces","Conversational User Interfaces (CUIs), such as chatbots, are becoming a common component of many software systems and they are evolving in many directions (including advanced features, often powered by AI-based components). However, less attention has been paid to their security aspects, such as access-control, which may pose a clear risk. In this paper, we apply Model-Driven techniques to define more secure CUIs. In particular, we propose a framework to integrate an Access-Control protocol into the CUI specification and implementation through a set of policy rules described using a Domain-Specific Language (DSL) integrated with the core CUI language. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-07475-2_21","Book chapter","2022","Access control; Problem oriented languages; Access control models; Access control protocol; Chatbots; Interface languages; Interface specification; Model-driven techniques; Policy rules; Security aspects; Software-systems; User interfaces","Scopus"
"In AI We Trust? Effects of Agency Locus and Transparency on Uncertainty Reduction in Human-AI Interaction","Artificial intelligence (AI) is increasingly used to make decisions for humans. Unlike traditional AI that is programmed to follow human-made rules, machine-learning AI generates rules from data. These machine-generated rules are often unintelligible to humans. Will users feel more uncertainty about decisions governed by such rules? To what extent does rule transparency reduce uncertainty and increase users' trust? In a 2 × 3 × 2 between-subjects online experiment, 491 participants interacted with a website that was purported to be a decision-making AI system. Three factors of the AI system were manipulated: agency locus (human-made rules vs. machine-learned rules), transparency (no vs. placebic vs. real explanations), and task (detecting fake news vs. assessing personality). Results show that machine-learning AI triggered less social presence, which increased uncertainty and lowered trust. Transparency reduced uncertainty and enhanced trust, but the mechanisms for this effect differed between the two types of AI. © 2021 The Author(s). Published by Oxford University Press on behalf of International Communication Association.","10.1093/jcmc/zmab013","Article","2021","Decision making; Machine learning; Agency attribution; Agency locus; Artificial intelligence systems; Decisions makings; Machine-learning; On-line experiments; Social presence; Trust; Uncertainty; Uncertainty reduction; Transparency","Scopus"
"Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems","Skill routing is an important component in large-scale conversational systems. In contrast to traditional rule-based skill routing, state-of-the-art systems use a model-based approach to enable natural conversations. To provide supervision signal required to train such models, ideas such as human annotation, replication of a rule-based system, relabeling based on user paraphrases, and bandit-based learning were suggested. However, these approaches: (a) do not scale in terms of the number of skills and skill on-boarding, (b) require a very costly expert annotation/rule-design, (c) introduce risks in the user experience with each model update. In this paper, we present a scalable self-learning approach to explore routing alternatives without causing abrupt policy changes that break the user experience, learn from the user interaction, and incrementally improve the routing via frequent model refreshes. To enable such robust frequent model updates, we suggest a simple and effective approach that ensures controlled policy updates for individual domains, followed by an off-policy evaluation for making deployment decisions without any need for lengthy A/B experimentation. We conduct various offline and online A/B experiments on a commercial large-scale conversational system to demonstrate the effectiveness of the proposed method in real-world production settings. © 2022 Association for Computational Linguistics.","","Conference paper","2022","Computational linguistics; AI systems; Conversational systems; Large-scales; Model updates; Routings; Rule based; Self-learning; State-of-the-art system; System use; Users' experiences; Learning systems","Scopus"
"Constrained plasticity reserve as a natural way to control frequency and weights in spiking neural networks","Biological neurons have adaptive nature and perform complex computations involving the filtering of redundant information. However, most common neural cell models, including biologically plausible, such as Hodgkin–Huxley or Izhikevich, do not possess predictive dynamics on a single-cell level. Moreover, the modern rules of synaptic plasticity or interconnections weights adaptation also do not provide grounding for the ability of neurons to adapt to the ever-changing input signal intensity. While natural neuron synaptic growth is precisely controlled and restricted by protein supply and recycling, weight correction rules such as widely used STDP are efficiently unlimited in change rate and scale. The present article introduces new mechanics of interconnection between neuron firing rate homeostasis and weight change through STDP growth bounded by abstract protein reserve, controlled by the intracellular optimization algorithm. We show how these cellular dynamics help neurons filter out the intense noise signals to help neurons keep a stable firing rate. We also examine that such filtering does not affect the ability of neurons to recognize the correlated inputs in unsupervised mode. Such an approach might be used in the machine learning domain to improve the robustness of AI systems. © 2021 Elsevier Ltd","10.1016/j.neunet.2021.08.016","Article","2021","Action Potentials; Algorithms; Models, Neurological; Neural Networks, Computer; Neuronal Plasticity; Neurons; Abstracting; Biomimetics; Information filtering; Neural networks; Proteins; Adaptive Control; Bio-inspired cognitive architecture; Biological neuron; Control frequency; Firing rates; Neural homeostasis; Neural-networks; Plasticity reserves; Spike timing dependent plasticities; Synaptic scaling; algorithm; Article; artificial intelligence; dendrite; firing rate; homeostasis; machine learning; model; nerve cell plasticity; spike timing dependent plasticity; spiking neural network; action potential; biological model; nerve cell; nerve cell plasticity; Neurons","Scopus"
"Explainable Clinical Decision Support: Towards Patient-Facing Explanations for Education and Long-Term Behavior Change","There is an increasing shift towards the self-management of long-term chronic illness by patients in a home setting, supported by personal health electronic equipment. Among others, self-management requires comprehensive education on the illness, i.e., understanding the effects of nutritional, fitness, and medication choices on personal health; and long-term health behavior change, i.e., modifying unhealthy lifestyles that contribute to chronic illness. Smart health recommendations, generated using AI-based Clinical Decision Support (CDS), can guide patients towards positive nutritional, fitness, and health behavioral choices. Moreover, we posit that explaining these recommendations to patients, using Explainable AI (XAI) techniques, will effect education and positive behavior change. We present our work towards an explanation framework for rule-based CDS, called EXPLAIN (EXPLanations of AI In N3), which aims to generate human-readable, patient-facing explanations. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-09342-5_6","Conference paper","2022","Decision support systems; Diseases; Facings; Oscillators (electronic); Behaviour changes; Chronic illness; Clinical decision support; Explainable AI; Health behaviors; Long-term behavior; Personal health; Rule based; Self management; Semantic-Web; Semantic Web","Scopus"
"The Problem of Analyzing Data Models in Non-Euclidean Spaces in Artificial Intelligence Systems","This article provides an overview of the problems of analyzing data models in non-Euclidean spaces in artificial intelligence systems. Both clustering and classification of information as methods of data analysis are widely used in AI systems. When working with Euclidean space, we do not always get the result that is correct for us in one context or another, so we use non-Euclidean spaces, the result of which satisfies us more. When working with these spaces, we face various problems, one of which is the lack of clear rules for measuring the distance, finding the length between points, selecting the right coordinates so that it is easier to straighten the segment and subsequently work with the analyzed information. © 2022 IEEE.","10.1109/ElConRus54750.2022.9755848","Conference paper","2022","Geometry; Machine learning; AI systems; Artificial intelligence systems; Clusterings; Euclidean spaces; Machine learning methods; Methods of data analysis; Non-Euclidean spaces; Riemannian manifold; Classification (of information)","Scopus"
"AI-based Academic Advising Framework: A Knowledge Management Perspective","Academic advising has become a critical factor of students’ success as universities offer a variety of programs and courses in their curriculum. It is a student-centered initiative that fosters a student’s involvement with the institution by supporting students in their academic progression and career goals. Managing the knowledge involved in the advising process is crucial to ensure that the knowledge is available to those who need it and that it is used effectively to make good advising decisions that impact student persistence and success. The use of AI-based tools strengthens the advising process by reducing the workload of advisors and providing better decision support tools to improve the advising practice. This study explores the challenges associated with the current advising system from a knowledge management perspective and proposes an integrated AI-based framework to tackle the main advising tasks. © 2022, International Journal of Advanced Computer Science and Applications. All rights reserved.","10.14569/IJACSA.2022.0130823","Article","2022","Decision support systems; Expert systems; Machine learning; Students; Academic advising; Career goals; Chatbots; Conversational agents; Critical factors; Machine-learning; Rule-based expert system; Student persistences; Student success; Student-centred; Knowledge management","Scopus"
"CASTLE: Cluster-aided space transformation for local explanations","With Artificial Intelligence becoming part of a rapidly increasing number of industrial applications, more and more requirements about their transparency and trustworthiness are being demanded to AI systems, especially in military, medical and financial domains, where decisions have a huge impact on lives. In this paper, we propose a novel model-agnostic Explainable AI (XAI) technique, named Cluster-aided Space Transformation for Local Explanation (CASTLE), able to provide rule-based explanations based on both the local and global model's workings, i.e. its detailed ”knowledge” in the neighborhood of the target instance and its general knowledge on the training dataset, respectively. The framework has been evaluated on six datasets in terms of temporal efficiency, cluster quality and model significance. Eventually, we asked 36 users to evaluate the explainability of the framework, getting as result an increase of interpretability of 6% with respect to another state-of-the-art technique, named Anchors. © 2021 Elsevier Ltd","10.1016/j.eswa.2021.115045","Article","2021","Learning systems; Military applications; Quality control; AI systems; Clusterings; Explainable artificial intelligence; Financial domains; Local model; Machine-learning; Medical domains; Military domains; Rule based; Space transformations; Artificial intelligence","Scopus"
"Using the Strategy Design Pattern for Hybrid AI System Design","The idea of design patterns originated in the architecture domain, subsequently shaped the standardization and communication of object-oriented system design for IT architectures, and facilitated the description of best practices in business process design. Recently, the idea of design patterns not only stipulated an initial collection and classification of machine learning patterns, but has also been used to structure and document machine learning based systems from a traditional software engineering perspective. We promote the idea of using design patterns as a general means to visualize the design of hybrid AI systems and present how the strategy design pattern in particular can be used for a passenger counting system by switching the implementation strategies from a standard YOLOv5 based object recognition with Deep Sort tracking to a customized head-based YOLOv5 detection in combination with a customized Deep Sort tracking strategy. In our example, the newly presented human head detector and tracker could significantly improve the overall accuracy of passenger counting in dense and crowded situations. Furthermore, we show, how rule-based symbolic decisions can be allocated to an abstractstrategy class, while the sub-symbolic machine learning task is delegated to the most appropriate person- or head-based ConcreteStrategy class during run-time. © 2022 Copyright for this paper by its authors","","Conference paper","2022","Deep learning; Design; Information retrieval systems; Object oriented programming; Object recognition; Software engineering; AI systems; Combining rule and machine learning; Combining rules; Deep sort; Design Patterns; Hybrid AI; Passenger counting; Strategy designs; UML; YOLOv5; Systems analysis","Scopus"
"Machine Learning Methods for Enhanced Cyber Security Intrusion Detection System","In the ever-changing world of information security, networks had expanded in scale and complexity that integrates wide range of business functions, intrusion threats have increased in occurrence and intelligence. Network administrators and vendors are now moving beyond conventional Intrusion-Detection Systems (IDS), that only identify problems after they have occurred, to a novel, constructive approach termed Artificial Intelligence (AI) based intrusion detection system. Conventional network Intrusion Detection Systems and firewalls are usually preconfigured to spot malicious network attacks. Now-a-days attackers have become profounder and can try evading common detection rules. There are a few targeted areas where Artificial Intelligence will distribute the extreme evolution for Cybersecurity. To design a proactive defence mechanism, the system has to understand the intelligence of threats that are currently targeting the organization. The implementation of Machine Learning (ML) and threat intelligent-based solutions into blend can revolutionize the landscape in cyber security industry against any kinds of network attacks. Machine Learning is an application of AI that uses a system which is capable of learning from experience. Even in the era of extremely large amount of data and cybersecurity skill shortage, ML can aid in solving the most common tasks including regression, prediction, and classification. In this chapter, the origin and evolution of IDS has been described, followed by the classification of IDS. This chapter will provide a truly interactive learning experience to help and prepare the researchers for the challenges in traditional IDS and the contributions of ML in IDS. This comprehensive review briefs the prominent current works, and an outline of the datasets frequently used for evaluation purpose. Moreover, this chapter will also describe the Collaborative Intrusion Detection that enhances the Big Data Security. Finally, it presents the IDS research issues and challenges; and the skills that need to survive and thrive in today’s threat-ridden and target-rich cyber environment. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-87049-2_27","Book chapter","2022","","Scopus"
"Ethics of automated vehicles: breaking traffic rules for road safety","In this paper, we explore and describe what is needed to allow connected and automated vehicles (CAVs) to break traffic rules in order to minimise road safety risk and to operate with appropriate transparency (according to recommendation 4 in Bonnefon et al., European Commission, 2020). Reviewing current traffic rules with particular reference to two driving situations (speeding and mounting the pavement), we illustrate why current traffic rules are not suitable for CAVs and why making new traffic rules specifically for CAVs would be inappropriate. In defining an alternative approach to achieving safe CAV driving behaviours, we describe the use of ethical goal functions as part of hybrid AI systems, suggesting that functions should be defined by governmental bodies with input from citizens and stakeholders. Ethical goal functions for CAVs would enable developers to optimise driving behaviours for safety under conditions of uncertainty whilst allowing for differentiation of products according to brand values. Such functions can differ between regions according to preferences for safety behaviours within that region and can be updated over time, responding to continual socio-technological feedback loops. We conclude that defining ethical goal functions is an urgent and necessary step from governmental bodies to enable the safe and transparent operation of CAVs and accelerate the reduction in road casualties they promise to achieve. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","10.1007/s10676-021-09614-x","Article","2021","Accident prevention; Automation; Automobile bodies; Motor transportation; Roads and streets; 'current; Automated vehicles; Breakings; Driving; Driving behaviour; European Commission; Goal functions; Road safety; Safety risks; Traffic rules; Philosophical aspects","Scopus"
"Machine Learning Approaches with Automated Sleep Staging System based on Two-Layer Heterogeneous Ensemble Learning Stacking Model","Sleep is an essential requirement for human health and well-being, but many people face sleep problems. These problems can lead to several neurological and physical disorders and adversely affect the overall quality of life. Artificial intelligence (AI)based methods for automated sleep stage classification is a fundamental approach to evaluating and treating this public health challenge.The main contribution of this research work is to develop an Automated Sleep Staging System based on Two-Layer Heterogeneous Ensemble Learning Stacking Model (ASSS-TL-HELSM) for sleep staging under the American Academy of Sleep Medicine (AASM) sleep scoring rules. The main aim of this model is to enhance sleep staging accuracy, reduce overfitting and handle overdrift. For signal preprocessing, we use two different feature selection techniques, Fisher Score (FS), and ReliefF (ReF). For feature extraction, we obtain a total of 28 features.The proposed model analyzes the sleep behavior of the subject using the seasonal and trend components. Sleep recordings from two different subgroups of Institute of Systems and Robotics University of Coimbra (ISRUC-Sleep) were obtained for our experiments.Compared with recent studies using single-channel electro encephalogram (EEG) signals, our proposed ASSS-TL-HELSM model shows the best sleep staging classification accuracy performance on a five sleep stages classification (SC-5) task. The overall classification accuracy is 97.93%, and 97% for features selected through FS and ReF respectively, with the subgroup-I(SG-I) data; similarly, for the subgroup-III(SG-III) data, the features selected through FS, and ReF show a classification accuracy of 98.16% and 98.78% respectively. The comparisons between the proposed model and the existing model show that the proposed model gives better sleep staging accuracy for the five-sleep state's classification. © 2022 University of Bahrain. All rights reserved.","10.12785/ijcds/110159","Article","2022","","Scopus"
"Public procurement of artificial intelligence systems: new risks and future proofing","Public entities around the world are increasingly deploying artificial intelligence (AI) and algorithmic decision-making systems to provide public services or to use their enforcement powers. The rationale for the public sector to use these systems is similar to private sector: increase efficiency and speed of transactions and lower the costs. However, public entities are first and foremost established to meet the needs of the members of society and protect the safety, fundamental rights, and wellbeing of those they serve. Currently AI systems are deployed by the public sector at various administrative levels without robust due diligence, monitoring, or transparency. This paper critically maps out the challenges in procurement of AI systems by public entities and the long-term implications necessitating AI-specific procurement guidelines and processes. This dual-prong exploration includes the new complexities and risks introduced by AI systems, and the institutional capabilities impacting the decision-making process. AI-specific public procurement guidelines are urgently needed to protect fundamental rights and due process. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00146-022-01572-2","Article","2022","Artificial intelligence; Decision making; Algorithmic accountability; Algorithmics; Artificial intelligence governance; Artificial intelligence systems; Decision-making systems; Due process; Human rights; Public entities; Public procurement; Public sector; Transparency","Scopus"
"How artificial intelligence can help us ‘Choose Wisely’","The overuse of low value medical tests and treatments drives costs and patient harm. Efforts to address overuse, such as Choosing Wisely campaigns, typically rely on passive implementation strategies- a form of low reliability system change. Embedding guidelines into clinical decision support (CDS) software is a higher leverage approach to provide ordering suggestions through an interface embedded within the clinical workflow. Growth in computing power is increasingly enabling artificial intelligence (AI) to augment such decision making tools. This article offers a roadmap of opportunities for AI-enabled CDS to reduce overuse, which are presented according to a patient’s journey of care. © 2021, The Author(s).","10.1186/s42234-021-00066-8","Article","2021","","Scopus"
"Are AI systems biased against the poor? A machine learning analysis using Word2Vec and GloVe embeddings","Among the myriad of technical approaches and abstract guidelines proposed to the topic of AI bias, there has been an urgent call to translate the principle of fairness into the operational AI reality with the involvement of social sciences specialists to analyse the context of specific types of bias, since there is not a generalizable solution. This article offers an interdisciplinary contribution to the topic of AI and societal bias, in particular against the poor, providing a conceptual framework of the issue and a tailor-made model from which meaningful data are obtained using Natural Language Processing word vectors in pretrained Google Word2Vec, Twitter and Wikipedia GloVe word embeddings. The results of the study offer the first set of data that evidences the existence of bias against the poor and suggest that Google Word2vec shows a higher degree of bias when the terms are related to beliefs, whereas bias is higher in Twitter GloVe when the terms express behaviour. This article contributes to the body of work on bias, both from and AI and a social sciences perspective, by providing evidence of a transversal aggravating factor for historical types of discrimination. The evidence of bias against the poor also has important consequences in terms of human development, since it often leads to discrimination, which constitutes an obstacle for the effectiveness of poverty reduction policies. © 2022, The Author(s).","10.1007/s00146-022-01494-z","Article","2022","Abstracting; Behavioral research; Machine learning; Natural language processing systems; Social networking (online); AI systems; Bias; Conceptual frameworks; Embeddings; Google+; Language processing; Machine-learning; Natural languages; Poverty; Tailor made models; Embeddings","Scopus"
"Assurance Cases as Foundation Stone for Auditing AI-Enabled and Autonomous Systems: Workshop Results and Political Recommendations for Action from the ExamAI Project","The European Machinery Directive and related harmonized standards do consider that software is used to generate safety-relevant behavior of the machinery but do not consider all kinds of software. In particular, software based on machine learning (ML) are not considered for the realization of safety-relevant behavior. This limits the introduction of suitable safety concepts for autonomous mobile robots and other autonomous machinery, which commonly depend on ML-based functions. We investigated this issue and the way safety standards define safety measures to be implemented against software faults. Functional safety standards use Safety Integrity Levels (SILs) to define which safety measures shall be implemented. They provide rules for determining the SIL and rules for selecting safety measures depending on the SIL. In this paper, we argue that this approach can hardly be adopted with respect to ML and other kinds of Artificial Intelligence (AI). Instead of simple rules for determining an SIL and applying related measures against faults, we propose the use of assurance cases to argue that the individually selected and applied measures are sufficient in the given case. To get a first rating regarding the feasibility and usefulness of our proposal, we presented and discussed it in a workshop with experts from industry, German statutory accident insurance companies, work safety and standardization commissions, and representatives from various national, European, and international working groups dealing with safety and AI. In this paper, we summarize the proposal and the workshop discussion. Moreover, we check to which extent our proposal is in line with the European AI Act proposal and current safety standardization initiatives addressing AI and Autonomous Systems. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-18158-0_21","Conference paper","2022","Artificial intelligence; Insurance; Machinery; Security systems; Standardization; Assurance case; Autonomous system; Harmonized standards; Integrity levels; Machine-learning; On-machines; Safety concepts; Safety integrity; Safety measures; Safety standard; Accident prevention","Scopus"
"First steps in the development of a support application for easy-to-read adaptation","The application of the easy-to-read (E2R) methodology is one of the ways to achieve cognitive accessibility and specifically, it is a path that guarantees the right of access to information of people with reading comprehension difficulties and thus improves their daily life. This methodology includes a set of guidelines and recommendations whose goal is to present clear and easily understood documents. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. These processes are very time and human-resource consuming, due to the need of involving E2R experts as well as people with cognitive disabilities. In order to alleviate such manual processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to support the E2R adaptation of documents in a (semi)-automatic fashion. The main goal of this research is to help E2R experts in their daily tasks of (a) assessing a particular document with respect to the E2R guidelines and (b) transforming such a document according to the E2R methodology. In this paper we present our initial efforts toward the development of an AI-based application for supporting the E2R adaptation of documents. These efforts are the elicitation of E2R needs and informal requirements and the design of an application called FACILE. © 2022, The Author(s).","10.1007/s10209-022-00946-z","Article","2022","Artificial intelligence techniques; Cognitive accessibility; Cognitive disability; Daily lives; Daily tasks; Easy-to-read methodology; Informal requirements; Manual process; Reading comprehension; Semi-automatics; Artificial intelligence","Scopus"
"Questioning the EU proposal for an Artificial Intelligence Act: The need for prohibitions and a stricter approach to biometric surveillance","Artificial Intelligence (AI)-based surveillance technologies such as facial recognition, emotion recognition and other biometric technologies have been rapidly introduced by both public and private entities all around the world, raising major concerns about their impact on fundamental rights, the rule of law and democracy. This article questions the efficiency of the European Commission's Proposal for Regulation of Artificial Intelligence, known as the AI Act, in addressing the threats and risks to fundamental rights posed by AI biometric surveillance systems. It argues that in order to meaningfully address risks to fundamental rights the proposed classification of these systems should be reconsidered. Although the draft AI Act acknowledges that some AI practices should be prohibited, the multiple exceptions and loopholes should be closed, and in addition new prohibitions, in particular to emotional recognition and biometric categorisation systems, should be added to counter AI surveillance practices violating fundamental rights. The AI Act should also introduce stronger legal requirements, such as third-party conformity assessment, fundamental rights impact assessment, transparency obligations as well as enhance existing EU data protection law and the rights and remedies available to individuals, thus not missing the unique opportunity to adopt the first legal framework that truly promotes trustworthy AI.  © 2022-The authors. Published by IOS Press.","10.3233/IP-211524","Article","2022","","Scopus"
"Trustworthy Artificial Intelligence and its use by Law Enforcement Authorities: where do we stand?","From all kinds of industry, communication, education, banking, government, service, manufacturing, medical, and more, Artificial Intelligence (hereinafter: AI) applications may be found in many sectors of our life. Public safety and criminal justice are gaining advantages thanks to artificial intelligence. For example, traffic safety systems detect infractions and alert authorities. AI is also assisting in the identification of criminals. As a public safety resource, AI is being researched in a number of ways. Face recognition is becoming increasingly popular as an AI application in both the public and private sectors. For law enforcement authorities, AI applications boost efficiency, promote data-driven processes, and extend capabilities. AI technology can help law enforcement agencies make judgments and complete tasks in general. They can strengthen data-driven procedures, increase efficiency, or extend capabilities for specific activities or choices. However, recognized human rights as adjudicated by European Convention of Human Rights are calling for caution in the development and usage of AI within the European Union. Fair Trials and 114 civil society organizations have launched a collective statement to call for an Artificial Intelligence Act which foregrounds fundamental rights in November 2021. This Act is under preparation in the EU. Ethics Guidelines for Trustworthy AI from 2019, by High Level Expert Group on Artificial intelligence set up by the European Commission, (hereinafter: Ethical Guidelines) are underlining how it is necessary to develop, deploy and use trustworthy AI systems in a way that adheres to the ethical principles of: respect for human autonomy, prevention of harm, fairness and explicability. European Parliament Resolution of 6 October 2021 on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (hereinafter: Resolution) underlines that AI, alongside benefits, possesses great risks for fundamental rights and democracies based on the rule of law. AI should not be seen as an end in itself, but as a tool for serving people, with the ultimate aim of increasing human well-being, human capabilities and safety. In this article the authors will analyse some of the concerns taking into accounts principles set in Ethical Guidelines and human rights concerns. As the Regulation on AI is underway in the EU, the authors will stress some of the concerns that should be addressed in its wording. © 2022 Croatian Society MIPRO.","10.23919/MIPRO55190.2022.9803606","Conference paper","2022","Artificial intelligence; Crime; Efficiency; Ethical technology; Microelectronics; Security systems; Social aspects; Traffic control; AI applications; Analyse; Data driven; Enforcement authorities; Ethical guideline; EU resolution and regulation on AI; Government services; Human rights; Law enforcement authority; Public safety; Face recognition","Scopus"
"Human Control and Discretion in AI-driven Decision-making in Government","Traditionally public decision-makers have been given discretion in many of the decisions they have to make in how to comply with legislation and policies. In this way, the context and specific circumstances can be taken into account when making decisions. This enables more acceptable solutions, but at the same time, discretion might result in treating individuals differently. With the advance of AI-based decisions, the role of the decision-makers is changing. The automation might result in fully automated decisions, humans-in-the-loop or AI might only be used as recommender systems in which humans have the discretion to deviate from the suggested decision. The predictability of and the accountability of the decisions might vary in these circumstances, although humans always remain accountable. Hence, there is a need for human-control and the decision-makers should be given sufficient authority to control the system and deal with undesired outcomes. In this direction this paper analyzes the degree of discretion and human control needed in AI-driven decision-making in government. Our analysis is based on the legal requirements set/posed to the administration, by the extensive legal frameworks that have been created for its operation, concerning the rule of law, the fairness-non-discrimination, the justifiability and accountability, and the certainty/predictability.  © 2021 ACM.","10.1145/3494193.3494195","Conference paper","2021","Artificial intelligence; Laws and legislation; Decision makers; Decisions makings; Fully automated; Human control; Human-in-the-loop; Legal frameworks; Legal requirements; Making decision; Paper analysis; Decision making","Scopus"
"AI-Enabled Assessment of Cardiac Systolic and Diastolic Function from Echocardiography","Left ventricular (LV) function is an important factor in terms of patient management, outcome, and long-term survival of patients with heart disease. The most recently published clinical guidelines for heart failure recognise that over reliance on only one measure of cardiac function (LV ejection fraction) as a diagnostic and treatment stratification biomarker is suboptimal. Recent advances in AI-based echocardiography analysis have shown excellent results on automated estimation of LV volumes and LV ejection fraction. However, from time-varying 2-D echocardiography acquisition, a richer description of cardiac function can be obtained by estimating functional biomarkers from the complete cardiac cycle. In this work we propose for the first time an AI approach for deriving advanced biomarkers of systolic and diastolic LV function from 2-D echocardiography based on segmentations of the full cardiac cycle. These biomarkers will allow clinicians to obtain a much richer picture of the heart in health and disease. The AI model is based on the ’nn-Unet’ framework and was trained and tested using four different databases. Results show excellent agreement between manual and automated analysis and showcase the potential of the advanced systolic and diastolic biomarkers for patient stratification. Finally, for a subset of 50 cases, we perform a correlation analysis between clinical biomarkers derived from echocardiography and cardiac magnetic resonance and we show a very strong relationship between the two modalities. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-16902-1_8","Conference paper","2022","Biomarkers; Cardiology; Deep learning; Heart; Image segmentation; Magnetic resonance; Medical imaging; Cardiac cycles; Cardiac functions; Clinical guideline; Deep learning; Diastolic function; Heart disease; Images segmentations; Left ventricular ejection fraction; Left ventricular function; Patient management; Echocardiography","Scopus"
"Counterfactual rule generation for fuzzy rule-based classification systems","EXplainable Artificial Intelligence (XAI) is of in-creasing importance as researchers and practitioners seek better transparency and verifiability of AI systems. Mamdani fuzzy systems can provide explanations based on their linguistic rules, and thus a potential pathway to XAI. A factual rule based explanation generally refers to the given set of rules executed, or fired, for a given input. However, research has shown that human explanations are often counterfactual (CF), i.e. rather than explaining why a given output was reached, they show why other potential outputs were not. Although several machine learning-based CF explanation generation methods have been proposed in recent years, quasi none of them focus on fuzzy systems. Also, where they do, they focus on correlation, which limits the interpretive value of any CF explanations obtained as humans expect a causal relationship in rules, i.e. we are cause-effect thinkers. In this paper, we propose a new rule generation framework for Mamdani fuzzy classification systems, which we refer to as CF-MABLAR, building on the MARkov BLAnket Rules (MABLAR) framework. CF-MABLAR approximates the causal links between inputs and output(s) of fuzzy systems and generates CF rules by leveraging them. Uniquely, the CF rules obtained not only provide a basic CF explanation, but can also articulate how the given inputs would need to be changed to generate a different output, crucial for lay-user insight, verification and sensitivity-evaluation of XAI systems, for example in decision support around credit risk, cyber security and medical assistance.  © 2022 IEEE.","10.1109/FUZZ-IEEE55066.2022.9882705","Conference paper","2022","Classification (of information); Decision support systems; Fuzzy inference; Fuzzy rules; AI systems; Causal; Counterfactuals; Explanation; Fuzzy; Fuzzy rule based classification systems; Markov Blankets; Rule; Rule generation; Verifiability; Risk assessment","Scopus"
"Artificial intelligence in healthcare","The ability of artificial intelligence (AI) to imitate human cognitive capabilities, coupled with the ease of accessibility of medical data and the expeditious advancement of analytical techniques, is bringing paramount difference to the healthcare industry. Former research demonstrates the remarkable accuracy of AI to aid physicians to settle on better clinical choices or supplant judgment made by human beings, in particular, technical and practical areas of medical care. Statistics indicate that the shortage of doctors in therapeutically under-resourced regions and the lack of availability of skilled physicians in highly engaged clinical settings tend to cause a rise in false detection rates. The excessive workload causes fatigue that could lead to poor recovery of diseases. AI is ever-evolving as it is making advancements at an exponential rate, especially in healthcare treatments, such as monitoring treatments, improving the planning, and analyzing data to provide better treatment plans. The procedure of data accumulation, data management, clustering, and tagging invites numerous governance and regulatory challenges that could take a long duration. The healthcare industry thrives in this unending battle as the complexity and intricacy of data, and strict guidelines take a major toll. A healthcare institute is subjected to ask for consent from an institutional review board’s work to attenuate a portion of these concerns, and researchers and scientists may measure, process, and anonymize DICOM information to strip away any patient’s medical information. The AI-enabled medical care employed in the institutes plays an imperative role as an informative assistant that provides aid to doctors in acquiring an understanding of meaningful patterns from data collection. This practice holds the potential to save a lot of time, cost, and effort while yielding consistent, unbiased, and prime diagnosis or treatment. AI and deep learning (DL) tools used in day-to-day medical decision-making have a grave impact on improving the patient’s treatment and overall cost incurred due to their employment efficiency and accuracy. AI and machine learning (ML) can prove to be of supreme importance and assistance in the early detection and thus the prevention of a plethora of diseases by reading and analyzing the patient’s vitals. The presented chapter is of 5-folds. First, the distinct data sources where the healthcare data is gathered from are discussed. Second, we talk about the moral and lawful difficulties of AI-driven medical care. Next, the structured and unstructured types of healthcare data have been analyzed followed by the AI techniques applied to these types of data, such as ML, natural language processing (NLP), and DL.We then analyze the crucial disease areas such as cardiology, radiology, neurology, and cancer, where the health issues can be alleviated by employing AI techniques. In conclusion, we further discuss the areas where AI-based techniques are applied in real life. © The Institution of Engineering and Technology 2022.","","Book chapter","2022","","Scopus"
"Let Me Take Over: Variable Autonomy for Meaningful Human Control","As Artificial Intelligence (AI) continues to expand its reach, the demand for human control and the development of AI systems that adhere to our legal, ethical, and social values also grows. Many (international and national) institutions have taken steps in this direction and published guidelines for the development and deployment of responsible AI systems. These guidelines, however, rely heavily on high-level statements that provide no clear criteria for system assessment, making the effective control over systems a challenge. “Human oversight” is one of the requirements being put forward as a means to support human autonomy and agency. In this paper, we argue that human presence alone does not meet this requirement and that such a misconception may limit the use of automation where it can otherwise provide so much benefit across industries. We therefore propose the development of systems with variable autonomy—dynamically adjustable levels of autonomy—as a means of ensuring meaningful human control over an artefact by satisfying all three core values commonly advocated in ethical guidelines: accountability, responsibility, and transparency. © Copyright © 2021 Methnani, Aler Tubella, Dignum and Theodorou.","10.3389/frai.2021.737072","Article","2021","","Scopus"
"Experiences with the Introduction of AI-based Tools for Moderation Automation of Voice-based Participatory Media Forum","Voice-based discussion forums where users can record audio messages which are then published for other users to listen and comment, are often moderated to ensure that the published audios are of good quality, relevant, and adhere to editorial guidelines of the forum. There is room for the introduction of AI-based tools in the moderation process, such as to identify and filter out blank or noisy audios, use speech recognition to transcribe the voice messages in text, and use natural language processing techniques to extract relevant metadata from the audio transcripts. We design such tools and deploy them within a social enterprise working in India that runs several voice-based discussion forums. We present our findings in terms of the time and cost-savings made through the introduction of these tools, and describe the feedback of the moderators towards the acceptability of AI-based automation in their workflow. Our work forms a case-study in the use of AI for automation of several routine tasks, and can be especially relevant for other researchers and practitioners involved with the use of voice-based technologies in developing regions of the world. © 2021 ACM.","10.1145/3506469.3506473","Conference paper","2021","Character recognition; Natural language processing systems; Speech recognition; And filters; Audio transcripts; Content moderation; Discussion forum; Interactive voice response; Interactive voice response system; Language processing techniques; Noisy audio; Voice messages; Voice response systems; Automation","Scopus"
"Decrypting the Black Boxing of Artificial Intelligence Using Explainable Artificial Intelligence in Smart Healthcare","Artificial Intelligence (AI) is creating a revolution in the healthcare industry with its recent developments in organized and amorphous data and quick progress in analytic techniques. The usefulness of AI in healthcare is being recognised at the same time as people begin to be concerned with the possible lack of explainability and bias in the models created. This explains the concept of explainable artificial intelligence (XAI), which increases the faith held in a system, thus leading to more widespread use of AI in healthcare. In this chapter, we offer diverse ways of viewing the XAI concepts, understandability and interpretability of explainable AI systems, mainly focussing on the healthcare domain. The intention is to educate healthcare providers on the understandability and interpretability of explainable AI systems. The medical model is the root cause of life, and we should be assured adequate to treat the patient according to its rules. This chapter uses AI explainability as a way to help build trustworthiness in the medical domain and takes a look at the recent developments in the area of explainable AI which encourages creativity, and at times are necessities in practice to raise awareness. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-97929-4_3","Book chapter","2022","","Scopus"
"Knowledge Transfer for Deep Reinforcement Agents in General Game Playing","Learning to master new games with nothing but the rules given is a hallmark of human intelligence. This ability has recently been successfully replicated in AI systems through a combination of Knowledge Representation, Monte Carlo Tree Search and Deep Reinforcement Learning: Generalised AlphaZero [7] provides a method for building general game-playing agents that can learn any game describable in a formal specification language. We investigate how to boost the ability of deep reinforcement agents for general game playing by applying transfer learning for new game variants. Experiments show that transfer learning can significantly reduce the training time on variations of games that were previously learned, and our results further suggest that the most successful method is to train a source network that uses the guidance of multiple expert networks. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-030-97546-3_5","Conference paper","2022","Deep learning; Knowledge management; Knowledge representation; Monte Carlo methods; Specification languages; AI systems; Expert networks; Formal specification language; Human intelligence; Knowledge transfer; Knowledge-representation; Learn+; Training time; Transfer learning; Reinforcement learning","Scopus"
"Augmenting medical diagnosis decisions? An investigation into physicians' decision-making process with artificial intelligence","Systems based on artificial intelligence (AI) increasingly support physicians in diagnostic decisions. Compared with rule-based systems, however, these systems are less transparent and their errors less predictable. Much research currently aims to improve AI technologies and debates their societal implications. Surprisingly little effort is spent on understanding the cognitive challenges of decision augmentation with AI-based systems although these systems make it more difficult for decision makers to evaluate the correctness of system advice and to decide whether to reject or accept it. As little is known about the cognitive mechanisms that underlie such evaluations, we take an inductive approach to understand how AI advice influences physicians' decision-making process. We conducted experiments with a total of 68 novice and 12 experienced physicians who diagnosed patient cases with an AI-based system that provided both correct and incorrect advice. Based on qualitative data from think-aloud protocols, interviews, and questionnaires, we elicit five decision-making patterns and develop a process model of medical diagnosis decision augmentation with AI advice. We show that physicians use second-order cognitive processes, namely metacognitions, to monitor and control their reasoning while assessing AI advice. These metacognitions determine whether physicians are able to reap the full benefits of AI or not. Specifically, wrong diagnostic decisions often result from shortcomings in utilizing metacognitions related to decision makers' own reasoning (self-monitoring) and metacognitions related to the AI-based system (system monitoring). As a result, physicians fall for decisions based on beliefs rather than actual data or engage in unsuitably superficial information search. Our findings provide a first perspective on the metacognitive mechanisms that decision makers use to evaluate system advice. Overall, our study sheds light on an overlooked facet of decision augmentation with AI, namely, the crucial role of human actors in compensating for technological errors. Copyright: © 2021 INFORMS","10.1287/ISRE.2020.0980","Article","2021","Artificial intelligence; Cognitive systems; Decision making; Diagnosis; Patient monitoring; Surveys; Advice taking; Decision makers; Decision supports; Decision-making process; Decisions makings; Diagnosis decision; Diagnostic decisions; Dual process; Metacognition; Rules based systems; Decision support systems","Scopus"
"Assessing the Quality of Computational Notebooks for a Frictionless Transition from Exploration to Production","The massive trend of integrating data-driven AI capabilities into traditional software systems is rising new intriguing challenges. One of such challenges is achieving a smooth transition from the explorative phase of Machine Learning projects - in which data scientists build prototypical models in the lab - to their production phase - in which software engineers translate prototypes into production-ready AI components. To narrow down the gap between these two phases, tools and practices adopted by data scientists might be improved by incorporating consolidated software engineering solutions. In particular, computational notebooks have a prominent role in determining the quality of data science prototypes. In my research project, I address this challenge by studying the best practices for collaboration with computational notebooks and proposing proof-of-concept tools to foster guidelines compliance.CCS CONCEPTS • Software and its engineering; • Computing methodologies → Machine learning; © 2022 IEEE.","10.1109/ICSE-Companion55297.2022.9793798","Conference paper","2022","Data Science; Learning systems; Machine components; Machine learning; Software engineering; Analysis tools; Computational notebook; Data driven; Learning projects; Linter; Machine-learning; Production phase; Smooth transitions; Software-systems; Static analyse tool; Static analysis","Scopus"
"Towards AIDOaRt Objectives via Joint Model-based Architectural Effort","This paper outlines the AIDOaRt project (AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development in Cyber-Physical Systems) objectives, the status, and current achievements. In particular we briefly outline one of its notable results so far, a model-based requirements engineering process that the project adopted to cope with the challenges of producing coherent joint technical results based on contributions of 32 partners. We shortly overview the process and give reference to the complete process that has been already applied and evaluated in several European Research projects. That way we intend to share the best practices in reaching ambitious objectives as targeted by the European research agenda. The project has received funding by the European Union KDT JU Key Digital Technologies Joint Undertaking, and it began in April 2021 for a period of 36 months. The Research Challenges in Information Science conference topics covered by the paper are the following: Information Systems Transformations, Model-Driven Engineering, User-Centered Design, Method Engineering.  © 2021 The Authors.","","Conference paper","2022","Embedded systems; User centered design; AIDOaRt; European research; Integration process; Joint models; KDT; Model-based OPC; Model-based requirement engineering; Model-based requirements; Requirement engineering; Requirement integration process; Requirements engineering","Scopus"
"Review of Research in the Field of Developing Methods to Extract Rules From Artificial Neural Networks","Abstract: A large-scale review and analysis of the existing methods and approaches to extract rules from artificial neural networks, including deep learning neural networks, is carried out. A wide range of methods and approaches to extract rules and related approaches to develop explainable artificial intelligence (AI) systems are considered. The taxonomy and several directions in studies of explainable neural networks related to the extraction of rules from neural networks, which allow the user to get an idea of how the neural network uses the input data, and also, using rules, to reveal the hidden relationships of the input data and the results found, are explored. This review focuses on the relationship of the most common rule-based explanation systems in AI with the most powerful machine learning algorithms using neural networks. In addition to rule extraction, other methods of constructing explainable AI systems are considered based on the construction of special modules that interpret each step of changing the neural network’s weights. A comprehensive analysis of the existing research makes it possible to draw conclusions about the appropriateness of using certain approaches. The results of the analysis will allow us to get a detailed picture of the state of research in this area and create our own applications based on neural networks, the results of which can be studied in detail and their reliability evaluated. The development of such systems is necessary for the development of the digital economy in Russia and the creation of applications that allow making responsible and explainable management decisions in critical areas of the national economy. © 2021, Pleiades Publishing, Ltd.","10.1134/S1064230721060046","Review","2021","Data mining; Deep learning; Extraction; Input output programs; Learning algorithms; Reliability analysis; Artificial intelligence systems; Comprehensive analysis; Explanation systems; Input datas; Large-scales; Learning neural networks; Machine learning algorithms; Neural-networks; Rule based; Rules extraction; Neural networks","Scopus"
"Green iot and edge AI as key technological enablers for a sustainable digital transition towards a smart circular economy: An industry 5.0 use case","Internet of Things (IoT) can help to pave the way to the circular economy and to a more sustainable world by enabling the digitalization of many operations and processes, such as water distribution, preventive maintenance, or smart manufacturing. Paradoxically, IoT technologies and paradigms such as edge computing, although they have a huge potential for the digital transition towards sustainability, they are not yet contributing to the sustainable development of the IoT sector itself. In fact, such a sector has a significant carbon footprint due to the use of scarce raw materials and its energy consumption in manufacturing, operating, and recycling processes. To tackle these issues, the Green IoT (G-IoT) paradigm has emerged as a research area to reduce such carbon footprint; however, its sustainable vision collides directly with the advent of Edge Artificial Intelligence (Edge AI), which imposes the consumption of additional energy. This article deals with this problem by exploring the different aspects that impact the design and development of Edge-AI G-IoT systems. Moreover, it presents a practical Industry 5.0 use case that illustrates the different concepts analyzed throughout the article. Specifically, the proposed scenario consists in an Industry 5.0 smart workshop that looks for improving operator safety and operation tracking. Such an application case makes use of a mist computing architecture composed of AI-enabled IoT nodes. After describing the application case, it is evaluated its energy consumption and it is analyzed the impact on the carbon footprint that it may have on different countries. Overall, this article provides guidelines that will help future developers to face the challenges that will arise when creating the next generation of Edge-AI G-IoT systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21175745","Article","2021","Artificial Intelligence; Diagnostic Tests, Routine; Industry; Internet of Things; Technology; Accident prevention; Artificial intelligence; Carbon footprint; Emission control; Energy utilization; Green manufacturing; Industrial economics; Sustainable development; Water supply systems; Circular economy; Computing architecture; Design and Development; Internet of Things (IOT); Operator safety; Recycling process; Smart manufacturing; Water distributions; artificial intelligence; diagnostic test; industry; technology; Internet of things","Scopus"
"Optimal Distribution of Current Resources in a Production Environment - A Sustainable and Ethical Framework for the Digital Era","Digital transformation has been achieved in one application (user interface – related to workplace excellence and the whole company environment) in a large chemical company in Germany. In connection with variable corporate goals such as fluctuating workload, agile responsiveness to customer inquiries, ecological and economic sustainability which require an intelligent and forward-looking management of the company. Hence, a prototype solution has been created to respond to a very dynamic market. Based on Microsoft PowerPoint (ISpring) and with some add-ons pre-selected operators may interact, including with video content. The current architecture of the IT system has already been done. Adjustments will still be made to become more agile and future-driven to follow all of the company business rules. An artificial intelligence (AI)-based methodical analysis and synthesis approach is followed, for human and other resource input calculation, to follow business KPIs (key performance indicators) and other business goals with an algorithm. This evolution or control system is seen as a natural response to a very complex environment where human effort and error must be minimized (through simplification and a mathematical algorithm and a fast loop e.g., every ten minutes KPIs may be re-calculated according to existing capacity due to availability of equipment and human resources). This holistic approach shortens reaction times to market situations and at the same time minimizes non-value-adding processes. The business roles are determined depending on the culture/size of the company and strategic parameters. The continuously available flexibility in product design and the instability of all resources is of significant importance. After initial research it was found that commercial systems do not have this ability to dynamically and agilely automatically adapt to the given optimum. Instead of isolated partial optimizations, the expected results are compared with the real results in a continuous dynamic simulation and readjusted promptly [1]. This algorithm represents the actual added value, which has a high economic but also humanity advantage, especially in the manufacturing industry. In the future most manufacturing enterprises will have to follow this AI and agile path to competitive advantage vis-à-vis Asian competitors. The last quarter of 2021 experienced a 10% productivity improvement due to this implementation, based on the prototype, and mainly due to one product implementation champion (in an area with 270 employees). © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-04829-6_55","Conference paper","2022","","Scopus"
"Internet of Healthcare: Opportunities and Legal Challenges in Internet of Things-Enabled Telehealth Ecosystems","The COVID-19 public health crisis has accelerated the transformation of health systems to become more closely tied to citizens/patients and increasingly dependent on the provision and use of telehealth services. Internet of Things (IoT)-enabled telehealth systems (deployed in conjunction with AI systems) could facilitate the smart transformation of healthcare from a merely reactive system to a data-driven and person-centred system that provides remote health diagnosis, monitoring and treatment services, integrated real-time response solutions, as well as prospective insights. However, the realisation of these health-related benefits requires the processing of vast amounts of data concerning health. These operations and the use of new enabling technologies raises significant legal concerns and questions the applicability of existing/proposed legal concepts. For this reason, the research analyses the adequateness of EU privacy, data protection, data governance, AI governance and other regulatory rules in IoT-enabled (and AI-augmented) telehealth systems. In addition, the research aims to identify technical and organisational measures (best practices), which could facilitate the implementation of normative principles in these information systems in an effective manner.  © 2021 ACM.","10.1145/3494193.3494260","Conference paper","2021","Data privacy; Diagnosis; Internet of things; Medical computing; Metadata; Real time systems; AI systems; Data governances; Ehealth; Health crisis; Health systems; Internet of healthcare; Privacy; Telehealth; Telehealth services; Telehealth system; eHealth","Scopus"
"ETS® AI Labs™ Ways of Working Tutorial: How to Build Evidence-Based, User-Obsessed, AI-Enabled Learning Solutions in an Agile Framework","How do you advance the science and engineering of digital learning solutions at your institution, business, or organization? Bring your current ways of working to this tutorial and get ready to innovate them alongside your fellow researchers, practitioners, business owners, and policy makers. As we work together to share our knowledge and lived experiences, presenters will assist participants in co-creating action plans for how they can utilize best practices from user-centered design (UCD), Design thinking, and Agile to deliver user-obsessed, AI-enabled, efficacious learning solutions. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-11647-6_21","Conference paper","2022","'current; Action plan; Agile; Business owners; Business policies; Design thinking; Digital-learning; Evidence-based; Policy makers; Science and engineering; User centered design","Scopus"
"Effective Opportunistic Esophageal Cancer Screening Using Noncontrast CT Imaging","Esophageal cancer is the second most deadly cancer. Early detection of resectable/curable esophageal cancers has a great potential to reduce mortality, but no guideline-recommended screening test is available. Although some screening methods have been developed, they are expensive, might be difficult to apply to the general population, and often fail to achieve satisfactory sensitivity for identifying early-stage cancers. In this work, we investigate the feasibility of esophageal tumor detection and classification (cancer or benign) on the noncontrast CT scan, which could potentially be used for opportunistic cancer screening. To capture the global context, a novel position-sensitive self-attention is proposed to augment nnUNet with non-local interactions. Our model achieves a sensitivity of 93.0% and specificity of 97.5% for the detection of esophageal tumors on a holdout testing set with 180 patients. In comparison, the mean sensitivity and specificity of four doctors are 75.0% and 83.8%, respectively. For the classification task, our model outperforms the mean doctors by absolute margins of 17%, 31%, and 14% for cancer, benign tumor, and normal, respectively. Compared with established state-of-the-art esophageal cancer screening methods, e.g., blood testing and endoscopy AI system, our method has comparable performance and is even more sensitive for early-stage cancer and benign tumor. Our proposed method is a novel, non-invasive, low-cost, and highly accurate tool for opportunistic screening of esophageal cancer. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-16437-8_33","Conference paper","2022","Diagnosis; Diseases; Tumors; Benign tumour; Cancer screening; CT imaging; Esophageal cancer; General population; Noncontrast CT; Screening methods; Screening tests; Self-attention; Tumour detection; Computerized tomography","Scopus"
"Transparency and Explainability of AI Systems: Ethical Guidelines in Practice","[Context and Motivation] Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few case studies that describe the current state of defining these quality requirements in practice. [Question] The goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and explainable AI systems. We analyzed the ethical guidelines in 16 organizations representing different industries and public sector. [Results] In the ethical guidelines, the importance of transparency was highlighted by almost all of the organizations, and explainability was considered as an integral part of transparency. Building trust in AI systems was one of the key reasons for developing transparency and explainability, and customers and users were raised as the main target groups of the explanations. The organizations also mentioned developers, partners, and stakeholders as important groups needing explanations. The ethical guidelines contained the following aspects of the AI system that should be explained: the purpose, role of AI, inputs, behavior, data utilized, outputs, and limitations. The guidelines also pointed out that transparency and explainability relate to several other quality requirements, such as trustworthiness, understandability, traceability, privacy, auditability, and fairness. [Contribution] For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a structured way to define explainability requirements of AI systems. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-030-98464-9_1","Conference paper","2022","Ethical technology; Requirements engineering; 'current; AI systems; Case-studies; Ethical guideline; Explainability; Industry sectors; Integral part; Public sector; Quality requirements; Target group; Transparency","Scopus"
"A framework for fostering transparency in shared artificial intelligence models by increasing visibility of contributions","Increased adoption of artificial intelligence (AI) systems into scientific workflows will result in an increasing technical debt as the distance between the data scientists and engineers who develop AI system components and scientists, researchers and other users grows. This could quickly become problematic, particularly where guidance or regulations change and once-acceptable best practice becomes outdated, or where data sources are later discredited as biased or inaccurate. This paper presents a novel method for deriving a quantifiable metric capable of ranking the overall transparency of the process pipelines used to generate AI systems, such that users, auditors and other stakeholders can gain confidence that they will be able to validate and trust the data sources and contributors in the AI systems that they rely on. The methodology for calculating the metric, and the type of criteria that could be used to make judgements on the visibility of contributions to systems are evaluated through models published at ModelHub and PyTorch Hub, popular archives for sharing science resources, and is found to be helpful in driving consideration of the contributions made to generating AI systems and approaches toward effective documentation and improving transparency in machine learning assets shared within scientific communities. © 2020 John Wiley & Sons, Ltd.","10.1002/cpe.6129","Conference paper","2021","Transparency; Visibility; Best practices; Data-sources; Overall transparencies; Process pipelines; Scientific community; Scientific workflows; Scientists and engineers; Technical debts; Artificial intelligence","Scopus"
"Improving AI Systems Through Trade-Offs Between Values","EU regulation mechanisms are typically designed to reinforce European values of human dignity, freedom, equality, democracy, human rights, and rule of law while establishing mechanisms that mobilize products and services and supporting economic and technological development. The EU Machinery Directive 2006 has had a pivotal role in securing the quality and safety of machines and devices on the European common market. This article discusses the points of convergence and divergence of values in light of various EU regulations, particularly in relation to digital products and AI applications. To distinguish the types of value conflicts, the article refers to Erik Hollnagel’s Efficiency-Thoroughness-Trade-Off (ETTO) principle and discusses how a reasonable balance between diverse values could be negotiated in designing AI-integrated devices and services. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-031-06018-2_23","Conference paper","2022","Economic and social effects; Laws and legislation; Machinery; AI systems; Economic development; Efficiency-thoroughness trade-off; EU machinery directive; EU regulations; Human rights; Product and services; Regulation mechanisms; Trade off; Usability; Efficiency","Scopus"
"Legal, Privacy, Social and Ethical Requirements and Impact Assessment for an Artificial Intelligence Based Medical Imaging Project","The use of Artificial Intelligence (AI) systems in the health domain requires developers of these systems to consider a wider view of requirements beyond traditional data security requirements. Data controllers of these systems should also include requirements that consider legal, privacy, fundamental rights, social, and ethical values. However, harmonized guidelines around AI principles and requirements are not agreed and divergent. This requires a creative approach with the development of these requirements for AI projects. Furthermore, many of the guidelines fail to establish a link between principles and actionable requirements. In this paper we present the methodology used to develop the legal, privacy, social and ethical requirements for an AI based medical imaging project entitled Medical Imaging Ireland (Med-I). Furthermore, we provide an overview of an assessment of these requirements implementation within the Med-I project. © 2022, Springer Nature Switzerland AG.","10.1007/978-3-031-15559-8_3","Conference paper","2022","Artificial intelligence; Ethical technology; Artificial intelligence; Artificial intelligence systems; Data controllers; Ethical values; Impact assessments; Ireland; Privacy; Security requirements; Social and ethical requirement; Social values; Medical imaging","Scopus"
"Software as a Medical Device: Regulating AI in Healthcare via Responsible AI","With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.  © 2021 Owner/Author.","10.1145/3447548.3470823","Conference paper","2021","Balancing; Health care; Information management; Machine learning; Privacy by design; Specifications; Balancing requirements; Data specifications; Feature engineerings; Governmental regulations; Model specifications; Optimization criteria; Regulatory bodies; Reproducibilities; Data mining","Scopus"
"Cody: An ai-based system to semi-automate coding for qalitative research","Qualitative research can produce a rich understanding of a phenomenon but requires an essential and strenuous data annotation process known as coding. Coding can be repetitive and timeconsuming, particularly for large datasets. Existing AI-based approaches for partially automating coding, like supervised machine learning (ML) or explicit knowledge represented in code rules, require high technical literacy and lack transparency. Further, little is known about the interaction of researchers with AI-based coding assistance. We introduce Cody, an AI-based system that semiautomates coding through code rules and supervised ML. Cody supports researchers with interactively (re)defning code rules and uses ML to extend coding to unseen data. In two studies with qualitative researchers, we found that (1) code rules provide structure and transparency, (2) explanations are commonly desired but rarely used, (3) suggestions beneft coding quality rather than coding speed, increasing the intercoder reliability, calculated with Krippendorf's Alpha, from 0.085 (MAXQDA) to 0.33 (Cody). © 2021 ACM.","10.1145/3411764.3445591","Conference paper","2021","Human engineering; Large dataset; Supervised learning; Coding quality; Coding speed; Data annotation; Explicit knowledge; Large datasets; Qualitative research; Supervised machine learning; Technical literacy; Transparency","Scopus"
"Artificial Intelligence with Radio-Diagnostic Modalities in Forensic Science - A Systematic Review","PURPOSE: The aim of this study was to provide an overview of Artificial intelligence in Forensic science with the aid of radio-diagnostic modalities. DATA SOURCES and SYNTHESIS: The data is gathered by searching the articles in varioussearch engines which have been published between January 2010 to December 2020. A total of 20 studies were found eligible after following inclusion and exclusion criteria described in the below article. Prisma Guidelines and Prisma Flowchart was followed. CONCLUSION: Artificial intelligence (AI) is a technology that involves computerised algorithms to dichotomize complex data. AI is widely used in diagnostic imaging for detection and quantification of a clinical condition. This systematic review aimed to explain the role of AI with diagnostic imaging modality of radiology in forensic. AI technology is now widely used for age and sex estimation. Most of the AI models are based on machine learning (ML) programs, artificial neural network(ANN) and convolutional neural network (CNN). The results of the studies are promising, providing great accuracy and decision making. These different AI based models will be act as identification tools in mass disasters cases, medicolegal cases. Further improvement in AI programs and diagnostic tool is needed for better accuracy and specificity in Forensic investigations. ©2021 Copyright for this paper by its authors.","","Conference paper","2021","Convolutional neural networks; Decision making; Digital forensics; Search engines; Clinical conditions; Complex data; Detection and quantifications; Diagnostic imaging; Diagnostic imaging modality; Diagnostic modality; Forensic identification; Imaging modality; Inclusion and exclusions; Systematic Review; Machine learning","Scopus"
"Exclusivity and paternalism in the public governance of explainable AI","In this comment, we address the apparent exclusivity and paternalism of goal and standard setting for explainable AI and its implications for the public governance of AI. We argue that the widening use of AI decision-making, including the development of autonomous systems, not only poses widely-discussed risks for human autonomy in itself, but is also the subject of a standard-setting process that is remarkably closed to effective public contestation. The implications of this turn in governance for democratic decision-making in Britain have also yet to be fully appreciated. As the governance of AI gathers pace, one of the major tasks will be ensure not only that AI systems are technically ‘explainable’ but that, in a fuller sense, the relevant standards and rules are contestable and that governing institutions and processes are open to democratic contestability. © 2020 Perry Keller","10.1016/j.clsr.2020.105490","Article","2021","Behavioral research; Decision making; Decision support systems; AI systems; Autonomous systems; Britain; Standard setting; Public risks","Scopus"
"Ethics as a Service: A Pragmatic Operationalisation of AI Ethics","As the range of potential uses for Artificial Intelligence (AI), in particular machine learning (ML), has increased, so has awareness of the associated ethical issues. This increased awareness has led to the realisation that existing legislation and regulation provides insufficient protection to individuals, groups, society, and the environment from AI harms. In response to this realisation, there has been a proliferation of principle-based ethics codes, guidelines and frameworks. However, it has become increasingly clear that a significant gap exists between the theory of AI ethics principles and the practical design of AI systems. In previous work, we analysed whether it is possible to close this gap between the ‘what’ and the ‘how’ of AI ethics through the use of tools and methods designed to help AI developers, engineers, and designers translate principles into practice. We concluded that this method of closure is currently ineffective as almost all existing translational tools and methods are either too flexible (and thus vulnerable to ethics washing) or too strict (unresponsive to context). This raised the question: if, even with technical guidance, AI ethics is challenging to embed in the process of algorithmic design, is the entire pro-ethical design endeavour rendered futile? And, if no, then how can AI ethics be made useful for AI practitioners? This is the question we seek to address here by exploring why principles and technical translational tools are still needed even if they are limited, and how these limitations can be potentially overcome by providing theoretical grounding of a concept that has been termed ‘Ethics as a Service.’ © 2021, The Author(s).","10.1007/s11023-021-09563-w","Article","2021","Laws and legislation; Object oriented programming; Philosophical aspects; AI systems; Algorithmic design; Ethical designs; Ethical issues; Technical guidances; Tools and methods; Artificial intelligence","Scopus"
"Fast and flexible: Human program induction in abstract reasoning tasks","The Abstraction and Reasoning Corpus (ARC) is a collection program induction tasks that was recently proposed by Chollet (2019) as a measure of machine intelligence. Here, we report a preliminary set of results from a behavioral study of humans solving a subset of tasks from ARC (40 out of 1000). We found that humans were able to infer the underlying program and generate the correct test output for a novel test input example, with an average of 84% of tasks solved per participant, and with 65% of tasks being solved by more than 80% of participants. Additionally, we find interesting patterns of behavioral consistency and variability across the action sequences to generate their responses, the natural language descriptions used to describe the rule for each task, and the errors people make. Our findings suggest that people can quickly and reliably determine the relevant features and properties of a task to compose a correct solution, despite limited experience in this domain. This dataset offers useful insights for designing AI systems that can solve abstract reasoning tasks such as ARC with the fluidity of human intelligence. © Cognitive Science Society: Comparative Cognition: Animal Minds, CogSci 2021.All rights reserved.","","Conference paper","2021","Artificial intelligence; Cognitive systems; Abstract reasoning; Action sequences; Behavioural consistency; Behavioural studies; Compositionality; Concept learning; Machine intelligence; Program induction; Reasoning tasks; Test inputs; Software testing","Scopus"
"AI Based Information Retrieval System for Identifying Harmful Online Gaming Patterns","Games of skill are an excellent source of recreation and relaxation. Games are also the safest and readily accessible constructs for social interaction and community affairs which potentially opens up new avenues for realising personal worth, social acceptance, respect and recognition. However, when these games are played with real money, ensuring game prudence, whereby users play real-money skill games only for entertainment purposes, and do so well within their resourceful means, becomes necessary. It becomes paramount for the wellness of players and also to ensure online gaming is only available for sheer entertainment. In this proposal, we present an automated, data driven, AI powered, Responsible Game Play (RGP) framework cum tool which has been integrated in our online skill gaming platform. RGP pipeline is a combination of: a) a couple of anomaly detection Rule Based Engines; b) a Deep Learning Pipeline which models the game play characteristics of healthy and engaged players to identify potentially risky players, and c) a ML based Local Expert which leverages users' longitudinal behavioral patterns and constructs new features using the adjacent AI OPS and Signal Processing Domains. We integrate the psychometric assessment to nudge and coarse correct at-risk players proactively, ahead of time  © 2021 Owner/Author.","10.1145/3404835.3464921","Conference paper","2021","Anomaly detection; Deep learning; Entertainment; Online systems; Pipelines; Risk assessment; Signal processing; Behavioral patterns; Data driven; Detection rules; Games of skills; Local experts; On-line gaming; Social acceptance; Social interactions; Search engines","Scopus"
"Machine/deep learning for performing orthodontic diagnoses and treatment planning","As automated treatment planning is expected to reduce inter-planner variability and the planning time allocated for the optimization process in order to improve the plan quality, researchers have attempted to develop such systems. Artificial intelligence (AI) attempts to reflect advanced human intelligence in machines, and efforts to develop AI systems have been made since the advent of computers. In the 1980s, an expert system that expressed expert knowledge in a program produced useful results as AI technology. However, because it was a system in which rules were embedded in advance, it was limited by its difficulty in handling exceptions. Furthermore, making rules is time-consuming. The importance of machine learning that inductively learns general rules and laws based on various events (data) became recognized in the 1990s. Machine learning techniques can be said to be general-purpose techniques for detecting regularity and specificity in observational data. In this chapter, we will introduce several AI systems that have been used to derive orthodontic diagnoses and develop treatment plans in the past. We will then introduce a newly developed AI system that uses natural language processing to conduct various clinical text evaluations and develop accompanying treatment protocols. © Springer Nature Switzerland AG 2021. All rights reserved.","10.1007/978-3-030-71881-7_6","Book chapter","2021","","Scopus"
"HPC AI500 V2.0: The Methodology, Tools, and Metrics for Benchmarking HPC AI Systems","Recent years witness a trend of applying large-scale distributed deep learning algorithms (HPC AI) in both business and scientific computing areas, whose goal is to speed up the training time to achieve a state-of-the-art quality. The HPC AI benchmarks accelerate the process. Unfortunately, benchmarking HPC AI systems at scale raises serious challenges. This paper presents a comprehensive HPC AI benchmarking methodology that achieves equivalence, representativeness, repeatability, and affordability. Among the nineteen AI workloads of AIBench Training-by far the most comprehensive AI benchmarks suite, we choose two representative and repeatable AI workloads in terms of both AI model and micro-architectural characteristics. The selected HPC AI benchmarks include both business and scientific computing: Image Classification and Extreme Weather Analytics. Finally, we propose three high levels of benchmarking and the corresponding rules to assure equivalence. To rank the performance of HPC AI systems, we present a new metric named Valid FLOPS, emphasizing both throughput performance and target quality. The evaluations show our methodology, benchmarks, and metrics can measure and rank the HPC AI systems in a simple, affordable and repeatable way. The specification, source code, datasets, and HPC AI500 ranking numbers are publicly available from https: //www.benchcouncil.org/aibench/hpcai500/index.html.  ©2021 IEEE.","10.1109/Cluster48925.2021.00022","Conference paper","2021","Deep learning; Learning algorithms; AI systems; Benchmark suites; Benchmarking methodology; Distributed deep learning; HPC AI; Large-scales; Metric; Speed up; State of the art; Training time; Benchmarking","Scopus"
"Artificial intelligence ethics guidelines for developers and users: clarifying their content and normative implications","Purpose: The purpose of this paper is clearly illustrate this convergence and the prescriptive recommendations that such documents entail. There is a significant amount of research into the ethical consequences of artificial intelligence (AI). This is reflected by many outputs across academia, policy and the media. Many of these outputs aim to provide guidance to particular stakeholder groups. It has recently been shown that there is a large degree of convergence in terms of the principles upon which these guidance documents are based. Despite this convergence, it is not always clear how these principles are to be translated into practice. Design/methodology/approach: In this paper, the authors move beyond the high-level ethical principles that are common across the AI ethics guidance literature and provide a description of the normative content that is covered by these principles. The outcome is a comprehensive compilation of normative requirements arising from existing guidance documents. This is not only required for a deeper theoretical understanding of AI ethics discussions but also for the creation of practical and implementable guidance for developers and users of AI. Findings: In this paper, the authors therefore provide a detailed explanation of the normative implications of existing AI ethics guidelines but directed towards developers and organisational users of AI. The authors believe that the paper provides the most comprehensive account of ethical requirements in AI currently available, which is of interest not only to the research and policy communities engaged in the topic but also to the user communities that require guidance when developing or deploying AI systems. Originality/value: The authors believe that they have managed to compile the most comprehensive document collecting existing guidance which can guide practical action but will hopefully also support the consolidation of the guidelines landscape. The authors’ findings should also be of academic interest and inspire philosophical research on the consistency and justification of the various normative statements that can be found in the literature. © 2020, Mark Ryan and Bernd Carsten Stahl.","10.1108/JICES-12-2019-0138","Article","2021","","Scopus"
"Diagnosing Covid-19 chest x-rays with a lightweight truncated DenseNet with partial layer freezing and feature fusion","Due to the unforeseen turn of events, our world has undergone another global pandemic from a highly contagious novel coronavirus named COVID-19. The novel virus inflames the lungs similarly to Pneumonia, making it challenging to diagnose. Currently, the common standard to diagnose the virus's presence from an individual is using a molecular real-time Reverse-Transcription Polymerase Chain Reaction (rRT-PCR) test from fluids acquired through nasal swabs. Such a test is difficult to acquire in most underdeveloped countries with a few experts that can perform the test. As a substitute, the widely available Chest X-Ray (CXR) became an alternative to rule out the virus. However, such a method does not come easy as the virus still possesses unknown characteristics that even experienced radiologists and other medical experts find difficult to diagnose through CXRs. Several studies have recently used computer-aided methods to automate and improve such diagnosis of CXRs through Artificial Intelligence (AI) based on computer vision and Deep Convolutional Neural Networks (DCNN), which some require heavy processing costs and other tedious methods to produce. Therefore, this work proposed the Fused-DenseNet-Tiny, a lightweight DCNN model based on a densely connected neural network (DenseNet) truncated and concatenated. The model trained to learn CXR features based on transfer learning, partial layer freezing, and feature fusion. Upon evaluation, the proposed model achieved a remarkable 97.99 % accuracy, with only 1.2 million parameters and a shorter end-to-end structure. It has also shown better performance than some existing studies and other massive state-of-the-art models that diagnosed COVID-19 from CXRs. © 2021 Elsevier Ltd","10.1016/j.bspc.2021.102583","Article","2021","Deep neural networks; Freezing; Viruses; Chest x-rays; Common standards; Computer-aided; Convolutional neural network; Coronaviruses; Covid-19; Deep learning; Densely connected neural network; Features fusions; Neural-networks; Article; convolutional neural network; coronavirus disease 2019; diagnostic accuracy; diagnostic test accuracy study; feature fusion; freezing; human; machine learning; major clinical study; partial layer freezing; pneumonia; priority journal; sensitivity and specificity; thorax radiography; transfer of learning; Computer aided diagnosis","Scopus"
"Towards an XAI-Assisted Third-Party Evaluation of AI Systems: Illustration on Decision Trees","We explored the potential contribution of eXplainable Artificial Intelligence (XAI) for the evaluation of Artificial Intelligence (AI), in a context where such an evaluation is performed by independent third-party evaluators, for example in the objective of certification. The experimental approach of this paper is based on “explainable by design” decision trees that produce predictions on health data and bank data. Results presented in this paper show that the explanations could be used by the evaluators to identify the parameters used in decision making and their levels of importance. The explanations would thus make it possible to orient the constitution of the evaluation corpus, to explore the rules followed for decision-making and to identify potentially critical relationships between different parameters. In addition, the explanations make it possible to inspect the presence of bias in the database and in the algorithm. These first results lay the groundwork for further additional research in order to generalize the conclusions of this paper to different XAI methods. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-82017-6_10","Conference paper","2021","Behavioral research; Decision making; Decision trees; Forestry; Intelligent agents; Trees (mathematics); AI systems; Experimental approaches; Health data; Third parties; Multi agent systems","Scopus"
"Mobile Data Science and Intelligent Apps: Concepts, AI-Based Modeling and Research Directions","Artificial intelligence (AI) techniques have grown rapidly in recent years in the context of computing with smart mobile phones that typically allows the devices to function in an intelligent manner. Popular AI techniques include machine learning and deep learning methods, natural language processing, as well as knowledge representation and expert systems, can be used to make the target mobile applications intelligent and more effective. In this paper, we present a comprehensive view on “mobile data science and intelligent apps” in terms of concepts and AI-based modeling that can be used to design and develop intelligent mobile applications for the betterment of human life in their diverse day-to-day situation. This study also includes the concepts and insights of various AI-powered intelligent apps in several application domains, ranging from personalized recommendation to healthcare services, including COVID-19 pandemic management in recent days. Finally, we highlight several research issues and future directions relevant to our analysis in the area of mobile data science and intelligent apps. Overall, this paper aims to serve as a reference point and guidelines for the mobile application developers as well as the researchers in this domain, particularly from the technical point of view. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","10.1007/s11036-020-01650-z","Article","2021","Data Science; Expert systems; Knowledge representation; mHealth; Mobile computing; Natural language processing systems; Healthcare services; Learning methods; Mobile applications; NAtural language processing; Personalized recommendation; Reference points; Research issues; Smart Mobile Phones; Learning systems","Scopus"
"A Typology of AI Applications in Politics","Politics relates to the most fundamental questions of humans’ existence, and modern western societies tend to pride themselves on basing politics on democratic principles, including principles of inclusivity, participation, and autonomy and self-rule. Meanwhile, the continuously improving capabilities of various artificial intelligence (AI) based systems have led to the use of AI in an increasing amount of politically significant settings. AI is now also used in official government decision-making processes, and the political significance of using AI in the political system is the topic of this chapter. The purpose is to examine the potential for AI in official political settings, distinguishing between five types of AI used to support, assist, alleviate, augment or supplant decision makers. The chapter explores the practical and theoretical potential for AI applications in politics, and the main contribution of the chapter is the development of a typology that can guide the evaluation of the impacts of such applications. AI in politics has the potential to drastically change how politics is performed, and as politics entails answering some of society’s most fundamental questions the article concludes that the issues here discussed should be subject to public processes, both in politics and society at large. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-88972-2_3","Book chapter","2021","","Scopus"
"On utilizing an enhanced object partitioning scheme to optimize self-organizing lists-on-lists","With the advent of “Big Data” as a field, in and of itself, there are at least three fundamentally new questions that have emerged, namely the Artificially Intelligence (AI)-based algorithms required, the hardware to process the data, and the methods to store and access the data efficiently. This paper (The work of the second author was partially supported by NSERC, the Natural Sciences and Engineering Council of Canada. We are very grateful for the feedback from the anonymous Referees of the original submission. Their input significantly improved the quality of this final version.) presents some novel schemes for the last of the three areas. There have been thousands of papers written regarding the algorithms themselves, and the hardware vendors are scrambling for the market share. However, the question of how to store, manage and access data, which has been central to the field of Computer Science, is even more pertinent in these days when megabytes of data are being generated every second. This paper considers the problem of minimizing the cost of retrieval using the most fundamental data structure, i.e., a Singly-Linked List (SLL). We consider a SLL in which the elements are accessed by a Non-stationary Environment (NSE) exhibiting the so-called “Locality of Reference”. We propose a solution to the problem by designing an “Adaptive” Data Structure (ADS), which is created by utilizing a composite of hierarchical data “sub”-structures to constitute the overall data structure (In this paper, the primitive data structure is the SLL. However, these concepts can be extended to more complicated data structures.). In this paper, we design hierarchical Lists-on-Lists (LOLs) by assembling a SLL into a hierarchical scheme that results in SLLs on SLLs (SLLs-on-SLLs) comprising of an outer-list and sublist contexts. The goal is that elements that are more likely to be accessed together are grouped within the same sub-context, while the sublists themselves are moved “en masse” towards the head of the list-context to minimize the overall access cost. This move is carried out by employing the “de-facto” list re-organization schemes, i.e., the Move-To-Front (MTF) and Transposition (TR) rules. To achieve the clustering of elements within the sublists, we invoke the Object Migration Automaton (OMA) family of reinforcement schemes from the theory of Learning Automata (LA). They capture the probabilistic dependence of the elements in the data structure, receiving query accesses from the Environment. We show that SLLs-on-SLLs augmented with the Enhanced OMA (EOMA) minimizes the retrieval cost for elements in NSEs, and are superior to the stand-alone MTF and TR schemes, and also superior to the OMA-augmented SLLs-on-SLLs operating in such Environments. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s12530-020-09327-4","Article","2021","Automata theory; Competition; Computer hardware; Robots; Learning Automata; Locality of reference; Natural sciences and engineerings; Non-stationary environment; Object migration automaton; Probabilistic dependence; Singly-linked list; Theory of learning; Data structures","Scopus"
"AIBench Scenario: Scenario-distilling AI Benchmarking","Modern real-world application scenarios like Internet services consist of a diversity of AI and non-AI modules with huge code sizes and long and complicated execution paths, which raises serious benchmarking or evaluating challenges. Using AI components or micro benchmarks alone can lead to error-prone conclusions. This paper presents a methodology to attack the above challenge. We formalize a real-world application scenario as a Directed Acyclic Graph-based model and propose the rules to distill it into a permutation of essential AI and non-AI tasks, which we call a scenario benchmark. Together with seventeen industry partners, we extract nine typical scenario benchmarks. We design and implement an extensible, configurable, and flexible benchmark framework. We implement two Internet service AI scenario benchmarks based on the framework as proxies to two real-world application scenarios. We consider scenario, component, and micro benchmarks as three indispensable parts for evaluating. Our evaluation shows the advantage of our methodology against using component or micro AI benchmarks alone. The specifications, source code, testbed, and results are publicly available from https://www.benchcouncil.org/aibench/scenario/. © 2021 IEEE","10.1109/PACT52795.2021.00018","Conference paper","2021","Directed graphs; Graphic methods; HTTP; Web services; Application scenario; Benchmark; Code size; Error prones; Execution paths; Graph-based models; Internet-services; Microbenchmarks; Real-world; Scenario; Benchmarking","Scopus"
"Explainable Artificial Intelligence (XAI) Supporting Public Administration Processes – On the Potential of XAI in Tax Audit Processes","Artificial Intelligence (AI) can offer significant potential for public administrations which – in Germany – are likely to face considerable skills shortages in the next few years. AI systems can especially support the automation of processes and thus disburden administrative staff. As transparency and fairness play a major role in administrative processes, explainable AI (XAI) approaches are expected to enable a proper usage of AI in public administration. In this article, we investigate the potential of XAI for the support of tax authority processes, especially the selection of tax audit target organizations. We illustrate relevant tax audit scenarios and present the potential of different XAI techniques which we currently develop in these scenarios. It shows that XAI can significantly support tax audit preparations resulting in more efficient processes and a better performance of tax authorities concerning their main responsibilities. A further contribution of this article lies in the exemplary application of XAI usage guidelines in the public administration context. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-86790-4_28","Conference paper","2021","","Scopus"
"Design science research and designing ethical guidelines for the SHAPES AI developers","This article targets the design process of ethical guidelines for the SHAPES project (Smart and Healthy Aging through People Engaging in Supportive Systems) which is a H2020 Innovation Action project. The aim of the project is to build solutions that can make it easier for older individuals to live at home, such as, robots, wearables and sensor technologies that apply artificial intelligence (AI). The guiding method of the design process of ethical guidelines is Alan Hevner's Design Science Research. Theoretical background consists of a form of literature overview, which contains the most relevant ethical theories and research on AI ethics, machine ethics and human rights. This article introduces the process of building the ethical guidelines for the SHAPES project and further discussion if providing guidelines is the sufficient tool to developers to take ethical action in development of the AI systems. The SHAPES guidelines include the following themes; accountability, transparency and explainability, diversity, inclusion and fairness, safety and security and societal wellbeing and humanity. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.","10.1016/j.procs.2021.08.223","Conference paper","2021","Intelligent robots; Wearable sensors; Design science; Design science reseach; Design-process; Design-science researches; Ethical competence; Ethical guideline; Ethical theories; Literature overview; Sensor technologies; SHAPES; Philosophical aspects","Scopus"
"How to Write Ethical User Stories? Impacts of the ECCOLA Method","Artificial Intelligence (AI) systems are increasing in significance within software services. Unfortunately, these systems are not flawless. Their faults, failures and other systemic issues have emphasized the urgency for consideration of ethical standards and practices in AI engineering. Despite the growing number of studies in AI ethics, comparatively little attention has been placed on how ethical issues can be mitigated in software engineering (SE) practice. Currently understanding is lacking regarding the provision of useful tools that can help companies transform high-level ethical guidelines for AI ethics into the actual workflow of developers. In this paper, we explore the idea of using user stories to transform abstract ethical requirements into tangible outcomes in Agile software development. We tested this idea by studying master’s level student projects (15 teams) developing web applications for a real industrial client over the course of five iterations. These projects resulted in 250+ user stories that were analyzed for the purposes of this paper. The teams were divided into two groups: half of the teams worked using the ECCOLA method for AI ethics in SE, while the other half, a control group, was used to compare the effectiveness of ECCOLA. Both teams were tasked with writing user stories to formulate customer needs into system requirements. Based on the data, we discuss the effectiveness of ECCOLA, and Primary Empirical Contributions (PECs) from formulating ethical user stories in Agile development. © 2021, The Author(s).","10.1007/978-3-030-78098-2_3","Conference paper","2021","Agile manufacturing systems; Artificial intelligence; Philosophical aspects; Agile development; Agile software development; Ethical standards; Software services; Student project; System requirements; Tangible outcomes; WEB application; Software design","Scopus"
"Current challenges and future opportunities for xai in machine learning-based clinical decision support systems: A systematic review","Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11115088","Article","2021","","Scopus"
"Learn to Machine Learn: Designing a Game Based Approach for Teaching Machine Learning to Primary and Secondary Education Students","With the ubiquitous role of Artificial Intelligence (AI) in everyday applications such as smartphones and social media, children need digital literacy skills to navigate the digital world, critically view, and reflect on the social and ethical implications of the design and architecture of AI systems. To address this increasing need for AI literacy skills, particularly for younger students, this paper presents the rationale of the LearnML project which aims to develop a framework and game-based educational material for promoting AI literacy among primary and secondary education students. We also describe the design and initial assessment of the game ""ArtBot"", developed as part of the LearnML project. We review existing literature, discuss the educational game design and development of ""ArtBot""and describe the initial feedback of students and teachers. Our goal is to provide insights and suggest guidelines for the implementation of game-based learning environments for supporting AI literacy skills of students. © 2021 Owner/Author.","10.1145/3459990.3465176","Conference paper","2021","Computer aided instruction; Machine learning; Digital literacies; Educational materials; Ethical implications; Game-based approaches; Game-based learning environments; Initial assessment; Initial feedback; Primary and secondary education; Students","Scopus"
"Designing Co-Creative AI for Virtual Environments","Co-creative AI tools provide a method of creative collaboration between a user and machine. One form of co-creative AI called generative design requires the user to input design parameters and wait substantial periods of time while the system computes design solutions. We explore this interaction dynamic by providing an embodied experience in VR. Calliope is a virtual reality (VR) system that enables users to explore and manipulate generative design solutions in real time. Calliope accounts for the typical idle times in the generative design process by using a virtual environment to encourage parallelized and embodied data-exploration and synthesis, while maintaining a tight human-in-The-loop collaboration with the underlying algorithms. In this paper we discuss design considerations informed by formative studies with generative designers and artists and provide design guidelines to aid others in the development of co-creative AI systems in virtual environments.  © 2021 ACM.","10.1145/3450741.3465260","Conference paper","2021","Computer applications; Computer programming; Data exploration; Design considerations; Design solutions; Embodied experience; Generative design; Human-in-the-loop; Input design; Interaction dynamics; Design","Scopus"
"EREBOTS: Privacy-compliant agent-based platform for multi-scenario personalized health-assistant chatbots","Context. Asynchronous messaging is increasingly used to support human–machine inter-actions, generally implemented through chatbots. Such virtual entities assist the users in activities of different kinds (e.g., work, leisure, and health-related) and are becoming ingrained into humans’ habits due to factors including (i) the availability of mobile devices such as smartphones and tablets, (ii) the increasingly engaging nature of chatbot interactions, (iii) the release of dedicated APIs from messaging platforms, and (iv) increasingly complex AI-based mechanisms to power the bots’ behav-iors. Nevertheless, most of the modern chatbots rely on state machines (implementing conversational rules) and one-fits-all approaches, neglecting personalization, data-stream privacy management, multi-topic management/interconnection, and multimodal interactions. Objective. This work ad-dresses the challenges above through an agent-based framework for chatbot development named EREBOTS. Methods. The foundations of the framework are based on the implementation of (i) multi-front-end connectors and interfaces (i.e., Telegram, dedicated App, and web interface), (ii) enabling the configuration of multi-scenario behaviors (i.e., preventive physical conditioning, smoking cessa-tion, and support for breast-cancer survivors), (iii) online learning, (iv) personalized conversations and recommendations (i.e., mood boost, anti-craving persuasion, and balance-preserving physical exercises), and (v) responsive multi-device monitoring interface (i.e., doctor and admin). Results. EREBOTS has been tested in the context of physical balance preservation in social confinement times (due to the ongoing pandemic). Thirteen individuals characterized by diverse age, gender, and country distribution have actively participated in the experimentation, reporting advancements in the physical balance and overall satisfaction of the interaction and exercises’ variety they have been proposed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/electronics10060666","Article","2021","","Scopus"
"A Framework for Understanding AI-Induced Field Change: How AI Technologies are Legitimized and Institutionalized","Artificial intelligence (AI) systems operate in increasingly diverse areas, from healthcare to facial recognition, the stock market, autonomous vehicles, and so on. While the underlying digital infrastructure of AI systems is developing rapidly, each area of implementation is subject to different degrees and processes of legitimization. By combining elements from institutional theory and information systems-theory, this paper presents a conceptual framework to analyze and understand AI-induced field-change. The introduction of novel AI-agents into new or existing fields creates a dynamic in which algorithms (re)shape organizations and institutions while existing institutional infrastructures determine the scope and speed at which organizational change is allowed to occur. Where institutional infrastructure and governance arrangements, such as standards, rules, and regulations, still are unelaborate, the field can move fast but is also more likely to be contested. The institutional infrastructure surrounding AI-induced fields is generally little elaborated, which could be an obstacle to the broader institutionalization of AI-systems going forward. © 2021 ACM.","10.1145/3461702.3462591","Conference paper","2021","Electronic trading; Face recognition; Philosophical aspects; AI systems; AI Technologies; Conceptual frameworks; Digital infrastructures; Facial recognition; Induced field; Institutional theory; Organizational change; Artificial intelligence","Scopus"
"Detecting Spurious Correlations With Sanity Tests for Artificial Intelligence Guided Radiology Systems","Artificial intelligence (AI) has been successful at solving numerous problems in machine perception. In radiology, AI systems are rapidly evolving and show progress in guiding treatment decisions, diagnosing, localizing disease on medical images, and improving radiologists' efficiency. A critical component to deploying AI in radiology is to gain confidence in a developed system's efficacy and safety. The current gold standard approach is to conduct an analytical validation of performance on a generalization dataset from one or more institutions, followed by a clinical validation study of the system's efficacy during deployment. Clinical validation studies are time-consuming, and best practices dictate limited re-use of analytical validation data, so it is ideal to know ahead of time if a system is likely to fail analytical or clinical validation. In this paper, we describe a series of sanity tests to identify when a system performs well on development data for the wrong reasons. We illustrate the sanity tests' value by designing a deep learning system to classify pancreatic cancer seen in computed tomography scans. © Copyright © 2021 Mahmood, Shrestha, Bates, Mannelli, Corrias, Erdi and Kanan.","10.3389/fdgth.2021.671015","Article","2021","Article; artificial intelligence; computer assisted tomography; confidence interval; confounding bias; correlation analysis; deep learning; dynamic contrast enhanced computed tomography; human; radiological procedures; sanity test; scientific literature; validation study; X ray","Scopus"
"Can You Trust the Black Box? The Effect of Personality Traits on Trust in AI-Enabled User Interfaces","Human-centred artificial intelligence is a fast-growing research stream within the artificial intelligence (AI) and human–computer interaction (HCI) communities. One key focus of this stream is the enablement of trust between end users and the intelligent solution. Although, the current body of literature discusses and proposes a range of best practices for the design of user interfaces for intelligent solutions, there is a dearth of research how such interfaces are perceived by users and especially focusing on trust in these interfaces. In this paper, we investigate how the Big Five personality traits affect trust in AI-enabled user interfaces. We then experimentally verify which design best practices and guidelines proposed by Google enable trust in AI-enabled user interfaces for the different personality types. Initial results (n = 211) reveal that three of the Big Five personality traits – Extraversion, Agreeableness and Open-Mindedness – show a significant correlation between the degree of the personality trait and trust in the proposed storyboards. In addition, we identified significant positive relationships between the perception of trust by users and four out of the twelve design principles: review implicit feedback; connect the feedback to UX changes; create opportunities for feedback; fail gracefully and highlight failure. This paper is of a highly explorative character and provides first experimental results on designing for trust to the HCI/AI community and also highlights future research directions in the form of a research agenda. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-77772-2_1","Conference paper","2021","Computer hardware description languages; Human computer interaction; User interfaces; Web browsers; Computer interaction; Design best practices; Design Principles; Future research directions; Implicit feedback; Intelligent solutions; Personality traits; Personality types; Artificial intelligence","Scopus"
"Explainable clustering with multidimensional bounding boxes","Explainable Artificial Intelligence (XAI) aims at introducing transparency and intelligibility into decision-making process of AI systems. Most of the work in this area is focused on supervised machine learning tasks such as classification and regression. Unsupervised algorithms such as clustering can also be explained with existing approaches. This is most often achieved by explaining a classifier trained on cluster data with cluster labels as a dependant variable. However, with such a transformation the information about cluster shape and distribution is lost, which may lead to wrong interpretation of explanations. In this paper, we introduce a method that aids end experts in cluster analysis with human-readable rule-based explanations. We use state-of-the-art explanation mechanism on the multidimensional bounding boxes that represent arbitrarily-shaped clusters. We demonstrate our approach on reproducible synthetic datasets. © 2021 IEEE.","10.1109/DSAA53316.2021.9564220","Conference paper","2021","Cluster analysis; Clustering algorithms; Decision making; Supervised learning; AI systems; Bounding-box; Clusterings; Decision-making process; Explainable AI; Human-readable; Learning tasks; Rule based; Supervised machine learning; Unsupervised algorithms; Data mining","Scopus"
"AI Healthcare System Interface: Explanation Design for Non-Expert User Trust","Research indicates that non-expert users tend to either over-trust or distrust AI systems. This raises concerns when AI is applied to healthcare, where a patient trusting the advice of an unreliable system, or completely distrusting a reliable one, can lead to fatal incidents or missed healthcare opportunities. Previous research indicated that explanations can help users to make appropriate judgements on AI Systems' trust, but how to design AI explanation interfaces for non-expert users in a medical support scenarios is still an open research challenge. This paper explores a stage-based participatory design process to develop a trustworthy explanation interface for non-experts in an AI medical support scenario. A trustworthy explanation is an explanation that helps users to make considered judgments on trusting (or not) and AI system for their healthcare. The objective of this paper was to identify the explanation components that can effectively inform the design of a trustworthy explanation interface. To achieve that, we undertook three data collections, examining experts' and non-experts' perceptions of AI medical support system's explanations. We then developed a User Mental Model, an Expert Mental Model, and a Target Mental Model of explanation, describing how non-expert and experts understand explanations, how their understandings differ, and how it can be combined. Based on the Target Mental Model, we then propose a set of 14 explanation design guidelines for trustworthy AI Healthcare System explanation, that take into account non-expert users needs, medical experts practice, and AI experts understanding. © 2020  Copyright © 2021 for this paper by its authors.","","Conference paper","2021","Cognitive systems; Design; Health care; User interfaces; Data collection; Explanation interfaces; Fatal incidents; Health-care system; Medical experts; Participatory design; Research challenges; Support systems; Artificial intelligence","Scopus"
"Evaluating XAI: A comparison of rule-based and example-based explanations","Current developments in Artificial Intelligence (AI) led to a resurgence of Explainable AI (XAI). New methods are being researched to obtain information from AI systems in order to generate explanations for their output. However, there is an overall lack of valid and reliable evaluations of the effects on users' experience of, and behavior in response to explanations. New XAI methods are often based on an intuitive notion what an effective explanation should be. Rule- and example-based contrastive explanations are two exemplary explanation styles. In this study we evaluate the effects of these two explanation styles on system understanding, persuasive power and task performance in the context of decision support in diabetes self-management. Furthermore, we provide three sets of recommendations based on our experience designing this evaluation to help improve future evaluations. Our results show that rule-based explanations have a small positive effect on system understanding, whereas both rule- and example-based explanations seem to persuade users in following the advice even when incorrect. Neither explanation improves task performance compared to no explanation. This can be explained by the fact that both explanation styles only provide details relevant for a single decision, not the underlying rational or causality. These results show the importance of user evaluations in assessing the current assumptions and intuitions on effective explanations. © 2020 Elsevier B.V.","10.1016/j.artint.2020.103404","Article","2021","Decision support systems; User experience; Decision supports; Diabetes self-management; Example based; OR-causality; Single decision; Task performance; User evaluations; Users' experiences; Artificial intelligence","Scopus"
"Qunomon: A FAIR testbed of quality evaluation for machine learning models","Rapid development of artificial intelligence (AI) technologies brings quality and reliability issues to real-world applications and business products, as well as their advanced performance. However, traditional testing methods of the quality of engineering systems have difficulties supporting AI systems with machine learning (ML) based on large-scale data due to their uncertainty, non-deterministic, and vulnerability. Academic fields have studied new techniques to manage and guarantee high-quality ML components in AI systems with the importance of realizing trustworthy AI. Moreover, regulatory authorities have developed new guidelines and rules for safe and broad market adoption to control quality. Although there is a lot of effort from both sides, ML quality control and assessment pose challenges that arise from gaps between their different points of view. This paper proposes a new testbed called 'Qunomon (QUality + gNOMON)' that harmonizes gaps of two sides and supports the combination and comparison of various testing methods in ML component quality. The testbed is designed to improve the findability, accessibility, interoperability, and reusability of testing methods. Furthermore, we show the efficiency of quality testing and reporting with case studies where our testbed is applied. © 2021 IEEE.","10.1109/APSECW53869.2021.00015","Conference paper","2021","Interoperability; Machine learning; Quality control; Reusability; Artificial intelligence systems; Artificial intelligence technologies; Business products; Machine learning models; Performance; Quality assessment; Quality evaluation; Real-world; Software testings; Testing method; Testbeds","Scopus"
"Band-selection of a portal LED-induced autofluorescence multispectral imager to improve oral cancer detection","This aim of this study was to find effective spectral bands for the early detection of oral cancer. The spectral images in different bands were acquired using a self-made portable light-emit-ting diode (LED)-induced autofluorescence multispectral imager equipped with 365 and 405 nm excitation LEDs, emission filters with center wavelengths of 470, 505, 525, 532, 550, 595, 632, 635, and 695 nm, and a color image sensor. The spectral images of 218 healthy points in 62 healthy participants and 218 tumor points in 62 patients were collected in the ex vivo trials at China Medical University Hospital. These ex vivo trials were similar to in vivo because the spectral images of anatomical specimens were immediately acquired after the on-site tumor resection. The spectral images associated with red, blue, and green filters correlated with and without nine emission filters were quantized by four computing method, including summated intensity, the highest number of the intensity level, entropy, and fractional dimension. The combination of four computing methods, two excitation light sources with two intensities, and 30 spectral bands in three experiments formed 264 classifiers. The quantized data in each classifier was divided into two groups: one was the training group optimizing the threshold of the quantized data, and the other was validating group tested under this optimized threshold. The sensitivity, specificity, and accuracy of each classifier were de-rived from these tests. To identify the influential spectral bands based on the area under the region and the testing results, a single-layer network learning process was used. This was compared to conventional rules-based approaches to show its superior and faster performance. Consequently, four emission filters with the center wavelengths of 470, 505, 532, and 550 nm were selected by an AI-based method and verified using a rule-based approach. The sensitivities of six classifiers using these emission filters were more significant than 90%. The average sensitivity of these was about 96.15%, the average specificity was approximately 69.55%, and the average accuracy was about 82.85%. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s21093219","Article","2021","China; Humans; Liver; Mouth Neoplasms; Classification (of information); Diseases; Green computing; Light emitting diodes; Medical imaging; Network layers; Spectroscopy; Tumors; Average sensitivities; Center wavelength; Color image sensors; Computing methods; Emission filters; Excitation light sources; Oral cancer detection; Rule-based approach; China; diagnostic imaging; human; liver; mouth tumor; Image enhancement","Scopus"
"Simultaneous Causal Noise Removal for Causal Rule Discovery and Learning","Identifying cause and effect, or for that matter correlations, between events is critical for the operations of general AI or robotic systems. Being able to learn correlations or causalities enables the system to predict what future events may occur based on the currently observed events, or to know what actions can be taken to effect future consequences. This is useful for prediction and problem solving processes that are very important aspects of intelligent capabilities. However, the purported correlations or causalities are often accompanied by unrelated noisy events. The noise can intervene between the relevant events, and are termed diachronic causal or correlational noise. The noise can also occur concomitantly with the events of interest, and are termed simultaneous causal or correlational noise. While there has been previous work that addresses the issue of diachronic causal or correlational noise, simultaneous causal or correlational noise, especially in a symbolic rule learning process, has not been adequately addressed. This paper presents an algorithm to remove simultaneous causal noise in order to recover the correct causal rules involved. The same method can also be applied to a correlational situation. © 2021 IEEE.","10.1109/SSCI50451.2021.9659961","Conference paper","2021","AI systems; Causal learning; Causal noise; Causality; Cause and effects; Noises removal; OR-causality; Rule discovery; Rule learning; Simultaneous causal noise; Learning systems","Scopus"
"Artificial Intelligence in Agri-Food Systems—An Introduction","Artificial intelligence (AI) is a replacement to human intelligence with expanded capabilities that has empowered the industries to handle and drive more complex systems. In agri-food industrial systems, an artificial intelligent system would drive a system towards the set objectives based on the information and knowledge gathered from the consumers, farmers, machines, and domain experts. Machine learning (ML) is the preferred tool to process the knowledge and information for identifying some underlying rules and patterns to support the implementation of the AI based solution. ML-based AI is preferred, because the heterogeneity in consumer preference, biological variability of material characteristics, and unpredictable system behavior presents a highly complex system to be handled by the rule based expert systems. This chapter gives an insight of the fundamentals of machine learning and deep learning with the emphasis on their application for AI implementation in the field of agri-food material handling. Popular ML algorithms viz., support vector machine (SVM), K-nearest neighbor (KNN), artificial neural networks (ANN), decision trees, and convolutional neural networks (CNN) are discussed as feature description methods for classification and recognition, based on the product images. Works from different researchers are cited to demonstrate the potential application of these techniques for solving real-life complex problems. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.","10.1007/978-981-16-6210-2_3","Article","2021","Consumer behavior; Convolutional neural networks; Decision trees; Deep learning; Expert systems; Intelligent systems; Materials handling; Nearest neighbor search; Support vector machines; Agri-food system; Artificial intelligent; Biological variability; Consumers' preferences; Deep learning; Domain experts; Human intelligence; Industrial systems; Machine experts; Material handling; Complex networks","Scopus"
"CAncer PAtients Better Life Experience (CAPABLE) First Proof-of-Concept Demonstration","The CAncer PAtient Better Life Experience (CAPABLE) project combines the most advanced technologies for data and knowledge management with a socio-psychological approach, to develop a coaching system for improving the quality of life of cancer patients managed at home. The team includes complementary expertise in data- and knowledge-driven AI, data integration, telemedicine and decision support. The time is right to fully exploit Artificial Intelligence for cancer care and bring the benefits right to patients’ homes. CAPABLE relies on predictive models based on both retrospective and prospective data, integrated with computer interpretable guidelines and made available to oncologists. CAPABLE’s Virtual Coach component identifies unexpected needs and provides patient-specific decision support and lifestyle guidance to improve mental and physical wellbeing of patients. The demo, designed around a use-case scenario developed with clinicians involved in the project, addresses the ESMO Diarrhea guideline. It revolves around a prototypical fictional patient named Maria. Maria, 66, is affected by renal cell carcinoma and moderate insomnia. The demo follows Maria during the first three days of using the CAPABLE system. This allows the audience to understand the scope and innovation behind this AI-based decision-support and coaching system that personalizes lifestyle and medication interventions to patients, their carer and clinicians. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-77211-6_34","Conference paper","2021","Data integration; Decision support systems; Diseases; Knowledge management; Patient treatment; Predictive analytics; Advanced technology; Decision supports; Life experiences; Patient specific; Predictive models; Proof of concept; Renal cell carcinoma; Use case scenario; Artificial intelligence","Scopus"
"Technical Briefing: Hands-On Session on the Development of Trustworthy AI Software","Following various real-world incidents involving both purely digital and cyber-physical Artificial Intelligence (AI) systems, AI Ethics has become a prominent topic of discussion in both research and practice, accompanied by various calls for trustworthy AI systems. Failures are often costly, and many of them stem from issues that could have been avoided during development. For example, AI ethics issues, such as data privacy are currently highly topical. However, implementing AI ethics in practice remains a challenge for organizations. Various guidelines have been published to aid companies in doing so, but these have not seen widespread adoption and may feel impractical. In this technical briefing, we discuss how to implement AI ethics. We showcase a method developed for this purpose, ECCOLA, which is based on academic research. ECCOLA is intended to make AI ethics more practical for developers in order to make it easier to incorporate into AI development to create trustworthy AI systems. It is a sprint-based and adaptive tool designed for agile development that facilitates reflection within the development team and helps developers make ethics into tangible product backlog items. © 2021 IEEE.","10.1109/ICSE-Companion52605.2021.00142","Conference paper","2021","Artificial intelligence; Data privacy; Academic research; Adaptive tools; Agile development; Artificial intelligence systems; Cyber physicals; Design method; Development teams; Ethics issues; Intelligence software; Real-world; Philosophical aspects","Scopus"
"A Toolkit to Enable the Design of Trustworthy AI","Technological progress in artificial intelligence (AI) and machine learning (ML) has an enormous impact on our society, economy and environment. And although the urgent need for creating sustainable and ethical AI technology is admitted, there exists a lack of design tools and expertise to facilitate this advancement. This study investigates how to help designers design for the value of trust in AI systems. A literature review unveiled a myriad of ethical AI principles as well as gathered existing tools addressing the research area. Iterative reviews together with an expert on trust in technology evaluated these guidelines and a first iteration of the toolkit containing 28 design principles had been created. Through multiple participatory design workshops the next iteration of the toolkit was co-designed in collaboration with design professionals. The result is an iterated toolkit comprising 16 principles relevant in the design for trust in AI systems, and providing tool suggestions for each principle. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-90963-5_41","Conference paper","2021","Ethical technology; Artificial intelligence guideline; Artificial intelligence systems; Artificial intelligence technologies; Design expertise; Design tool; Ethical artificial intelligence; Human-centered artificial intelligence; Literature reviews; Technological progress; Trustworthy artificial intelligence; Artificial intelligence","Scopus"
"UX Aspects of AI Principles: The Recommender System of VoD Platforms","This paper aims to investigate the user experience with recommender systems of Video on Demand (VoD) platforms based in Machine Learning (ML), focusing on the Artificial Intelligence (AI) principles. We start from the hypothesis that the inclusion of AI algorithms has the potential to improve the user experience in digital systems, but they are still developed with a greater focus on technology, however, they should also consider more aspects regarding human factors. Nine principles on AI related to UX were selected from a compilation of seven lists of government and industry entities to understand the bases that every AI system should respect to ensure a good user experience. In sequence, we discuss their effects on the user experience of VoD platforms. To finish, the experience with these platforms were explored in a directed storytelling method involving thirty-one participants. Some behaviors and patterns found were analyzed and discussed to suggest guidelines to be applied to ML algorithms of VoD Platforms. © Springer Nature Switzerland AG 2021.","10.1007/978-3-030-78227-6_38","Conference paper","2021","Artificial intelligence; Video on demand; Artificial intelligence; Artificial intelligence algorithms; Artificial intelligence systems; Digital system; Machine learning algorithms; Machine-learning; User experience (UX); Users' experiences; Recommender systems","Scopus"
"Data Catalogs: A Systematic Literature Review and Guidelines to Implementation","In enterprises, data is usually distributed across multiple data sources and stored in heterogeneous formats. The harmonization and integration of data is a prerequisite to leverage it for AI initiatives. Recently, data catalogs pose a promising solution to semantically classify and organize data sources across different environments and to enrich raw data with metadata. Data catalogs therefore allow to create a single, clear, and easy-accessible interface for training and testing computational models. Despite a lively discussion among practitioners, there is little research on data catalogs. In this paper, we systematically review existing literature and answer the following questions: (1) What are the conceptual components of a data catalog? and (2) Which guidelines can be recommended to implement a data catalog? The results benefit practitioners in implementing a data catalog to accelerate any AI initiative and researchers with a compilation of future research directions. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-87101-7_15","Conference paper","2021","AI system engineering; AI systems; Computational modelling; Data catalog; Data-source; Enterprise data; Harmonisation; Multiple data sources; Systematic literature review; Training and testing; Data integration","Scopus"
"Comparison of European Commission's Ethical Guidelines for AI to Other Organizational Ethical Guidelines","The European Commission's Ethical Guidelines for AI has a great relevance on the field since it is very thorough. Hagerdorff (2020) has evaluated 22 different ethical guidelines for AI. He found that in 80 per cent of the guidelines handle privacy, fairness and accountability as minimal requirements of responsible AI system. He also noted that these matters in addition to robustness and explainability are more easily solved as technical matters than the social issues that might be arising from the development of AI system. He found that the company codes of ethics were the most minimalistic which was also verified in our paper. Hagerdorff also found that the ethical guidelines usually do not commit to larger societal interests. This paper compares EC's ethical guidelines with those of IBM, Google and IEEE for getting a picture how the ethical issues are approached in commercial environment. The applied analysis method is data-driven; the ethical guidelines are examined and the common themes are noted to appear. The EC's ethical guidelines are the basis of the comparison. Noticed common themes of these guidelines are accountability, transparency and explainability, diversity, inclusion and fairness, safety and security, and societal wellbeing and humanity, even though all the themes are not discussed in all guidelines in detail. It seems that the ethical guidelines usually do not commit to larger societal interests because the societal issues and wider effects that AI has on the society are hard to write on the form of the simple guidelines. The discussion on the effects of the artificial intelligence on the societies needs to be addressed to political decision-makers and wider audience of researchers than just the developers of the AI or business organizations that exploit artificial intelligence. There is also need for involving the users and target groups to this discussion. © 2021 3rd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2021. All rights reserved.","10.34190/EAIR.21.023","Conference paper","2021","Ethical technology; Robotics; AI systems; Applied analysis; Code of Ethics; Ethic of AI; Ethical guideline for AI; Ethical issues; European Commission; Google+; Organisational; Social issues; Decision making","Scopus"
"Artificial Intelligence, Policing and Ethics - A best practice model for AI enabled policing in Australia","The application of Artificial Intelligence (AI) to policing processes and practices has transformative potential. Despite its potential, utilising AI for policing also comes with risks and challenges. The objective of this article is to provide a starting point for the development of a best practice model for the application of AI to policing in Australia. Such a best practice model would be the first of its kind and could put Australian police departments at the forefront of AI application - enabling Australian police to deploy AI in a way that has broad stake-holder support, maximising effectiveness and ensuring ethical concerns are adequately addressed  © 2021 IEEE.","10.1109/EDOCW52865.2021.00032","Conference paper","2021","Ethical technology; Law enforcement; Australia; Best practices; Ethical concerns; Governance; Law; Policing; Stake holders; Artificial intelligence","Scopus"
"What's up with Requirements Engineering for Artificial Intelligence Systems?","In traditional approaches to building software systems (that do not include an Artificial Intelligent (AI) or Machine Learning (ML) component), Requirements Engineering (RE) activities are well-established and researched. However, building software systems with one or more AI components may depend heavily on data with limited or no insight into the system's workings. Therefore, engineering such systems poses significant new challenges to RE. Our search showed that literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI). Our study's main objective was to investigate current approaches in writing requirements for AI/ML systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. We performed a Systematic Literature Review (SLR) of current RE4AI methods and identified 27 primary studies. Using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing RE4AI practices. We further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in Google PAIR). The SLR findings highlighted that present RE applications were not adaptive to manage most AI/ML systems and emphasised the need to provide new techniques and tools to support RE4AI.  © 2021 IEEE.","10.1109/RE51729.2021.00008","Conference paper","2021","Computer software; Machine learning; 'current; Artificial intelligent; Building softwares; Engineering activities; Intelligent machine; Machine learning systems; Machine-learning; Requirement engineering; Software-systems; Systematic literature review; Requirements engineering","Scopus"
"Theory of Mind Helps to Predict Neurodegenerative Processes in Parkinson’s Disease","Normally, it takes many years of theoretical and clinical training for a physician to be the movement disorder specialist. It takes additional multiple years of the clinical practice to handle various “non-typical” cases. The purpose of our study was to predict neurodegenerative disease development by abstract rules learned from experienced neurologists. Theory of mind (ToM) is human’s ability to represent mental states such as emotions, intensions or knowledge of others. ToM is crucial not only in human social interactions but also is used by neurologists to find an optimal treatment for patients with neurodegenerative pathologies such as Parkinson’s disease (PD). On the basis of doctors’ expertise, we have used supervised learning to build AI system that consists of abstract granules representing ToM of several movement disorders neurologists (their knowledge and intuitions). We were looking for similarities between granules of patients in different disease stages to granules of more advanced PD patients. We have compared group of 23 PD with attributes measured three times every half of the year (G1V1, G1V2, G1V3) to other group of 24 more advanced PD (G2V1). By means of the supervised learning and rough set theory we have found rules describing symptoms of G2V1 and applied them to G1V1, G1V2, and G1V3. We have obtained the following accuracies for all/speed/emotion/cognition attributes: G1V1: 68/59/53/72%; G1V2: 72/70/79/79%; G1V3: 82/92/71/74%. These results support our hypothesis that divergent sets of granules were characteristic for different brain’s parts that might degenerate in non-uniform ways with Parkinson’s disease progression. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-77967-2_45","Conference paper","2021","Computation theory; Granulation; Patient treatment; Rough set theory; Supervised learning; Clinical practices; Clinical training; Disease progression; Human social interactions; Movement disorders; Neurodegenerative; Optimal treatment; Theory of minds; Neurodegenerative diseases","Scopus"
"Applying Deutsch's concept of good explanations to artificial intelligence and neuroscience – An initial exploration","Artificial intelligence has made great strides since the deep learning revolution, but AI systems remain incapable of learning principles and rules which allow them to extrapolate outside of their training data to new situations. For inspiration we look to the domain of science, where scientists have been able to develop theories which show remarkable ability to extrapolate and sometimes even predict the existence of phenomena which have never been observed before. According to David Deutsch, this type of extrapolation, which he calls “reach”, is due to scientific theories being hard to vary. In this work we investigate Deutsch's hard-to-vary principle and how it relates to more formalized principles in deep learning such as the bias-variance trade-off and Occam's razor. We distinguish internal variability, how much a model/theory can be varied internally while still yielding the same predictions, with external variability, which is how much a model must be varied to predict new, out-of-distribution data. We discuss how to measure internal variability using the notion of the Rashomon set and how to measure external variability using Kolmogorov complexity. We explore what role hard-to-vary explanations play in intelligence by looking at the human brain, the only example of highly general purpose intelligence known. We distinguish two learning systems in the brain – the first operates similar to deep learning and likely underlies most of perception while the second is a more creative system capable of generating hard-to-vary models and explanations of the world. We make contact with Popperian epistemology which suggests that the generation of scientific theories is a not an inductive process but rather an evolutionary process which proceeds through conjecture and refutation. We argue that figuring out how replicate this second system, which is capable of generating hard-to-vary explanations, is a key challenge which needs to be solved in order to realize artificial general intelligence. © 2020 Elsevier B.V.","10.1016/j.cogsys.2020.12.002","Article","2021","Computational complexity; Deep learning; Economic and social effects; Extrapolation; Forecasting; Artificial general intelligences; Bias variance trade off; Evolutionary process; Inductive process; Initial exploration; Internal variability; Kolmogorov complexity; Scientific theories; article; artificial intelligence; brain; deep learning; epistemology; human; neuroscience; perception; prediction; theoretical study; Learning systems","Scopus"
"Biases in AI Systems","This article provides an organization of various kinds of biases that can occur in the AI pipeline starting from dataset creation and problem formulation to data analysis and evaluation. It highlights the challenges associated with the design of bias-mitigation strategies, and it outlines some best practices suggested by researchers. Finally, a set of guidelines is presented that could aid ML developers in identifying potential sources of bias, as well as avoiding the introduction of unwanted biases. The work is meant to serve as an educational resource for ML developers in handling and addressing issues related to bias in AI systems.  © 2021 ACM.","10.1145/3466132.3466134","Article","2021","Queueing theory; AI systems; Analysis and evaluation; Best practices; Educational resource; Mitigation strategy; Potential sources; Problem formulation; Computer science","Scopus"
"On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls","Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice. Copyright © 2021 Zicari, Brusseau, Blomberg, Christensen, Coffee, Ganapini, Gerke, Gilbert, Hickman, Hildt, Holm, Kühne, Madai, Osika, Spezzatti, Schnebel, Tithi, Vetter, Westerlund, Wurth, Amann, Antun, Beretta, Bruneault, Campano, Düdder, Gallucci, Goffi, Haase, Hagendorff, Kringen, Möslein, Ottenheimer, Ozols, Palazzani, Petrin, Tafur, Tørresen, Volland and Kararigas.","10.3389/fhumd.2021.673104","Article","2021","","Scopus"
"Artificial Intelligence Disclosure in the Annual Reports of Spanish IBEX-35 Companies (2018–2019)","This paper explores the information on Artificial Intelligence (AI) that Spanish IBEX 35 listed companies are including in their annual/sustainability reports. The study mainly focuses on the AI systems that companies indicate they are using or developing, the projects they are tackling and the extent to which they follow some principles or ethical guidelines when using AI-based technologies. The study analyses, both from a qualitative and quantitative perspective, the content of the reports of IBEX 35 companies for 2018 and 2019. The findings suggest that although AI reporting is growing because of the interest in these technologies, it is growing in a non-structured way, and that the adoption of ethical approaches to AI is at a very preliminary stage. The paper analyzes some evidence about a part of non-financial disclosure, AI disclosure, which has not been explored yet. It may serve as a starting point for researchers and companies interested in developing clear guidelines on what kind of information is relevant and mandatory for companies to report, what ethical principles or regulations AI applications must follow and how it has to be disclosed. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-73261-5_14","Conference paper","2021","","Scopus"
"Design Methods for Artificial Intelligence Fairness and Transparency","Fairness and transparency in artificial intelligence (AI) continue to become more prevalent as topics for research, design and development. General principles and guidelines for designing ethical and responsible AI systems have been proposed, yet there is a lack of design methods for these kinds of systems. In this paper, we present CoFAIR, a novel method to design user interfaces for exploring fairness, consisting of series of co-design workshops, and wider evaluation. This method can be readily applied in practice by researchers, designers and developers to create responsible and ethical AI systems. ©2021 Copyright for this paper by its authors.","","Conference paper","2021","Design; Philosophical aspects; Transparency; User interfaces; AI systems; Co-designs; Design and Development; Design method; Artificial intelligence","Scopus"
"SK-MOEFS Multi-Objective Evolutionary Fuzzy System Library effectiveness as User-Friendly Cryptocurrency Prediction Tool","The emergence of Cryptocurrency has long foreshadowed a more accessible exchange market. Cryptocurrency is easy to use and trade, and this ease of access into the market brought newcomers into the Crypto-trading scene. This surge of inexperienced newcomers causes market instability and major loss amongst themselves. AI models, algorithms, and systems have been long used as an important aspect of prediction. However, the use of AI systems is complex. AI tools and systems often use complicated mathematical formulas and are not easily understood. Amongst these AI systems, Fuzzy Rule-Based Systems (FRBSs) has one of the most easily understood displays. With accuracy that rivals of other less-understood methods, such as Neural Network, FRBSs present us a choice that is easily used by users while keeping the interface as basic and simple as possible. This paper aims to study the use of FRBSs using SK-MOEFS (SciKit-Multi Objective Evolutionary Fuzzy System) Python Library in predicting a bull signal or a bear signal in the Cryptocurrency market while still preserving FRBSs user-friendly nature. The fuzzy sets are partitioned as Very Low, Low, Medium, High, and Very High. Then the resulting classification are used to signal whether a Cryptocurrency is bearish or bullish on the current day. The parameter used on the system yields an undesirable result of 53% accuracy with 25 Total Rule Length, however still producing the desired ease-of-use nature of FRBSs.  © 2021 IEEE.","10.1109/ICAIBDA53487.2021.9689763","Conference paper","2021","Electronic money; Electronic trading; Evolutionary algorithms; Forecasting; Fuzzy rules; AI systems; Cryptocurrency market; Exchange markets; Fuzzy; Fuzzy inference systems; Fuzzy rule based systems; Multiobjective evolutionary fuzzy systems (MOEFS); Prediction tools; Price forecasting; User friendly; Fuzzy inference","Scopus"
"ConvAbuse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational AI","We present the first English corpus study on abusive language towards three conversational AI systems gathered 'in the wild': an open-domain social bot, a rule-based chatbot, and a task-based system. To account for the complexity of the task, we take a more 'nuanced' approach where our ConvAI dataset reflects fine-grained notions of abuse, as well as views from multiple expert annotators. We find that the distribution of abuse is vastly different compared to other commonly used datasets, with more sexually tinted aggression towards the virtual persona of these systems. Finally, we report results from bench-marking existing models against this data. Unsurprisingly, we find that there is substantial room for improvement with F1 scores below 90%. © 2021 Association for Computational Linguistics","","Conference paper","2021","AI systems; Chatbots; F1 scores; Fine grained; Rule based; Social bots; Task-based","Scopus"
"Artificial Intelligence in Neuro-ophthalmology","Despite the current hype in almost every area of the society and medicine, artificial intelligence (AI) is not very new. Machine learning (ML), one of the first AI methods, was described in the 50s, followed recently by an extraordinary technical development of computers and processing power leading to the current achievements of deep learning (DL). DL is the current state-of-art technique in ML, particularly well adapted for image analysis. DL techniques have allowed new algorithms to make predictions on various outcomes and diagnosis, based on « learning » (training) on large datasets, using either a supervised (labelled data) or un-supervised (unlabelled data) approach. As in other areas of DL, the input data is used for training purposes and needs to be selected according to the highest clinical diagnostic standards, because it represents the « ground truth » or the « reference standard ». All the results provided by a DL algorithm will be compared to this ground truth. After the training phase, the performance of the algorithm is tested, first via internal validation (cross-validation) and, more importantly, via external testing (in totally novel datasets). The datasets used for training, internal validation and external testing need to be distinct and should not intersect at any time. The performance of an algorithm is expressed as diagnostic accuracy, sensitivity, specificity and area under the receiving operating curve (AUC), compared to the reference standard. The current, extraordinary boom of AI requires a high need of rigorous, controlled, prospective evaluations to demonstrate the impact of AI systems in health outcomes. In response to this need, AI consensus groups have recently elaborated international guidelines regarding AI interventions, including instructions and skills required for use of AI systems, including considerations for the handling of input and output data, the human–AI interaction and analysis of error cases [1]. © Springer Nature Switzerland AG 2021. All rights are reserved.","10.1007/978-3-030-78601-4_21","Book chapter","2021","","Scopus"
"Memristive Concept of a High-Dimensional Neuron","We propose a novel concept of a hardware implementation of high-dimensional neurons with the aim of a functional simulation of the human hippocampus. To implement a high-dimensional neuron, we suggest using the arrays of trainable memristive devices as part of the custom-made software-hardware system to provide full neuronal functionality with fine-tuning of synaptic weights according to the self-learning rule. The proposed architecture can enable new efficient approaches to processing big data in artificial intelligence (AI) systems and a new generation of robots. © 2021 IEEE.","10.1109/CNN53494.2021.9580310","Conference paper","2021","Data handling; Intelligent robots; Memristors; Neurons; RRAM; Functional simulations; Hardware implementations; Hardware system; High-dimensional; High-dimensional brain; Higher-dimensional; Neuromorphic; Neuromorphic memory; Novel concept; Software/hardware; Neural networks","Scopus"
"Does change in ethical education influence core moral values? Towards history- and culture-aware morality model with application in automatic moral reasoning","In this study, we focus on ethical education as a means to improve artificial companion's conceptualization of moral decision-making process in human users. In particular, we focus on automatically determining whether changes in ethical education influenced core moral values in humans throughout the century. We analyze ethics as taught in Japan before WWII and today to verify how much the pre-WWII moral attitudes have in common with those of contemporary Japanese, to what degree what is taught as ethics in school overlaps with the general population's understanding of ethics, as well as to verify whether a major reform of the guidelines for teaching the school subject of “ethics” at school after 1946 has changed the way common people approach core moral questions (such as those concerning the sacredness of human life). We selected textbooks used in teaching ethics at school from between 1935 and 1937, and those used in junior high schools today (2019) and analyzed what emotional and moral associations such contents generated. The analysis was performed with an automatic moral and emotional reasoning agent and based on the largest available text corpus in Japanese as well as on the resources of a Japanese digital library. As a result, we found out that, despite changes in stereotypical view on Japan's moral sentiments, especially due to historical events, past and contemporary Japanese share a similar moral evaluation of certain basic moral concepts, although there is a large discrepancy between how they perceive some actions to be beneficial to the society as a whole while at the same time being inconclusive when it comes to assessing the same action's outcome on the individual performing them and in terms of emotional consequences. Some ethical categories, assessed positively before the war, while being associated with a nationalistic trend in education have also disappeared from the scope of interest of post- war society. The findings of this study support suggestions proposed by others that the development of personal AI systems requires supplementation with moral reasoning. Moreover, the paper builds upon this idea and further suggests that AI systems need to be aware of ethics not as a constant, but as a function with a correction on historical and cultural changes in moral reasoning. © 2020 Elsevier B.V.","10.1016/j.cogsys.2020.10.011","Article","2021","Decision making; Digital libraries; History; Philosophical aspects; Artificial companions; Cultural changes; Decision making process; General population; Junior high schools; Moral reasoning; Teaching ethics; Text corpora; article; attitude; ethics; high school; human; human experiment; Japan; Japanese (people); library; morality; outcome assessment; practice guideline; reasoning; teaching; Behavioral research","Scopus"
"A novel understanding of legal syllogism as a starting point for better legal symbolic AI systems","In the two most relevant categories of legal systems, the codified law systems and the case law systems, legal argumentation and legal reasoning are at the heart of legal theory and practice. Here we show that the concept of legal syllogism can be used as a starting point in both legal systems for new computational models of legal reasoning. We argue that legal syllogisms are not merely analytic logical inference rules but involve ampliative analogical inference. We aim to operationalize our account in terms of Context Graphs, i.e. internally consistent logical theories linked through rigorously defined analogical relations called views and argumentative relations such as attack and support. © 2021 Editions Weblaw. All rights reserved.","10.38023/1945d5d5-b8fe-40b6-b05c-00e55cfb8bad","Review","2021","","Scopus"
"A literature review on artificial intelligence and ethics in online learning","In recent years, artificial intelligence (AI) has been used in online learning to improve teaching and learning, with the aim of providing a more efficient, purposeful, adaptive, ubiquitous, and fair learning experiences. However, and as it has been seen in other contexts, the integration of AI can have unforeseen consequences with detrimental effects which can result in unfair and discriminatory decisions. Therefore it is worth thinking about potential risks that learning environments integrating AI systems might pose. This work explores the intersections between AI, online learning, and ethics in order to understand the ethical concerns surrounding this crossroads. We review the main ethical challenges identified in the literature and distill a set of guidelines to support the ethical design and integration of AI systems in online learning environments. This should help ensure that online learning is how is meant to be: accessible, inclusive, fair, and beneficial to society. © 2021 Elsevier Inc. All rights reserved.","10.1016/B978-0-12-823410-5.00006-1","Book chapter","2021","","Scopus"
"A fuzzy logic-based method for incorporating ethics in the internet of things","IoT is expected to have far-reaching consequences on society due to a wide spectrum of applications like smart healthcare, smart transportation, smart agriculture, smart home, etc. However, ethical considerations of AI-enabled smart devices have not been duly considered from a design perspective. In this paper, the authors propose a novel fuzzy logic-based method to incorporate ethics within smart things of IoT. Ethical considerations relevant to a machine context are represented in terms of fuzzy ethics variables (FEVs) and ethics rules. For each ethics rule, a value called scaled ethics value (SEV) is used to indicate its ethical desirability. In order to model flexibility in ethical response, the authors employ the concept of ethics modes that selectively allow scenarios depending on the value of SEV. The method offers a viable mechanism for smart devices to imbue ethical sensitivity that can pave the way for a technology society amenable to human ethics. However, the method does not account for varying ethics, as such incorporating learning mechanisms represent a promising research direction. Copyright © 2021, IGI Global.","10.4018/IJACI.2021070105","Article","2021","Agricultural robots; Automation; Computer circuits; Fuzzy logic; Internet of things; Turing machines; Ethical considerations; Learning mechanism; Modeling flexibility; Smart agricultures; Smart devices; Smart homes; Wide spectrum; Philosophical aspects","Scopus"
"Operationalizing Human-Centered Perspectives in Explainable AI","The realm of Artificial Intelligence (AI)'s impact on our lives is far reaching - with AI systems proliferating high-stakes domains such as healthcare, finance, mobility, law, etc., these systems must be able to explain their decision to diverse end-users comprehensibly. Yet the discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. There is a need to chart the domain and shape the discourse of XAI with reflective discussions from diverse stakeholders. The goal of this workshop is to examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on ""operationalizing"", aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI. © 2021 Owner/Author.","10.1145/3411763.3441342","Conference paper","2021","Human engineering; AI systems; Concrete design; End users; Evaluation methods; Research agenda; Technical levels; User need; Artificial intelligence","Scopus"
"Image processing and qr code application method for construction safety management","Construction safety accidents occur due to a combination of factors. Even a minor accident that could have been treated as a simple injury can lead to a serious accident or death, depending on when and where it occurred. Currently, methods for tracking worker behavior to manage such construction safety accidents are being studied. However, applying the methods to the construction site, various additional elements (e.g., sensors, transmitters, wearing equipment, and control systems) that must be additionally installed and managed are required. The cost of installation and management of these factors increases in proportion to the size of the site and the number of targets to be managed. In addition, the application of new equipment and new rules lowers the work efficiency of workers. In this paper, the following contents are described: (1) system overview, (2) image processing-QR code-based safety management target recognition methodology, and (3) object location discrimination technique applying the geometric transformation. Finally, the proposed methodology was tested to confirm the operation in the field, and the experimental results and conclusions were described in the paper. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11104400","Article","2021","","Scopus"
"The Deficiency of 'Redline/Greenline' Approach to Risk Management in AI Applications","Expanding application of technologies classified as AI draws public attention to associated risks and effective measures for risk mitigation. Policy makers in most countries are currently looking for effective approaches to securing the public interest against AI-related risks and unforeseen consequences of widening AI use. In this connection, there is widespread talk of defining 'red' and 'green' areas for AI technologies, frequently leading to calls to draw 'red lines' and 'green lines' for technological innovation. The authors draw on the analysis of AI related risks in a number of international fora and question the efficacy of this 'redline/greenline' approach in terms of making the benefits of AI available in the society, while not impeding innovation and technological progress. The authors propose that a more nuanced approach is required, which could involve certification of AI system in sensitive applications, or could apply codified ethical principles to derive specific rules for AI use dependent on the risks created by AI in a particular application. © 2021 IEEE.","10.1109/EnT52731.2021.00015","Conference paper","2021","Ethical technology; Risk assessment; Social aspects; AI applications; Classifieds; Codification; Effective measures; Human rights; Innovation; Regulation; Related risk; Risk measures; Risks management; Risk management","Scopus"
"Regulating AI: Considerations that apply across domains","Awareness that AI-based technologies have far outpaced the existing regulatory frameworks have raised challenging questions about how to set limits on the most dangerous developments (lethal autonomous weapons or surveillance bots, for instance). Under the assumption that the robotics industry cannot be relied on to regulate itself, calls for government intervention within the regulatory space-national and international-have multiplied. The various approaches to regulating AI fall into two main categories. A sectoral approach looks to identify the societal risks posed by individual technologies, so that preventive or mitigating strategies can be implemented, on the assumption that the rules applicable to AI, in say the financial industry, would be very different from those relevant to heath care providers. A cross-sectoral approach, by contrast, involves the formulation of rules (whether norms adopted by industrial consensus or laws set down by governmental authority) that, as the name implies, would have application to AI-based technologies in their generality. After surveying some domestic and international initiatives that typify the two approaches, the chapter concludes with a list of 15 recommendations to guide reflection on the promotion of societally beneficial AI. © The Author(s) 2021. All rights reserved.","10.1007/978-3-030-54173-6_21","Book chapter","2021","","Scopus"
"Towards risk modeling for collaborative AI","Collaborative AI systems aim at working together with humans in a shared space to achieve a common goal. This setting imposes potentially hazardous circumstances due to contacts that could harm human beings. Thus, building such systems with strong assurances of compliance with requirements domain specific standards and regulations is of greatest importance. Challenges associated with the achievement of this goal become even more severe when such systems rely on machine learning components rather than such as top-down rule-based AI. In this paper, we introduce a risk modeling approach tailored to Collaborative AI systems. The risk model includes goals, risk events and domain specific indicators that potentially expose humans to hazards. The risk model is then leveraged to drive assurance methods that feed in turn the risk model through insights extracted from run-time evidence. Our envisioned approach is described by means of a running example in the domain of Industry 4.0, where a robotic arm endowed with a visual perception component, implemented with machine learning, collaborates with a human operator for a production-relevant task.  © 2021 IEEE.","10.1109/WAIN52551.2021.00014","Conference paper","2021","Hazards; Industrial robots; Machine learning; Regulatory compliance; Software engineering; AI systems; Domain specific; Human being; Human operator; On-machines; Rule based; Shared spaces; Visual perception; Risk assessment","Scopus"
"Chinese guidelines for the application of colon cancer staging recognition systems based on artificial intelligence platforms (2021)","The incidence and mortality of colon cancer in China are increasing each year. At present, treatment selection for colon cancer patients mainly depends on imaging results, which require a large number of radiologists to interpret. In China, there is a shortage and uneven distribution of experienced radiologists, which leads to delays and bias in the evaluation of imaging data. Based on these considerations, the Colorectal Surgery Group of the Surgery Branch of the Chinese Medical Association in collaboration with experts at Beihang University has independently developed an artificial intelligence (AI)-based recognition system for the preoperative determination of colon cancer stage to partially replace the work of and relieve the pressure on radiologists. These guidelines aim to standardize the use of AI-based recognition systems in the preoperative staging of colon cancer and guide their clinical application. © 2021","10.1016/j.imed.2021.03.002","Article","2021","Deep learning; Surgery; Cancer patients; Cancer staging; Clinical application; Colon cancer; Colorectal surgery; Deep learning; Imaging data; Preoperative staging; Recognition systems; Treatment selection; Diseases","Scopus"
"DAMA - A transparent meta-assistant for data self-determination in smart environments","Global sales of AI-based smart voice assistants and other smart devices are increasing every year. Smart devices are becoming ubiquitous, including living and workspaces. These spaces often have very high privacy requirements, like living rooms, bedrooms or meeting rooms in office environments. Users of smart devices have security and privacy concerns regarding personal data collection, data storage and the use of such data by the devices and the providers. These concerns are aggravated by a lack of transparency by the device manufacturers. As a result, users have limited possibilities to make an informed decision due to missing information or interfaces. While this leads to limited trust regarding the security and privacy of smart devices, for most users, the practical benefit dominates. The project DAMA wants to address user's security and privacy concerns by creating transparency and regulating the smart devices in connection with the respective context (e.g. when users are alone at home or when they have visitors). For this purpose, the project is developing a “meta-assistant”, an assistant that regulates other AI-based assistants and other smart devices. It uses artificial intelligence (AI) for context detection and device regulation. The regulation processes are based on established ethical guidelines, which are adjusted to the project context. © 2021 Gesellschaft fur Informatik (GI). All rights reserved.","","Conference paper","2021","Automation; Data acquisition; Data privacy; Digital storage; Ethical technology; Intelligent buildings; Global sales; Privacy; Privacy concerns; Privacy requirements; Security and privacy; Smart devices; Smart environment; Smart homes; Smart offices; Smart speaker; Transparency","Scopus"
"Measures and Best Practices for Responsible AI","The use of machine learning (ML) based systems has become ubiquitous including their usage in critical applications like medicine and assistive technologies. Therefore, it is important to determine the trustworthiness of these ML models and tasks. A key component in this determination is the development of task specific datasets, metrics, and best practices which are able to measure the various aspects of responsible model development and deployment including robustness, interpretability and fairness. Further, datasets are also key when training for a given task, be it coreference resolution in language modeling or facial recognition in computer vision. Imbalances and inadequate representation in datasets can have repercussions of an undesirable nature. Some common examples include how coreference resolution systems in NLU are often not all gender inclusive, discrepancies in the measurement of how robust and trustworthy machine predictions are in domains where the selective labels problem is prevalent, and discriminatory determination of pain or care levels of people belonging to different demographics in health science applications. Development of task specific datasets which do better in this regard is also extremely vital. In this workshop, we invite contributions towards different (i) datasets which help enhance task performance and inclusivity, (ii) measures and metrics which help in determining the trustworthiness of a model/dataset, (iii) assessment or remediation tools for fairer, more transparent, robust, and reliable models, and (iv) case studies describing responsible development and deployment of AI systems across fields such as healthcare, financial services, insurance, etc. The datasets, measures, mitigation techniques, and best practices could focus on different areas including (but not restricted to) the following: Fairness and Bias Robustness Reliability and Safety Interpretability Explainability Ethical AI Causal Inference Counterfactual Example Analysis They could also be focussed on the applications in diverse fields such as industry, finance, healthcare and beyond. Text based datasets can be in languages other than English as well.  © 2021 Owner/Author.","10.1145/3447548.3469458","Conference paper","2021","Accident prevention; Behavioral research; Face recognition; Health care; Modeling languages; Natural language processing systems; Outsourcing; Reliability analysis; Service industry; Assistive technology; Causal inferences; Co-reference resolutions; Critical applications; Facial recognition; Financial service; Mitigation techniques; Reliability and safeties; Data mining","Scopus"
"HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline","Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system's predictions are significantly correlated to the person's actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline. © 2020","10.1016/j.future.2020.10.030","Article","2021","Ambient intelligence; Automation; Behavioral research; Diagnosis; Forecasting; Intelligent buildings; Accurate prediction; Aging societies; Cognitive decline; Cognitive functions; Collaborative approach; Research efforts; Spatial disorientation; Task performance; Artificial intelligence","Scopus"
"Pros and Cons of Artificial Intelligence - Lessons from E-Government Services in the COVID-19 Pandemic","How to understand the role and impact of information technology and artificial intelligence has triggered a big debate. To explore the pros and cons of artificial intelligence and its applications, this article takes the face mask distribution programs in the COVID-19 pandemic as research objects, conducting a multi-case comparative study of three cities in China. By manual coding of a total of 4560 We Chat official account messages, and by analyzing information related to the distribution process, it was found that: (1) On the demand side, the task complexity, the demand diversity, and the unstructured decision-making process in the public health emergency have exposed some limitations of AI in data collecting and unstructured problem-solving. (2) On the supply side, the procedural and substantive rules designed, together with the reliability of an AI system, will shape the performance of the AI service channel. (3) Though AI and other new technologies are advancing drastically in the pandemic, there is still much room for improvement whether by the optimization of AI systems, or by political control and social participation, and by the supplement of alternative channels such as the community service delivery. © 2021 IEEE.","10.1109/ICAIE53562.2021.00042","Conference paper","2021","Application programs; Artificial intelligence; e-government; Emergency services; Public health; AI systems; Distribution projects; e-Government; E-government services; Face masks; Health emergencies; ITS applications; Pandemic; Public health emergency; Public service deliveries; Decision making","Scopus"
"Gbt-hips: Explaining the classifications of gradient boosted tree ensembles","This research presents Gradient Boosted Tree High Importance Path Snippets (gbt-HIPS), a novel, heuristic method for explaining gradient boosted tree (GBT) classification models by extracting a single classification rule (CR) from the ensemble of decision trees that make up the GBT model. This CR contains the most statistically important boundary values of the input space as antecedent terms. The CR represents a hyper-rectangle of the input space inside which the GBT model is, very reliably, classifying all instances with the same class label as the explanandum instance. In a benchmark test using nine data sets and five competing state-of-the-art methods, gbt-HIPS offered the best trade-off between coverage (0.16–0.75) and precision (0.85–0.98). Unlike competing methods, gbt-HIPS is also demonstrably guarded against under-and over-fitting. A further distinguishing feature of our method is that, unlike much prior work, our explanations also provide counterfactual detail in accordance with widely accepted recommendations for what makes a good explanation. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/app11062511","Article","2021","","Scopus"
"The challenge of responsible AI","The dichotomic vision of artificial intelligence, which emerged during the last years, underlines both the benefits of machine learning in innovation and the negative consequences of AI on organizations and more globally on society. After an historical contextualization of digital transformation, this chapter first provides an understanding of the potential negative impacts of AI, second presents the concept of ethics and its application to AI systems, third describes different initiatives to tackle the issue of negative consequences of AI. It also illustrates the theoretical aspects of ethics in AI by analyzing current technologies presented at CES 2020 in Las Vegas. Finally, the chapter provides guidelines for managers to address the issue of ethics in AI, including metrics for corporate social responsibility. © Margherita Pagani and Renaud Champion 2021.","","Book chapter","2021","","Scopus"
"Towards explainable, compliant and adaptive human-automation interaction","AI-based systems use trained machine learning models to make important decisions in critical contexts. The EU guidelines for trustworthy AI emphasise the respect for human autonomy, prevention of harm, fairness, and explicability. Many successful machine learning methods, however, deliver opaque models where the reasons for decisions remain unclear to the end user. Hence, accountability and trust are difficult to ascertain. In this position paper, we focus on AI systems that are expected to interact with humans and we propose our visionary architecture, called ECA-HAI (Explainable, Compliant and Adaptive Human-Automation Interaction)-RefArch. ECA-HAI-RefArch allows for building intelligent systems where humans and AIs form teams, able to learn from data but also to learn from each other by playing “serious games”, for a continuous improvement of the overall system. Finally, conclusions are drawn. © 2020 for this paper by its authors.","","Conference paper","2021","Intelligent systems; Machine learning; Serious games; AI systems; Building intelligent systems; Continuous improvements; EU guidelines; Human-automation interactions; Machine learning methods; Machine learning models; Position papers; Man machine systems","Scopus"
"NEU-chatbot: Chatbot for admission of National Economics University","In the last few years, intelligent chatbot systems have been prevalent in various application fields, especially in education. Therefore, the demand for such online consulting services like chatbots is getting higher respectively. However, most communications between potential students and universities are performed manually, which is very time-consuming procedure, becoming a burden on the head of admissions. In this paper, we introduce an AI-based chatbot where students can instantly get daily updates of curriculum, admission for new students, tuition fees, IELTS writing task II score, etc. Our chatbot was developed by Deep Learning models, which are already integrated into the Rasa framework. We also proposed a rational pipeline for Vietnamese chatbots with our data preprocessing to obtain optimal accuracy and to avoid the overfitting of the model. Our model can detect more than fifty types of questions from users' input with an accuracy of 97.1% on test set. The chatbot was applied for National Economics University's official admission Fanpage on the Facebook platform, which is the most famous social network in Vietnam. This research shows detailed guidelines on how to build an AI chatbot from scratch, and the techniques we used, which can be applied to any language globally. © 2021 The Authors","10.1016/j.caeai.2021.100036","Article","2021","","Scopus"
"Responsible AI: A Primer for the Legal Community","Artificial intelligence (AI) is increasingly being adopted for automation and decision-making tasks across all industries, public sector, and law. Applications range from hiring and credit limit decisions, to loan and healthcare claim approvals, to criminal sentencing, and even the selective provision of information by social media companies to different groups of viewers. The increased adoption of AI, affecting so many aspects of our daily lives, highlights the potential risks around automated decision making and the need for better governance and ethical standards when deploying such systems. In response to that need, governments, states, municipalities, private sector organizations, and industry groups around the world have drafted hundreds, perhaps even thousands at this point - of new, regulatory proposals and guidelines; many already in effect and more on the way. The data-driven and often black box nature of these systems does not absolve organizations from the social responsibility or increasingly commonplace regulatory requirements to confirm they work as intended and are deployed in a responsible manner, lest they run the risk of reputational damage, regulatory fines, and/or legal action. The legal community should have a good understanding of the responsible development and deployment of artificial intelligence in order to inform, translate, and advise on the legal implications of AI systems. © 2020 IEEE.","10.1109/BigData50022.2020.9377738","Conference paper","2020","Behavioral research; Big data; Decision making; Professional aspects; Automated decision making; Ethical standards; Industry groups; Legal implications; Private sector organizations; Regulatory requirements; Reputational damage; Social responsibilities; Artificial intelligence","Scopus"
"AI should embody our values: Investigating journalistic values to inform AI technology design","In the current climate of shrinking newsrooms and revenues, journalists face increasing pressures exerted by the industry's for-profit focus and the expectation of intensified output. While AI-enabled journalism has great potential to help alleviate journalists' pressures, it might also disrupt journalistic norms and, at worst, interfere with their duty to inform the public. For AI systems to be as useful as possible, designers should understand journalists' professional values and incorporate them into their designs. We report findings from interviews with journalists to understand their perceptions of how professional values that are important to them (such as truth, impartiality and originality) might be supported and/or undermined by AI technologies. Based on these findings, we provide design insight and guidelines for incorporating values into the design of AI systems. We argue HCI design can achieve the strongest possible value alignment by moving beyond merely supporting important values, to truly embodying them. © 2020 ACM.","10.1145/3419249.3420105","Conference paper","2020","Artificial intelligence; AI systems; AI Technologies; Design insights; HCI design; Important value; Human computer interaction","Scopus"
"Artificial intelligence and legal liability: towards an international approach of proportional liability based on risk sharing","This paper critically examines the allocation of liability when autonomous artificial intelligence (AI) systems cause accidents. Problems of applying existing principles of legal liability in AI environment are addressed. This paper argues that the sharing of risk as a basis for proportionate liability should be a basis for a new liability regime to govern future autonomous machines. It is argued that this approach favors the reality of parties’ consent to taking the risk of unpredictable AI behavior over the technicality of existing principles of legal liability. The suggested approach also encourages transparency and responsible decisions of developers and owners of AI systems. A flowchart to clarify possible outcomes of applying the suggested approach is provided. The paper also discusses the need for harmonization of national laws and international cooperation regarding AI incidents crossing national borders to ensure predictability of legal rules governing the liability ensuing from AI applications. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","10.1080/13600834.2020.1856025","Article","2021","","Scopus"
"An on-device deep learning approach to battery saving on industrial mobile terminals","The mobile terminals used in the logistics industry can be exposed to wildly varying environments, which may hinder effective operation. In particular, those used in cold storages can be subject to frosting in the scanner window when they are carried out of the warehouses to a room-temperature space outside. To prevent this, they usually employ a film heater on the scanner window. However, the temperature and humidity conditions of the surrounding environment and the temperature of the terminal itself that cause frosting vary widely. Due to the complicated frost-forming conditions, existing industrial mobile terminals choose to implement rather simple rules that operate the film heater well above the freezing point, which inevitably leads to inefficient energy use. This paper demonstrates that to avoid such waste, on-device artificial intelligence (AI) a.k.a. edge AI can be readily employed to industrial mobile terminals and can improve their energy efficiency. We propose an artificial-intelligence-based approach that utilizes deep learning technology to avoid the energy-wasting defrosting operations. By combining the traditional temperature-sensing logic with a convolutional neural network (CNN) classifier that visually checks for frost, we can more precisely control the defrosting operation. We embed the CNN classifier in the device and demonstrate that the approach significantly reduces the energy consumption. On our test terminal, the net ratio of the energy consumption by the existing system to that of the edge AI for the heating film is almost 14:1. Even with the common current-dissipation accounted for, our edge AI system would increase the operating hours by 86%, or by more than 6 h compared with the system without the edge AI. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/s20144044","Article","2020","Cold storage; Computer terminals; Convolutional neural networks; Defrosting; Electric batteries; Energy efficiency; Energy utilization; Mobile telecommunication systems; Scanning; Current dissipation; Forming conditions; Learning approach; Learning technology; Logistics industry; Surrounding environment; Temperature and humidities; Temperature sensing; article; artificial intelligence; classifier; controlled study; convolutional neural network; deep learning; energy conservation; energy consumption; freezing point; heating; humidity; logic; temperature sensitivity; Deep learning","Scopus"
"Robustness of AI-based prognostic and systems health management","Prognostic and systems Health Management (PHM) is an integral part of a system. It is used for solving reliability problems that often manifest due to complexities in design, manufacturing, operating environment and system maintenance. For safety-critical applications, using a model-based development process for complex systems might not always be ideal but it is equally important to establish the robustness of the solution. The information revolution has allowed data-driven methods to diffuse within this field to construct the requisite process (or system models) to cope with the so-called big data phenomenon. This is supported by large datasets that help machine-learning models achieve impressive accuracy. AI technologies are now being integrated into many PHM related applications including aerospace, automotive, medical robots and even autonomous weapon systems. However, with such rapid growth in complexity and connectivity, a systems’ behaviour is influenced in unforeseen ways by cyberattacks, human errors, working with incorrect or incomplete models and even adversarial phenomena. Many of these models depend on the training data and how well the data represents the test data. These issues require fine-tuning and even retraining the models when there is even a small change in operating conditions or equipment. Yet, there is still ambiguity associated with their implementation, even if the learning algorithms classify accordingly. Uncertainties can lie in any part of the AI-based PHM model, including in the requirements, assumptions, or even in the data used for training and validation. These factors lead to sub-optimal solutions with an open interpretation as to why the requirements have not been met. This warrants the need for achieving a level of robustness in the implemented PHM, which is a challenging task in a machine learning solution. This article aims to present a framework for testing the robustness of AI-based PHM. It reviews some key milestones achieved in the AI research community to deal with three particular issues relevant for AI-based PHM in safety-critical applications: robustness to model errors, robustness to unknown phenomena and empirical evaluation of robustness during deployment. To deal with model errors, many techniques from probabilistic inference and robust optimisation are often used to provide some robustness guarantee metric. In the case of unknown phenomena, techniques include anomaly detection methods, using causal models, the construction of ensembles and reinforcement learning. It elicits from the authors’ work on fault diagnostics and robust optimisation via machine learning techniques to offer guidelines to the PHM research community. Finally, challenges and future directions are also examined; on how to better cope with any uncertainties as they appear during the operating life of an asset. © 2021","10.1016/j.arcontrol.2021.04.001","Article","2021","Anomaly detection; Diagnosis; Errors; Large dataset; Learning algorithms; Medical robotics; Optimization; Reinforcement learning; Safety engineering; Security of data; Turing machines; Anomaly detection methods; Machine learning models; Machine learning techniques; Model based development; Probabilistic inference; Robustness to modeling errors; Safety critical applications; Systems health management; Learning systems","Scopus"
"The Ethics of AI Ethics: An Evaluation of Guidelines","Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the “disruptive” potentials of new AI technologies. Designed as a semi-systematic evaluation, this paper analyzes and compares 22 guidelines, highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems—and how the effectiveness in the demands of AI ethics can be improved. © 2020, The Author(s).","10.1007/s11023-020-09517-8","Article","2020","Artificial intelligence; Learning systems; AI systems; AI Technologies; Development and applications; Ethical principles; Ethics; Guidelines; Implementation; Systematic evaluation; Philosophical aspects","Scopus"
"Towards the assessment of easy-to-read guidelines using artificial intelligence techniques","The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities, who have difficulties in reading comprehension. The main goal of the E2R Methodology is to present clear and easily understood documents. This methodology includes a set of guidelines and recommendations that affect the writing of texts, the supporting images, the design and layout of documents, and the final editing format. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. The process of adapting existing documents is cyclic and implies three activities: analysis, transformation, and validation. All these activities are human resource consuming, due to the need of involving people with cognitive disabilities as well as E2R experts. In order to alleviate such processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to perform the analysis and transformation of documents in a (semi)-automatic fashion. In this paper we present our AI-based method for assessing a particular document with respect to the E2R guidelines as well as an initial implementation of such a method; our research on the transformation of documents is out of the scope of this paper. We carried out a comparative evaluation of the results obtained by our initial implementation against the results of the document analysis performed by people with cognitive disabilities. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-58796-3_10","Conference paper","2020","Computer science; Computers; Artificial intelligence techniques; Cognitive disability; Comparative evaluations; Daily lives; Document analysis; Manual process; Reading comprehension; Artificial intelligence","Scopus"
"An Advanced Framework for Critical Infrastructure Protection Using Computer Vision Technologies","Over the past decade, there has been unprecedented advancements in the field of computer vision by adopting AI-based solutions. In particular, cutting edge computer vision technology based on deep-learning approaches has been deployed with an extraordinary degree of success. The ability to extract semantic concepts from continuous processing of video stream in real-time has led to the investigation of such solutions to enhance the operational security of critical infrastructure against intruders. Despite the success of computer vision technologies validated in a laboratory environment, there still exists several challenges that limit the deployment of these solutions in operational environment. Addressing these challenges, the paper presents a framework that integrates three main computer vision technologies namely (i) person detection; (ii) person re-identification and (iii) face recognition to enhance the operational security of critical infrastructure perimeter. The novelty of the proposed framework relies on the integration of key technical innovations that satisfies the operational requirements of critical infrastructure in using computer vision technologies. One such requirement relates to data privacy and citizen rights, following the implementation of General Data Protection Regulation across Europe for the successful adoption of video surveillance for infrastructure security. The video analytics solution proposed in the paper integrates privacy preserving technologies, high-level rule engine for threat identification and a knowledge model for escalating threat categorises to human operator. The various components of the proposed framework has been validated using commercially available graphical processing units for detecting intruders. The performance o the proposed framework has been evaluated in operational environments of the critical infrastructure. An overall accuracy of 97% is observed in generating alerts against malicious intruders. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-69781-5_8","Conference paper","2021","Computer vision; Deep learning; Face recognition; Graphics processing unit; Privacy by design; Public works; Security systems; Semantics; Computer vision technology; Critical infrastructure protection; General data protection regulations; Graphical processing unit (GPUs); Infrastructure security; Operational environments; Operational requirements; Person re identifications; Critical infrastructures","Scopus"
"MIRAI: A Modifiable, Interpretable, and Rational AI Decision Support System","With the recent advancements and results obtained by Deep Learning, several corporations are eager to begin adapting AI into their workflow to benefit from these systems, especially with the emergence of Industry 4.0. However, decision makers find themselves unable to fully trust AI systems from evaluation metrics alone and require some more transparency in their systems. As such, research has gone in the direction of Explainable AI (XAI), where the inner mechanics and reasoning processes of these learning systems are presented in such a way that it is interpretable by humans, opening the Black Box of opaque AI algorithms. This study intends to develop a Big Data and Online Learning-based Explaining AI architecture which utilizes a novel approach of combining Rule-Based Reasoning methodology alongside an explainable Deep Learning framework in order to create a system capable of a higher level of reasoning, or ‘Deep Understanding’. Evaluation for this system is to take place by means of standard Machine Learning evaluation metrics such as F1-Scores, Precision, Recall, and ROC Curves. Alongside this, user-feedback evaluation forms from relevant personnel will be used to verify how useful the explanations are in production. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-61045-6_10","Book chapter","2021","","Scopus"
"Employing hybrid reasoning to support clinical decision-making","Clinical reasoning, involving abstraction, abduction, deduction, and induction, is the primary tool that physicians use when making clinical decisions. To support them, we focus on the creation of an AI system that is able to emulate clinical reasoning. We leverage Semantic Web technologies to perform a set of AI tasks involving the various forms of inference associated with clinical reasoning strategies. In particular, for the scope of this work, we focus on clinical problems that require differential diagnosis techniques. For a given clinical scenario, overlapping reasoning types and strategies may be employed by a physician in conjunction, signifying the need for our AI system to perform hybrid reasoning. Therefore, we consider the construction of a hybrid reasoner that is compatible with description logics. For medical scenarios where description logics may not have some needed expressivity, we consider possible extensions that will allow for the representation of such a scenario. The reasoning system, clinical rule representation, and the resulting recommendations will be evaluated based on domain expert consultation in order to determine whether the recommendation aligns with what the expert would recommend. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2020","Data description; Decision making; Diagnosis; Formal languages; Knowledge acquisition; Clinical decision; Clinical decision making; Clinical problems; Clinical reasoning; Differential diagnosis; Hybrid reasonings; Rule representation; Semantic Web technology; Semantic Web","Scopus"
"Ambiguity-aware AI Assistants for Medical Data Analysis","Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments. © 2020 Owner/Author.","10.1145/3313831.3376506","Conference paper","2020","Decision making; Human engineering; Uncertainty analysis; Classification labels; Clinical assessments; Clinical decision making; Medical data analysis; Medical time series; Real-world; Uncertainty estimates; Work-flows; Artificial intelligence","Scopus"
"Fast Real-Time Reinforcement Learning for Partially-Observable Large-Scale Systems","We propose a fast real-time reinforcement learning (RL) control algorithm for large-scale partially-observable linear dynamic systems. We first develop a one-shot RL method for designing model-free optimal controllers based on a finite-time history of the inputs and the outputs. However, when the system dimension is large, this method may suffer from a long learning time. To overcome this problem, in the second half of the paper we introduce a new notion of approximation to the design, where the original set of input-output history is replaced by a much shorter set. We show that this approximation can lead to a nearly optimal controller that is based on a lower-dimensional approximant of the original system in terms of reachability and observability. We provide a guideline for determining an appropriate length of the input-output history to reduce the suboptimality gap. The dimension of the resulting suboptimal controller is far less than that of the optimal controller, thereby speeding up learning time. The learned controller, however may cause instability when implemented in the original high-dimensional system by adversely exciting the approximation error. We theoretically establish the conditions for closed-loop stability using robust control theory, followed by numerical investigations of the trade-offs between learning time, length of input/output history, and closed-loop performance. The effectiveness of the method is illustrated using examples from electric power systems, modeled by partially-observable nonlinear differential-algebraic equations. Impact Statement-Timing is a critical factor in the design and implementation of all AI-based control systems. For example, when avoiding collisions in a transportation network, or when controlling the electric power grid, control actions need to be taken just-in-time to avoid catastrophic consequences that could occur. Existing AI-based control laws have poor scalability due to the significant time needed to learn a controller on-the-fly. The problem is compounded due to constraints imposed by sensors and the limited set of measurements associated with partial observability of a plant. This paper proposes an approximation framework for large networks with such constraints, whereby the size of the controller can be projected onto a significantly lower-dimensional space, allowing orders of magnitude speed-up in learning and design time. The approach has the potential to transform AI-based control from slow models to fast ones with practical implications for any extreme-scale control application. © 2021 IEEE.","10.1109/TAI.2021.3058228","Article","2020","","Scopus"
"Rule-Based Safety Evidence for Neural Networks","Neural networks have many applications in safety and mission critical systems. As industrial standards in various safety-critical domains require developers of critical systems to provide safety assurance, tools and techniques must be developed that enable effective creation of safety evidence for AI systems. In this position paper, we propose the use of rules extracted from neural networks as artefacts for safety evidence. We discuss the rationale behind the use of rules and illustrate it using the MNIST dataset. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-55583-2_24","Conference paper","2020","Accident prevention; Embedded systems; System of systems; Critical systems; Industrial standards; Mission critical systems; Position papers; Safety assurance; Safety evidences; Safety-critical domain; Tools and techniques; Neural networks","Scopus"
"Decentered ethics in the machine era and guidance for AI regulation","Recent advancements in AI have prompted a large number of AI ethics guidelines published by governments and nonprofits. While many of these papers propose concrete or seemingly applicable ideas, few philosophically sound proposals are made. In particular, we observe that the line of questioning has often not been examined critically and underlying conceptual problems not always dealt with at the root. In this paper, we investigate the nature of ethical AI systems and what their moral status might be by first turning to the notions of moral agency and patience. We find that their explication would come at a too high cost which is why we, second, articulate a different approach that avoids vague and ambiguous concepts or the problem of other minds. Third, we explore the impact of our philosophical and conceptual analysis on the regulatory landscape, make this link explicit, and finally propose a set of promising policy steps. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","10.1007/s00146-019-00920-z","Article","2020","Conceptual analysis; Conceptual problems; Decentralization; High costs; Moral patiency; Moral status; Other minds; Regulations; Philosophical aspects","Scopus"
"A reference architecture for personalized and self-adaptive e-health apps","A wealth of e-Health mobile apps are available for many purposes, such as life style improvement, mental coaching, etc. The interventions, prompts, and encouragements of e-Health apps sometimes take context into account (e.g., previous interactions or geographical location of the user), but they still tend to be rigid, e.g., by using fixed rule sets or being not sufficiently tailored towards individuals. Personalization to the different users’ characteristics and run-time adaptation to their changing needs and context provide a great opportunity for getting users continuously engaged and active, eventually leading to better physical and mental conditions. This paper presents a reference architecture for enabling AI-based personalization and self-adaptation of mobile apps for e-Health. The reference architecture makes use of multiple MAPE loops operating at different levels of granularity and for different purposes. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-59155-7_15","Conference paper","2020","Software architecture; Changing needs; Geographical locations; Life styles; Mobile apps; Personalizations; Reference architecture; Runtime adaptation; Self adaptation; eHealth","Scopus"
"Social contracts for non-cooperative games","In future agent societies, we might see AI systems engaging in selfish, calculated behavior, furthering their owners' interests instead of socially desirable outcomes. How can we promote morally sound behaviour in such settings, in order to obtain more desirable outcomes? A solution from moral philosophy is the concept of a social contract, a set of rules that people would voluntarily commit to in order to obtain better outcomes than those brought by anarchy. We adapt this concept to a game-theoretic setting, to systematically modify the payoffs of a non-cooperative game, so that agents will rationally pursue socially desirable outcomes. We show that for any game, a suitable social contract can be designed to produce an optimal outcome in terms of social welfare. We then investigate the limitations of applying this approach to alternative moral objectives, and establish that, for any alternative moral objective that is significantly different from social welfare, there are games for which no such social contract will be feasible that produces non-negligible social benefit compared to collective selfish behaviour. © 2020 Copyright held by the owner/author(s).","10.1145/3375627.3375829","Conference paper","2020","Agents; Behavioral research; Ethical aspects; Agent society; Game-theoretic; Moral philosophy; Noncooperative game; Selfish behaviours; Social benefits; Social contract; Social welfare; Game theory","Scopus"
"Deep automation bias: How to tackle a wicked problem of ai?","The increasing use of AI in different societal contexts intensified the debate on risks, ethical problems and bias. Accordingly, promising research activities focus on debiasing to strengthen fairness, accountability and transparency in machine learning. There is, though, a tendency to fix societal and ethical issues with technical solutions that may cause additional, wicked problems. Alternative analytical approaches are thus needed to avoid this and to comprehend how societal and ethical issues occur in AI systems. Despite various forms of bias, ultimately, risks result from eventual rule conflicts between the AI system behavior due to feature complexity and user practices with limited options for scrutiny. Hence, although different forms of bias can occur, automation is their common ground. The paper highlights the role of automation and explains why deep automation bias (DAB) is a metarisk of AI. Based on former work it elaborates the main influencing factors and develops a heuristic model for assessing DAB-related risks in AI systems. This model aims at raising problem awareness and training on the sociotechnical risks resulting from AI-based automation and contributes to improving the general explicability of AI systems beyond technical issues. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","10.3390/bdcc5020018","Article","2021","","Scopus"
"Group-to-individual (G2i) inferences: challenges in modeling how the U.S. court system uses brain data","Regardless of formalization used, one on-going challenge for AI systems that model legal proceedings is accounting for contextual issues, particularly where judicial decisions are made in criminal cases. The law assumes a rational approach to rule application in deciding a defendant’s guilt; however, judges and juries can behave irrationally. What should a model prize: efficiency, accuracy, or fairness? Exactly whether and how to incorporate the psychology of courtroom interactions into formal models or expert systems has only just begun to be examined in a serious fashion. Here, I outline data from the United States which suggest that trying to incorporate psychological biases into formal models of legal decision-making will be challenging. I focus on the use of neuroscience data in criminal trials, homing in on so-called group-to-individual (G2i) inferences. I argue that data which should be the most effective at swaying judicial decisions are in fact those most likely not to make a difference in the disposition of the case. I conclude that judges often assign culpability by ignoring what our best science regarding how human decision-making occurs. © 2018, Springer Nature B.V.","10.1007/s10506-018-9234-0","Article","2020","Behavioral research; Crime; Expert systems; Neurology; Ambiguous Data; Bias; Criminal trials; Human decision making; Legal proceedings; Neuroscience; Psychological bias; Rule application; Decision making","Scopus"
"Towards Explainable Artificial Intelligence and Explanation User Interfaces to Open the ‘Black Box’ of Automated ECG Interpretation","This an exploratory paper that discusses the use of artificial intelligence (AI) in ECG interpretation and opportunities for improving the explainability of the AI (XAI) when reading 12-lead ECGs. To develop AI systems, many principles (human rights, well-being, data agency, effectiveness, transparency, accountability, awareness of misuse and competence) must be considered to ensure that the AI is trustworthy and applicable. The current computerised ECG interpretation algorithms can detect different types of heart diseases. However, there are some challenges and shortcomings that need to be addressed, such as the explainability issue and the interaction between the human and the AI for clinical decision making. These challenges create opportunities to develop a trustworthy XAI for automated ECG interpretation with a high performance and a high confidence level. This study reports a proposed XAI interface design in automatic ECG interpretation based on suggestions from previous studies and based on standard guidelines that were developed by the human computer interaction (HCI) community. New XAI interfaces should be developed in the future that facilitate more transparency of the decision logic of the algorithm which may allow users to calibrate their trust and use of the AI system. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-68007-7_6","Conference paper","2021","Behavioral research; Data visualization; Decision making; Electrocardiography; Human computer interaction; Transparency; User interfaces; Visualization; Clinical decision making; Decision logic; ECG interpretation; Heart disease; High confidence; Human computer interaction (HCI); Interface designs; Standard guidelines; Artificial intelligence","Scopus"
"Building explanations for fuzzy decision trees with the expliclas software","Fairness, Accountability, Transparency and Explainability have become strong requirements in most practical applications of Artificial Intelligence (AI). Fuzzy sets and systems are recognized world-wide because of their outstanding contribution to model AI systems with a good interpretability-accuracy trade-off. Accordingly, fuzzy sets and systems are at the core of the so-called Explainable AI. ExpliClas is a software as a service which paves the way for interpretable and self-explainable intelligent systems. Namely, this software provides users with both graphical visualizations and textual explanations associated with intelligent classifiers automatically learned from data. This paper presents the new functionality of ExpliClas regarding the generation, evaluation and explanation of fuzzy decision trees along with fuzzy inference-grams. This new functionality is validated with two well-known classification datasets (i.e., Wine and Pima), but also with a real-world beer-style classifier. © 2020 IEEE.","10.1109/FUZZ48607.2020.9177725","Conference paper","2020","Beer; Classification (of information); Decision trees; Economic and social effects; Forestry; Fuzzy sets; Intelligent systems; Software as a service (SaaS); AI systems; Classification datasets; Fuzzy decision trees; Fuzzy sets and systems; Graphical visualization; Intelligent classifiers; Interpretability; Real-world; Fuzzy inference","Scopus"
"Deep Learning-Based Smart Parking Management System and Business Model","In this fast-developing world, the increase in the number of vehicles demands a smart parking system in smart cities. The issue of spending a lot of time finding parking slots needs to be addressed. The increase of smartphones provides the space to develop smart applications enabled with AI and deep learning. This paper proposes an AI-based smart parking management system and a business model to provide a solution for both user and the owner of the parking space. Owners of the parking slots can opt for fixed or variable timeslots to make use of their parking spaces. Registered users can check the availability of the parking spaces at the destination in real-time and details of the users such as the time and vehicle details can be detected and updated automatically. Billing for the parking space usage will also be done automatically as per the regulated guidelines. Raspberry Pi and deep learning tools are used for the implementation. The proposed system is cost-effective and reduces time and energy. © 2021, Springer Nature Singapore Pte Ltd.","10.1007/978-981-16-1103-2_11","Conference paper","2021","Computer vision; Cost effectiveness; Developing countries; Business modeling; Developing world; Learning tool; Number of vehicles; Parking spaces; Smart applications; Smart parking; Smart parking systems; Deep learning","Scopus"
"Can GPT-3 speak? Wittgensteinian perspectives on human-machine communication","There has been a lot of hype surrounding OpenAI’s impressive language model GPT-3 ever since it was released in mid-2020. Not only AI researchers and journalists were astound-ed by its spectacular performance at generating human-like text in a wide variety of domains – there was also great astonishment in the philosophical community. David Chalmers, for example, calls OpenAI’s autoregressive language model “one of the most interesting and important AI systems ever produced” [1]. This assessment seems appropriate – not least because GPT-3 raises intricate philosophical questions, for instance: “Does the ability to generate ‘speech’ imply communicative ability?” [2] In other words, do machines that produce text or speech possess linguistic competence and qualify as speakers? More trenchantly put: Can GPT-3 speak? My paper develops a framework of human-machine communication which casts new light on the conversational capacity of GPT-3 and other AI-powered text generators. As a major source of inspiration serves Ludwig Wittgenstein’s later philosophy, particularly his much-discussed reflections on rule-following and private language. © 2021 AISB Convention 2021: Communication and Conversations. All rights reserved.","","Conference paper","2021","Philosophical aspects; Auto-regressive; Communicative abilities; Human like; Human-machine communication; Language model; Linguistic competences; Ludwig wittgenstein; Text generators; Computational linguistics","Scopus"
"Towards Responsible AI for Financial Transactions","The application of AI in finance is increasingly dependent on the principles of responsible AI. These principles-explainability, fairness, privacy, accountability, transparency and soundness form the basis for trust in future AI systems. In this empirical study, we address the first principle by providing an explanation for a deep neural nenvork that is trained on a mixture of numerical, categorical and textual inputs for financial transaction classification. The explanation is achieved through (1) a feature importance analysis using Shapley additive explanations (SHAP) and (2) a hybrid approach of text clustering and decision tree classifiers. We then test the robustness of the model by exposing it to a targeted evasion attack, leveraging the knowledge we gained about the model through the extracted explanation.  © 2020 IEEE.","10.1109/SSCI47803.2020.9308456","Conference paper","2020","Decision trees; Intelligent computing; Knowledge management; AI systems; Decision tree classifiers; Empirical studies; Financial transactions; First principles; Hybrid approach; Importance analysis; Text Clustering; Finance","Scopus"
"Analysis of a traditional and a fuzzy logic enhanced perturb and observe algorithm for the mppt of a photovoltaic system","This paper presents the results obtained for the maximum power point tracking (MPPT) technique applied to a photovoltaic (PV) system, composed of five solar panels in series using two different methodologies. First, we considered a traditional Perturb and Observe (P&O) algorithm and in a second stage we applied a Fuzzy Logic Controller (FLC) that uses fuzzy logic concepts to improve the traditional P&O; both were implemented in a boost converter. The main aim of this paper is to study if an artificial intelligence (AI) based MPPT method, can be more efficient, stable and adaptable than a traditional MPPT method, in varying environment conditions, namely solar irradiation and/or environment temperature and also to analyze their behaviour in steady state conditions. The proposed FLC with a rule base collection of 25 rules outperformed the controller using the traditional P&O algorithm due to its adaptative step size, enabling the FLC to adapt the PV system faster to changing environment conditions, guessing the correct maximum power point (MPP) faster and achieving lower oscillations in steady state conditions, leading to higher generated energy due to lower losses both in steady state and dynamic environment conditions. The simulations in this study were performed using MATLAB (Version 2018)/Simulink. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/a14010024","Article","2021","Artificial intelligence; Computer circuits; DC-DC converters; MATLAB; Maximum power point trackers; Photovoltaic cells; Solar power generation; Changing environment; Environment conditions; Environment temperature; Fuzzy logic controllers; Maximum Power Point Tracking; Perturb and observe algorithm; Photovoltaic systems; Steady-state condition; Fuzzy logic","Scopus"
"Using ai techniques in a serious game for socio-moral reasoning development","We present a serious game designed to help players/learners develop socio-moral reasoning (SMR) maturity. It is based on an existing computerized task that was converted into a game to improve the motivation of learners. The learner model is computed using a hybrid deep learning architecture, and adaptation rules are provided by both human experts and machine learning techniques. We conducted some experiments with two versions of the game (the initial version and the adaptive version with AI-Based learner modeling). The results show that the adaptive version provides significant better results in terms of learning gain.  © 2020, Association for the Advancement of Artificial Intelligence.","","Conference paper","2020","Deep learning; Learning systems; Adaptation rules; Adaptive versions; AI techniques; Learner model; Learning architectures; Learning gain; Machine learning techniques; Moral reasoning; Serious games","Scopus"
"ExplainEx: An Explainable Artificial Intelligence Framework for Interpreting Predictive Models","Artificial Intelligence (AI) systems are increasingly dependent on machine learning models which lack interpretability and algorithmic transparency, and hence may not be trusted by its users. The fear of failure in these systems is driving many governments to demand more explanation and accountability. Take, for example, the “Right of Explanation” rule proposed in the European Union in 2019, which gives citizens the right to demand an explanation from AI-based predictions. Explainable Artificial Intelligence (XAI) is an attempt to open up the “black box” and create more explainable systems which create predictive models whose results are easily understandable to humans. This paper describes an explanation model called ExplainEx which automatically generates natural language explanation for predictive models by consuming REST API provided by ExpliClas open-source web service. The classification model consists of four main decision tree algorithms including J48, Random Tree, RepTree and FURIA. The user interface was designed based on Microsoft.Net Framework programming platform. At the background is a software engine automating a seamless interaction between Expliclas API and the trained datasets, to provide natural language explanation to users. Unlike other studies, our proposed model is both a stand-alone and client-server based system capable of providing global explanations for any decision tree classifier. It supports multiple concurrent users in a client-server environment and can apply all four algorithms concurrently on a single dataset, returning both precision score and explanation. It is a ready tool for researchers who have datasets and classifiers prepared for explanation. This work bridges the gap between prediction and explanation, thereby allowing researchers to concentrate on data analysis and building state-of-the-art predictive models. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-73050-5_51","Conference paper","2021","Biomimetics; Boron compounds; Classification (of information); Decision trees; Intelligent systems; Machine learning; Open source software; Sodium compounds; User interfaces; Web services; Classification models; Client-server environment; Decision tree classifiers; Decision-tree algorithm; Interpretability; Natural language explanations; Predictive models; State of the art; Predictive analytics","Scopus"
"Preliminary results of a systematic review: Quality assessment of conversational agents (chatbots) for people with disabilities or special needs","People with disabilities or special needs can benefit from AI-based conversational agents, which are used in competence training and well-being management. Assessment of the quality of interactions with these chatbots is key to being able to reduce dissatisfaction with them and to understand their potential long-term benefits. This will in turn help to increase adherence to their use, thereby improving the quality of life of the large population of end-users that they are able to serve. We systematically reviewed the literature on methods of assessing the perceived quality of interactions with chatbots, and identified only 15 of 192 papers on this topic that included people with disabilities or special needs in their assessments. The results also highlighted the lack of a shared theoretical framework for assessing the perceived quality of interactions with chatbots. Systematic procedures based on reliable and valid methodologies continue to be needed in this field. The current lack of reliable tools and systematic methods for assessing chatbots for people with disabilities and special needs is concerning, and may lead to unreliable systems entering the market with disruptive consequences for users. Three major conclusions can be drawn from this systematic analysis: (i) researchers should adopt consolidated and comparable methodologies to rule out risks in use; (ii) the constructs of satisfaction and acceptability are different, and should be measured separately; (iii) dedicated tools and methods for assessing the quality of interaction with chatbots should be developed and used to enable the generation of comparable evidence. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-58796-3_30","Conference paper","2020","Artificial intelligence; Computer science; Computers; Conversational agents; People with disabilities; Perceived quality; Quality assessment; Quality of interaction; Systematic analysis; Systematic method; Theoretical framework; Risk assessment","Scopus"
"Can Children Emulate a Robotic Non-Player Character's Figural Creativity?","Can intelligent non-player game characters (NPCs) increase children's creativity during collaborative gameplay? Children's creativity is influenced by collaborative play with creative peers through social emulation. In this paper, we study children's emulation of an AI-enabled social Non-Player Character (NPC) as a new type of game mechanism to elicit creative expression. We developed Magic Draw, a collaborative drawing game designed to foster children's figural creativity that allows us to investigate the efficacy of an NPC's creativity demonstration in enhancing children's creativity in the resulting drawings. The NPC is an emotively expressive social robot that plays Magic Draw with a child as a peer-like playmate. We present the results of a study in which participants co-draw figures with a social robot that demonstrates different levels of figural creativity, to understand whether an NPC's creativity in its own contributions stimulates figural creativity in children. 78 participants (ages 5 - 10) were randomly assigned to a non-creative robot control condition (C-) and a creative robot condition (C+). Participants who interacted with the creative robot generated significantly more creative drawings, and hence exhibited higher levels of figural creativity. We infer that the social robotic peers' demonstration of figural creativity in a collaborative drawing game is emulated by young children. We discuss a new game design principle grounded in the social learning mechanism of emulation, specifically, that social and intelligent NPCs in games should demonstrate creative behavior to foster the same in human players.  © 2020 Owner/Author.","10.1145/3410404.3414251","Conference paper","2020","Human computer interaction; Interactive computer systems; Robotics; Collaborative drawing; Collaborative gameplay; Collaborative play; Creativity demonstrations; Non-player character; Robot controls; Social learning; Social robotics; Social robots","Scopus"
"Automated Software Quality Monitoring in Research Collaboration Projects","In collaborative research projects, both researchers and practitioners work together solving business-critical challenges. These projects often deal with ETL processes, in which humans extract information from non-machine-readable documents by hand. AI-based machine learning models can help to solve this problem. Since machine learning approaches are not deterministic, their quality of output may decrease over time. This fact leads to an overall quality loss of the application which embeds machine learning models. Hence, the software qualities in development and production may differ. Machine learning models are black boxes. That makes practitioners skeptical and increases the inhibition threshold for early productive use of research prototypes. Continuous monitoring of software quality in production offers an early response capability on quality loss and encourages the use of machine learning approaches. Furthermore, experts have to ensure that they integrate possible new inputs into the model training as quickly as possible. In this paper, we introduce an architecture pattern with a reference implementation that extends the concept of Metrics Driven Research Collaboration with an automated software quality monitoring in productive use and a possibility to auto-generate new test data coming from processed documents in production. Through automated monitoring of the software quality and auto-generated test data, this approach ensures that the software quality meets and keeps requested thresholds in productive use, even during further continuous deployment and changing input data.  © 2020 ACM.","10.1145/3387940.3391478","Conference paper","2020","Automatic test pattern generation; Automation; Computer software selection and evaluation; Engineering research; Machine learning; Software testing; Technical presentations; Architecture patterns; Collaborative research projects; Continuous monitoring; Extract informations; Machine learning approaches; Machine learning models; Reference implementation; Research collaborations; Software quality","Scopus"
"AI-Enabled Security Monitoring in Smart Cyber Physical Grids","According to the increasing demand for electrical energy, the development of power systems and using smart grid technologies are vital. Smart grids are known as the new generation of power systems applying intelligent tools and features to provide higher performance, stability, reliability, and manageability. For these purposes, power systems face two major challenges. The first one is the systems are more vulnerable to a cyberattack. This vulnerability originates from relying on Information and Communication Technology (ICT) systems. The second challenge is the consumption of fossil fuels as a major power source increases, which is costly and pollutes the environment, so it is necessary to use renewable energy like the wind as an alternative. Regarding enormous fluctuations in wind speed at different months and even each minute of a day, whereas it is impossible to store electrical energy on a massive scale, prediction plays a major rule to integrate the power grid and wind energy. Therefore, to address these challenges, some of the Machine Learning algorithms are tested to detect attacks and predict wind power generation. This chapter first detects attacks on a dataset that comes from a smart grid, the results are compared based on F-Score (Precision/Recall) Accuracy and also considering the velocity. The results show the best performance belongs to the Random forest if test time (score time) is ignored otherwise the K-Nearest Neighbor (KNN) has great performance. Towards the end, predict wind power generation by using a dataset that has been collected over a period of six years, by considering the nature of the dataset as a time series pattern, several methods of learning like Neural network (NN), Long short-term memory (LSTM) have been applied. Finally, Mean Absolute Error (MAE) and accuracy are chosen to evaluate the performance of the methods. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-45541-5_8","Book chapter","2020","","Scopus"
"Accessible Cultural Heritage through Explainable Artificial Intelligence","Ethics Guidelines for Trustworthy AI advocate for AI technology that is, among other things, more inclusive. Explainable AI (XAI) aims at making state of the art opaque models more transparent, and defends AI-based outcomes endorsed with a rationale explanation, i.e., an explanation that has as target the non-technical users. XAI and Responsible AI principles defend the fact that the audience expertise should be included in the evaluation of explainable AI systems. However, AI has not yet reached all public and audiences, some of which may need it the most. One example of domain where accessibility has not much been influenced by the latest AI advances is cultural heritage. We propose including minorities as special user and evaluator of the latest XAI techniques. In order to define catalytic scenarios for collaboration and improved user experience, we pose some challenges and research questions yet to address by the latest AI models likely to be involved in such synergy. © 2020 ACM.","10.1145/3386392.3399276","Conference paper","2020","User experience; AI systems; AI Technologies; Cultural heritages; Non-technical users; Research questions; State of the art; Artificial intelligence","Scopus"
"The Current State of Industrial Practice in Artificial Intelligence Ethics","High-level guidelines and tools for managing artificial intelligence (AI) ethics have been introduced to help industry organizations make more ethical AI systems. The results of a survey of 211 software companies provide insights into the current state of industrial practice. © 1984-2012 IEEE.","10.1109/MS.2020.2985621","Article","2020","Artificial intelligence; Industrial management; Sea ice; Software engineering; AI systems; Industrial practices; Software company; Software industry; State of practice; Ethical aspects","Scopus"
"Methods and Guidelines for Incorporating Human Factors Requirements in Automated Vehicles Development","Automated vehicles (AV) are transforming the future of the transportation and improving the quality of life. However, due to their societal impact in urban environments, AV development challenges the current development process. Particularly, it is unclear how human factors requirements can be communicated to developers of AI-based AV. It is quite challenging especially in agile development, where the focus is on continuous deployment and rapid release cycles with short lead-Times. Due to the importance of human factors and its impact on trust, acceptance, and safety of AV in urban environments, my work aims at providing a suitable requirements engineering perspective and method. © 2021 CEUR-WS. All rights reserved.","","Conference paper","2021","Computer software selection and evaluation; Requirements engineering; Urban planning; Agile development; Automated vehicles; Development process; Lead time; Quality of life; Rapid release; Societal impacts; Urban environments; Human engineering","Scopus"
"A hybrid-ai approach for competence assessment of automated driving functions","An increasing number of tasks is being taken over from the human driver as automated driving technology is developed. Accidents have been reported in situations where the automated driving technology was not able to function according to specifications. As data-driven Artificial Intelligence (AI) systems are becoming more ubiquitous in automated vehicles, it is increasingly important to make AI systems situational aware. One aspect of this is determining whether these systems are competent in the current and immediate traffic situation, or that they should hand over control to the driver or safety system. We aim to increase the safety of automated driving functions by combining data-driven AI systems with knowledge-based AI into a hybrid-AI system that can reason about competence in the traffic state now and in the next few seconds. We showcase our method using an intention prediction algorithm that is based on a deep neural network and trained with real-world data of traffic participants performing a cut-in maneuver in front of the vehicle. This is combined with a unified, quantitative representation of the situation on the road represented by an ontology-based knowledge graph and first-order logic inference rules, that takes as input both the observations of the sensors of the automated vehicle as well as the output of the intention prediction algorithm. The knowledge graph utilises the two features of importance, based on domain knowledge, and doubt, based on the observations and information about the dataset, to reason about the competence of the intention prediction algorithm. We have applied the competence assessment of the intention prediction algorithm to two cut-in scenarios: a traffic situation that is well within the operational design domain described by the training data set, and a traffic situation that includes an unknown entity in the form of a motorcycle that was not part of the training set. In the latter case the knowledge graph correctly reasoned that the intention prediction algorithm was incapable of producing a reliable prediction. This shows that hybrid AI for situational awareness holds great promise to reduce the risk of automated driving functions in an open world containing unknowns. Automated driving is one of the most appealing applications of artificial intelligence in an open world. It holds the promise of reducing the number of casualties (1.35 million yearly (WHO 2018)), increasing the comfort of travel by taking over the driving task from humans, and bringing mobility to those unable to drive. While fleets of fully automated vehicles that can run unrestrained in an open world are still far away (Koopman and Wagner 2016), many vehicles are already equipped with Advanced Driver Assistence Systems (Okuda, Kajiwara, and Terashima 2014), like Lane Keep Assist and Adaptive Cruise Control. According to The Geneva Convention on road traffic of 1949 and the Vienna Convention on road traffic 1968, on which many countries base their national traffic laws, a human driver has to be present in the vehicle (Vellinga 2019). Artificial Intelligence (AI) opens up the possibility of automation in increasingly complex situations, but also makes it increasingly complex for human drivers to understand the limitations of the system (Thill, Hemeren, and Nilsson 2014). Copyright © 2021for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2021","Adaptive control systems; Adaptive cruise control; Automation; Complex networks; Deep neural networks; Digital storage; Forecasting; Formal logic; Graph algorithms; Inference engines; Knowledge representation; Ontology; Road vehicles; Roads and streets; Safety engineering; Speed control; Automated vehicles; Competence assessments; Intention predictions; Operational design; Situational awareness; Traffic situations; Training data sets; Vienna conventions; Advanced driver assistance systems","Scopus"
"Ethical Guidelines for Solving Ethical Issues and Developing AI Systems","Artificial intelligence (AI) has become a fast-growing trend. Increasingly, organizations are interested in developing AI systems, but many of them have realized that the use of AI technologies can raise ethical questions. The goal of this study was to analyze what kind of ethical guidelines companies have for solving potential ethical issues of AI and developing AI systems. This paper presents the results of the case study conducted in three companies. The ethical guidelines defined by the case companies focused on solving potential ethical issues, such as accountability, explainability, fairness, privacy, and transparency. To analyze different viewpoints on critical ethical issues, two of the companies recommended using multi-disciplinary development teams. The companies also considered defining the purposes of their AI systems and analyzing their impacts to be important practices. Based on the results of the study, we suggest that organizations develop and use ethical guidelines to prioritize critical quality requirements of AI. The results also indicate that transparency, explainability, fairness, and privacy can be critical quality requirements of AI systems. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-64148-1_21","Conference paper","2020","Philosophical aspects; Privacy by design; Process engineering; Transparency; AI systems; AI Technologies; Critical quality; Ethical issues; Ethical question; Multi-disciplinary development; Artificial intelligence","Scopus"
"The impact of Artificial Intelligence, Blockchain, Big Data and evolving technologies in Coronavirus Disease-2019 (COVID-19) curtailment","The pandemic of Coronavirus Disease 2019 (COVID-19) is proliferating across the globe obnoxiously and it is the most heard buzzword in recent times. Every person ranging from older people, persons with disabilities, youth, indigenous people have become a part of this chain and are most likely to suffer in the upcoming chronology. Social distancing is likely to become a new norm where 'Work from Home', Online Lectures' and 'Meetings' ensue on social media applications. Technology has always lent a helping hand for mankind's problems. The idea focuses on highlighting the advancements in technology in the midst of a bizarre situation. Deep Learning applications to detect the symptoms of COVID-19, AI based robots to maintain social distancing, Blockchain technology to maintain patient records, Mathematical modeling to predict and assess the situation and Big Data to trace the spread of the virus and other technologies. These technologies have immensely contributed to curtailing this pandemic. Strong will power, patience and optimistic guidelines catered by the respective government are some of the altercations to COVID-19.. © 2020 IEEE.","10.1109/ICOSEC49089.2020.9215294","Conference paper","2020","Big data; Blockchain; Deep learning; Viruses; Coronaviruses; Indigenous people; Most likely; Older People; Patient record; Persons with disabilities; Social media; Engineering education","Scopus"
"A Comparative Study on Ethics Guidelines for Artificial Intelligence Across Nations","This study aimed to investigate the commonality and differences among AI research and development (R&D) guidelines across nations. Content analysis was conducted on AI R&D guidelines issued by more economically developed countries because they may guide the trend of AI-based applications in education. Specifically, this study consisted of three phases: 1) information retrieval, (2) key term extraction, and (3) data visualization. First, Fisher’s exact test was employed to ensure that different AI R&D guidelines (e.g., the latest ones in the US, EU, Japan, Mainland, and Taiwan) were comparable. Second, the Key Word Extraction System was developed to retrieve essential information in the guidelines. Third, data visualization techniques were performed on key terms across multiple guidelines. A word cloud revealed the similarity among guidelines (e.g., key terms that these guidelines share in common) while a color-coding scheme showed the differences (e.g., occurrence of a key term across guidelines and its frequency within a guideline). Importantly, three key terms, namely, AI, human, and development, are identified as essential commonality across guidelines. As for key terms that only extracted from particular guidelines, interestingly, results with the color-coding scheme suggested that these key terms were weighted differently depends on the developmental emphasis of a nation. Collectively, we discussed how these findings concerning ethics guidelines may shed light on AI research and development to educational technology. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-63885-6_33","Conference paper","2020","Data visualization; Extraction; Philosophical aspects; Visualization; Color coding; Comparative studies; Content analysis; Developed countries; Extraction systems; Key term extraction; Research and development; Visualization technique; Artificial intelligence","Scopus"
"Knowledge discovery from remote sensing images: A review","The development of Earth observation (EO) technology has made the volume of remote sensing data archiving continually larger, but the knowledge hidden in massive remote sensing images has not been fully exploited. Through in-depth research on the artificial intelligence (AI)-based knowledge discovery approaches from remote sensing images, we divided them into four typical types according to their development stage, including rule-based approaches, data-driven approaches, reinforcement learning approaches, and ensemble methods. The basic principles, typical applications, advantages, and disadvantages have been detailed for commonly used algorithms within each category. Conclusions include the following: (a) Rule-based, data-driven and reinforcement learning algorithms form a trilogy from knowledge to data, and to capabilities. (b) Rule-based data mining algorithms can provide prior knowledge for data-driven approaches, the knowledge discovered by data-driven models can be as an important complement to expert knowledge and rule sets, and reinforcement learning approaches can effectively make up for the lack of training samples or small training sample in data-driven models. (c) The traditional data-driven machine learning approaches and their ensemble methods are the current and may be the future mainstream methods for large regional and even global scale long time series remote sensing data mining and analysis, and improving their computing efficiency is the key research direction. (d) Deep learning, deep reinforcement learning, transfer learning, and an ensemble approach of the three may be the main means for small-area scope, short time series, and key geoscience information extraction from remote sensing images within a long time of the future. This article is categorized under: Algorithmic Development > Spatial and Temporal Data Mining Fundamental Concepts of Data and Knowledge > Big Data Mining Technologies > Artificial Intelligence. © 2020 Wiley Periodicals LLC.","10.1002/widm.1371","Review","2020","Data mining; Deep learning; Learning algorithms; Learning systems; Reinforcement learning; Sampling; Time series; Time series analysis; Transfer learning; Computing efficiency; Data mining algorithm; Data mining technology; Fundamental concepts; Geoscience information; Machine learning approaches; Reinforcement learning approach; Remote sensing images; Remote sensing","Scopus"
"'The Robot-Arm Talks Back to Me' - Human Perception of Augmented Human-Robot Collaboration in Virtual Reality","The usage of AI enhanced robots in shared task environments is likely to become more and more common with the increase of digitalization in different industrial sectors. To take up this new challenge, research on the design of Human-Robot-Collaboration (HRC) involving AI-based systems has yet to establish common targets and guidelines. This paper presents results from an explorative qualitative study. Participants (N= 80) were either exposed to a virtual representation of an industrial robot-arm equipped with several augmentation channels for communication with the human operator (lights, textual statements about intentions, etc.) or one with no communicative functions at all. Across all conditions, participants recognized the benefit of collaborating with robots in industrial scenarios regarding work efficiency and alleviation of working conditions. However, a communication channel from the robot to the human is crucial for achieving these benefits. Participants interacting with the non-communicative robot expressed dissatisfaction about the workflow. In both conditions we found remarks about the insufficient speed of the robot-arm for an efficient collaborative process. Our results indicate a wider spectrum of questions to be further explored in the design of collaborative experiences with intelligent technological counterparts considering efficiency, safety, economic success and well-being.  © 2020 IEEE.","10.1109/AIVR50618.2020.00062","Conference paper","2020","Artificial intelligence; Efficiency; Industrial robots; Machine design; Robotic arms; Virtual reality; Collaborative process; Communicative functions; Communicative robots; Human-robot collaboration; Industrial scenarios; Industrial sector; Qualitative study; Virtual representations; Social robots","Scopus"
"Would you do it?: Enacting Moral Dilemmas in Virtual Reality for Understanding Ethical Decision-Making","A moral dilemma is a decision-making paradox without unambiguously acceptable or preferable options. This paper investigates if and how the virtual enactment of two renowned moral dilemmas - -The Trolley and the Mad Bomber - -influence decision-making when compared with mentally visualizing such situations. We conducted two user studies with two gender-balanced samples of 60 participants in total that compared between paper-based and virtual-reality (VR) conditions, while simulating 5 distinct scenarios for the Trolley dilemma, and 4 storyline scenarios for the Mad Bomber's dilemma. Our findings suggest that the VR enactment of moral dilemmas further fosters utilitarian decision-making, while it amplifies biases such as sparing juveniles and seeking retribution. Ultimately, we theorize that the VR enactment of renowned moral dilemmas can yield ecologically-valid data for training future Artificial Intelligence (AI) systems on ethical decision-making, and we elicit early design principles for the training of such systems. © 2020 ACM.","10.1145/3313831.3376788","Conference paper","2020","Artificial intelligence; Bombers; Human engineering; Philosophical aspects; Virtual reality; Early designs; Ethical decision making; Storylines; User study; Decision making","Scopus"
"How much AI do you require? Decision factors for adopting AI technology","Artificial intelligence (AI) based on machine learning technology disrupts how knowledge is gained. Nevertheless, ML's improved accuracy of prediction comes at the cost of low traceability due to its black-box nature. The field of explainable AI tries to counter this. However, for practical use in IT projects, these two research streams offer only partial advice for AI adoption as the trade-off between accuracy and explainability has not been adequately discussed yet. Thus, we simulate a decision process by implementing three best practice AI-based decision support systems for a high-stake maintenance decision scenario and evaluate the decision and attitude factors using the Analytical Hierarchy Process (AHP) through an expert survey. The combined results indicate that system performance is still the most important factor and that implementation effort and explainability are relatively even factors. Further, we found that systems using similarity-based matching or direct modeling for remaining useful life estimation performed best. © ICIS 2020. All rights reserved.","","Conference paper","2020","Blending; Decision support systems; Economic and social effects; Information systems; Information use; AI Technologies; Analytical Hierarchy Process; Best practices; Decision factors; Decision process; Expert survey; Maintenance decisions; Remaining useful lives; Artificial intelligence","Scopus"
"Agent-based Modeling for Ontology-driven Analysis of Patient Trajectories","Patients are often required to follow a medical treatment after discharge, e.g., for a chronic condition, rehabilitation after surgery, or for cancer survivor therapies. The need to adapt to new lifestyles, medication, and treatment routines, can produce an individual burden to the patient, who is often at home without the full support of healthcare professionals. Although technological solutions –in the form of mobile apps and wearables– have been proposed to mitigate these issues, it is essential to consider individual characteristics, preferences, and the context of a patient in order to offer personalized and effective support. The specific events and circumstances linked to an individual profile can be abstracted as a patient trajectory, which can contribute to a better understanding of the patient, her needs, and the most appropriate personalized support. Although patient trajectories have been studied for different illnesses and conditions, it remains challenging to effectively use them as the basis for data analytics methodologies in decentralized eHealth systems. In this work, we present a novel approach based on the multi-agent paradigm, considering patient trajectories as the cornerstone of a methodology for modelling eHealth support systems. In this design, semantic representations of individual treatment pathways are used in order to exchange patient-relevant information, potentially fed to AI systems for prediction and classification tasks. This paper describes the major challenges in this scope, as well as the design principles of the proposed agent-based architecture, including an example of its use through a case scenario for cancer survivors support. © 2020, The Author(s).","10.1007/s10916-020-01620-8","Article","2020","Communication; Humans; Mobile Applications; Systems Analysis; Telemedicine; adult; article; cancer survivor; female; human; ontology; prediction; telehealth; interpersonal communication; mobile application; system analysis; telemedicine","Scopus"
"Addressing AI ethics through codification","AI ethics rapidly becomes one of the most significant issues in assessing the impact of AI on social welfare and development. A technology that does not meet the ethical criteria of a society is likely to face a long and hard process of acceptance regardless of its potentially tremendous positive potential for long-term socio-economic development. The development of artificial intelligence (AI) technologies is undoubtedly associated with the need to answer ethical questions, and the perception of AI in society will be largely determined by compliance with ethical criteria, whether written or not. At the same time, AI as a technological system itself does not have a natural ethical content; the authors believe that in practice ethical concerns may be addressed by means of ethical codes and compliance rules that articulate what constitutes ethical behaviour in specific areas of application of AI systems. Such a set of rules (a code for AI ethics) could be followed by all actors throughout the complete lifecycle of the system starting with the design stage. The specification of general ethical principles as industry-specific codes of practice would also facilitate classification, evaluation and measurement of systems, both at the technical level and at the level of public perception and trust.The article considers examples of codification of ethical principles and offers several approaches for practical use in solving issues of ethics in the field of AI at the national and international level.  © 2020 IEEE.","10.1109/EnT48576.2020.00011","Conference paper","2020","Economic and social effects; Economics; Life cycle; Philosophical aspects; Artificial intelligence technologies; Codes of practice; Compliance rules; Ethical principles; Positive potential; Public perception; Socio-economic development; Technological system; Artificial intelligence","Scopus"
"GLUCOSE: GeneraLized and contextualized story explanations","When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of 670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models. © 2020 Association for Computational Linguistics","","Conference paper","2020","Cognitive systems; Computational linguistics; Glucose; Natural language processing systems; AI systems; Causal explanations; Cognitive psychology; Commonsense knowledge; Concrete contribution; Inference rules; Knowledge resource; Large-scale datasets; Mental model; Semi-structured; Large dataset","Scopus"
"Artificial Intelligence and Its Impact on Public Management and Decision-Making","Artificial Intelligence (AI) is a high-speed technology that influences our everyday lives. It is traditional to mean an artificial development of an intelligence that enables the learning, planification, perception, or process of natural language to create vast and ethical and socio-economic opportunities. As AI is a technology activated by the Internet, the Internet Society recognizes that an Internet with which people can trust is important to the creation of an opportunity and challenge associated with AI. At the same time, in this dynamic area, AI or machine learning problems are more common and involve concerns when it comes to users’ trust in the internet. This happens most frequently in goods and services. A variety of problems, including the socio-economic effects, concerns on openness, partiality, and accountability, new uses of data, health, ethical issues and how AI makes it easier to build new ecosystems, have to be addressed when it comes to dealing with AI. We plan to give policymakers and other players in the broader Internet ecosystem help in this chapter. Nonetheless, if it continues unabated some people find AI to be a threat to mankind. Others claim AI would create the possibility of mass unemployment, as opposed to past technological revolutions. This chapter describes the basics of the AI system, described key technology issues and challenges, examined the AI impacts on the performance of organizations and finally provided some guidelines for coping with this technology. © 2020, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-62796-6_13","Book chapter","2021","","Scopus"
"Dual Indicators to Analyze AI Benchmarks: Difficulty, Discrimination, Ability, and Generality","With the purpose of better analyzing the result of artificial intelligence (AI) benchmarks, we present two indicators on the side of the AI problems, difficulty and discrimination, and two indicators on the side of the AI systems, ability and generality. The first three are adapted from psychometric models in item response theory (IRT), whereas generality is defined as a new metric that evaluates whether an agent is consistently good at easy problems and bad at difficult ones. We illustrate how these key indicators give us more insight on the results of two popular benchmarks in AI, the Arcade Learning Environment (Atari 2600 games) and the General Video Game AI competition, and we include some guidelines to estimate and interpret these indicators for other AI benchmarks and competitions. © 2018 IEEE.","10.1109/TG.2018.2883773","Article","2020","Computer aided instruction; AI systems; Item response theory; Key indicator; Learning environments; Video game; Artificial intelligence","Scopus"
"The effect of rule injection in a leakage free datasets","Knowledge graph embedding (KGE) has become a prominent topic for many AI-based tasks such as recommendation systems, natural language processing, and link prediction. Inclusion of additional knowledge such as ontology, logical rules and text improves the learning process of KGE models. One of the main characteristics of knowledge graphs (KGs) is the existence of relational patterns (e.g., symmetric and inverse relations) which usually remain unseen by the embedding models. Inclusion of logical rules provides embedding models with additional information about the patterns already present in the KGs. The injection of logical rules has not yet been studied in depth for KGE models. In this paper, we propose an approach for rule-based learning on top of the two embedding models namely RotatE and TransE within this scope of the paper. We first study the effect of rule injection in the performance of the selected models. Second, we explore how the removal of leakage from popular KGs such as FB15k and WN18 affects the results. By leakage we are referring to the patterns exist in the training set from the test set (e.g. if the test set contains (h, r, t) then it also contains t, r, h in the training set which is considered as a symmetric leakage where t, r and h refers to tail, relation and head respectively). Empirical results suggest that incorporation of logical rules in the training process improves the performance of KGE models. © 2020 CEUR-WS. All rights reserved.","","Conference paper","2020","Graph embeddings; Natural language processing systems; Embeddings; Graph embeddings; Knowledge graph embedding; Knowledge graphs; Logic; Logical rules; Performance; Relational pattern; Symmetrics; Training sets; Knowledge graph","Scopus"
"Detection of potential controversial issues for social sustainability: Case of green energy","More and more people are involved in sustainability-related activities through social network to support/protect their idea or motivation for sustainable development. Understanding the variety of issues of social pulsation is crucial in development of social sustainability. However, issues in social media generally change overtime. Issues not identified in advance may soon become popular topics discussed in society, particularly controversial issues. Previous studies have focused on the detection of hot topics and discussion of controversial issues, rather than the identification of potential controversial issues, which truly require paying attention to social sustainability. Furthermore, previous studies have focused on issue detection and tracking based on historical data. However, not all controversial issues are related to historical data to foster the cases. To avoid the above-mentioned research gap, Artificial Intelligence (AI) plays an essential role in issue detection in the early stage. In this study, an AI-based solution approach is proposed to resolve two practical problems in social media: (1) the impact caused by the number of fan pages from Facebook and (2) awareness of the levels for an issue. The proposed solution approach to detect potential issues is based on the popularity of public opinion in social media using a Web crawler to collect daily posts related to issues in social media under a big data environment. Some analytical findings are carried out via the congregational rules proposed in this research, and the solution approach detects the attentive subjects in the early stages. A comparison of the proposed method to the traditional methods are illustrated in the domain of green energy. The computational results demonstrate that the proposed approach is accurate and effective and therefore it provides significant contribution to upsurge green energy deployment. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/su12198057","Article","2020","artificial intelligence; detection method; green economy; identification method; perception; social media; social network; sustainability; sustainable development","Scopus"
"Bridging the gap between ethics and practice: Guidelines for reliable, safe, and trustworthy human-centered AI systems","This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, nongovernmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society. © 2020 Association for Computing Machinery.","10.1145/3419764","Article","2020","Insurance; Philosophical aspects; Software reliability; Software testing; User interfaces; Verification; Engineering workflows; Government intervention; Leadership commitments; Management strategies; Organizational structures; Professional organization; Software engineering practices; Verification-and-validation; Accident prevention","Scopus"
"Explainable artificial intelligence for developing smart cities solutions","Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of ‘explainable deep learning’ as a subset of the ‘explainable AI’ problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts’ knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/smartcities3040065","Article","2020","","Scopus"
"Towards a human-centric design framework for ai assisted music production","In this paper, we contribute to the discussion on how to best design human-centric MIR tools for live audio mixing by bridging the gap between research on complex systems, the psychology of automation and the design of tools that support creativity in music production. We present the design of the Channel-AI, an embedded AI system which performs instrument recognition and generates parameter settings suggestions for gain levels, gating, compression and equalization which are specific to the input signal and the instrument type. We discuss what we believe to be the key design principles and perspectives on the making of intelligent tools for creativity and for experts in the loop. We demonstrate how these principles have been applied to inform the design of the interaction between expert live audio mixing engineers with the Channel-AI (i.e. a corpus of AI features embedded in the Midas HD Console. We report the findings from a preliminary evaluation we conducted with three professional mixing engineers and reflect on mixing engineers’ comments about the Channel-AI on social media. © 2020, Steering Committee of the International Conference on New Interfaces for Musical Expression. All rights reserved.","","Conference paper","2020","Audio acoustics; Audio systems; Mixing; Music; AI systems; Audio mixing; Design frameworks; Human-AI interaction; Human-centric; Human-centric designs; Instrument recognition; Live audio; MIR system; Music production; Engineers","Scopus"
"Human-in-the-loop Approach towards Dual Process AI Decisions","How to develop AI systems that can explain how they made decisions is one of the important and hot topics today. Inspired by the dual-process theory in psychology, this paper proposes a human-in-the-loop approach to develop System-2 AI that makes an inference logically and outputs interpretable explanation. Our proposed method first asks crowd workers to raise understandable features of objects of multiple classes and collect training data from the Internet to generate classifiers for the features. Logical decision rules with the set of generated classifiers can explain why each object is of a particular class. In our preliminary experiment, we applied our method to an image classification of Asian national flags and examined the effectiveness and issues of our method. In our future studies, we plan to combine the System-2 AI with System-1 AI (e.g., neural networks) to efficiently output decisions. © 2020 IEEE.","10.1109/BigData50022.2020.9378459","Conference paper","2020","Big data; AI systems; Dual process; Dual-process theories; Hot topics; Human-in-the-loop; Logical decisions; Multiple class; Training data; Classification (of information)","Scopus"
"Software Architecture Best Practices for Enterprise Artificial Intelligence","AI systems are increasingly evolving from laboratory experiments in data analysis to increments of productive software products. A professional AI platform must therefore not only function as a laboratory environment but must be designed and procured as a workbench for the development, productive implementation, operation and maintenance of ML models. Subsequently, it needs to integrate within a global software engineering approach. This way, Enterprise Architecture Management (EAM) must implement efficient governance of the development cycle, to enable organization-wide collaboration, to accelerate the go-live and to standardize operations. In this paper we highlight obstacles and show best practices on how architects can integrate data science and AI in their environment. Additionally, we suggest an integrated approach adapting the best practices from both the data science and DevOps. © 2020 Gesellschaft fur Informatik (GI). All rights reserved.","10.18420/inf2020_16","Conference paper","2020","Data Science; Enterprise software; Software architecture; AI systems; Best practices; Enterprise Architecture; Global software engineering; Laboratory environment; Laboratory experiments; Machine-learning; MLOp; Operations and maintenance; Software products; Machine learning","Scopus"
"On handling ethical dilemmas in artificial intelligence systems","Artificial intelligence (AI) has been created to help humans to achieve goals, not to help AI itself to achieve its own goals. Hence, AI has to be designed, controlled, and utilized for humans. To be accepted in a human society, AI has to be armed with law and ethics, because law and ethics provide fundamental principles, rules, and guidance for interactions in a human society. Without them, a human society can hardly survive in a peaceful way. However, implementing ethics in AI systems is absolutely a challenge. There are several layers that need to be taken into consideration. There are dilemmas in each layer, making implementation even more complex and challenging. This paper intends to tackle this challenge. It starts with a hypothetical but possible case that an AI-enabled self-driving vehicle may encounter. It examines various dilemmas involved in this case, especially the ethical one. It reveals the ineffectiveness of the current approaches in dealing with the ethical dilemma. It then proposes a novel approach that fully utilizes both the unique strengths of AI systems and the unique strengths of humans in exploring paradigm-shift solutions in dealing with this type of dilemmas. As a result, ethics can be successfully implemented and dynamically executed in AI systems. © ECIAIR 2020.All right reserved.","10.34190/EAIR.20.051","Conference paper","2020","Agricultural robots; Robotics; AI systems; Artificial intelligence systems; Ethical dilemma; Fundamental principles; Human society; Paradigm shifts; Self drivings; Philosophical aspects","Scopus"
"The Data Protection Impact Assessment as a Tool to Enforce Non-discriminatory AI","This paper argues that the novel tools under the General Data Protection Regulation (GDPR) may provide an effective legally binding mechanism for enforcing non-discriminatory AI systems. Building on relevant guidelines, the generic literature on impact assessments and algorithmic fairness, this paper aims to propose a specialized methodological framework for carrying out a Data Protection Impact Assessment (DPIA) to enable controllers to assess and prevent ex ante the risk to the right to non-discrimination as one of the key fundamental rights that GDPR aims to safeguard. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-55196-4_1","Conference paper","2020","Discriminators; Risk assessment; AI systems; Binding mechanisms; Data protection impact assessments; Ex antes; General data protection regulations; Impact assessments; Methodological frameworks; Privacy by design","Scopus"
"Local Analytical System for Early Epidemic Detection","An Epidemic is a big threat to humanity. To reduce its catastrophic effect, many clinical practices and AI-based models are introduced to detect the onset of future Epidemic. An Analytical System can be useful for the prediction of an epidemic by collecting Quality data, modelling them and visualizing in different dimensions. This study deals with designing a Local Analytical System for early Epidemic detection in which the data related to human regular needs and responses are stored in the in-cube format. Analytical rules are used to produced faster pre-computed and pre-summarized inputs of the warehouse. Some desired inputs are selected from many local Warehouses which are then consolidated to form an incremental next higher-level data using the Layered Architecture style. This system can find the most commonly deviated data from the most frequently occurred patterns in the data submitted from the participating warehouses. The above-summarized patterns are mined using an FP-Growth algorithm to predict a new pattern. The patterns are ranked and inspected with their correlations for a possible unknown Epidemic. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-9682-7_4","Book chapter","2021","Epidemiology; Warehouses; Analytical systems; Catastrophic effects; Clinical practices; Epidemic detection; FP-growth algorithm; Layered architecture; Quality data; Data warehouses","Scopus"
"AI in the Law: Towards Assessing Ethical Risks","The exponential growth in data over the past decade has impacted the legal industry; both requiring automated solutions for the cost effective and efficient management of the volume and variety of big (legal) data; and, enabling artificial intelligence techniques based on machine learning for the analysis of that data. While many legal practitioners focus on specific services niches, the impact of AI in the law is much broader than individual niches. While AI systems and concerns for their ethical operation are not new, the scale of impact and adoption of AI systems in legal practice makes consideration of the ethics of these systems timely. While there has been recent progress in development of ethical guidelines for AI systems, much of this is targeted at the developers of these systems in general, or the actions of these AI systems as autonomous entities, rather than in the legal practice context. Much of the ethical guidance - whether for AI systems or legal professional is captured in high level principles within more narrowly defined domains, more specific guidance may be appropriate to identify and assess ethical risks. As adoption and operation of AI software in routine legal practice becomes more commonplace, more detailed guidance on assessing the scope and scale of ethical risks is needed. © 2020 IEEE.","10.1109/BigData50022.2020.9377950","Conference paper","2020","Big data; Cost effectiveness; Philosophical aspects; Risk assessment; Artificial intelligence techniques; Automated solutions; Autonomous entities; Cost effective; Efficient managements; Exponential growth; On-machines; Recent progress; Artificial intelligence","Scopus"
"Synthesizing retro game screenshot datasets for sprite detection","Scenes in 2D videogames generally consist of a static terrain and a set of dynamic sprites which move around freely. AI systems that aim to understand game rules (for design support or automated gameplay) must be able to distinguish moving elements from the background. To this end, we re-purposed an object detection model from deep learning literature, developing along the way YOLO Artificial Retro-game Data Synthesizer, or YARDS, which efficiently produces semi-realistic, retro-game sprite detection datasets without manual labeling. Provided with sprites, background images, and a set of parameters, the package uses sprite frequency spaces to create synthetic gameplay images along with their corresponding labels. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2020","Deep learning; Entertainment; Human computer interaction; AI systems; Background image; Data synthesizers; Design support; Frequency spaces; Game rules; Manual labeling; Video game; Object detection","Scopus"
"Bot-X: An AI-based virtual assistant for intelligent manufacturing","In light of recent trends toward introducing Artificial Intelligence (AI) to enhance the Human Machine Interface (HMI), companies need to identify the key issues of the communication between operator and production machines. Despite the fact that the industrial company starts to introduce chatbots to assist the communication between humans and machines, the virtual assistant (or digital assistant) by using human natural language is still widely required in the manufacturing domain. In this paper, we introduce an AI-based virtual assistant, Bot-X, for the manufacturing industry to handle a variety of complex services, e.g., order processing, production execution. This work expands the idea in three directions. Firstly, we introduce the design motivation of Bot-X, e.g., knowledge boundary in the manufacturing context. Secondly, the design principle of Bot-X is presented, including the framework, system architecture, model architecture, and the core algorithm. Then, three scenarios are presented to test the Bot-X usability and flexibility regarding the manufacturing environment.  © 2021 - IOS Press. All rights reserved.","10.3233/MGS-210340","Article","2021","Manufacture; Service industry; Human Machine Interface; Industrial companies; Intelligent Manufacturing; Knowledge boundaries; Manufacturing domains; Manufacturing environments; Manufacturing industries; Production execution; Artificial intelligence","Scopus"
"Aiding observational ergonomic evaluation methods using MOCAP systems supported by AI-based posture recognition","Observational ergonomic evaluation methods have inherent subjectivity. Observers' assessment results might differ even with the same dataset. While motion capture (MOCAP) systems have improved the speed and the accuracy of motion-data gathering, the algorithms used to compute assessments seem to rely on predefined conditions to perform them. Moreover, the authoring of these conditions is not always clear. Making use of artificial intelligence (AI), along with MOCAP systems, computerized ergonomic assessments can become more alike to human observation and improve over time, given proper training datasets. AI can assist ergonomic experts with posture detection, useful when using methods that require posture definition, such as Ovako Working Posture Assessment System (OWAS). This study aims to prove the usefulness of an AI model when performing ergonomic assessments and to prove the benefits of having a specialized database for current and future AI training. Several algorithms are trained, using Xsens MVN MOCAP datasets, and their performance within a use case is compared. AI algorithms can provide accurate posture predictions. The developed approach aspires to provide with guidelines to perform AI-assisted ergonomic assessment based on observation of multiple workers.  © 2020 The authors and IOS Press.","10.3233/ATDE200050","Conference paper","2020","Ergonomics; Ergonomic assessment; Ergonomic evaluation; Human observations; Posture detection; Posture prediction; Posture recognition; Training data sets; Working postures; Artificial intelligence","Scopus"
"A conceptual architecture for AI-based big data analysis and visualization supporting metagenomics research","This paper targets to introduce an architecture for Artificial Intelligence (AI) based Big Data Analysis and Visualization supported metagenomics research based on the AI2VIS4BigData Reference Model. Metagenomics research covers the examination of huge amounts of data to improve the understanding of microbial communities. Technological and methodical improvements in Big Data Analysis drive progress in metagenomics research and thereby support practical applications like, e.g., the analysis of cattle rumen with the research goal of reducing the negative impact of cattle breeding on global warming. AI2VIS4BigData is a reference model for the combined application areas of Big Data Analysis, AI, and Visualization. Its purpose is to support scientific and industrial activities with guidelines and a common terminology to enable efficient exchange of knowledge and information and thereby prevent”reinventing the wheel”. The general applicability of the AI2VIS4BigData model for metagenomics has been validated in a previous publication. As a next step, this paper derives a conceptual architecture that specifies a possible adaption of AI2VIS4BigData for metagenomics. For this, three new metagenomic publications utilizing AI and Visualizations are assessed. Copyright © 2020 for this paper by its authors.","","Conference paper","2020","Architecture; Big data; Data handling; Data visualization; Digital storage; Global warming; Information analysis; Knowledge management; Visualization; Application area; Cattle breedings; Conceptual architecture; Industrial activities; Metagenomics; Microbial communities; Reference modeling; Research goals; Artificial intelligence","Scopus"
"Controlling safety of artificial intelligence‐based systems in healthcare","In response to the need to address the safety challenges in the use of artificial intelligence (AI), this research aimed to develop a framework for a safety controlling system (SCS) to address the AI black‐box mystery in the healthcare industry. The main objective was to propose safety guidelines for implementing AI black‐box models to reduce the risk of potential healthcare‐related incidents and accidents. The system was developed by adopting the multi‐attribute value model approach (MAVT), which comprises four symmetrical parts: extracting attributes, generating weights for the attributes, developing a rating scale, and finalizing the system. On the basis of the MAVT approach, three layers of attributes were created. The first level contained six key dimensions, the second level included 14 attributes, and the third level comprised 78 attributes. The key first level dimensions of the SCS included safety policies, incentives for clinicians, clinician and patient training, communication and interaction, planning of actions, and control of such actions. The proposed system may provide a basis for detecting AI utilization risks, preventing incidents from occurring, and developing emergency plans for AI‐related risks. This approach could also guide and control the implementation of AI systems in the healthcare industry. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","10.3390/sym13010102","Article","2021","","Scopus"
"Medical Chatbot for Novel COVID-19","Conversational agents or more universally known as the chatbot were industrialized to respond to user’s queries in a particular domain. Chatbot would serve as a software delegate which enables a computer to converse with human via natural language. A chatbot is a human-like conversational character (Shaikh et al. Int J Eng Sci Comput 6:3117–3119, 2016 [1]. This technology was coined in 1960s, with the intention to impersonate a human (how he would reply to a particular situation) so that the user feels that he is talking to a real person and not a machine. Conversational agent that interacts with user’s turn by turn using natural language (Shawar A, Atwell E (2005) ICAME J Int Comput Arch Mod Med English J 29, 5–24, 2005 [2]). The world of chatbot has seen much of the advance since the invention, and they have progressed from conventional rule-based chatbot to unorthodox AI-based chatbot. The chat agents are expert in their fields [3]. The prime focus of this paper is to show implementation of a retrieval-based chabot with voice support, and we will investigate other standing chatbot and how it is useful in helping the patients fetching all the necessary details about COVID-19. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","10.1007/978-981-15-8354-4_42","Conference paper","2021","","Scopus"
"Global challenges in the standardization of ethics for trustworthy AI","In this paper, we examine the challenges of developing international standards for Trustworthy AI that aim both to be global applicable and to address the ethical questions key to building trust at a commercial and societal level. We begin by examining the validity of grounding standards that aim for international reach on human right agreements, and the need to accommodate variations in prioritization and tradeoffs in implementing rights in different societal and cultural settings. We then examine the major recent proposals from the OECD, the EU and the IEEE on ethical governance of Trustworthy AI systems in terms of their scope and use of normative language. From this analysis, we propose a preliminary minimal model for the functional roles relevant to Trustworthy AI as a framing for further standards development in this area. We also identify the different types of interoperability reference points that may exist between these functional roles and remark on the potential role they could play in future standardization. Finally we examine a current AI standardization effort under ISO/IEC JTC1 to consider how future Trustworthy AI standards may be able to build on existing standards in developing ethical guidelines and in particular on the ISO standard on Social Responsibility. We conclude by proposing some future directions for research and development of Trustworthy AI standards. © 2020 the Author(s). All rights reserved.","10.13052/jicts2245-800X.823","Article","2020","Economic and social effects; Ethical technology; ISO Standards; Social aspects; AI systems; Cultural settings; Ethical question; Global challenges; Human rights; International standards; Minimal model; Prioritization; Stakeholder; Trustworthy AI; Standardization","Scopus"
"Time for AI (Ethics) maturity model is now","There appears to be a common agreement that ethical concerns are of high importance when it comes to systems equipped with some sort of Artificial Intelligence (AI). Demands for ethical AI are declared from all directions. As a response, in recent years, public bodies, governments, and universities have rushed in to provide a set of principles to be considered when AI based systems are designed and used. We have learned, however, that high-level principles do not turn easily into actionable advice for practitioners. Hence, also companies are publishing their own ethical guidelines to guide their AI development. This paper argues that AI software is still software and needs to be approached from the software development perspective. The software engineering paradigm has introduced maturity model thinking, which provides a roadmap for companies to improve their performance from the selected viewpoints known as the key capabilities. We want to voice out a call for action for the development of a maturity model for AI software. We wish to discuss whether the focus should be on AI ethics or, more broadly, the quality of an AI system, called a maturity model for the development of AI systems. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2021","Philosophical aspects; Safety engineering; Software design; AI systems; Common agreement; Ethical concerns; Maturity model; Roadmap; Software engineering paradigm; Artificial intelligence","Scopus"
"Culture-based explainable human-agent deconfliction","Law codes and regulations help organise societies for centuries, and as AI systems gain more autonomy, we question how human-agent systems can operate as peers under the same norms, especially when resources are contended. We posit that agents must be accountable and explainable by referring to which rules justify their decisions. The need for explanations is associated with user acceptance and trust. This paper's contribution is twofold: i) we propose an argumentation-based human-agent architecture to map human regulations into a culture for artificial agents with explainable behaviour. Our architecture leans on the notion of argumentative dialogues and generates explanations from the history of such dialogues; and ii) we validate our architecture with a user study in the context of human-agent path deconfliction. Our results show that explanations provide a significantly higher improvement in human performance when systems are more complex. Consequently, we argue that the criteria defining the need of explanations should also consider the complexity of a system. Qualitative findings show that when rules are more complex, explanations significantly reduce the perception of challenge for humans. © 2020 International Foundation for Autonomous.","","Conference paper","2020","Architecture; Laws and legislation; Multi agent systems; AI systems; Argumentative dialogues; Artificial agents; Human agent; Human performance; User acceptance; User study; Autonomous agents","Scopus"
"It’s All About Data: How to Make Good Decisions in a World Awash with Information","The rise of big and alternative data has created significant new business opportunities in the financial sector. As we start on this journey of fast-moving technology disruption, f inancial professionals have a rare opportunity to balance the exponential growth of artif icial intelligence (AI)/data science with ethics, bias, and privacy to create trusted data-driven decision making. In this article, the authors discuss the nuances of big data sets that are critical when one considers standards, processes, best practices, and modeling algorithms for the deployment of AI systems. In addition, this industry is widely guided by a fiduciary standard that puts the interests of the client above all else. It is therefore critical to have a thorough understanding of the limitations of our knowledge, because there are many known unknowns and unknown unknowns that can have a signif icant impact on outcomes. The authors emphasize key success factors for the deployment of AI initiatives: talent and bridging the skills gap. To achieve a lasting impact of big data initiatives, multidisciplinary teams with well-defined roles need to be established with continuing training and education. The prize is the finance of the future. © 2020, With intelligence. All rights reserved.","10.3905/jfds.2020.1.025","Article","2020","","Scopus"
"On the use of available testing methods for verification & validation of ai-based software and systems","Verification and validation of software and systems is the essential part of the development cycle in order to meet given quality criteria including functional and non-functional requirements. Testing and in particular its automation has been an active research area for decades providing many methods and tools for automating test case generation and execution. Due to the increasing use of AI in software and systems, the question arises whether it is possible to utilize available testing techniques in the context of AI-based systems. In this position paper, we elaborate on testing issues arising when using AI methods for systems, consider the case of different stages of AI, and start investigating on the usefulness of certain testing methods for testing AI. We focus especially on testing at the system level where we are interesting not only in assuring a system to be correctly implemented but also to meet given criteria like not contradicting moral rules, or being dependable. We state that some well-known testing techniques can still be applied providing being tailored to the specific needs. Copyright © 2021 for this paper by its authors. Use permitted under Creative Commons License Attribute 4.0 International (CC BY 4.0).","","Conference paper","2021","Software testing; Verification; Well testing; Development cycle; Different stages; Non-functional requirements; Position papers; Quality criteria; Test case generation; Testing technique; Verification-and-validation; Artificial intelligence","Scopus"
"Towards developing trust-supporting design features for AI-based chatbots in customer service","Chatbots are predicted to play a key role in customer service based on recent advances in the area of Artificial Intelligence (AI). However, a lack of user trust impedes the widespread adaption of AI-based chatbots. Still, there is a lack of systematically derived design knowledge concerning user trust in those agents. In this short paper, we report on the first steps of our design science research project on which design principles are relevant for building trust in chatbots. Based on trust literature and user interviews, we propose preliminary requirements and design principles for trust-enhancing design features for chatbots in customer service. Furthermore, we present a first instantiation of those principles. These insights will support researchers and practitioners to better understand how user trust in chatbots can be systematically built to increase adoption and usage. © ICIS 2020. All rights reserved.","","Conference paper","2021","Blending; Information systems; Information use; Sales; Chatbots; Customer services; Design features; Design knowledge; Design Principles; Design-science researches; Supporting design; Artificial intelligence","Scopus"
"Artificial intelligence (AI) Ethics: Ethics of AI and ethical AI","Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of “machine ethics” was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI? Copyright © 2020, IGI Global.","10.4018/JDM.2020040105","Review","2020","Artificial intelligence; Data privacy; Diagnosis; Economic and social effects; Economics; Face recognition; Artificial intelligence ethic; Ethic of artificial intelligence; Ethical artificial intelligence; Ethical issues; Ethical principles; Facial recognition; Machine ethic; Moral issues; Policy and regulation; Roboethics; Philosophical aspects","Scopus"
"Analyzing the Economic Depression Post-COVID-19 Using Big Data Analytics","Various industries like technology, food, agriculture, and education are predicted to suffer major financial and production depreciation. The economic crisis suffered by the major large-scale industry on the other hand is predicted to effect the other economic enterprises effecting the world on a major scale. The lockdown incurred upon the general public is implemented all over the world in order to control the widespread of this pandemic. Coronavirus has hit the worldwide economy tremendously all over the world. Various countries have suffered life loss, temporary stop gap in various industries, economic growth, loss in revenues collected, etc. Though after a span the lockdown was made open, certain extra policies and rules were implemented such as social distancing and no gathering of people more than two or three in a close proximity. Restriction over number of people who can board at the same time over any public places like shops malls have effected the cash inflow to a huge extent. This chapter aims at analyzing the depression suffered by various sectors post-COVID-19 as a result of the lockdown along with various recent policies implemented. It also covers visualizing these issues with big data analytics perspective and how the concept of AI and other technologies is working across in order to solve these issues. It covers in brief how these upcoming technologies have been able to contribute in the healthcare sector while fighting against COVID-19 or uplifting the economy by helping the industry to build and design new models or plans to regain the cash inflow. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","10.1007/978-3-030-60039-6_16","Book chapter","2021","","Scopus"
"Interpretable off-policy evaluation in reinforcement learning by highlighting influential transitions","Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares, as well as importance sampling methods. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust. Copyright 2020 by the author(s).","","Conference paper","2020","Function evaluation; Importance sampling; Intensive care units; Knowledge acquisition; Learning systems; Least squares approximations; Petroleum reservoir evaluation; Confidence interval; Domain experts; Importance sampling method; Influence functions; Linear least squares; Medical simulations; Observational data; Policy evaluation; Reinforcement learning","Scopus"
"Using the Crowd to Prevent Harmful AI Behavior","To prevent harmful AI behavior, people need to specify constraints that forbid undesirable actions. Unfortunately, this is a complex task, since writing rules that distinguish harmful from non-harmful actions tends to be quite difficult in real-world situations. Therefore, such decisions have historically been made by a small group of powerful AI companies and developers, with limited community input. In this paper, we study how to enable a crowd of non-AI experts to work together to communicate high-quality, reliable constraints to AI systems. We first focus on understanding how humans reason about temporal dynamics in the context of AI behavior, finding through experiments on a novel game-based testbed that participants tend to adopt a long-term notion of harm, even in uncertain situations that do not affect them directly. Building off of this insight, we explore task design for long-term constraint specification, developing new filtering approaches and new methods of promoting user reflection. Next, we develop a novel rule-based interface which allows people to craft rules in an accessible fashion without programming knowledge. We test our approaches on a real-world AI problem in the domain of education, and find that our new filtering mechanisms and interfaces significantly improve constraint quality and human efficiency. We also demonstrate how these systems can be applied to other real-world AI problems (e.g. in social networks).  © 2020 ACM.","10.1145/3415168","Article","2020","Complex task; Constraint specifications; Filtering mechanism; High quality; Programming knowledge; Real world situations; Temporal dynamics; Writing rules; Behavioral research","Scopus"
"Software Quality for AI: Where We Are Now?","Artificial Intelligence is getting more and more popular, being adopted in a large number of applications and technology we use on a daily basis. However, a large number of Artificial Intelligence applications are produced by developers without proper training on software quality practices or processes, and in general, lack in-depth knowledge regarding software engineering processes. The main reason is due to the fact that the machine-learning engineer profession has been born very recently, and currently there is a very limited number of training or guidelines on issues (such as code quality or testing) for machine learning and applications using machine learning code. In this work, we aim at highlighting the main software quality issues of Artificial Intelligence systems, with a central focus on machine learning code, based on the experience of our four research groups. Moreover, we aim at defining a shared research road map, that we would like to discuss and to follow in collaboration with the workshop participants. As a result, the software quality of AI-enabled systems is often poorly tested and of very low quality. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-65854-0_4","Conference paper","2021","Application programs; Computer software selection and evaluation; Engineering research; Machine learning; Personnel training; Professional aspects; Software testing; Artificial intelligence systems; Code quality; In-depth knowledge; Low qualities; On-machines; Research groups; Software engineering process; Workshop participants; Software quality","Scopus"
"Towards Named AI Networking: Unveiling the Potential of NDN for Edge AI","Thanks to recent advancements in edge computing, the traditional centralized cloud-based approach to deploy Artificial Intelligence (AI) techniques will be soon replaced or complemented by the so-called edge AI approach. By pushing AI at the network edge, close to the large amount of raw input data, the traffic traversing the core network as well as the inference latency can be reduced. Despite such neat benefits, the actual deployment of edge AI across distributed nodes raises novel challenges to be addressed, such as the need to enforce proper addressing and discovery procedures, to identify AI components, and to chain them in an interoperable manner. Named Data Networking (NDN) has been recently argued as one of the main enablers of network and computing convergence, which edge AI should build upon. However, the peculiarities of such a new paradigm entails to go a step further. In this paper we disclose the potential of NDN to support the orchestration of edge AI. Several motivations are discussed, as well as the challenges which serve as guidelines for progress beyond the state of the art in this topic. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-61746-2_2","Conference paper","2020","Mobile ad hoc networks; Cloud-based; Core networks; Distributed nodes; Input datas; Large amounts; Named data networkings; Network edges; State of the art; Artificial intelligence","Scopus"
"Dialogical Guidelines Aided by Knowledge Acquisition: Enhancing the Design of Explainable Interfaces and Algorithmic Accuracy","Understanding expert domain knowledge may inform the design of explainable interfaces that convey comprehensible information by “mirroring” the explanation practice of domain experts. Likewise, scrutinizing expert domain knowledge is pivotal to guarantee data quality and enhance algorithmic accuracy, by zooming in on the types of data and information that constitute relevant and reliable representations in a given domain. Against this backdrop, the paper revitalizes the field of knowledge acquisition and presents easily applicable user-centered and value-oriented dialogical guidelines to unravel domain knowledge with the aim of enhancing the design of explainable interfaces and algorithmic accuracy. While it might seem counter-intuitive to revisit the field of knowledge acquisition in the era of machine learning and deep learning, there are plenty of cases in which AI systems, trained on biased data, have led to epistemological deficiencies with morally harmful consequences. In order to improve the data preparation and modelling stage in the development of ML models, this paper suggests that AI developers could benefit from the pragmatic application of manageable dialogical guidelines aided by knowledge acquisition to cultivate shared understanding between AI developers and domain expert end users. © 2021, Springer Nature Switzerland AG.","10.1007/978-3-030-63128-4_19","Conference paper","2021","Deep learning; Data and information; Data preparation; Data quality; Domain experts; Domain knowledge; Shared understanding; User-centered; Zooming-in; Knowledge acquisition","Scopus"
"Use of AI-based tools for healthcare purposes: A survey study from consumers' perspectives","Background: Several studies highlight the effects of artificial intelligence (AI) systems on healthcare delivery. AI-based tools may improve prognosis, diagnostics, and care planning. It is believed that AI will be an integral part of healthcare services in the near future and will be incorporated into several aspects of clinical care. Thus, many technology companies and governmental projects have invested in producing AI-based clinical tools and medical applications. Patients can be one of the most important beneficiaries and users of AI-based applications whose perceptions may affect the widespread use of AI-based tools. Patients should be ensured that they will not be harmed by AI-based devices, and instead, they will be benefited by using AI technology for healthcare purposes. Although AI can enhance healthcare outcomes, possible dimensions of concerns and risks should be addressed before its integration with routine clinical care. Methods: We develop a model mainly based on value perceptions due to the specificity of the healthcare field. This study aims at examining the perceived benefits and risks of AI medical devices with clinical decision support (CDS) features from consumers' perspectives. We use an online survey to collect data from 307 individuals in the United States. Results: The proposed model identifies the sources of motivation and pressure for patients in the development of AI-based devices. The results show that technological, ethical (trust factors), and regulatory concerns significantly contribute to the perceived risks of using AI applications in healthcare. Of the three categories, technological concerns (i.e., performance and communication feature) are found to be the most significant predictors of risk beliefs. Conclusions: This study sheds more light on factors affecting perceived risks and proposes some recommendations on how to practically reduce these concerns. The findings of this study provide implications for research and practice in the area of AI-based CDS. Regulatory agencies, in cooperation with healthcare institutions, should establish normative standard and evaluation guidelines for the implementation and use of AI in healthcare. Regular audits and ongoing monitoring and reporting systems can be used to continuously evaluate the safety, quality, transparency, and ethical factors of AI-based services.  © 2020 The Author(s).","10.1186/s12911-020-01191-1","Review","2020","Adult; Artificial Intelligence; Decision Support Systems, Clinical; Delivery of Health Care; Female; Health Facilities; Humans; Male; Middle Aged; Surveys and Questionnaires; United States; Young Adult; adult; artificial intelligence; clinical decision support system; female; health care delivery; health care facility; human; male; middle aged; questionnaire; United States; young adult","Scopus"
"Revisiting habitability in conversational systems","Conversational systems are inherently disadvantaged when indicating either what capabilities they have or the state they are in. The notion of habitability, the appropriate balancing in design between the language people use and the language a system can accept, emerged out of these early difficulties with conversational systems. This literature review aims to summarize progress in habitability research and explore implications for the design of current AI-enabled conversational systems. We found that i) the definitions of habitability focus mostly on matching between user expectations and system capabilities by employing well-balanced restrictions on language use; ii) there are two comprehensive design perspectives on different domains of habitability; iii) there is one standardized questionnaire with a sub-scale to measure habitability in a limited way. The review has allowed us to propose a working definition of habitability and some design implications that may prove useful for guiding future research and practice in this field. © 2020 Owner/Author.","10.1145/3334480.3383014","Conference paper","2020","Software engineering; Comprehensive designs; Conversational systems; Design implications; Different domains; Literature reviews; System capabilities; User expectations; Well balanced; Human engineering","Scopus"
"Guidelines for Quality Assurance of Machine Learning-Based Artificial Intelligence","Significant effort is being put into developing industrial applications for artificial intelligence (AI), especially those using machine learning (ML) techniques. Despite the intensive support for building ML applications, there are still challenges when it comes to evaluating, assuring, and improving the quality or dependability. The difficulty stems from the unique nature of ML, namely, system behavior is derived from training data not from logical design by human engineers. This leads to black-box and intrinsically imperfect implementations that invalidate many principles and techniques in traditional software engineering. In light of this situation, the Japanese industry has jointly worked on a set of guidelines for the quality assurance of AI systems (in the Consortium of Quality Assurance for AI-based Products and Services) from the viewpoint of traditional quality-assurance engineers and test engineers. We report on the second version of these guidelines, which cover a list of quality evaluation aspects, catalogue of current state-of-the-art techniques, and domain-specific discussions in five representative domains. The guidelines provide significant insights for engineers in terms of methodologies and designs for tests driven by application-specific requirements. © 2020 The Author(s).","10.1142/S0218194020400227","Conference paper","2020","Engineers; Machine learning; Personnel training; Service industry; Software engineering; Application specific requirements; Domain specific; Japanese industry; Logical design; Products and services; Quality evaluation; State-of-the-art techniques; System behaviors; Quality assurance","Scopus"
"It's Good to Chat?: Evaluation and Design Guidelines for Combining Open-Domain Social Conversation with Task-Based Dialogue in Intelligent Buildings","We present and evaluate a deployed conversational AI system that acts as a host of a working public building on a university campus. The system combines open-domain social chat with task-based conversation regarding navigation in the building, live resource updates (e.g. available computers), and events in the building. We investigated the impact of open-domain social chat on task completion and user preferences by comparing the combined system with a task-only version. We find that there is no significant difference in task completion or several aspects of user preference between the two systems, but that users would be significantly happier to talk to the task-only system in the future. This suggests that the ""walk-up""public setting and workplace nature of the environment creates a markedly different use case to the in-home, and more individual and private ""companion/assistant""setting which is commonly assumed for systems like Alexa. We discuss the implications for the design of conversational systems in other public settings. © 2020 ACM.","10.1145/3383652.3423889","Conference paper","2020","Intelligent buildings; AI systems; Combined system; Conversational systems; Public buildings; Social conversations; Task-based; University campus; Intelligent virtual agents","Scopus"
"Implementing artificial intelligence ethics: A tutorial","Artificial Intelligence (AI) Ethics have steadily gained attention following various real-world incidents surrounding both purely digital and cyber-physical AI systems. Concerns have been raised over the ethical aspects of these systems for example in relation to data privacy, or material harm in the case of cyber-physical systems. Though academic activity in the area has grown recently, much of the current corpus consists of theoretical and conceptual studies. Attempts to bring this on-going discussion into practice have been primarily made in the form of various guidelines for ethical development of AI systems. However, these guidelines have not been adopted out on the field. The current situation in the area calls for more actionable methods for AI ethics, focusing on the point of view of developers. In this paper, we discuss current methods for implementing ethics in different contexts and then provide an introduction to a tutorial on a developer-focused method for implementing AI ethics, the Ethics Card Deck. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-33742-1_38","Conference paper","2019","Artificial intelligence; Cyber Physical System; Data privacy; Embedded systems; Academic activities; Conceptual study; Current situation; Cyber physicals; Design method; Ethical aspects; Ethics; Real-world; Philosophical aspects","Scopus"
"A Review of Future and Ethical Perspectives of Robotics and AI","In recent years, there has been increased attention on the possible impact of future robotics and AI systems. Prominent thinkers have publicly warned about the risk of a dystopian future when the complexity of these systems progresses further. These warnings stand in contrast to the current state-of-the-art of the robotics and AI technology. This article reviews work considering both the future potential of robotics and AI systems, and ethical considerations that need to be taken in order to avoid a dystopian future. References to recent initiatives to outline ethical guidelines for both the design of systems and how they should operate are included. © Copyright © 2018 Torresen.","10.3389/frobt.2017.00075","Review","2018","","Scopus"
"The Design of Human Oversight in Autonomous Weapon Systems","As the reach and capabilities of Artificial Intelligence (AI) systems increases, there is also a growing awareness of the ethical, legal and societal impact of the potential actions and decisions of these systems. Many are calling for guidelines and regulations that can ensure the responsible design, development, implementation, and policy of AI. In scientific literature, AI is characterized by the concepts of Adaptability, Interactivity and Autonomy (Floridi & Sanders, 2004). According to Floridi and Sanders (2004), Adaptability means that the system can change based on its interaction and can learn from its experience. Machine learning techniques are an example of this. Interactivity occurs when the system and its environment act upon each other and Autonomy implies that the system itself can change its state. © 2018 Author.","10.1145/3278721.3278785","Conference paper","2018","Artificial intelligence; Decision making; Laws and legislation; Learning systems; Sanders; Ethical decision making; Human oversight; Machine learning techniques; moral judgement; Scientific literature; Societal impacts; Weapon system; Weapons systems; Philosophical aspects","Scopus"
"#MeToo: How conversational systems respond to sexual harassment","Conversational AI systems are rapidly developing from purely transactional systems to social chatbots, which can respond to a wide variety of user requests. In this article, we establish how current state-of-the-art conversational systems react to inappropriate requests, such as bullying and sexual harassment on the part of the user, by collecting and analysing the novel #MeToo corpus. Our results show that commercial systems mainly avoid answering, while rule-based chatbots show a variety of behaviours and often deflect. Data-driven systems, on the other hand, are often non-coherent, but also run the risk of being interpreted as flirtatious and sometimes react with counter-aggression. This includes our own system, trained on “clean” data, which suggests that inappropriate system behaviour is not caused by data bias. © 2018 Association for Computational Linguistics","","Conference paper","2018","'current; AI systems; Chatbots; Commercial systems; Conversational systems; Data driven; Rule based; Sexual harassment; State of the art; Transactional systems","Scopus"
"Managing bias in AI","Recent awareness of the impacts of bias in AI algorithms raises the risk for companies to deploy such algorithms, especially because the algorithms may not be explainable in the same way that non-AI algorithms are. Even with careful review of the algorithms and data sets, it may not be possible to delete all unwanted bias, particularly because AI systems learn from historical data, which encodes historical biases. In this paper, we propose a set of processes that companies can use to mitigate and manage three general classes of bias: those related to mapping the business intent into the AI implementation, those that arise due to the distribution of samples used for training, and those that are present in individual input samples. While there may be no simple or complete solution to this issue, best practices can be used to reduce the effects of bias on algorithmic outcomes. � 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND 4.0 License.","10.1145/3308560.3317590","Conference paper","2019","Artificial intelligence; AI algorithms; Best practices; Bias; Complete solutions; Creative Commons; General class; Historical data; Production monitoring; World Wide Web","Scopus"
"AI-Based Technical Approach for Designing Mobile Decision Aids","Conversational Voice User Interfaces (VUIs) help us in performing tasks in a wide range of domains these days. While there have been several efforts around designing dialogue systems and conversation flows, little information is available about technical concepts to extract critical information for addressing the users’ needs. For conversational VUIs to function appropriately as a decision aid, artificial intelligence (AI) that recognizes and supports diverse user decision strategies is a critical need. Following the design principle proposed by Kwon et al. [1] regarding the conversational flow between the user and conversational VUI, we developed an AI-based mobile-decision-aid (MODA) that predictively models and addresses users’ decision strategies to facilitate users’ in-store shopping decision process. In this paper, technical details about how MODA processes users’ natural language queries and generate the most appropriate and intelligent recommendations have been discussed. This developmental approach provides broad implications to conversational VUIs for diverse complex decision-making contexts and decision-makers with a critical need for decision assistants. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-23528-4_23","Conference paper","2019","Artificial intelligence; Decision making; Decision support systems; Human computer interaction; Natural language processing systems; Speech processing; Complex decision; Conversational agents; Decision aid system; Decision strategy; Design Principles; Natural language queries; Technical details; Voice user interface; User interfaces","Scopus"
"SocRob@Home: Integrating AI Components in a Domestic Robot System","This paper describes the SocRob@Home robot system, consisting of a mobile robot (MBOT) equipped with several sensors and actuators, including a manipulator arm, and several software modules that provide the skills and capability to perform domestic tasks while interacting with humans in a domestic environment. We describe the whole system holistically, explaining how it integrates the contributing modules, and then we focus on the most relevant sub-systems, pointing out the original contributions of our research and development on the system in the last 5 years. The robot system includes metric and semantic mapping, several navigation modes (way-point navigation, person following and multi-sensor obstacle detection and avoidance), vision-based object detection, recognition, servoing and grasping, speech understanding, task planning and task execution. The robot system is mostly activated by speech commands from a human, and these commands, after being interpreted, are executed by the robot sub-systems, coordinated by a task executor. Lessons learned during the development and use of this system, which are useful as guidelines for the development of similar robot systems, are provided. MBOT’s performance is assessed using the task benchmarks scoring system of the European Robotics League competitions on Consumer Service robots. © 2019, Gesellschaft für Informatik e.V. and Springer-Verlag GmbH Germany, part of Springer Nature.","10.1007/s13218-019-00618-w","Article","2019","Benchmarking; Manipulators; Mapping; Navigation; Object detection; Obstacle detectors; Robot programming; Semantics; Speech recognition; Mobile manipulation; Reasoning with uncertain knowledge; Robots system; Semantics mappings; Service robots; Speech understanding; Sub-systems; System levels; System-level AI for service robot; Uncertain knowledge; Mobile robots","Scopus"
"Adapting square for quality assessment of artificial intelligence systems","More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional software systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and Ethics guidelines for trustworthy AI from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts. © 2019 IEEE.","10.1109/ISSREW.2019.00035","Conference paper","2019","Application programs; Artificial intelligence; Computer software selection and evaluation; Ethical aspects; Learning systems; Machine learning; Quality control; Software quality; Technical presentations; Artificial intelligence systems; European Commission; Industrial applications of artificial intelligences; Quality assessment; Quality concepts; Software practitioners; SQuaRE; System behaviors; Software reliability","Scopus"
"A survey on recent advancements for AI enabled radiomics in neuro-oncology","Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistance in diagnosis of cancer, planning of treatment strategy, and prediction of survival. Radiomics in neuro-oncology has progressed significantly in the recent past. Deep learning has outperformed conventional machine learning methods in most image-based applications. Convolutional neural networks (CNNs) have seen some popularity in radiomics, since they do not require hand-crafted features and can automatically extract features during the learning process. In this regard, it is observed that CNN based radiomics could provide state-of-the-art results in neuro-oncology, similar to the recent success of such methods in a wide spectrum of medical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-40124-5_3","Conference paper","2020","Classification (of information); Convolutional neural networks; Deep learning; Diagnosis; Learning systems; Medical imaging; Best practices; Conventional machines; Future trends; Image-based application; Learning process; Neuro-oncology; Radiomics; State of the art; Oncology","Scopus"
"Interpretation of SVM Using Data Mining Technique to Extract Syllogistic Rules: Exploring the Notion of Explainable AI in Diagnosing CAD","Artificial Intelligence (AI) systems that can provide clear explanations of their behaviors have been suggested in many studies as a critical feature for human users to develop reliance and trust when using such systems. Medical Experts (ME) in particular while using an AI assistant system must understand how the system generates disease diagnoses before making patient care decisions based on the AI’s output. In this paper, we report our work in progress and preliminary findings toward the development of a human-centered explainable AI (XAI) specifically for the diagnosis of Coronary Artery Disease (CAD). We applied syllogistic inference rules based on CAD Clinical Practice Guidelines (CPGs) to interpret the data mining results using a Support Vector Machine (i.e., SVM) classification technique—which forms an early model for a knowledge base (KB). The SVM’s inference rules are then explained through a voice system to the MEs. Based on our initial findings, we discovered that MEs trusted the system’s diagnoses when the XAI described the chain of reasoning behind the diagnosis process in a more interpretable form—suggesting an enhanced level of trust. Using syllogistic rules alone, however, to interpret the classification of the SVM algorithm lacked sufficient contextual information—which required augmentation with more descriptive explanations provided by a medical expert. © 2020, IFIP International Federation for Information Processing.","10.1007/978-3-030-57321-8_14","Conference paper","2020","Classification (of information); Computer aided diagnosis; Diseases; Extraction; Knowledge based systems; Learning systems; Support vector machines; Classification technique; Clinical practice guidelines; Contextual information; Coronary artery disease; Critical features; Disease diagnosis; Medical experts; Work in progress; Data mining","Scopus"
"Towards a Taxonomy of Cognitive RPA Components","Robotic Process Automation (RPA) is a discipline that is increasingly growing hand in hand with Artificial Intelligence (AI) and Machine Learning enabling the so-called cognitive automation. In such context, the existing RPA platforms that include AI-based solutions classify their components, i.e. constituting part of a robot that performs a set of actions, in a way that seems to obey market or business decisions instead of common-sense rules. To be more precise, components that present similar functionality are identified with different names and grouped in different ways depending on the platform that provides the components. Therefore, the analysis of different cognitive RPA platforms to check their suitability for facing a specific need is typically a time-consuming and error-prone task. To overcome this problem and to provide users with support in the development of an RPA project, this paper proposes a method for the systematic construction of a taxonomy of cognitive RPA components. Moreover, such a method is applied over components that solve selected real-world use cases from the industry obtaining promising results. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-58779-6_11","Conference paper","2020","Blockchain; Enterprise resource management; Process control; Robotics; Taxonomies; Business decisions; Cognitive automations; Common sense; Error prone tasks; Hand in hands; Process automation; Real-world; Intelligent robots","Scopus"
"Designing an AI-based advisory platform for design techniques","The usage of design techniques in design processes is an important driver for the success of digital services. However, before using design techniques, suitable techniques need to be selected. With the continuous growth of the number of design techniques, the selection of appropriate ones becomes more difficult, especially for design novices with limited knowledge and expertise. In order to support the selection process, we propose design principles for the development of an advisory platform that interacts with design novices to suggest design techniques for different design situations using artificial intelligence (AI) techniques. Specifically, we leverage conversational agents, recommender techniques, and taxonomic background knowledge to conceptualize and implement an AI-based advisory platform. Following a design science research methodology, we contribute design knowledge for the class of advanced advisory platforms. Furthermore, from a practical point of view, we help design novices with our implemented advisory platform in the contextualized selection process of design techniques. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.","","Conference paper","2020","Information services; Information systems; Information use; Knowledge management; Back-ground knowledge; Conversational agents; Design knowledge; Design Principles; Design situations; Design technique; Design-science researches; Digital services; Design","Scopus"
"Predictions for the Potential Development of Artificial Intelligence in Chinese Education","Artificial intelligence (AI) is the simulation of human thought processes and consciousness on computer systems. Experts have gone so far as to chart the future development of AI systems that surpass human intelligence as a single civilization-shifting event, known as the ""technological singularity"" or ""the Singularity."" But in the more near future, AI promises to have more concrete applications throughout our everyday lives, including in education, a challenge that China has already taken up. At present, the main applications of this so-called ""weak"" artificial intelligence in Chinese education are MOOC, web classes, and the flipped class model, with the results already proving outstanding. With the deeper combination of AI and education, we can look forward to benefits like the increasing usefulness of after-school tutoring robots, reliving teachers of burdensome responsibilities, and balancing global education resources. We should, however, also use AI in education reasonably by contextualizing gathered data, strengthening legal protections, and developing moral guidelines in machine programming. Addressing these three points will address the concerns of many laypeople as AI systems are implemented, offering protection for their fragile beginnings in education and encouraging the development of better ones in the future. © 2018 ACM.","10.1145/3234825.3234839","Conference paper","2018","Balancing; Teaching; Chinese educations; Class modeling; Concrete applications; Global education; Human intelligence; Legal protection; Machine programming; Thought process; Artificial intelligence","Scopus"
"Evaluating Compositionality in Sentence Embeddings","An important challenge for human-like AI is compositional semantics. Recent research has attempted to address this by using deep neural networks to learn vector space embeddings of sentences, which then serve as input to other tasks. We present a new dataset for one such task, “natural language inference” (NLI), that cannot be solved using only word-level knowledge and requires some compositionality. We find that the performance of state of the art sentence embeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We analyze the decision rules learned by InferSent and find that they are largely driven by simple heuristics that are ecologically valid in its training dataset. Further, we find that augmenting training with our dataset improves test performance on our dataset without loss of performance on the original training dataset. This highlights the importance of structured datasets in better understanding and improving AI systems. © 2018 Proceedings of the 40th Annual Meeting of the Cognitive Science Society, CogSci 2018. All rights reserved.","","Conference paper","2018","Deep neural networks; Semantics; Statistical tests; Vector spaces; Compositional semantics; Compositionality; Embeddings; Human like; Learn+; Recent researches; Sentence embedding; Test dataset; Training dataset; Vector-space embedding; Embeddings","Scopus"
"Beyond the buzzwords: On the perspective of AI in UX and vice versa","Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-50334-5_10","Conference paper","2020","Decision support systems; Human computer interaction; User experience; Artificial intelligence technologies; Autonomous mobilities; Case-studies; Clinical decision support systems; On-demand systems; Prototyping tools; Smart System; Artificial intelligence","Scopus"
"Investigating the role of moral decision-making in emerging artificial intelligence technologies","In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development. © 2019 Copyright is held by the author/owner(s).","10.1145/3311957.3361858","Conference paper","2019","Artificial intelligence; Decision making; Design; Interactive computer systems; Philosophical aspects; Artificial intelligence technologies; Emerging applications; Ethical decision making; Ethical principles; Ethics; Moral agents; Social impact; System design and development; Groupware","Scopus"
"Explainable AI in industry","Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability [6]. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare [1] and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling. As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale [8, 9, 19]. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks. In this tutorial, we will present an overview of model interpretability and explainability in AI [4], key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems [7]. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community. © 2019 Copyright held by the owner/author(s).","10.1145/3292500.3332281","Conference paper","2019","Accident prevention; Artificial intelligence; Climate change; Climate models; Crime; Health care; Natural resources exploration; Climate change modeling; Data mining applications; Developing solutions; Economic implications; Model transparency; Predictive maintenance; Reliability and safeties; Research communities; Data mining","Scopus"
"Artificial intelligence and public governance: Normative guidelines for artificial intelligence in government and public administration","This chapter discusses normative guidelines for the use of artificial intelligence in Germany against the backdrop of international debates. Artificial intelligence (AI) is increasingly changing our lives and our social coexistence. AI is a research question and a field of research producing an ever-increasing number of technologies. It is set of technologies that are still evolving. These are driven and influenced by guidelines in the form of laws or strategies. This chapter examines AI systems in public administration and raises the question of what guidelines already exist and what trends are emerging. After defining AI and providing some examples from government and administration, identify ethics and politics as possible points of reference for guidelines. This chapter presents the law, technology, organization, strategy and visions as possible ways to influence and govern AI along with describing current developments. The chapter concludes with a call for interdisciplinary research and moderate regulation of technology in order to enhance its positive potential. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-32361-5_12","Book chapter","2019","","Scopus"
"Report on the first knowledge graph reasoning challenge 2018: Toward the eXplainable AI system","A new challenge for knowledge graph reasoning started in 2018. Deep learning has promoted the application of artificial intelligence (AI) techniques to a wide variety of social problems. Accordingly, being able to explain the reason for an AI decision is becoming important to ensure the secure and safe use of AI techniques. Thus, we, the Special Interest Group on Semantic Web and Ontology of the Japanese Society for AI, organized a challenge calling for techniques that reason and/or estimate which characters are criminals while providing a reasonable explanation based on an open knowledge graph of a well-known Sherlock Holmes mystery story. This paper presents a summary report of the first challenge held in 2018, including the knowledge graph construction, the techniques proposed for reasoning and/or estimation, the evaluation metrics, and the results. The first prize went to an approach that formalized the problem as a constraint satisfaction problem and solved it using a lightweight formal method; the second prize went to an approach that used SPARQL and rules; the best resource prize went to a submission that constructed word embedding of characters from all sentences of Sherlock Holmes novels; and the best idea prize went to a discussion multi-agents model. We conclude this paper with the plans and issues for the next challenge in 2019. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-41407-8_2","Conference paper","2020","Deep learning; Formal methods; Learning systems; Multi agent systems; Open Data; Semantic Web; AI techniques; Evaluation metrics; Knowledge graphs; Lightweight formal methods; Multi-agents models; Reasoning; Social problems; Special interest groups; Constraint satisfaction problems","Scopus"
"Towards AI-based Solutions in the System Development Lifecycle","Many teams across different industries and organizations explicitly apply agile methodologies such as Scrum in their system development lifecycle (SDLC). The choice of the technology stack, the programming language, or the decision whether AI solutions could be incorporated into the system design either is given by corporate guidelines or is chosen by the project team based on their individual skill set. The paper describes the business case of implementing an AI-based automatic passenger counting system for public transportation, shows preliminary results of the prototype using anonymous passenger recognition on the edge with the help of Google Coral devices. It shows how different solutions could be integrated with the help of rule base systems and how AI-based solutions could be established in the SDLC as valid and cost-saving alternatives to traditionally programmed software components. Copyright © 2020 held by the author(s).","","Conference paper","2020","Knowledge engineering; Machine learning; Springs (components); Agile Methodologies; Automatic passenger counting system; Business case; Individual skills; Project team; Public transportation; Software component; System development; Life cycle","Scopus"
"Designing ethical AI in the shadow of Hume’s guillotine","Artificially intelligent systems can collect knowledge regarding epistemic information, but can they be used to derive new values? Epistemic information concerns facts, including how things are in the world, and ethical values concern how actions should be taken. The operation of artificial intelligence (AI) is based on facts, but it require values. A critical question here regards Hume’s Guillotine, which claims that one cannot derive values from facts. Hume’s Guillotine appears to divide AI systems into two ethical categories: weak and strong. Ethically weak AI systems can be applied only within given value rules, but ethically strong AI systems may be able to generate new values from facts. If Hume is correct, ethically strong AI systems are impossible, but there are, of course, no obstacles to designing ethically weak AI systems. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-39512-4_92","Conference paper","2020","Design; Integration; Intelligent systems; Philosophical aspects; AI systems; Critical questions; Ethical values; Behavioral research","Scopus"
"Artificial intelligence meets software engineering in the classroom","We aimed to assess the reliability of teaching Artificial Intelligence for Software Engineering master students. We propose a semi-interactive course where the students have to develop applications for solving real world problems by using various intelligent tools. We try to integrate these two disciplines, since both deal with modeling of the real case studies, sharing some common elements. We report on a study that we conducted on observing student teams as they develop AI-based applications. We validate the proposed semi-interactive course by using various criteria. In addition, we checked if some best practices from industrial teams are followed by our students.; The current study presents the experience gained while introducing a course with two main purposes: i) use of AI methods and algorithms in solving real life problems and ii) integrate AI specific solutions in software systems. We explained the principle in designing the course content, with a special attention dedicated to the applicative part. We described in detail how the application stages interleaves AI tasks (model representation, training, statistical analysis) with SE tasks (requirements engineering, SE processes, project management). In the end, we give an overview of the course evaluation. The essential characteristics that differentiate the course from a generalist one, is dealing with real life industry data and specific software development phases for integrated AI projects. © 2019 Association for Computing Machinery.","10.1145/3340435.3342718","Conference paper","2019","Application programs; Artificial intelligence; Education computing; Project management; Software design; Software engineering; Software reliability; Students; Course evaluations; Essential characteristic; Intelligent tools; Model representation; Real-life problems; Real-world problem; Software creation; Theory; Curricula","Scopus"
"The complexity of criminal liability of AI systems","Technology is advancing at a rapid pace. As we anticipate a rapid increase in artificial intelligence (AI), we may soon find ourselves dealing with fully autonomous technology with the capacity to cause harm and injuries. What then? Who is going to be held accountable if AI systems harm us? Currently there is no answer to this question and the existing regulatory framework falls short in addressing the accountability regime of autonomous systems. This paper analyses criminal liability of AI systems, evaluated under the existing rules of criminal law. It highlights the social and legal implications of the current criminal liability regime as it is applied to the complex nature of industrial robots. Finally, the paper explores whether corporate liability is a viable option and what legal standards are possible for imposing criminal liability on the companies who deploy AI systems. The paper reveals that traditional criminal law and legal theory are not well positioned to answer the questions at hand, as there are many practical problems that require further evaluation. I have demonstrated that with the development of AI, more questions will surface and legal frameworks will inevitably need to adapt. The conclusions of this paper could be the basis for further research. © 2020, Masaryk University Journal of Law and Technology. All rights reserved.","10.5817/MUJLT2020-1-3","Article","2020","","Scopus"
"Opening the software engineering toolbox for the assessment of trustworthy AI","Trustworthiness is a central requirement for the acceptance and success of human-centered artificial intelligence (AI). To deem an AI system as trustworthy, it is crucial to assess its behaviour and characteristics against a gold standard of Trustworthy AI, consisting of guidelines, requirements, or only expectations. While AI systems are highly complex, their implementations are still based on software. The software engineering community has a long-established toolbox for the assessment of software systems, especially in the context of software testing. In this paper, we argue for the application of software engineering and testing practices for the assessment of trustworthy AI. We make the connection between the seven key requirements as defined by the European Commission's AI high-level expert group and established procedures from software engineering and raise questions for future work. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2020","Application programs; Software testing; AI systems; Engineering community; European Commission; Gold standards; Software systems; Artificial intelligence","Scopus"
"Identifying challenges and opportunities in human-AI collaboration in healthcare","The proposed workshop will identify research questions that will enable the field to uncover the types of work, labor relations, and social impacts that should be considered when designing AI-based healthcare technology. The workshop aims to outline key challenges, guidelines, and future agendas for the field, and provide collaboration opportunities for CSCW researchers, social scientists, AI researchers, clinicians, and relevant stakeholders in healthcare, to share their perspectives and co-create sociotechnical approaches to tackle timely issues related to AI and automation in healthcare work. © 2019 Copyright is held by the author/owner(s).","10.1145/3311957.3359433","Conference paper","2019","Algorithms; Artificial intelligence; Automation; Groupware; Health care; Interactive computer systems; Learning systems; Machine learning; Healthcare technology; Labor relations; Research questions; Social impact; Social scientists; Socio-technical approach; Sociotechnical systems; Economic and social effects","Scopus"
"A Study of Artificial Social Intelligence in Conversational Agents","The main goal of Artificial Intelligence (AI) is to make a machine as intelligent as a human. While AI has advanced significantly over the past years, with its ability surpassing humans in several fields, the one thing that it still lacks is social awareness i.e. have the social skills of a human, a sense of what is appropriate and what isn't and make decisions based on that. These are highly subjective and there is no single set of rules to determine them. With the use of AI increasing at such a high rate that AI has become a part of people's everyday lives it is absolutely necessary for AI systems to know what is socially acceptable. In this paper, we have conducted a thorough and systematic study of the current state of the art for implementing social and emotional intelligence into a conversational agent. © 2018 IEEE.","10.1109/ICICT43934.2018.9034313","Conference paper","2018","AI systems; Conversational agents; Set of rules; Social awareness; Social intelligence; Social skills; State of the art; Systematic study; Emotional intelligence","Scopus"
"CPMetric: Deep siamese networks for metric learning on structured preferences","Preferences are central to decision making by both machines and humans. Representing, learning, and reasoning with preferences is an important area of study both within computer science and across the social sciences. When we give our preferences to an AI system we expect the system to make decisions or recommendations that are consistent with our preferences but the decisions should also adhere to certain norms, guidelines, and ethical principles. Hence, when working with preferences it is necessary to understand and compute a metric (distance) between preferences – especially if we encode both the user preferences and ethical systems in the same formalism. In this paper we investigate the use of CP-nets as a formalism for representing orderings over actions for AI systems. We leverage a recently proposed metric for CP-nets and propose a neural network architecture to learn an approximation of the metric, CPMetric. Using these two tools we look at how one can build a fast and flexible value alignment system (This is an expanded version of our paper, “Metric Learning for Value Alignment”[38]. In this version we have added the classification and regression results and significantly expanded the description of the CPMetric network.). © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-56150-5_11","Conference paper","2020","Alignment; Behavioral research; Decision making; Network architecture; Philosophical aspects; AI systems; Alignment system; CP-nets; Ethical principles; Metric learning; Deep learning","Scopus"
"EmBench: Quantifying performance variations of deep neural networks across modern commodity devices","In recent years, advances in deep learning have resulted in unprecedented leaps in diverse tasks spanning from speech and object recognition to context awareness and health monitoring. As a result, an increasing number of AI-enabled applications are being developed targeting ubiquitous and mobile devices. While deep neural networks (DNNs) are getting bigger and more complex, they also impose a heavy computational and energy burden on the host devices, which has led to the integration of various specialized processors in commodity devices. Given the broad range of competing DNN architectures and the heterogeneity of the target hardware, there is an emerging need to understand the compatibility between DNN-platform pairs and the expected performance benefits on each platform. This work attempts to demystify this landscape by systematically evaluating a collection of state-of-the-art DNNs on a wide variety of commodity devices. In this respect, we identify potential bottlenecks in each architecture and provide important guidelines that can assist the community in the co-design of more efficient DNNs and accelerators. © 2019 ACM.","10.1145/3325413.3329793","Conference paper","2019","Mobile computing; Network architecture; Object recognition; Speech recognition; Context- awareness; Health monitoring; On-device inference; Performance benefits; Performance variations; Specialized processors; State of the art; Target hardware; Deep neural networks","Scopus"
"Artificial intelligence in healthcare: Doctors, patients and liabilities","AI is increasingly finding its way into medical research and everyday healthcare. However, the clear benefits offered to patients are accompanied not only by general limitations typical of the application of AI systems but also by challenges that specifically characterize the operationalization of the concepts of disease and health. Traditionally, these challenges have been dealt with in the physician-patient relationship in both medical ethics and civil law. The potential for incorrect decisions (and the question of who is responsible for such decisions) in cases where AI is used in a medical context calls for a differentiated implementation of medical ethical principles and a graduated model of liability law. Nevertheless, on closer examination of both fields covering relevant obligations towards patients and users against the backdrop of current medical use cases of AI, it seems that despite a certain level of differentiation in the assignment of responsibilities through rules on liability, those affected, in the end, are generally left to deal with any AI-specific risks and damages on their own. The role played by the physician in all this remains unclear. Taking into account the physician-patient relationship as a contractual obligation in a broad sense can assist in clarifying physicians’ roles and determining their duties in a sustainable and patient-friendly manner when applying AI-based medical systems. This can contribute to reinforcing their established ethical and legal status in the context of AI applications. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-32361-5_15","Book chapter","2019","","Scopus"
"Design of real time game system using fuzzy logic","This paper proposed the model and execution of a AI system based on real time fuzzy for an bilateral game. This game is a Repair of Pac-Man style game in which competitor select BDI knowledgeable buyers. System parts and schemes applied in fuzzifying game rules and mutable are powwow. Thereto, the proposed fuzzy resolving and are warped between crisp and fuzzy range. © 2018, Institute of Advanced Scientific Research, Inc. All rights reserved.","","Article","2018","","Scopus"
"Hume’s Guillotine Resolved","According to Hume’s guillotine, one cannot derive values from facts. Since intelligent systems are fact processors, one can ask how ethical machines can be possible. However, ethics is a real-life process. People analyze actions and situations emotionally and cognitively. Thus they learn rules, such as “this situation feels good/bad.” The cognitive analysis of actions is associated with emotional analysis. The association of action, emotion and cognition can be termed a primary ethical schema. Through an ethical information process in which emotions and cognitions interact in social discourse, primary ethical schemas are refined into ethical norms. Each component of the process is different, but they cooperate to construct an ethical approach to thinking. Hume’s guillotine mistakenly breaks down primary ethical schemas and juxtaposes emotions and cognitions. There is no ethics without coordinated emotional, cognitive and social analysis. Therefore, his theory can be seen as a pseudo problem. In the future, ethical processes will involve intelligent systems that can make ethical choices. Weak ethical artificial intelligence (AI) systems can apply given ethical rules to data, while strong ethical AI systems can derive their own rules from data and knowledge about human emotions. Resolving Hume’s guillotine introduces new ways to develop stronger forms of ethical AI. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-50267-6_10","Conference paper","2020","Behavioral research; Computation theory; Human computer interaction; Intelligent systems; AI systems; Cognitive analysis; Emotional analysis; Human emotion; Information process; Life process; Philosophical aspects","Scopus"
"Artificial intelligence and competition law","Artificial Intelligence (AI) is ‘in the air’. The disruptive technologies AI is based on (as well as respective applications) are likely to influence the competition on and for various markets in due course. The handling of opportunities and threats re AI are so far still an open question-and research on the competitive effects of AI has just commenced recently. Statements about AI and the corresponding effects are thereby necessarily only of a temporary nature. From a jurisprudential point of view, it is however important to underline (not only) the framework for AI provided by competition law. On the basis of the 9th amendment of the German Act Against Restraints of Competition (ARC) 2017, German competition law seems to be-to a large extent-adequately prepared for the phenomenon of AI. Nevertheless, considering the characteristics of AI described in this paper, at least the interpretation of German (and European) competition law rules requires an ‘update’. In particular, tacit collusion as well as systematic predispositions of AI applications re market abuse and cartelization analyzed in this paper are to be pictured. Additionally, this paper stresses that further amendments to (European and German) competition law rules should be examined with respect to the liability for AI and law enforcement, whereby the respective effects on innovation and the market themselves will have to be considered carefully. Against this background, this paper argues that strict liability for AI might lead to negative effects on innovation and discusses a limited liability re public sanctions in analogy to intermediary liability concepts developed in tort law, unfair competition law and intellectual property law. Addressing the topic of a ‘legal personality’ for AI-based autonomous systems, this paper finally engages with the consequences of such a status for competition law liability. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-32361-5_16","Book chapter","2019","","Scopus"
"AI generality and Spearman’s law of diminishing returns","Many areas of AI today use benchmarks and competitions with larger and wider sets of tasks. This tries to deter AI systems (and research effort) from specialising to a single task, and encourage them to be prepared to solve previously unseen tasks. It is unclear, however, whether the methods with best performance are actually those that are most general and, in perspective, whether the trend moves towards more general AI systems. This question has a striking similarity with the analysis of the so-called positive manifold and general factors in the area of human intelligence. In this paper, we first show how the existence of a manifold (positive average pairwise task correlation) can also be analysed in AI, and how this relates to the notion of agent generality, from the individual and the populational points of view. From the populational perspective, we analyse the following question: is this manifold correlation higher for the most or for the least able group of agents? We contrast this analysis with one of the most controversial issues in human intelligence research, the so-called Spearman’s Law of Diminishing Returns (SLODR), which basically states that the relevance of a general factor diminishes for most able human groups. We perform two empirical studies on these issues in AI. We analyse the results of the 2015 general video game AI (GVGAI) competition, with games as tasks and “controllers” as agents, and the results of a synthetic setting, with modified elementary cellular automata (ECA) rules as tasks and simple interactive programs as agents. In both cases, we see that SLODR does not appear. The data, and the use of just two scenarios, does not clearly support the reverse either, a Universal Law of Augmenting Returns (ULOAR), but calls for more experiments on this question. © 2019 AI Access Foundation. All rights reserved.","10.1613/jair.1.11388","Article","2019","Factor analysis; Elementary cellular automaton; Empirical studies; General factors; Human intelligence; Interactive programs; Law of diminishing returns; Research efforts; Video game; Multi agent systems","Scopus"
"Analyzing the Impact of Characteristics on Artificial Intelligence IQ Test: A Fuzzy Cognitive Map Approach","This research paper we present a Fuzzy Cognitive Map (FCM)-based approach to improving a previously proposed IQ test for Artificial Intelligence (AI) systems. Starting from linguistic terms analyses, fuzzy logic along with triangular membership function is adopted for the defuzzification process. Based on the defuzzification result, a calculated defuzzified value is assigned for the quantitative weights of each edge in the resulting FCM. Mean Square Error (MSE) is used for evaluation. Experiments have shown that the FCM-based approach outperforms other methods (including Delphi weights). © 2018 The Authors. Published by Elsevier B.V.","10.1016/j.procs.2018.10.221","Conference paper","2018","Fuzzy logic; Fuzzy rules; Intelligent systems; Linguistics; Mean square error; Membership functions; Artificial intelligent; Defuzzifications; Fuzzy cognitive map; Linguistic analysis; Linguistic terms; Quantitative weights; Research papers; Triangular membership functions; Cognitive systems","Scopus"
"Automatic Diagnosis of Neurodegenerative Diseases: An evolutionary approach for facing the interpretability problem","Background: The use of Artificial Intelligence (AI) systems for automatic diagnoses is increasingly in the clinical field, being a useful support for the identification of several diseases. Nonetheless, the acceptance of AI-based diagnoses by the physicians is hampered by the black-box approach implemented by most performing systems, which do not clearly state the classification rules adopted. Methods: In this framework we propose a classification method based on a Cartesian Genetic Programming (CGP) approach, which allows for the automatic identification of the presence of the disease, and concurrently, provides the explicit classification model used by the system. Results: The proposed approach has been evaluated on the publicly available HandPD dataset, which contains handwriting samples drawn by Parkinson's disease patients and healthy controls. We show that our approach compares favorably with state-of-the-art methods, and more importantly, allows the physician to identify an explicit model relevant for the diagnosis based on the most informative subset of features. Conclusion: The obtained results suggest that the proposed approach is particularly appealing in that, starting from the explicit model, it allows the physicians to derive a set of guidelines for defining novel testing protocols and intervention strategies. © 2019 by the authors.","10.3390/info10010030","Article","2019","Artificial intelligence; Automation; Evolutionary algorithms; Genetic algorithms; Genetic programming; Learning systems; Neurodegenerative diseases; Automatic identification; Cartesian genetic programming; Classification methods; Classification models; Evolutionary approach; Intervention strategy; Parkinson disease; State-of-the-art methods; Diagnosis","Scopus"
"A multimodal convolutional neuro-fuzzy network for emotion understanding of movie clips","Multimodal emotion understanding enables AI systems to interpret human emotions. With accelerated video surge, emotion understanding remains challenging due to inherent data ambiguity and diversity of video content. Although deep learning has made a considerable progress in big data feature learning, they are viewed as deterministic models used in a “black-box” manner which does not have capabilities to represent inherent ambiguities with data. Since the possibility theory of fuzzy logic focuses on knowledge representation and reasoning under uncertainty, we intend to incorporate the concepts of fuzzy logic into deep learning framework. This paper presents a novel convolutional neuro-fuzzy network, which is an integration of convolutional neural networks in fuzzy logic domain to extract high-level emotion features from text, audio, and visual modalities. The feature sets extracted by fuzzy convolutional layers are compared with those of convolutional neural networks at the same level using t-distributed Stochastic Neighbor Embedding. This paper demonstrates a multimodal emotion understanding framework with an adaptive neural fuzzy inference system that can generate new rules to classify emotions. For emotion understanding of movie clips, we concatenate audio, visual, and text features extracted using the proposed convolutional neuro-fuzzy network to train adaptive neural fuzzy inference system. In this paper, we go one step further to explain how deep learning arrives at a conclusion that can guide us to an interpretable AI. To identify which visual/text/audio aspects are important for emotion understanding, we use direct linear non-Gaussian additive model to explain the relevance in terms of causal relationships between features of deep hidden layers. The critical features extracted are input to the proposed multimodal framework to achieve higher accuracy. © 2019 Elsevier Ltd","10.1016/j.neunet.2019.06.010","Article","2019","Algorithms; Deep Learning; Emotions; Fuzzy Logic; Humans; Motion Pictures; Neural Networks, Computer; Photic Stimulation; Computer circuits; Convolution; Deep neural networks; Fuzzy logic; Fuzzy neural networks; Fuzzy systems; Knowledge representation; Multilayer neural networks; Stochastic systems; Adaptive neural fuzzy inference system (ANFIS); Causal relationships; Convolutional neural network; Emotion understanding; Knowledge representation and reasoning; Multimodal frameworks; Neuro-fuzzy network; Stochastic neighbor embedding; Article; emotion; fuzzy logic; fuzzy system; interpersonal communication; learning algorithm; neuro fuzzy network; priority journal; sound; videorecording; algorithm; classification; fuzzy logic; human; movie; photostimulation; physiology; procedures; Fuzzy inference","Scopus"
"Can we build guidelines for trustworthy, ethical AI?","[No abstract available]","","Article","2019","Behavioral research; AI systems; Social and environmental; Well being; Philosophical aspects","Scopus"
"A comparative study on ai-based anti-terror crime system","Background/Objectives: Recent terrorisms are not restrained in time and place, but have occurred simultaneously and throughout the world in various ways against random people. Therefore, the research suggests AI-based Anti-terror System module to predict terrorisms in advance, in a response to recognition of severity of the current terrorism state. Methods/Statistical analysis:AI-based Anti-terror System module consists of 6 components - Data Collection and Filtering Module, 1st Analysis of Data and Rule Generation Module, D/B, Monitoring Device, 2nd Analysis of Data and Rule Generation Module and Crime Response Module - more accurate and rapid terror responses is enabled through systematic process of collection, analysis, monitoring, response and feedback on terror-related risk data from each of the modules and devices. Findings: The proposal module collect relevant data to terror suspects with Big Data, analyze the realistically high terror-risk data, but filtered and stored, in two different phases, and generate and modify each rule based on extracted pattern of the analyzed data. Then, consistent monitoring on risky data of probable terrors is performed in concerns of the saved analysis and Crime Response Modules are triggered on the basis of the consequent results.Such a proposal module can improve the accuracy of related date, but save duration time in collection of particular data as it only collects relevant data to terror risks via Big Data Source and Filtering Module compared to the existing module. Furthermore, the operation manuals of 1st/2nd phase Data Analysis Modules systematically analyze the terror risks and probabilities, thus can minimize the risk of actual terrorisms in fields by triggering Terror Crime Response Modules rapidly by phases with an increased terror prediction accuracy. As Monitoring Device is additionally incorporated, constant supervision and feedbacks regarding certain risk data relevant to terrors are enabled - as a result, detailed analysis of high risk data is available. Improvements/Applications: Owing to connections among recent terror groups, terror risks are omnipresent throughout the world and prior data collection for time and patterns of terrors has become difficult, hence the AI-based Anti-terror System Module would allow minimization of consequent terror damages, enabling preliminary terror prevention and rapid crime responses. © BEIESP.","","Article","2019","","Scopus"
"Intelligent, affective systems: Peoples perspective & implications","AI-based systems are shifting and will increasingly shift how we relate to content, context and each other. This extended keynote abstract discusses insights from a global study that focused on peoples perceptions, attitudes, thresholds and expectations of intelligent systems as well as their perspectives on smart home, autonomous cars, and smart workspace. Insights helped create ten design guidelines to assist intelligent systems designers, technologists and decision makers. © 2018 Copyright is held by the owner/author(s).","10.1145/3205946.3205962","Conference paper","2018","Artificial intelligence; Automation; Decision making; Intelligent buildings; Intelligent systems; Systems analysis; Affective Computing; Autonomous car; Decision makers; Smart homes; User experience; Human computer interaction","Scopus"
"Design principles for an intelligent-Augmented-Reality-based M-learning application to improve engineering students' English language skills","Introducing an intelligent augmented reality based M-learning application designed and developed for improving engineering students' English language skills, this chapter reports a work-in-progress that focuses on system design procedure. The application consists of Artificial Intelligence (AI) based functions to ensure an effective learning flow while taking advantages of game-based learning by providing a story board structure with a content tree. Four design principles ""fair use, flexible use, fault tolerance, educational climate"" by Elias in addition to Stockwell and Hubbard's principles for mobile supported language learning have been taken into account. Furthermore, the proposed system here employs an effective approach combining both real and virtual environments to achieve an Augmented Reality based learning experiences for students. After the introduction of the application, the chapter outlines how it will be processed in the future. © 2018, IGI Global.","10.4018/978-1-5225-5469-1.ch018","Book chapter","2018","Augmented reality; Computer aided instruction; Design; E-learning; Fault tolerance; Virtual reality; Design Principles; Effective approaches; Effective learning; English languages; Game-based Learning; Language learning; Learning experiences; System design procedures; Students","Scopus"
"Survey on AI-based multimodal methods for emotion detection","Automatic emotion recognition constitutes one of the great challenges providing new tools for more objective and quicker diagnosis, communication and research. Quick and accurate emotion recognition may increase possibilities of computers, robots, and integrated environments to recognize human emotions, and response accordingly to them a social rules. The purpose of this paper is to investigate the possibility of automated emotion representation, recognition and prediction its state-of-the-art and main directions for further research. We focus on the impact of emotion analysis and state of the arts of multimodal emotion detection. We present existing works, possibilities and existing methods to analyze emotion in text, sound, image, video and physiological signals. We also emphasize the most important features for all available emotion recognition modes. Finally, we present the available platform and outlines the existing projects, which deal with multimodal emotion analysis. © The Author(s) 2019.","10.1007/978-3-030-16272-6_11","Book chapter","2019","Artificial intelligence; Big data; Data handling; Speech recognition; Automatic data processing; Automatic emotion recognition; Data collection; Emotion detection; Emotion representation; Expressed emotion; Integrated environment; Physiological signals; Affective Computing; Modal analysis","Scopus"
"Design and simulation of neuro-fuzzy controller for indirect vector-controlled induction motor drive","This paper displays a unique adaptable Neuro-Fuzzy Controller (NFC)-based speed control for three-phase induction motor drive. The suggested NFC integrates fuzzy logic idea with a four-layer Artificial Neural Network (ANN). Speed and change in speed are sent as input to Neuro-Fuzzy Controller and it winds up noticeably fit for real-time electromechanical drives. The complete simulation model for indirect vector control of induction motor including the suggested NFC is developed. Induction motor assumes an imperative part in the field of electric drives. Without genuine controlling of the speed, it is difficult to accomplish required errand for specific application. AC motors are solid, less cost, reliable, and maintenance free. In light of absence of capacity of regular control strategies like PID and PI controllers to work in a broad range of operations, AI-based controllers are extensively utilized as a part of the industry like Neural Networks, Fuzzy Logic, and Neuro-Fuzzy controller. The principle issue with the typical fuzzy-based controllers is that the parameters related with the membership functions and the rules depend predominantly on instinct of the specialists, fuzzy logic cannot naturally get the rules utilized for settling on the decision, however, great at clarifying the decision. To overcome from this issue, Neuro-Fuzzy Controller [ability to learn without anyone else alongside decision-making] is recommended. Keeping in mind the end goal to prove the predominance of the proposed Neuro-Fuzzy Controller, the results of the suggested NFC technique is compared with the results of PI controller. NFC-based control of induction motor will end up being more trustworthy than other conventional control techniques. © Springer Nature Singapore Pte Ltd 2019.","10.1007/978-981-13-2514-4_14","Book chapter","2019","","Scopus"
"Robust continuous build-order optimization in starcraft","To solve complex real-world planning problems it is often beneficial to decompose tasks into high-level and low-level components and optimize actions separately. Examples of such modularization include car navigation (a high-level path planning problem) and obstacle avoidance (a lower-level control problem), and decomposing playing policies in modern video games into strategic (""macro"") and tactical (""micro"") components. In real-time strategy (RTS) video games such as StarCraft, players face decision problems ranging from economic development to maneuvering units in combat situations. A popular strategy employed in building AI agents for complex games like StarCraft is to use this strategy of task decomposition to construct separate AI systems for each of these sub-problems, combining them to form a complete game-playing agent. Existing AI systems for such games often contain build-order planning systems that attempt to minimize makespans for constructing specific sets of units, which are typically decided by hand-coded human expert knowledge rules. Drawbacks of this approach include the human expert effort involved in constructing these rules, as well as a lack of online adaptability to unforeseen circumstances, which can lead to brittle behavior that can be exploited by more advanced opponents. In this paper we introduce a new robust build-order planning system for RTS games that automatically produces build-orders which optimize unit compositions toward strategic game concepts (such as total unit firepower), without the need for specific unit goals. When incorporated into an existing StarCraft AI agent in a real tournament setting, it outperformed the previous state-of-the-art planning system which relied on human expert knowledge rules for deciding unit compositions. © 2019 IEEE.","10.1109/CIG.2019.8848109","Conference paper","2019","Collision avoidance; Decomposition; Human computer interaction; Interactive computer graphics; Maneuverability; Modular construction; Motion planning; Economic development; Human expert knowledge; Online adaptability; Order optimizations; Path planning problems; Real time strategies; Real-world planning problem; Task decomposition; Computer software","Scopus"
"Artificial intelligence meets large-scale sensing: Using Large-Area Electronics (LAE) to enable intelligent spaces","The tremendous value artificial intelligence (AI) is showing across a broad range of applications is driving it from cyber-systems to systems pervading every aspect of our lives. But real-world data challenges the efficiency and robustness with which AI systems of today can perform, due to the highly dynamic and noisy scenarios they face. While algorithmic solutions are required, this paper also explores technological solutions based on large-scale sensing. Specifically, Large-Area Electronics (LAE) is a technology that can make large-scale, form-fitting sensors possible for broad deployment in our lives. System-design principles, architectural approaches, supporting circuits, and underlying technological concerns surrounding LAE and its use in emerging systems for intelligent sensing are explored. © 2018 IEEE.","10.1109/CICC.2018.8357031","Conference paper","2018","Artificial intelligence; Integrated circuits; Intelligent systems; Internet of things; Learning systems; Algorithmic solutions; Architectural approach; Data challenges; Design Principles; Intelligent sensing; Intelligent spaces; Large-area electronics; Technological solution; Flexible electronics","Scopus"
"The basic rules for coexistence: The possible applicability of metalaw for human-AGI relations","Human-AGI relations are soon going to be a subject to number of policies and regulations. Although most current Blue Sky de lege ferenda postulates towards robot and artificial intelligence regulatory framework are focused on the liability of the producer or the owner of the AI based product, one might try to conceptualize the legal relations and rules for the coexistence between humans and an anthropocognitive AI's (AGI) possessing proper capacity. The main purpose of this article is to explore the possibility of applying the principles of Metalaw to mentioned relations. The scope shall consider a non-chattel and non-property based status of those types of AIs, as well as sufficient advancement of such entities, or the emergence of advanced non-human based intelligence. © 2020 Kamil Muzyka, published by De Gruyter 2020.","10.1515/pjbr-2020-0011","Article","2020","Intelligent robots; 'current; Basic rules; Metalaw; Policy and regulation; Property-based; Regulatory frameworks; SETI; Laws and legislation","Scopus"
"Meaningful explanations of black box ai decision systems","Black box AI systems for automated decision making, often based on machine learning over (big) data, map a user's features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases inherited by the algorithms from human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We focus on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems, introducing the local-to-global framework for black box explanation, articulated along three lines: (i) the language for expressing explanations in terms of logic rules, with statistical and causal interpretation; (ii) the inference of local explanations for revealing the decision rationale for a specific case, by auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of many local explanations into simple global ones, with algorithms that optimize for quality and comprehensibility. We argue that the local-first approach opens the door to a wide variety of alternative solutions along different dimensions: a variety of data sources (relational, text, images, etc.), a variety of learning problems (multi-label classification, regression, scoring, ranking), a variety of languages for expressing meaningful explanations, a variety of means to audit a black box. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2019","Behavioral research; Classification (of information); Decision making; Inference engines; Text processing; Alternative solutions; Automated decision making; Data-sources; Decision systems; Learning problem; Multi label classification; On-machines; Training data; Artificial intelligence","Scopus"
"Building ethically bounded ai","The more AI agents are deployed in scenarios with possibly unexpected situations, the more they need to be flexible, adaptive, and creative in achieving the goal we have given them. Thus, a certain level of freedom to choose the best path to the goal is inherent in making AI robust and flexible enough. At the same time, however, the pervasive deployment of AI in our life, whether AI is autonomous or collaborating with humans, raises several ethical challenges. AI agents should be aware and follow appropriate ethical principles and should thus exhibit properties such as fairness or other virtues. These ethical principles should define the boundaries of AI's freedom and creativity. However, it is still a challenge to understand how to specify and reason with ethical boundaries in AI agents and how to combine them appropriately with subjective preferences and goal specifications. Some initial attempts employ either a data-driven example-based approach for both, or a symbolic rule-based approach for both. We envision a modular approach where any AI technique can be used for any of these essential ingredients in decision making or decision support systems, paired with a contextual approach to define their combination and relative weight. In a world where neither humans nor AI systems work in isolation, but are tightly interconnected, e.g., the Internet of Things, we also envision a compositional approach to building ethically bounded AI, where the ethical properties of each component can be fruitfully exploited to derive those of the overall system. In this paper we define and motivate the notion of ethically-bounded AI, we describe two concrete examples, and we outline some outstanding challenges. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2019","Behavioral research; Decision making; Decision support systems; Philosophical aspects; AI techniques; Data driven; Ethical principles; Example based; Goal specifications; Modular approach; Relative weights; Rule-based approach; Artificial intelligence","Scopus"
"Adaptive Game AI-Based Dynamic Difficulty Scaling via the Symbiotic Game Agent","This work presents AdaptiveSGA, a model for implementing Dynamic Difficulty Scaling through Adaptive Game AI via the Symbiotic Game Agent framework. The use of Dynamic Difficulty Balancing in modern computer games is useful when looking to improve the entertainment value of a game. Moreover, the Symbiotic Game Agent, as a framework, provides flexibility and robustness as a design principle for game agents. The work presented here leverages both the advantages of Adaptive Game AI and Symbiotic Game Agents to implement a robust, efficient and testable model for game difficulty scaling. The model is discussed in detail and is compared to the original Symbiotic Game Agent architecture. Finally, the paper describes how it was applied in simulated soccer. Finally, experimental results, which show that Dynamic Difficulty Balancing was achieved, are briefly analyzed. © 2020, IFIP International Federation for Information Processing.","10.1007/978-3-030-46931-3_11","Conference paper","2020","Multi agent systems; Adaptive game AI; Agent architectures; Agent Framework; Design Principles; Computer games","Scopus"
"Towards Successful Collaboration: Design Guidelines for AI-based Services enriching Information Systems in Organisations","Information systems (IS) are widely used in organisations to improve business performance. The steady progression in improving technologies like artificial intelligence (AI) and the need of securing future success of organisations lead to new requirements for IS. This research in progress firstly introduces the term AI-based services (AIBS) describing AI as a component enriching IS aiming at collaborating with employees and assisting in the execution of work-related tasks. The study derives requirements from ten expert interviews to successful design AIBS following Design Science Research (DSR). For a successful deployment of AIBS in organisations the D&M IS Success Model will be considered to validated requirements within three major dimensions of quality: Information Quality, System Quality, and Service Quality. Amongst others, preliminary findings propose that AIBS must be preferably authentic. Further discussion and research on AIBS is forced, thus, providing first insights on the deployment of AIBS in organisations. © 2019 Frick, Brünker, Ross & Stieglitz.","","Conference paper","2019","Artificial intelligence; Concentration (process); Design; Information use; Artificial intelligence-based service; Business performance; Collaboration; Collaboration design guidelines; Design guideline; Design-science researches; Information quality; Information systems success models; Quality information; Work-related; Information systems","Scopus"
"Self-explaining ai as an alternative to interpretable ai","The ability to explain decisions made by AI systems is highly sought after, especially in domains where human lives are at stake such as medicine or autonomous vehicles. While it is often possible to approximate the input-output relations of deep neural networks with a few human-understandable rules, the discovery of the double descent phenomena suggests that such approximations do not accurately capture the mechanism by which deep neural networks work. Double descent indicates that deep neural networks typically operate by smoothly interpolating between data points rather than by extracting a few high level rules. As a result, neural networks trained on complex real world data are inherently hard to interpret and prone to failure if asked to extrapolate. To show how we might be able to trust AI despite these problems we introduce the concept of self-explaining AI. Self-explaining AIs are capable of providing a human-understandable explanation of each decision along with confidence levels for both the decision and explanation. Some difficulties with this approach along with possible solutions are sketched. Finally, we argue it is important that deep learning based systems include a “warning light” based on techniques from applicability domain analysis to warn the user if a model is asked to extrapolate outside its training distribution. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-52152-3_10","Conference paper","2020","Deep learning; Deep neural networks; Extrapolation; AI systems; Confidence levels; Data points; Domain analysis; High-level rules; Human lives; Input-output relations; Warning lights; Neural networks","Scopus"
"Artificial intelligence and law enforcement","Artificial intelligence is increasingly able to autonomously detect suspicious activities (‘smart’ law enforcement). In certain domains, technology already fulfills the task of detecting suspicious activities better than human police officers ever could. In such areas, i.e. if and where smart law enforcement technologies actually work well enough, legislators and law enforcement agencies should consider their use. Unfortunately, the German Constitutional Court, the European Court of Justice, and the US Supreme Court are all struggling to develop convincing and clear-cut guidelines to direct these legislative and administrative considerations. This article attempts to offer such guidance: First, lawmakers need to implement regulatory provisions in order to maintain human accountability if AI-based law enforcement technologies are to be used. Secondly, AI law enforcement should be used, if and where possible, to overcome discriminatory traits in human policing that have plagued some jurisdictions for decades. Finally, given that smart law enforcement promises an ever more effective and even ubiquitous enforcement of the law-a ‘perfect’ rule of law, in that sense-it invites us as democratic societies to decide if, where, and when we might wish to preserve the freedom to disobey the rule(s) of law. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-32361-5_10","Book chapter","2019","","Scopus"
"Recommendation agent adoption: How recommendation presentation influences employees' perceptions, behaviors, and decision quality","The purpose of this paper is to report the results of a laboratory experiment that investigated how assortment planners' perceptions, usage behavior, and decision quality are influenced by the way recommendations of an artificial intelligence (AI)-based recommendation agent (RA) are presented. A within-subject laboratory experiment was conducted with twenty subjects. Participants perceptions and usage behavior toward anRAwhile making decisions were assessed using validated measurement scales and eye-tracking technology. The results of this study show the importance of a transparent RA demanding less cognitive effort to understand and access the explanations of a transparent RA on assortment planners' perceptions (i.e., source credibility, sense of control, decision quality, and satisfaction), usage behavior, and decision quality. Results from this study suggest that designing RAs with more transparency for the users bring perceptual and attitudinal benefits that influence both the adoption and continuous use of those systems by employees. This study contributes to filling the literature gap on RAs in organizational contexts, thus advancing knowledge in the human-computer interaction literature. The findings of this study provide guidelines for RA developers and user experience (UX) designers on how to best create and present an AI-based RA to employees. © 2019 by the authors.","10.3390/app9204244","Article","2019","","Scopus"
"The benefits of using artificial intelligence in payment fraud detection: A case study","This paper presents a case study on the use of advanced artificial intelligence (AI) for the detection of payments fraud. The process applies AI within a typical online payment environment to detect fraudulent transactions in real time. The design focuses on an effective supervised learning engine with a data analytics component to support high-performance fraud detection, improving the predictive value of the original data.The design exploits the discriminant properties of customer data by finding hidden patterns. This feature significantly improves fraud detection rate and performance stability compared with a rule-based solution.The developed solution, based on an advanced AI-based technology and platform increased fraud detection rate from 85 per cent to 90 per cent (in terms of number of transaction records) and to 95 per cent in related amount volume (in terms of transaction value), while the alert rate (the percentage of daily transactions investigated manually) was reduced from 40 per cent to 10 per cent.The solution falls under the category of explainable AI because it can explain the rationale behind the decisions. © Henry Stewart Publications, 1750-1806.","","Article","2018","","Scopus"
"Impacts on Trust of Healthcare AI","Artificial Intelligence and robotics are rapidly moving into healthcare, playing key roles in specific medical functions, including diagnosis and clinical treatment. Much of the focus in the technology development has been on human-machine interactions, leading to a host of related technology-centric questions. In this paper, we focus instead on the impact of these technologies on human-human interactions and relationships within the healthcare domain. In particular, we argue that trust plays a central role for relationships in the healthcare domain, and the introduction of healthcare AI can potentially have significant impacts on those relations of trust. We contend that healthcare AI systems ought to be treated as assistive technologies that go beyond the usual functions of medical devices. As a result, we need to rethink regulation of healthcare AI systems to ensure they advance relevant values. We propose three distinct guidelines that can be universalized across federal regulatory boards to ensure that patient-doctor trust is not detrimentally affected by the deployment and widespread adoption of healthcare AI technologies. © 2018 ACM.","10.1145/3278721.3278771","Conference paper","2018","Diagnosis; Philosophical aspects; Assistive technology; Clinical treatments; ethics; Human machine interaction; Human-human interactions; Regulatory frameworks; Technology development; trust; Health care","Scopus"
"One-trial correction of legacy AI systems and stochastic separation theorems","We consider the problem of efficient “on the fly” tuning of existing, or legacy, Artificial Intelligence (AI) systems. The legacy AI systems are allowed to be of arbitrary class, albeit the data they are using for computing interim or final decision responses should posses an underlying structure of a high-dimensional topological real vector space. The tuning method that we propose enables dealing with errors without the need to re-train the system. Instead of re-training a simple cascade of perceptron nodes is added to the legacy system. The added cascade modulates the AI legacy system's decisions. If applied repeatedly, the process results in a network of modulating rules “dressing up” and improving performance of existing AI systems. Mathematical rationale behind the method is based on the fundamental property of measure concentration in high dimensional spaces. The method is illustrated with an example of fine-tuning a deep convolutional network that has been pre-trained to detect pedestrians in images. © 2019 Elsevier Inc.","10.1016/j.ins.2019.02.001","Article","2019","Artificial intelligence; Big data; Learning systems; Stochastic systems; Theorem proving; Vector spaces; Convolutional networks; Fundamental properties; High dimensional spaces; High-dimensional; Improving performance; Measure concentration; Real vector space; Separation theorem; Legacy systems","Scopus"
"An agile framework for trustworthy AI","The ethics guidelines put forward by the AI High Level Expert Group (AI-HLEG) present a list of seven key requirements that Human-centered, trustworthy AI systems should meet. These guidelines are useful for the evaluation of AI systems, but can be complemented by applied methods and tools for the development of trustworthy AI systems in practice. In this position paper we propose a framework for translating the AI-HLEG ethics guidelines into the specific context within which an AI system operates. This approach aligns well with a set of Agile principles commonly employed in software engineering. © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","","Conference paper","2020","Agile manufacturing systems; Philosophical aspects; Software engineering; AI systems; Position papers; Artificial intelligence","Scopus"
"Hybrid self-organizing feature map (SOM) for anomaly detection in cloud infrastructures using granular clustering based upon value-difference metrics","We have witnessed an increase in the availability of data from diverse sources over the past few years. Cloud computing, big data and Internet-of-Things (IoT) are distinctive cases of such an increase which demand novel approaches for data analytics in order to process and analyze huge volumes of data for security and business use. Cloud computing has been becoming popular for critical structure IT mainly due to cost savings and dynamic scalability. Current offerings, however, are not mature enough with respect to stringent security and resilience requirements. Mechanisms such as anomaly detection hybrid systems are required in order to protect against various challenges that include network based attacks, performance issues and operational anomalies. Such hybrid AI systems include Neural Networks, blackboard systems, belief (Bayesian) networks, case-based reasoning and rule-based systems and can be implemented in a variety of ways. Traffic in the cloud comes from multiple heterogeneous domains and changes rapidly due to the variety of operational characteristics of the tenants using the cloud and the elasticity of the provided services. The underlying detection mechanisms rely upon measurements drawn from multiple sources. However, the characteristics of the distribution of measurements within specific subspaces might be unknown. We argue in this paper that there is a need to cluster the observed data during normal network operation into multiple subspaces each one of them featuring specific local attributes, i.e. granules of information. Clustering is implemented by the inference engine of a model hybrid NN system. Several variations of the so-called value-difference metric (VDM) are investigated like local histograms and the Canberra distance for scalar attributes, the Jaccard distance for binary word attributes, rough sets as well as local histograms over an aggregate ordering distance and the Canberra measure for vectorial attributes. Low-dimensional subspace representations of each group of points (measurements) in the context of anomaly detection in critical cloud implementations is based upon VD metrics and can be either parametric or non-parametric. A novel application of a Self-Organizing-Feature Map (SOFM) of reduced/aggregate ordered sets of objects featuring VD metrics (as obtained from distributed network measurements) is proposed. Each node of the SOFM stands for a structured local distribution of such objects within the input space. The so-called Neighborhood-based Outlier Factor (NOOF) is defined for such reduced/aggregate ordered sets of objects as a value-difference metric of histogrammes. Measurements that do not belong to local distributions are detected as anomalies, i.e. outliers of the trained SOFM. Several methods of subspace clustering using Expectation-Maximization Gaussian Mixture Models (a parametric approach) as well as local data densities (a non-parametric approach) are outlined and compared against the proposed method using data that are obtained from our cloud testbed in emulated anomalous traffic conditions. The results—which are obtained from a model NN system—indicate that the proposed method performs well in comparison with conventional techniques. © 2019 Elsevier Inc.","10.1016/j.ins.2019.03.069","Article","2019","Bayesian networks; Behavioral research; Case based reasoning; Classifiers; Cloud computing; Clustering algorithms; Conformal mapping; Data Analytics; Geographical distribution; Hybrid systems; Information granules; Internet of things; Maximum principle; Self organizing maps; Set theory; Statistics; Conventional techniques; Expectation - maximizations; Internet of Things (IOT); Low-dimensional subspace; Nonparametric approaches; Operational characteristics; SelfOrganizing Feature Map (SOM); Value difference metric; Anomaly detection","Scopus"
"Assessing process suitability for AI-based automation. research idea and design","Recent advancements in Big Data and Machine Learning (ML) have triggered progressive adoption of Artificial Intelligence (AI) in the enterprise domains to address growing business process complexity. What is yet largely missing in the traditional Business Process Management (BPM) approaches, are formal frameworks and guidelines for decision making support when applying AI in a company. Proposed research aims to extend existing BPM frameworks and guidelines by novel methods, this way increasing understanding of business processes in the view of recent technology developments in Big Data, AI and ML. © Springer Nature Switzerland AG 2019.","10.1007/978-3-030-04849-5_59","Conference paper","2019","Artificial intelligence; Big data; Data mining; Enterprise resource management; Information systems; Information use; Learning systems; Business Process; Business process management; ITIL; Process automation; Text analytics; Text mining; Decision making","Scopus"
"The evolution of marketing in the context of voice commerce: A managerial perspective","The world is confronted with the rise of voice assistants, increasingly used for shopping activities. This paper examines managers’ perceptions of the evolution of voice assistants and their potential effects on the marketing practice. Shopping-related voice assistants are likely to radically change the way consumers search and purchase products with severe impact on brands. However, the behavior of these AI-enabled machines represents a “black box” for brand owners. The study of the managers’ interpretation of a voice-enabled marketplace is critical as it may influence future marketing choices. The authors use an inductive theory construction process to study the phenomenon of voice commerce through the eyes of AI experts and voice-aware managers. A mixed-method approach paced three distinct data collection phases. First, systematic machine behavior observations (Amazon Alexa) unfolded the unique characteristics of voice shopping. Second, in-depth interviews with 30 executives drew the current brand owner’s challenges and opportunities in the context of voice commerce. Third, an expert survey with international managers (N = 62) revealed the expected impact of voice assistants on the shopping process. Findings show that managers consider voice assistants a disruptive technology assuming a central relational role in the consumer market. However, they often divergence in opinions across industry, function, and seniority level. Besides, managers’ familiarity with voice commerce is correlated to a higher optimism towards voice technologies (opportunity for brands) but also a greater sense of urgency (short-term focus) with implications for marketing strategy. This article offers support to brand owners explaining how voice assistants work and examining their effects on consumption. The authors discuss empirical results while providing managerial guidelines to create resilient and sustainable brands in the era of voice commerce. © Springer Nature Switzerland AG 2020.","10.1007/978-3-030-50341-3_32","Conference paper","2020","Human computer interaction; Managers; Marketing; Disruptive technology; In-depth interviews; Inductive theories; Machine behavior; Marketing strategy; Potential effects; Shopping activity; Voice technologies; Commerce","Scopus"
"Towards Designing Conversational Agent Systems","Conversation is interactive communication between two and more people which enhances knowledge among these people. It is key to exchange thoughts and ideas while listening to each other. Based on this idea the advances in artificial intelligence started to develop technologies in which computer can communicate with human in a more natural way. A computer program which acts as an automated conversation agent is also called as a Chatbot. Chatbots are useful in many different applications like health care, education, financial marketing, banking, agriculture, etc. This paper presents a survey on different issues in designing conversational agents. The paper discusses the types and applications of Chatbot; it lists research challenges while designing and implementing these systems. The paper presents a study and comparison of different techniques like NLP (Natural Language Processing), Deep Learning and Neural Networks used for designing these systems. The paper also presents various datasets being used by popular Chatbots in the industry. The paper ends by summarizing scope for future work in this domain. © 2020, Springer Nature Singapore Pte Ltd.","10.1007/978-981-32-9515-5_51","Conference paper","2020","Artificial intelligence; Deep learning; Learning algorithms; Learning systems; Chatbot; Conversation agents; Conversational agents; Interactive communications; Nlp (natural language processing); Research challenges; Rule based; Types and applications; Natural language processing systems","Scopus"
"AI vs AI: fraudsters turn defensive technology into an attack tool","The first rule of managing online fraud and mitigating risk is to remember that fraudsters are entrepreneurs. While it's tempting to think of those committing digital fraud as hoody-wearing lone wolves spending hours in their bedroom working to weasel their way into someone's online account, in reality professional fraud operations look more like the JP Morgan trading floor. Cyber criminals are not simple, hoodie-wearing lone wolves. Many are sophisticated fraud operations using the most advanced technology, including artificial intelligence (AI). The energy and ingenuity with which fraud rings and cyber criminals have deployed AI-based solutions has matched that of the businesses and organisations that work to protect themselves from bad actors. Machines have been put to malicious use in ways ranging from click farms to complex model extraction schemes, explains Swami Vaithianathasamy of Signifyd. © 2019 Elsevier Ltd","10.1016/S1361-3723(19)30083-1","Article","2019","Wear of materials; Advanced technology; Complex model; Cyber criminals; Fraudsters; Jp morgans; Mitigating risk; Trading floors; Crime","Scopus"
"Implementation of artificial intelligence system and traditional system: A comparative study","The main purpose of this paper is to study about efficient AI project implementation as a case study. For the purpose of successful AI implementation, the project plan should be complete and robust with long term view. The implementation plan includes top management decision, organization and human resource, infra structure for AI system, end user support, and company strategy. The biggest benefits of AI systems are cost reduction, quality improvement, and faster response time. The goal of this study is to provide AI system team members with successful AI project implementation guidelines compared with traditional ones as recommendation. © 2019, Success Culture Press. All rights reserved.","","Article","2019","","Scopus"
"Impossibility and uncertainty theorems in AI value alignment or why your AGI should not have a utility function","Utility functions or their equivalents (value functions, objective functions, loss functions, reward functions, preference orderings) are a central tool in most current machine learning systems. These mechanisms for defining goals and guiding optimization run into practical and conceptual difficulty when there are independent, multi-dimensional objectives that need to be pursued simultaneously and cannot be reduced to each other. Ethicists have proved several impossibility theorems that stem from this origin; those results appear to show that there is no way of formally specifying what it means for an outcome to be good for a population without violating strong human ethical intuitions (in such cases, the objective function is a social welfare function). We argue that this is a practical problem for any machine learning system (such as medical decision support systems or autonomous weapons) or rigidly rule-based bureaucracy that will make high stakes decisions about human lives: such systems should not use objective functions in the strict mathematical sense. We explore the alternative of using uncertain objectives, represented for instance as partially ordered preferences, or as probability distributions over total orders. We show that previously known impossibility theorems can be transformed into uncertainty theorems in both of those settings, and prove lower bounds on how much uncertainty is implied by the impossibility results. We close by proposing two conjectures about the relationship between uncertainty in objectives and severe unintended consequences from AI systems. © 2019 CEUR-WS. All rights reserved.","","Conference paper","2019","Decision support systems; Machine learning; Probability distributions; Impossibility results; Medical decision support system; Multi dimensional; Objective functions; Practical problems; Social welfare functions; Unintended consequences; Utility functions; Functions","Scopus"
"Responsible ai","Since the Cambridge Analytica case broke, the discussion on how to use Artificial Intelligence (AI) ethically has intensified. Some companies, especially those that are building and selling AI solutions, began publishing guidelines for ethical AI. Microsoft already did so in 2017 [1] while the AI leader Google followed in 2018 [2]. Recently, ethical guidelines have been criticised as vague and unenforceable. The discussion in the AI community is shifting towards how engineering principles can be used to ensure that AI systems are designed and used responsibly. © 2019 Institute of Telecommunications Professionals. All rights reserved.","","Article","2019","Telecommunication; AI systems; Cambridge; Community IS; Engineering principles; MicroSoft; Philosophical aspects","Scopus"
"Explainable AI for Dataset Comparison","With the increasing use of intelligent systems to make sense of data, lately, explainable AI systems are gaining a lot of traction. A distance measure that can distinguish data sets in linguistic terms can help AI systems in achieving explainability. We make use of Linguistic Protoform Summaries in tandem with Fuzzy Rules to design a system that can compare datasets numerically, as well as explain the difference in Natural Language. We validate our method with the help of synthetic data and show that it produces high correlation with the well-known Euclidean distance measure. We also employ the proposed method to explain changes in daily pulse rate measurements of an elderly resident living in a sensor equipped smart home. We postulate that the method will help in future endeavors to produce explainable pattern recognition systems. © 2019 IEEE.","10.1109/FUZZ-IEEE.2019.8858911","Conference paper","2019","Automation; Clustering algorithms; Fuzzy inference; Fuzzy rules; Intelligent systems; Linguistics; Natural language processing systems; Distance measure; Euclidean distance measure; Linguistic terms; Natural language generation; Natural languages; Protoforms; Smart homes; Synthetic data; Pattern recognition systems","Scopus"
"Metric learning for value alignment","Preference are central to decision making by both machines and humans. Representing, learning, and reasoning with preferences is an important area of study both within computer science and across the social sciences. When we give our preferences to an AI system we expect the system to make decisions or recommendations that are consistent with our preferences but the decisions should also adhere to certain norms, guidelines, and ethical principles. Hence, when working with preferences it is necessary to understand and compute a metric (distance) between preferences - especially if we encode both the user preferences and ethical systems in the same formalism. In this paper we investigate the use of CP-nets as a formalism for representing orderings over actions for AI systems. We leverage a recently proposed metric for CP-nets and a neural network architecture, CPMETRIC, for computing this metric. Using these two tools we look at the how one can build a fast and flexible value alignment system. © 2019 CEUR-WS. All rights reserved.","","Conference paper","2019","Behavioral research; Decision making; Network architecture; Philosophical aspects; AI systems; Alignment system; CP-nets; Ethical principles; Metric learning; Artificial intelligence","Scopus"
"Leverage white-collar workers with AI","While in the manufacturing industry robots do the majority of the assembly tasks, robotics process automation, where software robots are taking over repetitive tasks from humans have been introduced only recently. Many routine tasks continue to be executed without adequate assistance from tools that would be in reach of the current technical capabilities of AI. Using the example of taking meeting minutes, the paper presents some intermediate results of the capabilities and problems of currently available natural language processing systems to automatically record meeting minutes. It further highlights the potential of optimizing the allocation of tasks between humans and machines to take the particular strengths and weaknesses of both into account. In order to combine the functionality of supervised and unsupervised machine learning with rule-based AI or traditionally programmed software components, the capabilities of AI-based system actors need to be incorporated into the system design process as early as possible. Treating AI as actors enables a more effective allocation of tasks upfront, which makes it easier to come up with a hybrid workplace scenario where AI can support humans in doing their work more efficiently. Copyright held by the author(s).","","Conference paper","2019","Knowledge engineering; Learning algorithms; Machine learning; Springs (components); Systems analysis; Intermediate results; Manufacturing industries; Process automation; Repetitive task; Software component; System design process; Technical capabilities; Unsupervised machine learning; Natural language processing systems","Scopus"
"Methodologies for continuous life-long machine learning for AI systems","Current machine learning architectures, strategies, and methods are typically static and non-interactive, making them incapable of adapting to changing and/or heterogeneous data environments, either in real-time, or in near-real-time. Typically, in real-time applications, large amounts of disparate data must be processed, learned from, and actionable intelligence provided in terms of recognition of evolving activities. Applications like Rapid Situational Awareness (RSA) used for support of critical systems (e.g., Battlefield Management and Control) require critical analytical assessment and decision support by automatically processing massive and increasingly amounts of data to provide recognition of evolving events, alerts, and providing actionable intelligence to operators and analysts [2 and 4]. Herein we prescribe potential methods and strategies for continuously adapting, life-long machine learning within a self-learning and self-evaluation environment to enhance real-time/near real-time support for mission critical systems. We describe the notion of continuous adaptation, which requires an augmented paradigm for enhancing traditional probabilistic machine learning. Specifically, systems which must more aptly operate in harsh/soft unknown environments without the need of a priori statistically trained neural networks nor fully developed learning rules for situations that have never been thought of yet. This leads to a hypothesis requiring new machine learning processes, in which abductive learning is applied. We utilize varying unsupervised/self-supervised learning techniques, statistical/fuzzy models for entities, relationships, and descriptor extraction. We also involve topic and group discovery and abductive inference algorithms. to expand system aperture in order to envision what outlying factors could have also caused current observations. Once extended plausible explanations are found, we will show how a system uses the afore mentioned implements to potentially learn about new or modified causal relationships and extend, reinterpret, or create new situational driven memories. CSREA Press ©.","","Conference paper","2018","Decision support systems; Inference engines; Information management; Machine learning; Unsupervised learning; Abductive learning; Battlefield management; Descriptor extractions; Mission critical systems; Probabilistic machines; Real-time application; Situational awareness; Trained neural networks; Real time systems","Scopus"
"Moving towards an adaptive enterprise intrusion detection and prevention system","In this paper, we describe our plans to create a smarter network defense system through the collection and analysis of network signatures generated by real security threats. To meet this goal, we plan to create software agents interconnected to a central behavior analysis database service where each software agent records attack meta-information collected during previous intrusion attempts. The central database warehouses and analyzes the meta-information collected by the interconnected agents. The agents can then utilize both instantaneous and historical data by integrating rules derived from the data collection and analysis process into intrusion prevention policies. The result is a modular and scalable network defense system that should be more responsive and adaptable to imminent threats. © 2019 ICAI 2015 - WORLDCOMP 2015. All rights reserved.","","Conference paper","2019","Artificial intelligence; Data mining; Decision support systems; Intelligent networks; Intrusion detection; Network security; Adaptive enterprise; Behavior analysis; Cyber security; Distributed AI; Intrusion detection and prevention systems; Intrusion prevention; Network defense systems; Scalable networks; Software agents","Scopus"
"A multi-modal approach for non-invasive detection of coronary artery disease","Coronary Artery Disease (CAD) is a leading cause of death globally. Coronary angiography, the clinical diagnosis for CAD involves a surgery and admission to hospital. While this is a proven gold standard, having a less exact low-cost non-invasive screening method would be very helpful in mass diagnosis and pre-diagnosis. However, all physiological manifestations of CAD either appear late in the time-curve or are non-specific surrogate markers. With the advent of Artificial Intelligence (AI), there is new hope using multi-modal non-invasive sensing and analysis. In this paper, we combine domain knowledge with AI based data analysis to propose a novel two-stage approach that effectively incorporates multiple CAD markers in various non-invasive cardiovascular signals for an improved diagnosis system. At first stage, a hierarchical rule-engine identifies the high cardiac risk population using patient demography and medical history, who are further analysed at the second stage using numeric features from various cardiovascular signals. Results show that the proposed approach achieves sensitivity = 0.96 and specificity = 0.91 in classifying CAD patients on an in-house hospital dataset, recorded using commercially available sensors. © 2019 Association for Computing Machinery.","10.1145/3341162.3349331","Conference paper","2019","Classification (of information); Computer aided diagnosis; Feature extraction; Heart; Hospitals; Ubiquitous computing; Wearable computers; Cardiovascular signals; Clinical diagnosis; Coronary angiography; Coronary artery disease; Multi-modal approach; Non-invasive detection; Non-invasive sensing; Two stage approach; Diseases","Scopus"
"SK-MOEFS: A Library in Python for Designing Accurate and Explainable Fuzzy Models","Recently, the explainability of Artificial Intelligence (AI) models and algorithms is becoming an important requirement in real-world applications. Indeed, although AI allows us to address and solve very difficult and complicated problems, AI-based tools act as a black box and, usually, do not explain how/why/when a specific decision has been taken. Among AI models, Fuzzy Rule-Based Systems (FRBSs) are recognized world-wide as transparent and interpretable tools: they can provide explanations in terms of linguistic rules. Moreover, FRBSs may achieve accuracy comparable to those achieved by less transparent models, such as neural networks and statistical models. In this work, we introduce SK-MOEFS (acronym of SciKit-Multi Objective Evolutionary Fuzzy System), a new Python library that allows the user to easily and quickly design FRBSs, employing Multi-Objective Evolutionary Algorithms. Indeed, a set of FRBSs, characterized by different trade-offs between their accuracy and their explainability, can be generated by SK-MOEFS. The user, then, will be able to select the most suitable model for his/her specific application. © 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-50153-2_6","Conference paper","2020","Economic and social effects; Fuzzy inference; High level languages; Information management; Knowledge based systems; Black boxes; Fuzzy models; Linguistic rules; Models and algorithms; Multi objective evolutionary algorithms; Multi-objective evolutionary fuzzy systems; Real-world; Trade off; Evolutionary algorithms","Scopus"
"Artificial intelligence-based optimal PID controller design for BLDC motor with phase advance","This paper proposes the artificial intelligence (AI)-based optimal PID controller design optimization of brushless direct current (BLDC) motor speed control with phase advance approach. The proposed control system allows the speed adjustment of the BLDC motor by phase advance technique. In this paper, two selected AI algorithms, i.e., the adaptive tabu search (ATS) and the intensified current search (ICS) are conducted as the optimizer for the PID controller design. The proposed control system is simulated by MATLAB/SIMULINK. Results obtained by the ATS and ICS will be compared with those obtained by the Ziegler-Nichols (ZN) tuning rule and the genetic algorithm (GA). It shows that the speed response of the BLDC motor by phase advance with the PID controller optimized by the ICS outperforms better than the ZN, GA and ATS. © 2019 Institute of Advanced Engineering and Science. All rights reserved.","10.11591/ijeei.v7i1.xxxx","Article","2019","","Scopus"
"ISR-brain machine intelligence for unmanned aircraft systems","This paper presents a system for extrapolating knowledge and classification rules from existing ISR FMV and creating an ISRBrain. As combat operations have grown to depend upon assured, live ISR support during operations, US forces are presented with formidable challenges to integrate artificial intelligence (AI) capabilities with existing ISR systems. The common challenge being the variance at which advances in commercial and academic AI are deployed compared to rate of speed that innovative AI systems are developed and utilized in military domains. ISR, USAF and SOCOM need to develop a means to seamlessly integrate military and commercial state-of-the-art systems. The ISR-Brain presented will be capable of converting classifiers in existing ISR FMV to machine learning rules for real time ISR sensor, multi-source, multi-enclave data and adaptable with ongoing research efforts with A2, SOCOM, JIEDO, MITRE and Project MAVEN to develop and test and ISR-Brain to enable the system to integrate with all ISR sensors and predict future Troops in Contact events (TIC) and IED events. © 2018 Association for Computing Machinery.","10.1145/3271553.3271594","Conference paper","2018","Artificial intelligence; Image processing; Learning systems; Combat operations; Knowledge and classification; Machine intelligence; Military domains; Multi-Sources; Research efforts; State-of-the-art system; Unmanned aircraft system; Unmanned aerial vehicles (UAV)","Scopus"
"Metamorphic testing of AI-based applications: A critical review","Metamorphic testing is the youngest testing approach among other members of the testing family. It is designed to test software, which are complex in nature and it is difficult to compute test oracle for them against a given set of inputs. Metamorphic testing approach tests the software with the help of metamorphic relations that guide the tester to check if the observed output can be produced after applying a certain input. Since its first appearance, a lot of research has been done to check its effectiveness on different complex families of software applications like search engines, compilers, artificial intelligence (AI) and so on. Artificial intelligence has gained immense attention due to its successfully application in many of the computer science and even other domains like medical science, social science, economic, and so on. AI-based applications are quite complex in nature as compared to other conventional software applications and because of that they are hard to test. We have selected specifically testing of AI-based applications for this research study. Although all the researchers claim to propose the best set of metamorphic relations to test AI-based applications but that still needs to be verified. In this study, we have performed a critical review supported by rigorous set of parameters that we have prepared after thorough literature survey. The survey shows that researchers have applied metamorphic testing on applications that are either based on Genetic Algorithm (GA) or Machine Learning (ML). Our analysis has helped us identifying the strengths and weaknesses of the proposed approaches. Research still needs to be done to design a generalized set of metamorphic rules that can test a family of AI applications rather than just one. The findings are supported by strong arguments and justified with logical reasoning. The identified problem domains can be targeted by the researchers in future to further enhance the capabilities of metamorphic testing and its range of applications. © 2020 Science and Information Organization.","10.14569/IJACSA.2020.0110498","Article","2020","Application programs; Learning algorithms; Machine learning; Search engines; Social sciences computing; Software testing; Surveys; Testing; Critical review; Medical science; Metamorphic relations; Metamorphic testing; Oracle problem; Research studies; Software applications; Test oracle problem; Test oracles; Test softwares; Genetic algorithms","Scopus"
"Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions","Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase. © 2018 ACM.","10.1145/3278721.3278751","Conference paper","2018","Computation theory; Decision making; Employment; Philosophical aspects; attempts at refutation; Automatic decision; Computational framework; Constrained models; Logical theories; problem of induction; Semi-automatics; Structured approach; Behavioral research","Scopus"
"A Nursing Robot for Social Interactions and Health Assessment","Social Robotics for nursing care gain increasing importance in the age of demographic change and fast development of artificial intelligence. Social robots are automated or autonomous machines capable of interacting with people on the basis of social rules and are mostly humanoid and mobile. The Cologne Cobots Lab (Cologne Cobots Lab is an interdisciplinary research lab of the TH K&#x00F6;ln &#x2013; University of Applied Sciences, with its main research focus in the areas of collaborative and social robotics) is currently carrying out research in social and cognitive robotics. In the context of nursing care, approaches for capturing emotions and the state of mind of patients through different interaction analytics will be developed. We will use the humanoid robot pepper and extend its software functions so that it can take initiatives in human-machine-conversation. We conduct different user-centered experiments in real-world conditions and investigate the verbal interactions among human users and the robot system. In this regard, it would be both valuable and interesting to find out whether an AI enabled humanoid robot is able to stimulate or encourage conversation or even perform better than a natural conversation partner. &#x00A9; 2020, Springer Nature Switzerland AG.","10.1007/978-3-030-20467-9_8","Conference paper","2020","Anthropomorphic robots; Human computer interaction; Human engineering; Nursing; Robotics; Health assessments; Human-robot collaboration; Natural languages; Nursing care; Social interactions; Social robotics; Human robot interaction","Scopus"
"Trustworthy AI: Towards the golden age of RE?","In April, 2018, the European Commission established its vision of Arti- ficial Intelligence (AI), leading to the production of guidelines to achieve trustworthy AI one year later. These guidelines, although not men- tioning it explicitly, overow with issues well known in Requirements Engineering (RE). By relating recent RE works to these guidelines, this position paper attempts to show that RE is one of the core components for achieving trustworthy AI, and thus can have a critical impact on the evolution of AI systems and the AI field as a whole for the next few years in Europe. Copyright © 2020 for this paper by its authors.","","Conference paper","2020","Computer software selection and evaluation; AI systems; Core components; European Commission; Position papers; Requirements engineering","Scopus"
"Privacy and Security of Big Data in AI Systems: A Research and Standards Perspective","The huge volume, variety, and velocity of big data have empowered Machine Learning (ML) techniques and Artificial Intelligence (AI) systems. However, the vast portion of data used to train AI systems is sensitive information. Hence, any vulnerability has a potentially disastrous impact on privacy aspects and security issues. Nevertheless, the increased demands for high-quality AI from governments and companies require the utilization of big data in the systems. Several studies have highlighted the threats of big data on different platforms and the countermeasures to reduce the risks caused by attacks. In this paper, we provide an overview of the existing threats which violate privacy aspects and security issues inflicted by big data as a primary driving force within the AI/ML workflow. We define an adversarial model to investigate the attacks. Additionally, we analyze and summarize the defense strategies and countermeasures of these attacks. Furthermore, due to the impact of AI systems in the market and the vast majority of business sectors, we also investigate Standards Developing Organizations (SDOs) that are actively involved in providing guidelines to protect the privacy and ensure the security of big data and AI systems. Our far-reaching goal is to bridge the research and standardization frame to increase the consistency and efficiency of AI systems developments guaranteeing customer satisfaction while transferring a high degree of trustworthiness. © 2019 IEEE.","10.1109/BigData47090.2019.9006283","Conference paper","2019","Artificial intelligence; Big data; Customer satisfaction; Network security; Business sector; Defense strategy; Driving forces; High quality; Privacy and security; Privacy aspects; Security issues; Sensitive informations; Data privacy","Scopus"
"An architecture for a military AI system with ethical rules","The current era of computer science has seen a significant increase in the application of machine learning (ML) and knowledge representation (KR). The problem with the current situation regarding ethics and AI is the weaknesses of ML and KR when used separately. ML will “learn” ethical behaviour as it is observed and may therefore disagree with human morals. On the other hand, KR is too rigid and can only process scenarios that have been predefined. This paper proposes a solution to the question posed by Rossi (2016) “How to combine bottom-up learning approaches with top-down rule-based approaches in defining ethical principles for AI systems?” This system focuses on potential unethical behaviors that are caused by human nature instead of ethical dilemmas caused by technology insufficiency in the wartime scenarios. Our solution is an architecture that combines a classifier to identify targets in wartime scenarios and a rules-based system in the form of ontologies to guide an AI agent’s behaviour in the given circumstance. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2018","Computer architecture; Knowledge representation; Philosophical aspects; Current situation; Ethical dilemma; Ethical principles; Learning approach; On potentials; Rule-based approach; Rules based systems; System focus; Learning systems","Scopus"
"Explainable artificial intelligence for kids","Artificial Intelligence (AI) is part of our everyday life and has become one of the most outstanding and strategic technologies of the 21st century. Explainable AI (XAI in short) is expected to endow AI systems with explanation ability when interacting with humans. This paper describes how to provide kids with natural explanations, i.e., explanations verbalized in Natural Language, in the context of identifying/recognizing roles of basketball players. Semantic grounding is achieved through fuzzy concepts such as tall or short. Selected players are automatically classified by an ensemble of three different decision trees and one fuzzy rule-based classifier. All the single classifiers were first trained with the open source Weka software and then natural explanations were generated by the open source web service ExpliClas. The Human-Computer Interaction interface is implemented in Scratch, that is a visual programming language adapted to kids. The developed Scratch program is used for dissemination purposes when high-school teenagers visit the Research Center in Intelligent Technologies of the University of Santiago de Compostela. Copyright © 2019, the Authors. Published by Atlantis Press. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by-nc/4.0/).","","Conference paper","2020","Basketball; Computer circuits; Decision trees; Fuzzy inference; Fuzzy logic; Human computer interaction; Open source software; Open systems; Semantics; Visual languages; Web services; Fuzzy concept; Fuzzy rule-based classifier; Human computer interaction interface; Intelligent technology; Natural languages; Research center; Strategic technologies; Visual programming languages; Artificial intelligence","Scopus"
"Legible normativity for AI alignment: The value of silly rules","It has become commonplace to assert that autonomous agents will have to be built to follow human rules of behavior-social norms and laws. But human laws and norms are complex and culturally varied systems; in many cases agents will have to learn the rules. This requires autonomous agents to have models of how human rule systems work so that they can make reliable predictions about rules. In this paper we contribute to the building of such models by analyzing an overlooked distinction between important rules and what we call silly rules -rules with no discernible direct impact on welfare. We show that silly rules render a normative system both more robust and more adaptable in response to shocks to perceived stability. They make normativity more legible for humans, and can increase legibility for AI systems as well. For AI systems to integrate into human normative systems, we suggest, it may be important for them to have models that include representations of silly rules. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","10.1145/3306618.3314258","Conference paper","2019","Behavioral research; Philosophical aspects; AI systems; Collective enforcement; Direct impact; Human-AI interaction; Normative system; Rule systems; Social norm; Autonomous agents","Scopus"
"Execution monitoring as meta-games for general game-playing robots","General Game Playing aims to create AI systems that can understand the rules of new games and learn to play them effectively without human intervention. The recent proposal for general game-playing robots extends this to AI systems that play games in the real world. Execution monitoring becomes a necessity when moving from a virtual to a physical environment, because in reality actions may not be executed properly and (human) opponents may make illegal game moves. We develop a formal framework for execution monitoring by which an action theory that provides an axiomatic description of a game is automatically embedded in a meta-game for a robotic player - called the arbiter - whose role is to monitor and correct failed actions. This allows for the seamless encoding of recovery behaviours within a meta-game, enabling a robot to recover from these unexpected events.","","Conference paper","2015","Artificial intelligence; Robots; Virtual reality; Action theory; Execution monitoring; Formal framework; General game playing; Human intervention; Physical environments; Real-world; Unexpected events; Game theory","Scopus"
"Towards providing notifications to enhance teacher's awareness in the classroom","Students often need prompt feedback to make the best from the learning activities. Within classrooms, being aware of students' achievements and weaknesses can help teachers decide how to time feedback. However, they usually cannot easily assess student's progress. We present an approach to generate automated notifications that can enhance teacher's awareness in runtime. This paper formulates the theoretical framing and describes the technological infrastructure of a system that can help teachers orchestrate learning activities and monitor small groups in a multi-tabletop classroom. We define the design guidelines underpinning our system, which include: i) generating notifications from teacher-designed or AI-based sources; ii) enhancing teacher's awareness in the orchestration loop; iii) presenting both positive and negative notifications; iv) allowing teachers to tune the system; and v) providing a private teacher's user interface. Our approach aims to guide research on ways to generate notifications that can help teachers drive their attention and provide relevant feedback for small group learning activities in the classroom. © 2014 Springer International Publishing Switzerland.","10.1007/978-3-319-07221-0_64","Conference paper","2014","Computer aided instruction; Students; User interfaces; Classroom; CSCL; F2F Collaboration; Notifications; Orchestration; Teaching","Scopus"
"Integrating rule-based AI tools into mainstream game development","Rule-based declarative formalisms enjoy several advantages when compared with imperative solutions, especially when dealing with AI-based application development: solid theoretical bases, no need for algorithm design or coding, explicit and easily modifiable knowledge bases, executable declarative specifications, fast prototyping, quick error detection, modularity. For these reasons, ways for combining declarative paradigms, such as Answer Set Programming (ASP), with traditional ones have been significantly studied in the recent years; there are however relevant contexts, in which this road is unexplored, such as development of real-time games. In such a setting, the strict requirements on reaction times, the presence of computer-human interactivity and a generally increased impedance between the two development paradigms make the task nontrivial. In this work we illustrate how to embed rule-based reasoning modules into the well-known Unity game development engine. To this end, we present an extension of EmbASP, a framework to ease the integration of declarative formalisms with generic applications. We prove the viability of our approach by developing a proof-of-concept Unity game that makes use of ASP-based AI modules. © Springer Nature Switzerland AG 2018.","10.1007/978-3-319-99906-7_23","Conference paper","2018","Artificial intelligence; Computer programming languages; Knowledge based systems; Knowledge representation; Logic programming; Software design; Answer set programming; Game Programming; Knowledge representation and reasoning; Logic programs; Unity; Software prototyping","Scopus"
"AIC - An AI-system for Combination of senses","AI-complete systems developed today, are commonly used for solving different artificial intelligence problems. A problem is a typical image recognition or speech recognition, but it can also be language processing, as well as, other complex systems dealing with general problem solving. However, no AI-complete system, which models the human brain or behavior, can exist without looking at the totality of the whole situation and, and hence, incorporating an AI-computerized sensory systems into a totality that constitute a combination of senses. This paper proposes a combination of sensory systems to form a comprehensive AI-system by combining the different senses, called AIC-AI-system for a combination of senses. The AIC-system is not a complete system in the sense that it contains a total set of information or uses all kinds of digital sensory systems. Nonetheless, it is a system under self-development. It develops its own knowledge base, as experiences, which will be based on the different characteristics: images, sounds, smells, tastes, touches with emotions/feelings and expressions. The result is a kind of perception of the surrounding environment. © 2013 The Authors.","10.1016/j.procs.2013.09.079","Conference paper","2013","","Scopus"
"Novel AI based on-line sequential learning technique for high performance DC servo motor control","In this paper a neuro-fuzzy based adaptive tracking controller which is trained when the controller is operating in an online mode for high performance DC servo motor control is presented. The proposed structure consists of five layer feed-forward network which is trained using sequential learning method. Extreme Learning Machine (ELM), a recently developed novel method for the training of the single hidden layer feed forward neural networks (SLFNs) is used to initialize the training algorithm with a small chunk of training data. The membership function for each rule is determined using heuristics based methods and the consequent parameters of the Tagaki-Sugeno-Kang (TSK) type fuzzy inference are then determined in an online manner using the recursive least square method. The performance of the proposed technique in terms of the training time, training accuracy for tracking a reference trajectory is evaluated and is compared with the adaptive neuro-fuzzy based controller and other existing faster training algorithms such as ELM. The robustness of the proposed scheme is tested under DC motor parameters variations such as armature resistance, viscous friction and moment of inertia for all implemented controllers. Results obtained ensure the robustness of the proposed controller versus other implemented controllers.","","Article","2015","","Scopus"
"A comparison of hybrid neural network based breast cancer diagnosis systems","Breast cancer is the second leading cause of death among the women aged between 40 and 59 in the world. The diagnosis of such disease has been a challenging research problem. With the advancement of artificial intelligence in medical science, numerous AI based breast cancer diagnosis system have been proposed. Many researches combine different algorithms to develop hybrid systems to improve the diagnosis accuracy. In this study, we propose three artificial neural network based hybrid diagnosis systems respectively combining association rule, correlation and genetic algorithm. The effectiveness of these systems is examined on Wisconsin Breast Cancer Dataset. We then compare the accuracy of these three hybrid diagnosis systems. The results indicated that the neural network combining with association rule not only has excellent dimensionality reduction ability but also has the similar accurate prediction with correlation based neural network which has best accurate prediction rate among all three systems compared. © Springer International Publishing Switzerland 2015.","10.1007/978-3-319-20895-4_59","Conference paper","2015","Algorithms; Artificial intelligence; Association rules; Diseases; Genetic algorithms; Human computer interaction; Hybrid systems; Neural networks; Accurate prediction; Breast cancer diagnosis; Dimensionality reduction; Hybrid diagnosis; Hybrid neural networks; Medical science; Research problems; Wisconsin breast cancer dataset; Diagnosis","Scopus"
"Towards general game-playing robots: Models, architecture and game controller","General Game Playing aims at AI systems that can understand the rules of new games and learn to play them effectively without human intervention. Our paper takes the first step towards general game-playing robots, which extend this capability to AI systems that play games in the real world.We develop a formal model for general games in physical environments and provide a systems architecture that allows the embedding of existing general game players as the ""brain"" and suitable robotic systems as the ""body"" of a general game-playing robot. We also report on an initial robot prototype that can understand the rules of arbitrary games and learns to play them in a fixed physical game environment. © Springer International Publishing 2013.","10.1007/978-3-319-03680-9_29","Conference paper","2013","Artificial intelligence; Game controller; General game playing; Human intervention; Physical environments; Physical games; Robot prototypes; Robotic systems; Systems architecture; Robots","Scopus"
"Production systems: New techniques in AAA games","Production systems have been around since the 1940s and are now applied in a wide array of applications and ongoing research. AAA games bring a unique set of challenges to production systems; they require that AI systems be runtime efficient, deterministic, memory lean, and above all, implementable within the development cycle. Over the course of many of our titles, production systems have developed along different lines. This chapter tries to describe the majority of our more unique production systems, assuming that the reader has a basic knowledge of production systems. For readers who want to code their first production system, there is a list of references that describe basic production systems in more detail [Luger 93, Millington 09, Laird 12, Bourg 04] and these 9.1 Introduction 9.2 What Decisions Is the System Trying to Make? 9.3 Choice of Rules Representation 9.4 Method of Rules Authoring 9.5 Choice of Matching System 9.6 What Happens If the AI Fails to Find a Rule? © 2015 by Taylor & Francis Group, LLC.","10.1201/b18373","Book chapter","2015","","Scopus"
"Graph databases for designing high-performance speech recognition grammars","The present paper reports on the advantages of using graph databases in the development of dynamic language models in Spoken Language Understanding applications, such as spoken dialogue systems. First of all, we introduce Neo4J graph databases and, specifically, MultiWordNet-Extended, a graph representing linguistic knowledge. After this first overview, we show how information included in graphs can be used in speech recognition grammars to automatically extend a generic rule structure. This can be the case of linguistic elements, such as synonyms, hypernyms, meronyms and phonological neighbours, which are semantically or structurally related to each other in our mental lexicon. In all the AI based approaches depending on a training process using large and representative corpora, the probability to correctly predict the creativity a speaker can perform in using language and posing questions is lower than expected. Trying to capture most of the possible words and expressions a speaker could use is extremely necessary, but even an empirical, finite collection of cases could not be enough. For this reason, the use of our tool appears as an appealing solution, capable of including many pieces of information. In addition, we used the proposed tool to develop a spoken dialogue system for museums and the preliminary results are shown and discussed in this paper. © IWCS 2017. All rights reserved.","","Conference paper","2017","Linguistics; Speech processing; Speech recognition; Dynamic languages; Generic rules; Graph database; Hypernyms; Language model; Linguistic knowledge; Multi-wordnet; Performance; Spoken dialogue system; Spoken language understanding; Graph Databases","Scopus"
"Criteria for human-compatible AI in two-player vision-language tasks","We propose rule-based search systems that outperform not only the state-of-the-art but the human performance, measured in accuracy, in Guess- What?!, a vision-language game where either of two players can be a human. Although those systems achieve the high accuracy, they do not meet other requirements to be considered as an AI system that communicates effectively with humans. To clarify what they lack, we suggest the use of three criteria to enable effective communication with humans in vision-language tasks. These criteria also apply to other two-player vision-language tasks that require communication with humans, e.g., ReferIt.","","Conference paper","2017","AI systems; Effective communication; High-accuracy; Human performance; Language games; Rule based; Search system; State of the art; Linguistics","Scopus"
"A process to transfer Fail2ban data to an adaptive enterprise intrusion detection and prevention system","In this paper, we describe a process that has been developed to transfer network intrusion data captured by Fail2ban to an adaptive enterprise intrusion detection and prevention system. The process involves software agents that we have created that are interconnected to a central behavior analysis database service where each software agent records attack meta-information collected during previous intrusion attempts. These distributed agents are the first phase of an overall plan to create a smarter network defense system through the collection and analysis of network signatures generated by real security threats. The central database to which the agents report warehouses and analyzes the meta-information collected by the interconnected agents. The agents can then utilize both instantaneous and historical data by integrating rules derived from the data collection and analysis process into intrusion prevention policies. The final result will be a modular and scalable network defense system that should be more responsive and adaptable to imminent threats. © 2016 IEEE.","10.1109/SECON.2016.7506771","Conference paper","2016","Artificial intelligence; Data mining; Decision support systems; Intelligent networks; Intrusion detection; Mercury (metal); Network security; Adaptive enterprise; Behavior analysis; Cyber security; Distributed agents; Distributed AI; Intrusion detection and prevention systems; Intrusion prevention; Network defense systems; Software agents","Scopus"
"Arguments for ethical systems design","Today's AI applications are so successful that they inspire renewed concerns about AI systems becoming ever more powerful. Addressing these concerns requires AI systems that are designed as ethical systems, in the sense that their choices are context-dependent, value-guided and rule-following. It is shown how techniques connecting qualitative and quantitative primitives recently developed for evidential argumentation in the law can be used for the design of such ethical systems. In this way, AI and Law techniques are extended to the theoretical understanding of intelligent systems guided by embedded values. © 2016 The authors and IOS Press. All rights reserved.","10.3233/978-1-61499-726-9-101","Conference paper","2016","Information systems; Intelligent systems; Philosophical aspects; AI and law; AI applications; AI systems; Context dependent; Embedded systems","Scopus"
"A relational dual tableau decision procedure for multimodal and description logics","We present a dual tableau based decision procedure for a class of fragments of the classical relational logic of binary relations. The logics considered share a common language involving a restricted composition operator and infinitely many relational constants which may have the properties of reflexivity, transitivity, and heredity. The construction of the dual tableau is carried out by applying in a deterministic way axioms and inference rules of the system without resorting to external tools. An important feature of the dual tableau procedure is a rule to handle the relational composition operator, that permits to decompose in a single step compositional formulae and negative compositional formulae with the same left object variable. Our relational dual tableau can be used as a decision procedure for validity verification in the multimodal logic K, the description logic ALC, and several non-classical logics for reasoning in various AI systems. © 2014 Springer International Publishing.","10.1007/978-3-319-07617-1_41","Conference paper","2014","Formal languages; Composition operators; Decision procedure; Description logic; Important features; Multi-modal logic; Non-classical logic; Relational composition; Validity verifications; Data description","Scopus"
"Applying and improving monte-carlo tree search in a fighting game AI","This paper evaluates the performance of Monte-Carlo Tree Search (MCTS) in a fighting game AI and proposes an improvement for the algorithm. Most existing fighting game AIs rely on rule bases and react to every situation with predefined actions, making them predictable for human players. We attempt to overcome this weakness by applying MCTS, which can adapt to different circumstances without relying on predefined action patterns or tactics. In this paper, an AI based on Upper Confidence bounds applied to Trees (UCT) and MCTS is first developed. Next, the paper proposes improving the AI with Roulette Selection and a rule base. Through testing and evaluation using Fighting-ICE, an international fighting game AI competition platform, it is proven that the aforementioned MCTS-based AI is effective in a fighting game, and our proposed improvement can further enhance its performance. © 2016 ACM.","10.1145/3001773.3001797","Conference paper","2016","Artificial intelligence; Monte Carlo methods; Fighting game; FightingICE; MCTS; Monte Carlo tree search (MCTS); Monte-Carlo tree searches; Roulette selection; Testing and evaluation; Upper confidence bound; Trees (mathematics)","Scopus"
"The ethics of robotic caregivers","As Artificial Intelligence technology seems poised for a major take-off and changing societal dynamics are creating a high demand for caregivers for elders, children, and those infirmed, robotic caregivers may well be used much more often. This article examines the ethical concerns raised by the use of AI caregivers and concludes that many of these concerns are avoided when AI caregivers operate as partners rather than substitutes. Furthermore, most of the remaining concerns are minor and are faced by human caregivers as well. Nonetheless, because AI caregivers' systems are learning systems, an AI caregiver could stray from its initial guidelines. Therefore, subjecting AI caregivers to an AI-based oversight system is proposed to ensure that their actions remain both legal and ethical.","10.1075/is.18.2.02etz","Article","2017","","Scopus"
"Dynamic rule-based agent","This paper proposes a dynamic rule-based agent that can support the dynamic reasoning by coherently combining the conventional rule-based expert system agent with the dynamic modelling framework. The dynamic reasoning is one of essential mechanisms to mimic the human decision-making process. Since the timing difference between internal rule firing and externally incoming fact is critical to conclude the final decision. Unfortunately conventional AI systems cannot deal with such problems. In order to overcome this limitation, we have proposed the dynamic rule structure that consists of the condition and action as well as the inferencing time. Then we also have developed the dynamic inference algorithm that can handle the time-based rules. Our approach is compared with others in that it can support the dynamic rule structure and dynamic inference. Simulation test performed on the baseball example has been successfully applied to illustrate the feasibility of our technique. © International Research Publication House.","","Article","2018","","Scopus"
"Developing high value IoT solutions using AI enhanced ISO 16355 for QFD integrating market drivers into the design of IoT offerings","The Internet of Things (IoT) provides huge opportunities for organisations developing new business models supported by interconnected product, service and software systems. Due to the complexity of IoT systems, the understanding and development of attractive new system functions is a great challenge compared with traditional, stand-alone product systems. Methods that focus on the integration of market and business analysis with product design and development emerged from Japan in the late 1960s under the title of Quality Function Deployment (QFD). These have undergone considerable development over the last 30 years to ensure they are appropriate for the development of both complex hardware, software and service systems and the current best practices are described in the recently published ISO 16355 for QFD. Recent significant progress in development of cognitive artificial intelligence (AI) systems such as IBM's Watson system, provides opportunities to gather and analyse significant volumes of market and technological information to support the core objectives of QFD i.e. aligning new product system design to customer and stakeholder priorities. This involves targeting information sources, refining analysis algorithms to ensure market priorities with associated underlying trends are identified reliably. In this paper, background concepts related to QFD are discussed and the areas where cognitive AI can have most significant impact on the QFD approach towards design and development of IoT systems will be covered. © 2017 IEEE.","10.1109/C-CODE.2017.7918967","Conference paper","2017","C (programming language); Cognitive systems; Commerce; Product design; Quality control; Quality function deployment; Systems analysis; Analysis algorithms; Design and Development; Information sources; Internet of thing (IOT); ISO 16355; New business models; Product design and development; Quality function deployments (QFD); Internet of things","Scopus"
"Viewpoint designing ai systems that obey our laws and values calling for research on automatic oversight for artificial intelligence systems.","OPERATIONAL AI SYSTEMS (for example, self-driving cars) need to obey both the law of the land and our values. We propose AI oversight systems (""AI Guardians"") as an approach to addressing this challenge, and to respond to the potential risks associated with increasingly autonomous AI systems.a These AI oversight systems serve to verify that operational systems did not stray unduly from the guidelines of their programmers and to bring them back in compliance if they do stray. The introduction of such second-order, oversight systems is not meant to suggest strict, powerful, or rigid (from here on 'strong') controls. Operations systems need a great degree of latitude in order to follow the lessons of their learning from additional data mining and experience and to be able to render at least semiautonomous decisions (more about this later). However, all operational systems need some boundaries, both in order to not violate the law and to adhere to ethical norms. Developing such oversight systems, AI Guardians, is a major new mission for the AI community.","10.1145/2955091","Review","2016","Artificial intelligence; Data mining; Additional datum; AI systems; Artificial intelligence systems; Operational systems; Potential risks; Second orders; Self drivings; Compliance control","Scopus"
"Aesthetic visual quality evaluation of Chinese handwritings","Aesthetic evaluation of Chinese calligraphy is one of the most challenging tasks in Artificial Intelligence. This paper attempts to solve this problem by proposing a number of aesthetic feature representations and feeding them into Artificial Neural Networks. Specifically, 22 global shape features are presented to describe a given handwritten Chinese character from different aspects according to classical calligraphic rules, and a new 10-dimensional feature vector is introduced to represent the component layout information using sparse coding. Moreover, a Chinese Handwriting Aesthetic Evaluation Database (CHAED) is also built by collecting 1000 Chinese handwriting images with diverse aesthetic qualities and inviting 33 subjects to evaluate the aesthetic quality for each calligraphic image. Finally, back propagation neural networks are constructed with the concatenation of the proposed features as input and then trained on our CHAED database for the aesthetic evaluation of Chinese calligraphy. Experimental results demonstrate that the proposed AI system provides a comparable performance with human evaluation. Through our experiments, we also compare the importance of each individual feature and reveal the relationship between our aesthetic features and the aesthetic perceptions of human beings.","","Conference paper","2015","Artificial intelligence; Backpropagation; Neural networks; Aesthetic perception; Back propagation neural networks; Chinese calligraphy; Chinese handwriting; Global shape feature; Handwritten Chinese character; Individual features; Visual quality evaluation; Quality control","Scopus"
"Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement","The evaluation of artificial intelligence systems and components is crucial for the progress of the discipline. In this paper we describe and critically assess the different ways AI systems are evaluated, and the role of components and techniques in these systems. We first focus on the traditional task-oriented evaluation approach. We identify three kinds of evaluation: human discrimination, problem benchmarks and peer confrontation. We describe some of the limitations of the many evaluation schemes and competitions in these three categories, and follow the progression of some of these tests. We then focus on a less customary (and challenging) ability-oriented evaluation approach, where a system is characterised by its (cognitive) abilities, rather than by the tasks it is designed to solve. We discuss several possibilities: the adaptation of cognitive tests used for humans and animals, the development of tests derived from algorithmic information theory or more integrated approaches under the perspective of universal psychometrics. We analyse some evaluation tests from AI that are better positioned for an ability-oriented evaluation and discuss how their problems and limitations can possibly be addressed with some of the tools and ideas that appear within the paper. Finally, we enumerate a series of lessons learnt and generic guidelines to be used when an AI evaluation scheme is under consideration. © 2016, Springer Science+Business Media Dordrecht.","10.1007/s10462-016-9505-7","Article","2017","Information theory; Algorithmic information theory; Artificial intelligence systems; Cognitive ability; Evaluation approach; Integrated approach; Machine intelligence; Turing tests; Universal psychometrics; Artificial intelligence","Scopus"
"Crowdsourcing and massively collaborative science: A systematic literature review and mapping study","Current times are denoting unprecedented indicators of scientific data production, and the involvement of the wider public (the crowd) on research has attracted increasing attention. Drawing on review of extant literature, this paper outlines some ways in which crowdsourcing and mass collaboration can leverage the design of intelligent systems to keep pace with the rapid transformation of scientific work. A systematic literature review was performed following the guidelines of evidence-based software engineering and a total of 148 papers were identified as primary after querying digital libraries. From our review, a lack of methodological frameworks and algorithms for enhancing interactive intelligent systems by combining machine and crowd intelligence is clearly manifested and we will need more technical support in the future. We lay out a vision for a cyberinfrastructure that comprises crowd behavior, task features, platform facilities, and integration of human inputs into AI systems. © Springer Nature Switzerland AG 2018.","10.1007/978-3-319-99504-5_11","Conference paper","2018","Artificial intelligence; Crowdsourcing; Digital libraries; Distributed computer systems; Intelligent systems; Software engineering; Human computation; Hybrid computation; Massively collaborative science; Scientific collaboration; Systematic literature review; Behavioral research","Scopus"
"AI-based playtesting of contemporary board games","Ticket to Ride is a popular contemporary board game for two to four players, featuring a number of expansions with additional maps and tweaks to the core game mechanics. In this paper, four different game-playing agents that embody different playing styles are defined and used to analyze Ticket to Ride. Different playing styles are shown to be effective depending on the map and rule variation, and also depending on how many players play the game. The performance profiles of the different agents can be used to characterize maps and identify the most similar maps in the space of playstyles. Further analysis of the automatically played games reveal which cities on the map are most desirable, and that the relative attractiveness of cities is remarkably consistent across numbers of players. Finally, the automated analysis also reveals two classes of failures states, where the agents find states which are not covered by the game rules; this is akin to finding bugs in the rules. We see the analysis performed here as a possible template for AI-based playtesting of contemporary board games. © 2017 ACM.","10.1145/3102071.3102105","Conference paper","2017","Artificial intelligence; Computer applications; Computer programming; Automated analysis; Board games; Game playing; Game rules; Performance profile; Playing style; Playtesting; Ticket to Ride; Computer games","Scopus"
"Procedural content generation: An overview","Procedural content generation (PCG) is the process of using an AI system to author aspects of a game that a human designer would typically be responsible for creating, from textures and natural effects to levels and quests, and even to the game rules themselves. Therefore, the creator of a PCG system is responsible for capturing some aspect of a designer’s expertise-a challenging task for an AI! © 2015 by Taylor & Francis Group, LLC.","10.1201/b18373","Book chapter","2015","","Scopus"
"Lifting model sampling for General Game Playing to incomplete-information models","General Game Playing is the design of AI systems able to understand the rules of new games and to use such descriptions to play those games effectively. Games with incomplete information have recently been added as a new challenge for general game-playing systems. The only published solutions to this challenge are based on sampling complete information models. In doing so they ground all of the unknown information, thereby making information gathering moves of no value; a well-known criticism of such sampling based systems. We present and analyse a method for escalating reasoning from complete information models to incomplete information models and show how this enables a general game player to correctly value information in incomplete information games. Experimental results demonstrate the success of this technique over standard model sampling. © Copyright 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2015","Artificial intelligence; Game theory; Complete information; Games with incomplete information; General game playing; Incomplete information; Incomplete information games; Information gathering; Sampling-based; Standard model; Information theory","Scopus"
"How AI wins friends and influences people in repeated games with cheap talk","Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as “if you can't say something nice, don't say anything at all” and principles articulated in Carnegie's classic How to Win Friends and Influence People, offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Conference paper","2018","Artificial intelligence; Philosophical aspects; AI systems; Cheap talk; Financial success; Professional knowledge; Repeated games; User study; Behavioral research","Scopus"
"Framework to Develop Artificial Intelligent Autonomous Operating System for Nuclear Power Plants","As artificial intelligent (AI) technology has been dramatically developed, various industries have been challenged to apply it. In a view of nuclear power plants (NPP), it seems that AI technology applies to NPPs at the last because NPPs are required the most stringent level of regulatory guideline for safety. To overcome it, AI technology should be applied incrementally into the NPPs rather than all at once. According to the unintended shutdown records during startup and shutdown operation from 1997 to 2017 in Korea, it is reported that human errors accounts for 40% of the total. This is because operators feel heavy burden to monitor hundreds of parameters for a long time of operating time. Also, there are lots of startup and shutdown operating history that can be used for correcting the data from the NPP simulator. Therefore, this work proposes a framework to develop AI automatic operating system for startup and shutdown operations of NPPs. Operating procedures of startup and shutdown operations are categorized. In addition, AI technologies will be introduced to find out the most suitable learning algorithm. It is expected that economic loss from human error during startup and shutdown operation will be reduced as AI system developed. © Springer International Publishing AG, part of Springer Nature 2018.","10.1007/978-3-319-92046-7_42","Conference paper","2018","Artificial intelligence; Errors; Losses; Nuclear energy; Nuclear fuels; Nuclear power plants; AI Technologies; All-at-once; Artificial intelligent; Economic loss; Human errors; Operating procedure; Operating time; Regulatory guidelines; Plant shutdowns","Scopus"
"SenticNet 4: A semantic resource for sentiment analysis based on conceptual primitives","An important difference between traditional AI systems and human intelligence is the human ability to harness commonsense knowledge gleaned from a lifetime of learning and experience to make informed decisions. This allows humans to adapt easily to novel situations where AI fails catastrophically due to a lack of situation-specific rules and generalization capabilities. Commonsense knowledge also provides background information that enables humans to successfully operate in social situations where such knowledge is typically assumed. Since commonsense consists of information that humans take for granted, gathering it is an extremely difficult task. Previous versions of SenticNet were focused on collecting this kind of knowledge for sentiment analysis but they were heavily limited by their inability to generalize. SenticNet 4 overcomes such limitations by leveraging on conceptual primitives automatically generated by means of hierarchical clustering and dimensionality reduction. © 1963-2018 ACL.","","Conference paper","2016","Computational linguistics; Semantics; Sentiment analysis; Automatically generated; Background information; Commonsense knowledge; Dimensionality reduction; Generalization capability; Hier-archical clustering; Human intelligence; Semantic resources; Data mining","Scopus"
"Machine Learning and Deep Learning Methods for Enhancing Building Energy Efficiency and Indoor Environmental Quality - A Review","The built environment sector is responsible for almost one-third of the world's final energy consumption. Hence, seeking plausible solutions to minimise building energy demands and mitigate adverse environmental impacts is necessary. Artificial intelligence (AI) techniques such as machine and deep learning have been increasingly and successfully applied to develop solutions for the built environment. This review provided a critical summary of the existing literature on the machine and deep learning methods for the built environment over the past decade, with special reference to holistic approaches. Different AI-based techniques employed to resolve interconnected problems related to heating, ventilation and air conditioning (HVAC) systems and enhance building performances were reviewed, including energy forecasting and management, indoor air quality and occupancy com-fort/satisfaction prediction, occupancy detection and recognition, and fault detection and diagnosis. The present study explored existing AI-based techniques focusing on the framework, methodology, and performance. The literature highlighted that selecting the most suitable machine learning and deep learning model for solving a problem could be challenging. The recent explosive growth experienced by the research area has led to hundreds of machine learning algorithms being applied to building performance-related studies. The literature showed that existing research studies considered a wide range of scope/scales (from an HVAC component to urban areas) and time scales (minute to year). This makes it difficult to find an optimal algorithm for a specific task or case. The studies also employed a wide range of evaluation metrics, adding to the challenge. Further developments and more specific guidelines are required for the built environment field to encourage best practices in evaluating and selecting models. The literature also showed that while machine and deep learning had been successfully applied in building energy efficiency research, most of the studies are still at the experimental or testing stage, and there are limited studies which implemented machine and deep learning strategies in actual buildings and conducted the post-occupancy evaluation.","10.1016/j.egyai.2022.100198","Journal Article","2022","Artificial intelligence; Building energy management; Deep learning; Heating ventilation and air conditioning (HVAC); Indoor environmental quality (IEQ); Machine learning; Occupancy detection; Thermal comfort","WoS"
"A Comprehensive Review on AI-Enabled Models for Parkinson's Disease Diagnosis","Parkinson's disease (PD) is a devastating neurological disease that cannot be identified with traditional plasma experiments, necessitating the development of a faster, less expensive diagnostic instrument. Due to the difficulty of quantifying PD in the past, doctors have tended to focus on some signs while ignoring others, primarily relying on an intuitive assessment scale because of the disease's characteristics, which include loss of motor control and speech that can be utilized to detect and diagnose this disease. It is an illness that impacts both motion and non-motion functions. It takes years to develop and has a wide range of clinical symptoms and prognoses. Parkinson's patients commonly display non-motor symptoms such as sleep problems, neurocognitive ailments, and cognitive impairment long before the diagnosis, even though scientists have been working to develop designs for diagnosing and categorizing the disease, only noticeable defects such as movement patterns, speech, or writing skills are offered in this paper. This article provides a thorough analysis of several AI-based ML and DL techniques used to diagnose PD and their influence on developing additional research directions. It follows the guidelines of Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR). This review also examines the current state of PD diagnosis and the potential applications of data-driven AI technology. It ends with a discussion of future developments, which aids in filling critical gaps in the current Parkinson's study.","10.3390/electronics12040783","Journal Article","2023","Parkinson's disease; computational intelligence; deep learning; diagnosis; machine learning; smartphone; augmented reality; virtual reality","WoS"
"Shaping the future of chronic disease management: Insights into patient needs for AI-based homecare systems","Background: The rising demand for healthcare resources, especially in chronic disease management, has elevated the importance of Artificial Intelligence (AI) in healthcare. While AI-based homecare systems are being developed, the perspectives of chronic patients, who are one of the primary beneficiaries and risk bearers of these technologies, remain largely under-researched. While recent research has highlighted the importance of AI-based homecare systems, the current understanding of patients' desired designs and features is still limited. Objective: This paper explores chronic patients' perspectives regarding AI-based homecare systems, an area currently underrepresented in research. We aim to identify the factors influencing their decision to use such systems, elucidate the potential roles of government and other concerned authorities, and provide feedback to AI developers to enhance adoption, system design, and usability and improve the overall healthcare experiences of chronic patients. Method: A web-based open-ended questionnaire was designed to gather the perspectives of chronic patients about AI-based homecare systems. In total, responses from 181 participants were collected. Using Krippendorff's clustering technique, an inductive thematic analysis was performed to identify the main themes and their respective subthemes. Result: Through rigorous coding and thematic analysis of the collected responses, we identified four major themes further segmented into thirteen subthemes. These four primary themes were: 1) ``Personalized Design'', emphasizing the need for patients to manage their health condition better through personalized and educational resources and user-friendly interfaces; 2) ``Emotional & Social Support'', underscoring the desire for AI systems to facilitate social connectivity and provide emotional support to improve the well-being of chronic patients at home; 3) ``System Integration & Proactive Care'', addressing the importance of seamless communication, proactive patient monitoring and integration with existing healthcare platforms; and 4) ``Ethics & Regulation'', prioritizing ethical guidelines, regulatory compliance, and affordability in the design. Conclusion: This study has offered significant insights into the needs and expectations of chronic patients regarding AI-based home care systems. `The findings highlight the importance of personalized and accessible care, emotional and social support, seamless system integration, proactive care, and ethical considerations in designing and implementing such systems. By aligning the design and operation of these systems with the lived experiences and expectations of patients, we can better ensure their acceptance and effectiveness.","10.1016/j.ijmedinf.2023.105301","Journal Article","2024","Artificial Intelligence; Chronic patients; Governance systems; Health Informatics; Qualitative study; Digital health","WoS"
"Artificial intelligence system for stator condition diagnostic","In this paper, an artificial intelligence (AI) system is created in order to overcome difficulties in extracting information about electrical generator stator condition from data generated during offline electrical testing. The proposed AI system will enable classification of generators and that way expose urgency for any service activity. The logic used in expert decision-making is implemented in a fuzzy expert system and tested on a database of 82 generators in Serbia's power plants. This way an objective tool is made to overcome deficiency in sharp, discrete criteria or lack of criteria in international standards. Analysis and fuzzy system rule base will be based on conclusions from official reports about each generator condition and valid international standards and recommendations. The presented methodology is used for condition-based management (CBM) and risk-based management (RBM) of generators.","10.1007/s00202-021-01402-6","Journal Article","2022","Artificial intelligence; Stator; Condition assessment; CBM; RBM","WoS"
"How to explain AI systems to end users: a systematic literature review and research agenda","Purpose Inscrutable machine learning (ML) models are part of increasingly many information systems. Understanding how these models behave, and what their output is based on, is a challenge for developers let alone non-technical end users. Design/methodology/approach The authors investigate how AI systems and their decisions ought to be explained for end users through a systematic literature review. Findings The authors' synthesis of the literature suggests that AI system communication for end users has five high-level goals: (1) understandability, (2) trustworthiness, (3) transparency, (4) controllability and (5) fairness. The authors identified several design recommendations, such as offering personalized and on-demand explanations and focusing on the explainability of key functionalities instead of aiming to explain the whole system. There exists multiple trade-offs in AI system explanations, and there is no single best solution that fits all cases. Research limitations/implications Based on the synthesis, the authors provide a design framework for explaining AI systems to end users. The study contributes to the work on AI governance by suggesting guidelines on how to make AI systems more understandable, fair, trustworthy, controllable and transparent. Originality/value This literature review brings together the literature on AI system communication and explainable AI (XAI) for end users. Building on previous academic literature on the topic, it provides synthesized insights, design recommendations and future research agenda.","10.1108/INTR-08-2021-0600","Journal Article","2022","Explainable AI; Explanatory AI; XAI; Machine learning; Human-computer interaction; End users; Literature review; Systematic literature review","WoS"
"Ethical Challenges for Human-Agent Interaction in Virtual Collaboration at Work","In virtual collaboration at the workplace, a growing number of teams apply supportive conversational agents (CAs). They take on different work-related tasks for teams and single users such as scheduling meetings or stimulating creativity. Previous research merely focused on these positive aspects of introducing CAs at the workplace, omitting ethical challenges faced by teams using these often artificial intelligence (AI)-enabled technologies. Thus, on the one hand, CAs can present themselves as benevolent teammates, but on the other hand, they can collect user data, reduce worker autonomy, or foster social isolation by their service. In this work, we conducted 15 expert interviews with senior researchers from the fields of ethics, collaboration, and computer science in order to derive ethical guidelines for introducing CAs in virtual team collaboration. We derived 14 guidelines and seven research questions to pave the way for future research on the dark sides of human-agent interaction in organizations.","10.1080/10447318.2023.2279400","Journal Article","2023","Conversational agents; human-computer interaction; virtual collaboration; ethics; virtual teams; trust","WoS"
"Enhancing Interpretability of Data-Driven Fault Detection and Diagnosis Methodology with Maintainability Rules in Smart Building Management","Data-driven fault detection and diagnosis (FDD) methods, referring to the newer generation of artificial intelligence (AI) empowered classification methods, such as data science analysis, big data, Internet of things (IoT), industry 4.0, etc., become increasingly important for facility management in the smart building design and smart city construction. While data-driven FDD methods nowadays outperform the majority of traditional FDD approaches, such as the physically based models and mathematically based models, in terms of both efficiency and accuracy, the interpretability of those methods does not grow significantly. Instead, according to the literature survey, the interpretability of the data-driven FDD methods becomes the main concern and creates barriers for those methods to be adopted in real-world industrial applications. In this study, we reviewed the existing data-driven FDD approaches for building mechanical & electrical engineering (M&E) services faults and discussed the interpretability of the modern data-driven FDD methods. Two data-driven FDD strategies integrating the expert reasoning of the faults were proposed. Lists of expert rules, knowledge of maintainability, international/local standards were concluded for various M&E services, including heating, ventilation air-conditioning (HVAC), plumbing, fire safety, electrical and elevator systems based on surveys of 110 buildings in Singapore. The surveyed results significantly enhance the interpretability of data-driven FDD methods for M&E services, potentially enhance the FDD performance in terms of accuracy and promote the data-driven FDD approaches to real-world facility management practices.","10.1155/2022/5975816","Journal Article","2022","","WoS"
"Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)","At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.","10.1109/ACCESS.2018.2870052","Journal Article","2018","Explainable artificial intelligence; interpretable machine learning; black-box models","WoS"
"Savana: Re-using Electronic Health Records with Artificial Intelligence","Health information grows exponentially (doubling every 5 years), thus generating a sort of inflation of science, i.e. the generation of more knowledge than we can leverage. In an unprecedented data-driven shift, today doctors have no longer time to keep updated. This fact explains why only one in every five medical decisions is based strictly on evidence, which inevitably leads to variability. A good solution lies on clinical decision support systems, based on big data analysis. As the processing of large amounts of information gains relevance, automatic approaches become increasingly capable to see and correlate information further and better than the human mind can. In this context, healthcare professionals are increasingly counting on a new set of tools in order to deal with the growing information that becomes available to them on a daily basis. By allowing the grouping of collective knowledge and prioritizing ``mindlines'' against ``guidelines'', these support systems are among the most promising applications of big data in health. In this demo paper we introduce Savana, an AI-enabled system based on Natural Language Processing (NLP) and Neural Networks, capable of, for instance, the automatic expansion of medical terminologies, thus enabling the re-use of information expressed in natural language in clinical reports. This automatized and precise digital extraction allows the generation of a real time information engine, which is currently being deployed in healthcare institutions, as well as clinical research and management.","10.9781/ijimai.2017.03.001","Journal Article","2018","Natural Language Processing; Artificial Intelligence; E-Health; Machine Learning; Electronic Health Records","WoS"
"Trust, but Verify: Informed Consent, AI Technologies, and Public Health Emergencies","To use technology or engage with research or medical treatment typically requires user consent: agreeing to terms of use with technology or services, or providing informed consent for research participation, for clinical trials and medical intervention, or as one legal basis for processing personal data. Introducing AI technologies, where explainability and trustworthiness are focus items for both government guidelines and responsible technologists, imposes additional challenges. Understanding enough of the technology to be able to make an informed decision, or consent, is essential but involves an acceptance of uncertain outcomes. Further, the contribution of AI-enabled technologies not least during the COVID-19 pandemic raises ethical concerns about the governance associated with their development and deployment. Using three typical scenarios-contact tracing, big data analytics and research during public emergencies-this paper explores a trust-based alternative to consent. Unlike existing consent-based mechanisms, this approach sees consent as a typical behavioural response to perceived contextual characteristics. Decisions to engage derive from the assumption that all relevant stakeholders including research participants will negotiate on an ongoing basis. Accepting dynamic negotiation between the main stakeholders as proposed here introduces a specifically socio-psychological perspective into the debate about human responses to artificial intelligence. This trust-based consent process leads to a set of recommendations for the ethical use of advanced technologies as well as for the ethical review of applied research projects.","10.3390/fi13050132","Journal Article","2021","informed consent; terms of use; AI-technologies; technology acceptance; trust; public health emergency; COVID-19; big data; contact tracing; research ethics","WoS"
"AI-based medical e-diagnosis for fast and automatic ventricular volume measurement in patients with normal pressure hydrocephalus","Based on CT and MRI images acquired from normal pressure hydrocephalus (NPH) patients, using machine learning methods, we aim to establish a multimodal and high-performance automatic ventricle segmentation method to achieve an efficient and accurate automatic measurement of the ventricular volume. First, we extract the brain CT and MRI images of 143 definite NPH patients. Second, we manually label the ventricular volume (VV) and intracranial volume (ICV). Then, we use the machine learning method to extract features and establish automatic ventricle segmentation model. Finally, we verify the reliability of the model and achieved automatic measurement of VV and ICV. In CT images, the Dice similarity coefficient (DSC), intraclass correlation coefficient (ICC), Pearson correlation, and Bland-Altman analysis of the automatic and manual segmentation result of the VV were 0.95, 0.99, 0.99, and 4.2 +/- 2.6, respectively. The results of ICV were 0.96, 0.99, 0.99, and 6.0 +/- 3.8, respectively. The whole process takes 3.4 +/- 0.3 s. In MRI images, the DSC, ICC, Pearson correlation, and Bland-Altman analysis of the automatic and manual segmentation result of the VV were 0.94, 0.99, 0.99, and 2.0 +/- 0.6, respectively. The results of ICV were 0.93, 0.99, 0.99, and 7.9 +/- 3.8, respectively. The whole process took 1.9 +/- 0.1 s. We have established a multimodal and high-performance automatic ventricle segmentation method to achieve efficient and accurate automatic measurement of the ventricular volume of NPH patients. This can help clinicians quickly and accurately understand the situation of NPH patient's ventricles.","10.1007/s00521-022-07048-0","Journal Article","2023","Normal pressure hydrocephalus; Machine learning; Computed tomography; Magnetic resonance imaging; Ventricular volume; Intracranial volume; Medical AI; AI-based diagnosis","WoS"
"A Survey of AI-enabled Dynamic Manufacturing Scheduling: From Directed Heuristics to Autonomous Learning","As one of the most complex parts in manufacturing systems, scheduling plays an important role in the efficient allocation of resources to meet individual customization requirements. However, due to the uncertain disruptions (e.g., task arrival time, service breakdown duration) of manufacturing processes, how to respond to various dynamics in manufacturing to keep the scheduling process moving forward smoothly and efficiently is becoming a major challenge in dynamic manufacturing scheduling. To solve such a problem, a wide spectrum of artificial intelligence techniques have been developed to (1) accurately construct dynamic scheduling models that can represent both personalized customer needs and uncertain provider capabilities and (2) efficiently obtain a qualified schedule within a limited time. From these two perspectives, this article systemically makes a state-of-the-art literature survey on the application of these artificial intelligence techniques in dynamic manufacturing modeling and scheduling. It first introduces two types of dynamic scheduling problems that consider service- and task-related disruptions in the manufacturing process, respectively, followed by a bibliometric analysis of artificial intelligence techniques for dynamic manufacturing scheduling. Next, various kinds of artificial-intelligence-enabled schedulers for solving dynamic scheduling problems including both directed heuristics and autonomous learning methods are reviewed, which strive not only to quickly obtain optimized solutions but also to effectively achieve the adaption to dynamics. Finally, this article further elaborates on the future opportunities and challenges of using artificial-intelligence-enabled schedulers to solve complex dynamic scheduling problems. In summary, this survey aims to present a thorough and organized overview of artificial-intelligence-enabled dynamic manufacturing scheduling and shed light on some related research directions that are worth studying in the future.","10.1145/3590163","Journal Article","2023","Artificial intelligence; dynamic scheduling; directed heuristic; autonomous learning; manufacturing system","WoS"
"``Virtual Doctor'' Management Technique in the Diagnosis of ENT Diseases","This research project is about the managing of an ENT (Ear Nose Throat) diagnosis expert system through the virtual doctor that can assist physicians in diagnosing ENT related diseases. ENT problems can distress hearing, speaking, learning and many other significant behaviors and untreated ENT diseases can be serious. Therefore, early diagnose of ENT diseases is fundamental. This study is qualitative in nature where we have used the concept of Virtual Doctor under artificial intelligence (AI) based expert system, already designed to assist physicians in the diagnosis of ENT related disease in the absence of ENT experts. This system can reduce the excess created due to the busy schedules of ENT experts and enhance the effectiveness and efficiency of healthcare system. Virtual Doctor for ENT diagnosis uses rule based system for knowledge representation and has sub-systems which can enhance the physician's ability in reaching a diagnosis decision with assurance. In this paper, we described the management system for application of Virtual Doctor for the diagnosis of ENT related diseases which can be used by physicians in their daily practice.","10.3991/ijoe.v15i09.10665","Journal Article","2019","Virtual Doctor; ENT; Artificial Intelligence; Physians; Expert Systems","WoS"
"Explainable deep learning for attack intelligence and combating cyber-physical attacks","Cyber-physical control loops comprising sensors, actuators and controllers pose the most valued and critical part of the industrial Internet of Things (IIoT) as it regulates the state of the physical process, such as water treatment or gas flow. Thus, any malicious activities could lead to physical damage, affecting human safety. Cyber-physical attacks against the physical process are difficult to detect using existing threats and attack intelligence due to the (1) lack of such intelligence for the physical process and operational technology systems and (2) such attacks affect the process parameters and states. Artificial Intelligence (AI)-based attack intelligence is required. This study proposes an attack intelligence framework for identifying cyber- physical attacks and extracting attack intelligence. We propose an attribution module for attack identification using various machine and deep learning algorithms. We also utilize Explainable AI (XAI) to improve the explainability of the attack attribution module and extract attack intelligence. Our proposed framework is evaluated and tested using a gas pipeline dataset as a use case. We demonstrate that the proposed framework improves the understanding of attacks and provides attack rules, assisting security analysts in securing critical physical processes.","10.1016/j.adhoc.2023.103329","Journal Article","2024","Deep learning; XAI; Industrial process; Detection; Attack intelligence; Industrial IoT","WoS"
"Machine Learning Predicts Patient Tangible Outcomes After Dental Implant Surgery","Dental implants have become increasingly important in daily dental offices. The degree of pain and discomfort experienced during a surgical procedure varies from one patient to another. Using advanced machine learning algorithms to predict pain, the dentist and the patient would make more informed decisions about the treatment. This study aims at Predicting postoperative discomfort using an AI-based multi-linear regression model. The functional parametric association between the eight parameters (age, sex, and operating technique) and the patient's postoperative pain was established following implant surgery. The output was normalized information regarding both incidence and severity of immediate discomfort post-implant surgery. To enhance the generalization ability of the multiple linear regression (MLR) model and avoid overfitting, 825 cases were provided as the training set, while 207 cases were given for data authentication. In addition, 45 samples were used as controls to determine the model's prediction accuracy. Evaluation of the given model reveals a Root Mean Squared Error of 0.1085. This prototype predicted AI model postoperative pain following implant surgery with 89.6 % accuracy. Finally, this AI model exhibited clinical viability and utility in predicting postoperative pain after surgery.","10.1109/ACCESS.2022.3228793","Journal Article","2022","Artificial intelligence; technology; multi-linear regression model; pain; swelling","WoS"
"Artificial intelligence-based detection and assessment of ascites on CT scans","Clinically important ascites are a result of multifactorial pathogenesis. Planning therapy merely depends on precisely detecting and quantitatively classifying ascites to minimize potential adverse effects. However, manually segmenting and quantifying ascites is time-consuming asascites typically appear on multiple CT scans. In this study, an AI-based approach (SRFLab) is developed to quantify ascites from CT scans automatically. First, abdomen sections are automatically acquired from the retrospectively screened CT volume using multitask classification (AcquNet). The proposed CNN is retrieved under a task-specific objective using transfer learning. Alternatively, ascites are learned from a supervision representation fusion CNN (QuanNet) to evaluate fluid formation. Experimental results demonstrate that the proposed schema leads to good performance compared to other existing methods. AcquNet achieved a mean accuracy of 97.80% +/- and a 1.97% standard deviation, while the accuracy of QuanNet achieved a mean accuracy of 97.21% +/- and a 2.61% standard deviation. Overall, the results of this study demonstrate the effec-tiveness of the proposed model and the advancement of the volumetric assessment of ascites on CT volume images. The proposed model is more efficient at detecting and quantifying ascites in patients than clinical experts. Thus, the proposed model can support the rapid grading of ascites on CT volume images and aid radiologists in clinical practice.","10.1016/j.eswa.2023.119979","Journal Article","2023","","WoS"
"Ethical Challenges in the Development of Virtual Assistants Powered by Large Language Models","Virtual assistants (VAs) have gained widespread popularity across a wide range of applications, and the integration of Large Language Models (LLMs), such as ChatGPT, has opened up new possibilities for developing even more sophisticated VAs. However, this integration poses new ethical issues and challenges that must be carefully considered, particularly as these systems are increasingly used in public services: transfer of personal data, decision-making transparency, potential biases, and privacy risks. This paper, an extension of the work presented at IberSPEECH 2022, analyzes the current regulatory framework for AI-based VAs in Europe and delves into ethical issues in depth, examining potential benefits and drawbacks of integrating LLMs with VAs. Based on the analysis, this paper argues that the development and use of VAs powered by LLMs should be guided by a set of ethical principles that prioritize transparency, fairness, and harm prevention. The paper presents specific guidelines for the ethical use and development of this technology, including recommendations for data privacy, bias mitigation, and user control. By implementing these guidelines, the potential benefits of VAs powered by LLMs can be fully realized while minimizing the risks of harm and ensuring that ethical considerations are at the forefront of the development process.","10.3390/electronics12143170","Journal Article","2023","ethical challenges; virtual assistants; Large Language Models; ethical AI; ethical guidelines; data privacy; bias mitigation; public services; AI regulation","WoS"
"Technical Analysis of Contact Tracing Platform Developed by Google-Apple for Constraining the Spread of COVID-19","Amid the ongoing COVID-19 pandemic, technical solutions (e.g., smartphone apps, web-based platforms, digital surveillance platforms, etc.) have played a vital role in constraining the spread of COVID-19. The major aspects in which technical solutions have helped the general public (or health officials) are contact tracing, spread prediction, trend forecasting, infection risk estimation, hotspot identification, alerting people to stay away from contaminated places, hospitalization length estimation, clinical severity analysis, and quarantine monitoring, to name a few. Apart from other services, contact tracing has been extensively performed with the help of Bluetooth and GPS-powered smartphone applications when vaccines were unavailable. In this article, we technically analyze the contact tracing platform developed by Google-Apple for constraining the spread of COVID-19. We suggest unexplored technical functionalities that can further strengthen the platform from privacy preservation, service scenarios, and robustness point of view. Lastly, some AI-based and privacy-assured services that can be integrated with the platform to control the pandemic adequately are suggested. The technical analysis demonstrates that while the Google-Apple platform is well-engineered, it is not free of vulnerabilities, weaknesses, and misconfigurations that may lead to its poor adoption in real-life scenarios. This work can serve as a guideline for further enhancing the practicality of contact tracing platform to effectively handle future infectious diseases.","10.3390/ijgi11110539","Journal Article","2022","COVID-19 pandemic; contact tracing; spread prediction; infection risk estimation; GPS- and Bluetooth-based smart apps; digital surveillance platforms; privacy preservation","WoS"
"Supply chain risk identification: a real-time data-mining approach","Purpose The global pandemic COVID-19 unveils transforming the supply chain (SC) to be more resilient against unprecedented events. Identifying and assessing these risk factors is the most significant phase in supply chain risk management (SCRM). The earlier risk quantification methods make timely decision-making more complex due to their inability to provide early warning. The paper aims to propose a model for analyzing the social media data to understand the potential SC risk factors in real-time. Design/methodology/approach In this paper, the potential of text-mining, one of the most popular Artificial Intelligence (AI)-based data analytics approaches for extracting information from social media is exploited. The model retrieves the information using Twitter streaming API from online SC forums. Findings The potential risk factors that disrupt SC performance are obtained from the recent data by text-mining analyses. The outcomes carry valuable insights about some contemporary SC issues due to the pandemic during the year 2021. The most frequent risk factors using rule mining techniques are also analyzed. Originality/value This study presents the significant role of Twitter in real-time risk identification from online SC platforms like ``Supply Chain Dive'', ``Supply Chain Brain'' and ``Supply Chain Digest''. The results indicate the significant role of data analytics in achieving accurate decision-making. Future research will extend to represent a digital twin for identifying potential risks through social media analytics, assessing risk propagation and obtaining mitigation strategies.","10.1108/IMDS-11-2021-0719","Journal Article","2022","Supply chain risk identification; Data analytics; Text-mining; Sentiment analysis; Social-media","WoS"
"Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence","Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as `Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.","10.1007/s12559-023-10179-8","Journal Article","2023","Machine learning; XAI; Black-box models; Interpretability; Transparency; Responsible AI","WoS"
"AI-based ICD coding and classification approaches using discharge summaries: A literature review","The assignment of codes to free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning clinical codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related machine learning and deep learning methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. The main objective of this systematic literature review is to provide a comprehensive overview of automated clinical coding systems that utilise appropriate NLP, machine learning and deep learning methods and techniques to assign the International Classification of Diseases (ICD) codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2021 in four high quality academic databases: PubMed, ScienceDirect, Association for Computing Machinery (ACM) Digital Library, and the Association for Computational Linguistics (ACL) Anthology. We reviewed 6128 publications; 42 met the inclusion criteria. This review identified: 6 datasets having discharge summaries (2 publicly available, 4 acquired from hospitals); 14 NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. The review also shows that there is a significant increase in the use of deep learning models compared to machine learning. To measure the performance of classification methods, different evaluation metrics are used. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers.","10.1016/j.eswa.2022.118997","Journal Article","2023","Computer assisted clinical coding; Clinical classification and coding; Discharge summaries; Natural Language Processing; Machine learning; Deep learning","WoS"
"Trustworthy artificial intelligence in Alzheimer's disease: state of the art, opportunities, and challenges","Medical applications of Artificial Intelligence (AI) have consistently shown remarkable performance in providing medical professionals and patients with support for complex tasks. Nevertheless, the use of these applications in sensitive clinical domains where high-stakes decisions are involved could be much more extensive if patients, medical professionals, and regulators were provided with mechanisms for trusting the results provided by AI systems. A key issue for achieving this is endowing AI systems with key dimensions of Trustworthy AI (TAI), such as fairness, transparency, robustness, or accountability, which are not usually considered within this context in a generalized and systematic manner. This paper reviews the recent advances in the TAI domain, including TAI standards and guidelines. We propose several requirements to be addressed in the design, development, and deployment of TAI systems and present a novel machine learning pipeline that contains TAI requirements as embedded components. Moreover, as an example of how current AI systems in medicine consider the TAI perspective, the study extensively reviews the recent literature (2017-2021) on AI systems in a prevalent and high social-impact disease: diagnosis and progression detection of Alzheimer's Disease (AD). The most relevant AI systems in the AD domain are compared and discussed (such as machine learning, deep learning, ensembles, time series, and multimodal multitask) from the perspective of how they address TAI in their design. Several open challenges are highlighted, which could be claimed as one of the main reasons to justify the rare application of AI systems in real clinical environments. The study provides a roadmap to measure the TAI status of an AI systems and highlights its limitations. In addition, it provides the main guidelines to overcome these limitations and build medically trusted AI-based applications in the medical domain.","10.1007/s10462-023-10415-5","Journal Article","2023","Trustworthy AI; AI for Alzheimer's disease diagnosis and progression detection; Machine learning in medicine; Responsible AI; Fairness; accountability; and transparency in AI","WoS"
"Chat GPT in Diagnostic Human Pathology: Will It Be Useful to Pathologists? A Preliminary Review with `Query Session' and Future Perspectives","The advent of Artificial Intelligence (AI) has in just a few years supplied multiple areas of knowledge, including in the medical and scientific fields. An increasing number of AI-based applications have been developed, among which conversational AI has emerged. Regarding the latter, ChatGPT has risen to the headlines, scientific and otherwise, for its distinct propensity to simulate a `real' discussion with its interlocutor, based on appropriate prompts. Although several clinical studies using ChatGPT have already been published in the literature, very little has yet been written about its potential application in human pathology. We conduct a systematic review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, using PubMed, Scopus and the Web of Science (WoS) as databases, with the following keywords: ChatGPT OR Chat GPT, in combination with each of the following: pathology, diagnostic pathology, anatomic pathology, before 31 July 2023. A total of 103 records were initially identified in the literature search, of which 19 were duplicates. After screening for eligibility and inclusion criteria, only five publications were ultimately included. The majority of publications were original articles (n = 2), followed by a case report (n = 1), letter to the editor (n = 1) and review (n = 1). Furthermore, we performed a `query session' with ChatGPT regarding pathologies such as pigmented skin lesions, malignant melanoma and variants, Gleason's score of prostate adenocarcinoma, differential diagnosis between germ cell tumors and high grade serous carcinoma of the ovary, pleural mesothelioma and pediatric diffuse midline glioma. Although the premises are exciting and ChatGPT is able to co-advise the pathologist in providing large amounts of scientific data for use in routine microscopic diagnostic practice, there are many limitations (such as data of training, amount of data available, `hallucination' phenomena) that need to be addressed and resolved, with the caveat that an AI-driven system should always provide support and never a decision-making motive during the histopathological diagnostic process.","10.3390/ai4040051","Journal Article","2023","ChatGPT; chatbot; artificial intelligence; AI; pathology; histology","WoS"
"ExAID: A multimodal explanation framework for computer-aided diagnosis of skin lesions","Background and objectives: One principal impediment in the successful deployment of Artificial Intelligence (AI) based Computer-Aided Diagnosis (CAD) systems in everyday clinical workflows is their lack of transparent decision-making. Although commonly used eXplainable AI (XAI) methods provide insights into these largely opaque algorithms, such explanations are usually convoluted and not readily comprehensible. The explanation of decisions regarding the malignancy of skin lesions from dermoscopic images demands particular clarity, as the underlying medical problem definition is ambiguous in itself. This work presents ExAID (Explainable AI for Dermatology), a novel XAI framework for biomedical image analysis that provides multi-modal concept-based explanations, consisting of easy-to-understand textual explanations and visual maps, to justify the predictions. Methods: Our framework relies on Concept Activation Vectors to map human-understandable concepts to those learned by an arbitrary Deep Learning (DL) based algorithm, and Concept Localisation Maps to highlight those concepts in the input space. This identification of relevant concepts is then used to construct fine-grained textual explanations supplemented by concept-wise location information to provide comprehensive and coherent multi-modal explanations. All decision-related information is presented in a diagnostic interface for use in clinical routines. Moreover, the framework includes an educational mode providing dataset-level explanation statistics as well as tools for data and model exploration to aid medical research and education processes. Results: Through rigorous quantitative and qualitative evaluation of our framework on a range of publicly available dermoscopic image datasets, we show the utility of multi-modal explanations for CAD-assisted scenarios even in case of wrong disease predictions. We demonstrate that concept detectors for the explanation of pre-trained networks reach accuracies of up to 81.46%, which is comparable to supervised networks trained end-to-end. Conclusions: We present a new end-to-end framework for the multi-modal explanation of DL-based biomedical image analysis in Melanoma classification and evaluate its utility on an array of datasets. Since perspicuous explanation is one of the cornerstones of any CAD system, we believe that ExAID will accelerate the transition from AI research to practice by providing dermatologists and researchers with an effective tool that they can both understand and trust. ExAID can also serve as the basis for similar applications in other biomedical fields. (C) 2022 Elsevier B.V. All rights reserved.","10.1016/j.cmpb.2022.106620","Journal Article","2022","Artificial intelligence in dermatology; Computer-aided diagnosis; Explainable artificial intelligence; Interpretability; Medical image processing; Textual explanations","WoS"
